-- >> Start of training phase << --
-- Starting training on experience 0 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9439
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4468
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1886
-- Starting training on experience 1 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8035
	data_grads_norm = 9.6514
	new_data_grads_norm = 14.4453
	old_data_grads_norm = 10.5969
	sim_grads_norm_tr = -0.0252
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7526
	data_grads_norm = 8.3843
	new_data_grads_norm = 13.7645
	old_data_grads_norm = 7.6533
	sim_grads_norm_tr = -0.1228
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7111
	data_grads_norm = 8.9148
	new_data_grads_norm = 14.6718
	old_data_grads_norm = 5.7295
	sim_grads_norm_tr = -0.1421
-- Starting training on experience 2 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7306
	data_grads_norm = 7.8142
	new_data_grads_norm = 11.9356
	old_data_grads_norm = 8.8770
	sim_grads_norm_tr = -0.0343
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8007
	data_grads_norm = 7.8808
	new_data_grads_norm = 10.5884
	old_data_grads_norm = 7.9475
	sim_grads_norm_tr = -0.0061
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9344
	data_grads_norm = 12.0352
	new_data_grads_norm = 14.7025
	old_data_grads_norm = 12.8230
	sim_grads_norm_tr = 0.0037
-- Starting training on experience 3 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3405
	data_grads_norm = 10.4951
	new_data_grads_norm = 13.9027
	old_data_grads_norm = 14.1127
	sim_grads_norm_tr = 0.1293
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1715
	data_grads_norm = 8.9874
	new_data_grads_norm = 9.7017
	old_data_grads_norm = 12.0676
	sim_grads_norm_tr = 0.1771
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8663
	data_grads_norm = 8.3529
	new_data_grads_norm = 9.2605
	old_data_grads_norm = 11.1112
	sim_grads_norm_tr = 0.0943
-- Starting training on experience 4 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9292
	data_grads_norm = 8.2339
	new_data_grads_norm = 12.3351
	old_data_grads_norm = 8.2463
	sim_grads_norm_tr = 0.3011
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7247
	data_grads_norm = 6.6459
	new_data_grads_norm = 8.8270
	old_data_grads_norm = 9.2203
	sim_grads_norm_tr = 0.0565
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9748
	data_grads_norm = 6.6586
	new_data_grads_norm = 9.1976
	old_data_grads_norm = 7.9351
	sim_grads_norm_tr = 0.2229
-- Starting training on experience 5 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2139
	data_grads_norm = 6.8863
	new_data_grads_norm = 9.4558
	old_data_grads_norm = 7.7677
	sim_grads_norm_tr = 0.2670
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4748
	data_grads_norm = 8.6988
	new_data_grads_norm = 10.2034
	old_data_grads_norm = 9.8686
	sim_grads_norm_tr = 0.4773
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3783
	data_grads_norm = 8.7437
	new_data_grads_norm = 11.2933
	old_data_grads_norm = 10.6895
	sim_grads_norm_tr = 0.2729
-- Starting training on experience 6 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2570
	data_grads_norm = 5.0988
	new_data_grads_norm = 5.9461
	old_data_grads_norm = 6.9682
	sim_grads_norm_tr = 0.1542
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3735
	data_grads_norm = 6.5789
	new_data_grads_norm = 9.2118
	old_data_grads_norm = 5.3818
	sim_grads_norm_tr = 0.0627
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5213
	data_grads_norm = 6.9689
	new_data_grads_norm = 9.8622
	old_data_grads_norm = 7.9446
	sim_grads_norm_tr = 0.3517
-- Starting training on experience 7 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8792
	data_grads_norm = 6.1398
	new_data_grads_norm = 7.7480
	old_data_grads_norm = 7.8000
	sim_grads_norm_tr = 0.2587
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5361
	data_grads_norm = 4.8608
	new_data_grads_norm = 6.3555
	old_data_grads_norm = 6.2856
	sim_grads_norm_tr = 0.2100
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8074
	data_grads_norm = 6.3917
	new_data_grads_norm = 7.2903
	old_data_grads_norm = 8.5636
	sim_grads_norm_tr = 0.3349
-- Starting training on experience 8 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8353
	data_grads_norm = 5.7558
	new_data_grads_norm = 8.0434
	old_data_grads_norm = 7.8147
	sim_grads_norm_tr = 0.1210
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7315
	data_grads_norm = 5.0696
	new_data_grads_norm = 6.5660
	old_data_grads_norm = 6.4581
	sim_grads_norm_tr = 0.1904
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8575
	data_grads_norm = 5.8855
	new_data_grads_norm = 7.2355
	old_data_grads_norm = 7.3070
	sim_grads_norm_tr = 0.2904
-- Starting training on experience 9 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7586
	data_grads_norm = 5.5242
	new_data_grads_norm = 7.6370
	old_data_grads_norm = 6.8959
	sim_grads_norm_tr = 0.1521
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9367
	data_grads_norm = 6.4413
	new_data_grads_norm = 8.7258
	old_data_grads_norm = 6.7265
	sim_grads_norm_tr = 0.2022
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2840
	data_grads_norm = 8.0077
	new_data_grads_norm = 9.2231
	old_data_grads_norm = 10.3801
	sim_grads_norm_tr = 0.3962
-- Starting training on experience 10 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3972
	data_grads_norm = 7.5061
	new_data_grads_norm = 7.8609
	old_data_grads_norm = 9.7674
	sim_grads_norm_tr = 0.4211
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9312
	data_grads_norm = 5.5456
	new_data_grads_norm = 7.4115
	old_data_grads_norm = 6.3066
	sim_grads_norm_tr = 0.2842
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6370
	data_grads_norm = 4.2840
	new_data_grads_norm = 5.7132
	old_data_grads_norm = 5.6160
	sim_grads_norm_tr = 0.1563
-- Starting training on experience 11 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7939
	data_grads_norm = 5.5524
	new_data_grads_norm = 7.3829
	old_data_grads_norm = 5.6025
	sim_grads_norm_tr = 0.4816
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7921
	data_grads_norm = 5.4069
	new_data_grads_norm = 6.6656
	old_data_grads_norm = 7.6022
	sim_grads_norm_tr = 0.2580
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7211
	data_grads_norm = 4.9550
	new_data_grads_norm = 6.5769
	old_data_grads_norm = 7.5888
	sim_grads_norm_tr = 0.2361
-- Starting training on experience 12 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1882
	data_grads_norm = 6.4560
	new_data_grads_norm = 7.7549
	old_data_grads_norm = 7.4810
	sim_grads_norm_tr = 0.4773
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3896
	data_grads_norm = 7.1199
	new_data_grads_norm = 7.7142
	old_data_grads_norm = 8.3140
	sim_grads_norm_tr = 0.5930
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4448
	data_grads_norm = 3.7643
	new_data_grads_norm = 7.2902
	old_data_grads_norm = 4.0758
	sim_grads_norm_tr = 0.2412
-- Starting training on experience 13 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5646
	data_grads_norm = 4.5643
	new_data_grads_norm = 6.6401
	old_data_grads_norm = 6.3848
	sim_grads_norm_tr = 0.1713
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6730
	data_grads_norm = 4.4956
	new_data_grads_norm = 4.7509
	old_data_grads_norm = 6.8922
	sim_grads_norm_tr = 0.1800
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9327
	data_grads_norm = 4.7034
	new_data_grads_norm = 6.5849
	old_data_grads_norm = 5.5830
	sim_grads_norm_tr = 0.4419
-- Starting training on experience 14 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6233
	data_grads_norm = 3.7576
	new_data_grads_norm = 4.9293
	old_data_grads_norm = 4.7625
	sim_grads_norm_tr = 0.1296
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5866
	data_grads_norm = 4.2147
	new_data_grads_norm = 5.1870
	old_data_grads_norm = 5.8278
	sim_grads_norm_tr = 0.2812
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5014
	data_grads_norm = 3.2476
	new_data_grads_norm = 3.9965
	old_data_grads_norm = 4.7791
	sim_grads_norm_tr = -0.0143
-- Starting training on experience 15 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6865
	data_grads_norm = 4.7643
	new_data_grads_norm = 6.3860
	old_data_grads_norm = 7.6440
	sim_grads_norm_tr = 0.1652
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7741
	data_grads_norm = 3.6350
	new_data_grads_norm = 5.4217
	old_data_grads_norm = 5.0169
	sim_grads_norm_tr = -0.1275
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2100
	data_grads_norm = 5.7490
	new_data_grads_norm = 6.9855
	old_data_grads_norm = 6.8387
	sim_grads_norm_tr = 0.3834
-- Starting training on experience 16 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7305
	data_grads_norm = 3.6117
	new_data_grads_norm = 4.5987
	old_data_grads_norm = 4.7053
	sim_grads_norm_tr = 0.1159
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0533
	data_grads_norm = 4.2867
	new_data_grads_norm = 5.5375
	old_data_grads_norm = 5.4490
	sim_grads_norm_tr = 0.2142
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7054
	data_grads_norm = 3.6483
	new_data_grads_norm = 5.2336
	old_data_grads_norm = 3.8039
	sim_grads_norm_tr = 0.1971
-- Starting training on experience 17 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8040
	data_grads_norm = 4.2541
	new_data_grads_norm = 6.7259
	old_data_grads_norm = 4.7125
	sim_grads_norm_tr = 0.0117
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7093
	data_grads_norm = 4.2430
	new_data_grads_norm = 6.6535
	old_data_grads_norm = 3.5620
	sim_grads_norm_tr = 0.2953
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7412
	data_grads_norm = 5.1656
	new_data_grads_norm = 6.8887
	old_data_grads_norm = 4.3492
	sim_grads_norm_tr = 0.6212
-- Starting training on experience 18 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8043
	data_grads_norm = 3.8499
	new_data_grads_norm = 5.2787
	old_data_grads_norm = 4.9113
	sim_grads_norm_tr = 0.1393
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4765
	data_grads_norm = 3.2007
	new_data_grads_norm = 5.1106
	old_data_grads_norm = 3.6167
	sim_grads_norm_tr = 0.2097
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3844
	data_grads_norm = 2.7559
	new_data_grads_norm = 4.6715
	old_data_grads_norm = 2.8901
	sim_grads_norm_tr = 0.0660
-- Starting training on experience 19 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2341
	data_grads_norm = 3.2349
	new_data_grads_norm = 5.1421
	old_data_grads_norm = 5.1680
	sim_grads_norm_tr = -0.1478
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6837
	data_grads_norm = 4.4798
	new_data_grads_norm = 6.1047
	old_data_grads_norm = 5.7905
	sim_grads_norm_tr = 0.2275
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8505
	data_grads_norm = 5.0038
	new_data_grads_norm = 5.9136
	old_data_grads_norm = 6.0720
	sim_grads_norm_tr = 0.2744
-- Starting training on experience 20 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6534
	data_grads_norm = 3.4848
	new_data_grads_norm = 4.2568
	old_data_grads_norm = 4.4425
	sim_grads_norm_tr = -0.0737
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6158
	data_grads_norm = 4.4149
	new_data_grads_norm = 4.7852
	old_data_grads_norm = 5.2588
	sim_grads_norm_tr = 0.3152
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6299
	data_grads_norm = 4.2310
	new_data_grads_norm = 6.0014
	old_data_grads_norm = 4.4806
	sim_grads_norm_tr = 0.3111
-- Starting training on experience 21 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5344
	data_grads_norm = 3.7385
	new_data_grads_norm = 5.6628
	old_data_grads_norm = 4.4580
	sim_grads_norm_tr = 0.2956
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6927
	data_grads_norm = 3.8330
	new_data_grads_norm = 4.4749
	old_data_grads_norm = 5.4884
	sim_grads_norm_tr = 0.0871
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3890
	data_grads_norm = 3.1841
	new_data_grads_norm = 5.3464
	old_data_grads_norm = 3.3249
	sim_grads_norm_tr = -0.0947
-- Starting training on experience 22 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5929
	data_grads_norm = 3.6997
	new_data_grads_norm = 5.8979
	old_data_grads_norm = 3.8138
	sim_grads_norm_tr = 0.0459
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7198
	data_grads_norm = 4.0855
	new_data_grads_norm = 5.8118
	old_data_grads_norm = 5.5587
	sim_grads_norm_tr = 0.1002
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9174
	data_grads_norm = 4.4950
	new_data_grads_norm = 6.8979
	old_data_grads_norm = 6.8192
	sim_grads_norm_tr = 0.1238
-- Starting training on experience 23 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6152
	data_grads_norm = 4.2237
	new_data_grads_norm = 6.4412
	old_data_grads_norm = 4.8515
	sim_grads_norm_tr = 0.0693
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7190
	data_grads_norm = 4.4025
	new_data_grads_norm = 6.5107
	old_data_grads_norm = 5.4508
	sim_grads_norm_tr = 0.1474
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1200
	data_grads_norm = 5.9997
	new_data_grads_norm = 7.6968
	old_data_grads_norm = 6.1976
	sim_grads_norm_tr = 0.4580
-- Starting training on experience 24 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6557
	data_grads_norm = 4.2275
	new_data_grads_norm = 6.2006
	old_data_grads_norm = 4.7248
	sim_grads_norm_tr = 0.2804
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4563
	data_grads_norm = 3.5777
	new_data_grads_norm = 4.6953
	old_data_grads_norm = 4.8749
	sim_grads_norm_tr = 0.3408
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4730
	data_grads_norm = 3.8806
	new_data_grads_norm = 5.2605
	old_data_grads_norm = 4.7933
	sim_grads_norm_tr = 0.2912
-- Starting training on experience 25 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3865
	data_grads_norm = 3.1649
	new_data_grads_norm = 4.1326
	old_data_grads_norm = 7.0521
	sim_grads_norm_tr = -0.2156
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6473
	data_grads_norm = 4.4743
	new_data_grads_norm = 6.8972
	old_data_grads_norm = 5.3122
	sim_grads_norm_tr = 0.2598
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5892
	data_grads_norm = 3.7351
	new_data_grads_norm = 6.3967
	old_data_grads_norm = 5.7759
	sim_grads_norm_tr = 0.0368
-- Starting training on experience 26 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5335
	data_grads_norm = 4.5765
	new_data_grads_norm = 5.7074
	old_data_grads_norm = 5.3868
	sim_grads_norm_tr = 0.3144
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5698
	data_grads_norm = 4.5971
	new_data_grads_norm = 4.5726
	old_data_grads_norm = 5.4602
	sim_grads_norm_tr = 0.6858
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2771
	data_grads_norm = 2.9966
	new_data_grads_norm = 3.4622
	old_data_grads_norm = 4.2349
	sim_grads_norm_tr = 0.3130
-- Starting training on experience 27 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6094
	data_grads_norm = 3.7484
	new_data_grads_norm = 4.4781
	old_data_grads_norm = 4.8547
	sim_grads_norm_tr = 0.2561
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3988
	data_grads_norm = 2.7415
	new_data_grads_norm = 3.7065
	old_data_grads_norm = 3.6262
	sim_grads_norm_tr = 0.1797
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2984
	data_grads_norm = 2.5377
	new_data_grads_norm = 3.6409
	old_data_grads_norm = 3.7398
	sim_grads_norm_tr = 0.0198
-- Starting training on experience 28 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5615
	data_grads_norm = 4.0879
	new_data_grads_norm = 5.2669
	old_data_grads_norm = 5.3044
	sim_grads_norm_tr = 0.4156
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2637
	data_grads_norm = 2.7156
	new_data_grads_norm = 3.5469
	old_data_grads_norm = 3.8466
	sim_grads_norm_tr = 0.1455
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2541
	data_grads_norm = 2.9582
	new_data_grads_norm = 4.4960
	old_data_grads_norm = 4.3310
	sim_grads_norm_tr = 0.0921
-- Starting training on experience 29 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1080
	data_grads_norm = 2.5686
	new_data_grads_norm = 5.7330
	old_data_grads_norm = 4.1454
	sim_grads_norm_tr = -0.2612
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6078
	data_grads_norm = 4.8315
	new_data_grads_norm = 5.0797
	old_data_grads_norm = 6.1843
	sim_grads_norm_tr = 0.4361
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2861
	data_grads_norm = 3.2119
	new_data_grads_norm = 4.7288
	old_data_grads_norm = 5.2235
	sim_grads_norm_tr = 0.1665
-- Starting training on experience 30 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8799
	data_grads_norm = 4.9839
	new_data_grads_norm = 6.9520
	old_data_grads_norm = 5.4378
	sim_grads_norm_tr = 0.4041
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7571
	data_grads_norm = 3.7646
	new_data_grads_norm = 5.9428
	old_data_grads_norm = 4.5008
	sim_grads_norm_tr = 0.1946
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5583
	data_grads_norm = 3.2722
	new_data_grads_norm = 4.6630
	old_data_grads_norm = 4.1831
	sim_grads_norm_tr = 0.1856
-- Starting training on experience 31 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4161
	data_grads_norm = 3.2614
	new_data_grads_norm = 3.9595
	old_data_grads_norm = 4.8479
	sim_grads_norm_tr = 0.2241
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5233
	data_grads_norm = 3.5261
	new_data_grads_norm = 4.6107
	old_data_grads_norm = 4.2272
	sim_grads_norm_tr = 0.2212
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1523
	data_grads_norm = 2.2265
	new_data_grads_norm = 3.5388
	old_data_grads_norm = 3.8365
	sim_grads_norm_tr = -0.1966
-- Starting training on experience 32 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3115
	data_grads_norm = 3.6218
	new_data_grads_norm = 5.2952
	old_data_grads_norm = 3.8983
	sim_grads_norm_tr = 0.2552
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4471
	data_grads_norm = 4.2145
	new_data_grads_norm = 4.6815
	old_data_grads_norm = 5.8943
	sim_grads_norm_tr = 0.0162
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2633
	data_grads_norm = 3.6432
	new_data_grads_norm = 5.2903
	old_data_grads_norm = 6.2597
	sim_grads_norm_tr = 0.1512
-- Starting training on experience 33 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7491
	data_grads_norm = 4.2708
	new_data_grads_norm = 7.3997
	old_data_grads_norm = 5.7063
	sim_grads_norm_tr = 0.3019
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6066
	data_grads_norm = 3.6320
	new_data_grads_norm = 6.7178
	old_data_grads_norm = 5.1204
	sim_grads_norm_tr = -0.0153
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7711
	data_grads_norm = 3.6871
	new_data_grads_norm = 6.0714
	old_data_grads_norm = 4.7877
	sim_grads_norm_tr = 0.1199
-- Starting training on experience 34 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4781
	data_grads_norm = 4.2893
	new_data_grads_norm = 5.6019
	old_data_grads_norm = 4.2786
	sim_grads_norm_tr = 0.3594
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1535
	data_grads_norm = 3.3290
	new_data_grads_norm = 4.6183
	old_data_grads_norm = 2.7458
	sim_grads_norm_tr = 0.0324
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2781
	data_grads_norm = 2.8498
	new_data_grads_norm = 5.3725
	old_data_grads_norm = 5.6775
	sim_grads_norm_tr = -0.3999
-- Starting training on experience 35 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8667
	data_grads_norm = 4.3365
	new_data_grads_norm = 5.6429
	old_data_grads_norm = 5.5954
	sim_grads_norm_tr = 0.3241
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5654
	data_grads_norm = 3.7859
	new_data_grads_norm = 4.9249
	old_data_grads_norm = 4.8444
	sim_grads_norm_tr = 0.3804
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6264
	data_grads_norm = 3.2229
	new_data_grads_norm = 3.9890
	old_data_grads_norm = 5.1336
	sim_grads_norm_tr = 0.2619
-- Starting training on experience 36 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5243
	data_grads_norm = 3.2945
	new_data_grads_norm = 3.6978
	old_data_grads_norm = 4.8634
	sim_grads_norm_tr = 0.2794
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6077
	data_grads_norm = 3.4132
	new_data_grads_norm = 4.5067
	old_data_grads_norm = 6.1362
	sim_grads_norm_tr = 0.1370
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7738
	data_grads_norm = 3.7570
	new_data_grads_norm = 4.2487
	old_data_grads_norm = 5.2103
	sim_grads_norm_tr = 0.2921
-- Starting training on experience 37 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2671
	data_grads_norm = 2.8563
	new_data_grads_norm = 5.1517
	old_data_grads_norm = 3.9017
	sim_grads_norm_tr = -0.0517
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5953
	data_grads_norm = 4.3693
	new_data_grads_norm = 4.6531
	old_data_grads_norm = 5.9379
	sim_grads_norm_tr = 0.3774
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2366
	data_grads_norm = 3.0091
	new_data_grads_norm = 2.9917
	old_data_grads_norm = 5.6384
	sim_grads_norm_tr = 0.1014
-- Starting training on experience 38 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3563
	data_grads_norm = 2.0506
	new_data_grads_norm = 3.3674
	old_data_grads_norm = 3.0988
	sim_grads_norm_tr = -0.1472
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3008
	data_grads_norm = 2.2551
	new_data_grads_norm = 3.6658
	old_data_grads_norm = 3.5009
	sim_grads_norm_tr = -0.3999
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7094
	data_grads_norm = 4.0006
	new_data_grads_norm = 5.7115
	old_data_grads_norm = 3.9330
	sim_grads_norm_tr = 0.5389
-- Starting training on experience 39 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4951
	data_grads_norm = 2.9094
	new_data_grads_norm = 3.5251
	old_data_grads_norm = 4.6786
	sim_grads_norm_tr = 0.2810
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4836
	data_grads_norm = 2.7581
	new_data_grads_norm = 4.2764
	old_data_grads_norm = 4.5698
	sim_grads_norm_tr = 0.2824
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2728
	data_grads_norm = 3.2415
	new_data_grads_norm = 3.9329
	old_data_grads_norm = 4.0458
	sim_grads_norm_tr = 0.2938
-- Starting training on experience 40 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2506
	data_grads_norm = 2.8646
	new_data_grads_norm = 5.0666
	old_data_grads_norm = 5.1613
	sim_grads_norm_tr = -0.0440
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4341
	data_grads_norm = 3.4629
	new_data_grads_norm = 4.8876
	old_data_grads_norm = 5.2566
	sim_grads_norm_tr = -0.1949
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9446
	data_grads_norm = 5.1411
	new_data_grads_norm = 6.6959
	old_data_grads_norm = 5.2495
	sim_grads_norm_tr = 0.5230
-- Starting training on experience 41 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4830
	data_grads_norm = 3.5752
	new_data_grads_norm = 5.2773
	old_data_grads_norm = 4.1875
	sim_grads_norm_tr = 0.2190
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4381
	data_grads_norm = 3.5033
	new_data_grads_norm = 4.3423
	old_data_grads_norm = 4.8880
	sim_grads_norm_tr = 0.1097
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5073
	data_grads_norm = 3.9685
	new_data_grads_norm = 4.1523
	old_data_grads_norm = 5.3410
	sim_grads_norm_tr = 0.4491
-- Starting training on experience 42 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4128
	data_grads_norm = 3.2150
	new_data_grads_norm = 4.0491
	old_data_grads_norm = 4.4845
	sim_grads_norm_tr = 0.2648
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1854
	data_grads_norm = 2.8873
	new_data_grads_norm = 4.5947
	old_data_grads_norm = 3.2571
	sim_grads_norm_tr = 0.0104
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5461
	data_grads_norm = 3.9361
	new_data_grads_norm = 5.0112
	old_data_grads_norm = 5.8178
	sim_grads_norm_tr = -0.1529
-- Starting training on experience 43 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6627
	data_grads_norm = 5.9357
	new_data_grads_norm = 6.2565
	old_data_grads_norm = 7.6162
	sim_grads_norm_tr = 0.0562
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4393
	data_grads_norm = 2.9078
	new_data_grads_norm = 5.2855
	old_data_grads_norm = 3.4400
	sim_grads_norm_tr = 0.0968
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7385
	data_grads_norm = 3.8052
	new_data_grads_norm = 5.6910
	old_data_grads_norm = 4.5622
	sim_grads_norm_tr = 0.0564
-- Starting training on experience 44 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6727
	data_grads_norm = 3.6925
	new_data_grads_norm = 5.8940
	old_data_grads_norm = 3.8341
	sim_grads_norm_tr = 0.0080
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8227
	data_grads_norm = 4.8424
	new_data_grads_norm = 6.8714
	old_data_grads_norm = 5.9703
	sim_grads_norm_tr = 0.1243
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7104
	data_grads_norm = 4.3668
	new_data_grads_norm = 5.9928
	old_data_grads_norm = 5.0865
	sim_grads_norm_tr = 0.4695
-- Starting training on experience 45 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2571
	data_grads_norm = 2.9137
	new_data_grads_norm = 3.3878
	old_data_grads_norm = 4.5548
	sim_grads_norm_tr = 0.1274
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2270
	data_grads_norm = 2.5016
	new_data_grads_norm = 3.4855
	old_data_grads_norm = 4.0915
	sim_grads_norm_tr = 0.0807
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3571
	data_grads_norm = 2.6106
	new_data_grads_norm = 3.8846
	old_data_grads_norm = 4.3759
	sim_grads_norm_tr = -0.0458
-- Starting training on experience 46 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4694
	data_grads_norm = 3.7042
	new_data_grads_norm = 5.3510
	old_data_grads_norm = 5.2313
	sim_grads_norm_tr = 0.2218
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6244
	data_grads_norm = 4.7576
	new_data_grads_norm = 4.7990
	old_data_grads_norm = 6.1785
	sim_grads_norm_tr = 0.2403
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5663
	data_grads_norm = 3.6315
	new_data_grads_norm = 4.9145
	old_data_grads_norm = 5.0112
	sim_grads_norm_tr = 0.0940
-- Starting training on experience 47 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4584
	data_grads_norm = 4.1049
	new_data_grads_norm = 4.4363
	old_data_grads_norm = 5.7627
	sim_grads_norm_tr = 0.6015
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2604
	data_grads_norm = 2.7849
	new_data_grads_norm = 3.1974
	old_data_grads_norm = 5.1639
	sim_grads_norm_tr = -0.0767
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2722
	data_grads_norm = 2.8477
	new_data_grads_norm = 4.0508
	old_data_grads_norm = 5.3912
	sim_grads_norm_tr = 0.1434
-- Starting training on experience 48 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6803
	data_grads_norm = 4.9976
	new_data_grads_norm = 5.3678
	old_data_grads_norm = 4.9923
	sim_grads_norm_tr = 0.2727
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4452
	data_grads_norm = 3.8567
	new_data_grads_norm = 4.9244
	old_data_grads_norm = 4.7941
	sim_grads_norm_tr = 0.2390
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2028
	data_grads_norm = 3.9318
	new_data_grads_norm = 5.3443
	old_data_grads_norm = 4.3893
	sim_grads_norm_tr = 0.5078
-- Starting training on experience 49 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7989
	data_grads_norm = 5.0048
	new_data_grads_norm = 5.4882
	old_data_grads_norm = 6.6836
	sim_grads_norm_tr = 0.3090
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1801
	data_grads_norm = 3.0364
	new_data_grads_norm = 5.6188
	old_data_grads_norm = 2.6126
	sim_grads_norm_tr = -0.2049
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5696
	data_grads_norm = 4.2326
	new_data_grads_norm = 5.6295
	old_data_grads_norm = 5.6380
	sim_grads_norm_tr = 0.2284
-- Starting training on experience 50 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1755
	data_grads_norm = 2.6258
	new_data_grads_norm = 4.9656
	old_data_grads_norm = 2.3034
	sim_grads_norm_tr = 0.0263
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5143
	data_grads_norm = 4.1097
	new_data_grads_norm = 5.1950
	old_data_grads_norm = 5.4068
	sim_grads_norm_tr = 0.4770
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4308
	data_grads_norm = 4.0950
	new_data_grads_norm = 4.7760
	old_data_grads_norm = 5.4000
	sim_grads_norm_tr = 0.1266
-- Starting training on experience 51 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8540
	data_grads_norm = 4.4783
	new_data_grads_norm = 5.3741
	old_data_grads_norm = 5.8249
	sim_grads_norm_tr = 0.3542
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3929
	data_grads_norm = 3.3505
	new_data_grads_norm = 4.1117
	old_data_grads_norm = 4.2618
	sim_grads_norm_tr = 0.0851
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3244
	data_grads_norm = 3.3031
	new_data_grads_norm = 3.8010
	old_data_grads_norm = 4.1875
	sim_grads_norm_tr = 0.3566
-- Starting training on experience 52 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6885
	data_grads_norm = 3.7817
	new_data_grads_norm = 5.7744
	old_data_grads_norm = 5.5078
	sim_grads_norm_tr = 0.3373
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2323
	data_grads_norm = 2.7401
	new_data_grads_norm = 3.6648
	old_data_grads_norm = 3.6002
	sim_grads_norm_tr = 0.1764
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6355
	data_grads_norm = 3.0902
	new_data_grads_norm = 4.4838
	old_data_grads_norm = 4.4252
	sim_grads_norm_tr = 0.1658
-- Starting training on experience 53 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3663
	data_grads_norm = 3.8212
	new_data_grads_norm = 4.4145
	old_data_grads_norm = 5.5788
	sim_grads_norm_tr = 0.2907
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3087
	data_grads_norm = 3.2685
	new_data_grads_norm = 4.9289
	old_data_grads_norm = 4.8795
	sim_grads_norm_tr = 0.0423
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7727
	data_grads_norm = 4.3010
	new_data_grads_norm = 6.1967
	old_data_grads_norm = 5.6112
	sim_grads_norm_tr = 0.2428
-- Starting training on experience 54 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4189
	data_grads_norm = 4.1491
	new_data_grads_norm = 4.6338
	old_data_grads_norm = 5.3773
	sim_grads_norm_tr = 0.3760
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2275
	data_grads_norm = 3.4587
	new_data_grads_norm = 5.0041
	old_data_grads_norm = 4.0353
	sim_grads_norm_tr = 0.2416
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1833
	data_grads_norm = 3.2222
	new_data_grads_norm = 4.4728
	old_data_grads_norm = 4.4329
	sim_grads_norm_tr = 0.0046
-- Starting training on experience 55 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1794
	data_grads_norm = 2.2298
	new_data_grads_norm = 4.0412
	old_data_grads_norm = 2.3491
	sim_grads_norm_tr = 0.1332
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1347
	data_grads_norm = 2.1849
	new_data_grads_norm = 3.8315
	old_data_grads_norm = 3.5302
	sim_grads_norm_tr = -0.1635
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2114
	data_grads_norm = 3.1487
	new_data_grads_norm = 4.6975
	old_data_grads_norm = 3.4686
	sim_grads_norm_tr = 0.2816
-- Starting training on experience 56 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2407
	data_grads_norm = 3.1113
	new_data_grads_norm = 4.4238
	old_data_grads_norm = 3.7044
	sim_grads_norm_tr = 0.1454
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3502
	data_grads_norm = 4.0810
	new_data_grads_norm = 4.3352
	old_data_grads_norm = 4.9225
	sim_grads_norm_tr = 0.2720
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2896
	data_grads_norm = 3.3682
	new_data_grads_norm = 4.2363
	old_data_grads_norm = 4.7302
	sim_grads_norm_tr = 0.1968
-- Starting training on experience 57 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3098
	data_grads_norm = 4.2450
	new_data_grads_norm = 5.0890
	old_data_grads_norm = 5.1144
	sim_grads_norm_tr = 0.4834
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2926
	data_grads_norm = 4.1771
	new_data_grads_norm = 3.2739
	old_data_grads_norm = 5.4081
	sim_grads_norm_tr = 0.0834
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2743
	data_grads_norm = 3.2312
	new_data_grads_norm = 4.1374
	old_data_grads_norm = 4.4213
	sim_grads_norm_tr = -0.0076
-- Starting training on experience 58 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4742
	data_grads_norm = 3.8018
	new_data_grads_norm = 6.1230
	old_data_grads_norm = 4.4853
	sim_grads_norm_tr = 0.2308
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3022
	data_grads_norm = 3.3142
	new_data_grads_norm = 7.1551
	old_data_grads_norm = 2.8838
	sim_grads_norm_tr = 0.0787
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3744
	data_grads_norm = 3.6115
	new_data_grads_norm = 7.4769
	old_data_grads_norm = 5.1515
	sim_grads_norm_tr = -0.0093
-- Starting training on experience 59 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2121
	data_grads_norm = 3.5788
	new_data_grads_norm = 5.8327
	old_data_grads_norm = 3.9486
	sim_grads_norm_tr = 0.1954
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7586
	data_grads_norm = 4.1953
	new_data_grads_norm = 5.2484
	old_data_grads_norm = 6.1939
	sim_grads_norm_tr = -0.0463
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7367
	data_grads_norm = 4.0848
	new_data_grads_norm = 6.5889
	old_data_grads_norm = 5.9308
	sim_grads_norm_tr = 0.5624
-- Starting training on experience 60 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5863
	data_grads_norm = 3.9324
	new_data_grads_norm = 4.5421
	old_data_grads_norm = 4.1642
	sim_grads_norm_tr = 0.3036
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3798
	data_grads_norm = 3.5621
	new_data_grads_norm = 3.9648
	old_data_grads_norm = 6.0286
	sim_grads_norm_tr = 0.0914
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5141
	data_grads_norm = 3.6761
	new_data_grads_norm = 4.8384
	old_data_grads_norm = 4.8317
	sim_grads_norm_tr = 0.1671
-- Starting training on experience 61 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2829
	data_grads_norm = 3.3600
	new_data_grads_norm = 3.6178
	old_data_grads_norm = 4.8359
	sim_grads_norm_tr = 0.1570
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0479
	data_grads_norm = 2.4860
	new_data_grads_norm = 4.0097
	old_data_grads_norm = 2.4146
	sim_grads_norm_tr = 0.2198
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1846
	data_grads_norm = 3.5184
	new_data_grads_norm = 3.7040
	old_data_grads_norm = 5.9096
	sim_grads_norm_tr = -0.0830
-- Starting training on experience 62 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1428
	data_grads_norm = 2.5044
	new_data_grads_norm = 4.5890
	old_data_grads_norm = 3.9405
	sim_grads_norm_tr = 0.0642
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2142
	data_grads_norm = 2.7202
	new_data_grads_norm = 3.8380
	old_data_grads_norm = 3.3025
	sim_grads_norm_tr = -0.1871
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6316
	data_grads_norm = 4.2229
	new_data_grads_norm = 3.7161
	old_data_grads_norm = 5.2160
	sim_grads_norm_tr = 0.4056
-- Starting training on experience 63 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2717
	data_grads_norm = 2.6407
	new_data_grads_norm = 4.7511
	old_data_grads_norm = 2.6133
	sim_grads_norm_tr = 0.1101
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2277
	data_grads_norm = 2.2938
	new_data_grads_norm = 5.1308
	old_data_grads_norm = 2.9058
	sim_grads_norm_tr = -0.0200
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3858
	data_grads_norm = 2.7334
	new_data_grads_norm = 5.2476
	old_data_grads_norm = 3.6900
	sim_grads_norm_tr = 0.0151
-- Starting training on experience 64 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4459
	data_grads_norm = 2.7544
	new_data_grads_norm = 3.8670
	old_data_grads_norm = 4.2086
	sim_grads_norm_tr = 0.1307
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2913
	data_grads_norm = 3.3977
	new_data_grads_norm = 3.9106
	old_data_grads_norm = 5.7149
	sim_grads_norm_tr = 0.2052
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2166
	data_grads_norm = 3.0625
	new_data_grads_norm = 5.3154
	old_data_grads_norm = 3.3460
	sim_grads_norm_tr = 0.0953
-- Starting training on experience 65 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1305
	data_grads_norm = 3.2311
	new_data_grads_norm = 6.3674
	old_data_grads_norm = 3.3424
	sim_grads_norm_tr = 0.1435
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1757
	data_grads_norm = 3.3057
	new_data_grads_norm = 5.1390
	old_data_grads_norm = 4.4173
	sim_grads_norm_tr = 0.1543
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1930
	data_grads_norm = 3.7087
	new_data_grads_norm = 5.2374
	old_data_grads_norm = 5.6782
	sim_grads_norm_tr = 0.1178
-- Starting training on experience 66 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8602
	data_grads_norm = 4.6305
	new_data_grads_norm = 5.5480
	old_data_grads_norm = 5.9240
	sim_grads_norm_tr = 0.2217
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4376
	data_grads_norm = 2.9273
	new_data_grads_norm = 5.2200
	old_data_grads_norm = 4.0536
	sim_grads_norm_tr = -0.3474
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0790
	data_grads_norm = 4.6265
	new_data_grads_norm = 6.3198
	old_data_grads_norm = 4.2645
	sim_grads_norm_tr = 0.4419
-- Starting training on experience 67 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4537
	data_grads_norm = 4.3651
	new_data_grads_norm = 6.6273
	old_data_grads_norm = 5.3060
	sim_grads_norm_tr = 0.3742
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2282
	data_grads_norm = 3.1395
	new_data_grads_norm = 4.6906
	old_data_grads_norm = 4.0726
	sim_grads_norm_tr = 0.0264
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0247
	data_grads_norm = 2.6912
	new_data_grads_norm = 4.8755
	old_data_grads_norm = 3.8151
	sim_grads_norm_tr = -0.1343
-- Starting training on experience 68 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4048
	data_grads_norm = 3.4127
	new_data_grads_norm = 4.4186
	old_data_grads_norm = 4.8222
	sim_grads_norm_tr = 0.1516
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4468
	data_grads_norm = 3.2294
	new_data_grads_norm = 4.5856
	old_data_grads_norm = 4.2615
	sim_grads_norm_tr = 0.2400
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3936
	data_grads_norm = 3.4241
	new_data_grads_norm = 4.3774
	old_data_grads_norm = 4.4400
	sim_grads_norm_tr = 0.3352
-- Starting training on experience 69 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4283
	data_grads_norm = 3.4723
	new_data_grads_norm = 5.0745
	old_data_grads_norm = 3.5169
	sim_grads_norm_tr = 0.1589
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5065
	data_grads_norm = 4.5076
	new_data_grads_norm = 5.5483
	old_data_grads_norm = 4.5392
	sim_grads_norm_tr = 0.3560
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0435
	data_grads_norm = 2.0827
	new_data_grads_norm = 3.7886
	old_data_grads_norm = 2.8680
	sim_grads_norm_tr = -0.1141
-- Starting training on experience 70 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1260
	data_grads_norm = 2.7565
	new_data_grads_norm = 3.7628
	old_data_grads_norm = 4.0032
	sim_grads_norm_tr = -0.0537
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1599
	data_grads_norm = 2.5924
	new_data_grads_norm = 4.1353
	old_data_grads_norm = 3.7522
	sim_grads_norm_tr = -0.0172
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2680
	data_grads_norm = 3.4472
	new_data_grads_norm = 5.9463
	old_data_grads_norm = 4.3419
	sim_grads_norm_tr = 0.3526
-- Starting training on experience 71 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1144
	data_grads_norm = 2.6289
	new_data_grads_norm = 3.4826
	old_data_grads_norm = 3.0029
	sim_grads_norm_tr = 0.2296
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0817
	data_grads_norm = 2.3517
	new_data_grads_norm = 4.1856
	old_data_grads_norm = 3.4363
	sim_grads_norm_tr = 0.0342
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2543
	data_grads_norm = 4.0301
	new_data_grads_norm = 3.6612
	old_data_grads_norm = 5.7722
	sim_grads_norm_tr = -0.0699
-- Starting training on experience 72 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5916
	data_grads_norm = 4.6180
	new_data_grads_norm = 4.1341
	old_data_grads_norm = 6.5005
	sim_grads_norm_tr = 0.3808
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2796
	data_grads_norm = 3.5885
	new_data_grads_norm = 4.9295
	old_data_grads_norm = 4.8222
	sim_grads_norm_tr = 0.2901
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7659
	data_grads_norm = 4.3550
	new_data_grads_norm = 4.3845
	old_data_grads_norm = 6.0936
	sim_grads_norm_tr = 0.2234
-- Starting training on experience 73 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5340
	data_grads_norm = 4.7505
	new_data_grads_norm = 5.5561
	old_data_grads_norm = 5.2348
	sim_grads_norm_tr = 0.5467
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9360
	data_grads_norm = 2.4961
	new_data_grads_norm = 3.8351
	old_data_grads_norm = 2.6251
	sim_grads_norm_tr = 0.1901
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8125
	data_grads_norm = 2.0887
	new_data_grads_norm = 4.4102
	old_data_grads_norm = 2.1832
	sim_grads_norm_tr = -0.0177
-- Starting training on experience 74 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3460
	data_grads_norm = 3.3876
	new_data_grads_norm = 3.3956
	old_data_grads_norm = 5.5879
	sim_grads_norm_tr = 0.3633
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4605
	data_grads_norm = 3.8039
	new_data_grads_norm = 2.8318
	old_data_grads_norm = 8.0363
	sim_grads_norm_tr = 0.2477
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4112
	data_grads_norm = 3.4880
	new_data_grads_norm = 4.0601
	old_data_grads_norm = 4.8968
	sim_grads_norm_tr = 0.2862
-- Starting training on experience 75 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3961
	data_grads_norm = 2.7423
	new_data_grads_norm = 3.3309
	old_data_grads_norm = 4.3662
	sim_grads_norm_tr = -0.0039
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9730
	data_grads_norm = 2.3213
	new_data_grads_norm = 3.3417
	old_data_grads_norm = 3.4434
	sim_grads_norm_tr = 0.0380
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9488
	data_grads_norm = 2.0880
	new_data_grads_norm = 3.7436
	old_data_grads_norm = 2.8895
	sim_grads_norm_tr = -0.0794
-- Starting training on experience 76 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3091
	data_grads_norm = 3.8043
	new_data_grads_norm = 4.7438
	old_data_grads_norm = 4.2474
	sim_grads_norm_tr = 0.3918
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1600
	data_grads_norm = 3.0567
	new_data_grads_norm = 3.3490
	old_data_grads_norm = 4.8521
	sim_grads_norm_tr = 0.0217
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2565
	data_grads_norm = 3.4302
	new_data_grads_norm = 4.1440
	old_data_grads_norm = 5.5255
	sim_grads_norm_tr = 0.1282
-- Starting training on experience 77 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3398
	data_grads_norm = 2.9932
	new_data_grads_norm = 3.4928
	old_data_grads_norm = 4.2514
	sim_grads_norm_tr = 0.0656
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1829
	data_grads_norm = 2.8502
	new_data_grads_norm = 3.4311
	old_data_grads_norm = 4.8958
	sim_grads_norm_tr = 0.0232
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6486
	data_grads_norm = 4.6114
	new_data_grads_norm = 5.8818
	old_data_grads_norm = 5.5813
	sim_grads_norm_tr = 0.4302
-- Starting training on experience 78 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1746
	data_grads_norm = 3.1054
	new_data_grads_norm = 4.8808
	old_data_grads_norm = 3.4701
	sim_grads_norm_tr = 0.1779
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9679
	data_grads_norm = 2.4649
	new_data_grads_norm = 4.6676
	old_data_grads_norm = 4.4668
	sim_grads_norm_tr = -0.3524
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6238
	data_grads_norm = 4.2929
	new_data_grads_norm = 5.5952
	old_data_grads_norm = 3.8310
	sim_grads_norm_tr = 0.6042
-- Starting training on experience 79 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1413
	data_grads_norm = 3.2164
	new_data_grads_norm = 4.5789
	old_data_grads_norm = 4.6336
	sim_grads_norm_tr = 0.0867
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2968
	data_grads_norm = 3.3919
	new_data_grads_norm = 4.3347
	old_data_grads_norm = 4.3101
	sim_grads_norm_tr = 0.1695
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1428
	data_grads_norm = 3.1470
	new_data_grads_norm = 4.8351
	old_data_grads_norm = 3.3130
	sim_grads_norm_tr = 0.1440
-- Starting training on experience 80 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2040
	data_grads_norm = 3.0236
	new_data_grads_norm = 4.9336
	old_data_grads_norm = 3.9221
	sim_grads_norm_tr = 0.0236
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1601
	data_grads_norm = 3.1733
	new_data_grads_norm = 4.7645
	old_data_grads_norm = 3.4581
	sim_grads_norm_tr = 0.1953
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0524
	data_grads_norm = 2.7661
	new_data_grads_norm = 4.4784
	old_data_grads_norm = 4.8312
	sim_grads_norm_tr = -0.0543
-- Starting training on experience 81 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4340
	data_grads_norm = 4.1304
	new_data_grads_norm = 4.4348
	old_data_grads_norm = 6.7681
	sim_grads_norm_tr = 0.3345
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4026
	data_grads_norm = 3.4964
	new_data_grads_norm = 3.0251
	old_data_grads_norm = 5.5198
	sim_grads_norm_tr = 0.4308
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2284
	data_grads_norm = 2.4678
	new_data_grads_norm = 3.1258
	old_data_grads_norm = 3.8375
	sim_grads_norm_tr = -0.0431
-- Starting training on experience 82 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6459
	data_grads_norm = 3.6624
	new_data_grads_norm = 4.4608
	old_data_grads_norm = 5.0209
	sim_grads_norm_tr = 0.2687
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3325
	data_grads_norm = 2.4541
	new_data_grads_norm = 3.4190
	old_data_grads_norm = 4.4319
	sim_grads_norm_tr = -0.2799
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5203
	data_grads_norm = 3.4588
	new_data_grads_norm = 4.2593
	old_data_grads_norm = 4.3035
	sim_grads_norm_tr = 0.1717
-- Starting training on experience 83 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0645
	data_grads_norm = 2.4070
	new_data_grads_norm = 2.7495
	old_data_grads_norm = 4.0434
	sim_grads_norm_tr = -0.1110
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0255
	data_grads_norm = 2.2152
	new_data_grads_norm = 3.2137
	old_data_grads_norm = 4.4926
	sim_grads_norm_tr = -0.0467
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0370
	data_grads_norm = 2.2350
	new_data_grads_norm = 3.3804
	old_data_grads_norm = 2.5917
	sim_grads_norm_tr = 0.0850
-- Starting training on experience 84 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2329
	data_grads_norm = 2.8744
	new_data_grads_norm = 3.8879
	old_data_grads_norm = 3.9702
	sim_grads_norm_tr = 0.2427
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2004
	data_grads_norm = 3.1018
	new_data_grads_norm = 4.1997
	old_data_grads_norm = 3.5431
	sim_grads_norm_tr = 0.2345
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1592
	data_grads_norm = 3.1240
	new_data_grads_norm = 3.3433
	old_data_grads_norm = 4.4105
	sim_grads_norm_tr = 0.2868
-- Starting training on experience 85 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1796
	data_grads_norm = 2.8206
	new_data_grads_norm = 4.5235
	old_data_grads_norm = 4.3946
	sim_grads_norm_tr = -0.3197
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5425
	data_grads_norm = 3.9967
	new_data_grads_norm = 4.6989
	old_data_grads_norm = 4.1270
	sim_grads_norm_tr = 0.5898
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3870
	data_grads_norm = 3.2778
	new_data_grads_norm = 4.4410
	old_data_grads_norm = 4.2556
	sim_grads_norm_tr = 0.0172
-- Starting training on experience 86 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4677
	data_grads_norm = 3.7915
	new_data_grads_norm = 5.0653
	old_data_grads_norm = 4.8315
	sim_grads_norm_tr = 0.1320
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2743
	data_grads_norm = 2.5537
	new_data_grads_norm = 4.3573
	old_data_grads_norm = 3.9673
	sim_grads_norm_tr = -0.0809
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4113
	data_grads_norm = 3.2917
	new_data_grads_norm = 5.4723
	old_data_grads_norm = 4.3705
	sim_grads_norm_tr = 0.1620
-- Starting training on experience 87 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1219
	data_grads_norm = 4.0039
	new_data_grads_norm = 5.4784
	old_data_grads_norm = 4.2528
	sim_grads_norm_tr = 0.0987
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8872
	data_grads_norm = 2.9166
	new_data_grads_norm = 5.2018
	old_data_grads_norm = 2.8902
	sim_grads_norm_tr = 0.0567
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9402
	data_grads_norm = 3.3802
	new_data_grads_norm = 4.9436
	old_data_grads_norm = 3.9032
	sim_grads_norm_tr = 0.3144
-- Starting training on experience 88 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9459
	data_grads_norm = 2.5745
	new_data_grads_norm = 4.1952
	old_data_grads_norm = 3.7556
	sim_grads_norm_tr = -0.0267
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3409
	data_grads_norm = 3.6121
	new_data_grads_norm = 4.8761
	old_data_grads_norm = 4.4030
	sim_grads_norm_tr = 0.0600
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3057
	data_grads_norm = 3.6157
	new_data_grads_norm = 5.4398
	old_data_grads_norm = 4.1313
	sim_grads_norm_tr = 0.2181
-- Starting training on experience 89 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9466
	data_grads_norm = 3.0619
	new_data_grads_norm = 4.6784
	old_data_grads_norm = 2.9253
	sim_grads_norm_tr = 0.1893
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1706
	data_grads_norm = 3.0657
	new_data_grads_norm = 3.7162
	old_data_grads_norm = 4.0300
	sim_grads_norm_tr = 0.0023
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2293
	data_grads_norm = 3.7793
	new_data_grads_norm = 4.7203
	old_data_grads_norm = 4.5952
	sim_grads_norm_tr = 0.2209
-- Starting training on experience 90 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3937
	data_grads_norm = 4.5359
	new_data_grads_norm = 5.3880
	old_data_grads_norm = 5.5512
	sim_grads_norm_tr = 0.4336
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0994
	data_grads_norm = 2.6859
	new_data_grads_norm = 3.5326
	old_data_grads_norm = 4.8954
	sim_grads_norm_tr = 0.0985
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4866
	data_grads_norm = 4.4428
	new_data_grads_norm = 4.6971
	old_data_grads_norm = 5.7237
	sim_grads_norm_tr = 0.2157
-- Starting training on experience 91 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6525
	data_grads_norm = 4.7105
	new_data_grads_norm = 6.0600
	old_data_grads_norm = 7.4099
	sim_grads_norm_tr = 0.0656
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5293
	data_grads_norm = 4.0864
	new_data_grads_norm = 5.5830
	old_data_grads_norm = 5.2572
	sim_grads_norm_tr = 0.1106
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3681
	data_grads_norm = 3.9688
	new_data_grads_norm = 4.8461
	old_data_grads_norm = 5.7728
	sim_grads_norm_tr = 0.3346
-- Starting training on experience 92 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5122
	data_grads_norm = 4.1851
	new_data_grads_norm = 5.2036
	old_data_grads_norm = 5.4081
	sim_grads_norm_tr = 0.0716
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5879
	data_grads_norm = 3.8446
	new_data_grads_norm = 4.3744
	old_data_grads_norm = 5.7621
	sim_grads_norm_tr = 0.0009
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4637
	data_grads_norm = 3.1502
	new_data_grads_norm = 5.6471
	old_data_grads_norm = 4.4840
	sim_grads_norm_tr = 0.0947
-- Starting training on experience 93 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3832
	data_grads_norm = 2.9300
	new_data_grads_norm = 3.5372
	old_data_grads_norm = 5.0720
	sim_grads_norm_tr = 0.0457
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1338
	data_grads_norm = 2.8040
	new_data_grads_norm = 3.6927
	old_data_grads_norm = 3.3030
	sim_grads_norm_tr = 0.2328
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0256
	data_grads_norm = 2.3955
	new_data_grads_norm = 3.3915
	old_data_grads_norm = 2.9975
	sim_grads_norm_tr = 0.0394
-- Starting training on experience 94 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0526
	data_grads_norm = 2.6739
	new_data_grads_norm = 2.9293
	old_data_grads_norm = 3.5796
	sim_grads_norm_tr = 0.4550
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8015
	data_grads_norm = 1.8844
	new_data_grads_norm = 2.4522
	old_data_grads_norm = 2.8537
	sim_grads_norm_tr = -0.1197
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9202
	data_grads_norm = 2.6708
	new_data_grads_norm = 2.9730
	old_data_grads_norm = 5.5424
	sim_grads_norm_tr = 0.1443
-- Starting training on experience 95 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1429
	data_grads_norm = 2.2935
	new_data_grads_norm = 4.0255
	old_data_grads_norm = 3.0227
	sim_grads_norm_tr = -0.0089
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1968
	data_grads_norm = 3.4322
	new_data_grads_norm = 5.3886
	old_data_grads_norm = 3.5335
	sim_grads_norm_tr = 0.1534
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1428
	data_grads_norm = 2.9844
	new_data_grads_norm = 4.0072
	old_data_grads_norm = 4.4504
	sim_grads_norm_tr = -0.0009
-- Starting training on experience 96 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5160
	data_grads_norm = 4.0261
	new_data_grads_norm = 6.1231
	old_data_grads_norm = 3.6305
	sim_grads_norm_tr = 0.3485
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9785
	data_grads_norm = 2.5992
	new_data_grads_norm = 4.4213
	old_data_grads_norm = 2.5863
	sim_grads_norm_tr = 0.1264
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3213
	data_grads_norm = 3.6197
	new_data_grads_norm = 5.7063
	old_data_grads_norm = 5.4500
	sim_grads_norm_tr = -0.0147
-- Starting training on experience 97 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2501
	data_grads_norm = 3.0375
	new_data_grads_norm = 5.0741
	old_data_grads_norm = 4.2103
	sim_grads_norm_tr = -0.2481
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6115
	data_grads_norm = 3.5432
	new_data_grads_norm = 5.3837
	old_data_grads_norm = 4.2134
	sim_grads_norm_tr = 0.3082
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3330
	data_grads_norm = 3.7641
	new_data_grads_norm = 5.0363
	old_data_grads_norm = 5.2493
	sim_grads_norm_tr = 0.2161
-- Starting training on experience 98 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8885
	data_grads_norm = 5.0357
	new_data_grads_norm = 7.7618
	old_data_grads_norm = 5.8689
	sim_grads_norm_tr = 0.3055
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3622
	data_grads_norm = 3.4630
	new_data_grads_norm = 5.4361
	old_data_grads_norm = 4.6421
	sim_grads_norm_tr = 0.1221
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3724
	data_grads_norm = 3.7075
	new_data_grads_norm = 7.3365
	old_data_grads_norm = 4.2906
	sim_grads_norm_tr = 0.2785
-- Starting training on experience 99 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1314
	data_grads_norm = 2.7259
	new_data_grads_norm = 3.5218
	old_data_grads_norm = 3.1682
	sim_grads_norm_tr = 0.3589
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5222
	data_grads_norm = 3.4957
	new_data_grads_norm = 4.1231
	old_data_grads_norm = 4.8858
	sim_grads_norm_tr = 0.1560
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1835
	data_grads_norm = 1.8957
	new_data_grads_norm = 3.7843
	old_data_grads_norm = 2.9220
	sim_grads_norm_tr = -0.0368
-- Starting training on experience 100 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1629
	data_grads_norm = 2.5117
	new_data_grads_norm = 3.6512
	old_data_grads_norm = 3.0854
	sim_grads_norm_tr = 0.1676
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1371
	data_grads_norm = 2.3950
	new_data_grads_norm = 3.6525
	old_data_grads_norm = 4.5848
	sim_grads_norm_tr = -0.2107
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3642
	data_grads_norm = 3.4913
	new_data_grads_norm = 5.4353
	old_data_grads_norm = 4.3969
	sim_grads_norm_tr = 0.0722
-- Starting training on experience 101 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8438
	data_grads_norm = 2.7473
	new_data_grads_norm = 3.5635
	old_data_grads_norm = 4.1747
	sim_grads_norm_tr = -0.0039
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1827
	data_grads_norm = 3.2558
	new_data_grads_norm = 4.7175
	old_data_grads_norm = 4.3434
	sim_grads_norm_tr = 0.1290
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1782
	data_grads_norm = 2.8164
	new_data_grads_norm = 4.7843
	old_data_grads_norm = 3.8494
	sim_grads_norm_tr = -0.3276
-- Starting training on experience 102 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6447
	data_grads_norm = 3.8556
	new_data_grads_norm = 5.4694
	old_data_grads_norm = 5.0199
	sim_grads_norm_tr = 0.2079
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4800
	data_grads_norm = 3.7627
	new_data_grads_norm = 5.2684
	old_data_grads_norm = 4.5599
	sim_grads_norm_tr = -0.1425
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4627
	data_grads_norm = 3.3809
	new_data_grads_norm = 5.1706
	old_data_grads_norm = 3.4858
	sim_grads_norm_tr = 0.0018
-- Starting training on experience 103 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2792
	data_grads_norm = 2.9966
	new_data_grads_norm = 5.1772
	old_data_grads_norm = 2.6995
	sim_grads_norm_tr = 0.0663
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3855
	data_grads_norm = 3.6057
	new_data_grads_norm = 4.6992
	old_data_grads_norm = 3.8022
	sim_grads_norm_tr = 0.0746
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3912
	data_grads_norm = 3.3954
	new_data_grads_norm = 4.7976
	old_data_grads_norm = 4.3191
	sim_grads_norm_tr = 0.2140
-- Starting training on experience 104 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1075
	data_grads_norm = 2.6811
	new_data_grads_norm = 3.2958
	old_data_grads_norm = 5.9268
	sim_grads_norm_tr = -0.2129
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4128
	data_grads_norm = 3.7854
	new_data_grads_norm = 5.1132
	old_data_grads_norm = 3.9591
	sim_grads_norm_tr = 0.2253
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5107
	data_grads_norm = 3.8164
	new_data_grads_norm = 5.4449
	old_data_grads_norm = 4.4277
	sim_grads_norm_tr = 0.2836
-- Starting training on experience 105 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0369
	data_grads_norm = 2.6655
	new_data_grads_norm = 5.0094
	old_data_grads_norm = 2.6272
	sim_grads_norm_tr = 0.1608
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1829
	data_grads_norm = 2.7996
	new_data_grads_norm = 4.8209
	old_data_grads_norm = 3.5334
	sim_grads_norm_tr = 0.1308
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2766
	data_grads_norm = 2.8021
	new_data_grads_norm = 4.5709
	old_data_grads_norm = 5.0329
	sim_grads_norm_tr = 0.3938
-- Starting training on experience 106 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2775
	data_grads_norm = 2.8673
	new_data_grads_norm = 3.5766
	old_data_grads_norm = 4.9314
	sim_grads_norm_tr = 0.0340
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4942
	data_grads_norm = 4.1871
	new_data_grads_norm = 4.9285
	old_data_grads_norm = 4.9786
	sim_grads_norm_tr = 0.5675
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2744
	data_grads_norm = 3.0256
	new_data_grads_norm = 3.4775
	old_data_grads_norm = 3.6622
	sim_grads_norm_tr = 0.3379
-- Starting training on experience 107 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1491
	data_grads_norm = 2.6170
	new_data_grads_norm = 3.8104
	old_data_grads_norm = 3.3772
	sim_grads_norm_tr = -0.0939
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0885
	data_grads_norm = 3.3688
	new_data_grads_norm = 4.3339
	old_data_grads_norm = 4.7837
	sim_grads_norm_tr = 0.1357
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1325
	data_grads_norm = 2.6788
	new_data_grads_norm = 4.3796
	old_data_grads_norm = 2.8775
	sim_grads_norm_tr = -0.0351
-- Starting training on experience 108 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0578
	data_grads_norm = 2.8051
	new_data_grads_norm = 3.9629
	old_data_grads_norm = 5.1344
	sim_grads_norm_tr = -0.3815
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5833
	data_grads_norm = 4.1520
	new_data_grads_norm = 5.3161
	old_data_grads_norm = 4.3358
	sim_grads_norm_tr = 0.3389
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2944
	data_grads_norm = 4.0089
	new_data_grads_norm = 5.0143
	old_data_grads_norm = 5.0131
	sim_grads_norm_tr = 0.3836
-- Starting training on experience 109 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3337
	data_grads_norm = 2.6966
	new_data_grads_norm = 3.5461
	old_data_grads_norm = 3.5459
	sim_grads_norm_tr = -0.1247
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5448
	data_grads_norm = 3.2273
	new_data_grads_norm = 3.8714
	old_data_grads_norm = 3.9019
	sim_grads_norm_tr = 0.4667
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2213
	data_grads_norm = 2.3618
	new_data_grads_norm = 2.7013
	old_data_grads_norm = 4.1384
	sim_grads_norm_tr = -0.0286
-- Starting training on experience 110 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5764
	data_grads_norm = 3.4464
	new_data_grads_norm = 4.8616
	old_data_grads_norm = 4.0829
	sim_grads_norm_tr = 0.2336
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2463
	data_grads_norm = 2.6811
	new_data_grads_norm = 4.4323
	old_data_grads_norm = 2.2863
	sim_grads_norm_tr = 0.2845
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2487
	data_grads_norm = 2.4333
	new_data_grads_norm = 4.2407
	old_data_grads_norm = 2.5019
	sim_grads_norm_tr = -0.0192
-- Starting training on experience 111 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0033
	data_grads_norm = 2.4119
	new_data_grads_norm = 3.3218
	old_data_grads_norm = 3.3596
	sim_grads_norm_tr = -0.2524
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1861
	data_grads_norm = 2.6684
	new_data_grads_norm = 3.1401
	old_data_grads_norm = 5.2322
	sim_grads_norm_tr = 0.2140
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1857
	data_grads_norm = 2.2544
	new_data_grads_norm = 2.9247
	old_data_grads_norm = 3.0527
	sim_grads_norm_tr = 0.1257
-- Starting training on experience 112 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9097
	data_grads_norm = 2.5913
	new_data_grads_norm = 4.5332
	old_data_grads_norm = 3.0210
	sim_grads_norm_tr = 0.2862
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9276
	data_grads_norm = 2.6802
	new_data_grads_norm = 4.3766
	old_data_grads_norm = 3.5199
	sim_grads_norm_tr = -0.1045
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9502
	data_grads_norm = 3.0478
	new_data_grads_norm = 4.9780
	old_data_grads_norm = 2.6372
	sim_grads_norm_tr = -0.0964
-- Starting training on experience 113 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3860
	data_grads_norm = 3.2149
	new_data_grads_norm = 4.1069
	old_data_grads_norm = 3.8024
	sim_grads_norm_tr = 0.2138
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2619
	data_grads_norm = 2.4789
	new_data_grads_norm = 3.2295
	old_data_grads_norm = 3.3876
	sim_grads_norm_tr = 0.0410
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1420
	data_grads_norm = 2.8424
	new_data_grads_norm = 3.7652
	old_data_grads_norm = 4.2102
	sim_grads_norm_tr = 0.0494
-- Starting training on experience 114 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0328
	data_grads_norm = 2.7407
	new_data_grads_norm = 5.0744
	old_data_grads_norm = 3.2670
	sim_grads_norm_tr = -0.3274
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4177
	data_grads_norm = 3.9924
	new_data_grads_norm = 5.2415
	old_data_grads_norm = 4.7840
	sim_grads_norm_tr = 0.3676
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4235
	data_grads_norm = 3.3639
	new_data_grads_norm = 5.2696
	old_data_grads_norm = 5.2029
	sim_grads_norm_tr = 0.0292
-- Starting training on experience 115 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5960
	data_grads_norm = 5.1455
	new_data_grads_norm = 6.3491
	old_data_grads_norm = 5.7405
	sim_grads_norm_tr = 0.1600
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4211
	data_grads_norm = 3.5465
	new_data_grads_norm = 5.2367
	old_data_grads_norm = 5.2611
	sim_grads_norm_tr = 0.1197
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3624
	data_grads_norm = 3.6387
	new_data_grads_norm = 5.1159
	old_data_grads_norm = 4.0115
	sim_grads_norm_tr = 0.1947
-- Starting training on experience 116 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3731
	data_grads_norm = 3.5678
	new_data_grads_norm = 4.8616
	old_data_grads_norm = 3.6984
	sim_grads_norm_tr = 0.2416
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6105
	data_grads_norm = 4.0764
	new_data_grads_norm = 4.6222
	old_data_grads_norm = 4.4322
	sim_grads_norm_tr = 0.3659
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1213
	data_grads_norm = 2.5899
	new_data_grads_norm = 4.3207
	old_data_grads_norm = 3.6598
	sim_grads_norm_tr = -0.2851
-- Starting training on experience 117 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1201
	data_grads_norm = 2.8961
	new_data_grads_norm = 2.6310
	old_data_grads_norm = 4.4770
	sim_grads_norm_tr = 0.0692
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7783
	data_grads_norm = 1.8114
	new_data_grads_norm = 2.6811
	old_data_grads_norm = 2.9747
	sim_grads_norm_tr = -0.1024
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9984
	data_grads_norm = 2.5360
	new_data_grads_norm = 3.0603
	old_data_grads_norm = 3.8496
	sim_grads_norm_tr = 0.2467
-- Starting training on experience 118 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8644
	data_grads_norm = 3.3639
	new_data_grads_norm = 5.5897
	old_data_grads_norm = 3.1376
	sim_grads_norm_tr = -0.0925
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4967
	data_grads_norm = 4.0680
	new_data_grads_norm = 5.8474
	old_data_grads_norm = 6.5130
	sim_grads_norm_tr = 0.0871
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2589
	data_grads_norm = 3.5464
	new_data_grads_norm = 4.7929
	old_data_grads_norm = 3.0643
	sim_grads_norm_tr = 0.1865
-- Starting training on experience 119 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1844
	data_grads_norm = 2.5283
	new_data_grads_norm = 3.7536
	old_data_grads_norm = 3.9296
	sim_grads_norm_tr = -0.1428
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1960
	data_grads_norm = 2.7256
	new_data_grads_norm = 3.5820
	old_data_grads_norm = 3.5280
	sim_grads_norm_tr = 0.1838
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1039
	data_grads_norm = 2.6562
	new_data_grads_norm = 3.5668
	old_data_grads_norm = 4.0370
	sim_grads_norm_tr = 0.0358
-- Starting training on experience 120 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4624
	data_grads_norm = 3.3985
	new_data_grads_norm = 4.2396
	old_data_grads_norm = 5.0418
	sim_grads_norm_tr = 0.1775
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3141
	data_grads_norm = 2.0624
	new_data_grads_norm = 4.6942
	old_data_grads_norm = 2.3657
	sim_grads_norm_tr = -0.0906
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3644
	data_grads_norm = 3.1224
	new_data_grads_norm = 4.5580
	old_data_grads_norm = 4.6293
	sim_grads_norm_tr = 0.1555
-- Starting training on experience 121 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9302
	data_grads_norm = 2.0664
	new_data_grads_norm = 2.8760
	old_data_grads_norm = 2.9667
	sim_grads_norm_tr = 0.1260
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1016
	data_grads_norm = 2.1110
	new_data_grads_norm = 2.7839
	old_data_grads_norm = 4.3297
	sim_grads_norm_tr = -0.0417
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6154
	data_grads_norm = 3.5052
	new_data_grads_norm = 4.3712
	old_data_grads_norm = 4.9770
	sim_grads_norm_tr = 0.1166
-- Starting training on experience 122 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1649
	data_grads_norm = 2.0179
	new_data_grads_norm = 2.7444
	old_data_grads_norm = 3.7979
	sim_grads_norm_tr = -0.0987
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1470
	data_grads_norm = 3.1825
	new_data_grads_norm = 4.0901
	old_data_grads_norm = 4.0372
	sim_grads_norm_tr = 0.1469
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5816
	data_grads_norm = 3.2922
	new_data_grads_norm = 3.7859
	old_data_grads_norm = 5.5188
	sim_grads_norm_tr = 0.1124
-- Starting training on experience 123 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2280
	data_grads_norm = 2.3477
	new_data_grads_norm = 3.6553
	old_data_grads_norm = 3.0834
	sim_grads_norm_tr = 0.0032
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2231
	data_grads_norm = 2.8898
	new_data_grads_norm = 3.6974
	old_data_grads_norm = 3.9599
	sim_grads_norm_tr = 0.0768
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2924
	data_grads_norm = 2.7908
	new_data_grads_norm = 3.6161
	old_data_grads_norm = 3.9316
	sim_grads_norm_tr = 0.3821
-- Starting training on experience 124 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3245
	data_grads_norm = 2.3077
	new_data_grads_norm = 3.0523
	old_data_grads_norm = 3.2399
	sim_grads_norm_tr = 0.0729
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1849
	data_grads_norm = 1.8471
	new_data_grads_norm = 2.9488
	old_data_grads_norm = 2.8627
	sim_grads_norm_tr = 0.2068
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1719
	data_grads_norm = 2.0862
	new_data_grads_norm = 3.1247
	old_data_grads_norm = 2.2045
	sim_grads_norm_tr = -0.0428
-- Starting training on experience 125 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5165
	data_grads_norm = 2.8904
	new_data_grads_norm = 4.1061
	old_data_grads_norm = 3.9545
	sim_grads_norm_tr = 0.1001
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3612
	data_grads_norm = 2.7170
	new_data_grads_norm = 4.2484
	old_data_grads_norm = 2.9600
	sim_grads_norm_tr = 0.0600
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2293
	data_grads_norm = 2.4269
	new_data_grads_norm = 3.4878
	old_data_grads_norm = 3.0300
	sim_grads_norm_tr = 0.1950
-- Starting training on experience 126 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0248
	data_grads_norm = 2.1295
	new_data_grads_norm = 3.2532
	old_data_grads_norm = 2.3681
	sim_grads_norm_tr = 0.2334
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9108
	data_grads_norm = 2.2657
	new_data_grads_norm = 2.2870
	old_data_grads_norm = 3.8880
	sim_grads_norm_tr = 0.0625
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9011
	data_grads_norm = 1.6438
	new_data_grads_norm = 3.2844
	old_data_grads_norm = 2.4022
	sim_grads_norm_tr = 0.1220
-- Starting training on experience 127 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6246
	data_grads_norm = 3.6923
	new_data_grads_norm = 4.4989
	old_data_grads_norm = 5.0524
	sim_grads_norm_tr = 0.1484
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1599
	data_grads_norm = 2.2387
	new_data_grads_norm = 3.3833
	old_data_grads_norm = 3.1245
	sim_grads_norm_tr = 0.1691
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0050
	data_grads_norm = 2.5002
	new_data_grads_norm = 3.6025
	old_data_grads_norm = 4.1699
	sim_grads_norm_tr = -0.0836
-- Starting training on experience 128 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4629
	data_grads_norm = 3.0974
	new_data_grads_norm = 4.5836
	old_data_grads_norm = 3.3988
	sim_grads_norm_tr = 0.3021
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3944
	data_grads_norm = 2.3185
	new_data_grads_norm = 4.2590
	old_data_grads_norm = 3.6309
	sim_grads_norm_tr = -0.1095
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5678
	data_grads_norm = 4.2275
	new_data_grads_norm = 5.3991
	old_data_grads_norm = 4.3590
	sim_grads_norm_tr = 0.5223
-- Starting training on experience 129 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0730
	data_grads_norm = 3.1489
	new_data_grads_norm = 3.9157
	old_data_grads_norm = 4.4004
	sim_grads_norm_tr = 0.3887
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7719
	data_grads_norm = 1.8497
	new_data_grads_norm = 2.9105
	old_data_grads_norm = 2.8595
	sim_grads_norm_tr = 0.0214
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1895
	data_grads_norm = 3.4882
	new_data_grads_norm = 3.6127
	old_data_grads_norm = 5.1029
	sim_grads_norm_tr = 0.2381
-- Starting training on experience 130 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2168
	data_grads_norm = 2.7122
	new_data_grads_norm = 3.7558
	old_data_grads_norm = 4.9264
	sim_grads_norm_tr = -0.1020
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2601
	data_grads_norm = 3.5633
	new_data_grads_norm = 3.9232
	old_data_grads_norm = 4.4459
	sim_grads_norm_tr = 0.5346
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8936
	data_grads_norm = 1.8285
	new_data_grads_norm = 2.5227
	old_data_grads_norm = 2.7559
	sim_grads_norm_tr = 0.2146
-- Starting training on experience 131 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2004
	data_grads_norm = 2.2460
	new_data_grads_norm = 3.2443
	old_data_grads_norm = 2.9323
	sim_grads_norm_tr = 0.1854
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2010
	data_grads_norm = 2.7049
	new_data_grads_norm = 3.3958
	old_data_grads_norm = 3.9759
	sim_grads_norm_tr = -0.0861
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3277
	data_grads_norm = 3.1930
	new_data_grads_norm = 3.7654
	old_data_grads_norm = 4.4796
	sim_grads_norm_tr = 0.1182
-- Starting training on experience 132 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1766
	data_grads_norm = 2.6931
	new_data_grads_norm = 3.7189
	old_data_grads_norm = 4.8546
	sim_grads_norm_tr = 0.0281
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2109
	data_grads_norm = 2.2406
	new_data_grads_norm = 3.4643
	old_data_grads_norm = 2.8198
	sim_grads_norm_tr = 0.0698
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9991
	data_grads_norm = 2.3372
	new_data_grads_norm = 4.0473
	old_data_grads_norm = 2.8083
	sim_grads_norm_tr = -0.1589
-- Starting training on experience 133 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0745
	data_grads_norm = 3.6978
	new_data_grads_norm = 5.8183
	old_data_grads_norm = 4.0331
	sim_grads_norm_tr = 0.2644
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0402
	data_grads_norm = 2.7450
	new_data_grads_norm = 4.6598
	old_data_grads_norm = 3.5137
	sim_grads_norm_tr = 0.1831
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0065
	data_grads_norm = 2.7407
	new_data_grads_norm = 4.2682
	old_data_grads_norm = 3.5815
	sim_grads_norm_tr = -0.0524
-- Starting training on experience 134 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2441
	data_grads_norm = 2.6472
	new_data_grads_norm = 4.5096
	old_data_grads_norm = 2.6498
	sim_grads_norm_tr = 0.0740
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2016
	data_grads_norm = 4.0432
	new_data_grads_norm = 4.6702
	old_data_grads_norm = 4.5637
	sim_grads_norm_tr = 0.4740
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0244
	data_grads_norm = 2.3199
	new_data_grads_norm = 3.6015
	old_data_grads_norm = 3.9742
	sim_grads_norm_tr = -0.0058
-- Starting training on experience 135 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4983
	data_grads_norm = 3.7288
	new_data_grads_norm = 5.3232
	old_data_grads_norm = 3.6841
	sim_grads_norm_tr = 0.3244
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1842
	data_grads_norm = 3.7430
	new_data_grads_norm = 3.8937
	old_data_grads_norm = 5.9175
	sim_grads_norm_tr = -0.0168
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2241
	data_grads_norm = 3.1424
	new_data_grads_norm = 4.9808
	old_data_grads_norm = 3.3593
	sim_grads_norm_tr = 0.2050
-- Starting training on experience 136 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2472
	data_grads_norm = 3.4304
	new_data_grads_norm = 6.0803
	old_data_grads_norm = 5.1058
	sim_grads_norm_tr = 0.2634
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0731
	data_grads_norm = 2.6536
	new_data_grads_norm = 4.5329
	old_data_grads_norm = 3.0452
	sim_grads_norm_tr = 0.0015
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1354
	data_grads_norm = 3.1146
	new_data_grads_norm = 4.3885
	old_data_grads_norm = 4.0671
	sim_grads_norm_tr = -0.1468
-- Starting training on experience 137 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1182
	data_grads_norm = 3.0474
	new_data_grads_norm = 4.7045
	old_data_grads_norm = 3.6676
	sim_grads_norm_tr = 0.0992
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3318
	data_grads_norm = 3.2677
	new_data_grads_norm = 4.5192
	old_data_grads_norm = 4.9245
	sim_grads_norm_tr = -0.0777
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6674
	data_grads_norm = 4.0454
	new_data_grads_norm = 4.7837
	old_data_grads_norm = 5.1429
	sim_grads_norm_tr = 0.1844
-- Starting training on experience 138 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0294
	data_grads_norm = 2.1677
	new_data_grads_norm = 2.1789
	old_data_grads_norm = 3.7551
	sim_grads_norm_tr = 0.0935
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9335
	data_grads_norm = 1.8534
	new_data_grads_norm = 3.1390
	old_data_grads_norm = 3.3830
	sim_grads_norm_tr = -0.1991
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2993
	data_grads_norm = 3.7405
	new_data_grads_norm = 4.1648
	old_data_grads_norm = 5.2540
	sim_grads_norm_tr = 0.3806
-- Starting training on experience 139 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9865
	data_grads_norm = 2.0100
	new_data_grads_norm = 2.9968
	old_data_grads_norm = 4.0100
	sim_grads_norm_tr = -0.2563
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1120
	data_grads_norm = 2.7200
	new_data_grads_norm = 4.1749
	old_data_grads_norm = 2.8103
	sim_grads_norm_tr = 0.5990
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8462
	data_grads_norm = 2.2101
	new_data_grads_norm = 3.0903
	old_data_grads_norm = 3.1949
	sim_grads_norm_tr = 0.0342
-- Starting training on experience 140 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2167
	data_grads_norm = 3.0302
	new_data_grads_norm = 4.2058
	old_data_grads_norm = 3.6932
	sim_grads_norm_tr = 0.1543
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2366
	data_grads_norm = 3.2978
	new_data_grads_norm = 4.2864
	old_data_grads_norm = 5.1947
	sim_grads_norm_tr = 0.1134
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7192
	data_grads_norm = 4.4320
	new_data_grads_norm = 4.9526
	old_data_grads_norm = 6.4179
	sim_grads_norm_tr = 0.2509
-- Starting training on experience 141 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9923
	data_grads_norm = 2.4355
	new_data_grads_norm = 3.6584
	old_data_grads_norm = 3.1578
	sim_grads_norm_tr = 0.0229
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2280
	data_grads_norm = 2.5924
	new_data_grads_norm = 3.8869
	old_data_grads_norm = 3.9541
	sim_grads_norm_tr = -0.3116
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2921
	data_grads_norm = 3.5546
	new_data_grads_norm = 4.5411
	old_data_grads_norm = 4.2621
	sim_grads_norm_tr = 0.2805
-- Starting training on experience 142 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5345
	data_grads_norm = 3.2223
	new_data_grads_norm = 4.3841
	old_data_grads_norm = 4.1509
	sim_grads_norm_tr = 0.2705
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5401
	data_grads_norm = 3.4695
	new_data_grads_norm = 4.0072
	old_data_grads_norm = 4.4766
	sim_grads_norm_tr = 0.3259
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3025
	data_grads_norm = 2.4679
	new_data_grads_norm = 3.4533
	old_data_grads_norm = 3.9752
	sim_grads_norm_tr = 0.1310
-- Starting training on experience 143 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9923
	data_grads_norm = 2.1896
	new_data_grads_norm = 2.8113
	old_data_grads_norm = 3.3393
	sim_grads_norm_tr = 0.0098
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9792
	data_grads_norm = 2.2221
	new_data_grads_norm = 2.5482
	old_data_grads_norm = 3.3898
	sim_grads_norm_tr = 0.1875
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0528
	data_grads_norm = 2.9106
	new_data_grads_norm = 2.3791
	old_data_grads_norm = 3.5247
	sim_grads_norm_tr = -0.0044
-- Starting training on experience 144 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1056
	data_grads_norm = 2.4603
	new_data_grads_norm = 3.5995
	old_data_grads_norm = 3.1338
	sim_grads_norm_tr = 0.3773
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2579
	data_grads_norm = 2.7711
	new_data_grads_norm = 3.2722
	old_data_grads_norm = 4.4061
	sim_grads_norm_tr = 0.0665
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2806
	data_grads_norm = 2.7281
	new_data_grads_norm = 3.2797
	old_data_grads_norm = 3.7644
	sim_grads_norm_tr = 0.1080
-- Starting training on experience 145 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1262
	data_grads_norm = 1.9691
	new_data_grads_norm = 3.8083
	old_data_grads_norm = 2.8739
	sim_grads_norm_tr = -0.0594
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3184
	data_grads_norm = 2.7774
	new_data_grads_norm = 4.6240
	old_data_grads_norm = 3.3597
	sim_grads_norm_tr = 0.1397
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1784
	data_grads_norm = 2.7662
	new_data_grads_norm = 3.6024
	old_data_grads_norm = 3.4320
	sim_grads_norm_tr = 0.2847
-- Starting training on experience 146 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1334
	data_grads_norm = 2.6513
	new_data_grads_norm = 3.4155
	old_data_grads_norm = 3.6783
	sim_grads_norm_tr = 0.1281
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1655
	data_grads_norm = 2.3454
	new_data_grads_norm = 3.1676
	old_data_grads_norm = 3.9530
	sim_grads_norm_tr = 0.0934
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2211
	data_grads_norm = 2.6867
	new_data_grads_norm = 4.2912
	old_data_grads_norm = 4.8306
	sim_grads_norm_tr = -0.0928
-- Starting training on experience 147 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9919
	data_grads_norm = 3.1811
	new_data_grads_norm = 4.2330
	old_data_grads_norm = 3.4412
	sim_grads_norm_tr = 0.1985
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1215
	data_grads_norm = 2.5515
	new_data_grads_norm = 4.4121
	old_data_grads_norm = 3.5528
	sim_grads_norm_tr = 0.1029
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1755
	data_grads_norm = 2.9311
	new_data_grads_norm = 4.7592
	old_data_grads_norm = 3.5438
	sim_grads_norm_tr = 0.0559
-- Starting training on experience 148 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9046
	data_grads_norm = 2.0957
	new_data_grads_norm = 3.7498
	old_data_grads_norm = 3.6491
	sim_grads_norm_tr = -0.1296
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0348
	data_grads_norm = 2.9836
	new_data_grads_norm = 4.6680
	old_data_grads_norm = 2.7823
	sim_grads_norm_tr = 0.2271
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0375
	data_grads_norm = 2.2046
	new_data_grads_norm = 4.2098
	old_data_grads_norm = 3.9715
	sim_grads_norm_tr = -0.1478
-- Starting training on experience 149 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1033
	data_grads_norm = 2.5470
	new_data_grads_norm = 5.2842
	old_data_grads_norm = 3.4499
	sim_grads_norm_tr = 0.0977
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9810
	data_grads_norm = 3.2802
	new_data_grads_norm = 4.7545
	old_data_grads_norm = 3.5557
	sim_grads_norm_tr = 0.2161
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1078
	data_grads_norm = 3.2558
	new_data_grads_norm = 4.5238
	old_data_grads_norm = 4.7296
	sim_grads_norm_tr = 0.2604
-- Starting training on experience 150 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1851
	data_grads_norm = 2.2154
	new_data_grads_norm = 3.4763
	old_data_grads_norm = 3.1133
	sim_grads_norm_tr = 0.0859
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0671
	data_grads_norm = 3.0334
	new_data_grads_norm = 3.8105
	old_data_grads_norm = 3.8647
	sim_grads_norm_tr = 0.4132
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3033
	data_grads_norm = 2.8006
	new_data_grads_norm = 2.7830
	old_data_grads_norm = 5.3557
	sim_grads_norm_tr = 0.0694
-- Starting training on experience 151 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1065
	data_grads_norm = 2.9347
	new_data_grads_norm = 2.8086
	old_data_grads_norm = 6.0827
	sim_grads_norm_tr = 0.1106
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1764
	data_grads_norm = 3.0479
	new_data_grads_norm = 3.5380
	old_data_grads_norm = 4.8629
	sim_grads_norm_tr = 0.0726
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2786
	data_grads_norm = 3.0290
	new_data_grads_norm = 4.0664
	old_data_grads_norm = 3.5228
	sim_grads_norm_tr = 0.3012
-- Starting training on experience 152 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3369
	data_grads_norm = 2.5371
	new_data_grads_norm = 3.2993
	old_data_grads_norm = 4.5664
	sim_grads_norm_tr = -0.0286
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6329
	data_grads_norm = 2.6368
	new_data_grads_norm = 3.4418
	old_data_grads_norm = 3.4598
	sim_grads_norm_tr = 0.0315
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2719
	data_grads_norm = 2.4591
	new_data_grads_norm = 3.5805
	old_data_grads_norm = 3.0543
	sim_grads_norm_tr = 0.2211
-- Starting training on experience 153 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2451
	data_grads_norm = 2.3369
	new_data_grads_norm = 3.2516
	old_data_grads_norm = 3.1912
	sim_grads_norm_tr = 0.2767
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2085
	data_grads_norm = 2.0981
	new_data_grads_norm = 2.7739
	old_data_grads_norm = 4.1738
	sim_grads_norm_tr = -0.0788
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3177
	data_grads_norm = 3.0708
	new_data_grads_norm = 3.1600
	old_data_grads_norm = 5.8587
	sim_grads_norm_tr = 0.2009
-- Starting training on experience 154 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2814
	data_grads_norm = 3.4335
	new_data_grads_norm = 4.5442
	old_data_grads_norm = 3.3456
	sim_grads_norm_tr = 0.4986
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9700
	data_grads_norm = 2.1599
	new_data_grads_norm = 3.9162
	old_data_grads_norm = 4.1752
	sim_grads_norm_tr = -0.2456
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1101
	data_grads_norm = 2.5915
	new_data_grads_norm = 4.1776
	old_data_grads_norm = 3.2148
	sim_grads_norm_tr = 0.0650
-- Starting training on experience 155 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2330
	data_grads_norm = 2.7822
	new_data_grads_norm = 4.5734
	old_data_grads_norm = 4.0061
	sim_grads_norm_tr = 0.1267
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3075
	data_grads_norm = 2.7562
	new_data_grads_norm = 4.9177
	old_data_grads_norm = 2.7463
	sim_grads_norm_tr = 0.1554
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6111
	data_grads_norm = 3.2608
	new_data_grads_norm = 5.3942
	old_data_grads_norm = 4.9540
	sim_grads_norm_tr = 0.0148
-- Starting training on experience 156 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9676
	data_grads_norm = 1.8698
	new_data_grads_norm = 3.9147
	old_data_grads_norm = 1.9580
	sim_grads_norm_tr = 0.0378
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1800
	data_grads_norm = 3.1762
	new_data_grads_norm = 4.3043
	old_data_grads_norm = 3.9013
	sim_grads_norm_tr = 0.2192
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9516
	data_grads_norm = 1.7378
	new_data_grads_norm = 3.4833
	old_data_grads_norm = 3.1679
	sim_grads_norm_tr = -0.2020
-- Starting training on experience 157 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1235
	data_grads_norm = 2.3127
	new_data_grads_norm = 4.4988
	old_data_grads_norm = 3.3770
	sim_grads_norm_tr = 0.0996
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2149
	data_grads_norm = 2.4399
	new_data_grads_norm = 4.7368
	old_data_grads_norm = 2.3794
	sim_grads_norm_tr = 0.1147
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3218
	data_grads_norm = 2.8235
	new_data_grads_norm = 4.5936
	old_data_grads_norm = 3.8455
	sim_grads_norm_tr = 0.0319
-- Starting training on experience 158 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1077
	data_grads_norm = 3.4062
	new_data_grads_norm = 4.8285
	old_data_grads_norm = 3.8306
	sim_grads_norm_tr = 0.2562
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9978
	data_grads_norm = 2.6128
	new_data_grads_norm = 3.9869
	old_data_grads_norm = 3.2854
	sim_grads_norm_tr = 0.2588
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9844
	data_grads_norm = 2.6541
	new_data_grads_norm = 4.3422
	old_data_grads_norm = 3.2473
	sim_grads_norm_tr = -0.0379
-- Starting training on experience 159 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0224
	data_grads_norm = 3.1774
	new_data_grads_norm = 2.9997
	old_data_grads_norm = 4.0602
	sim_grads_norm_tr = 0.2959
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9043
	data_grads_norm = 2.0704
	new_data_grads_norm = 2.5116
	old_data_grads_norm = 3.3047
	sim_grads_norm_tr = -0.0429
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0798
	data_grads_norm = 2.6490
	new_data_grads_norm = 3.4385
	old_data_grads_norm = 4.3377
	sim_grads_norm_tr = -0.0412
-- Starting training on experience 160 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1441
	data_grads_norm = 2.2581
	new_data_grads_norm = 3.3492
	old_data_grads_norm = 2.8750
	sim_grads_norm_tr = -0.0851
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3847
	data_grads_norm = 2.6385
	new_data_grads_norm = 3.5638
	old_data_grads_norm = 3.3987
	sim_grads_norm_tr = 0.1844
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0927
	data_grads_norm = 2.2231
	new_data_grads_norm = 3.6494
	old_data_grads_norm = 3.1622
	sim_grads_norm_tr = -0.0768
-- Starting training on experience 161 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2049
	data_grads_norm = 3.1793
	new_data_grads_norm = 3.8489
	old_data_grads_norm = 4.3779
	sim_grads_norm_tr = 0.1509
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9763
	data_grads_norm = 2.6200
	new_data_grads_norm = 2.9250
	old_data_grads_norm = 5.0707
	sim_grads_norm_tr = -0.0920
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1575
	data_grads_norm = 2.4513
	new_data_grads_norm = 3.8082
	old_data_grads_norm = 4.2932
	sim_grads_norm_tr = 0.1934
-- Starting training on experience 162 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9887
	data_grads_norm = 2.2265
	new_data_grads_norm = 3.1059
	old_data_grads_norm = 2.5661
	sim_grads_norm_tr = 0.3140
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1109
	data_grads_norm = 2.4386
	new_data_grads_norm = 2.6589
	old_data_grads_norm = 3.2100
	sim_grads_norm_tr = 0.3315
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2245
	data_grads_norm = 2.4214
	new_data_grads_norm = 2.8666
	old_data_grads_norm = 3.5624
	sim_grads_norm_tr = 0.1505
-- Starting training on experience 163 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0526
	data_grads_norm = 2.6447
	new_data_grads_norm = 3.0251
	old_data_grads_norm = 4.4580
	sim_grads_norm_tr = 0.0325
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9022
	data_grads_norm = 2.1503
	new_data_grads_norm = 3.2540
	old_data_grads_norm = 2.8813
	sim_grads_norm_tr = -0.0441
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1389
	data_grads_norm = 2.4390
	new_data_grads_norm = 3.2872
	old_data_grads_norm = 2.7730
	sim_grads_norm_tr = 0.3889
-- Starting training on experience 164 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9398
	data_grads_norm = 1.9660
	new_data_grads_norm = 2.8893
	old_data_grads_norm = 3.3407
	sim_grads_norm_tr = 0.0961
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0732
	data_grads_norm = 2.1274
	new_data_grads_norm = 2.5886
	old_data_grads_norm = 4.0489
	sim_grads_norm_tr = -0.0458
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0991
	data_grads_norm = 2.3999
	new_data_grads_norm = 3.2536
	old_data_grads_norm = 3.6749
	sim_grads_norm_tr = 0.0379
-- Starting training on experience 165 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8609
	data_grads_norm = 1.8039
	new_data_grads_norm = 2.5410
	old_data_grads_norm = 4.2378
	sim_grads_norm_tr = -0.1555
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9861
	data_grads_norm = 2.5023
	new_data_grads_norm = 4.2463
	old_data_grads_norm = 3.1791
	sim_grads_norm_tr = 0.1477
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1739
	data_grads_norm = 2.2661
	new_data_grads_norm = 3.7985
	old_data_grads_norm = 3.1516
	sim_grads_norm_tr = 0.0542
-- Starting training on experience 166 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0032
	data_grads_norm = 1.8284
	new_data_grads_norm = 3.1964
	old_data_grads_norm = 4.3236
	sim_grads_norm_tr = -0.3682
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0785
	data_grads_norm = 2.9357
	new_data_grads_norm = 4.6032
	old_data_grads_norm = 2.1475
	sim_grads_norm_tr = 0.1525
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8730
	data_grads_norm = 1.9606
	new_data_grads_norm = 4.1980
	old_data_grads_norm = 2.1802
	sim_grads_norm_tr = -0.3959
-- Starting training on experience 167 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3319
	data_grads_norm = 5.9040
	new_data_grads_norm = 8.5791
	old_data_grads_norm = 5.8349
	sim_grads_norm_tr = 0.2893
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2921
	data_grads_norm = 3.4727
	new_data_grads_norm = 6.8586
	old_data_grads_norm = 3.5299
	sim_grads_norm_tr = -0.1574
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6572
	data_grads_norm = 5.7366
	new_data_grads_norm = 7.7396
	old_data_grads_norm = 5.4252
	sim_grads_norm_tr = 0.3428
-- Starting training on experience 168 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2028
	data_grads_norm = 3.2127
	new_data_grads_norm = 4.2603
	old_data_grads_norm = 2.8089
	sim_grads_norm_tr = 0.0118
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5973
	data_grads_norm = 4.4493
	new_data_grads_norm = 4.3703
	old_data_grads_norm = 6.2975
	sim_grads_norm_tr = 0.3804
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0096
	data_grads_norm = 3.0172
	new_data_grads_norm = 2.9076
	old_data_grads_norm = 4.7559
	sim_grads_norm_tr = 0.1171
-- Starting training on experience 169 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2007
	data_grads_norm = 2.2927
	new_data_grads_norm = 3.8529
	old_data_grads_norm = 3.1012
	sim_grads_norm_tr = 0.1825
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1320
	data_grads_norm = 2.6111
	new_data_grads_norm = 4.1688
	old_data_grads_norm = 4.0117
	sim_grads_norm_tr = -0.0229
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2194
	data_grads_norm = 3.1980
	new_data_grads_norm = 4.6164
	old_data_grads_norm = 3.7034
	sim_grads_norm_tr = 0.2656
-- Starting training on experience 170 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4841
	data_grads_norm = 2.7178
	new_data_grads_norm = 4.4115
	old_data_grads_norm = 3.8624
	sim_grads_norm_tr = 0.0471
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2090
	data_grads_norm = 2.5714
	new_data_grads_norm = 4.2785
	old_data_grads_norm = 2.8812
	sim_grads_norm_tr = 0.1040
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3114
	data_grads_norm = 2.5021
	new_data_grads_norm = 4.1528
	old_data_grads_norm = 3.2854
	sim_grads_norm_tr = -0.0917
-- Starting training on experience 171 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9396
	data_grads_norm = 1.8750
	new_data_grads_norm = 2.6320
	old_data_grads_norm = 3.9833
	sim_grads_norm_tr = -0.0079
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0417
	data_grads_norm = 2.2644
	new_data_grads_norm = 2.7958
	old_data_grads_norm = 3.3180
	sim_grads_norm_tr = 0.0506
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0304
	data_grads_norm = 2.1890
	new_data_grads_norm = 2.8055
	old_data_grads_norm = 3.6388
	sim_grads_norm_tr = -0.0554
-- Starting training on experience 172 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0499
	data_grads_norm = 2.6336
	new_data_grads_norm = 4.3811
	old_data_grads_norm = 3.5782
	sim_grads_norm_tr = 0.1361
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0611
	data_grads_norm = 3.3339
	new_data_grads_norm = 3.5905
	old_data_grads_norm = 4.4756
	sim_grads_norm_tr = 0.1720
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0202
	data_grads_norm = 2.5236
	new_data_grads_norm = 3.2111
	old_data_grads_norm = 3.2665
	sim_grads_norm_tr = 0.1740
-- Starting training on experience 173 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3314
	data_grads_norm = 3.3503
	new_data_grads_norm = 4.6228
	old_data_grads_norm = 3.1471
	sim_grads_norm_tr = 0.1927
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2076
	data_grads_norm = 3.2224
	new_data_grads_norm = 4.1684
	old_data_grads_norm = 4.5500
	sim_grads_norm_tr = 0.2463
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1761
	data_grads_norm = 3.6932
	new_data_grads_norm = 4.6456
	old_data_grads_norm = 3.2806
	sim_grads_norm_tr = 0.2841
-- Starting training on experience 174 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3985
	data_grads_norm = 3.7359
	new_data_grads_norm = 5.7158
	old_data_grads_norm = 2.6167
	sim_grads_norm_tr = 0.1240
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8118
	data_grads_norm = 4.4506
	new_data_grads_norm = 6.1931
	old_data_grads_norm = 4.2158
	sim_grads_norm_tr = 0.1763
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3547
	data_grads_norm = 3.5636
	new_data_grads_norm = 5.5017
	old_data_grads_norm = 4.1828
	sim_grads_norm_tr = 0.2893
-- Starting training on experience 175 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3545
	data_grads_norm = 3.1968
	new_data_grads_norm = 2.4157
	old_data_grads_norm = 4.5291
	sim_grads_norm_tr = -0.0693
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1522
	data_grads_norm = 2.2378
	new_data_grads_norm = 3.2273
	old_data_grads_norm = 2.8108
	sim_grads_norm_tr = 0.3049
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0541
	data_grads_norm = 2.0509
	new_data_grads_norm = 2.5573
	old_data_grads_norm = 3.6442
	sim_grads_norm_tr = 0.2140
-- Starting training on experience 176 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9823
	data_grads_norm = 2.4387
	new_data_grads_norm = 3.8314
	old_data_grads_norm = 2.9398
	sim_grads_norm_tr = 0.0868
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8508
	data_grads_norm = 2.1559
	new_data_grads_norm = 4.1834
	old_data_grads_norm = 3.2287
	sim_grads_norm_tr = -0.1800
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1733
	data_grads_norm = 2.7134
	new_data_grads_norm = 4.1536
	old_data_grads_norm = 3.9976
	sim_grads_norm_tr = 0.1575
-- Starting training on experience 177 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1769
	data_grads_norm = 3.7771
	new_data_grads_norm = 4.0830
	old_data_grads_norm = 4.9749
	sim_grads_norm_tr = 0.4087
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7983
	data_grads_norm = 2.0635
	new_data_grads_norm = 2.9428
	old_data_grads_norm = 4.2788
	sim_grads_norm_tr = -0.2059
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0593
	data_grads_norm = 2.8892
	new_data_grads_norm = 3.5693
	old_data_grads_norm = 3.8679
	sim_grads_norm_tr = 0.1424
-- Starting training on experience 178 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1972
	data_grads_norm = 3.2563
	new_data_grads_norm = 3.4657
	old_data_grads_norm = 4.5436
	sim_grads_norm_tr = 0.3316
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1339
	data_grads_norm = 2.5184
	new_data_grads_norm = 3.0645
	old_data_grads_norm = 3.8125
	sim_grads_norm_tr = 0.0443
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1754
	data_grads_norm = 2.9051
	new_data_grads_norm = 3.0779
	old_data_grads_norm = 5.3053
	sim_grads_norm_tr = 0.2613
-- Starting training on experience 179 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3528
	data_grads_norm = 3.1686
	new_data_grads_norm = 4.9262
	old_data_grads_norm = 5.5365
	sim_grads_norm_tr = 0.0158
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1806
	data_grads_norm = 2.7484
	new_data_grads_norm = 5.2327
	old_data_grads_norm = 2.5115
	sim_grads_norm_tr = -0.0873
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2595
	data_grads_norm = 3.1323
	new_data_grads_norm = 5.0182
	old_data_grads_norm = 3.5698
	sim_grads_norm_tr = -0.0162
-- Starting training on experience 180 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0328
	data_grads_norm = 2.9614
	new_data_grads_norm = 3.9328
	old_data_grads_norm = 3.8541
	sim_grads_norm_tr = 0.2258
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9793
	data_grads_norm = 2.3627
	new_data_grads_norm = 2.9663
	old_data_grads_norm = 2.7602
	sim_grads_norm_tr = 0.2551
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9349
	data_grads_norm = 2.9389
	new_data_grads_norm = 3.0839
	old_data_grads_norm = 4.3755
	sim_grads_norm_tr = 0.3932
-- Starting training on experience 181 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0414
	data_grads_norm = 2.2980
	new_data_grads_norm = 3.0266
	old_data_grads_norm = 3.6799
	sim_grads_norm_tr = 0.1736
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1130
	data_grads_norm = 2.1216
	new_data_grads_norm = 2.8016
	old_data_grads_norm = 2.8954
	sim_grads_norm_tr = 0.0851
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1019
	data_grads_norm = 2.3208
	new_data_grads_norm = 2.8309
	old_data_grads_norm = 3.1168
	sim_grads_norm_tr = 0.2140
-- Starting training on experience 182 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0947
	data_grads_norm = 2.6040
	new_data_grads_norm = 2.8452
	old_data_grads_norm = 5.9455
	sim_grads_norm_tr = 0.0256
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1357
	data_grads_norm = 2.6599
	new_data_grads_norm = 3.3051
	old_data_grads_norm = 3.5245
	sim_grads_norm_tr = 0.0400
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3520
	data_grads_norm = 3.1218
	new_data_grads_norm = 3.3586
	old_data_grads_norm = 5.3442
	sim_grads_norm_tr = 0.3638
-- Starting training on experience 183 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9968
	data_grads_norm = 2.4134
	new_data_grads_norm = 3.3192
	old_data_grads_norm = 3.0151
	sim_grads_norm_tr = -0.0362
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1538
	data_grads_norm = 3.0064
	new_data_grads_norm = 3.1196
	old_data_grads_norm = 4.3901
	sim_grads_norm_tr = 0.2277
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0237
	data_grads_norm = 2.8725
	new_data_grads_norm = 2.8227
	old_data_grads_norm = 4.4203
	sim_grads_norm_tr = -0.0176
-- Starting training on experience 184 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9357
	data_grads_norm = 2.8570
	new_data_grads_norm = 3.4452
	old_data_grads_norm = 3.7128
	sim_grads_norm_tr = 0.2636
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7132
	data_grads_norm = 2.0040
	new_data_grads_norm = 2.9291
	old_data_grads_norm = 3.2944
	sim_grads_norm_tr = 0.0488
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9284
	data_grads_norm = 2.2307
	new_data_grads_norm = 2.9154
	old_data_grads_norm = 3.6834
	sim_grads_norm_tr = -0.2317
-- Starting training on experience 185 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2180
	data_grads_norm = 2.7018
	new_data_grads_norm = 4.6886
	old_data_grads_norm = 3.4983
	sim_grads_norm_tr = 0.0414
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0657
	data_grads_norm = 2.6420
	new_data_grads_norm = 4.4978
	old_data_grads_norm = 2.4146
	sim_grads_norm_tr = 0.3890
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8835
	data_grads_norm = 2.9678
	new_data_grads_norm = 3.7872
	old_data_grads_norm = 3.5923
	sim_grads_norm_tr = 0.4498
-- Starting training on experience 186 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0513
	data_grads_norm = 2.9401
	new_data_grads_norm = 4.2386
	old_data_grads_norm = 4.3593
	sim_grads_norm_tr = 0.0181
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1575
	data_grads_norm = 3.4884
	new_data_grads_norm = 4.5332
	old_data_grads_norm = 4.6391
	sim_grads_norm_tr = 0.2389
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0503
	data_grads_norm = 3.4547
	new_data_grads_norm = 4.4104
	old_data_grads_norm = 3.8395
	sim_grads_norm_tr = 0.2681
-- Starting training on experience 187 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9574
	data_grads_norm = 2.6623
	new_data_grads_norm = 4.3042
	old_data_grads_norm = 3.1985
	sim_grads_norm_tr = 0.0119
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0901
	data_grads_norm = 2.6675
	new_data_grads_norm = 4.8125
	old_data_grads_norm = 3.0992
	sim_grads_norm_tr = 0.1365
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7946
	data_grads_norm = 2.9567
	new_data_grads_norm = 4.1702
	old_data_grads_norm = 3.9573
	sim_grads_norm_tr = 0.2896
-- Starting training on experience 188 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7516
	data_grads_norm = 2.2920
	new_data_grads_norm = 2.8310
	old_data_grads_norm = 4.4316
	sim_grads_norm_tr = -0.1499
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9179
	data_grads_norm = 2.4024
	new_data_grads_norm = 3.2512
	old_data_grads_norm = 3.0464
	sim_grads_norm_tr = 0.3478
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0412
	data_grads_norm = 2.0136
	new_data_grads_norm = 2.7217
	old_data_grads_norm = 2.9133
	sim_grads_norm_tr = 0.1392
-- Starting training on experience 189 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9426
	data_grads_norm = 2.5986
	new_data_grads_norm = 3.7319
	old_data_grads_norm = 3.2044
	sim_grads_norm_tr = 0.1895
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9519
	data_grads_norm = 3.0918
	new_data_grads_norm = 2.8571
	old_data_grads_norm = 4.5882
	sim_grads_norm_tr = 0.0150
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2358
	data_grads_norm = 3.0781
	new_data_grads_norm = 4.0948
	old_data_grads_norm = 4.4009
	sim_grads_norm_tr = -0.0703
-- Starting training on experience 190 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7793
	data_grads_norm = 6.8001
	new_data_grads_norm = 5.1204
	old_data_grads_norm = 7.4069
	sim_grads_norm_tr = 0.3672
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1056
	data_grads_norm = 2.5110
	new_data_grads_norm = 4.7544
	old_data_grads_norm = 3.5700
	sim_grads_norm_tr = -0.0262
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2790
	data_grads_norm = 3.1756
	new_data_grads_norm = 4.4546
	old_data_grads_norm = 4.5328
	sim_grads_norm_tr = 0.1920
-- Starting training on experience 191 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3425
	data_grads_norm = 3.3676
	new_data_grads_norm = 4.1163
	old_data_grads_norm = 5.5818
	sim_grads_norm_tr = 0.2349
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2878
	data_grads_norm = 2.6050
	new_data_grads_norm = 4.0147
	old_data_grads_norm = 4.1051
	sim_grads_norm_tr = -0.0470
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8972
	data_grads_norm = 2.9415
	new_data_grads_norm = 5.2261
	old_data_grads_norm = 2.0053
	sim_grads_norm_tr = 0.0379
-- Starting training on experience 192 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2050
	data_grads_norm = 2.1925
	new_data_grads_norm = 3.3482
	old_data_grads_norm = 3.5385
	sim_grads_norm_tr = 0.0090
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5498
	data_grads_norm = 2.8363
	new_data_grads_norm = 3.8092
	old_data_grads_norm = 4.4687
	sim_grads_norm_tr = 0.0385
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3909
	data_grads_norm = 2.5077
	new_data_grads_norm = 3.5544
	old_data_grads_norm = 3.2764
	sim_grads_norm_tr = 0.0831
-- Starting training on experience 193 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0140
	data_grads_norm = 1.8833
	new_data_grads_norm = 3.5777
	old_data_grads_norm = 2.2777
	sim_grads_norm_tr = 0.0411
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0767
	data_grads_norm = 2.5406
	new_data_grads_norm = 4.3400
	old_data_grads_norm = 3.0397
	sim_grads_norm_tr = 0.1694
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0632
	data_grads_norm = 2.3380
	new_data_grads_norm = 2.6358
	old_data_grads_norm = 3.2180
	sim_grads_norm_tr = 0.1411
-- Starting training on experience 194 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9765
	data_grads_norm = 2.5101
	new_data_grads_norm = 2.2015
	old_data_grads_norm = 4.0869
	sim_grads_norm_tr = 0.1495
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9765
	data_grads_norm = 2.0381
	new_data_grads_norm = 1.8411
	old_data_grads_norm = 4.9132
	sim_grads_norm_tr = -0.1877
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8971
	data_grads_norm = 1.9812
	new_data_grads_norm = 2.7213
	old_data_grads_norm = 2.5138
	sim_grads_norm_tr = 0.2259
-- Starting training on experience 195 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1723
	data_grads_norm = 2.2204
	new_data_grads_norm = 3.1396
	old_data_grads_norm = 3.2102
	sim_grads_norm_tr = -0.0006
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1750
	data_grads_norm = 2.3759
	new_data_grads_norm = 3.3616
	old_data_grads_norm = 3.1997
	sim_grads_norm_tr = 0.2200
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9859
	data_grads_norm = 2.0998
	new_data_grads_norm = 3.5848
	old_data_grads_norm = 3.5841
	sim_grads_norm_tr = -0.2143
-- Starting training on experience 196 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1386
	data_grads_norm = 2.0353
	new_data_grads_norm = 3.0777
	old_data_grads_norm = 3.1000
	sim_grads_norm_tr = -0.0425
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2239
	data_grads_norm = 2.7434
	new_data_grads_norm = 3.3036
	old_data_grads_norm = 3.9347
	sim_grads_norm_tr = -0.0020
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4273
	data_grads_norm = 3.3748
	new_data_grads_norm = 3.4039
	old_data_grads_norm = 5.0917
	sim_grads_norm_tr = 0.3214
-- Starting training on experience 197 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1558
	data_grads_norm = 3.1491
	new_data_grads_norm = 3.1043
	old_data_grads_norm = 4.8405
	sim_grads_norm_tr = 0.1482
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9249
	data_grads_norm = 2.2043
	new_data_grads_norm = 3.0103
	old_data_grads_norm = 3.1569
	sim_grads_norm_tr = 0.0780
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0411
	data_grads_norm = 2.3605
	new_data_grads_norm = 3.4307
	old_data_grads_norm = 2.8807
	sim_grads_norm_tr = 0.1154
-- Starting training on experience 198 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3184
	data_grads_norm = 2.9927
	new_data_grads_norm = 5.8845
	old_data_grads_norm = 3.9759
	sim_grads_norm_tr = 0.1174
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1501
	data_grads_norm = 2.5376
	new_data_grads_norm = 4.5555
	old_data_grads_norm = 2.8793
	sim_grads_norm_tr = -0.0177
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2812
	data_grads_norm = 2.9677
	new_data_grads_norm = 4.5049
	old_data_grads_norm = 4.1693
	sim_grads_norm_tr = 0.1999
-- Starting training on experience 199 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2556
	data_grads_norm = 3.1473
	new_data_grads_norm = 3.7340
	old_data_grads_norm = 5.0988
	sim_grads_norm_tr = 0.0942
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0891
	data_grads_norm = 3.1193
	new_data_grads_norm = 3.2578
	old_data_grads_norm = 5.3101
	sim_grads_norm_tr = 0.1373
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8907
	data_grads_norm = 2.0983
	new_data_grads_norm = 2.9430
	old_data_grads_norm = 3.0062
	sim_grads_norm_tr = 0.1254
-- Starting training on experience 200 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8634
	data_grads_norm = 1.9731
	new_data_grads_norm = 4.3427
	old_data_grads_norm = 2.2990
	sim_grads_norm_tr = -0.1194
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3065
	data_grads_norm = 2.7066
	new_data_grads_norm = 4.5345
	old_data_grads_norm = 3.7776
	sim_grads_norm_tr = 0.1178
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9565
	data_grads_norm = 2.3441
	new_data_grads_norm = 4.1764
	old_data_grads_norm = 2.9748
	sim_grads_norm_tr = 0.0773
-- Starting training on experience 201 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9942
	data_grads_norm = 2.1873
	new_data_grads_norm = 3.4150
	old_data_grads_norm = 2.9265
	sim_grads_norm_tr = 0.2587
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0531
	data_grads_norm = 2.1319
	new_data_grads_norm = 3.4712
	old_data_grads_norm = 3.5464
	sim_grads_norm_tr = -0.0630
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1046
	data_grads_norm = 2.5418
	new_data_grads_norm = 3.8836
	old_data_grads_norm = 4.4791
	sim_grads_norm_tr = -0.0027
-- Starting training on experience 202 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2704
	data_grads_norm = 3.0050
	new_data_grads_norm = 3.8049
	old_data_grads_norm = 3.9942
	sim_grads_norm_tr = 0.2737
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0506
	data_grads_norm = 2.2050
	new_data_grads_norm = 3.1521
	old_data_grads_norm = 2.8507
	sim_grads_norm_tr = -0.0074
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9182
	data_grads_norm = 2.1866
	new_data_grads_norm = 3.6297
	old_data_grads_norm = 3.2678
	sim_grads_norm_tr = -0.0812
-- Starting training on experience 203 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3340
	data_grads_norm = 2.7442
	new_data_grads_norm = 4.3301
	old_data_grads_norm = 3.9194
	sim_grads_norm_tr = 0.0669
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9100
	data_grads_norm = 2.2416
	new_data_grads_norm = 4.3844
	old_data_grads_norm = 2.9766
	sim_grads_norm_tr = -0.0153
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0196
	data_grads_norm = 2.7241
	new_data_grads_norm = 4.7863
	old_data_grads_norm = 3.3742
	sim_grads_norm_tr = 0.1207
-- Starting training on experience 204 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0014
	data_grads_norm = 2.4788
	new_data_grads_norm = 4.8761
	old_data_grads_norm = 3.1608
	sim_grads_norm_tr = -0.0520
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3494
	data_grads_norm = 3.8203
	new_data_grads_norm = 4.9927
	old_data_grads_norm = 4.4754
	sim_grads_norm_tr = 0.3668
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4584
	data_grads_norm = 3.5567
	new_data_grads_norm = 5.1165
	old_data_grads_norm = 4.6992
	sim_grads_norm_tr = 0.0328
-- Starting training on experience 205 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9965
	data_grads_norm = 2.5460
	new_data_grads_norm = 4.8936
	old_data_grads_norm = 4.0406
	sim_grads_norm_tr = -0.1366
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3862
	data_grads_norm = 3.8952
	new_data_grads_norm = 5.6716
	old_data_grads_norm = 4.9930
	sim_grads_norm_tr = 0.0753
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9858
	data_grads_norm = 2.7976
	new_data_grads_norm = 4.6847
	old_data_grads_norm = 2.7389
	sim_grads_norm_tr = 0.0713
-- Starting training on experience 206 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3716
	data_grads_norm = 3.3629
	new_data_grads_norm = 4.6209
	old_data_grads_norm = 4.2760
	sim_grads_norm_tr = 0.3214
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4084
	data_grads_norm = 3.8934
	new_data_grads_norm = 3.9034
	old_data_grads_norm = 5.8783
	sim_grads_norm_tr = 0.3930
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9949
	data_grads_norm = 2.8722
	new_data_grads_norm = 2.6302
	old_data_grads_norm = 4.3425
	sim_grads_norm_tr = 0.2175
-- Starting training on experience 207 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3309
	data_grads_norm = 2.9217
	new_data_grads_norm = 6.1585
	old_data_grads_norm = 3.3391
	sim_grads_norm_tr = -0.0396
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2958
	data_grads_norm = 2.9932
	new_data_grads_norm = 5.6039
	old_data_grads_norm = 3.3708
	sim_grads_norm_tr = 0.0868
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2495
	data_grads_norm = 3.0577
	new_data_grads_norm = 5.5328
	old_data_grads_norm = 2.6335
	sim_grads_norm_tr = 0.1033
-- Starting training on experience 208 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1501
	data_grads_norm = 2.7271
	new_data_grads_norm = 3.4755
	old_data_grads_norm = 4.6491
	sim_grads_norm_tr = 0.1015
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9630
	data_grads_norm = 1.9643
	new_data_grads_norm = 3.5724
	old_data_grads_norm = 2.9029
	sim_grads_norm_tr = -0.0859
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2430
	data_grads_norm = 2.9145
	new_data_grads_norm = 3.6838
	old_data_grads_norm = 4.6726
	sim_grads_norm_tr = 0.0680
-- Starting training on experience 209 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8487
	data_grads_norm = 2.2425
	new_data_grads_norm = 3.5755
	old_data_grads_norm = 3.3225
	sim_grads_norm_tr = -0.2108
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3096
	data_grads_norm = 3.9521
	new_data_grads_norm = 5.3857
	old_data_grads_norm = 3.0608
	sim_grads_norm_tr = 0.3168
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3388
	data_grads_norm = 4.3651
	new_data_grads_norm = 4.5816
	old_data_grads_norm = 5.9764
	sim_grads_norm_tr = 0.4611
-- Starting training on experience 210 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7995
	data_grads_norm = 2.4198
	new_data_grads_norm = 4.4218
	old_data_grads_norm = 3.1749
	sim_grads_norm_tr = -0.1193
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8547
	data_grads_norm = 2.6020
	new_data_grads_norm = 5.7721
	old_data_grads_norm = 2.6960
	sim_grads_norm_tr = -0.0001
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2562
	data_grads_norm = 3.7382
	new_data_grads_norm = 6.2039
	old_data_grads_norm = 4.6019
	sim_grads_norm_tr = 0.1613
-- Starting training on experience 211 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0709
	data_grads_norm = 2.5338
	new_data_grads_norm = 3.7830
	old_data_grads_norm = 4.4045
	sim_grads_norm_tr = -0.1806
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4291
	data_grads_norm = 3.5417
	new_data_grads_norm = 4.7675
	old_data_grads_norm = 4.5725
	sim_grads_norm_tr = 0.1369
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0043
	data_grads_norm = 2.3766
	new_data_grads_norm = 4.6115
	old_data_grads_norm = 2.9445
	sim_grads_norm_tr = -0.0963
-- Starting training on experience 212 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9718
	data_grads_norm = 2.9423
	new_data_grads_norm = 3.5934
	old_data_grads_norm = 4.1102
	sim_grads_norm_tr = -0.0133
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8557
	data_grads_norm = 1.7402
	new_data_grads_norm = 2.8963
	old_data_grads_norm = 2.9792
	sim_grads_norm_tr = -0.1731
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8920
	data_grads_norm = 2.9435
	new_data_grads_norm = 3.7309
	old_data_grads_norm = 4.1618
	sim_grads_norm_tr = 0.2407
-- Starting training on experience 213 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2596
	data_grads_norm = 3.3031
	new_data_grads_norm = 3.0168
	old_data_grads_norm = 4.6814
	sim_grads_norm_tr = 0.3176
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2376
	data_grads_norm = 2.8105
	new_data_grads_norm = 2.5366
	old_data_grads_norm = 3.9136
	sim_grads_norm_tr = 0.1581
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9127
	data_grads_norm = 2.3548
	new_data_grads_norm = 2.2105
	old_data_grads_norm = 3.5851
	sim_grads_norm_tr = 0.0159
-- Starting training on experience 214 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8599
	data_grads_norm = 1.8792
	new_data_grads_norm = 3.3290
	old_data_grads_norm = 2.9370
	sim_grads_norm_tr = -0.2808
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8874
	data_grads_norm = 2.3116
	new_data_grads_norm = 3.4288
	old_data_grads_norm = 2.5225
	sim_grads_norm_tr = 0.2817
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1701
	data_grads_norm = 2.6446
	new_data_grads_norm = 3.1188
	old_data_grads_norm = 4.5848
	sim_grads_norm_tr = 0.1218
-- Starting training on experience 215 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0323
	data_grads_norm = 2.8859
	new_data_grads_norm = 4.5336
	old_data_grads_norm = 3.4244
	sim_grads_norm_tr = 0.2115
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9363
	data_grads_norm = 2.4185
	new_data_grads_norm = 4.1843
	old_data_grads_norm = 3.2985
	sim_grads_norm_tr = 0.0535
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9692
	data_grads_norm = 2.8750
	new_data_grads_norm = 4.1043
	old_data_grads_norm = 3.5923
	sim_grads_norm_tr = 0.2278
-- Starting training on experience 216 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0101
	data_grads_norm = 2.0745
	new_data_grads_norm = 3.3981
	old_data_grads_norm = 4.7361
	sim_grads_norm_tr = 0.0020
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0417
	data_grads_norm = 2.7640
	new_data_grads_norm = 3.8350
	old_data_grads_norm = 4.1775
	sim_grads_norm_tr = -0.0869
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0773
	data_grads_norm = 2.2827
	new_data_grads_norm = 3.3296
	old_data_grads_norm = 3.4381
	sim_grads_norm_tr = -0.0156
-- Starting training on experience 217 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9778
	data_grads_norm = 3.1664
	new_data_grads_norm = 2.9944
	old_data_grads_norm = 5.0199
	sim_grads_norm_tr = 0.0210
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0636
	data_grads_norm = 2.9149
	new_data_grads_norm = 3.5858
	old_data_grads_norm = 4.6276
	sim_grads_norm_tr = 0.2635
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8147
	data_grads_norm = 1.7783
	new_data_grads_norm = 3.0394
	old_data_grads_norm = 2.3809
	sim_grads_norm_tr = 0.1466
-- Starting training on experience 218 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3553
	data_grads_norm = 3.2293
	new_data_grads_norm = 3.8950
	old_data_grads_norm = 5.0825
	sim_grads_norm_tr = 0.2929
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8559
	data_grads_norm = 2.3219
	new_data_grads_norm = 3.9001
	old_data_grads_norm = 2.1323
	sim_grads_norm_tr = 0.2111
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9044
	data_grads_norm = 2.4066
	new_data_grads_norm = 3.6764
	old_data_grads_norm = 4.9701
	sim_grads_norm_tr = -0.2507
-- Starting training on experience 219 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2597
	data_grads_norm = 3.1106
	new_data_grads_norm = 4.6928
	old_data_grads_norm = 3.5194
	sim_grads_norm_tr = 0.2085
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0506
	data_grads_norm = 2.2762
	new_data_grads_norm = 3.9760
	old_data_grads_norm = 3.6976
	sim_grads_norm_tr = -0.1037
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5183
	data_grads_norm = 3.5103
	new_data_grads_norm = 4.6254
	old_data_grads_norm = 4.5734
	sim_grads_norm_tr = 0.1645
-- Starting training on experience 220 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8454
	data_grads_norm = 2.1821
	new_data_grads_norm = 3.7106
	old_data_grads_norm = 3.9558
	sim_grads_norm_tr = -0.0844
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8868
	data_grads_norm = 2.7957
	new_data_grads_norm = 4.3212
	old_data_grads_norm = 3.7427
	sim_grads_norm_tr = 0.0499
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7240
	data_grads_norm = 2.0246
	new_data_grads_norm = 4.3841
	old_data_grads_norm = 2.6799
	sim_grads_norm_tr = -0.0423
-- Starting training on experience 221 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3068
	data_grads_norm = 3.1100
	new_data_grads_norm = 4.8585
	old_data_grads_norm = 3.4498
	sim_grads_norm_tr = 0.0449
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7166
	data_grads_norm = 5.0515
	new_data_grads_norm = 5.5606
	old_data_grads_norm = 8.4650
	sim_grads_norm_tr = 0.2622
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9208
	data_grads_norm = 3.1887
	new_data_grads_norm = 4.4129
	old_data_grads_norm = 4.2682
	sim_grads_norm_tr = 0.0950
-- Starting training on experience 222 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3462
	data_grads_norm = 3.1420
	new_data_grads_norm = 4.5042
	old_data_grads_norm = 3.5372
	sim_grads_norm_tr = 0.2340
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9986
	data_grads_norm = 2.7807
	new_data_grads_norm = 4.1259
	old_data_grads_norm = 2.6157
	sim_grads_norm_tr = 0.4533
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7549
	data_grads_norm = 1.8246
	new_data_grads_norm = 3.9780
	old_data_grads_norm = 2.8195
	sim_grads_norm_tr = -0.1708
-- Starting training on experience 223 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7555
	data_grads_norm = 2.0466
	new_data_grads_norm = 4.2586
	old_data_grads_norm = 4.5902
	sim_grads_norm_tr = -0.1097
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9567
	data_grads_norm = 2.8212
	new_data_grads_norm = 4.5824
	old_data_grads_norm = 3.2774
	sim_grads_norm_tr = 0.2611
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.6843
	data_grads_norm = 2.5335
	new_data_grads_norm = 4.9873
	old_data_grads_norm = 3.3263
	sim_grads_norm_tr = 0.1827
-- Starting training on experience 224 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7851
	data_grads_norm = 2.4871
	new_data_grads_norm = 4.7055
	old_data_grads_norm = 4.9745
	sim_grads_norm_tr = 0.0616
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8190
	data_grads_norm = 3.3266
	new_data_grads_norm = 4.4640
	old_data_grads_norm = 6.5979
	sim_grads_norm_tr = 0.2128
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8937
	data_grads_norm = 3.6393
	new_data_grads_norm = 4.8777
	old_data_grads_norm = 4.0049
	sim_grads_norm_tr = 0.2547
-- Starting training on experience 225 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6774
	data_grads_norm = 4.8047
	new_data_grads_norm = 5.1237
	old_data_grads_norm = 6.3975
	sim_grads_norm_tr = 0.0514
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0282
	data_grads_norm = 2.5247
	new_data_grads_norm = 5.0486
	old_data_grads_norm = 2.9750
	sim_grads_norm_tr = 0.1540
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1768
	data_grads_norm = 3.2946
	new_data_grads_norm = 5.2611
	old_data_grads_norm = 3.6723
	sim_grads_norm_tr = 0.1223
-- Starting training on experience 226 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0213
	data_grads_norm = 3.2462
	new_data_grads_norm = 3.5946
	old_data_grads_norm = 5.0294
	sim_grads_norm_tr = 0.2032
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1819
	data_grads_norm = 3.2558
	new_data_grads_norm = 4.0517
	old_data_grads_norm = 6.0241
	sim_grads_norm_tr = -0.1386
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6168
	data_grads_norm = 4.6816
	new_data_grads_norm = 5.2463
	old_data_grads_norm = 6.5586
	sim_grads_norm_tr = 0.2806
-- Starting training on experience 227 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2632
	data_grads_norm = 3.3040
	new_data_grads_norm = 4.4880
	old_data_grads_norm = 4.7038
	sim_grads_norm_tr = -0.0560
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8851
	data_grads_norm = 2.6454
	new_data_grads_norm = 3.8911
	old_data_grads_norm = 4.0392
	sim_grads_norm_tr = 0.0916
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9838
	data_grads_norm = 2.2501
	new_data_grads_norm = 3.7413
	old_data_grads_norm = 3.0061
	sim_grads_norm_tr = 0.1504
-- Starting training on experience 228 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9200
	data_grads_norm = 2.0539
	new_data_grads_norm = 3.3047
	old_data_grads_norm = 3.2723
	sim_grads_norm_tr = -0.0387
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2614
	data_grads_norm = 2.6743
	new_data_grads_norm = 3.3379
	old_data_grads_norm = 4.3426
	sim_grads_norm_tr = 0.1090
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0869
	data_grads_norm = 1.9644
	new_data_grads_norm = 3.3194
	old_data_grads_norm = 2.7929
	sim_grads_norm_tr = 0.3200
-- Starting training on experience 229 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3204
	data_grads_norm = 2.6844
	new_data_grads_norm = 3.4767
	old_data_grads_norm = 4.4058
	sim_grads_norm_tr = -0.0296
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5502
	data_grads_norm = 3.9175
	new_data_grads_norm = 4.0063
	old_data_grads_norm = 4.8375
	sim_grads_norm_tr = 0.5261
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9810
	data_grads_norm = 2.0456
	new_data_grads_norm = 2.8113
	old_data_grads_norm = 3.5810
	sim_grads_norm_tr = 0.0636
-- Starting training on experience 230 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9241
	data_grads_norm = 2.5866
	new_data_grads_norm = 4.2666
	old_data_grads_norm = 2.2792
	sim_grads_norm_tr = 0.4270
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0269
	data_grads_norm = 3.1773
	new_data_grads_norm = 4.0783
	old_data_grads_norm = 3.6739
	sim_grads_norm_tr = 0.1231
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1782
	data_grads_norm = 3.1007
	new_data_grads_norm = 3.5911
	old_data_grads_norm = 4.2499
	sim_grads_norm_tr = 0.2605
-- Starting training on experience 231 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0624
	data_grads_norm = 2.2963
	new_data_grads_norm = 4.2454
	old_data_grads_norm = 2.6586
	sim_grads_norm_tr = -0.0280
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8346
	data_grads_norm = 2.4272
	new_data_grads_norm = 3.2477
	old_data_grads_norm = 3.5828
	sim_grads_norm_tr = 0.1216
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8900
	data_grads_norm = 2.1414
	new_data_grads_norm = 2.9245
	old_data_grads_norm = 2.7973
	sim_grads_norm_tr = 0.2341
-- Starting training on experience 232 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9945
	data_grads_norm = 3.6045
	new_data_grads_norm = 4.5534
	old_data_grads_norm = 3.9301
	sim_grads_norm_tr = 0.4257
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7940
	data_grads_norm = 1.8385
	new_data_grads_norm = 2.8758
	old_data_grads_norm = 3.3554
	sim_grads_norm_tr = -0.2606
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9632
	data_grads_norm = 3.0259
	new_data_grads_norm = 4.0154
	old_data_grads_norm = 4.3611
	sim_grads_norm_tr = -0.2847
-- Starting training on experience 233 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8142
	data_grads_norm = 1.8367
	new_data_grads_norm = 4.0886
	old_data_grads_norm = 1.8915
	sim_grads_norm_tr = -0.0361
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9637
	data_grads_norm = 3.3375
	new_data_grads_norm = 4.5324
	old_data_grads_norm = 4.0175
	sim_grads_norm_tr = 0.3298
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7738
	data_grads_norm = 2.0275
	new_data_grads_norm = 4.1771
	old_data_grads_norm = 2.9542
	sim_grads_norm_tr = 0.1021
-- Starting training on experience 234 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9914
	data_grads_norm = 3.4621
	new_data_grads_norm = 5.0163
	old_data_grads_norm = 6.3761
	sim_grads_norm_tr = 0.1036
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1549
	data_grads_norm = 2.9593
	new_data_grads_norm = 6.0597
	old_data_grads_norm = 4.1628
	sim_grads_norm_tr = 0.2596
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8843
	data_grads_norm = 2.0133
	new_data_grads_norm = 6.1075
	old_data_grads_norm = 3.3465
	sim_grads_norm_tr = -0.0559
-- Starting training on experience 235 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4809
	data_grads_norm = 4.2106
	new_data_grads_norm = 7.0581
	old_data_grads_norm = 3.5098
	sim_grads_norm_tr = 0.0675
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4535
	data_grads_norm = 4.0539
	new_data_grads_norm = 6.3680
	old_data_grads_norm = 3.6832
	sim_grads_norm_tr = -0.0667
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3810
	data_grads_norm = 4.2266
	new_data_grads_norm = 7.2005
	old_data_grads_norm = 3.4578
	sim_grads_norm_tr = 0.3403
-- Starting training on experience 236 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.5942
	data_grads_norm = 1.4514
	new_data_grads_norm = 2.3899
	old_data_grads_norm = 2.0501
	sim_grads_norm_tr = 0.0775
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9002
	data_grads_norm = 2.3613
	new_data_grads_norm = 2.6019
	old_data_grads_norm = 3.6618
	sim_grads_norm_tr = 0.0488
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1198
	data_grads_norm = 2.7103
	new_data_grads_norm = 2.9088
	old_data_grads_norm = 4.0484
	sim_grads_norm_tr = 0.2858
-- Starting training on experience 237 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
-- >> End of training phase << --
-- >> Start of eval phase << --
-- Starting eval on experience 0 (Task 0) from test stream --
> Eval on experience 0 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp000 = 1.1281
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.5220
	mb_index = 238
	time = 44.4441
-- >> End of eval phase << --
	CumulativeAccuracy/eval_phase/test_stream/Exp000 = 0.5220
	Loss_Stream/eval_phase/test_stream/Task000 = 1.1281
	Top1_Acc_Stream/eval_phase/test_stream/Task000 = 0.5220
-- >> Start of training phase << --
-- Starting training on experience 0 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2545
	data_grads_norm = 3.1092
	new_data_grads_norm = 5.5218
	old_data_grads_norm = 4.7569
	sim_grads_norm_tr = -0.1607
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1096
	data_grads_norm = 3.2822
	new_data_grads_norm = 6.0063
	old_data_grads_norm = 3.1022
	sim_grads_norm_tr = -0.1250
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3889
	data_grads_norm = 3.2879
	new_data_grads_norm = 6.2444
	old_data_grads_norm = 3.7851
	sim_grads_norm_tr = -0.0424
-- Starting training on experience 1 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3789
	data_grads_norm = 2.8457
	new_data_grads_norm = 5.4752
	old_data_grads_norm = 3.8183
	sim_grads_norm_tr = -0.1094
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4604
	data_grads_norm = 4.3597
	new_data_grads_norm = 6.4290
	old_data_grads_norm = 6.2182
	sim_grads_norm_tr = -0.0818
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2331
	data_grads_norm = 3.1475
	new_data_grads_norm = 6.8263
	old_data_grads_norm = 2.1043
	sim_grads_norm_tr = -0.1274
-- Starting training on experience 2 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9222
	data_grads_norm = 5.4366
	new_data_grads_norm = 6.7933
	old_data_grads_norm = 6.3924
	sim_grads_norm_tr = 0.1384
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2925
	data_grads_norm = 3.2900
	new_data_grads_norm = 5.8540
	old_data_grads_norm = 3.4985
	sim_grads_norm_tr = -0.1240
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3399
	data_grads_norm = 3.4079
	new_data_grads_norm = 6.4600
	old_data_grads_norm = 3.3812
	sim_grads_norm_tr = 0.0243
-- Starting training on experience 3 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5662
	data_grads_norm = 3.6737
	new_data_grads_norm = 6.3560
	old_data_grads_norm = 3.5573
	sim_grads_norm_tr = 0.1477
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5801
	data_grads_norm = 3.9000
	new_data_grads_norm = 5.9696
	old_data_grads_norm = 4.8919
	sim_grads_norm_tr = 0.0734
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2817
	data_grads_norm = 3.1722
	new_data_grads_norm = 5.7176
	old_data_grads_norm = 3.5800
	sim_grads_norm_tr = -0.1411
-- Starting training on experience 4 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6556
	data_grads_norm = 4.0212
	new_data_grads_norm = 7.1356
	old_data_grads_norm = 3.9632
	sim_grads_norm_tr = -0.1461
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7695
	data_grads_norm = 4.6835
	new_data_grads_norm = 8.1875
	old_data_grads_norm = 5.2666
	sim_grads_norm_tr = 0.0236
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4710
	data_grads_norm = 4.1288
	new_data_grads_norm = 8.8214
	old_data_grads_norm = 3.5804
	sim_grads_norm_tr = -0.1431
-- Starting training on experience 5 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3630
	data_grads_norm = 6.4408
	new_data_grads_norm = 10.4480
	old_data_grads_norm = 6.9907
	sim_grads_norm_tr = 0.1910
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5174
	data_grads_norm = 4.1914
	new_data_grads_norm = 8.0190
	old_data_grads_norm = 2.8254
	sim_grads_norm_tr = -0.1761
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7335
	data_grads_norm = 6.5267
	new_data_grads_norm = 8.4019
	old_data_grads_norm = 5.6226
	sim_grads_norm_tr = 0.2499
-- Starting training on experience 6 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6006
	data_grads_norm = 3.9796
	new_data_grads_norm = 7.3564
	old_data_grads_norm = 3.6696
	sim_grads_norm_tr = 0.0955
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4716
	data_grads_norm = 3.8052
	new_data_grads_norm = 7.3372
	old_data_grads_norm = 3.4240
	sim_grads_norm_tr = 0.1515
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8483
	data_grads_norm = 4.4905
	new_data_grads_norm = 6.7696
	old_data_grads_norm = 5.2439
	sim_grads_norm_tr = 0.1770
-- Starting training on experience 7 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3205
	data_grads_norm = 4.1137
	new_data_grads_norm = 5.6264
	old_data_grads_norm = 5.9335
	sim_grads_norm_tr = -0.0373
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7903
	data_grads_norm = 4.1206
	new_data_grads_norm = 6.3393
	old_data_grads_norm = 4.4458
	sim_grads_norm_tr = 0.0115
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2387
	data_grads_norm = 4.9855
	new_data_grads_norm = 6.0829
	old_data_grads_norm = 6.6576
	sim_grads_norm_tr = 0.2687
-- Starting training on experience 8 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6443
	data_grads_norm = 3.6216
	new_data_grads_norm = 5.2990
	old_data_grads_norm = 5.1145
	sim_grads_norm_tr = -0.0227
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9559
	data_grads_norm = 3.6545
	new_data_grads_norm = 5.4144
	old_data_grads_norm = 4.9293
	sim_grads_norm_tr = 0.1314
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6790
	data_grads_norm = 3.1091
	new_data_grads_norm = 5.0660
	old_data_grads_norm = 3.3183
	sim_grads_norm_tr = 0.0894
-- Starting training on experience 9 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4168
	data_grads_norm = 3.1553
	new_data_grads_norm = 5.7917
	old_data_grads_norm = 3.5183
	sim_grads_norm_tr = -0.0649
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3689
	data_grads_norm = 3.1212
	new_data_grads_norm = 5.7605
	old_data_grads_norm = 3.0950
	sim_grads_norm_tr = -0.0608
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4597
	data_grads_norm = 3.4018
	new_data_grads_norm = 6.1120
	old_data_grads_norm = 3.1182
	sim_grads_norm_tr = -0.2135
-- Starting training on experience 10 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6240
	data_grads_norm = 3.6335
	new_data_grads_norm = 6.6212
	old_data_grads_norm = 3.2895
	sim_grads_norm_tr = -0.0356
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9607
	data_grads_norm = 4.3073
	new_data_grads_norm = 7.0468
	old_data_grads_norm = 4.1199
	sim_grads_norm_tr = 0.1320
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8230
	data_grads_norm = 3.9481
	new_data_grads_norm = 7.7019
	old_data_grads_norm = 4.2333
	sim_grads_norm_tr = 0.0982
-- Starting training on experience 11 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0882
	data_grads_norm = 4.3247
	new_data_grads_norm = 7.0537
	old_data_grads_norm = 4.1654
	sim_grads_norm_tr = 0.1172
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6596
	data_grads_norm = 3.2826
	new_data_grads_norm = 6.3189
	old_data_grads_norm = 2.7394
	sim_grads_norm_tr = -0.1250
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9360
	data_grads_norm = 3.7977
	new_data_grads_norm = 6.7534
	old_data_grads_norm = 3.3477
	sim_grads_norm_tr = -0.0415
-- Starting training on experience 12 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9039
	data_grads_norm = 4.6965
	new_data_grads_norm = 7.4846
	old_data_grads_norm = 4.1441
	sim_grads_norm_tr = 0.1142
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7261
	data_grads_norm = 4.2126
	new_data_grads_norm = 8.0020
	old_data_grads_norm = 3.8467
	sim_grads_norm_tr = -0.0295
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9466
	data_grads_norm = 5.4195
	new_data_grads_norm = 7.3846
	old_data_grads_norm = 4.3555
	sim_grads_norm_tr = 0.0657
-- Starting training on experience 13 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1564
	data_grads_norm = 4.8316
	new_data_grads_norm = 7.9412
	old_data_grads_norm = 3.7284
	sim_grads_norm_tr = 0.1305
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6315
	data_grads_norm = 4.1508
	new_data_grads_norm = 7.6107
	old_data_grads_norm = 3.0570
	sim_grads_norm_tr = -0.0118
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2879
	data_grads_norm = 5.4820
	new_data_grads_norm = 8.0546
	old_data_grads_norm = 5.4883
	sim_grads_norm_tr = 0.2566
-- Starting training on experience 14 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5010
	data_grads_norm = 3.7431
	new_data_grads_norm = 6.7062
	old_data_grads_norm = 4.9777
	sim_grads_norm_tr = -0.0946
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7051
	data_grads_norm = 3.7492
	new_data_grads_norm = 7.2176
	old_data_grads_norm = 2.5912
	sim_grads_norm_tr = -0.0846
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5595
	data_grads_norm = 4.4208
	new_data_grads_norm = 6.4442
	old_data_grads_norm = 4.4310
	sim_grads_norm_tr = 0.3584
-- Starting training on experience 15 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7370
	data_grads_norm = 3.5185
	new_data_grads_norm = 6.1646
	old_data_grads_norm = 4.7986
	sim_grads_norm_tr = 0.1579
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3824
	data_grads_norm = 3.4692
	new_data_grads_norm = 5.6973
	old_data_grads_norm = 4.0018
	sim_grads_norm_tr = -0.1281
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7492
	data_grads_norm = 3.6483
	new_data_grads_norm = 5.7711
	old_data_grads_norm = 3.6005
	sim_grads_norm_tr = 0.1616
-- Starting training on experience 16 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4494
	data_grads_norm = 3.0391
	new_data_grads_norm = 4.8246
	old_data_grads_norm = 4.3200
	sim_grads_norm_tr = 0.1140
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8334
	data_grads_norm = 3.3363
	new_data_grads_norm = 4.8275
	old_data_grads_norm = 3.6430
	sim_grads_norm_tr = 0.1803
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0029
	data_grads_norm = 3.8261
	new_data_grads_norm = 4.2900
	old_data_grads_norm = 4.2234
	sim_grads_norm_tr = 0.4585
-- Starting training on experience 17 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1421
	data_grads_norm = 2.4075
	new_data_grads_norm = 4.2066
	old_data_grads_norm = 2.9808
	sim_grads_norm_tr = -0.0327
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3059
	data_grads_norm = 2.6880
	new_data_grads_norm = 4.4764
	old_data_grads_norm = 4.0129
	sim_grads_norm_tr = 0.1585
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1183
	data_grads_norm = 2.7839
	new_data_grads_norm = 4.2583
	old_data_grads_norm = 3.0854
	sim_grads_norm_tr = 0.1480
-- Starting training on experience 18 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0520
	data_grads_norm = 4.1745
	new_data_grads_norm = 5.2776
	old_data_grads_norm = 5.6712
	sim_grads_norm_tr = 0.3528
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1651
	data_grads_norm = 2.6402
	new_data_grads_norm = 4.4443
	old_data_grads_norm = 3.5337
	sim_grads_norm_tr = -0.0803
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1835
	data_grads_norm = 2.8138
	new_data_grads_norm = 4.7226
	old_data_grads_norm = 3.5974
	sim_grads_norm_tr = -0.1519
-- Starting training on experience 19 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0909
	data_grads_norm = 2.5834
	new_data_grads_norm = 6.1770
	old_data_grads_norm = 3.5608
	sim_grads_norm_tr = -0.0566
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1357
	data_grads_norm = 2.7379
	new_data_grads_norm = 6.2062
	old_data_grads_norm = 3.0741
	sim_grads_norm_tr = -0.0939
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1365
	data_grads_norm = 2.9710
	new_data_grads_norm = 6.6028
	old_data_grads_norm = 3.7897
	sim_grads_norm_tr = 0.0071
-- Starting training on experience 20 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5023
	data_grads_norm = 3.9592
	new_data_grads_norm = 6.2093
	old_data_grads_norm = 3.9929
	sim_grads_norm_tr = 0.1379
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3349
	data_grads_norm = 3.7376
	new_data_grads_norm = 6.1743
	old_data_grads_norm = 4.4516
	sim_grads_norm_tr = 0.0817
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1183
	data_grads_norm = 3.0101
	new_data_grads_norm = 5.7034
	old_data_grads_norm = 2.6326
	sim_grads_norm_tr = -0.2398
-- Starting training on experience 21 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5717
	data_grads_norm = 3.7521
	new_data_grads_norm = 6.0798
	old_data_grads_norm = 3.7641
	sim_grads_norm_tr = 0.1397
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0370
	data_grads_norm = 4.3208
	new_data_grads_norm = 5.6399
	old_data_grads_norm = 4.7695
	sim_grads_norm_tr = 0.2271
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1111
	data_grads_norm = 2.6119
	new_data_grads_norm = 4.7257
	old_data_grads_norm = 3.0782
	sim_grads_norm_tr = -0.0195
-- Starting training on experience 22 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1925
	data_grads_norm = 3.3227
	new_data_grads_norm = 5.3419
	old_data_grads_norm = 3.5912
	sim_grads_norm_tr = 0.3044
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8763
	data_grads_norm = 2.9224
	new_data_grads_norm = 4.9637
	old_data_grads_norm = 4.3474
	sim_grads_norm_tr = -0.0519
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3083
	data_grads_norm = 3.2341
	new_data_grads_norm = 5.0113
	old_data_grads_norm = 2.6787
	sim_grads_norm_tr = 0.1749
-- Starting training on experience 23 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2758
	data_grads_norm = 2.6707
	new_data_grads_norm = 5.0943
	old_data_grads_norm = 2.2573
	sim_grads_norm_tr = 0.2055
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5363
	data_grads_norm = 2.7960
	new_data_grads_norm = 4.7740
	old_data_grads_norm = 3.2416
	sim_grads_norm_tr = 0.1302
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4015
	data_grads_norm = 3.2649
	new_data_grads_norm = 4.8119
	old_data_grads_norm = 4.4473
	sim_grads_norm_tr = 0.3395
-- Starting training on experience 24 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9294
	data_grads_norm = 3.3161
	new_data_grads_norm = 4.9779
	old_data_grads_norm = 4.2139
	sim_grads_norm_tr = -0.0695
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9645
	data_grads_norm = 2.8229
	new_data_grads_norm = 5.5779
	old_data_grads_norm = 2.7952
	sim_grads_norm_tr = -0.0849
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0436
	data_grads_norm = 3.1208
	new_data_grads_norm = 5.8230
	old_data_grads_norm = 3.3309
	sim_grads_norm_tr = -0.0861
-- Starting training on experience 25 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3571
	data_grads_norm = 2.8812
	new_data_grads_norm = 4.9480
	old_data_grads_norm = 2.9234
	sim_grads_norm_tr = -0.0651
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0545
	data_grads_norm = 2.6390
	new_data_grads_norm = 6.1714
	old_data_grads_norm = 2.9885
	sim_grads_norm_tr = -0.1819
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2481
	data_grads_norm = 3.1488
	new_data_grads_norm = 5.8312
	old_data_grads_norm = 2.9201
	sim_grads_norm_tr = -0.0034
-- Starting training on experience 26 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8874
	data_grads_norm = 2.2588
	new_data_grads_norm = 4.7899
	old_data_grads_norm = 3.1009
	sim_grads_norm_tr = -0.1698
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4953
	data_grads_norm = 3.4521
	new_data_grads_norm = 5.5753
	old_data_grads_norm = 4.8137
	sim_grads_norm_tr = 0.0829
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2508
	data_grads_norm = 2.9588
	new_data_grads_norm = 5.1486
	old_data_grads_norm = 4.2057
	sim_grads_norm_tr = 0.0433
-- Starting training on experience 27 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9900
	data_grads_norm = 2.6304
	new_data_grads_norm = 5.1705
	old_data_grads_norm = 2.7561
	sim_grads_norm_tr = -0.1762
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2031
	data_grads_norm = 3.2462
	new_data_grads_norm = 5.3627
	old_data_grads_norm = 3.3303
	sim_grads_norm_tr = 0.2311
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2180
	data_grads_norm = 3.2159
	new_data_grads_norm = 5.4215
	old_data_grads_norm = 3.1365
	sim_grads_norm_tr = 0.1555
-- Starting training on experience 28 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3183
	data_grads_norm = 4.0295
	new_data_grads_norm = 4.8518
	old_data_grads_norm = 5.6569
	sim_grads_norm_tr = 0.1200
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0174
	data_grads_norm = 3.0395
	new_data_grads_norm = 5.2228
	old_data_grads_norm = 3.1540
	sim_grads_norm_tr = -0.0739
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1664
	data_grads_norm = 3.3314
	new_data_grads_norm = 5.0413
	old_data_grads_norm = 3.5413
	sim_grads_norm_tr = 0.2404
-- Starting training on experience 29 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9644
	data_grads_norm = 3.3655
	new_data_grads_norm = 6.8123
	old_data_grads_norm = 3.9585
	sim_grads_norm_tr = -0.0542
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1037
	data_grads_norm = 5.1983
	new_data_grads_norm = 8.0887
	old_data_grads_norm = 3.4429
	sim_grads_norm_tr = 0.1680
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8155
	data_grads_norm = 2.3884
	new_data_grads_norm = 4.6927
	old_data_grads_norm = 3.0234
	sim_grads_norm_tr = -0.0759
-- Starting training on experience 30 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8388
	data_grads_norm = 3.3122
	new_data_grads_norm = 7.0075
	old_data_grads_norm = 3.7161
	sim_grads_norm_tr = -0.0681
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6589
	data_grads_norm = 5.3019
	new_data_grads_norm = 8.1365
	old_data_grads_norm = 5.6189
	sim_grads_norm_tr = 0.3546
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3919
	data_grads_norm = 3.9160
	new_data_grads_norm = 6.4619
	old_data_grads_norm = 3.9339
	sim_grads_norm_tr = 0.1866
-- Starting training on experience 31 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1404
	data_grads_norm = 2.9942
	new_data_grads_norm = 5.0761
	old_data_grads_norm = 3.7487
	sim_grads_norm_tr = 0.0951
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1989
	data_grads_norm = 3.1850
	new_data_grads_norm = 5.1462
	old_data_grads_norm = 4.8083
	sim_grads_norm_tr = 0.2346
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9384
	data_grads_norm = 2.7007
	new_data_grads_norm = 4.5795
	old_data_grads_norm = 2.6327
	sim_grads_norm_tr = 0.0956
-- Starting training on experience 32 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8458
	data_grads_norm = 2.8616
	new_data_grads_norm = 4.5848
	old_data_grads_norm = 3.5828
	sim_grads_norm_tr = 0.0199
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3028
	data_grads_norm = 3.4555
	new_data_grads_norm = 4.5397
	old_data_grads_norm = 4.2227
	sim_grads_norm_tr = 0.1561
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0228
	data_grads_norm = 3.8186
	new_data_grads_norm = 4.9459
	old_data_grads_norm = 5.5142
	sim_grads_norm_tr = 0.0999
-- Starting training on experience 33 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1134
	data_grads_norm = 3.2720
	new_data_grads_norm = 5.7093
	old_data_grads_norm = 3.4582
	sim_grads_norm_tr = 0.1300
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1526
	data_grads_norm = 3.3942
	new_data_grads_norm = 6.0566
	old_data_grads_norm = 3.8083
	sim_grads_norm_tr = -0.0243
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1386
	data_grads_norm = 3.6344
	new_data_grads_norm = 6.6289
	old_data_grads_norm = 3.8769
	sim_grads_norm_tr = 0.2565
-- Starting training on experience 34 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8515
	data_grads_norm = 2.6725
	new_data_grads_norm = 4.4534
	old_data_grads_norm = 3.7804
	sim_grads_norm_tr = -0.0642
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9150
	data_grads_norm = 3.1102
	new_data_grads_norm = 5.4186
	old_data_grads_norm = 3.2761
	sim_grads_norm_tr = 0.2098
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0148
	data_grads_norm = 2.7878
	new_data_grads_norm = 4.9249
	old_data_grads_norm = 4.2704
	sim_grads_norm_tr = -0.0820
-- Starting training on experience 35 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3911
	data_grads_norm = 2.5339
	new_data_grads_norm = 4.7632
	old_data_grads_norm = 4.6097
	sim_grads_norm_tr = -0.0605
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9548
	data_grads_norm = 3.4354
	new_data_grads_norm = 5.4855
	old_data_grads_norm = 3.5534
	sim_grads_norm_tr = 0.1460
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9598
	data_grads_norm = 3.1100
	new_data_grads_norm = 5.0471
	old_data_grads_norm = 3.5049
	sim_grads_norm_tr = 0.3694
-- Starting training on experience 36 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5437
	data_grads_norm = 2.3231
	new_data_grads_norm = 4.4844
	old_data_grads_norm = 3.0590
	sim_grads_norm_tr = -0.0606
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9967
	data_grads_norm = 3.0855
	new_data_grads_norm = 4.6362
	old_data_grads_norm = 4.0017
	sim_grads_norm_tr = 0.0276
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6835
	data_grads_norm = 2.5472
	new_data_grads_norm = 5.5148
	old_data_grads_norm = 1.9173
	sim_grads_norm_tr = 0.0766
-- Starting training on experience 37 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8474
	data_grads_norm = 3.6975
	new_data_grads_norm = 5.8055
	old_data_grads_norm = 5.5439
	sim_grads_norm_tr = -0.0628
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8572
	data_grads_norm = 2.3404
	new_data_grads_norm = 6.1548
	old_data_grads_norm = 2.4392
	sim_grads_norm_tr = 0.0061
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3288
	data_grads_norm = 3.6864
	new_data_grads_norm = 6.3786
	old_data_grads_norm = 4.5356
	sim_grads_norm_tr = -0.0065
-- Starting training on experience 38 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8053
	data_grads_norm = 2.6405
	new_data_grads_norm = 4.7983
	old_data_grads_norm = 2.9111
	sim_grads_norm_tr = -0.0532
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2298
	data_grads_norm = 3.2912
	new_data_grads_norm = 5.2303
	old_data_grads_norm = 4.1400
	sim_grads_norm_tr = 0.0734
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1767
	data_grads_norm = 3.4531
	new_data_grads_norm = 5.3482
	old_data_grads_norm = 4.9490
	sim_grads_norm_tr = 0.0439
-- Starting training on experience 39 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9764
	data_grads_norm = 3.9372
	new_data_grads_norm = 6.3435
	old_data_grads_norm = 3.5238
	sim_grads_norm_tr = 0.0932
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8938
	data_grads_norm = 3.3371
	new_data_grads_norm = 6.1215
	old_data_grads_norm = 4.8661
	sim_grads_norm_tr = -0.0310
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9639
	data_grads_norm = 3.9490
	new_data_grads_norm = 6.1857
	old_data_grads_norm = 4.9918
	sim_grads_norm_tr = 0.1930
-- Starting training on experience 40 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7237
	data_grads_norm = 2.4396
	new_data_grads_norm = 4.0033
	old_data_grads_norm = 2.5147
	sim_grads_norm_tr = -0.1498
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2387
	data_grads_norm = 4.5073
	new_data_grads_norm = 4.1812
	old_data_grads_norm = 4.7810
	sim_grads_norm_tr = 0.0830
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4938
	data_grads_norm = 2.2252
	new_data_grads_norm = 5.0011
	old_data_grads_norm = 2.8052
	sim_grads_norm_tr = -0.3235
-- Starting training on experience 41 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6765
	data_grads_norm = 2.7836
	new_data_grads_norm = 5.5648
	old_data_grads_norm = 4.0595
	sim_grads_norm_tr = -0.0417
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8193
	data_grads_norm = 3.7232
	new_data_grads_norm = 5.1575
	old_data_grads_norm = 4.4726
	sim_grads_norm_tr = 0.2037
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9200
	data_grads_norm = 3.7769
	new_data_grads_norm = 5.1655
	old_data_grads_norm = 5.2556
	sim_grads_norm_tr = 0.2731
-- Starting training on experience 42 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7919
	data_grads_norm = 3.3140
	new_data_grads_norm = 4.4286
	old_data_grads_norm = 5.2686
	sim_grads_norm_tr = 0.1081
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8344
	data_grads_norm = 2.6663
	new_data_grads_norm = 4.5909
	old_data_grads_norm = 3.4160
	sim_grads_norm_tr = 0.1534
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7009
	data_grads_norm = 2.4821
	new_data_grads_norm = 4.1654
	old_data_grads_norm = 5.0731
	sim_grads_norm_tr = -0.3022
-- Starting training on experience 43 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3480
	data_grads_norm = 5.4762
	new_data_grads_norm = 6.8290
	old_data_grads_norm = 5.9303
	sim_grads_norm_tr = 0.2810
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4501
	data_grads_norm = 5.0122
	new_data_grads_norm = 6.5651
	old_data_grads_norm = 4.6109
	sim_grads_norm_tr = 0.0982
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0602
	data_grads_norm = 4.0690
	new_data_grads_norm = 6.3682
	old_data_grads_norm = 3.9107
	sim_grads_norm_tr = 0.0283
-- Starting training on experience 44 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0057
	data_grads_norm = 3.8020
	new_data_grads_norm = 5.0835
	old_data_grads_norm = 4.5959
	sim_grads_norm_tr = 0.0594
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5217
	data_grads_norm = 5.1833
	new_data_grads_norm = 6.1286
	old_data_grads_norm = 5.1073
	sim_grads_norm_tr = 0.1697
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9293
	data_grads_norm = 3.4293
	new_data_grads_norm = 4.6419
	old_data_grads_norm = 4.1232
	sim_grads_norm_tr = 0.1433
-- Starting training on experience 45 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9724
	data_grads_norm = 3.2269
	new_data_grads_norm = 5.1668
	old_data_grads_norm = 4.1886
	sim_grads_norm_tr = 0.1728
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8747
	data_grads_norm = 2.9566
	new_data_grads_norm = 4.8659
	old_data_grads_norm = 3.4467
	sim_grads_norm_tr = 0.1859
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8135
	data_grads_norm = 3.3215
	new_data_grads_norm = 4.7510
	old_data_grads_norm = 4.0022
	sim_grads_norm_tr = 0.1112
-- Starting training on experience 46 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5762
	data_grads_norm = 5.1593
	new_data_grads_norm = 7.2689
	old_data_grads_norm = 4.9566
	sim_grads_norm_tr = 0.4047
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5277
	data_grads_norm = 2.7663
	new_data_grads_norm = 6.0356
	old_data_grads_norm = 3.2249
	sim_grads_norm_tr = -0.0778
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4967
	data_grads_norm = 3.1287
	new_data_grads_norm = 6.8552
	old_data_grads_norm = 3.8936
	sim_grads_norm_tr = -0.1483
-- Starting training on experience 47 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2715
	data_grads_norm = 3.8648
	new_data_grads_norm = 5.6946
	old_data_grads_norm = 5.8882
	sim_grads_norm_tr = 0.0652
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2648
	data_grads_norm = 3.2056
	new_data_grads_norm = 5.1658
	old_data_grads_norm = 3.9868
	sim_grads_norm_tr = -0.1316
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2895
	data_grads_norm = 3.3212
	new_data_grads_norm = 5.5311
	old_data_grads_norm = 3.3343
	sim_grads_norm_tr = 0.1040
-- Starting training on experience 48 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9227
	data_grads_norm = 3.0738
	new_data_grads_norm = 4.7076
	old_data_grads_norm = 4.1363
	sim_grads_norm_tr = 0.0689
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1097
	data_grads_norm = 3.1634
	new_data_grads_norm = 4.2154
	old_data_grads_norm = 3.9079
	sim_grads_norm_tr = 0.0735
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0770
	data_grads_norm = 3.3064
	new_data_grads_norm = 4.9273
	old_data_grads_norm = 5.0330
	sim_grads_norm_tr = 0.1543
-- Starting training on experience 49 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5913
	data_grads_norm = 2.3309
	new_data_grads_norm = 4.0793
	old_data_grads_norm = 3.1545
	sim_grads_norm_tr = 0.1017
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8229
	data_grads_norm = 2.5934
	new_data_grads_norm = 4.9017
	old_data_grads_norm = 2.9925
	sim_grads_norm_tr = -0.0177
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7637
	data_grads_norm = 2.4422
	new_data_grads_norm = 4.6697
	old_data_grads_norm = 4.4772
	sim_grads_norm_tr = -0.1878
-- Starting training on experience 50 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7911
	data_grads_norm = 2.8589
	new_data_grads_norm = 5.9820
	old_data_grads_norm = 3.2249
	sim_grads_norm_tr = -0.2155
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2058
	data_grads_norm = 4.3073
	new_data_grads_norm = 6.6516
	old_data_grads_norm = 4.7003
	sim_grads_norm_tr = 0.1147
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7984
	data_grads_norm = 2.3528
	new_data_grads_norm = 6.1050
	old_data_grads_norm = 2.2708
	sim_grads_norm_tr = 0.0004
-- Starting training on experience 51 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6976
	data_grads_norm = 2.4737
	new_data_grads_norm = 4.9699
	old_data_grads_norm = 3.9332
	sim_grads_norm_tr = -0.0412
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8176
	data_grads_norm = 2.5946
	new_data_grads_norm = 4.9498
	old_data_grads_norm = 4.0901
	sim_grads_norm_tr = 0.1555
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9417
	data_grads_norm = 3.5666
	new_data_grads_norm = 5.2653
	old_data_grads_norm = 4.4539
	sim_grads_norm_tr = -0.1643
-- Starting training on experience 52 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1252
	data_grads_norm = 2.8594
	new_data_grads_norm = 4.2550
	old_data_grads_norm = 3.8206
	sim_grads_norm_tr = 0.0402
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0085
	data_grads_norm = 2.7821
	new_data_grads_norm = 4.4496
	old_data_grads_norm = 5.8351
	sim_grads_norm_tr = -0.0243
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5213
	data_grads_norm = 4.3506
	new_data_grads_norm = 5.4429
	old_data_grads_norm = 3.3873
	sim_grads_norm_tr = 0.3485
-- Starting training on experience 53 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1949
	data_grads_norm = 3.5155
	new_data_grads_norm = 4.9985
	old_data_grads_norm = 3.6038
	sim_grads_norm_tr = 0.1512
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7716
	data_grads_norm = 2.7316
	new_data_grads_norm = 4.5442
	old_data_grads_norm = 3.3787
	sim_grads_norm_tr = -0.1048
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1637
	data_grads_norm = 2.8244
	new_data_grads_norm = 4.7871
	old_data_grads_norm = 4.1110
	sim_grads_norm_tr = 0.0813
-- Starting training on experience 54 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8326
	data_grads_norm = 3.1744
	new_data_grads_norm = 4.9228
	old_data_grads_norm = 3.7883
	sim_grads_norm_tr = -0.0963
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7188
	data_grads_norm = 3.1666
	new_data_grads_norm = 5.1968
	old_data_grads_norm = 3.9917
	sim_grads_norm_tr = 0.0153
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8831
	data_grads_norm = 3.1897
	new_data_grads_norm = 5.3767
	old_data_grads_norm = 3.7451
	sim_grads_norm_tr = 0.0528
-- Starting training on experience 55 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9216
	data_grads_norm = 3.2051
	new_data_grads_norm = 4.2437
	old_data_grads_norm = 5.1309
	sim_grads_norm_tr = 0.0496
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9240
	data_grads_norm = 3.1557
	new_data_grads_norm = 4.2376
	old_data_grads_norm = 6.6919
	sim_grads_norm_tr = 0.0799
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1276
	data_grads_norm = 3.8105
	new_data_grads_norm = 4.9338
	old_data_grads_norm = 4.1441
	sim_grads_norm_tr = 0.4035
-- Starting training on experience 56 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8476
	data_grads_norm = 2.9242
	new_data_grads_norm = 4.8983
	old_data_grads_norm = 3.4141
	sim_grads_norm_tr = -0.0089
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3808
	data_grads_norm = 2.3109
	new_data_grads_norm = 5.0578
	old_data_grads_norm = 3.9634
	sim_grads_norm_tr = -0.3104
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7661
	data_grads_norm = 3.5095
	new_data_grads_norm = 6.6124
	old_data_grads_norm = 3.5141
	sim_grads_norm_tr = -0.1207
-- Starting training on experience 57 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2018
	data_grads_norm = 3.0410
	new_data_grads_norm = 5.3783
	old_data_grads_norm = 2.7889
	sim_grads_norm_tr = 0.0590
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1936
	data_grads_norm = 3.3405
	new_data_grads_norm = 5.0274
	old_data_grads_norm = 4.4837
	sim_grads_norm_tr = 0.1941
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3101
	data_grads_norm = 4.2764
	new_data_grads_norm = 5.2928
	old_data_grads_norm = 6.0311
	sim_grads_norm_tr = 0.1936
-- Starting training on experience 58 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7103
	data_grads_norm = 2.8902
	new_data_grads_norm = 3.6367
	old_data_grads_norm = 3.4646
	sim_grads_norm_tr = 0.1212
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5608
	data_grads_norm = 2.0105
	new_data_grads_norm = 3.8642
	old_data_grads_norm = 3.1191
	sim_grads_norm_tr = 0.1166
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7174
	data_grads_norm = 2.7706
	new_data_grads_norm = 3.6612
	old_data_grads_norm = 3.2189
	sim_grads_norm_tr = 0.1685
-- Starting training on experience 59 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7183
	data_grads_norm = 2.2853
	new_data_grads_norm = 4.4028
	old_data_grads_norm = 5.6745
	sim_grads_norm_tr = -0.0997
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7031
	data_grads_norm = 3.0254
	new_data_grads_norm = 3.9069
	old_data_grads_norm = 3.9455
	sim_grads_norm_tr = -0.0543
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6761
	data_grads_norm = 2.1530
	new_data_grads_norm = 4.1789
	old_data_grads_norm = 3.1242
	sim_grads_norm_tr = -0.0736
-- Starting training on experience 60 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0399
	data_grads_norm = 2.5134
	new_data_grads_norm = 3.6591
	old_data_grads_norm = 4.0098
	sim_grads_norm_tr = 0.1646
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8595
	data_grads_norm = 2.5344
	new_data_grads_norm = 3.4789
	old_data_grads_norm = 3.0573
	sim_grads_norm_tr = 0.3870
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7861
	data_grads_norm = 2.5934
	new_data_grads_norm = 3.4968
	old_data_grads_norm = 3.8694
	sim_grads_norm_tr = -0.3693
-- Starting training on experience 61 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8882
	data_grads_norm = 3.1064
	new_data_grads_norm = 5.7861
	old_data_grads_norm = 2.6235
	sim_grads_norm_tr = -0.0878
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0205
	data_grads_norm = 3.6140
	new_data_grads_norm = 6.1588
	old_data_grads_norm = 3.2588
	sim_grads_norm_tr = 0.1525
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2403
	data_grads_norm = 3.8460
	new_data_grads_norm = 6.6284
	old_data_grads_norm = 3.9629
	sim_grads_norm_tr = 0.2214
-- Starting training on experience 62 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5144
	data_grads_norm = 2.7092
	new_data_grads_norm = 4.5429
	old_data_grads_norm = 2.8421
	sim_grads_norm_tr = -0.0052
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5404
	data_grads_norm = 2.8168
	new_data_grads_norm = 4.8723
	old_data_grads_norm = 2.5674
	sim_grads_norm_tr = 0.0777
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5714
	data_grads_norm = 2.5997
	new_data_grads_norm = 4.9273
	old_data_grads_norm = 2.4970
	sim_grads_norm_tr = -0.0864
-- Starting training on experience 63 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8724
	data_grads_norm = 2.8298
	new_data_grads_norm = 4.2321
	old_data_grads_norm = 4.0903
	sim_grads_norm_tr = 0.1202
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6604
	data_grads_norm = 2.5365
	new_data_grads_norm = 4.0800
	old_data_grads_norm = 3.5191
	sim_grads_norm_tr = -0.1363
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4824
	data_grads_norm = 2.5339
	new_data_grads_norm = 4.0751
	old_data_grads_norm = 4.2575
	sim_grads_norm_tr = 0.0051
-- Starting training on experience 64 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0315
	data_grads_norm = 2.9446
	new_data_grads_norm = 5.5608
	old_data_grads_norm = 4.1885
	sim_grads_norm_tr = 0.0710
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0235
	data_grads_norm = 3.1274
	new_data_grads_norm = 5.1856
	old_data_grads_norm = 4.3616
	sim_grads_norm_tr = -0.0275
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8583
	data_grads_norm = 2.8767
	new_data_grads_norm = 5.3440
	old_data_grads_norm = 3.8275
	sim_grads_norm_tr = 0.2054
-- Starting training on experience 65 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6662
	data_grads_norm = 2.3647
	new_data_grads_norm = 3.9933
	old_data_grads_norm = 2.7058
	sim_grads_norm_tr = -0.0793
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1135
	data_grads_norm = 3.9771
	new_data_grads_norm = 4.2235
	old_data_grads_norm = 5.1584
	sim_grads_norm_tr = 0.1884
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2410
	data_grads_norm = 3.0860
	new_data_grads_norm = 4.3219
	old_data_grads_norm = 4.9306
	sim_grads_norm_tr = -0.1203
-- Starting training on experience 66 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9692
	data_grads_norm = 3.1016
	new_data_grads_norm = 4.8853
	old_data_grads_norm = 3.7444
	sim_grads_norm_tr = 0.0146
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9917
	data_grads_norm = 3.0699
	new_data_grads_norm = 4.6801
	old_data_grads_norm = 3.5833
	sim_grads_norm_tr = 0.0830
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8139
	data_grads_norm = 3.0086
	new_data_grads_norm = 4.4159
	old_data_grads_norm = 2.8290
	sim_grads_norm_tr = 0.1493
-- Starting training on experience 67 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5523
	data_grads_norm = 2.4124
	new_data_grads_norm = 4.9232
	old_data_grads_norm = 2.7986
	sim_grads_norm_tr = -0.0681
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9462
	data_grads_norm = 3.4746
	new_data_grads_norm = 5.5108
	old_data_grads_norm = 4.5751
	sim_grads_norm_tr = 0.0864
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6052
	data_grads_norm = 2.7796
	new_data_grads_norm = 5.0812
	old_data_grads_norm = 3.2340
	sim_grads_norm_tr = 0.0088
-- Starting training on experience 68 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1743
	data_grads_norm = 4.6305
	new_data_grads_norm = 6.2715
	old_data_grads_norm = 4.3760
	sim_grads_norm_tr = 0.0045
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1971
	data_grads_norm = 4.9515
	new_data_grads_norm = 6.1861
	old_data_grads_norm = 4.5386
	sim_grads_norm_tr = -0.0513
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1508
	data_grads_norm = 3.9646
	new_data_grads_norm = 5.6696
	old_data_grads_norm = 4.5881
	sim_grads_norm_tr = 0.3446
-- Starting training on experience 69 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2443
	data_grads_norm = 4.3645
	new_data_grads_norm = 5.9921
	old_data_grads_norm = 5.5689
	sim_grads_norm_tr = 0.1879
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7129
	data_grads_norm = 3.5038
	new_data_grads_norm = 4.3981
	old_data_grads_norm = 4.4461
	sim_grads_norm_tr = 0.2667
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5661
	data_grads_norm = 2.9328
	new_data_grads_norm = 4.0577
	old_data_grads_norm = 4.5538
	sim_grads_norm_tr = 0.0013
-- Starting training on experience 70 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4480
	data_grads_norm = 2.4641
	new_data_grads_norm = 3.6743
	old_data_grads_norm = 2.9575
	sim_grads_norm_tr = -0.0596
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7006
	data_grads_norm = 2.8593
	new_data_grads_norm = 3.4973
	old_data_grads_norm = 4.0855
	sim_grads_norm_tr = 0.0790
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3138
	data_grads_norm = 2.5812
	new_data_grads_norm = 3.6806
	old_data_grads_norm = 2.7801
	sim_grads_norm_tr = 0.2166
-- Starting training on experience 71 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5452
	data_grads_norm = 2.5727
	new_data_grads_norm = 4.1321
	old_data_grads_norm = 3.6583
	sim_grads_norm_tr = -0.1173
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3002
	data_grads_norm = 2.3783
	new_data_grads_norm = 4.4596
	old_data_grads_norm = 3.5134
	sim_grads_norm_tr = -0.0168
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7948
	data_grads_norm = 2.5874
	new_data_grads_norm = 4.6363
	old_data_grads_norm = 3.9183
	sim_grads_norm_tr = -0.0503
-- Starting training on experience 72 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7204
	data_grads_norm = 3.5364
	new_data_grads_norm = 6.3336
	old_data_grads_norm = 5.0222
	sim_grads_norm_tr = 0.0011
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2037
	data_grads_norm = 4.4867
	new_data_grads_norm = 5.6415
	old_data_grads_norm = 5.3568
	sim_grads_norm_tr = 0.2827
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6137
	data_grads_norm = 2.7409
	new_data_grads_norm = 5.4181
	old_data_grads_norm = 3.2005
	sim_grads_norm_tr = -0.0239
-- Starting training on experience 73 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9036
	data_grads_norm = 3.4616
	new_data_grads_norm = 5.2452
	old_data_grads_norm = 3.6307
	sim_grads_norm_tr = 0.2949
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7000
	data_grads_norm = 2.8888
	new_data_grads_norm = 4.7007
	old_data_grads_norm = 3.4132
	sim_grads_norm_tr = -0.0119
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7832
	data_grads_norm = 2.7073
	new_data_grads_norm = 4.6900
	old_data_grads_norm = 3.2817
	sim_grads_norm_tr = -0.0613
-- Starting training on experience 74 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4192
	data_grads_norm = 3.0316
	new_data_grads_norm = 5.3627
	old_data_grads_norm = 4.4822
	sim_grads_norm_tr = 0.0710
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2975
	data_grads_norm = 2.9641
	new_data_grads_norm = 6.0147
	old_data_grads_norm = 4.1143
	sim_grads_norm_tr = -0.1129
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0825
	data_grads_norm = 4.6360
	new_data_grads_norm = 5.3222
	old_data_grads_norm = 5.8420
	sim_grads_norm_tr = 0.3672
-- Starting training on experience 75 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2453
	data_grads_norm = 2.9985
	new_data_grads_norm = 3.7582
	old_data_grads_norm = 3.8259
	sim_grads_norm_tr = 0.2864
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2834
	data_grads_norm = 2.0111
	new_data_grads_norm = 2.9767
	old_data_grads_norm = 4.0686
	sim_grads_norm_tr = -0.0446
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7400
	data_grads_norm = 2.9115
	new_data_grads_norm = 3.6748
	old_data_grads_norm = 4.7439
	sim_grads_norm_tr = -0.1060
-- Starting training on experience 76 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7674
	data_grads_norm = 2.3043
	new_data_grads_norm = 3.7262
	old_data_grads_norm = 4.2427
	sim_grads_norm_tr = 0.0492
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9314
	data_grads_norm = 3.0732
	new_data_grads_norm = 3.7689
	old_data_grads_norm = 4.4203
	sim_grads_norm_tr = 0.0034
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7798
	data_grads_norm = 2.9728
	new_data_grads_norm = 4.2799
	old_data_grads_norm = 3.2524
	sim_grads_norm_tr = 0.1026
-- Starting training on experience 77 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3926
	data_grads_norm = 2.5140
	new_data_grads_norm = 4.4469
	old_data_grads_norm = 4.4616
	sim_grads_norm_tr = -0.2108
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5935
	data_grads_norm = 2.9772
	new_data_grads_norm = 5.3788
	old_data_grads_norm = 3.0813
	sim_grads_norm_tr = -0.0292
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6695
	data_grads_norm = 3.2170
	new_data_grads_norm = 5.3791
	old_data_grads_norm = 3.9662
	sim_grads_norm_tr = 0.0549
-- Starting training on experience 78 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8230
	data_grads_norm = 3.5083
	new_data_grads_norm = 5.0869
	old_data_grads_norm = 3.8111
	sim_grads_norm_tr = 0.0964
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7277
	data_grads_norm = 3.3871
	new_data_grads_norm = 5.7189
	old_data_grads_norm = 4.2415
	sim_grads_norm_tr = 0.0150
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7258
	data_grads_norm = 3.3121
	new_data_grads_norm = 5.2816
	old_data_grads_norm = 4.2193
	sim_grads_norm_tr = 0.1716
-- Starting training on experience 79 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7040
	data_grads_norm = 3.0762
	new_data_grads_norm = 3.7952
	old_data_grads_norm = 4.0167
	sim_grads_norm_tr = 0.2955
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2987
	data_grads_norm = 2.4043
	new_data_grads_norm = 3.2226
	old_data_grads_norm = 3.0741
	sim_grads_norm_tr = 0.3569
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5778
	data_grads_norm = 2.5585
	new_data_grads_norm = 3.2645
	old_data_grads_norm = 4.6696
	sim_grads_norm_tr = -0.0168
-- Starting training on experience 80 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7164
	data_grads_norm = 3.0789
	new_data_grads_norm = 4.4731
	old_data_grads_norm = 3.8005
	sim_grads_norm_tr = 0.1695
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7126
	data_grads_norm = 2.9997
	new_data_grads_norm = 5.0231
	old_data_grads_norm = 4.0289
	sim_grads_norm_tr = -0.2695
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5811
	data_grads_norm = 4.1283
	new_data_grads_norm = 6.0017
	old_data_grads_norm = 3.2562
	sim_grads_norm_tr = 0.1805
-- Starting training on experience 81 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4837
	data_grads_norm = 3.0661
	new_data_grads_norm = 5.1542
	old_data_grads_norm = 4.8920
	sim_grads_norm_tr = -0.1567
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7093
	data_grads_norm = 3.9447
	new_data_grads_norm = 7.9168
	old_data_grads_norm = 5.3831
	sim_grads_norm_tr = -0.0185
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8844
	data_grads_norm = 4.0528
	new_data_grads_norm = 6.8134
	old_data_grads_norm = 3.2768
	sim_grads_norm_tr = 0.2821
-- Starting training on experience 82 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6859
	data_grads_norm = 3.0828
	new_data_grads_norm = 4.0535
	old_data_grads_norm = 3.7593
	sim_grads_norm_tr = 0.3865
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5538
	data_grads_norm = 2.1020
	new_data_grads_norm = 3.1844
	old_data_grads_norm = 3.0822
	sim_grads_norm_tr = -0.0719
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4440
	data_grads_norm = 2.1343
	new_data_grads_norm = 3.1974
	old_data_grads_norm = 2.6294
	sim_grads_norm_tr = 0.0814
-- Starting training on experience 83 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4707
	data_grads_norm = 2.1227
	new_data_grads_norm = 4.1615
	old_data_grads_norm = 3.4712
	sim_grads_norm_tr = -0.1644
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4630
	data_grads_norm = 2.7093
	new_data_grads_norm = 5.1535
	old_data_grads_norm = 2.4752
	sim_grads_norm_tr = 0.1452
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8835
	data_grads_norm = 4.6143
	new_data_grads_norm = 4.6562
	old_data_grads_norm = 5.8124
	sim_grads_norm_tr = 0.3805
-- Starting training on experience 84 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8599
	data_grads_norm = 2.9058
	new_data_grads_norm = 4.0248
	old_data_grads_norm = 4.7153
	sim_grads_norm_tr = 0.0633
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9696
	data_grads_norm = 3.2690
	new_data_grads_norm = 4.1457
	old_data_grads_norm = 3.9703
	sim_grads_norm_tr = 0.1898
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5596
	data_grads_norm = 2.4690
	new_data_grads_norm = 3.8333
	old_data_grads_norm = 3.0588
	sim_grads_norm_tr = 0.0472
-- Starting training on experience 85 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3892
	data_grads_norm = 2.5630
	new_data_grads_norm = 4.9074
	old_data_grads_norm = 4.5828
	sim_grads_norm_tr = -0.2154
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6012
	data_grads_norm = 3.5029
	new_data_grads_norm = 5.4270
	old_data_grads_norm = 2.8055
	sim_grads_norm_tr = 0.0586
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5284
	data_grads_norm = 3.2582
	new_data_grads_norm = 5.3969
	old_data_grads_norm = 4.3054
	sim_grads_norm_tr = -0.2721
-- Starting training on experience 86 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6938
	data_grads_norm = 3.6647
	new_data_grads_norm = 5.9159
	old_data_grads_norm = 4.0961
	sim_grads_norm_tr = -0.0309
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6455
	data_grads_norm = 3.1328
	new_data_grads_norm = 5.5899
	old_data_grads_norm = 3.1342
	sim_grads_norm_tr = -0.1283
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6140
	data_grads_norm = 3.3304
	new_data_grads_norm = 5.5801
	old_data_grads_norm = 2.5990
	sim_grads_norm_tr = 0.1362
-- Starting training on experience 87 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6596
	data_grads_norm = 3.3359
	new_data_grads_norm = 5.3343
	old_data_grads_norm = 3.7211
	sim_grads_norm_tr = 0.1593
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3180
	data_grads_norm = 3.0729
	new_data_grads_norm = 4.4972
	old_data_grads_norm = 4.4826
	sim_grads_norm_tr = 0.1494
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4859
	data_grads_norm = 3.3566
	new_data_grads_norm = 5.7057
	old_data_grads_norm = 3.3713
	sim_grads_norm_tr = 0.2956
-- Starting training on experience 88 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5382
	data_grads_norm = 3.5207
	new_data_grads_norm = 4.8090
	old_data_grads_norm = 5.6963
	sim_grads_norm_tr = -0.1550
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8326
	data_grads_norm = 4.7672
	new_data_grads_norm = 6.1009
	old_data_grads_norm = 5.1964
	sim_grads_norm_tr = 0.5904
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2858
	data_grads_norm = 2.6462
	new_data_grads_norm = 3.9149
	old_data_grads_norm = 2.8312
	sim_grads_norm_tr = 0.1462
-- Starting training on experience 89 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4775
	data_grads_norm = 3.5041
	new_data_grads_norm = 5.1427
	old_data_grads_norm = 4.5575
	sim_grads_norm_tr = -0.0486
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7250
	data_grads_norm = 3.2684
	new_data_grads_norm = 5.1948
	old_data_grads_norm = 4.5173
	sim_grads_norm_tr = 0.1342
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6408
	data_grads_norm = 2.9633
	new_data_grads_norm = 4.9961
	old_data_grads_norm = 3.5255
	sim_grads_norm_tr = -0.0391
-- Starting training on experience 90 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4255
	data_grads_norm = 3.3751
	new_data_grads_norm = 5.4466
	old_data_grads_norm = 4.2931
	sim_grads_norm_tr = 0.1490
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4264
	data_grads_norm = 3.6621
	new_data_grads_norm = 6.2608
	old_data_grads_norm = 3.7136
	sim_grads_norm_tr = 0.0227
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5243
	data_grads_norm = 3.1825
	new_data_grads_norm = 5.0779
	old_data_grads_norm = 3.8133
	sim_grads_norm_tr = 0.2196
-- Starting training on experience 91 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2683
	data_grads_norm = 2.4699
	new_data_grads_norm = 4.9325
	old_data_grads_norm = 3.7883
	sim_grads_norm_tr = -0.0864
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5896
	data_grads_norm = 3.3873
	new_data_grads_norm = 4.5466
	old_data_grads_norm = 4.4782
	sim_grads_norm_tr = 0.1268
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5427
	data_grads_norm = 3.0360
	new_data_grads_norm = 5.0141
	old_data_grads_norm = 3.2609
	sim_grads_norm_tr = 0.1874
-- Starting training on experience 92 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8188
	data_grads_norm = 3.4868
	new_data_grads_norm = 5.4551
	old_data_grads_norm = 5.6682
	sim_grads_norm_tr = -0.0731
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0638
	data_grads_norm = 4.1458
	new_data_grads_norm = 5.7083
	old_data_grads_norm = 5.6238
	sim_grads_norm_tr = 0.0958
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5194
	data_grads_norm = 2.1893
	new_data_grads_norm = 5.4786
	old_data_grads_norm = 2.3887
	sim_grads_norm_tr = -0.0584
-- Starting training on experience 93 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1779
	data_grads_norm = 2.4179
	new_data_grads_norm = 4.1789
	old_data_grads_norm = 2.7080
	sim_grads_norm_tr = -0.0943
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4895
	data_grads_norm = 2.8993
	new_data_grads_norm = 4.7881
	old_data_grads_norm = 5.4803
	sim_grads_norm_tr = 0.0954
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3961
	data_grads_norm = 2.6475
	new_data_grads_norm = 4.8757
	old_data_grads_norm = 3.0634
	sim_grads_norm_tr = -0.0808
-- Starting training on experience 94 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8775
	data_grads_norm = 3.7901
	new_data_grads_norm = 4.7868
	old_data_grads_norm = 4.9452
	sim_grads_norm_tr = 0.4073
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4229
	data_grads_norm = 2.8466
	new_data_grads_norm = 3.9930
	old_data_grads_norm = 4.0508
	sim_grads_norm_tr = -0.0719
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4758
	data_grads_norm = 2.5050
	new_data_grads_norm = 4.1510
	old_data_grads_norm = 3.3269
	sim_grads_norm_tr = 0.0214
-- Starting training on experience 95 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6925
	data_grads_norm = 3.2042
	new_data_grads_norm = 5.5957
	old_data_grads_norm = 3.2228
	sim_grads_norm_tr = 0.0372
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7329
	data_grads_norm = 3.6283
	new_data_grads_norm = 4.9540
	old_data_grads_norm = 4.6832
	sim_grads_norm_tr = 0.2109
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3558
	data_grads_norm = 2.7742
	new_data_grads_norm = 4.4400
	old_data_grads_norm = 3.6831
	sim_grads_norm_tr = 0.0751
-- Starting training on experience 96 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3511
	data_grads_norm = 2.3677
	new_data_grads_norm = 3.5409
	old_data_grads_norm = 3.2912
	sim_grads_norm_tr = -0.0344
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4415
	data_grads_norm = 2.4348
	new_data_grads_norm = 3.4303
	old_data_grads_norm = 4.8792
	sim_grads_norm_tr = -0.1280
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7237
	data_grads_norm = 2.6505
	new_data_grads_norm = 3.7678
	old_data_grads_norm = 3.5408
	sim_grads_norm_tr = 0.0217
-- Starting training on experience 97 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9365
	data_grads_norm = 3.2397
	new_data_grads_norm = 4.2823
	old_data_grads_norm = 3.6690
	sim_grads_norm_tr = 0.2712
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4459
	data_grads_norm = 2.3139
	new_data_grads_norm = 4.0195
	old_data_grads_norm = 3.2076
	sim_grads_norm_tr = -0.0517
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7904
	data_grads_norm = 2.8340
	new_data_grads_norm = 4.3247
	old_data_grads_norm = 4.4305
	sim_grads_norm_tr = 0.2099
-- Starting training on experience 98 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2066
	data_grads_norm = 2.5227
	new_data_grads_norm = 3.7873
	old_data_grads_norm = 3.2843
	sim_grads_norm_tr = -0.1004
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2899
	data_grads_norm = 3.1544
	new_data_grads_norm = 4.9986
	old_data_grads_norm = 4.1927
	sim_grads_norm_tr = -0.0883
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3696
	data_grads_norm = 2.5383
	new_data_grads_norm = 4.8866
	old_data_grads_norm = 3.8277
	sim_grads_norm_tr = -0.2735
-- Starting training on experience 99 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8956
	data_grads_norm = 3.7690
	new_data_grads_norm = 5.6133
	old_data_grads_norm = 3.6458
	sim_grads_norm_tr = 0.2141
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3513
	data_grads_norm = 3.0028
	new_data_grads_norm = 5.9915
	old_data_grads_norm = 2.6742
	sim_grads_norm_tr = 0.0937
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5234
	data_grads_norm = 3.2923
	new_data_grads_norm = 5.6550
	old_data_grads_norm = 4.9468
	sim_grads_norm_tr = -0.0345
-- Starting training on experience 100 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2786
	data_grads_norm = 3.2792
	new_data_grads_norm = 4.5456
	old_data_grads_norm = 5.4058
	sim_grads_norm_tr = 0.1840
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6803
	data_grads_norm = 3.0698
	new_data_grads_norm = 4.3883
	old_data_grads_norm = 4.8874
	sim_grads_norm_tr = 0.0783
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4886
	data_grads_norm = 2.3729
	new_data_grads_norm = 4.2083
	old_data_grads_norm = 4.9649
	sim_grads_norm_tr = -0.2165
-- Starting training on experience 101 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8188
	data_grads_norm = 3.7465
	new_data_grads_norm = 3.4789
	old_data_grads_norm = 5.6005
	sim_grads_norm_tr = 0.1542
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5649
	data_grads_norm = 2.1310
	new_data_grads_norm = 2.9616
	old_data_grads_norm = 3.0117
	sim_grads_norm_tr = 0.0022
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3294
	data_grads_norm = 2.3394
	new_data_grads_norm = 2.9951
	old_data_grads_norm = 3.0480
	sim_grads_norm_tr = 0.1858
-- Starting training on experience 102 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3787
	data_grads_norm = 2.5633
	new_data_grads_norm = 3.5658
	old_data_grads_norm = 3.3649
	sim_grads_norm_tr = -0.0299
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0436
	data_grads_norm = 2.2327
	new_data_grads_norm = 3.5449
	old_data_grads_norm = 2.5122
	sim_grads_norm_tr = 0.1301
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2269
	data_grads_norm = 2.3164
	new_data_grads_norm = 3.5288
	old_data_grads_norm = 4.6206
	sim_grads_norm_tr = 0.0969
-- Starting training on experience 103 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5440
	data_grads_norm = 3.3538
	new_data_grads_norm = 3.7473
	old_data_grads_norm = 5.9467
	sim_grads_norm_tr = 0.1273
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1439
	data_grads_norm = 2.5441
	new_data_grads_norm = 3.6424
	old_data_grads_norm = 4.6377
	sim_grads_norm_tr = -0.0694
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3658
	data_grads_norm = 2.7402
	new_data_grads_norm = 4.1176
	old_data_grads_norm = 5.3083
	sim_grads_norm_tr = -0.0846
-- Starting training on experience 104 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5831
	data_grads_norm = 3.6383
	new_data_grads_norm = 4.8634
	old_data_grads_norm = 4.5197
	sim_grads_norm_tr = 0.2482
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3883
	data_grads_norm = 2.8577
	new_data_grads_norm = 3.8755
	old_data_grads_norm = 3.7749
	sim_grads_norm_tr = 0.2696
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3779
	data_grads_norm = 2.5195
	new_data_grads_norm = 4.0605
	old_data_grads_norm = 3.3021
	sim_grads_norm_tr = 0.1696
-- Starting training on experience 105 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5300
	data_grads_norm = 2.4488
	new_data_grads_norm = 3.5437
	old_data_grads_norm = 3.6037
	sim_grads_norm_tr = -0.2154
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5615
	data_grads_norm = 2.6882
	new_data_grads_norm = 3.8708
	old_data_grads_norm = 4.4395
	sim_grads_norm_tr = -0.2701
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8322
	data_grads_norm = 3.7287
	new_data_grads_norm = 5.1285
	old_data_grads_norm = 4.8887
	sim_grads_norm_tr = 0.2295
-- Starting training on experience 106 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4316
	data_grads_norm = 3.0861
	new_data_grads_norm = 5.6272
	old_data_grads_norm = 3.5387
	sim_grads_norm_tr = -0.0136
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4989
	data_grads_norm = 3.2217
	new_data_grads_norm = 5.8969
	old_data_grads_norm = 4.1808
	sim_grads_norm_tr = 0.0276
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6873
	data_grads_norm = 3.0375
	new_data_grads_norm = 5.6957
	old_data_grads_norm = 3.1538
	sim_grads_norm_tr = 0.0972
-- Starting training on experience 107 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4121
	data_grads_norm = 2.2685
	new_data_grads_norm = 4.4365
	old_data_grads_norm = 3.7269
	sim_grads_norm_tr = -0.0690
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5059
	data_grads_norm = 3.4519
	new_data_grads_norm = 5.2479
	old_data_grads_norm = 4.5806
	sim_grads_norm_tr = -0.0817
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6275
	data_grads_norm = 3.0860
	new_data_grads_norm = 5.8998
	old_data_grads_norm = 4.2316
	sim_grads_norm_tr = 0.0257
-- Starting training on experience 108 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6907
	data_grads_norm = 3.7756
	new_data_grads_norm = 6.1382
	old_data_grads_norm = 5.0842
	sim_grads_norm_tr = 0.0133
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9666
	data_grads_norm = 5.1390
	new_data_grads_norm = 6.0941
	old_data_grads_norm = 5.4285
	sim_grads_norm_tr = 0.4198
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0485
	data_grads_norm = 2.9708
	new_data_grads_norm = 5.1047
	old_data_grads_norm = 4.0925
	sim_grads_norm_tr = -0.0313
-- Starting training on experience 109 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3111
	data_grads_norm = 2.9717
	new_data_grads_norm = 4.6840
	old_data_grads_norm = 4.3387
	sim_grads_norm_tr = -0.0552
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5230
	data_grads_norm = 3.4764
	new_data_grads_norm = 4.3221
	old_data_grads_norm = 4.8633
	sim_grads_norm_tr = 0.0900
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4817
	data_grads_norm = 2.4340
	new_data_grads_norm = 4.6792
	old_data_grads_norm = 3.9964
	sim_grads_norm_tr = -0.1325
-- Starting training on experience 110 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4011
	data_grads_norm = 2.9168
	new_data_grads_norm = 4.5150
	old_data_grads_norm = 3.9872
	sim_grads_norm_tr = 0.0618
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4400
	data_grads_norm = 2.7771
	new_data_grads_norm = 4.1641
	old_data_grads_norm = 3.1098
	sim_grads_norm_tr = 0.2670
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7678
	data_grads_norm = 3.6097
	new_data_grads_norm = 3.9892
	old_data_grads_norm = 4.7489
	sim_grads_norm_tr = 0.0158
-- Starting training on experience 111 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3178
	data_grads_norm = 2.5674
	new_data_grads_norm = 3.7235
	old_data_grads_norm = 4.1972
	sim_grads_norm_tr = -0.0306
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6313
	data_grads_norm = 3.2163
	new_data_grads_norm = 4.3140
	old_data_grads_norm = 4.6192
	sim_grads_norm_tr = 0.1933
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3195
	data_grads_norm = 2.9171
	new_data_grads_norm = 4.5168
	old_data_grads_norm = 4.7066
	sim_grads_norm_tr = 0.1476
-- Starting training on experience 112 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4339
	data_grads_norm = 2.7795
	new_data_grads_norm = 4.2558
	old_data_grads_norm = 3.8035
	sim_grads_norm_tr = 0.0242
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2683
	data_grads_norm = 2.7214
	new_data_grads_norm = 3.9034
	old_data_grads_norm = 3.3064
	sim_grads_norm_tr = 0.0195
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4569
	data_grads_norm = 2.8032
	new_data_grads_norm = 4.0578
	old_data_grads_norm = 3.5492
	sim_grads_norm_tr = 0.0720
-- Starting training on experience 113 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3171
	data_grads_norm = 2.6526
	new_data_grads_norm = 4.1575
	old_data_grads_norm = 2.9840
	sim_grads_norm_tr = 0.2096
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3152
	data_grads_norm = 3.1488
	new_data_grads_norm = 4.3539
	old_data_grads_norm = 4.8461
	sim_grads_norm_tr = 0.0448
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9098
	data_grads_norm = 3.5045
	new_data_grads_norm = 4.0496
	old_data_grads_norm = 5.8712
	sim_grads_norm_tr = 0.0223
-- Starting training on experience 114 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4075
	data_grads_norm = 2.9865
	new_data_grads_norm = 4.8842
	old_data_grads_norm = 4.2842
	sim_grads_norm_tr = 0.0482
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3305
	data_grads_norm = 2.5343
	new_data_grads_norm = 4.7392
	old_data_grads_norm = 4.5532
	sim_grads_norm_tr = -0.1607
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6621
	data_grads_norm = 3.7249
	new_data_grads_norm = 5.9911
	old_data_grads_norm = 3.9578
	sim_grads_norm_tr = 0.1978
-- Starting training on experience 115 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7743
	data_grads_norm = 3.7777
	new_data_grads_norm = 5.4879
	old_data_grads_norm = 5.2724
	sim_grads_norm_tr = 0.0222
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4940
	data_grads_norm = 2.6795
	new_data_grads_norm = 5.1635
	old_data_grads_norm = 2.9089
	sim_grads_norm_tr = 0.0952
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6180
	data_grads_norm = 3.1993
	new_data_grads_norm = 5.1871
	old_data_grads_norm = 4.0556
	sim_grads_norm_tr = 0.1118
-- Starting training on experience 116 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3914
	data_grads_norm = 2.4610
	new_data_grads_norm = 4.2960
	old_data_grads_norm = 3.5916
	sim_grads_norm_tr = -0.1920
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6959
	data_grads_norm = 2.9896
	new_data_grads_norm = 4.5194
	old_data_grads_norm = 3.9998
	sim_grads_norm_tr = 0.0347
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5970
	data_grads_norm = 2.7732
	new_data_grads_norm = 4.4382
	old_data_grads_norm = 2.8726
	sim_grads_norm_tr = 0.1988
-- Starting training on experience 117 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5568
	data_grads_norm = 3.3816
	new_data_grads_norm = 5.6513
	old_data_grads_norm = 4.2664
	sim_grads_norm_tr = 0.0600
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5248
	data_grads_norm = 4.3030
	new_data_grads_norm = 6.0611
	old_data_grads_norm = 5.7822
	sim_grads_norm_tr = 0.1284
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5062
	data_grads_norm = 3.1640
	new_data_grads_norm = 5.5117
	old_data_grads_norm = 5.0094
	sim_grads_norm_tr = 0.0649
-- Starting training on experience 118 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7212
	data_grads_norm = 3.6650
	new_data_grads_norm = 6.5393
	old_data_grads_norm = 5.3597
	sim_grads_norm_tr = -0.0179
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5205
	data_grads_norm = 3.4911
	new_data_grads_norm = 6.7116
	old_data_grads_norm = 3.3009
	sim_grads_norm_tr = -0.0547
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4972
	data_grads_norm = 3.1955
	new_data_grads_norm = 6.3021
	old_data_grads_norm = 3.8951
	sim_grads_norm_tr = -0.0434
-- Starting training on experience 119 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4292
	data_grads_norm = 3.5442
	new_data_grads_norm = 7.0349
	old_data_grads_norm = 4.6424
	sim_grads_norm_tr = 0.0639
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7098
	data_grads_norm = 3.9009
	new_data_grads_norm = 6.2995
	old_data_grads_norm = 5.2581
	sim_grads_norm_tr = 0.0904
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4666
	data_grads_norm = 3.0981
	new_data_grads_norm = 6.6313
	old_data_grads_norm = 3.9032
	sim_grads_norm_tr = 0.2562
-- Starting training on experience 120 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6438
	data_grads_norm = 4.0396
	new_data_grads_norm = 4.6475
	old_data_grads_norm = 4.8534
	sim_grads_norm_tr = 0.3873
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3759
	data_grads_norm = 2.2935
	new_data_grads_norm = 3.6057
	old_data_grads_norm = 2.9993
	sim_grads_norm_tr = -0.1331
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2677
	data_grads_norm = 2.7176
	new_data_grads_norm = 3.9261
	old_data_grads_norm = 3.6774
	sim_grads_norm_tr = 0.2257
-- Starting training on experience 121 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9876
	data_grads_norm = 2.6080
	new_data_grads_norm = 3.2554
	old_data_grads_norm = 5.6986
	sim_grads_norm_tr = 0.0009
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1425
	data_grads_norm = 2.6728
	new_data_grads_norm = 3.4088
	old_data_grads_norm = 3.7368
	sim_grads_norm_tr = 0.0999
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0909
	data_grads_norm = 2.3082
	new_data_grads_norm = 3.8048
	old_data_grads_norm = 3.8589
	sim_grads_norm_tr = -0.0733
-- Starting training on experience 122 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7481
	data_grads_norm = 3.4569
	new_data_grads_norm = 4.3237
	old_data_grads_norm = 4.4836
	sim_grads_norm_tr = -0.0715
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1680
	data_grads_norm = 2.4339
	new_data_grads_norm = 3.7836
	old_data_grads_norm = 2.8258
	sim_grads_norm_tr = 0.0012
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6086
	data_grads_norm = 3.1452
	new_data_grads_norm = 4.0950
	old_data_grads_norm = 3.1002
	sim_grads_norm_tr = -0.0449
-- Starting training on experience 123 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5725
	data_grads_norm = 3.3568
	new_data_grads_norm = 4.9064
	old_data_grads_norm = 3.6248
	sim_grads_norm_tr = 0.1147
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6677
	data_grads_norm = 3.8570
	new_data_grads_norm = 4.6243
	old_data_grads_norm = 5.3448
	sim_grads_norm_tr = 0.1837
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3454
	data_grads_norm = 2.5017
	new_data_grads_norm = 5.1248
	old_data_grads_norm = 3.1734
	sim_grads_norm_tr = 0.0863
-- Starting training on experience 124 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7154
	data_grads_norm = 3.4828
	new_data_grads_norm = 5.0868
	old_data_grads_norm = 3.9094
	sim_grads_norm_tr = 0.1320
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4965
	data_grads_norm = 3.1259
	new_data_grads_norm = 4.0026
	old_data_grads_norm = 5.4643
	sim_grads_norm_tr = -0.1213
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6356
	data_grads_norm = 2.7319
	new_data_grads_norm = 4.5646
	old_data_grads_norm = 3.4350
	sim_grads_norm_tr = -0.0276
-- Starting training on experience 125 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3559
	data_grads_norm = 2.6715
	new_data_grads_norm = 6.1181
	old_data_grads_norm = 3.4485
	sim_grads_norm_tr = -0.1679
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5049
	data_grads_norm = 3.4904
	new_data_grads_norm = 6.0759
	old_data_grads_norm = 4.0514
	sim_grads_norm_tr = -0.1277
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8399
	data_grads_norm = 3.7178
	new_data_grads_norm = 6.7389
	old_data_grads_norm = 5.5843
	sim_grads_norm_tr = -0.0140
-- Starting training on experience 126 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6690
	data_grads_norm = 3.6109
	new_data_grads_norm = 4.8119
	old_data_grads_norm = 4.3172
	sim_grads_norm_tr = 0.2065
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4504
	data_grads_norm = 2.4514
	new_data_grads_norm = 4.5981
	old_data_grads_norm = 3.1267
	sim_grads_norm_tr = -0.3076
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7289
	data_grads_norm = 3.1509
	new_data_grads_norm = 4.8532
	old_data_grads_norm = 4.5041
	sim_grads_norm_tr = 0.0216
-- Starting training on experience 127 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3834
	data_grads_norm = 3.1371
	new_data_grads_norm = 5.2616
	old_data_grads_norm = 4.0041
	sim_grads_norm_tr = -0.0229
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7561
	data_grads_norm = 3.9035
	new_data_grads_norm = 5.4680
	old_data_grads_norm = 4.4173
	sim_grads_norm_tr = 0.2248
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6509
	data_grads_norm = 3.7585
	new_data_grads_norm = 5.6439
	old_data_grads_norm = 4.2576
	sim_grads_norm_tr = 0.1395
-- Starting training on experience 128 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4125
	data_grads_norm = 3.3293
	new_data_grads_norm = 4.9844
	old_data_grads_norm = 3.3424
	sim_grads_norm_tr = 0.2218
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3576
	data_grads_norm = 2.7871
	new_data_grads_norm = 4.9196
	old_data_grads_norm = 2.8747
	sim_grads_norm_tr = 0.1697
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6560
	data_grads_norm = 2.9988
	new_data_grads_norm = 4.9255
	old_data_grads_norm = 5.1464
	sim_grads_norm_tr = -0.0416
-- Starting training on experience 129 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4598
	data_grads_norm = 3.0205
	new_data_grads_norm = 3.7108
	old_data_grads_norm = 6.4547
	sim_grads_norm_tr = 0.1674
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1476
	data_grads_norm = 2.9861
	new_data_grads_norm = 3.4137
	old_data_grads_norm = 4.5053
	sim_grads_norm_tr = -0.0049
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2375
	data_grads_norm = 3.0018
	new_data_grads_norm = 3.7822
	old_data_grads_norm = 3.6038
	sim_grads_norm_tr = 0.1775
-- Starting training on experience 130 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1526
	data_grads_norm = 3.4916
	new_data_grads_norm = 4.5222
	old_data_grads_norm = 4.1885
	sim_grads_norm_tr = 0.4205
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4399
	data_grads_norm = 3.0444
	new_data_grads_norm = 4.2749
	old_data_grads_norm = 4.9890
	sim_grads_norm_tr = 0.0078
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0950
	data_grads_norm = 2.7676
	new_data_grads_norm = 4.0180
	old_data_grads_norm = 3.5337
	sim_grads_norm_tr = 0.1730
-- Starting training on experience 131 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4427
	data_grads_norm = 2.7772
	new_data_grads_norm = 5.4062
	old_data_grads_norm = 3.9585
	sim_grads_norm_tr = 0.0217
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5462
	data_grads_norm = 2.9390
	new_data_grads_norm = 5.4552
	old_data_grads_norm = 4.6425
	sim_grads_norm_tr = -0.1630
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5040
	data_grads_norm = 3.0479
	new_data_grads_norm = 6.4557
	old_data_grads_norm = 3.6082
	sim_grads_norm_tr = 0.0540
-- Starting training on experience 132 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2244
	data_grads_norm = 2.5934
	new_data_grads_norm = 4.2042
	old_data_grads_norm = 2.6307
	sim_grads_norm_tr = -0.1925
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5684
	data_grads_norm = 2.8354
	new_data_grads_norm = 4.7117
	old_data_grads_norm = 6.3652
	sim_grads_norm_tr = 0.0019
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9403
	data_grads_norm = 4.9169
	new_data_grads_norm = 5.7137
	old_data_grads_norm = 5.6228
	sim_grads_norm_tr = 0.1774
-- Starting training on experience 133 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4805
	data_grads_norm = 3.5319
	new_data_grads_norm = 4.9436
	old_data_grads_norm = 5.3921
	sim_grads_norm_tr = -0.1137
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6303
	data_grads_norm = 3.8807
	new_data_grads_norm = 5.3300
	old_data_grads_norm = 4.7203
	sim_grads_norm_tr = 0.2278
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9953
	data_grads_norm = 2.9337
	new_data_grads_norm = 4.2252
	old_data_grads_norm = 3.6742
	sim_grads_norm_tr = -0.0274
-- Starting training on experience 134 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5230
	data_grads_norm = 3.1833
	new_data_grads_norm = 4.6230
	old_data_grads_norm = 4.2240
	sim_grads_norm_tr = 0.1291
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4672
	data_grads_norm = 2.9993
	new_data_grads_norm = 5.0221
	old_data_grads_norm = 4.6409
	sim_grads_norm_tr = -0.0530
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4061
	data_grads_norm = 3.5263
	new_data_grads_norm = 6.2651
	old_data_grads_norm = 3.9385
	sim_grads_norm_tr = -0.0534
-- Starting training on experience 135 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8417
	data_grads_norm = 3.6398
	new_data_grads_norm = 6.3284
	old_data_grads_norm = 4.8217
	sim_grads_norm_tr = -0.0478
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4484
	data_grads_norm = 5.1471
	new_data_grads_norm = 7.6609
	old_data_grads_norm = 5.9307
	sim_grads_norm_tr = 0.1772
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8034
	data_grads_norm = 4.5104
	new_data_grads_norm = 6.5720
	old_data_grads_norm = 5.3351
	sim_grads_norm_tr = 0.1340
-- Starting training on experience 136 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8775
	data_grads_norm = 4.5578
	new_data_grads_norm = 3.6154
	old_data_grads_norm = 6.8140
	sim_grads_norm_tr = 0.1605
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3820
	data_grads_norm = 2.6384
	new_data_grads_norm = 3.7564
	old_data_grads_norm = 3.5287
	sim_grads_norm_tr = 0.0292
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3356
	data_grads_norm = 2.3347
	new_data_grads_norm = 3.9321
	old_data_grads_norm = 5.1783
	sim_grads_norm_tr = 0.0205
-- Starting training on experience 137 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7180
	data_grads_norm = 3.7732
	new_data_grads_norm = 5.0421
	old_data_grads_norm = 6.2154
	sim_grads_norm_tr = 0.2324
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3480
	data_grads_norm = 2.4781
	new_data_grads_norm = 4.4941
	old_data_grads_norm = 4.3029
	sim_grads_norm_tr = -0.1244
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7580
	data_grads_norm = 3.4469
	new_data_grads_norm = 5.3859
	old_data_grads_norm = 4.7469
	sim_grads_norm_tr = 0.0707
-- Starting training on experience 138 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7588
	data_grads_norm = 3.3815
	new_data_grads_norm = 5.3420
	old_data_grads_norm = 4.2039
	sim_grads_norm_tr = -0.0170
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7732
	data_grads_norm = 2.9460
	new_data_grads_norm = 5.2074
	old_data_grads_norm = 4.7884
	sim_grads_norm_tr = -0.0606
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7737
	data_grads_norm = 3.1389
	new_data_grads_norm = 4.9095
	old_data_grads_norm = 4.1987
	sim_grads_norm_tr = -0.0044
-- Starting training on experience 139 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4457
	data_grads_norm = 3.0931
	new_data_grads_norm = 4.0307
	old_data_grads_norm = 4.3197
	sim_grads_norm_tr = 0.0853
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5950
	data_grads_norm = 3.0259
	new_data_grads_norm = 4.1740
	old_data_grads_norm = 4.7942
	sim_grads_norm_tr = 0.0761
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5272
	data_grads_norm = 3.0219
	new_data_grads_norm = 4.7958
	old_data_grads_norm = 3.8622
	sim_grads_norm_tr = 0.1404
-- Starting training on experience 140 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8598
	data_grads_norm = 3.7358
	new_data_grads_norm = 5.6982
	old_data_grads_norm = 3.9720
	sim_grads_norm_tr = 0.1343
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0255
	data_grads_norm = 3.4373
	new_data_grads_norm = 4.8037
	old_data_grads_norm = 5.1326
	sim_grads_norm_tr = 0.1094
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7481
	data_grads_norm = 3.1752
	new_data_grads_norm = 5.3958
	old_data_grads_norm = 2.9885
	sim_grads_norm_tr = -0.0542
-- Starting training on experience 141 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0307
	data_grads_norm = 3.1555
	new_data_grads_norm = 4.9377
	old_data_grads_norm = 4.2699
	sim_grads_norm_tr = -0.0065
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4465
	data_grads_norm = 3.0864
	new_data_grads_norm = 4.8234
	old_data_grads_norm = 4.1520
	sim_grads_norm_tr = 0.0256
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7840
	data_grads_norm = 3.6903
	new_data_grads_norm = 6.5335
	old_data_grads_norm = 3.4395
	sim_grads_norm_tr = 0.3065
-- Starting training on experience 142 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0127
	data_grads_norm = 3.3427
	new_data_grads_norm = 5.5900
	old_data_grads_norm = 4.7545
	sim_grads_norm_tr = -0.0058
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9108
	data_grads_norm = 3.2508
	new_data_grads_norm = 5.5700
	old_data_grads_norm = 4.7381
	sim_grads_norm_tr = -0.1318
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8569
	data_grads_norm = 3.8329
	new_data_grads_norm = 6.7364
	old_data_grads_norm = 4.4313
	sim_grads_norm_tr = 0.0955
-- Starting training on experience 143 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8294
	data_grads_norm = 4.4809
	new_data_grads_norm = 7.6732
	old_data_grads_norm = 4.4008
	sim_grads_norm_tr = -0.1005
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2189
	data_grads_norm = 6.0757
	new_data_grads_norm = 9.0262
	old_data_grads_norm = 4.7808
	sim_grads_norm_tr = 0.3212
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7209
	data_grads_norm = 4.3000
	new_data_grads_norm = 6.6381
	old_data_grads_norm = 3.8960
	sim_grads_norm_tr = 0.3353
-- Starting training on experience 144 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3268
	data_grads_norm = 2.8346
	new_data_grads_norm = 4.4016
	old_data_grads_norm = 6.3135
	sim_grads_norm_tr = 0.0167
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3241
	data_grads_norm = 3.2937
	new_data_grads_norm = 4.3622
	old_data_grads_norm = 4.0837
	sim_grads_norm_tr = 0.1992
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2157
	data_grads_norm = 2.2659
	new_data_grads_norm = 4.0825
	old_data_grads_norm = 3.1231
	sim_grads_norm_tr = -0.0588
-- Starting training on experience 145 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5984
	data_grads_norm = 3.1516
	new_data_grads_norm = 5.2142
	old_data_grads_norm = 3.7200
	sim_grads_norm_tr = 0.1826
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5939
	data_grads_norm = 3.6575
	new_data_grads_norm = 6.3682
	old_data_grads_norm = 2.9535
	sim_grads_norm_tr = -0.0115
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5230
	data_grads_norm = 3.6714
	new_data_grads_norm = 5.5207
	old_data_grads_norm = 4.4087
	sim_grads_norm_tr = 0.0331
-- Starting training on experience 146 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7659
	data_grads_norm = 6.0877
	new_data_grads_norm = 8.8707
	old_data_grads_norm = 5.2602
	sim_grads_norm_tr = 0.1820
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4706
	data_grads_norm = 4.1124
	new_data_grads_norm = 6.3347
	old_data_grads_norm = 4.2526
	sim_grads_norm_tr = 0.0842
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7051
	data_grads_norm = 4.1197
	new_data_grads_norm = 6.9350
	old_data_grads_norm = 6.1168
	sim_grads_norm_tr = -0.0319
-- Starting training on experience 147 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5248
	data_grads_norm = 4.2828
	new_data_grads_norm = 6.0132
	old_data_grads_norm = 4.6298
	sim_grads_norm_tr = 0.2300
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7287
	data_grads_norm = 3.7608
	new_data_grads_norm = 5.2918
	old_data_grads_norm = 5.5994
	sim_grads_norm_tr = 0.1256
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3425
	data_grads_norm = 2.8016
	new_data_grads_norm = 4.8873
	old_data_grads_norm = 3.6749
	sim_grads_norm_tr = -0.0014
-- Starting training on experience 148 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9468
	data_grads_norm = 3.6186
	new_data_grads_norm = 5.2894
	old_data_grads_norm = 4.7009
	sim_grads_norm_tr = 0.1648
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6503
	data_grads_norm = 3.6331
	new_data_grads_norm = 4.8600
	old_data_grads_norm = 3.3239
	sim_grads_norm_tr = 0.3051
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5618
	data_grads_norm = 3.3862
	new_data_grads_norm = 4.8297
	old_data_grads_norm = 4.4190
	sim_grads_norm_tr = 0.0190
-- Starting training on experience 149 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5593
	data_grads_norm = 3.1587
	new_data_grads_norm = 4.5037
	old_data_grads_norm = 4.7542
	sim_grads_norm_tr = 0.0857
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8860
	data_grads_norm = 4.4914
	new_data_grads_norm = 4.6625
	old_data_grads_norm = 6.6249
	sim_grads_norm_tr = 0.0721
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8411
	data_grads_norm = 3.8839
	new_data_grads_norm = 5.1696
	old_data_grads_norm = 4.8362
	sim_grads_norm_tr = -0.0052
-- Starting training on experience 150 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7203
	data_grads_norm = 3.6001
	new_data_grads_norm = 5.6559
	old_data_grads_norm = 3.5770
	sim_grads_norm_tr = 0.0042
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4106
	data_grads_norm = 3.2708
	new_data_grads_norm = 5.9679
	old_data_grads_norm = 2.8441
	sim_grads_norm_tr = 0.0200
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5864
	data_grads_norm = 3.1500
	new_data_grads_norm = 5.6751
	old_data_grads_norm = 3.5076
	sim_grads_norm_tr = 0.1258
-- Starting training on experience 151 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4042
	data_grads_norm = 2.7348
	new_data_grads_norm = 4.3345
	old_data_grads_norm = 4.6748
	sim_grads_norm_tr = -0.0878
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4868
	data_grads_norm = 2.9880
	new_data_grads_norm = 4.5303
	old_data_grads_norm = 4.4610
	sim_grads_norm_tr = 0.1108
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8865
	data_grads_norm = 3.8156
	new_data_grads_norm = 4.9507
	old_data_grads_norm = 4.7781
	sim_grads_norm_tr = 0.0923
-- Starting training on experience 152 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4974
	data_grads_norm = 2.8448
	new_data_grads_norm = 4.3052
	old_data_grads_norm = 5.4078
	sim_grads_norm_tr = -0.1641
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2278
	data_grads_norm = 2.3456
	new_data_grads_norm = 4.6567
	old_data_grads_norm = 2.5062
	sim_grads_norm_tr = -0.0924
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4970
	data_grads_norm = 2.7614
	new_data_grads_norm = 4.8477
	old_data_grads_norm = 2.6362
	sim_grads_norm_tr = 0.1483
-- Starting training on experience 153 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3411
	data_grads_norm = 2.7425
	new_data_grads_norm = 4.3300
	old_data_grads_norm = 3.8407
	sim_grads_norm_tr = -0.0105
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8267
	data_grads_norm = 3.0342
	new_data_grads_norm = 4.2573
	old_data_grads_norm = 5.0230
	sim_grads_norm_tr = 0.0020
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5873
	data_grads_norm = 2.9488
	new_data_grads_norm = 4.7303
	old_data_grads_norm = 4.3559
	sim_grads_norm_tr = 0.0415
-- Starting training on experience 154 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3441
	data_grads_norm = 2.0311
	new_data_grads_norm = 4.0777
	old_data_grads_norm = 3.3946
	sim_grads_norm_tr = -0.2079
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4734
	data_grads_norm = 3.4321
	new_data_grads_norm = 5.0850
	old_data_grads_norm = 4.5200
	sim_grads_norm_tr = -0.0236
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3393
	data_grads_norm = 2.8514
	new_data_grads_norm = 4.8314
	old_data_grads_norm = 2.7981
	sim_grads_norm_tr = -0.1702
-- Starting training on experience 155 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7276
	data_grads_norm = 3.2547
	new_data_grads_norm = 5.0115
	old_data_grads_norm = 3.3724
	sim_grads_norm_tr = 0.2308
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5479
	data_grads_norm = 3.3155
	new_data_grads_norm = 4.7344
	old_data_grads_norm = 4.2795
	sim_grads_norm_tr = 0.1120
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5302
	data_grads_norm = 3.4506
	new_data_grads_norm = 4.9595
	old_data_grads_norm = 4.1128
	sim_grads_norm_tr = 0.2184
-- Starting training on experience 156 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2640
	data_grads_norm = 2.6166
	new_data_grads_norm = 3.4648
	old_data_grads_norm = 4.8552
	sim_grads_norm_tr = -0.0572
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1299
	data_grads_norm = 2.5315
	new_data_grads_norm = 3.9332
	old_data_grads_norm = 4.1406
	sim_grads_norm_tr = 0.0132
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4036
	data_grads_norm = 2.8371
	new_data_grads_norm = 4.1843
	old_data_grads_norm = 3.6627
	sim_grads_norm_tr = 0.0947
-- Starting training on experience 157 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4550
	data_grads_norm = 2.5963
	new_data_grads_norm = 4.0965
	old_data_grads_norm = 4.0115
	sim_grads_norm_tr = -0.1738
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4018
	data_grads_norm = 2.8527
	new_data_grads_norm = 4.2753
	old_data_grads_norm = 3.6753
	sim_grads_norm_tr = 0.0348
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4416
	data_grads_norm = 2.8849
	new_data_grads_norm = 4.5626
	old_data_grads_norm = 4.6349
	sim_grads_norm_tr = 0.2341
-- Starting training on experience 158 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4628
	data_grads_norm = 2.7510
	new_data_grads_norm = 4.0533
	old_data_grads_norm = 3.8782
	sim_grads_norm_tr = 0.2901
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1529
	data_grads_norm = 2.7644
	new_data_grads_norm = 4.0016
	old_data_grads_norm = 3.0723
	sim_grads_norm_tr = 0.0797
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3930
	data_grads_norm = 2.7074
	new_data_grads_norm = 4.0807
	old_data_grads_norm = 4.2174
	sim_grads_norm_tr = -0.1570
-- Starting training on experience 159 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5442
	data_grads_norm = 3.5638
	new_data_grads_norm = 4.7702
	old_data_grads_norm = 3.9561
	sim_grads_norm_tr = 0.0706
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3450
	data_grads_norm = 2.2924
	new_data_grads_norm = 4.0438
	old_data_grads_norm = 2.4148
	sim_grads_norm_tr = -0.1293
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3995
	data_grads_norm = 2.6565
	new_data_grads_norm = 4.5199
	old_data_grads_norm = 4.5677
	sim_grads_norm_tr = -0.1448
-- Starting training on experience 160 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5222
	data_grads_norm = 3.7012
	new_data_grads_norm = 4.9771
	old_data_grads_norm = 4.9608
	sim_grads_norm_tr = 0.1876
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5559
	data_grads_norm = 2.9744
	new_data_grads_norm = 4.2231
	old_data_grads_norm = 3.5260
	sim_grads_norm_tr = 0.1693
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4356
	data_grads_norm = 2.4300
	new_data_grads_norm = 4.4458
	old_data_grads_norm = 3.5235
	sim_grads_norm_tr = -0.0834
-- Starting training on experience 161 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6178
	data_grads_norm = 3.6411
	new_data_grads_norm = 5.2479
	old_data_grads_norm = 4.3092
	sim_grads_norm_tr = 0.2376
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4976
	data_grads_norm = 2.9225
	new_data_grads_norm = 5.3966
	old_data_grads_norm = 3.9601
	sim_grads_norm_tr = -0.0193
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3366
	data_grads_norm = 2.6706
	new_data_grads_norm = 5.6584
	old_data_grads_norm = 4.6571
	sim_grads_norm_tr = -0.2270
-- Starting training on experience 162 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9438
	data_grads_norm = 4.3980
	new_data_grads_norm = 7.0080
	old_data_grads_norm = 4.3958
	sim_grads_norm_tr = 0.2805
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2722
	data_grads_norm = 3.6147
	new_data_grads_norm = 4.9413
	old_data_grads_norm = 3.2598
	sim_grads_norm_tr = 0.1957
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9527
	data_grads_norm = 2.1500
	new_data_grads_norm = 6.8186
	old_data_grads_norm = 2.3550
	sim_grads_norm_tr = -0.1255
-- Starting training on experience 163 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4892
	data_grads_norm = 3.5693
	new_data_grads_norm = 5.0271
	old_data_grads_norm = 4.1861
	sim_grads_norm_tr = 0.0217
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2455
	data_grads_norm = 3.1303
	new_data_grads_norm = 4.8631
	old_data_grads_norm = 3.2791
	sim_grads_norm_tr = 0.0316
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2515
	data_grads_norm = 3.0729
	new_data_grads_norm = 4.8521
	old_data_grads_norm = 2.5056
	sim_grads_norm_tr = 0.2465
-- Starting training on experience 164 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6716
	data_grads_norm = 4.5639
	new_data_grads_norm = 7.2036
	old_data_grads_norm = 4.7243
	sim_grads_norm_tr = 0.0755
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1529
	data_grads_norm = 4.1372
	new_data_grads_norm = 5.9643
	old_data_grads_norm = 4.5455
	sim_grads_norm_tr = 0.0822
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9413
	data_grads_norm = 4.7980
	new_data_grads_norm = 6.6383
	old_data_grads_norm = 5.0291
	sim_grads_norm_tr = 0.0745
-- Starting training on experience 165 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4572
	data_grads_norm = 3.1968
	new_data_grads_norm = 5.2491
	old_data_grads_norm = 3.4060
	sim_grads_norm_tr = -0.1347
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5654
	data_grads_norm = 2.8386
	new_data_grads_norm = 5.0616
	old_data_grads_norm = 3.8745
	sim_grads_norm_tr = -0.0405
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5369
	data_grads_norm = 3.4581
	new_data_grads_norm = 5.4825
	old_data_grads_norm = 3.5417
	sim_grads_norm_tr = 0.2745
-- Starting training on experience 166 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8371
	data_grads_norm = 3.5639
	new_data_grads_norm = 6.2686
	old_data_grads_norm = 5.1783
	sim_grads_norm_tr = 0.1195
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4481
	data_grads_norm = 2.9704
	new_data_grads_norm = 5.4957
	old_data_grads_norm = 3.2052
	sim_grads_norm_tr = -0.1065
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7805
	data_grads_norm = 3.3124
	new_data_grads_norm = 5.3668
	old_data_grads_norm = 4.7845
	sim_grads_norm_tr = -0.0864
-- Starting training on experience 167 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7349
	data_grads_norm = 3.1809
	new_data_grads_norm = 4.0562
	old_data_grads_norm = 5.1021
	sim_grads_norm_tr = -0.0771
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4780
	data_grads_norm = 2.7061
	new_data_grads_norm = 3.7654
	old_data_grads_norm = 3.6161
	sim_grads_norm_tr = -0.0015
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4022
	data_grads_norm = 2.8539
	new_data_grads_norm = 4.2011
	old_data_grads_norm = 3.7018
	sim_grads_norm_tr = 0.0894
-- Starting training on experience 168 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7278
	data_grads_norm = 3.3719
	new_data_grads_norm = 5.5262
	old_data_grads_norm = 3.8110
	sim_grads_norm_tr = 0.1256
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7139
	data_grads_norm = 2.9480
	new_data_grads_norm = 5.0558
	old_data_grads_norm = 2.6274
	sim_grads_norm_tr = 0.0673
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7223
	data_grads_norm = 3.2531
	new_data_grads_norm = 4.7948
	old_data_grads_norm = 4.8878
	sim_grads_norm_tr = 0.0708
-- Starting training on experience 169 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8032
	data_grads_norm = 3.0782
	new_data_grads_norm = 7.0720
	old_data_grads_norm = 4.1456
	sim_grads_norm_tr = -0.0919
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7526
	data_grads_norm = 4.4254
	new_data_grads_norm = 7.6976
	old_data_grads_norm = 3.7866
	sim_grads_norm_tr = 0.0747
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9053
	data_grads_norm = 4.0362
	new_data_grads_norm = 6.7374
	old_data_grads_norm = 4.8973
	sim_grads_norm_tr = 0.0351
-- Starting training on experience 170 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6398
	data_grads_norm = 4.2876
	new_data_grads_norm = 6.0104
	old_data_grads_norm = 4.0381
	sim_grads_norm_tr = 0.2399
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8566
	data_grads_norm = 3.8302
	new_data_grads_norm = 4.8693
	old_data_grads_norm = 4.7916
	sim_grads_norm_tr = 0.0576
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2585
	data_grads_norm = 3.2436
	new_data_grads_norm = 5.6368
	old_data_grads_norm = 2.9899
	sim_grads_norm_tr = 0.0138
-- Starting training on experience 171 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2759
	data_grads_norm = 3.1948
	new_data_grads_norm = 6.4620
	old_data_grads_norm = 4.5582
	sim_grads_norm_tr = -0.1042
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7334
	data_grads_norm = 4.5469
	new_data_grads_norm = 7.5104
	old_data_grads_norm = 4.4528
	sim_grads_norm_tr = 0.2260
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7033
	data_grads_norm = 4.7595
	new_data_grads_norm = 5.5447
	old_data_grads_norm = 6.0577
	sim_grads_norm_tr = 0.3004
-- Starting training on experience 172 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6888
	data_grads_norm = 4.0429
	new_data_grads_norm = 7.3916
	old_data_grads_norm = 5.1682
	sim_grads_norm_tr = 0.2181
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7667
	data_grads_norm = 4.8415
	new_data_grads_norm = 6.5605
	old_data_grads_norm = 5.3571
	sim_grads_norm_tr = 0.1498
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8107
	data_grads_norm = 4.4527
	new_data_grads_norm = 6.8980
	old_data_grads_norm = 4.3619
	sim_grads_norm_tr = -0.1225
-- Starting training on experience 173 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5490
	data_grads_norm = 3.1247
	new_data_grads_norm = 3.8729
	old_data_grads_norm = 4.4291
	sim_grads_norm_tr = 0.3126
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3505
	data_grads_norm = 2.6199
	new_data_grads_norm = 3.5369
	old_data_grads_norm = 5.1932
	sim_grads_norm_tr = -0.1603
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3626
	data_grads_norm = 2.6189
	new_data_grads_norm = 3.9591
	old_data_grads_norm = 3.1099
	sim_grads_norm_tr = 0.1367
-- Starting training on experience 174 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9908
	data_grads_norm = 2.9641
	new_data_grads_norm = 4.9084
	old_data_grads_norm = 2.8065
	sim_grads_norm_tr = 0.2762
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2064
	data_grads_norm = 3.5621
	new_data_grads_norm = 4.6045
	old_data_grads_norm = 3.9758
	sim_grads_norm_tr = 0.3311
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9514
	data_grads_norm = 2.4084
	new_data_grads_norm = 4.2820
	old_data_grads_norm = 3.0682
	sim_grads_norm_tr = 0.0668
-- Starting training on experience 175 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1876
	data_grads_norm = 2.8396
	new_data_grads_norm = 3.9891
	old_data_grads_norm = 3.5571
	sim_grads_norm_tr = 0.0228
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3329
	data_grads_norm = 3.4026
	new_data_grads_norm = 4.4596
	old_data_grads_norm = 5.5878
	sim_grads_norm_tr = -0.1143
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6400
	data_grads_norm = 3.3698
	new_data_grads_norm = 5.3078
	old_data_grads_norm = 4.3691
	sim_grads_norm_tr = -0.0301
-- Starting training on experience 176 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1720
	data_grads_norm = 3.1832
	new_data_grads_norm = 5.3825
	old_data_grads_norm = 3.5177
	sim_grads_norm_tr = 0.1635
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1940
	data_grads_norm = 3.8801
	new_data_grads_norm = 4.7024
	old_data_grads_norm = 5.3979
	sim_grads_norm_tr = 0.2183
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3352
	data_grads_norm = 2.9966
	new_data_grads_norm = 3.8454
	old_data_grads_norm = 4.3213
	sim_grads_norm_tr = 0.2663
-- Starting training on experience 177 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3375
	data_grads_norm = 2.8541
	new_data_grads_norm = 4.2242
	old_data_grads_norm = 4.1220
	sim_grads_norm_tr = -0.0911
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6497
	data_grads_norm = 3.4716
	new_data_grads_norm = 4.2469
	old_data_grads_norm = 5.3709
	sim_grads_norm_tr = -0.0152
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5026
	data_grads_norm = 3.5194
	new_data_grads_norm = 4.8776
	old_data_grads_norm = 4.6668
	sim_grads_norm_tr = 0.0559
-- Starting training on experience 178 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4116
	data_grads_norm = 3.1278
	new_data_grads_norm = 3.6391
	old_data_grads_norm = 5.5394
	sim_grads_norm_tr = 0.1905
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3084
	data_grads_norm = 2.8391
	new_data_grads_norm = 3.6403
	old_data_grads_norm = 5.3016
	sim_grads_norm_tr = 0.0662
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6214
	data_grads_norm = 2.9018
	new_data_grads_norm = 4.0957
	old_data_grads_norm = 5.5077
	sim_grads_norm_tr = -0.1484
-- Starting training on experience 179 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3432
	data_grads_norm = 2.6503
	new_data_grads_norm = 3.4574
	old_data_grads_norm = 4.4851
	sim_grads_norm_tr = 0.1000
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1770
	data_grads_norm = 2.7805
	new_data_grads_norm = 3.8189
	old_data_grads_norm = 4.5912
	sim_grads_norm_tr = 0.0304
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0914
	data_grads_norm = 2.0995
	new_data_grads_norm = 3.5472
	old_data_grads_norm = 3.0942
	sim_grads_norm_tr = -0.0827
-- Starting training on experience 180 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5200
	data_grads_norm = 3.3127
	new_data_grads_norm = 4.7951
	old_data_grads_norm = 4.5049
	sim_grads_norm_tr = 0.0532
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1160
	data_grads_norm = 2.9930
	new_data_grads_norm = 5.2943
	old_data_grads_norm = 3.2130
	sim_grads_norm_tr = 0.2310
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1555
	data_grads_norm = 2.4283
	new_data_grads_norm = 3.9339
	old_data_grads_norm = 2.7983
	sim_grads_norm_tr = 0.0413
-- Starting training on experience 181 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4121
	data_grads_norm = 2.8629
	new_data_grads_norm = 4.2422
	old_data_grads_norm = 3.6794
	sim_grads_norm_tr = 0.0205
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4119
	data_grads_norm = 2.9375
	new_data_grads_norm = 4.7425
	old_data_grads_norm = 5.4205
	sim_grads_norm_tr = -0.0497
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6791
	data_grads_norm = 2.9984
	new_data_grads_norm = 4.8267
	old_data_grads_norm = 3.2056
	sim_grads_norm_tr = 0.0805
-- Starting training on experience 182 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3289
	data_grads_norm = 3.2891
	new_data_grads_norm = 4.3854
	old_data_grads_norm = 3.8272
	sim_grads_norm_tr = 0.1895
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4065
	data_grads_norm = 3.4526
	new_data_grads_norm = 4.0141
	old_data_grads_norm = 5.7601
	sim_grads_norm_tr = 0.0679
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2712
	data_grads_norm = 3.2527
	new_data_grads_norm = 4.8090
	old_data_grads_norm = 4.7407
	sim_grads_norm_tr = 0.0664
-- Starting training on experience 183 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6278
	data_grads_norm = 3.9000
	new_data_grads_norm = 6.1247
	old_data_grads_norm = 4.3272
	sim_grads_norm_tr = -0.0253
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8325
	data_grads_norm = 4.5217
	new_data_grads_norm = 6.2063
	old_data_grads_norm = 4.7593
	sim_grads_norm_tr = 0.2625
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5397
	data_grads_norm = 3.6028
	new_data_grads_norm = 5.6578
	old_data_grads_norm = 4.8752
	sim_grads_norm_tr = 0.0404
-- Starting training on experience 184 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4722
	data_grads_norm = 3.8420
	new_data_grads_norm = 4.1896
	old_data_grads_norm = 6.2313
	sim_grads_norm_tr = 0.4894
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9888
	data_grads_norm = 2.1221
	new_data_grads_norm = 2.5358
	old_data_grads_norm = 4.7264
	sim_grads_norm_tr = 0.0765
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0482
	data_grads_norm = 2.0688
	new_data_grads_norm = 2.8172
	old_data_grads_norm = 4.5638
	sim_grads_norm_tr = -0.1563
-- Starting training on experience 185 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3362
	data_grads_norm = 3.3180
	new_data_grads_norm = 5.5389
	old_data_grads_norm = 4.0527
	sim_grads_norm_tr = -0.0740
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5751
	data_grads_norm = 3.3550
	new_data_grads_norm = 5.1855
	old_data_grads_norm = 5.6617
	sim_grads_norm_tr = -0.1452
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4490
	data_grads_norm = 5.5799
	new_data_grads_norm = 7.0204
	old_data_grads_norm = 5.7359
	sim_grads_norm_tr = 0.5073
-- Starting training on experience 186 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3139
	data_grads_norm = 2.8834
	new_data_grads_norm = 4.1587
	old_data_grads_norm = 4.4968
	sim_grads_norm_tr = 0.0598
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1416
	data_grads_norm = 3.0241
	new_data_grads_norm = 4.6419
	old_data_grads_norm = 3.6873
	sim_grads_norm_tr = -0.0281
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2541
	data_grads_norm = 2.7897
	new_data_grads_norm = 4.4718
	old_data_grads_norm = 3.3087
	sim_grads_norm_tr = -0.0597
-- Starting training on experience 187 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3898
	data_grads_norm = 3.3911
	new_data_grads_norm = 5.5717
	old_data_grads_norm = 4.5207
	sim_grads_norm_tr = 0.0425
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0271
	data_grads_norm = 4.6804
	new_data_grads_norm = 5.6420
	old_data_grads_norm = 6.4571
	sim_grads_norm_tr = 0.0880
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6720
	data_grads_norm = 3.8205
	new_data_grads_norm = 4.8665
	old_data_grads_norm = 5.4316
	sim_grads_norm_tr = 0.0600
-- Starting training on experience 188 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0350
	data_grads_norm = 2.1231
	new_data_grads_norm = 4.3478
	old_data_grads_norm = 3.1045
	sim_grads_norm_tr = -0.1901
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4593
	data_grads_norm = 3.5124
	new_data_grads_norm = 5.6349
	old_data_grads_norm = 4.4150
	sim_grads_norm_tr = 0.1891
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0326
	data_grads_norm = 3.0632
	new_data_grads_norm = 4.7227
	old_data_grads_norm = 3.2405
	sim_grads_norm_tr = 0.1795
-- Starting training on experience 189 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2867
	data_grads_norm = 2.8329
	new_data_grads_norm = 3.8912
	old_data_grads_norm = 4.6361
	sim_grads_norm_tr = -0.0082
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2956
	data_grads_norm = 3.1516
	new_data_grads_norm = 3.9286
	old_data_grads_norm = 4.4457
	sim_grads_norm_tr = 0.1841
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0009
	data_grads_norm = 2.6424
	new_data_grads_norm = 3.1394
	old_data_grads_norm = 3.8576
	sim_grads_norm_tr = 0.0074
-- Starting training on experience 190 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5788
	data_grads_norm = 3.0933
	new_data_grads_norm = 5.1752
	old_data_grads_norm = 4.9218
	sim_grads_norm_tr = -0.0021
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5476
	data_grads_norm = 3.2393
	new_data_grads_norm = 5.2411
	old_data_grads_norm = 5.4765
	sim_grads_norm_tr = -0.2026
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9884
	data_grads_norm = 4.7887
	new_data_grads_norm = 6.4462
	old_data_grads_norm = 5.4510
	sim_grads_norm_tr = 0.3652
-- Starting training on experience 191 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3606
	data_grads_norm = 3.9229
	new_data_grads_norm = 6.5520
	old_data_grads_norm = 4.4165
	sim_grads_norm_tr = 0.0372
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9384
	data_grads_norm = 5.4452
	new_data_grads_norm = 6.1695
	old_data_grads_norm = 7.0296
	sim_grads_norm_tr = 0.4267
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2339
	data_grads_norm = 3.1003
	new_data_grads_norm = 4.2260
	old_data_grads_norm = 4.6670
	sim_grads_norm_tr = 0.2158
-- Starting training on experience 192 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2031
	data_grads_norm = 2.8266
	new_data_grads_norm = 5.4832
	old_data_grads_norm = 3.8839
	sim_grads_norm_tr = -0.1552
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6816
	data_grads_norm = 4.8078
	new_data_grads_norm = 7.2694
	old_data_grads_norm = 4.7828
	sim_grads_norm_tr = 0.2734
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1850
	data_grads_norm = 3.7153
	new_data_grads_norm = 5.7356
	old_data_grads_norm = 4.4547
	sim_grads_norm_tr = 0.1227
-- Starting training on experience 193 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5331
	data_grads_norm = 3.9033
	new_data_grads_norm = 5.6759
	old_data_grads_norm = 4.5419
	sim_grads_norm_tr = 0.0053
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5394
	data_grads_norm = 4.5621
	new_data_grads_norm = 5.5353
	old_data_grads_norm = 6.3249
	sim_grads_norm_tr = 0.2917
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0964
	data_grads_norm = 2.8835
	new_data_grads_norm = 4.5536
	old_data_grads_norm = 3.8073
	sim_grads_norm_tr = -0.0194
-- Starting training on experience 194 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7708
	data_grads_norm = 4.2002
	new_data_grads_norm = 7.6170
	old_data_grads_norm = 3.7878
	sim_grads_norm_tr = 0.0752
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5672
	data_grads_norm = 3.9668
	new_data_grads_norm = 6.3300
	old_data_grads_norm = 3.4921
	sim_grads_norm_tr = 0.2181
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3429
	data_grads_norm = 3.8245
	new_data_grads_norm = 7.1265
	old_data_grads_norm = 3.9430
	sim_grads_norm_tr = -0.0294
-- Starting training on experience 195 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5367
	data_grads_norm = 3.5047
	new_data_grads_norm = 4.4428
	old_data_grads_norm = 7.4702
	sim_grads_norm_tr = 0.0674
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6397
	data_grads_norm = 3.2989
	new_data_grads_norm = 4.6436
	old_data_grads_norm = 3.9839
	sim_grads_norm_tr = 0.1949
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2763
	data_grads_norm = 3.1123
	new_data_grads_norm = 3.7744
	old_data_grads_norm = 4.1186
	sim_grads_norm_tr = 0.1846
-- Starting training on experience 196 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2291
	data_grads_norm = 3.2807
	new_data_grads_norm = 4.4691
	old_data_grads_norm = 4.1853
	sim_grads_norm_tr = -0.0814
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4518
	data_grads_norm = 3.4027
	new_data_grads_norm = 5.2091
	old_data_grads_norm = 5.0687
	sim_grads_norm_tr = 0.0735
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3103
	data_grads_norm = 2.9417
	new_data_grads_norm = 4.6922
	old_data_grads_norm = 4.7947
	sim_grads_norm_tr = 0.0642
-- Starting training on experience 197 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5294
	data_grads_norm = 2.9370
	new_data_grads_norm = 5.7300
	old_data_grads_norm = 4.8455
	sim_grads_norm_tr = 0.0797
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6087
	data_grads_norm = 3.3948
	new_data_grads_norm = 7.7473
	old_data_grads_norm = 4.7634
	sim_grads_norm_tr = 0.1040
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4580
	data_grads_norm = 3.3220
	new_data_grads_norm = 7.2038
	old_data_grads_norm = 3.1223
	sim_grads_norm_tr = 0.0124
-- Starting training on experience 198 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3415
	data_grads_norm = 2.9342
	new_data_grads_norm = 4.1010
	old_data_grads_norm = 3.5250
	sim_grads_norm_tr = 0.0560
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4115
	data_grads_norm = 2.6686
	new_data_grads_norm = 4.4690
	old_data_grads_norm = 3.8023
	sim_grads_norm_tr = -0.0354
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4069
	data_grads_norm = 2.6612
	new_data_grads_norm = 4.4730
	old_data_grads_norm = 4.0385
	sim_grads_norm_tr = -0.1395
-- Starting training on experience 199 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0641
	data_grads_norm = 2.8525
	new_data_grads_norm = 5.3267
	old_data_grads_norm = 2.5590
	sim_grads_norm_tr = 0.0200
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1351
	data_grads_norm = 2.6451
	new_data_grads_norm = 4.5449
	old_data_grads_norm = 2.8988
	sim_grads_norm_tr = 0.1054
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3348
	data_grads_norm = 3.5200
	new_data_grads_norm = 5.3412
	old_data_grads_norm = 3.5086
	sim_grads_norm_tr = 0.0338
-- Starting training on experience 200 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5929
	data_grads_norm = 3.9846
	new_data_grads_norm = 5.6147
	old_data_grads_norm = 4.8828
	sim_grads_norm_tr = 0.2961
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0815
	data_grads_norm = 3.2563
	new_data_grads_norm = 4.5636
	old_data_grads_norm = 4.0715
	sim_grads_norm_tr = -0.0379
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4668
	data_grads_norm = 3.1454
	new_data_grads_norm = 4.6210
	old_data_grads_norm = 4.5751
	sim_grads_norm_tr = 0.2338
-- Starting training on experience 201 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6887
	data_grads_norm = 3.6207
	new_data_grads_norm = 6.4269
	old_data_grads_norm = 4.7161
	sim_grads_norm_tr = 0.1738
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0029
	data_grads_norm = 4.1142
	new_data_grads_norm = 5.5393
	old_data_grads_norm = 5.1048
	sim_grads_norm_tr = 0.0387
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8833
	data_grads_norm = 3.8110
	new_data_grads_norm = 5.5375
	old_data_grads_norm = 5.0875
	sim_grads_norm_tr = 0.0694
-- Starting training on experience 202 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1841
	data_grads_norm = 3.5838
	new_data_grads_norm = 5.1214
	old_data_grads_norm = 3.2865
	sim_grads_norm_tr = 0.2636
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4705
	data_grads_norm = 3.0807
	new_data_grads_norm = 4.9388
	old_data_grads_norm = 4.6207
	sim_grads_norm_tr = -0.0257
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1739
	data_grads_norm = 2.7738
	new_data_grads_norm = 4.7595
	old_data_grads_norm = 2.8658
	sim_grads_norm_tr = -0.0409
-- Starting training on experience 203 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3454
	data_grads_norm = 3.8665
	new_data_grads_norm = 4.5676
	old_data_grads_norm = 5.6154
	sim_grads_norm_tr = 0.1783
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3930
	data_grads_norm = 2.9672
	new_data_grads_norm = 3.7937
	old_data_grads_norm = 4.0039
	sim_grads_norm_tr = -0.0275
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0756
	data_grads_norm = 2.4383
	new_data_grads_norm = 3.9610
	old_data_grads_norm = 2.4060
	sim_grads_norm_tr = 0.2441
-- Starting training on experience 204 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3565
	data_grads_norm = 3.3832
	new_data_grads_norm = 6.4182
	old_data_grads_norm = 2.8422
	sim_grads_norm_tr = 0.1619
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2918
	data_grads_norm = 3.5839
	new_data_grads_norm = 5.2808
	old_data_grads_norm = 4.8857
	sim_grads_norm_tr = 0.0076
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5594
	data_grads_norm = 4.0473
	new_data_grads_norm = 6.8542
	old_data_grads_norm = 5.1468
	sim_grads_norm_tr = -0.0813
-- Starting training on experience 205 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6395
	data_grads_norm = 4.8022
	new_data_grads_norm = 6.6177
	old_data_grads_norm = 5.4905
	sim_grads_norm_tr = 0.3660
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0697
	data_grads_norm = 2.9313
	new_data_grads_norm = 4.4958
	old_data_grads_norm = 4.1835
	sim_grads_norm_tr = -0.0161
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1892
	data_grads_norm = 2.6545
	new_data_grads_norm = 4.7256
	old_data_grads_norm = 3.6907
	sim_grads_norm_tr = -0.1062
-- Starting training on experience 206 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3267
	data_grads_norm = 2.6691
	new_data_grads_norm = 3.6276
	old_data_grads_norm = 4.1317
	sim_grads_norm_tr = -0.1467
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4225
	data_grads_norm = 3.2442
	new_data_grads_norm = 4.5227
	old_data_grads_norm = 4.5169
	sim_grads_norm_tr = 0.1684
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3178
	data_grads_norm = 3.0338
	new_data_grads_norm = 4.5187
	old_data_grads_norm = 3.3558
	sim_grads_norm_tr = -0.0104
-- Starting training on experience 207 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0427
	data_grads_norm = 2.7308
	new_data_grads_norm = 5.1400
	old_data_grads_norm = 4.5066
	sim_grads_norm_tr = -0.1692
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7051
	data_grads_norm = 4.3753
	new_data_grads_norm = 6.1053
	old_data_grads_norm = 5.8904
	sim_grads_norm_tr = -0.0989
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6305
	data_grads_norm = 5.3356
	new_data_grads_norm = 6.9972
	old_data_grads_norm = 6.5498
	sim_grads_norm_tr = 0.4026
-- Starting training on experience 208 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5705
	data_grads_norm = 2.8527
	new_data_grads_norm = 3.9733
	old_data_grads_norm = 5.0655
	sim_grads_norm_tr = -0.0577
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1436
	data_grads_norm = 2.6947
	new_data_grads_norm = 4.6714
	old_data_grads_norm = 2.9600
	sim_grads_norm_tr = 0.1474
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5347
	data_grads_norm = 3.6488
	new_data_grads_norm = 4.4792
	old_data_grads_norm = 6.2873
	sim_grads_norm_tr = 0.0090
-- Starting training on experience 209 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0478
	data_grads_norm = 2.4144
	new_data_grads_norm = 6.0373
	old_data_grads_norm = 3.3153
	sim_grads_norm_tr = -0.1579
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7068
	data_grads_norm = 4.0435
	new_data_grads_norm = 6.4573
	old_data_grads_norm = 5.0429
	sim_grads_norm_tr = 0.0573
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5718
	data_grads_norm = 3.8266
	new_data_grads_norm = 6.3306
	old_data_grads_norm = 5.8538
	sim_grads_norm_tr = 0.0637
-- Starting training on experience 210 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0817
	data_grads_norm = 3.3563
	new_data_grads_norm = 5.4774
	old_data_grads_norm = 4.0471
	sim_grads_norm_tr = 0.0548
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0687
	data_grads_norm = 3.2274
	new_data_grads_norm = 5.7136
	old_data_grads_norm = 4.3033
	sim_grads_norm_tr = 0.0400
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1554
	data_grads_norm = 2.8047
	new_data_grads_norm = 6.0588
	old_data_grads_norm = 3.5542
	sim_grads_norm_tr = -0.1003
-- Starting training on experience 211 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4207
	data_grads_norm = 3.5085
	new_data_grads_norm = 6.8639
	old_data_grads_norm = 4.2577
	sim_grads_norm_tr = 0.0523
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3839
	data_grads_norm = 3.4608
	new_data_grads_norm = 6.6892
	old_data_grads_norm = 4.3933
	sim_grads_norm_tr = 0.1313
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2799
	data_grads_norm = 3.2070
	new_data_grads_norm = 6.6166
	old_data_grads_norm = 4.5591
	sim_grads_norm_tr = -0.0603
-- Starting training on experience 212 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2160
	data_grads_norm = 3.5235
	new_data_grads_norm = 4.4449
	old_data_grads_norm = 4.8973
	sim_grads_norm_tr = 0.1033
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1845
	data_grads_norm = 2.9785
	new_data_grads_norm = 3.9949
	old_data_grads_norm = 3.5015
	sim_grads_norm_tr = 0.0798
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1425
	data_grads_norm = 3.6498
	new_data_grads_norm = 4.7392
	old_data_grads_norm = 5.0701
	sim_grads_norm_tr = 0.0035
-- Starting training on experience 213 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1670
	data_grads_norm = 2.5302
	new_data_grads_norm = 4.2698
	old_data_grads_norm = 6.6483
	sim_grads_norm_tr = -0.0156
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5764
	data_grads_norm = 4.2886
	new_data_grads_norm = 5.3472
	old_data_grads_norm = 5.2771
	sim_grads_norm_tr = 0.0172
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5741
	data_grads_norm = 4.1212
	new_data_grads_norm = 5.6286
	old_data_grads_norm = 4.4634
	sim_grads_norm_tr = 0.1270
-- Starting training on experience 214 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1582
	data_grads_norm = 3.6519
	new_data_grads_norm = 5.7216
	old_data_grads_norm = 5.0014
	sim_grads_norm_tr = -0.1243
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7255
	data_grads_norm = 5.2970
	new_data_grads_norm = 6.1508
	old_data_grads_norm = 6.9362
	sim_grads_norm_tr = 0.1628
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1759
	data_grads_norm = 3.4421
	new_data_grads_norm = 5.3225
	old_data_grads_norm = 5.1101
	sim_grads_norm_tr = -0.0590
-- Starting training on experience 215 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4210
	data_grads_norm = 3.5632
	new_data_grads_norm = 4.4323
	old_data_grads_norm = 5.0254
	sim_grads_norm_tr = 0.0202
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5911
	data_grads_norm = 4.0444
	new_data_grads_norm = 6.4182
	old_data_grads_norm = 5.0528
	sim_grads_norm_tr = 0.2300
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1562
	data_grads_norm = 3.3008
	new_data_grads_norm = 4.5648
	old_data_grads_norm = 5.1460
	sim_grads_norm_tr = -0.0906
-- Starting training on experience 216 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4191
	data_grads_norm = 3.4526
	new_data_grads_norm = 5.4569
	old_data_grads_norm = 4.0000
	sim_grads_norm_tr = 0.0875
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4977
	data_grads_norm = 3.7846
	new_data_grads_norm = 5.3414
	old_data_grads_norm = 6.0353
	sim_grads_norm_tr = 0.2228
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4522
	data_grads_norm = 3.1919
	new_data_grads_norm = 4.3010
	old_data_grads_norm = 6.4389
	sim_grads_norm_tr = -0.1225
-- Starting training on experience 217 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5628
	data_grads_norm = 4.2944
	new_data_grads_norm = 6.9008
	old_data_grads_norm = 4.3059
	sim_grads_norm_tr = 0.3669
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4162
	data_grads_norm = 3.6808
	new_data_grads_norm = 5.7396
	old_data_grads_norm = 5.8510
	sim_grads_norm_tr = 0.0904
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2141
	data_grads_norm = 3.4006
	new_data_grads_norm = 5.1642
	old_data_grads_norm = 5.5166
	sim_grads_norm_tr = -0.0821
-- Starting training on experience 218 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0817
	data_grads_norm = 3.0129
	new_data_grads_norm = 4.4084
	old_data_grads_norm = 3.9936
	sim_grads_norm_tr = 0.0826
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7724
	data_grads_norm = 3.9755
	new_data_grads_norm = 5.4608
	old_data_grads_norm = 5.8145
	sim_grads_norm_tr = 0.1856
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3176
	data_grads_norm = 3.9429
	new_data_grads_norm = 4.6937
	old_data_grads_norm = 5.6704
	sim_grads_norm_tr = 0.1967
-- Starting training on experience 219 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5665
	data_grads_norm = 4.1203
	new_data_grads_norm = 6.4903
	old_data_grads_norm = 5.8883
	sim_grads_norm_tr = 0.1362
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2766
	data_grads_norm = 2.8897
	new_data_grads_norm = 5.7866
	old_data_grads_norm = 3.6118
	sim_grads_norm_tr = -0.0324
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1079
	data_grads_norm = 3.1302
	new_data_grads_norm = 6.3825
	old_data_grads_norm = 3.9726
	sim_grads_norm_tr = -0.0355
-- Starting training on experience 220 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0150
	data_grads_norm = 2.9404
	new_data_grads_norm = 4.4538
	old_data_grads_norm = 4.7028
	sim_grads_norm_tr = 0.0210
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4896
	data_grads_norm = 3.5548
	new_data_grads_norm = 4.8114
	old_data_grads_norm = 3.8571
	sim_grads_norm_tr = -0.0158
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0423
	data_grads_norm = 2.9454
	new_data_grads_norm = 4.5065
	old_data_grads_norm = 3.2241
	sim_grads_norm_tr = 0.3730
-- Starting training on experience 221 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1792
	data_grads_norm = 4.8562
	new_data_grads_norm = 5.6973
	old_data_grads_norm = 7.5445
	sim_grads_norm_tr = 0.3086
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2723
	data_grads_norm = 3.0614
	new_data_grads_norm = 4.2593
	old_data_grads_norm = 3.6236
	sim_grads_norm_tr = 0.1052
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2216
	data_grads_norm = 3.3983
	new_data_grads_norm = 4.2153
	old_data_grads_norm = 4.4757
	sim_grads_norm_tr = 0.0721
-- Starting training on experience 222 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4076
	data_grads_norm = 3.3340
	new_data_grads_norm = 4.5762
	old_data_grads_norm = 4.3205
	sim_grads_norm_tr = 0.1432
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3901
	data_grads_norm = 3.3126
	new_data_grads_norm = 3.6069
	old_data_grads_norm = 5.1162
	sim_grads_norm_tr = 0.2352
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9441
	data_grads_norm = 3.0500
	new_data_grads_norm = 3.9160
	old_data_grads_norm = 4.0249
	sim_grads_norm_tr = 0.2022
-- Starting training on experience 223 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4919
	data_grads_norm = 2.8988
	new_data_grads_norm = 4.6198
	old_data_grads_norm = 4.6335
	sim_grads_norm_tr = 0.0375
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3047
	data_grads_norm = 3.0717
	new_data_grads_norm = 4.4580
	old_data_grads_norm = 4.4410
	sim_grads_norm_tr = -0.0530
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6186
	data_grads_norm = 3.7410
	new_data_grads_norm = 4.6681
	old_data_grads_norm = 5.4727
	sim_grads_norm_tr = 0.1503
-- Starting training on experience 224 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5746
	data_grads_norm = 3.6395
	new_data_grads_norm = 5.9777
	old_data_grads_norm = 4.4400
	sim_grads_norm_tr = 0.2013
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4386
	data_grads_norm = 3.8999
	new_data_grads_norm = 6.9587
	old_data_grads_norm = 3.8353
	sim_grads_norm_tr = 0.0760
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5977
	data_grads_norm = 3.7656
	new_data_grads_norm = 6.8965
	old_data_grads_norm = 3.9611
	sim_grads_norm_tr = -0.0650
-- Starting training on experience 225 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1487
	data_grads_norm = 2.5994
	new_data_grads_norm = 4.8065
	old_data_grads_norm = 4.2376
	sim_grads_norm_tr = -0.1746
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3314
	data_grads_norm = 3.0567
	new_data_grads_norm = 4.6895
	old_data_grads_norm = 4.6890
	sim_grads_norm_tr = -0.0354
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6372
	data_grads_norm = 3.6183
	new_data_grads_norm = 6.4463
	old_data_grads_norm = 3.8304
	sim_grads_norm_tr = 0.0894
-- Starting training on experience 226 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5873
	data_grads_norm = 4.3093
	new_data_grads_norm = 6.7644
	old_data_grads_norm = 4.4251
	sim_grads_norm_tr = 0.1222
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6773
	data_grads_norm = 4.0658
	new_data_grads_norm = 6.1965
	old_data_grads_norm = 4.8736
	sim_grads_norm_tr = 0.1358
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2073
	data_grads_norm = 3.5326
	new_data_grads_norm = 5.8779
	old_data_grads_norm = 3.2927
	sim_grads_norm_tr = 0.2055
-- Starting training on experience 227 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0168
	data_grads_norm = 3.4094
	new_data_grads_norm = 5.2162
	old_data_grads_norm = 4.2560
	sim_grads_norm_tr = 0.0865
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8269
	data_grads_norm = 3.1986
	new_data_grads_norm = 5.2159
	old_data_grads_norm = 4.8973
	sim_grads_norm_tr = -0.0219
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1697
	data_grads_norm = 4.1706
	new_data_grads_norm = 5.9049
	old_data_grads_norm = 5.1873
	sim_grads_norm_tr = 0.0858
-- Starting training on experience 228 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1259
	data_grads_norm = 2.9591
	new_data_grads_norm = 5.0647
	old_data_grads_norm = 4.1905
	sim_grads_norm_tr = 0.0273
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2888
	data_grads_norm = 3.1184
	new_data_grads_norm = 5.3570
	old_data_grads_norm = 3.9237
	sim_grads_norm_tr = 0.0712
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6499
	data_grads_norm = 3.1256
	new_data_grads_norm = 5.4035
	old_data_grads_norm = 4.9501
	sim_grads_norm_tr = 0.0581
-- Starting training on experience 229 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1815
	data_grads_norm = 3.0147
	new_data_grads_norm = 4.1939
	old_data_grads_norm = 5.7092
	sim_grads_norm_tr = -0.1653
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0681
	data_grads_norm = 3.8015
	new_data_grads_norm = 5.4779
	old_data_grads_norm = 4.9082
	sim_grads_norm_tr = 0.1930
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2844
	data_grads_norm = 3.3818
	new_data_grads_norm = 4.8338
	old_data_grads_norm = 6.1904
	sim_grads_norm_tr = 0.0363
-- Starting training on experience 230 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7436
	data_grads_norm = 3.5455
	new_data_grads_norm = 6.8164
	old_data_grads_norm = 5.2009
	sim_grads_norm_tr = 0.1257
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5429
	data_grads_norm = 2.9675
	new_data_grads_norm = 5.7043
	old_data_grads_norm = 3.6364
	sim_grads_norm_tr = 0.1359
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5181
	data_grads_norm = 3.1382
	new_data_grads_norm = 6.0604
	old_data_grads_norm = 5.1973
	sim_grads_norm_tr = -0.1461
-- Starting training on experience 231 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7464
	data_grads_norm = 4.6086
	new_data_grads_norm = 6.3070
	old_data_grads_norm = 5.8812
	sim_grads_norm_tr = 0.0863
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6200
	data_grads_norm = 3.8918
	new_data_grads_norm = 6.1783
	old_data_grads_norm = 5.1445
	sim_grads_norm_tr = -0.0304
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3770
	data_grads_norm = 3.6011
	new_data_grads_norm = 5.9493
	old_data_grads_norm = 4.3375
	sim_grads_norm_tr = 0.1621
-- Starting training on experience 232 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3842
	data_grads_norm = 4.1222
	new_data_grads_norm = 6.5031
	old_data_grads_norm = 4.9726
	sim_grads_norm_tr = 0.0145
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2816
	data_grads_norm = 3.6115
	new_data_grads_norm = 7.0041
	old_data_grads_norm = 3.9367
	sim_grads_norm_tr = -0.0575
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0896
	data_grads_norm = 3.7155
	new_data_grads_norm = 6.4802
	old_data_grads_norm = 3.9816
	sim_grads_norm_tr = 0.2498
-- Starting training on experience 233 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2972
	data_grads_norm = 3.9091
	new_data_grads_norm = 4.9908
	old_data_grads_norm = 6.3765
	sim_grads_norm_tr = 0.0477
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0191
	data_grads_norm = 3.2057
	new_data_grads_norm = 4.6088
	old_data_grads_norm = 3.2728
	sim_grads_norm_tr = 0.1861
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1721
	data_grads_norm = 3.8981
	new_data_grads_norm = 4.1485
	old_data_grads_norm = 6.3466
	sim_grads_norm_tr = 0.1382
-- Starting training on experience 234 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1957
	data_grads_norm = 4.3702
	new_data_grads_norm = 6.7769
	old_data_grads_norm = 5.1850
	sim_grads_norm_tr = 0.3010
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0376
	data_grads_norm = 3.4877
	new_data_grads_norm = 5.7569
	old_data_grads_norm = 4.8170
	sim_grads_norm_tr = 0.1141
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3607
	data_grads_norm = 3.4660
	new_data_grads_norm = 4.9016
	old_data_grads_norm = 3.6639
	sim_grads_norm_tr = 0.2005
-- Starting training on experience 235 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0006
	data_grads_norm = 3.1892
	new_data_grads_norm = 5.8994
	old_data_grads_norm = 3.3160
	sim_grads_norm_tr = 0.0254
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2417
	data_grads_norm = 3.5519
	new_data_grads_norm = 6.6360
	old_data_grads_norm = 6.1122
	sim_grads_norm_tr = -0.2624
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3779
	data_grads_norm = 6.2415
	new_data_grads_norm = 11.8347
	old_data_grads_norm = 2.9645
	sim_grads_norm_tr = 0.1465
-- Starting training on experience 236 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3123
	data_grads_norm = 4.7033
	new_data_grads_norm = 6.1299
	old_data_grads_norm = 5.8005
	sim_grads_norm_tr = 0.1988
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1513
	data_grads_norm = 3.4385
	new_data_grads_norm = 4.5109
	old_data_grads_norm = 4.2338
	sim_grads_norm_tr = 0.0711
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0208
	data_grads_norm = 3.7703
	new_data_grads_norm = 4.0606
	old_data_grads_norm = 4.8622
	sim_grads_norm_tr = 0.2326
-- Starting training on experience 237 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
-- >> End of training phase << --
-- >> Start of eval phase << --
-- Starting eval on experience 0 (Task 0) from test stream --
> Eval on experience 0 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp000 = 1.5737
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.4260
	mb_index = 476
	time = 89.8505
-- Starting eval on experience 1 (Task 0) from test stream --
> Eval on experience 1 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp001 = 1.0189
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.6500
-- >> End of eval phase << --
	CumulativeAccuracy/eval_phase/test_stream/Exp000 = 0.6960
	CumulativeAccuracy/eval_phase/test_stream/Exp001 = 0.5380
	Loss_Stream/eval_phase/test_stream/Task000 = 1.2963
	Top1_Acc_Stream/eval_phase/test_stream/Task000 = 0.5380
-- >> Start of training phase << --
-- Starting training on experience 0 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3783
	data_grads_norm = 3.8589
	new_data_grads_norm = 5.7386
	old_data_grads_norm = 5.8577
	sim_grads_norm_tr = -0.0148
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3865
	data_grads_norm = 3.1482
	new_data_grads_norm = 6.1373
	old_data_grads_norm = 3.9205
	sim_grads_norm_tr = -0.0028
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7033
	data_grads_norm = 4.0465
	new_data_grads_norm = 6.3756
	old_data_grads_norm = 5.9938
	sim_grads_norm_tr = -0.0324
-- Starting training on experience 1 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8709
	data_grads_norm = 3.9421
	new_data_grads_norm = 5.7896
	old_data_grads_norm = 5.1213
	sim_grads_norm_tr = -0.1253
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9434
	data_grads_norm = 4.0492
	new_data_grads_norm = 5.8863
	old_data_grads_norm = 6.4887
	sim_grads_norm_tr = -0.0508
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9360
	data_grads_norm = 4.7289
	new_data_grads_norm = 6.7962
	old_data_grads_norm = 5.8291
	sim_grads_norm_tr = 0.0707
-- Starting training on experience 2 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7808
	data_grads_norm = 5.6470
	new_data_grads_norm = 6.5849
	old_data_grads_norm = 7.0647
	sim_grads_norm_tr = 0.1401
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7524
	data_grads_norm = 4.4792
	new_data_grads_norm = 6.1804
	old_data_grads_norm = 5.0337
	sim_grads_norm_tr = 0.0794
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3551
	data_grads_norm = 2.9636
	new_data_grads_norm = 5.4407
	old_data_grads_norm = 3.7432
	sim_grads_norm_tr = -0.0733
-- Starting training on experience 3 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4885
	data_grads_norm = 3.3789
	new_data_grads_norm = 6.6105
	old_data_grads_norm = 3.8000
	sim_grads_norm_tr = -0.0023
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5189
	data_grads_norm = 3.6975
	new_data_grads_norm = 6.7778
	old_data_grads_norm = 3.6612
	sim_grads_norm_tr = -0.0873
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9333
	data_grads_norm = 5.0187
	new_data_grads_norm = 6.5828
	old_data_grads_norm = 7.4565
	sim_grads_norm_tr = 0.1796
-- Starting training on experience 4 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2296
	data_grads_norm = 4.7605
	new_data_grads_norm = 7.4960
	old_data_grads_norm = 6.3109
	sim_grads_norm_tr = -0.0577
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9997
	data_grads_norm = 5.3570
	new_data_grads_norm = 8.1308
	old_data_grads_norm = 5.8052
	sim_grads_norm_tr = 0.0097
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4055
	data_grads_norm = 4.7057
	new_data_grads_norm = 7.2118
	old_data_grads_norm = 5.4394
	sim_grads_norm_tr = 0.0332
-- Starting training on experience 5 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7676
	data_grads_norm = 3.5755
	new_data_grads_norm = 5.9101
	old_data_grads_norm = 4.7468
	sim_grads_norm_tr = -0.0579
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1892
	data_grads_norm = 5.2718
	new_data_grads_norm = 6.9199
	old_data_grads_norm = 5.5324
	sim_grads_norm_tr = 0.0746
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8667
	data_grads_norm = 4.9841
	new_data_grads_norm = 6.3096
	old_data_grads_norm = 5.8777
	sim_grads_norm_tr = -0.0842
-- Starting training on experience 6 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8925
	data_grads_norm = 4.2867
	new_data_grads_norm = 8.5772
	old_data_grads_norm = 4.5447
	sim_grads_norm_tr = 0.0852
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4053
	data_grads_norm = 5.5862
	new_data_grads_norm = 8.2953
	old_data_grads_norm = 7.6686
	sim_grads_norm_tr = -0.0165
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2577
	data_grads_norm = 5.6742
	new_data_grads_norm = 7.5550
	old_data_grads_norm = 7.0378
	sim_grads_norm_tr = 0.1267
-- Starting training on experience 7 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1916
	data_grads_norm = 3.8521
	new_data_grads_norm = 7.1573
	old_data_grads_norm = 4.4283
	sim_grads_norm_tr = 0.0160
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2672
	data_grads_norm = 4.7780
	new_data_grads_norm = 7.4520
	old_data_grads_norm = 5.6271
	sim_grads_norm_tr = 0.0158
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8463
	data_grads_norm = 3.6409
	new_data_grads_norm = 7.1414
	old_data_grads_norm = 3.8551
	sim_grads_norm_tr = 0.0214
-- Starting training on experience 8 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2875
	data_grads_norm = 4.2105
	new_data_grads_norm = 6.3001
	old_data_grads_norm = 4.3426
	sim_grads_norm_tr = 0.0222
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0273
	data_grads_norm = 3.6305
	new_data_grads_norm = 6.2725
	old_data_grads_norm = 4.1257
	sim_grads_norm_tr = 0.0131
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4190
	data_grads_norm = 4.2898
	new_data_grads_norm = 6.3603
	old_data_grads_norm = 4.5887
	sim_grads_norm_tr = 0.0492
-- Starting training on experience 9 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6893
	data_grads_norm = 3.0331
	new_data_grads_norm = 5.4972
	old_data_grads_norm = 3.0442
	sim_grads_norm_tr = 0.0829
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5065
	data_grads_norm = 3.4370
	new_data_grads_norm = 5.7709
	old_data_grads_norm = 4.4839
	sim_grads_norm_tr = -0.0335
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6717
	data_grads_norm = 4.8623
	new_data_grads_norm = 5.9516
	old_data_grads_norm = 5.9703
	sim_grads_norm_tr = 0.1114
-- Starting training on experience 10 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9389
	data_grads_norm = 3.9416
	new_data_grads_norm = 6.7824
	old_data_grads_norm = 4.6672
	sim_grads_norm_tr = -0.0169
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7676
	data_grads_norm = 3.6251
	new_data_grads_norm = 6.9549
	old_data_grads_norm = 4.0634
	sim_grads_norm_tr = 0.0122
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3597
	data_grads_norm = 4.4497
	new_data_grads_norm = 6.9624
	old_data_grads_norm = 5.8092
	sim_grads_norm_tr = 0.0394
-- Starting training on experience 11 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5255
	data_grads_norm = 3.6513
	new_data_grads_norm = 7.9561
	old_data_grads_norm = 3.9746
	sim_grads_norm_tr = -0.2687
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3833
	data_grads_norm = 4.4026
	new_data_grads_norm = 7.5687
	old_data_grads_norm = 3.9379
	sim_grads_norm_tr = 0.0488
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5196
	data_grads_norm = 5.1641
	new_data_grads_norm = 7.7528
	old_data_grads_norm = 5.1932
	sim_grads_norm_tr = 0.0025
-- Starting training on experience 12 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0100
	data_grads_norm = 4.3733
	new_data_grads_norm = 6.7623
	old_data_grads_norm = 8.2024
	sim_grads_norm_tr = 0.1030
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6749
	data_grads_norm = 4.9620
	new_data_grads_norm = 6.9370
	old_data_grads_norm = 6.6535
	sim_grads_norm_tr = 0.1001
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0565
	data_grads_norm = 5.8416
	new_data_grads_norm = 6.7106
	old_data_grads_norm = 7.3561
	sim_grads_norm_tr = 0.0581
-- Starting training on experience 13 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5454
	data_grads_norm = 3.4770
	new_data_grads_norm = 7.4796
	old_data_grads_norm = 5.2559
	sim_grads_norm_tr = -0.0061
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8965
	data_grads_norm = 3.6187
	new_data_grads_norm = 7.5684
	old_data_grads_norm = 4.3099
	sim_grads_norm_tr = 0.0549
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5058
	data_grads_norm = 4.5554
	new_data_grads_norm = 6.8680
	old_data_grads_norm = 6.5458
	sim_grads_norm_tr = 0.1189
-- Starting training on experience 14 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7228
	data_grads_norm = 3.7077
	new_data_grads_norm = 6.6498
	old_data_grads_norm = 5.5292
	sim_grads_norm_tr = -0.0469
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7498
	data_grads_norm = 4.8631
	new_data_grads_norm = 6.5712
	old_data_grads_norm = 6.0940
	sim_grads_norm_tr = 0.1311
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5442
	data_grads_norm = 4.6292
	new_data_grads_norm = 6.2817
	old_data_grads_norm = 4.9734
	sim_grads_norm_tr = 0.1536
-- Starting training on experience 15 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0780
	data_grads_norm = 4.5042
	new_data_grads_norm = 6.5218
	old_data_grads_norm = 7.3213
	sim_grads_norm_tr = 0.0383
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0094
	data_grads_norm = 5.2330
	new_data_grads_norm = 7.4671
	old_data_grads_norm = 5.5792
	sim_grads_norm_tr = 0.0255
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9080
	data_grads_norm = 4.0007
	new_data_grads_norm = 6.7787
	old_data_grads_norm = 4.7267
	sim_grads_norm_tr = 0.0956
-- Starting training on experience 16 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8212
	data_grads_norm = 3.9281
	new_data_grads_norm = 6.7267
	old_data_grads_norm = 4.2341
	sim_grads_norm_tr = 0.0146
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7465
	data_grads_norm = 3.7006
	new_data_grads_norm = 6.6448
	old_data_grads_norm = 3.7975
	sim_grads_norm_tr = 0.0192
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2218
	data_grads_norm = 4.7063
	new_data_grads_norm = 6.9671
	old_data_grads_norm = 5.5169
	sim_grads_norm_tr = 0.0177
-- Starting training on experience 17 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3552
	data_grads_norm = 2.9465
	new_data_grads_norm = 5.5672
	old_data_grads_norm = 4.4929
	sim_grads_norm_tr = -0.1114
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0731
	data_grads_norm = 4.5426
	new_data_grads_norm = 6.0771
	old_data_grads_norm = 5.9593
	sim_grads_norm_tr = 0.0356
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8627
	data_grads_norm = 3.8992
	new_data_grads_norm = 6.2775
	old_data_grads_norm = 5.8885
	sim_grads_norm_tr = -0.0040
-- Starting training on experience 18 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0588
	data_grads_norm = 4.9638
	new_data_grads_norm = 6.3867
	old_data_grads_norm = 4.4225
	sim_grads_norm_tr = 0.1394
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9694
	data_grads_norm = 4.6791
	new_data_grads_norm = 6.8366
	old_data_grads_norm = 5.5494
	sim_grads_norm_tr = 0.0578
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8130
	data_grads_norm = 3.9038
	new_data_grads_norm = 7.4622
	old_data_grads_norm = 3.9033
	sim_grads_norm_tr = 0.2286
-- Starting training on experience 19 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3493
	data_grads_norm = 3.3642
	new_data_grads_norm = 6.8577
	old_data_grads_norm = 3.3718
	sim_grads_norm_tr = -0.0364
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5186
	data_grads_norm = 3.9089
	new_data_grads_norm = 6.6184
	old_data_grads_norm = 5.7551
	sim_grads_norm_tr = 0.0087
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3211
	data_grads_norm = 5.0269
	new_data_grads_norm = 6.7426
	old_data_grads_norm = 7.5172
	sim_grads_norm_tr = 0.0914
-- Starting training on experience 20 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2306
	data_grads_norm = 4.6325
	new_data_grads_norm = 6.5218
	old_data_grads_norm = 5.7045
	sim_grads_norm_tr = 0.3814
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9490
	data_grads_norm = 4.0601
	new_data_grads_norm = 5.0652
	old_data_grads_norm = 6.4422
	sim_grads_norm_tr = -0.0280
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6275
	data_grads_norm = 3.0699
	new_data_grads_norm = 5.3363
	old_data_grads_norm = 3.8572
	sim_grads_norm_tr = 0.1708
-- Starting training on experience 21 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6351
	data_grads_norm = 2.6847
	new_data_grads_norm = 4.8878
	old_data_grads_norm = 2.2742
	sim_grads_norm_tr = 0.0629
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7603
	data_grads_norm = 3.4012
	new_data_grads_norm = 5.0975
	old_data_grads_norm = 4.0054
	sim_grads_norm_tr = -0.0049
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2879
	data_grads_norm = 2.2261
	new_data_grads_norm = 4.9246
	old_data_grads_norm = 2.6587
	sim_grads_norm_tr = -0.0518
-- Starting training on experience 22 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4382
	data_grads_norm = 3.1087
	new_data_grads_norm = 5.6582
	old_data_grads_norm = 3.2671
	sim_grads_norm_tr = 0.0318
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3092
	data_grads_norm = 4.3158
	new_data_grads_norm = 4.8782
	old_data_grads_norm = 5.7915
	sim_grads_norm_tr = 0.0187
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0216
	data_grads_norm = 3.9241
	new_data_grads_norm = 5.1083
	old_data_grads_norm = 4.7703
	sim_grads_norm_tr = 0.0454
-- Starting training on experience 23 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8965
	data_grads_norm = 5.6380
	new_data_grads_norm = 5.8461
	old_data_grads_norm = 9.6627
	sim_grads_norm_tr = 0.1453
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4314
	data_grads_norm = 2.8799
	new_data_grads_norm = 5.2825
	old_data_grads_norm = 4.1158
	sim_grads_norm_tr = -0.0067
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7145
	data_grads_norm = 2.8765
	new_data_grads_norm = 4.9115
	old_data_grads_norm = 3.1886
	sim_grads_norm_tr = 0.0666
-- Starting training on experience 24 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1120
	data_grads_norm = 3.1081
	new_data_grads_norm = 5.6141
	old_data_grads_norm = 4.7234
	sim_grads_norm_tr = -0.1533
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6142
	data_grads_norm = 3.5372
	new_data_grads_norm = 5.7336
	old_data_grads_norm = 3.7666
	sim_grads_norm_tr = 0.1066
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5200
	data_grads_norm = 3.6556
	new_data_grads_norm = 5.4996
	old_data_grads_norm = 5.0484
	sim_grads_norm_tr = -0.0296
-- Starting training on experience 25 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5354
	data_grads_norm = 3.6775
	new_data_grads_norm = 4.5935
	old_data_grads_norm = 3.8699
	sim_grads_norm_tr = 0.0243
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9030
	data_grads_norm = 3.6196
	new_data_grads_norm = 4.9882
	old_data_grads_norm = 4.6241
	sim_grads_norm_tr = 0.0880
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2333
	data_grads_norm = 2.7319
	new_data_grads_norm = 4.7977
	old_data_grads_norm = 5.4820
	sim_grads_norm_tr = -0.1167
-- Starting training on experience 26 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9107
	data_grads_norm = 3.7954
	new_data_grads_norm = 5.1379
	old_data_grads_norm = 4.5264
	sim_grads_norm_tr = 0.1338
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4606
	data_grads_norm = 3.3268
	new_data_grads_norm = 4.8241
	old_data_grads_norm = 4.5893
	sim_grads_norm_tr = -0.0383
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6556
	data_grads_norm = 3.9562
	new_data_grads_norm = 5.9111
	old_data_grads_norm = 5.3169
	sim_grads_norm_tr = -0.0365
-- Starting training on experience 27 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5331
	data_grads_norm = 3.8682
	new_data_grads_norm = 5.5087
	old_data_grads_norm = 4.9927
	sim_grads_norm_tr = 0.0260
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2607
	data_grads_norm = 3.4258
	new_data_grads_norm = 6.5579
	old_data_grads_norm = 3.8733
	sim_grads_norm_tr = -0.0870
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3197
	data_grads_norm = 3.4284
	new_data_grads_norm = 6.4652
	old_data_grads_norm = 3.4894
	sim_grads_norm_tr = 0.1286
-- Starting training on experience 28 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2744
	data_grads_norm = 3.1309
	new_data_grads_norm = 6.3733
	old_data_grads_norm = 3.4797
	sim_grads_norm_tr = -0.0221
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6650
	data_grads_norm = 3.8683
	new_data_grads_norm = 6.6775
	old_data_grads_norm = 4.3126
	sim_grads_norm_tr = 0.0485
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0051
	data_grads_norm = 4.6855
	new_data_grads_norm = 6.2790
	old_data_grads_norm = 4.9901
	sim_grads_norm_tr = 0.5116
-- Starting training on experience 29 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2920
	data_grads_norm = 3.8718
	new_data_grads_norm = 5.4646
	old_data_grads_norm = 3.8644
	sim_grads_norm_tr = 0.0474
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2293
	data_grads_norm = 3.6964
	new_data_grads_norm = 5.1182
	old_data_grads_norm = 5.3188
	sim_grads_norm_tr = 0.0033
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3147
	data_grads_norm = 3.8210
	new_data_grads_norm = 5.4389
	old_data_grads_norm = 6.6001
	sim_grads_norm_tr = -0.0069
-- Starting training on experience 30 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3296
	data_grads_norm = 3.4704
	new_data_grads_norm = 4.5074
	old_data_grads_norm = 4.2172
	sim_grads_norm_tr = 0.2037
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2022
	data_grads_norm = 2.5811
	new_data_grads_norm = 4.5724
	old_data_grads_norm = 4.5703
	sim_grads_norm_tr = -0.0300
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3316
	data_grads_norm = 3.8011
	new_data_grads_norm = 4.5294
	old_data_grads_norm = 5.8895
	sim_grads_norm_tr = -0.0262
-- Starting training on experience 31 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2745
	data_grads_norm = 3.5756
	new_data_grads_norm = 5.5266
	old_data_grads_norm = 4.2502
	sim_grads_norm_tr = -0.0039
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2535
	data_grads_norm = 3.5330
	new_data_grads_norm = 6.3043
	old_data_grads_norm = 3.3790
	sim_grads_norm_tr = 0.1537
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8796
	data_grads_norm = 4.5268
	new_data_grads_norm = 6.2160
	old_data_grads_norm = 6.3289
	sim_grads_norm_tr = 0.1273
-- Starting training on experience 32 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5595
	data_grads_norm = 3.8030
	new_data_grads_norm = 6.4018
	old_data_grads_norm = 4.6915
	sim_grads_norm_tr = 0.0778
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2108
	data_grads_norm = 3.6725
	new_data_grads_norm = 6.5213
	old_data_grads_norm = 4.3599
	sim_grads_norm_tr = 0.0332
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1340
	data_grads_norm = 2.7368
	new_data_grads_norm = 5.9218
	old_data_grads_norm = 3.6698
	sim_grads_norm_tr = -0.0014
-- Starting training on experience 33 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2384
	data_grads_norm = 3.1714
	new_data_grads_norm = 5.9271
	old_data_grads_norm = 4.0323
	sim_grads_norm_tr = 0.1130
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5685
	data_grads_norm = 3.6657
	new_data_grads_norm = 6.4963
	old_data_grads_norm = 4.0215
	sim_grads_norm_tr = 0.1509
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0115
	data_grads_norm = 2.6394
	new_data_grads_norm = 5.3501
	old_data_grads_norm = 2.8482
	sim_grads_norm_tr = 0.1071
-- Starting training on experience 34 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6024
	data_grads_norm = 4.2613
	new_data_grads_norm = 4.1137
	old_data_grads_norm = 6.5997
	sim_grads_norm_tr = 0.0717
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4699
	data_grads_norm = 2.9110
	new_data_grads_norm = 4.1963
	old_data_grads_norm = 4.2244
	sim_grads_norm_tr = 0.0329
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3482
	data_grads_norm = 3.4219
	new_data_grads_norm = 4.0085
	old_data_grads_norm = 4.6295
	sim_grads_norm_tr = 0.1804
-- Starting training on experience 35 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7214
	data_grads_norm = 2.6804
	new_data_grads_norm = 4.7667
	old_data_grads_norm = 5.0830
	sim_grads_norm_tr = -0.1911
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1905
	data_grads_norm = 3.3098
	new_data_grads_norm = 5.2973
	old_data_grads_norm = 4.8252
	sim_grads_norm_tr = -0.1024
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2945
	data_grads_norm = 2.9580
	new_data_grads_norm = 5.5292
	old_data_grads_norm = 2.7806
	sim_grads_norm_tr = 0.0504
-- Starting training on experience 36 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6758
	data_grads_norm = 4.1252
	new_data_grads_norm = 5.6135
	old_data_grads_norm = 5.6293
	sim_grads_norm_tr = 0.0940
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5598
	data_grads_norm = 4.0793
	new_data_grads_norm = 5.5416
	old_data_grads_norm = 4.8263
	sim_grads_norm_tr = 0.1994
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0298
	data_grads_norm = 3.5019
	new_data_grads_norm = 5.3045
	old_data_grads_norm = 4.6610
	sim_grads_norm_tr = -0.0122
-- Starting training on experience 37 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2800
	data_grads_norm = 3.3503
	new_data_grads_norm = 5.5390
	old_data_grads_norm = 5.0314
	sim_grads_norm_tr = 0.0036
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7128
	data_grads_norm = 3.2568
	new_data_grads_norm = 6.1023
	old_data_grads_norm = 4.1543
	sim_grads_norm_tr = 0.1222
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5619
	data_grads_norm = 4.1691
	new_data_grads_norm = 5.2939
	old_data_grads_norm = 5.7783
	sim_grads_norm_tr = 0.1530
-- Starting training on experience 38 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4551
	data_grads_norm = 4.5513
	new_data_grads_norm = 6.0282
	old_data_grads_norm = 5.7987
	sim_grads_norm_tr = 0.0347
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2998
	data_grads_norm = 2.6491
	new_data_grads_norm = 5.6878
	old_data_grads_norm = 3.0958
	sim_grads_norm_tr = 0.0343
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3479
	data_grads_norm = 2.9045
	new_data_grads_norm = 5.6744
	old_data_grads_norm = 4.0030
	sim_grads_norm_tr = -0.0508
-- Starting training on experience 39 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3490
	data_grads_norm = 3.3929
	new_data_grads_norm = 5.9015
	old_data_grads_norm = 4.4054
	sim_grads_norm_tr = 0.0190
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5460
	data_grads_norm = 3.6373
	new_data_grads_norm = 5.7462
	old_data_grads_norm = 5.1711
	sim_grads_norm_tr = -0.1259
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4489
	data_grads_norm = 3.0865
	new_data_grads_norm = 6.0478
	old_data_grads_norm = 4.1169
	sim_grads_norm_tr = -0.0351
-- Starting training on experience 40 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2215
	data_grads_norm = 2.9724
	new_data_grads_norm = 5.0026
	old_data_grads_norm = 3.7971
	sim_grads_norm_tr = 0.2048
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6521
	data_grads_norm = 4.1204
	new_data_grads_norm = 5.1622
	old_data_grads_norm = 5.5189
	sim_grads_norm_tr = 0.2257
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5564
	data_grads_norm = 3.9847
	new_data_grads_norm = 5.4503
	old_data_grads_norm = 4.9701
	sim_grads_norm_tr = 0.2015
-- Starting training on experience 41 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3647
	data_grads_norm = 3.3674
	new_data_grads_norm = 4.6371
	old_data_grads_norm = 5.2871
	sim_grads_norm_tr = -0.0698
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2273
	data_grads_norm = 3.1569
	new_data_grads_norm = 5.2649
	old_data_grads_norm = 3.6253
	sim_grads_norm_tr = -0.1732
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6159
	data_grads_norm = 4.3300
	new_data_grads_norm = 5.5608
	old_data_grads_norm = 4.9446
	sim_grads_norm_tr = 0.3372
-- Starting training on experience 42 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2110
	data_grads_norm = 2.7491
	new_data_grads_norm = 5.0613
	old_data_grads_norm = 3.5698
	sim_grads_norm_tr = -0.0908
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0304
	data_grads_norm = 2.3601
	new_data_grads_norm = 4.9453
	old_data_grads_norm = 3.4287
	sim_grads_norm_tr = -0.1221
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4080
	data_grads_norm = 2.8464
	new_data_grads_norm = 4.9998
	old_data_grads_norm = 3.3179
	sim_grads_norm_tr = 0.1109
-- Starting training on experience 43 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5722
	data_grads_norm = 4.2579
	new_data_grads_norm = 5.5244
	old_data_grads_norm = 5.4163
	sim_grads_norm_tr = 0.1169
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5130
	data_grads_norm = 4.4314
	new_data_grads_norm = 4.6044
	old_data_grads_norm = 5.8594
	sim_grads_norm_tr = 0.0882
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3489
	data_grads_norm = 3.7788
	new_data_grads_norm = 4.7963
	old_data_grads_norm = 5.8212
	sim_grads_norm_tr = -0.0598
-- Starting training on experience 44 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3151
	data_grads_norm = 3.4228
	new_data_grads_norm = 5.4208
	old_data_grads_norm = 3.7334
	sim_grads_norm_tr = 0.1070
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2921
	data_grads_norm = 3.0576
	new_data_grads_norm = 5.1364
	old_data_grads_norm = 3.7547
	sim_grads_norm_tr = 0.1285
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0741
	data_grads_norm = 3.1693
	new_data_grads_norm = 5.9445
	old_data_grads_norm = 3.5318
	sim_grads_norm_tr = 0.1537
-- Starting training on experience 45 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3001
	data_grads_norm = 3.6148
	new_data_grads_norm = 3.7767
	old_data_grads_norm = 4.8487
	sim_grads_norm_tr = 0.1176
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1872
	data_grads_norm = 4.4868
	new_data_grads_norm = 4.2613
	old_data_grads_norm = 7.4796
	sim_grads_norm_tr = 0.0652
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9805
	data_grads_norm = 2.0033
	new_data_grads_norm = 4.1318
	old_data_grads_norm = 3.1785
	sim_grads_norm_tr = -0.1218
-- Starting training on experience 46 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8682
	data_grads_norm = 2.1571
	new_data_grads_norm = 4.4541
	old_data_grads_norm = 2.8316
	sim_grads_norm_tr = -0.0265
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1068
	data_grads_norm = 2.5656
	new_data_grads_norm = 4.7726
	old_data_grads_norm = 3.5597
	sim_grads_norm_tr = -0.0207
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7781
	data_grads_norm = 2.7964
	new_data_grads_norm = 4.3361
	old_data_grads_norm = 3.7629
	sim_grads_norm_tr = -0.1011
-- Starting training on experience 47 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8334
	data_grads_norm = 2.8134
	new_data_grads_norm = 5.3583
	old_data_grads_norm = 3.7313
	sim_grads_norm_tr = 0.0051
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1449
	data_grads_norm = 2.7743
	new_data_grads_norm = 5.0894
	old_data_grads_norm = 3.3823
	sim_grads_norm_tr = 0.0221
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8082
	data_grads_norm = 2.9623
	new_data_grads_norm = 4.9204
	old_data_grads_norm = 3.2112
	sim_grads_norm_tr = 0.0427
-- Starting training on experience 48 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0457
	data_grads_norm = 2.6857
	new_data_grads_norm = 5.5811
	old_data_grads_norm = 3.8207
	sim_grads_norm_tr = 0.0051
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1984
	data_grads_norm = 3.2426
	new_data_grads_norm = 5.4883
	old_data_grads_norm = 4.2713
	sim_grads_norm_tr = 0.0929
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8330
	data_grads_norm = 4.3081
	new_data_grads_norm = 4.9724
	old_data_grads_norm = 5.6508
	sim_grads_norm_tr = 0.0933
-- Starting training on experience 49 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0643
	data_grads_norm = 3.9075
	new_data_grads_norm = 5.2802
	old_data_grads_norm = 7.2862
	sim_grads_norm_tr = -0.1132
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4568
	data_grads_norm = 3.8899
	new_data_grads_norm = 6.1959
	old_data_grads_norm = 3.9153
	sim_grads_norm_tr = 0.1807
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7559
	data_grads_norm = 4.8678
	new_data_grads_norm = 5.5879
	old_data_grads_norm = 6.6416
	sim_grads_norm_tr = 0.2265
-- Starting training on experience 50 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1071
	data_grads_norm = 3.2434
	new_data_grads_norm = 5.3455
	old_data_grads_norm = 3.7460
	sim_grads_norm_tr = 0.1104
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9094
	data_grads_norm = 2.7983
	new_data_grads_norm = 5.1111
	old_data_grads_norm = 3.1284
	sim_grads_norm_tr = -0.1280
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9700
	data_grads_norm = 3.1989
	new_data_grads_norm = 4.9298
	old_data_grads_norm = 3.9553
	sim_grads_norm_tr = -0.0264
-- Starting training on experience 51 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8239
	data_grads_norm = 3.8908
	new_data_grads_norm = 5.5031
	old_data_grads_norm = 4.6417
	sim_grads_norm_tr = 0.0722
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4476
	data_grads_norm = 4.3750
	new_data_grads_norm = 5.0912
	old_data_grads_norm = 7.1134
	sim_grads_norm_tr = -0.0002
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9794
	data_grads_norm = 4.1028
	new_data_grads_norm = 5.1681
	old_data_grads_norm = 5.7762
	sim_grads_norm_tr = 0.0627
-- Starting training on experience 52 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0527
	data_grads_norm = 3.7214
	new_data_grads_norm = 5.2203
	old_data_grads_norm = 5.9570
	sim_grads_norm_tr = 0.0196
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4473
	data_grads_norm = 4.4602
	new_data_grads_norm = 5.0969
	old_data_grads_norm = 6.4777
	sim_grads_norm_tr = 0.0830
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3653
	data_grads_norm = 3.8265
	new_data_grads_norm = 4.7462
	old_data_grads_norm = 5.4529
	sim_grads_norm_tr = 0.1355
-- Starting training on experience 53 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3917
	data_grads_norm = 3.5046
	new_data_grads_norm = 5.4302
	old_data_grads_norm = 4.9169
	sim_grads_norm_tr = -0.0053
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4194
	data_grads_norm = 3.3899
	new_data_grads_norm = 5.6305
	old_data_grads_norm = 3.7483
	sim_grads_norm_tr = 0.0990
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1382
	data_grads_norm = 2.7753
	new_data_grads_norm = 5.1703
	old_data_grads_norm = 3.3683
	sim_grads_norm_tr = -0.0346
-- Starting training on experience 54 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2029
	data_grads_norm = 2.9874
	new_data_grads_norm = 6.0144
	old_data_grads_norm = 3.7291
	sim_grads_norm_tr = 0.1511
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1400
	data_grads_norm = 3.5751
	new_data_grads_norm = 4.8322
	old_data_grads_norm = 4.4047
	sim_grads_norm_tr = 0.0587
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3144
	data_grads_norm = 3.9953
	new_data_grads_norm = 5.1830
	old_data_grads_norm = 6.4316
	sim_grads_norm_tr = 0.0313
-- Starting training on experience 55 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3717
	data_grads_norm = 2.8010
	new_data_grads_norm = 5.0867
	old_data_grads_norm = 3.1828
	sim_grads_norm_tr = 0.1562
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5363
	data_grads_norm = 3.2717
	new_data_grads_norm = 5.3143
	old_data_grads_norm = 4.6301
	sim_grads_norm_tr = 0.0117
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9800
	data_grads_norm = 2.5293
	new_data_grads_norm = 5.7899
	old_data_grads_norm = 3.2164
	sim_grads_norm_tr = -0.0336
-- Starting training on experience 56 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7983
	data_grads_norm = 4.0526
	new_data_grads_norm = 5.0747
	old_data_grads_norm = 5.3300
	sim_grads_norm_tr = 0.1629
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3653
	data_grads_norm = 3.3477
	new_data_grads_norm = 5.0417
	old_data_grads_norm = 4.7397
	sim_grads_norm_tr = -0.0799
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6074
	data_grads_norm = 3.8770
	new_data_grads_norm = 4.8715
	old_data_grads_norm = 5.8242
	sim_grads_norm_tr = 0.1423
-- Starting training on experience 57 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9847
	data_grads_norm = 2.5323
	new_data_grads_norm = 5.4511
	old_data_grads_norm = 3.0169
	sim_grads_norm_tr = -0.0185
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1079
	data_grads_norm = 2.9600
	new_data_grads_norm = 4.8396
	old_data_grads_norm = 3.9661
	sim_grads_norm_tr = -0.0406
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5398
	data_grads_norm = 4.0428
	new_data_grads_norm = 4.7516
	old_data_grads_norm = 5.0573
	sim_grads_norm_tr = 0.2456
-- Starting training on experience 58 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3218
	data_grads_norm = 3.5819
	new_data_grads_norm = 5.0300
	old_data_grads_norm = 4.3705
	sim_grads_norm_tr = 0.1176
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0694
	data_grads_norm = 3.5670
	new_data_grads_norm = 4.7248
	old_data_grads_norm = 4.2170
	sim_grads_norm_tr = 0.1628
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9070
	data_grads_norm = 2.6546
	new_data_grads_norm = 4.5744
	old_data_grads_norm = 3.3400
	sim_grads_norm_tr = 0.1072
-- Starting training on experience 59 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8425
	data_grads_norm = 3.1213
	new_data_grads_norm = 5.2396
	old_data_grads_norm = 4.4641
	sim_grads_norm_tr = 0.0219
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0027
	data_grads_norm = 3.3513
	new_data_grads_norm = 5.1927
	old_data_grads_norm = 4.5690
	sim_grads_norm_tr = 0.1139
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1357
	data_grads_norm = 2.9045
	new_data_grads_norm = 5.0258
	old_data_grads_norm = 4.5915
	sim_grads_norm_tr = -0.1934
-- Starting training on experience 60 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4019
	data_grads_norm = 4.9044
	new_data_grads_norm = 6.2494
	old_data_grads_norm = 7.3089
	sim_grads_norm_tr = 0.0773
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9184
	data_grads_norm = 4.4169
	new_data_grads_norm = 5.4402
	old_data_grads_norm = 6.6695
	sim_grads_norm_tr = 0.1116
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9969
	data_grads_norm = 3.4569
	new_data_grads_norm = 5.1588
	old_data_grads_norm = 4.9538
	sim_grads_norm_tr = -0.1061
-- Starting training on experience 61 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0095
	data_grads_norm = 3.7949
	new_data_grads_norm = 5.0767
	old_data_grads_norm = 5.0331
	sim_grads_norm_tr = 0.0764
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8049
	data_grads_norm = 2.9236
	new_data_grads_norm = 5.6965
	old_data_grads_norm = 4.1537
	sim_grads_norm_tr = -0.1675
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9397
	data_grads_norm = 2.7391
	new_data_grads_norm = 5.9120
	old_data_grads_norm = 2.8704
	sim_grads_norm_tr = 0.0309
-- Starting training on experience 62 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1224
	data_grads_norm = 3.2904
	new_data_grads_norm = 4.7735
	old_data_grads_norm = 4.1039
	sim_grads_norm_tr = 0.1553
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6713
	data_grads_norm = 2.6032
	new_data_grads_norm = 4.0690
	old_data_grads_norm = 4.0362
	sim_grads_norm_tr = -0.0715
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9647
	data_grads_norm = 3.0316
	new_data_grads_norm = 4.4555
	old_data_grads_norm = 3.9614
	sim_grads_norm_tr = -0.0379
-- Starting training on experience 63 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5929
	data_grads_norm = 3.9141
	new_data_grads_norm = 5.2839
	old_data_grads_norm = 4.6691
	sim_grads_norm_tr = 0.1546
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9891
	data_grads_norm = 3.4254
	new_data_grads_norm = 4.7283
	old_data_grads_norm = 4.2258
	sim_grads_norm_tr = 0.1198
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8402
	data_grads_norm = 2.8950
	new_data_grads_norm = 4.5822
	old_data_grads_norm = 3.3969
	sim_grads_norm_tr = 0.1045
-- Starting training on experience 64 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2076
	data_grads_norm = 3.9713
	new_data_grads_norm = 4.1603
	old_data_grads_norm = 5.9262
	sim_grads_norm_tr = 0.0337
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0388
	data_grads_norm = 2.8593
	new_data_grads_norm = 4.6152
	old_data_grads_norm = 4.2288
	sim_grads_norm_tr = 0.0419
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9554
	data_grads_norm = 2.2092
	new_data_grads_norm = 4.8300
	old_data_grads_norm = 3.5799
	sim_grads_norm_tr = -0.0412
-- Starting training on experience 65 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9613
	data_grads_norm = 4.1889
	new_data_grads_norm = 5.7176
	old_data_grads_norm = 6.1180
	sim_grads_norm_tr = 0.0792
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4554
	data_grads_norm = 4.3196
	new_data_grads_norm = 5.2574
	old_data_grads_norm = 6.1152
	sim_grads_norm_tr = 0.0039
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9673
	data_grads_norm = 3.3573
	new_data_grads_norm = 5.6136
	old_data_grads_norm = 4.0255
	sim_grads_norm_tr = 0.0048
-- Starting training on experience 66 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7327
	data_grads_norm = 2.8182
	new_data_grads_norm = 4.2205
	old_data_grads_norm = 4.0821
	sim_grads_norm_tr = -0.1098
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2381
	data_grads_norm = 3.5936
	new_data_grads_norm = 5.0242
	old_data_grads_norm = 4.9186
	sim_grads_norm_tr = -0.0028
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8973
	data_grads_norm = 3.3577
	new_data_grads_norm = 5.0049
	old_data_grads_norm = 4.6713
	sim_grads_norm_tr = -0.1342
-- Starting training on experience 67 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7833
	data_grads_norm = 4.7762
	new_data_grads_norm = 6.4432
	old_data_grads_norm = 5.6692
	sim_grads_norm_tr = 0.1092
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0457
	data_grads_norm = 3.3058
	new_data_grads_norm = 4.9404
	old_data_grads_norm = 5.2102
	sim_grads_norm_tr = -0.0449
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0349
	data_grads_norm = 3.9249
	new_data_grads_norm = 5.5523
	old_data_grads_norm = 4.7838
	sim_grads_norm_tr = -0.0149
-- Starting training on experience 68 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2705
	data_grads_norm = 4.5077
	new_data_grads_norm = 4.4187
	old_data_grads_norm = 6.5474
	sim_grads_norm_tr = 0.0384
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1664
	data_grads_norm = 4.0084
	new_data_grads_norm = 4.5248
	old_data_grads_norm = 6.8821
	sim_grads_norm_tr = -0.0877
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4283
	data_grads_norm = 4.3352
	new_data_grads_norm = 4.9979
	old_data_grads_norm = 5.6090
	sim_grads_norm_tr = 0.1241
-- Starting training on experience 69 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3028
	data_grads_norm = 3.7063
	new_data_grads_norm = 5.8160
	old_data_grads_norm = 3.8125
	sim_grads_norm_tr = 0.2275
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5694
	data_grads_norm = 4.2892
	new_data_grads_norm = 5.6234
	old_data_grads_norm = 5.8550
	sim_grads_norm_tr = 0.0917
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9510
	data_grads_norm = 2.8603
	new_data_grads_norm = 4.9406
	old_data_grads_norm = 3.6225
	sim_grads_norm_tr = -0.1051
-- Starting training on experience 70 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3309
	data_grads_norm = 4.6985
	new_data_grads_norm = 5.2311
	old_data_grads_norm = 6.0900
	sim_grads_norm_tr = 0.1291
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2105
	data_grads_norm = 4.1969
	new_data_grads_norm = 4.9409
	old_data_grads_norm = 5.4287
	sim_grads_norm_tr = 0.0989
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3620
	data_grads_norm = 4.7584
	new_data_grads_norm = 4.9860
	old_data_grads_norm = 7.1727
	sim_grads_norm_tr = 0.0456
-- Starting training on experience 71 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7834
	data_grads_norm = 5.6604
	new_data_grads_norm = 4.9435
	old_data_grads_norm = 8.2138
	sim_grads_norm_tr = 0.2084
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1304
	data_grads_norm = 3.9793
	new_data_grads_norm = 4.3104
	old_data_grads_norm = 5.1459
	sim_grads_norm_tr = 0.2767
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7892
	data_grads_norm = 2.9093
	new_data_grads_norm = 3.8740
	old_data_grads_norm = 4.2793
	sim_grads_norm_tr = -0.0605
-- Starting training on experience 72 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0489
	data_grads_norm = 3.7133
	new_data_grads_norm = 4.7461
	old_data_grads_norm = 5.1703
	sim_grads_norm_tr = 0.0813
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3702
	data_grads_norm = 3.5809
	new_data_grads_norm = 4.9090
	old_data_grads_norm = 4.5636
	sim_grads_norm_tr = 0.0622
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1332
	data_grads_norm = 3.3382
	new_data_grads_norm = 5.0308
	old_data_grads_norm = 3.6133
	sim_grads_norm_tr = 0.2221
-- Starting training on experience 73 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7560
	data_grads_norm = 3.0843
	new_data_grads_norm = 4.8088
	old_data_grads_norm = 4.5653
	sim_grads_norm_tr = -0.1362
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2852
	data_grads_norm = 3.3491
	new_data_grads_norm = 5.1581
	old_data_grads_norm = 4.1305
	sim_grads_norm_tr = 0.1200
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6278
	data_grads_norm = 4.9358
	new_data_grads_norm = 5.3773
	old_data_grads_norm = 6.7793
	sim_grads_norm_tr = 0.2323
-- Starting training on experience 74 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6801
	data_grads_norm = 2.1322
	new_data_grads_norm = 3.9441
	old_data_grads_norm = 3.8626
	sim_grads_norm_tr = -0.1678
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9334
	data_grads_norm = 2.5296
	new_data_grads_norm = 4.3874
	old_data_grads_norm = 2.9765
	sim_grads_norm_tr = 0.1911
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2569
	data_grads_norm = 3.9293
	new_data_grads_norm = 4.3327
	old_data_grads_norm = 5.6408
	sim_grads_norm_tr = 0.1128
-- Starting training on experience 75 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2683
	data_grads_norm = 3.3002
	new_data_grads_norm = 4.7970
	old_data_grads_norm = 4.9725
	sim_grads_norm_tr = -0.0660
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5148
	data_grads_norm = 3.5559
	new_data_grads_norm = 5.3308
	old_data_grads_norm = 4.6063
	sim_grads_norm_tr = 0.1526
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8552
	data_grads_norm = 2.9390
	new_data_grads_norm = 4.9259
	old_data_grads_norm = 4.3305
	sim_grads_norm_tr = -0.1034
-- Starting training on experience 76 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7216
	data_grads_norm = 2.6217
	new_data_grads_norm = 5.2174
	old_data_grads_norm = 2.8511
	sim_grads_norm_tr = 0.1268
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0924
	data_grads_norm = 3.3499
	new_data_grads_norm = 4.8090
	old_data_grads_norm = 4.8312
	sim_grads_norm_tr = 0.0279
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2036
	data_grads_norm = 3.5504
	new_data_grads_norm = 4.7874
	old_data_grads_norm = 4.1400
	sim_grads_norm_tr = 0.1556
-- Starting training on experience 77 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7845
	data_grads_norm = 2.5161
	new_data_grads_norm = 4.4334
	old_data_grads_norm = 3.1402
	sim_grads_norm_tr = -0.2013
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4151
	data_grads_norm = 3.4716
	new_data_grads_norm = 4.7756
	old_data_grads_norm = 4.5699
	sim_grads_norm_tr = 0.0485
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1378
	data_grads_norm = 3.7396
	new_data_grads_norm = 4.9790
	old_data_grads_norm = 5.5162
	sim_grads_norm_tr = 0.0029
-- Starting training on experience 78 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0003
	data_grads_norm = 3.4098
	new_data_grads_norm = 5.2554
	old_data_grads_norm = 4.0750
	sim_grads_norm_tr = 0.1151
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8657
	data_grads_norm = 2.7605
	new_data_grads_norm = 5.4341
	old_data_grads_norm = 3.7180
	sim_grads_norm_tr = -0.0630
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2347
	data_grads_norm = 3.8210
	new_data_grads_norm = 5.1961
	old_data_grads_norm = 5.5165
	sim_grads_norm_tr = -0.0142
-- Starting training on experience 79 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9579
	data_grads_norm = 3.3040
	new_data_grads_norm = 5.3444
	old_data_grads_norm = 4.3823
	sim_grads_norm_tr = -0.0113
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2700
	data_grads_norm = 3.7267
	new_data_grads_norm = 5.6040
	old_data_grads_norm = 3.8304
	sim_grads_norm_tr = 0.0570
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4064
	data_grads_norm = 3.4174
	new_data_grads_norm = 5.8253
	old_data_grads_norm = 3.4156
	sim_grads_norm_tr = 0.3372
-- Starting training on experience 80 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8250
	data_grads_norm = 3.2404
	new_data_grads_norm = 4.9162
	old_data_grads_norm = 4.0701
	sim_grads_norm_tr = -0.0108
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0704
	data_grads_norm = 3.3793
	new_data_grads_norm = 4.2337
	old_data_grads_norm = 5.7439
	sim_grads_norm_tr = -0.1917
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2123
	data_grads_norm = 4.8361
	new_data_grads_norm = 6.2632
	old_data_grads_norm = 6.1276
	sim_grads_norm_tr = 0.2223
-- Starting training on experience 81 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6242
	data_grads_norm = 3.8940
	new_data_grads_norm = 5.2786
	old_data_grads_norm = 4.9940
	sim_grads_norm_tr = 0.1416
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2089
	data_grads_norm = 3.7796
	new_data_grads_norm = 4.8385
	old_data_grads_norm = 5.1150
	sim_grads_norm_tr = 0.0894
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1318
	data_grads_norm = 3.7278
	new_data_grads_norm = 5.4570
	old_data_grads_norm = 4.4118
	sim_grads_norm_tr = 0.0258
-- Starting training on experience 82 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2726
	data_grads_norm = 4.4129
	new_data_grads_norm = 5.6302
	old_data_grads_norm = 6.2408
	sim_grads_norm_tr = 0.0063
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0235
	data_grads_norm = 5.2665
	new_data_grads_norm = 5.8140
	old_data_grads_norm = 7.7162
	sim_grads_norm_tr = 0.1407
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2667
	data_grads_norm = 3.4151
	new_data_grads_norm = 4.9271
	old_data_grads_norm = 4.3831
	sim_grads_norm_tr = -0.0154
-- Starting training on experience 83 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0418
	data_grads_norm = 3.2763
	new_data_grads_norm = 4.8806
	old_data_grads_norm = 4.6757
	sim_grads_norm_tr = -0.0173
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4003
	data_grads_norm = 3.9683
	new_data_grads_norm = 5.1000
	old_data_grads_norm = 5.1235
	sim_grads_norm_tr = 0.1934
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8632
	data_grads_norm = 3.4626
	new_data_grads_norm = 5.1946
	old_data_grads_norm = 5.6923
	sim_grads_norm_tr = -0.1441
-- Starting training on experience 84 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2063
	data_grads_norm = 3.6976
	new_data_grads_norm = 5.7152
	old_data_grads_norm = 4.1967
	sim_grads_norm_tr = 0.1226
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1761
	data_grads_norm = 3.1081
	new_data_grads_norm = 5.1498
	old_data_grads_norm = 3.9022
	sim_grads_norm_tr = 0.0441
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4323
	data_grads_norm = 4.0564
	new_data_grads_norm = 4.8659
	old_data_grads_norm = 5.9312
	sim_grads_norm_tr = 0.1609
-- Starting training on experience 85 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4811
	data_grads_norm = 4.2677
	new_data_grads_norm = 5.3986
	old_data_grads_norm = 5.8529
	sim_grads_norm_tr = 0.1618
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9935
	data_grads_norm = 2.2814
	new_data_grads_norm = 4.9861
	old_data_grads_norm = 2.9303
	sim_grads_norm_tr = -0.0479
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0618
	data_grads_norm = 3.0203
	new_data_grads_norm = 4.7313
	old_data_grads_norm = 4.0284
	sim_grads_norm_tr = 0.0345
-- Starting training on experience 86 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0907
	data_grads_norm = 3.4578
	new_data_grads_norm = 6.6637
	old_data_grads_norm = 4.5014
	sim_grads_norm_tr = 0.0440
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7109
	data_grads_norm = 2.3186
	new_data_grads_norm = 5.8735
	old_data_grads_norm = 3.0876
	sim_grads_norm_tr = -0.0232
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4914
	data_grads_norm = 5.0730
	new_data_grads_norm = 5.6671
	old_data_grads_norm = 6.2408
	sim_grads_norm_tr = 0.2068
-- Starting training on experience 87 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3003
	data_grads_norm = 4.3139
	new_data_grads_norm = 5.0877
	old_data_grads_norm = 6.1932
	sim_grads_norm_tr = 0.0974
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9936
	data_grads_norm = 3.3479
	new_data_grads_norm = 4.4395
	old_data_grads_norm = 5.0878
	sim_grads_norm_tr = 0.0256
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0133
	data_grads_norm = 3.0838
	new_data_grads_norm = 4.5926
	old_data_grads_norm = 4.2298
	sim_grads_norm_tr = 0.0631
-- Starting training on experience 88 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0264
	data_grads_norm = 4.2885
	new_data_grads_norm = 6.2078
	old_data_grads_norm = 5.8950
	sim_grads_norm_tr = -0.0632
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2677
	data_grads_norm = 3.6200
	new_data_grads_norm = 6.6327
	old_data_grads_norm = 4.4269
	sim_grads_norm_tr = 0.0697
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5509
	data_grads_norm = 3.8752
	new_data_grads_norm = 6.2775
	old_data_grads_norm = 4.1070
	sim_grads_norm_tr = 0.1060
-- Starting training on experience 89 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9522
	data_grads_norm = 3.3002
	new_data_grads_norm = 5.1184
	old_data_grads_norm = 4.4413
	sim_grads_norm_tr = -0.0324
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0172
	data_grads_norm = 3.2428
	new_data_grads_norm = 4.7439
	old_data_grads_norm = 4.7010
	sim_grads_norm_tr = -0.0483
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2098
	data_grads_norm = 3.6126
	new_data_grads_norm = 5.2416
	old_data_grads_norm = 4.1651
	sim_grads_norm_tr = 0.1009
-- Starting training on experience 90 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8016
	data_grads_norm = 4.3175
	new_data_grads_norm = 5.9609
	old_data_grads_norm = 5.7677
	sim_grads_norm_tr = 0.0139
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4064
	data_grads_norm = 4.1086
	new_data_grads_norm = 5.7272
	old_data_grads_norm = 5.2518
	sim_grads_norm_tr = 0.1452
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8907
	data_grads_norm = 3.1592
	new_data_grads_norm = 5.0235
	old_data_grads_norm = 4.0006
	sim_grads_norm_tr = -0.0113
-- Starting training on experience 91 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4717
	data_grads_norm = 4.0286
	new_data_grads_norm = 5.4474
	old_data_grads_norm = 4.7493
	sim_grads_norm_tr = 0.0616
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1691
	data_grads_norm = 3.6855
	new_data_grads_norm = 5.0655
	old_data_grads_norm = 6.0731
	sim_grads_norm_tr = -0.0590
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4641
	data_grads_norm = 3.5688
	new_data_grads_norm = 5.0583
	old_data_grads_norm = 5.7418
	sim_grads_norm_tr = 0.1869
-- Starting training on experience 92 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7712
	data_grads_norm = 2.5705
	new_data_grads_norm = 4.4204
	old_data_grads_norm = 2.8454
	sim_grads_norm_tr = 0.1766
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7715
	data_grads_norm = 2.3368
	new_data_grads_norm = 4.1644
	old_data_grads_norm = 3.3121
	sim_grads_norm_tr = -0.0297
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9250
	data_grads_norm = 2.2996
	new_data_grads_norm = 4.2977
	old_data_grads_norm = 3.0886
	sim_grads_norm_tr = 0.0109
-- Starting training on experience 93 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7282
	data_grads_norm = 3.0012
	new_data_grads_norm = 4.4466
	old_data_grads_norm = 4.3555
	sim_grads_norm_tr = -0.0515
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2252
	data_grads_norm = 3.9040
	new_data_grads_norm = 4.7280
	old_data_grads_norm = 5.1161
	sim_grads_norm_tr = 0.1167
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2476
	data_grads_norm = 3.5357
	new_data_grads_norm = 4.5449
	old_data_grads_norm = 5.2876
	sim_grads_norm_tr = -0.0211
-- Starting training on experience 94 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8590
	data_grads_norm = 2.8001
	new_data_grads_norm = 4.6597
	old_data_grads_norm = 3.5358
	sim_grads_norm_tr = -0.0388
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9747
	data_grads_norm = 3.3494
	new_data_grads_norm = 5.4813
	old_data_grads_norm = 4.3002
	sim_grads_norm_tr = 0.0481
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8227
	data_grads_norm = 3.2599
	new_data_grads_norm = 5.0920
	old_data_grads_norm = 4.2896
	sim_grads_norm_tr = -0.0184
-- Starting training on experience 95 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1477
	data_grads_norm = 2.8536
	new_data_grads_norm = 4.4070
	old_data_grads_norm = 4.2935
	sim_grads_norm_tr = 0.1068
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7902
	data_grads_norm = 2.7851
	new_data_grads_norm = 4.1002
	old_data_grads_norm = 4.2555
	sim_grads_norm_tr = 0.0421
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6569
	data_grads_norm = 3.5257
	new_data_grads_norm = 4.2796
	old_data_grads_norm = 5.0013
	sim_grads_norm_tr = 0.1046
-- Starting training on experience 96 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8663
	data_grads_norm = 3.0154
	new_data_grads_norm = 5.3385
	old_data_grads_norm = 4.2380
	sim_grads_norm_tr = -0.0915
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9278
	data_grads_norm = 3.2353
	new_data_grads_norm = 5.0307
	old_data_grads_norm = 4.1364
	sim_grads_norm_tr = 0.2804
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0705
	data_grads_norm = 2.9776
	new_data_grads_norm = 4.9967
	old_data_grads_norm = 4.1911
	sim_grads_norm_tr = -0.0355
-- Starting training on experience 97 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7481
	data_grads_norm = 2.3463
	new_data_grads_norm = 5.0348
	old_data_grads_norm = 2.5965
	sim_grads_norm_tr = 0.1612
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0672
	data_grads_norm = 2.8603
	new_data_grads_norm = 4.8752
	old_data_grads_norm = 3.6702
	sim_grads_norm_tr = 0.1147
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6724
	data_grads_norm = 3.1193
	new_data_grads_norm = 4.4100
	old_data_grads_norm = 3.7713
	sim_grads_norm_tr = 0.1525
-- Starting training on experience 98 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0370
	data_grads_norm = 2.9704
	new_data_grads_norm = 5.4335
	old_data_grads_norm = 3.3976
	sim_grads_norm_tr = 0.0880
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8573
	data_grads_norm = 3.3864
	new_data_grads_norm = 5.3709
	old_data_grads_norm = 4.1017
	sim_grads_norm_tr = 0.0527
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8210
	data_grads_norm = 2.9405
	new_data_grads_norm = 5.4036
	old_data_grads_norm = 3.9100
	sim_grads_norm_tr = 0.0115
-- Starting training on experience 99 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6616
	data_grads_norm = 2.5238
	new_data_grads_norm = 5.1235
	old_data_grads_norm = 4.2505
	sim_grads_norm_tr = 0.0142
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7218
	data_grads_norm = 3.5386
	new_data_grads_norm = 6.2507
	old_data_grads_norm = 4.1498
	sim_grads_norm_tr = -0.0692
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9726
	data_grads_norm = 4.5663
	new_data_grads_norm = 6.9116
	old_data_grads_norm = 5.6314
	sim_grads_norm_tr = 0.0833
-- Starting training on experience 100 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1635
	data_grads_norm = 2.8212
	new_data_grads_norm = 5.8543
	old_data_grads_norm = 3.7766
	sim_grads_norm_tr = 0.0827
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1838
	data_grads_norm = 3.9190
	new_data_grads_norm = 5.0897
	old_data_grads_norm = 5.3538
	sim_grads_norm_tr = -0.0221
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9191
	data_grads_norm = 3.7222
	new_data_grads_norm = 4.7777
	old_data_grads_norm = 5.0425
	sim_grads_norm_tr = 0.1718
-- Starting training on experience 101 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2025
	data_grads_norm = 2.7479
	new_data_grads_norm = 5.0802
	old_data_grads_norm = 3.6961
	sim_grads_norm_tr = 0.0268
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8706
	data_grads_norm = 2.6855
	new_data_grads_norm = 5.5050
	old_data_grads_norm = 4.4735
	sim_grads_norm_tr = -0.1184
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6270
	data_grads_norm = 4.3665
	new_data_grads_norm = 5.9431
	old_data_grads_norm = 5.3669
	sim_grads_norm_tr = 0.1987
-- Starting training on experience 102 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7053
	data_grads_norm = 3.6298
	new_data_grads_norm = 4.9323
	old_data_grads_norm = 5.6980
	sim_grads_norm_tr = 0.0477
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7767
	data_grads_norm = 2.9732
	new_data_grads_norm = 4.6029
	old_data_grads_norm = 3.8166
	sim_grads_norm_tr = 0.0229
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7132
	data_grads_norm = 2.2842
	new_data_grads_norm = 5.0914
	old_data_grads_norm = 3.3436
	sim_grads_norm_tr = -0.1130
-- Starting training on experience 103 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0416
	data_grads_norm = 4.1078
	new_data_grads_norm = 6.3745
	old_data_grads_norm = 4.6456
	sim_grads_norm_tr = 0.1070
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9701
	data_grads_norm = 4.0425
	new_data_grads_norm = 6.1414
	old_data_grads_norm = 5.1890
	sim_grads_norm_tr = 0.0691
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0527
	data_grads_norm = 3.2918
	new_data_grads_norm = 6.3036
	old_data_grads_norm = 3.9589
	sim_grads_norm_tr = 0.1429
-- Starting training on experience 104 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7171
	data_grads_norm = 2.2316
	new_data_grads_norm = 4.4345
	old_data_grads_norm = 3.5872
	sim_grads_norm_tr = -0.1472
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9697
	data_grads_norm = 3.2092
	new_data_grads_norm = 5.1949
	old_data_grads_norm = 3.5840
	sim_grads_norm_tr = 0.2013
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6561
	data_grads_norm = 3.1434
	new_data_grads_norm = 5.7494
	old_data_grads_norm = 4.4058
	sim_grads_norm_tr = 0.0355
-- Starting training on experience 105 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8798
	data_grads_norm = 2.4800
	new_data_grads_norm = 5.0784
	old_data_grads_norm = 3.3430
	sim_grads_norm_tr = -0.1135
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9363
	data_grads_norm = 2.9511
	new_data_grads_norm = 5.8065
	old_data_grads_norm = 4.0583
	sim_grads_norm_tr = -0.1072
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7344
	data_grads_norm = 4.3580
	new_data_grads_norm = 5.4653
	old_data_grads_norm = 5.6957
	sim_grads_norm_tr = 0.2076
-- Starting training on experience 106 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3687
	data_grads_norm = 3.8802
	new_data_grads_norm = 6.6307
	old_data_grads_norm = 4.9292
	sim_grads_norm_tr = -0.0218
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1514
	data_grads_norm = 3.1131
	new_data_grads_norm = 6.9505
	old_data_grads_norm = 3.2119
	sim_grads_norm_tr = 0.0525
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2210
	data_grads_norm = 4.0357
	new_data_grads_norm = 6.7278
	old_data_grads_norm = 3.5677
	sim_grads_norm_tr = 0.1882
-- Starting training on experience 107 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8542
	data_grads_norm = 3.3741
	new_data_grads_norm = 4.3068
	old_data_grads_norm = 4.1891
	sim_grads_norm_tr = -0.0400
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9208
	data_grads_norm = 3.3659
	new_data_grads_norm = 4.8358
	old_data_grads_norm = 3.4595
	sim_grads_norm_tr = 0.1017
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6863
	data_grads_norm = 3.7662
	new_data_grads_norm = 4.5758
	old_data_grads_norm = 4.6625
	sim_grads_norm_tr = 0.0086
-- Starting training on experience 108 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4407
	data_grads_norm = 4.6116
	new_data_grads_norm = 7.0934
	old_data_grads_norm = 6.1864
	sim_grads_norm_tr = 0.0478
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4744
	data_grads_norm = 4.7936
	new_data_grads_norm = 7.8470
	old_data_grads_norm = 5.2293
	sim_grads_norm_tr = 0.1422
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2514
	data_grads_norm = 4.2871
	new_data_grads_norm = 6.8866
	old_data_grads_norm = 6.5122
	sim_grads_norm_tr = -0.0012
-- Starting training on experience 109 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4340
	data_grads_norm = 4.1487
	new_data_grads_norm = 5.3256
	old_data_grads_norm = 5.6825
	sim_grads_norm_tr = 0.1485
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9024
	data_grads_norm = 3.6395
	new_data_grads_norm = 5.2333
	old_data_grads_norm = 5.1552
	sim_grads_norm_tr = 0.0084
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9789
	data_grads_norm = 4.2073
	new_data_grads_norm = 5.6094
	old_data_grads_norm = 5.5434
	sim_grads_norm_tr = 0.0324
-- Starting training on experience 110 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9434
	data_grads_norm = 4.6256
	new_data_grads_norm = 5.7081
	old_data_grads_norm = 6.7902
	sim_grads_norm_tr = 0.1150
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7516
	data_grads_norm = 2.8658
	new_data_grads_norm = 5.4511
	old_data_grads_norm = 3.3488
	sim_grads_norm_tr = -0.0329
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4452
	data_grads_norm = 3.0599
	new_data_grads_norm = 5.6018
	old_data_grads_norm = 4.3395
	sim_grads_norm_tr = 0.0109
-- Starting training on experience 111 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6624
	data_grads_norm = 2.2705
	new_data_grads_norm = 4.1137
	old_data_grads_norm = 3.1766
	sim_grads_norm_tr = -0.0476
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8867
	data_grads_norm = 3.8886
	new_data_grads_norm = 4.6546
	old_data_grads_norm = 5.4352
	sim_grads_norm_tr = -0.0187
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0155
	data_grads_norm = 3.5522
	new_data_grads_norm = 4.6872
	old_data_grads_norm = 4.7941
	sim_grads_norm_tr = 0.1484
-- Starting training on experience 112 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0140
	data_grads_norm = 3.3815
	new_data_grads_norm = 5.3161
	old_data_grads_norm = 3.9874
	sim_grads_norm_tr = -0.0249
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8170
	data_grads_norm = 3.3200
	new_data_grads_norm = 5.2749
	old_data_grads_norm = 3.6495
	sim_grads_norm_tr = 0.0340
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8765
	data_grads_norm = 4.1970
	new_data_grads_norm = 6.2058
	old_data_grads_norm = 5.5031
	sim_grads_norm_tr = -0.0749
-- Starting training on experience 113 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6885
	data_grads_norm = 3.0502
	new_data_grads_norm = 5.0317
	old_data_grads_norm = 4.1439
	sim_grads_norm_tr = -0.0362
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7928
	data_grads_norm = 3.3509
	new_data_grads_norm = 5.0351
	old_data_grads_norm = 5.6907
	sim_grads_norm_tr = 0.0842
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0421
	data_grads_norm = 4.0795
	new_data_grads_norm = 5.5115
	old_data_grads_norm = 6.6557
	sim_grads_norm_tr = 0.0241
-- Starting training on experience 114 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2962
	data_grads_norm = 4.6521
	new_data_grads_norm = 6.1495
	old_data_grads_norm = 6.1367
	sim_grads_norm_tr = 0.0094
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8176
	data_grads_norm = 3.5833
	new_data_grads_norm = 5.7982
	old_data_grads_norm = 8.3068
	sim_grads_norm_tr = -0.0901
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5201
	data_grads_norm = 4.7639
	new_data_grads_norm = 6.1831
	old_data_grads_norm = 6.8406
	sim_grads_norm_tr = 0.1638
-- Starting training on experience 115 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3077
	data_grads_norm = 4.2439
	new_data_grads_norm = 6.0362
	old_data_grads_norm = 4.7269
	sim_grads_norm_tr = 0.2051
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0181
	data_grads_norm = 2.9876
	new_data_grads_norm = 5.4641
	old_data_grads_norm = 3.7408
	sim_grads_norm_tr = -0.1071
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7793
	data_grads_norm = 3.0867
	new_data_grads_norm = 5.3230
	old_data_grads_norm = 4.2011
	sim_grads_norm_tr = -0.0142
-- Starting training on experience 116 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8237
	data_grads_norm = 3.2756
	new_data_grads_norm = 5.8091
	old_data_grads_norm = 4.3565
	sim_grads_norm_tr = 0.1214
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6748
	data_grads_norm = 4.1050
	new_data_grads_norm = 5.8312
	old_data_grads_norm = 4.0880
	sim_grads_norm_tr = -0.0493
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7589
	data_grads_norm = 3.2017
	new_data_grads_norm = 5.8840
	old_data_grads_norm = 5.2471
	sim_grads_norm_tr = -0.0821
-- Starting training on experience 117 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2551
	data_grads_norm = 3.7514
	new_data_grads_norm = 5.3114
	old_data_grads_norm = 4.3395
	sim_grads_norm_tr = 0.1145
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9429
	data_grads_norm = 2.9273
	new_data_grads_norm = 5.5241
	old_data_grads_norm = 3.4010
	sim_grads_norm_tr = -0.0535
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4229
	data_grads_norm = 4.1367
	new_data_grads_norm = 5.5234
	old_data_grads_norm = 5.4528
	sim_grads_norm_tr = 0.1244
-- Starting training on experience 118 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2171
	data_grads_norm = 3.8563
	new_data_grads_norm = 6.4123
	old_data_grads_norm = 4.2980
	sim_grads_norm_tr = 0.1017
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7797
	data_grads_norm = 3.7260
	new_data_grads_norm = 5.5978
	old_data_grads_norm = 6.6166
	sim_grads_norm_tr = -0.0702
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0144
	data_grads_norm = 3.8601
	new_data_grads_norm = 5.5387
	old_data_grads_norm = 4.6320
	sim_grads_norm_tr = 0.1347
-- Starting training on experience 119 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9680
	data_grads_norm = 3.4951
	new_data_grads_norm = 5.4008
	old_data_grads_norm = 5.0321
	sim_grads_norm_tr = -0.0078
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4018
	data_grads_norm = 3.9417
	new_data_grads_norm = 5.5383
	old_data_grads_norm = 5.9226
	sim_grads_norm_tr = -0.0102
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5139
	data_grads_norm = 2.6227
	new_data_grads_norm = 5.7896
	old_data_grads_norm = 2.7270
	sim_grads_norm_tr = 0.0407
-- Starting training on experience 120 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0783
	data_grads_norm = 3.8801
	new_data_grads_norm = 5.1551
	old_data_grads_norm = 6.0405
	sim_grads_norm_tr = 0.0299
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1356
	data_grads_norm = 3.5871
	new_data_grads_norm = 5.7072
	old_data_grads_norm = 4.3044
	sim_grads_norm_tr = 0.1055
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0560
	data_grads_norm = 4.2434
	new_data_grads_norm = 5.1980
	old_data_grads_norm = 5.8282
	sim_grads_norm_tr = 0.1454
-- Starting training on experience 121 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2084
	data_grads_norm = 3.7273
	new_data_grads_norm = 6.4116
	old_data_grads_norm = 4.5105
	sim_grads_norm_tr = 0.0660
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0803
	data_grads_norm = 3.5653
	new_data_grads_norm = 5.6703
	old_data_grads_norm = 4.0095
	sim_grads_norm_tr = 0.0216
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4979
	data_grads_norm = 3.9582
	new_data_grads_norm = 6.2054
	old_data_grads_norm = 6.0064
	sim_grads_norm_tr = -0.0241
-- Starting training on experience 122 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6308
	data_grads_norm = 3.8304
	new_data_grads_norm = 5.3666
	old_data_grads_norm = 4.9884
	sim_grads_norm_tr = 0.2615
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9031
	data_grads_norm = 3.2855
	new_data_grads_norm = 5.0964
	old_data_grads_norm = 3.7784
	sim_grads_norm_tr = 0.0411
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9801
	data_grads_norm = 3.6616
	new_data_grads_norm = 4.6233
	old_data_grads_norm = 5.2096
	sim_grads_norm_tr = 0.1313
-- Starting training on experience 123 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7741
	data_grads_norm = 3.5660
	new_data_grads_norm = 5.1238
	old_data_grads_norm = 5.1980
	sim_grads_norm_tr = -0.0217
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9419
	data_grads_norm = 3.2078
	new_data_grads_norm = 5.4621
	old_data_grads_norm = 4.4539
	sim_grads_norm_tr = 0.0431
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7992
	data_grads_norm = 3.0936
	new_data_grads_norm = 5.1396
	old_data_grads_norm = 4.1464
	sim_grads_norm_tr = -0.0396
-- Starting training on experience 124 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7353
	data_grads_norm = 3.0304
	new_data_grads_norm = 5.4851
	old_data_grads_norm = 5.4030
	sim_grads_norm_tr = -0.0403
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9262
	data_grads_norm = 3.0033
	new_data_grads_norm = 5.6597
	old_data_grads_norm = 3.3791
	sim_grads_norm_tr = 0.2222
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8200
	data_grads_norm = 3.5345
	new_data_grads_norm = 5.3457
	old_data_grads_norm = 4.7154
	sim_grads_norm_tr = 0.0966
-- Starting training on experience 125 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1668
	data_grads_norm = 4.1987
	new_data_grads_norm = 7.4213
	old_data_grads_norm = 5.1070
	sim_grads_norm_tr = 0.0386
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9325
	data_grads_norm = 3.8952
	new_data_grads_norm = 7.4286
	old_data_grads_norm = 4.9144
	sim_grads_norm_tr = -0.0132
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1222
	data_grads_norm = 3.9639
	new_data_grads_norm = 5.5890
	old_data_grads_norm = 5.2146
	sim_grads_norm_tr = 0.1280
-- Starting training on experience 126 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0587
	data_grads_norm = 3.5730
	new_data_grads_norm = 4.7325
	old_data_grads_norm = 5.0504
	sim_grads_norm_tr = -0.0380
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2441
	data_grads_norm = 2.5415
	new_data_grads_norm = 5.0642
	old_data_grads_norm = 4.2196
	sim_grads_norm_tr = -0.1313
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7616
	data_grads_norm = 3.4223
	new_data_grads_norm = 5.5686
	old_data_grads_norm = 5.4445
	sim_grads_norm_tr = -0.0708
-- Starting training on experience 127 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1829
	data_grads_norm = 4.7264
	new_data_grads_norm = 6.3527
	old_data_grads_norm = 6.2574
	sim_grads_norm_tr = 0.0388
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6004
	data_grads_norm = 4.6506
	new_data_grads_norm = 5.9907
	old_data_grads_norm = 6.0420
	sim_grads_norm_tr = -0.0474
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0811
	data_grads_norm = 4.4863
	new_data_grads_norm = 6.1298
	old_data_grads_norm = 7.9907
	sim_grads_norm_tr = -0.0036
-- Starting training on experience 128 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1799
	data_grads_norm = 4.0033
	new_data_grads_norm = 6.0702
	old_data_grads_norm = 4.6847
	sim_grads_norm_tr = 0.1776
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1889
	data_grads_norm = 4.4426
	new_data_grads_norm = 5.3807
	old_data_grads_norm = 5.5781
	sim_grads_norm_tr = -0.0177
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0418
	data_grads_norm = 3.5299
	new_data_grads_norm = 5.6241
	old_data_grads_norm = 5.3348
	sim_grads_norm_tr = -0.0241
-- Starting training on experience 129 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5634
	data_grads_norm = 4.2484
	new_data_grads_norm = 6.3870
	old_data_grads_norm = 5.4185
	sim_grads_norm_tr = 0.0292
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2052
	data_grads_norm = 4.2859
	new_data_grads_norm = 6.3601
	old_data_grads_norm = 7.2397
	sim_grads_norm_tr = 0.0027
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6949
	data_grads_norm = 3.9870
	new_data_grads_norm = 7.0234
	old_data_grads_norm = 5.0684
	sim_grads_norm_tr = 0.0558
-- Starting training on experience 130 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4773
	data_grads_norm = 4.4655
	new_data_grads_norm = 5.7955
	old_data_grads_norm = 5.7658
	sim_grads_norm_tr = 0.1979
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8129
	data_grads_norm = 3.2227
	new_data_grads_norm = 6.3658
	old_data_grads_norm = 3.0668
	sim_grads_norm_tr = 0.1458
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1981
	data_grads_norm = 4.2172
	new_data_grads_norm = 5.4970
	old_data_grads_norm = 4.9869
	sim_grads_norm_tr = 0.0563
-- Starting training on experience 131 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0048
	data_grads_norm = 3.9637
	new_data_grads_norm = 6.0847
	old_data_grads_norm = 4.7089
	sim_grads_norm_tr = 0.1562
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9827
	data_grads_norm = 2.7916
	new_data_grads_norm = 5.2872
	old_data_grads_norm = 3.5287
	sim_grads_norm_tr = 0.0992
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5929
	data_grads_norm = 2.6372
	new_data_grads_norm = 5.2331
	old_data_grads_norm = 3.4430
	sim_grads_norm_tr = -0.0656
-- Starting training on experience 132 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0900
	data_grads_norm = 3.8074
	new_data_grads_norm = 4.5998
	old_data_grads_norm = 4.7261
	sim_grads_norm_tr = 0.2133
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9131
	data_grads_norm = 2.9846
	new_data_grads_norm = 4.3600
	old_data_grads_norm = 4.1581
	sim_grads_norm_tr = 0.1083
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2240
	data_grads_norm = 3.7434
	new_data_grads_norm = 4.2156
	old_data_grads_norm = 5.6334
	sim_grads_norm_tr = 0.0926
-- Starting training on experience 133 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8632
	data_grads_norm = 2.9121
	new_data_grads_norm = 5.5615
	old_data_grads_norm = 3.4611
	sim_grads_norm_tr = 0.0362
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8664
	data_grads_norm = 3.3414
	new_data_grads_norm = 5.9173
	old_data_grads_norm = 5.0443
	sim_grads_norm_tr = 0.0185
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0868
	data_grads_norm = 3.9967
	new_data_grads_norm = 5.2646
	old_data_grads_norm = 6.0754
	sim_grads_norm_tr = 0.0198
-- Starting training on experience 134 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7744
	data_grads_norm = 3.2535
	new_data_grads_norm = 5.7696
	old_data_grads_norm = 3.6788
	sim_grads_norm_tr = -0.0521
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2147
	data_grads_norm = 3.3084
	new_data_grads_norm = 5.8649
	old_data_grads_norm = 3.3807
	sim_grads_norm_tr = 0.1840
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0170
	data_grads_norm = 3.8629
	new_data_grads_norm = 5.6388
	old_data_grads_norm = 4.5289
	sim_grads_norm_tr = 0.0673
-- Starting training on experience 135 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7724
	data_grads_norm = 3.0301
	new_data_grads_norm = 5.3492
	old_data_grads_norm = 3.5314
	sim_grads_norm_tr = 0.0460
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2907
	data_grads_norm = 4.0253
	new_data_grads_norm = 6.1073
	old_data_grads_norm = 4.7825
	sim_grads_norm_tr = 0.1939
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2707
	data_grads_norm = 4.1184
	new_data_grads_norm = 5.8396
	old_data_grads_norm = 4.5041
	sim_grads_norm_tr = 0.1066
-- Starting training on experience 136 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8030
	data_grads_norm = 2.9363
	new_data_grads_norm = 5.0531
	old_data_grads_norm = 3.8710
	sim_grads_norm_tr = 0.0160
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6440
	data_grads_norm = 2.9740
	new_data_grads_norm = 5.6958
	old_data_grads_norm = 3.2205
	sim_grads_norm_tr = 0.2052
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2701
	data_grads_norm = 3.6116
	new_data_grads_norm = 4.7057
	old_data_grads_norm = 4.2351
	sim_grads_norm_tr = -0.0614
-- Starting training on experience 137 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1648
	data_grads_norm = 3.1792
	new_data_grads_norm = 5.1184
	old_data_grads_norm = 4.4350
	sim_grads_norm_tr = 0.0731
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1608
	data_grads_norm = 3.8062
	new_data_grads_norm = 5.1172
	old_data_grads_norm = 4.6676
	sim_grads_norm_tr = 0.0137
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1250
	data_grads_norm = 3.1100
	new_data_grads_norm = 5.3829
	old_data_grads_norm = 3.8995
	sim_grads_norm_tr = -0.0640
-- Starting training on experience 138 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0708
	data_grads_norm = 3.6287
	new_data_grads_norm = 5.3899
	old_data_grads_norm = 4.6836
	sim_grads_norm_tr = 0.0543
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1652
	data_grads_norm = 3.9905
	new_data_grads_norm = 5.7223
	old_data_grads_norm = 5.6551
	sim_grads_norm_tr = 0.0646
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0511
	data_grads_norm = 3.8203
	new_data_grads_norm = 5.9157
	old_data_grads_norm = 5.1049
	sim_grads_norm_tr = 0.0027
-- Starting training on experience 139 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7888
	data_grads_norm = 3.0056
	new_data_grads_norm = 5.3163
	old_data_grads_norm = 3.7850
	sim_grads_norm_tr = -0.0152
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8646
	data_grads_norm = 3.3829
	new_data_grads_norm = 5.1017
	old_data_grads_norm = 3.4584
	sim_grads_norm_tr = 0.1810
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8701
	data_grads_norm = 3.2671
	new_data_grads_norm = 5.7029
	old_data_grads_norm = 4.3331
	sim_grads_norm_tr = 0.0525
-- Starting training on experience 140 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0832
	data_grads_norm = 3.5813
	new_data_grads_norm = 5.3237
	old_data_grads_norm = 4.6451
	sim_grads_norm_tr = -0.0096
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8597
	data_grads_norm = 3.5478
	new_data_grads_norm = 5.7293
	old_data_grads_norm = 4.1435
	sim_grads_norm_tr = 0.0834
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2213
	data_grads_norm = 3.7323
	new_data_grads_norm = 5.3891
	old_data_grads_norm = 5.9170
	sim_grads_norm_tr = -0.0307
-- Starting training on experience 141 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5929
	data_grads_norm = 2.7625
	new_data_grads_norm = 6.1961
	old_data_grads_norm = 3.0915
	sim_grads_norm_tr = -0.0086
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8224
	data_grads_norm = 3.8822
	new_data_grads_norm = 6.3181
	old_data_grads_norm = 4.2709
	sim_grads_norm_tr = 0.3183
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0328
	data_grads_norm = 3.5313
	new_data_grads_norm = 6.2174
	old_data_grads_norm = 4.9242
	sim_grads_norm_tr = 0.0077
-- Starting training on experience 142 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2699
	data_grads_norm = 3.6860
	new_data_grads_norm = 6.0508
	old_data_grads_norm = 4.4678
	sim_grads_norm_tr = 0.1907
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7250
	data_grads_norm = 3.0862
	new_data_grads_norm = 4.7366
	old_data_grads_norm = 5.2047
	sim_grads_norm_tr = 0.0563
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8992
	data_grads_norm = 3.1979
	new_data_grads_norm = 4.9848
	old_data_grads_norm = 5.2799
	sim_grads_norm_tr = -0.0096
-- Starting training on experience 143 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2985
	data_grads_norm = 4.1807
	new_data_grads_norm = 5.7133
	old_data_grads_norm = 5.0900
	sim_grads_norm_tr = 0.0932
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2277
	data_grads_norm = 3.4408
	new_data_grads_norm = 6.2382
	old_data_grads_norm = 3.6298
	sim_grads_norm_tr = 0.0868
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9271
	data_grads_norm = 3.0959
	new_data_grads_norm = 6.3231
	old_data_grads_norm = 3.7699
	sim_grads_norm_tr = 0.0024
-- Starting training on experience 144 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5921
	data_grads_norm = 2.2517
	new_data_grads_norm = 5.2119
	old_data_grads_norm = 2.6181
	sim_grads_norm_tr = -0.0899
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0875
	data_grads_norm = 4.4273
	new_data_grads_norm = 5.7999
	old_data_grads_norm = 5.0643
	sim_grads_norm_tr = 0.0580
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6927
	data_grads_norm = 3.6099
	new_data_grads_norm = 5.6900
	old_data_grads_norm = 4.3446
	sim_grads_norm_tr = 0.1413
-- Starting training on experience 145 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3403
	data_grads_norm = 4.5755
	new_data_grads_norm = 6.7462
	old_data_grads_norm = 5.0262
	sim_grads_norm_tr = 0.0989
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4554
	data_grads_norm = 4.4608
	new_data_grads_norm = 6.6708
	old_data_grads_norm = 5.0485
	sim_grads_norm_tr = 0.0554
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0411
	data_grads_norm = 4.0049
	new_data_grads_norm = 6.6698
	old_data_grads_norm = 4.6586
	sim_grads_norm_tr = -0.0320
-- Starting training on experience 146 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5986
	data_grads_norm = 2.9086
	new_data_grads_norm = 5.2332
	old_data_grads_norm = 4.0612
	sim_grads_norm_tr = 0.0176
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0034
	data_grads_norm = 3.6876
	new_data_grads_norm = 5.2939
	old_data_grads_norm = 4.8909
	sim_grads_norm_tr = 0.0883
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6959
	data_grads_norm = 3.0732
	new_data_grads_norm = 4.3300
	old_data_grads_norm = 4.5277
	sim_grads_norm_tr = -0.0402
-- Starting training on experience 147 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7757
	data_grads_norm = 3.4555
	new_data_grads_norm = 5.7011
	old_data_grads_norm = 5.6190
	sim_grads_norm_tr = -0.1220
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2630
	data_grads_norm = 3.8057
	new_data_grads_norm = 5.4169
	old_data_grads_norm = 4.8664
	sim_grads_norm_tr = 0.1457
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6476
	data_grads_norm = 3.1652
	new_data_grads_norm = 5.4501
	old_data_grads_norm = 3.9233
	sim_grads_norm_tr = 0.0346
-- Starting training on experience 148 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6355
	data_grads_norm = 3.2539
	new_data_grads_norm = 5.7373
	old_data_grads_norm = 4.8831
	sim_grads_norm_tr = 0.0398
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9425
	data_grads_norm = 3.4012
	new_data_grads_norm = 4.9941
	old_data_grads_norm = 4.5813
	sim_grads_norm_tr = 0.0404
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7154
	data_grads_norm = 3.6926
	new_data_grads_norm = 4.8805
	old_data_grads_norm = 4.7216
	sim_grads_norm_tr = -0.0476
-- Starting training on experience 149 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5901
	data_grads_norm = 5.0055
	new_data_grads_norm = 7.0072
	old_data_grads_norm = 6.2352
	sim_grads_norm_tr = 0.0683
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1128
	data_grads_norm = 3.6604
	new_data_grads_norm = 6.9297
	old_data_grads_norm = 3.9825
	sim_grads_norm_tr = -0.0624
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1771
	data_grads_norm = 4.3952
	new_data_grads_norm = 7.5263
	old_data_grads_norm = 4.6945
	sim_grads_norm_tr = 0.0828
-- Starting training on experience 150 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6964
	data_grads_norm = 2.8576
	new_data_grads_norm = 6.2567
	old_data_grads_norm = 3.7694
	sim_grads_norm_tr = -0.1705
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1859
	data_grads_norm = 3.4656
	new_data_grads_norm = 6.3610
	old_data_grads_norm = 4.0425
	sim_grads_norm_tr = 0.1888
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9538
	data_grads_norm = 3.0899
	new_data_grads_norm = 5.4899
	old_data_grads_norm = 3.2815
	sim_grads_norm_tr = 0.1470
-- Starting training on experience 151 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7703
	data_grads_norm = 3.5300
	new_data_grads_norm = 6.0619
	old_data_grads_norm = 4.5856
	sim_grads_norm_tr = 0.0604
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9530
	data_grads_norm = 3.2654
	new_data_grads_norm = 6.2271
	old_data_grads_norm = 2.9794
	sim_grads_norm_tr = 0.2498
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6217
	data_grads_norm = 3.2971
	new_data_grads_norm = 6.1369
	old_data_grads_norm = 4.2094
	sim_grads_norm_tr = -0.0616
-- Starting training on experience 152 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9869
	data_grads_norm = 4.4162
	new_data_grads_norm = 6.0138
	old_data_grads_norm = 5.3745
	sim_grads_norm_tr = 0.0857
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2276
	data_grads_norm = 4.2592
	new_data_grads_norm = 5.3235
	old_data_grads_norm = 5.2317
	sim_grads_norm_tr = 0.2975
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7997
	data_grads_norm = 3.4853
	new_data_grads_norm = 4.7243
	old_data_grads_norm = 4.8948
	sim_grads_norm_tr = 0.0259
-- Starting training on experience 153 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1152
	data_grads_norm = 4.0343
	new_data_grads_norm = 5.8496
	old_data_grads_norm = 5.6540
	sim_grads_norm_tr = -0.0650
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9139
	data_grads_norm = 4.0495
	new_data_grads_norm = 5.9569
	old_data_grads_norm = 4.5087
	sim_grads_norm_tr = 0.0356
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3723
	data_grads_norm = 4.6872
	new_data_grads_norm = 6.4487
	old_data_grads_norm = 6.2976
	sim_grads_norm_tr = -0.0221
-- Starting training on experience 154 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8464
	data_grads_norm = 3.6170
	new_data_grads_norm = 5.4157
	old_data_grads_norm = 5.0218
	sim_grads_norm_tr = 0.0227
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9907
	data_grads_norm = 4.0984
	new_data_grads_norm = 5.6402
	old_data_grads_norm = 5.7902
	sim_grads_norm_tr = -0.0285
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9299
	data_grads_norm = 3.3849
	new_data_grads_norm = 5.8375
	old_data_grads_norm = 4.5542
	sim_grads_norm_tr = -0.0251
-- Starting training on experience 155 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1580
	data_grads_norm = 4.2876
	new_data_grads_norm = 5.7538
	old_data_grads_norm = 5.6404
	sim_grads_norm_tr = -0.0734
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8863
	data_grads_norm = 2.2698
	new_data_grads_norm = 5.4320
	old_data_grads_norm = 2.8940
	sim_grads_norm_tr = -0.0759
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1108
	data_grads_norm = 3.4955
	new_data_grads_norm = 7.0088
	old_data_grads_norm = 3.9459
	sim_grads_norm_tr = 0.1754
-- Starting training on experience 156 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8384
	data_grads_norm = 3.3781
	new_data_grads_norm = 5.8481
	old_data_grads_norm = 3.5346
	sim_grads_norm_tr = 0.1276
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0481
	data_grads_norm = 2.9353
	new_data_grads_norm = 5.5666
	old_data_grads_norm = 3.7692
	sim_grads_norm_tr = 0.0143
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9785
	data_grads_norm = 4.2577
	new_data_grads_norm = 5.9831
	old_data_grads_norm = 5.3687
	sim_grads_norm_tr = 0.0982
-- Starting training on experience 157 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3659
	data_grads_norm = 5.2495
	new_data_grads_norm = 6.2679
	old_data_grads_norm = 6.7298
	sim_grads_norm_tr = 0.2200
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0427
	data_grads_norm = 3.7443
	new_data_grads_norm = 4.9254
	old_data_grads_norm = 7.5855
	sim_grads_norm_tr = -0.1070
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9902
	data_grads_norm = 3.7456
	new_data_grads_norm = 6.3625
	old_data_grads_norm = 4.2702
	sim_grads_norm_tr = 0.1817
-- Starting training on experience 158 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2463
	data_grads_norm = 3.7535
	new_data_grads_norm = 6.7466
	old_data_grads_norm = 4.1087
	sim_grads_norm_tr = 0.0533
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9025
	data_grads_norm = 3.9783
	new_data_grads_norm = 6.7133
	old_data_grads_norm = 4.3355
	sim_grads_norm_tr = -0.0139
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5732
	data_grads_norm = 5.3863
	new_data_grads_norm = 6.4619
	old_data_grads_norm = 6.7734
	sim_grads_norm_tr = 0.1121
-- Starting training on experience 159 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8066
	data_grads_norm = 2.6209
	new_data_grads_norm = 5.7975
	old_data_grads_norm = 3.6597
	sim_grads_norm_tr = -0.1147
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3377
	data_grads_norm = 4.1271
	new_data_grads_norm = 5.8749
	old_data_grads_norm = 4.9423
	sim_grads_norm_tr = 0.1118
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2922
	data_grads_norm = 4.7444
	new_data_grads_norm = 5.3887
	old_data_grads_norm = 6.8091
	sim_grads_norm_tr = 0.0454
-- Starting training on experience 160 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9678
	data_grads_norm = 3.3676
	new_data_grads_norm = 5.3356
	old_data_grads_norm = 4.6738
	sim_grads_norm_tr = -0.0859
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0700
	data_grads_norm = 3.3451
	new_data_grads_norm = 5.3678
	old_data_grads_norm = 4.6830
	sim_grads_norm_tr = 0.0097
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3692
	data_grads_norm = 4.5123
	new_data_grads_norm = 5.5299
	old_data_grads_norm = 6.7950
	sim_grads_norm_tr = 0.0165
-- Starting training on experience 161 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6524
	data_grads_norm = 3.0260
	new_data_grads_norm = 4.8416
	old_data_grads_norm = 4.5335
	sim_grads_norm_tr = -0.0212
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5374
	data_grads_norm = 3.7435
	new_data_grads_norm = 5.1399
	old_data_grads_norm = 5.0058
	sim_grads_norm_tr = 0.1206
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1437
	data_grads_norm = 3.6470
	new_data_grads_norm = 5.2433
	old_data_grads_norm = 5.3839
	sim_grads_norm_tr = 0.0550
-- Starting training on experience 162 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8055
	data_grads_norm = 3.4893
	new_data_grads_norm = 4.6886
	old_data_grads_norm = 5.1904
	sim_grads_norm_tr = 0.1543
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8660
	data_grads_norm = 3.5421
	new_data_grads_norm = 4.6528
	old_data_grads_norm = 4.3679
	sim_grads_norm_tr = -0.0500
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2972
	data_grads_norm = 4.0895
	new_data_grads_norm = 4.9313
	old_data_grads_norm = 6.1967
	sim_grads_norm_tr = 0.0356
-- Starting training on experience 163 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0873
	data_grads_norm = 3.2883
	new_data_grads_norm = 5.9714
	old_data_grads_norm = 3.4419
	sim_grads_norm_tr = 0.0536
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7882
	data_grads_norm = 4.5667
	new_data_grads_norm = 7.0592
	old_data_grads_norm = 6.1239
	sim_grads_norm_tr = -0.0139
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7088
	data_grads_norm = 4.9596
	new_data_grads_norm = 7.0334
	old_data_grads_norm = 6.2317
	sim_grads_norm_tr = 0.0310
-- Starting training on experience 164 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9007
	data_grads_norm = 3.0465
	new_data_grads_norm = 4.8464
	old_data_grads_norm = 3.0799
	sim_grads_norm_tr = 0.1365
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3486
	data_grads_norm = 3.8362
	new_data_grads_norm = 5.0657
	old_data_grads_norm = 5.3076
	sim_grads_norm_tr = 0.0766
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8918
	data_grads_norm = 3.1644
	new_data_grads_norm = 4.8244
	old_data_grads_norm = 4.3571
	sim_grads_norm_tr = -0.0901
-- Starting training on experience 165 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1555
	data_grads_norm = 2.9664
	new_data_grads_norm = 5.7906
	old_data_grads_norm = 3.3924
	sim_grads_norm_tr = 0.0012
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2751
	data_grads_norm = 3.9420
	new_data_grads_norm = 5.5128
	old_data_grads_norm = 4.6965
	sim_grads_norm_tr = 0.2431
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0173
	data_grads_norm = 2.9029
	new_data_grads_norm = 5.5174
	old_data_grads_norm = 3.8372
	sim_grads_norm_tr = 0.0421
-- Starting training on experience 166 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3172
	data_grads_norm = 2.7832
	new_data_grads_norm = 4.2642
	old_data_grads_norm = 3.8230
	sim_grads_norm_tr = -0.0612
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5629
	data_grads_norm = 2.3417
	new_data_grads_norm = 4.8203
	old_data_grads_norm = 3.3885
	sim_grads_norm_tr = -0.1181
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7627
	data_grads_norm = 4.1387
	new_data_grads_norm = 4.7205
	old_data_grads_norm = 5.1546
	sim_grads_norm_tr = -0.1721
-- Starting training on experience 167 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9808
	data_grads_norm = 3.2316
	new_data_grads_norm = 5.1326
	old_data_grads_norm = 4.3063
	sim_grads_norm_tr = 0.0434
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7482
	data_grads_norm = 2.5665
	new_data_grads_norm = 4.8572
	old_data_grads_norm = 3.0174
	sim_grads_norm_tr = 0.1046
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6621
	data_grads_norm = 2.6271
	new_data_grads_norm = 4.9426
	old_data_grads_norm = 3.5434
	sim_grads_norm_tr = -0.0227
-- Starting training on experience 168 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9169
	data_grads_norm = 2.9350
	new_data_grads_norm = 5.8941
	old_data_grads_norm = 4.4455
	sim_grads_norm_tr = -0.0700
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8404
	data_grads_norm = 4.2392
	new_data_grads_norm = 5.6153
	old_data_grads_norm = 5.4180
	sim_grads_norm_tr = -0.0035
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7746
	data_grads_norm = 2.9243
	new_data_grads_norm = 5.8561
	old_data_grads_norm = 4.0420
	sim_grads_norm_tr = -0.0308
-- Starting training on experience 169 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1507
	data_grads_norm = 4.0938
	new_data_grads_norm = 5.5181
	old_data_grads_norm = 4.8375
	sim_grads_norm_tr = 0.1746
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9404
	data_grads_norm = 3.5196
	new_data_grads_norm = 5.7594
	old_data_grads_norm = 4.3421
	sim_grads_norm_tr = -0.0373
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0699
	data_grads_norm = 4.3182
	new_data_grads_norm = 6.1741
	old_data_grads_norm = 5.8603
	sim_grads_norm_tr = 0.0502
-- Starting training on experience 170 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4260
	data_grads_norm = 5.1473
	new_data_grads_norm = 6.8930
	old_data_grads_norm = 6.3620
	sim_grads_norm_tr = 0.2795
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5346
	data_grads_norm = 3.5704
	new_data_grads_norm = 5.9373
	old_data_grads_norm = 4.1765
	sim_grads_norm_tr = 0.0205
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7291
	data_grads_norm = 3.3151
	new_data_grads_norm = 5.8994
	old_data_grads_norm = 3.7949
	sim_grads_norm_tr = -0.0696
-- Starting training on experience 171 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8846
	data_grads_norm = 4.1590
	new_data_grads_norm = 5.7902
	old_data_grads_norm = 5.5682
	sim_grads_norm_tr = 0.1212
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7681
	data_grads_norm = 3.0167
	new_data_grads_norm = 5.3981
	old_data_grads_norm = 3.2649
	sim_grads_norm_tr = 0.0120
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1894
	data_grads_norm = 3.9721
	new_data_grads_norm = 5.4426
	old_data_grads_norm = 5.1686
	sim_grads_norm_tr = 0.0763
-- Starting training on experience 172 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0297
	data_grads_norm = 4.2725
	new_data_grads_norm = 6.5564
	old_data_grads_norm = 5.3532
	sim_grads_norm_tr = 0.0329
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0655
	data_grads_norm = 3.8630
	new_data_grads_norm = 6.3586
	old_data_grads_norm = 4.7284
	sim_grads_norm_tr = 0.0438
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1254
	data_grads_norm = 3.8532
	new_data_grads_norm = 5.9729
	old_data_grads_norm = 4.2806
	sim_grads_norm_tr = -0.0399
-- Starting training on experience 173 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9234
	data_grads_norm = 3.3903
	new_data_grads_norm = 5.6819
	old_data_grads_norm = 4.7284
	sim_grads_norm_tr = -0.0317
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0332
	data_grads_norm = 3.3980
	new_data_grads_norm = 5.6266
	old_data_grads_norm = 4.0392
	sim_grads_norm_tr = 0.0746
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3832
	data_grads_norm = 4.3272
	new_data_grads_norm = 5.7983
	old_data_grads_norm = 5.3688
	sim_grads_norm_tr = 0.2062
-- Starting training on experience 174 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1198
	data_grads_norm = 3.9336
	new_data_grads_norm = 5.8113
	old_data_grads_norm = 3.9295
	sim_grads_norm_tr = 0.0571
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7429
	data_grads_norm = 3.4744
	new_data_grads_norm = 5.3190
	old_data_grads_norm = 3.8393
	sim_grads_norm_tr = -0.0150
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0072
	data_grads_norm = 3.9138
	new_data_grads_norm = 5.5146
	old_data_grads_norm = 4.0849
	sim_grads_norm_tr = 0.1918
-- Starting training on experience 175 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8438
	data_grads_norm = 3.3316
	new_data_grads_norm = 5.4221
	old_data_grads_norm = 3.8825
	sim_grads_norm_tr = 0.0098
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9703
	data_grads_norm = 3.5083
	new_data_grads_norm = 5.4031
	old_data_grads_norm = 4.5628
	sim_grads_norm_tr = -0.0046
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8620
	data_grads_norm = 4.0642
	new_data_grads_norm = 6.2181
	old_data_grads_norm = 5.8309
	sim_grads_norm_tr = 0.1123
-- Starting training on experience 176 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0596
	data_grads_norm = 4.0853
	new_data_grads_norm = 7.0038
	old_data_grads_norm = 4.5832
	sim_grads_norm_tr = 0.0697
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8828
	data_grads_norm = 4.5054
	new_data_grads_norm = 6.8195
	old_data_grads_norm = 5.8239
	sim_grads_norm_tr = 0.0963
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9653
	data_grads_norm = 3.9008
	new_data_grads_norm = 7.4308
	old_data_grads_norm = 4.5262
	sim_grads_norm_tr = -0.0202
-- Starting training on experience 177 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7851
	data_grads_norm = 4.8104
	new_data_grads_norm = 6.1515
	old_data_grads_norm = 6.9029
	sim_grads_norm_tr = 0.0847
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3644
	data_grads_norm = 4.2757
	new_data_grads_norm = 6.4319
	old_data_grads_norm = 5.1402
	sim_grads_norm_tr = 0.0850
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9812
	data_grads_norm = 3.3804
	new_data_grads_norm = 6.0694
	old_data_grads_norm = 5.3803
	sim_grads_norm_tr = -0.0011
-- Starting training on experience 178 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3733
	data_grads_norm = 3.5118
	new_data_grads_norm = 5.5224
	old_data_grads_norm = 4.3538
	sim_grads_norm_tr = 0.0362
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7238
	data_grads_norm = 2.8527
	new_data_grads_norm = 5.5557
	old_data_grads_norm = 3.7530
	sim_grads_norm_tr = 0.0089
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9402
	data_grads_norm = 3.3316
	new_data_grads_norm = 5.8445
	old_data_grads_norm = 4.1478
	sim_grads_norm_tr = 0.0623
-- Starting training on experience 179 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5450
	data_grads_norm = 3.0798
	new_data_grads_norm = 5.7255
	old_data_grads_norm = 3.3249
	sim_grads_norm_tr = -0.0538
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8250
	data_grads_norm = 3.4302
	new_data_grads_norm = 5.3444
	old_data_grads_norm = 4.8480
	sim_grads_norm_tr = -0.0309
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8775
	data_grads_norm = 3.5635
	new_data_grads_norm = 5.9247
	old_data_grads_norm = 4.7584
	sim_grads_norm_tr = 0.0394
-- Starting training on experience 180 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8837
	data_grads_norm = 3.9598
	new_data_grads_norm = 6.0231
	old_data_grads_norm = 4.1288
	sim_grads_norm_tr = -0.0542
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3721
	data_grads_norm = 4.5515
	new_data_grads_norm = 6.1782
	old_data_grads_norm = 6.3980
	sim_grads_norm_tr = 0.1324
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0109
	data_grads_norm = 3.6988
	new_data_grads_norm = 5.6972
	old_data_grads_norm = 4.2491
	sim_grads_norm_tr = -0.0326
-- Starting training on experience 181 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0371
	data_grads_norm = 4.5904
	new_data_grads_norm = 6.6812
	old_data_grads_norm = 6.8369
	sim_grads_norm_tr = -0.0033
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5290
	data_grads_norm = 4.9182
	new_data_grads_norm = 6.6058
	old_data_grads_norm = 7.1065
	sim_grads_norm_tr = 0.1365
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9411
	data_grads_norm = 4.7374
	new_data_grads_norm = 5.9405
	old_data_grads_norm = 8.3733
	sim_grads_norm_tr = -0.0286
-- Starting training on experience 182 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2687
	data_grads_norm = 3.8107
	new_data_grads_norm = 5.7636
	old_data_grads_norm = 4.3740
	sim_grads_norm_tr = -0.0102
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2044
	data_grads_norm = 3.3809
	new_data_grads_norm = 5.8900
	old_data_grads_norm = 4.2312
	sim_grads_norm_tr = 0.1165
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5558
	data_grads_norm = 2.2014
	new_data_grads_norm = 5.4824
	old_data_grads_norm = 3.0051
	sim_grads_norm_tr = -0.2054
-- Starting training on experience 183 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9894
	data_grads_norm = 3.5020
	new_data_grads_norm = 5.0660
	old_data_grads_norm = 5.1019
	sim_grads_norm_tr = 0.0784
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9760
	data_grads_norm = 3.7465
	new_data_grads_norm = 5.3244
	old_data_grads_norm = 4.9299
	sim_grads_norm_tr = 0.1622
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9084
	data_grads_norm = 3.5394
	new_data_grads_norm = 5.4394
	old_data_grads_norm = 5.6730
	sim_grads_norm_tr = -0.0040
-- Starting training on experience 184 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5720
	data_grads_norm = 4.0694
	new_data_grads_norm = 5.9705
	old_data_grads_norm = 5.5112
	sim_grads_norm_tr = 0.0663
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1098
	data_grads_norm = 3.5287
	new_data_grads_norm = 5.7394
	old_data_grads_norm = 4.8045
	sim_grads_norm_tr = -0.0597
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0042
	data_grads_norm = 3.7728
	new_data_grads_norm = 5.8924
	old_data_grads_norm = 4.8891
	sim_grads_norm_tr = 0.0078
-- Starting training on experience 185 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9438
	data_grads_norm = 3.5624
	new_data_grads_norm = 4.2487
	old_data_grads_norm = 5.6501
	sim_grads_norm_tr = -0.0316
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7571
	data_grads_norm = 3.0864
	new_data_grads_norm = 4.2839
	old_data_grads_norm = 4.1300
	sim_grads_norm_tr = -0.1065
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9442
	data_grads_norm = 3.9514
	new_data_grads_norm = 4.8445
	old_data_grads_norm = 4.8459
	sim_grads_norm_tr = 0.2662
-- Starting training on experience 186 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7296
	data_grads_norm = 2.9770
	new_data_grads_norm = 5.0649
	old_data_grads_norm = 3.9075
	sim_grads_norm_tr = 0.0065
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7702
	data_grads_norm = 3.4476
	new_data_grads_norm = 5.5030
	old_data_grads_norm = 3.1838
	sim_grads_norm_tr = 0.0606
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7926
	data_grads_norm = 3.8713
	new_data_grads_norm = 5.2829
	old_data_grads_norm = 4.0759
	sim_grads_norm_tr = 0.4663
-- Starting training on experience 187 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8581
	data_grads_norm = 3.6082
	new_data_grads_norm = 5.3085
	old_data_grads_norm = 5.7691
	sim_grads_norm_tr = -0.1341
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4388
	data_grads_norm = 2.6616
	new_data_grads_norm = 6.4889
	old_data_grads_norm = 4.0464
	sim_grads_norm_tr = -0.1936
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4680
	data_grads_norm = 3.3554
	new_data_grads_norm = 6.2204
	old_data_grads_norm = 4.1141
	sim_grads_norm_tr = 0.0905
-- Starting training on experience 188 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7175
	data_grads_norm = 3.6801
	new_data_grads_norm = 4.9458
	old_data_grads_norm = 4.6308
	sim_grads_norm_tr = 0.2503
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3752
	data_grads_norm = 3.0379
	new_data_grads_norm = 4.5056
	old_data_grads_norm = 5.3497
	sim_grads_norm_tr = -0.2242
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5239
	data_grads_norm = 2.9211
	new_data_grads_norm = 5.4521
	old_data_grads_norm = 3.3001
	sim_grads_norm_tr = 0.0561
-- Starting training on experience 189 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4560
	data_grads_norm = 5.4501
	new_data_grads_norm = 5.6663
	old_data_grads_norm = 7.2153
	sim_grads_norm_tr = 0.2846
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3740
	data_grads_norm = 2.6411
	new_data_grads_norm = 4.8125
	old_data_grads_norm = 3.9329
	sim_grads_norm_tr = -0.0910
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6430
	data_grads_norm = 3.0284
	new_data_grads_norm = 4.5115
	old_data_grads_norm = 4.0657
	sim_grads_norm_tr = 0.1131
-- Starting training on experience 190 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6594
	data_grads_norm = 3.3807
	new_data_grads_norm = 4.2124
	old_data_grads_norm = 4.7696
	sim_grads_norm_tr = 0.0705
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7829
	data_grads_norm = 3.4043
	new_data_grads_norm = 5.2008
	old_data_grads_norm = 4.5458
	sim_grads_norm_tr = -0.0061
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6904
	data_grads_norm = 2.8768
	new_data_grads_norm = 5.6069
	old_data_grads_norm = 4.3475
	sim_grads_norm_tr = -0.0294
-- Starting training on experience 191 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8514
	data_grads_norm = 3.8997
	new_data_grads_norm = 5.0729
	old_data_grads_norm = 5.2566
	sim_grads_norm_tr = 0.1499
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5480
	data_grads_norm = 3.4647
	new_data_grads_norm = 5.2637
	old_data_grads_norm = 5.0177
	sim_grads_norm_tr = 0.0362
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6468
	data_grads_norm = 3.2619
	new_data_grads_norm = 4.9622
	old_data_grads_norm = 5.0090
	sim_grads_norm_tr = -0.0684
-- Starting training on experience 192 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5177
	data_grads_norm = 2.5643
	new_data_grads_norm = 4.1094
	old_data_grads_norm = 3.8761
	sim_grads_norm_tr = -0.0841
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8167
	data_grads_norm = 3.5703
	new_data_grads_norm = 4.3912
	old_data_grads_norm = 4.7518
	sim_grads_norm_tr = 0.0038
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5579
	data_grads_norm = 3.5269
	new_data_grads_norm = 4.9365
	old_data_grads_norm = 5.8667
	sim_grads_norm_tr = -0.1219
-- Starting training on experience 193 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4279
	data_grads_norm = 4.3387
	new_data_grads_norm = 7.5531
	old_data_grads_norm = 3.8660
	sim_grads_norm_tr = 0.1950
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9272
	data_grads_norm = 3.6762
	new_data_grads_norm = 7.2389
	old_data_grads_norm = 4.2798
	sim_grads_norm_tr = -0.0537
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7122
	data_grads_norm = 3.2328
	new_data_grads_norm = 6.7582
	old_data_grads_norm = 3.4060
	sim_grads_norm_tr = -0.0707
-- Starting training on experience 194 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2450
	data_grads_norm = 4.1274
	new_data_grads_norm = 6.6128
	old_data_grads_norm = 4.6888
	sim_grads_norm_tr = 0.1325
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3097
	data_grads_norm = 3.6517
	new_data_grads_norm = 6.1307
	old_data_grads_norm = 3.6653
	sim_grads_norm_tr = 0.1228
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7483
	data_grads_norm = 3.2949
	new_data_grads_norm = 6.0080
	old_data_grads_norm = 3.5856
	sim_grads_norm_tr = -0.0520
-- Starting training on experience 195 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0736
	data_grads_norm = 3.6244
	new_data_grads_norm = 4.9907
	old_data_grads_norm = 5.7117
	sim_grads_norm_tr = 0.0093
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4595
	data_grads_norm = 3.0553
	new_data_grads_norm = 5.2373
	old_data_grads_norm = 4.0347
	sim_grads_norm_tr = -0.1334
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1748
	data_grads_norm = 4.3019
	new_data_grads_norm = 5.7716
	old_data_grads_norm = 5.3791
	sim_grads_norm_tr = 0.1160
-- Starting training on experience 196 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8263
	data_grads_norm = 3.4115
	new_data_grads_norm = 5.7378
	old_data_grads_norm = 3.5831
	sim_grads_norm_tr = 0.1464
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4728
	data_grads_norm = 2.4796
	new_data_grads_norm = 6.5474
	old_data_grads_norm = 2.6265
	sim_grads_norm_tr = -0.0382
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7446
	data_grads_norm = 3.3603
	new_data_grads_norm = 5.8004
	old_data_grads_norm = 5.2673
	sim_grads_norm_tr = -0.0871
-- Starting training on experience 197 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2756
	data_grads_norm = 3.8056
	new_data_grads_norm = 5.6742
	old_data_grads_norm = 4.7487
	sim_grads_norm_tr = 0.0094
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5635
	data_grads_norm = 4.0006
	new_data_grads_norm = 6.1283
	old_data_grads_norm = 3.9921
	sim_grads_norm_tr = 0.0938
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2031
	data_grads_norm = 3.7108
	new_data_grads_norm = 5.9115
	old_data_grads_norm = 4.8258
	sim_grads_norm_tr = 0.1346
-- Starting training on experience 198 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0427
	data_grads_norm = 4.3725
	new_data_grads_norm = 5.7015
	old_data_grads_norm = 5.1491
	sim_grads_norm_tr = 0.0853
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0112
	data_grads_norm = 4.2220
	new_data_grads_norm = 6.0277
	old_data_grads_norm = 5.9674
	sim_grads_norm_tr = -0.0687
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2803
	data_grads_norm = 3.2140
	new_data_grads_norm = 5.8300
	old_data_grads_norm = 5.1819
	sim_grads_norm_tr = 0.0024
-- Starting training on experience 199 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3442
	data_grads_norm = 5.0650
	new_data_grads_norm = 6.8077
	old_data_grads_norm = 6.7166
	sim_grads_norm_tr = -0.0794
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0593
	data_grads_norm = 4.0810
	new_data_grads_norm = 6.5952
	old_data_grads_norm = 4.8194
	sim_grads_norm_tr = -0.0588
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8388
	data_grads_norm = 3.4414
	new_data_grads_norm = 6.8427
	old_data_grads_norm = 3.6616
	sim_grads_norm_tr = 0.0386
-- Starting training on experience 200 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9952
	data_grads_norm = 4.1982
	new_data_grads_norm = 5.6134
	old_data_grads_norm = 6.5571
	sim_grads_norm_tr = -0.1418
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4409
	data_grads_norm = 4.7986
	new_data_grads_norm = 6.7213
	old_data_grads_norm = 5.4104
	sim_grads_norm_tr = 0.2396
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9505
	data_grads_norm = 4.3974
	new_data_grads_norm = 5.2097
	old_data_grads_norm = 5.9807
	sim_grads_norm_tr = -0.0072
-- Starting training on experience 201 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8425
	data_grads_norm = 4.0556
	new_data_grads_norm = 5.7831
	old_data_grads_norm = 5.1598
	sim_grads_norm_tr = 0.0911
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3596
	data_grads_norm = 3.1533
	new_data_grads_norm = 6.0300
	old_data_grads_norm = 4.3818
	sim_grads_norm_tr = -0.0962
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0313
	data_grads_norm = 4.0136
	new_data_grads_norm = 5.6733
	old_data_grads_norm = 5.6912
	sim_grads_norm_tr = 0.1000
-- Starting training on experience 202 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3113
	data_grads_norm = 3.8613
	new_data_grads_norm = 5.4387
	old_data_grads_norm = 5.1538
	sim_grads_norm_tr = 0.0626
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3918
	data_grads_norm = 4.4326
	new_data_grads_norm = 5.3006
	old_data_grads_norm = 5.7382
	sim_grads_norm_tr = 0.1614
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7693
	data_grads_norm = 2.8112
	new_data_grads_norm = 5.4744
	old_data_grads_norm = 3.3383
	sim_grads_norm_tr = 0.0100
-- Starting training on experience 203 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4754
	data_grads_norm = 5.0059
	new_data_grads_norm = 6.8964
	old_data_grads_norm = 6.2167
	sim_grads_norm_tr = 0.2410
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4749
	data_grads_norm = 3.3245
	new_data_grads_norm = 5.9102
	old_data_grads_norm = 4.3994
	sim_grads_norm_tr = -0.0771
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5467
	data_grads_norm = 3.4012
	new_data_grads_norm = 5.7731
	old_data_grads_norm = 4.2000
	sim_grads_norm_tr = -0.0420
-- Starting training on experience 204 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9408
	data_grads_norm = 3.9990
	new_data_grads_norm = 5.8341
	old_data_grads_norm = 5.5434
	sim_grads_norm_tr = -0.1112
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2069
	data_grads_norm = 4.5922
	new_data_grads_norm = 6.2859
	old_data_grads_norm = 6.3476
	sim_grads_norm_tr = 0.1120
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0287
	data_grads_norm = 3.9976
	new_data_grads_norm = 6.0382
	old_data_grads_norm = 4.0996
	sim_grads_norm_tr = 0.2725
-- Starting training on experience 205 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8726
	data_grads_norm = 3.3865
	new_data_grads_norm = 4.8809
	old_data_grads_norm = 5.1324
	sim_grads_norm_tr = -0.0059
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7810
	data_grads_norm = 3.2241
	new_data_grads_norm = 5.1352
	old_data_grads_norm = 4.2160
	sim_grads_norm_tr = 0.1063
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3589
	data_grads_norm = 2.8321
	new_data_grads_norm = 5.0295
	old_data_grads_norm = 2.7658
	sim_grads_norm_tr = -0.0299
-- Starting training on experience 206 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5669
	data_grads_norm = 3.1703
	new_data_grads_norm = 5.0679
	old_data_grads_norm = 4.3912
	sim_grads_norm_tr = 0.0094
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7102
	data_grads_norm = 3.1968
	new_data_grads_norm = 5.4732
	old_data_grads_norm = 4.2351
	sim_grads_norm_tr = 0.1636
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9166
	data_grads_norm = 3.2862
	new_data_grads_norm = 4.6907
	old_data_grads_norm = 4.4718
	sim_grads_norm_tr = 0.2435
-- Starting training on experience 207 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7732
	data_grads_norm = 3.1187
	new_data_grads_norm = 5.4424
	old_data_grads_norm = 3.9374
	sim_grads_norm_tr = -0.0219
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0261
	data_grads_norm = 3.6011
	new_data_grads_norm = 5.0784
	old_data_grads_norm = 5.4146
	sim_grads_norm_tr = -0.1052
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1339
	data_grads_norm = 4.2754
	new_data_grads_norm = 5.7272
	old_data_grads_norm = 6.3842
	sim_grads_norm_tr = 0.0438
-- Starting training on experience 208 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1016
	data_grads_norm = 3.3988
	new_data_grads_norm = 6.0544
	old_data_grads_norm = 3.7134
	sim_grads_norm_tr = 0.0058
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2986
	data_grads_norm = 3.9355
	new_data_grads_norm = 6.1680
	old_data_grads_norm = 4.5248
	sim_grads_norm_tr = 0.2046
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0187
	data_grads_norm = 4.0006
	new_data_grads_norm = 5.4914
	old_data_grads_norm = 5.7227
	sim_grads_norm_tr = 0.0915
-- Starting training on experience 209 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9329
	data_grads_norm = 3.3208
	new_data_grads_norm = 4.6840
	old_data_grads_norm = 4.5557
	sim_grads_norm_tr = -0.0903
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5983
	data_grads_norm = 4.3119
	new_data_grads_norm = 4.7309
	old_data_grads_norm = 6.6340
	sim_grads_norm_tr = 0.0145
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1492
	data_grads_norm = 4.1214
	new_data_grads_norm = 4.9342
	old_data_grads_norm = 5.2828
	sim_grads_norm_tr = 0.0810
-- Starting training on experience 210 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9517
	data_grads_norm = 3.0720
	new_data_grads_norm = 5.8425
	old_data_grads_norm = 3.5318
	sim_grads_norm_tr = 0.0359
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6557
	data_grads_norm = 2.9537
	new_data_grads_norm = 5.3993
	old_data_grads_norm = 3.1760
	sim_grads_norm_tr = 0.0707
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8859
	data_grads_norm = 3.4081
	new_data_grads_norm = 5.6818
	old_data_grads_norm = 3.9021
	sim_grads_norm_tr = -0.0639
-- Starting training on experience 211 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0623
	data_grads_norm = 4.2186
	new_data_grads_norm = 6.6804
	old_data_grads_norm = 4.0271
	sim_grads_norm_tr = 0.2350
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6901
	data_grads_norm = 3.5050
	new_data_grads_norm = 5.8029
	old_data_grads_norm = 4.2555
	sim_grads_norm_tr = 0.0347
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1448
	data_grads_norm = 4.1630
	new_data_grads_norm = 6.0352
	old_data_grads_norm = 4.6704
	sim_grads_norm_tr = 0.0616
-- Starting training on experience 212 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6047
	data_grads_norm = 4.6877
	new_data_grads_norm = 5.9320
	old_data_grads_norm = 5.4607
	sim_grads_norm_tr = -0.0571
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1810
	data_grads_norm = 3.1732
	new_data_grads_norm = 6.2282
	old_data_grads_norm = 3.4757
	sim_grads_norm_tr = 0.1498
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0628
	data_grads_norm = 3.4269
	new_data_grads_norm = 5.9648
	old_data_grads_norm = 5.3570
	sim_grads_norm_tr = -0.0140
-- Starting training on experience 213 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9160
	data_grads_norm = 3.2762
	new_data_grads_norm = 5.5409
	old_data_grads_norm = 3.4836
	sim_grads_norm_tr = 0.0452
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7159
	data_grads_norm = 4.4329
	new_data_grads_norm = 5.8034
	old_data_grads_norm = 5.7496
	sim_grads_norm_tr = 0.0933
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8967
	data_grads_norm = 3.6181
	new_data_grads_norm = 5.6380
	old_data_grads_norm = 4.3499
	sim_grads_norm_tr = 0.1383
-- Starting training on experience 214 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7886
	data_grads_norm = 3.6582
	new_data_grads_norm = 4.9099
	old_data_grads_norm = 4.2187
	sim_grads_norm_tr = 0.1693
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8621
	data_grads_norm = 4.6799
	new_data_grads_norm = 4.2081
	old_data_grads_norm = 4.9162
	sim_grads_norm_tr = 0.2938
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9057
	data_grads_norm = 4.3072
	new_data_grads_norm = 4.6350
	old_data_grads_norm = 7.2516
	sim_grads_norm_tr = 0.0227
-- Starting training on experience 215 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5630
	data_grads_norm = 2.8891
	new_data_grads_norm = 4.6047
	old_data_grads_norm = 3.7940
	sim_grads_norm_tr = -0.0956
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9529
	data_grads_norm = 3.8794
	new_data_grads_norm = 5.0326
	old_data_grads_norm = 6.1614
	sim_grads_norm_tr = -0.0568
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6498
	data_grads_norm = 3.1082
	new_data_grads_norm = 5.4570
	old_data_grads_norm = 4.0675
	sim_grads_norm_tr = -0.1569
-- Starting training on experience 216 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9448
	data_grads_norm = 3.2877
	new_data_grads_norm = 5.2964
	old_data_grads_norm = 4.2290
	sim_grads_norm_tr = -0.1029
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2595
	data_grads_norm = 4.2952
	new_data_grads_norm = 5.2855
	old_data_grads_norm = 7.3163
	sim_grads_norm_tr = 0.1617
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9538
	data_grads_norm = 3.8360
	new_data_grads_norm = 5.3742
	old_data_grads_norm = 5.8544
	sim_grads_norm_tr = 0.0258
-- Starting training on experience 217 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2927
	data_grads_norm = 4.5334
	new_data_grads_norm = 5.7060
	old_data_grads_norm = 5.8110
	sim_grads_norm_tr = 0.0908
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6737
	data_grads_norm = 3.5621
	new_data_grads_norm = 5.3900
	old_data_grads_norm = 3.7022
	sim_grads_norm_tr = 0.1276
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8022
	data_grads_norm = 3.4806
	new_data_grads_norm = 5.7647
	old_data_grads_norm = 4.0348
	sim_grads_norm_tr = -0.0350
-- Starting training on experience 218 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8256
	data_grads_norm = 3.2791
	new_data_grads_norm = 6.1233
	old_data_grads_norm = 4.2255
	sim_grads_norm_tr = 0.1724
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9018
	data_grads_norm = 2.9102
	new_data_grads_norm = 5.6927
	old_data_grads_norm = 3.3588
	sim_grads_norm_tr = 0.1860
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9343
	data_grads_norm = 3.8565
	new_data_grads_norm = 5.2594
	old_data_grads_norm = 5.3330
	sim_grads_norm_tr = -0.0232
-- Starting training on experience 219 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2250
	data_grads_norm = 3.1854
	new_data_grads_norm = 5.4144
	old_data_grads_norm = 3.5257
	sim_grads_norm_tr = -0.0157
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9623
	data_grads_norm = 3.9676
	new_data_grads_norm = 5.7263
	old_data_grads_norm = 5.0522
	sim_grads_norm_tr = 0.0101
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1051
	data_grads_norm = 3.4122
	new_data_grads_norm = 5.9979
	old_data_grads_norm = 4.1299
	sim_grads_norm_tr = 0.1937
-- Starting training on experience 220 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4494
	data_grads_norm = 2.6823
	new_data_grads_norm = 4.7813
	old_data_grads_norm = 3.3334
	sim_grads_norm_tr = -0.0144
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4846
	data_grads_norm = 3.3037
	new_data_grads_norm = 5.2892
	old_data_grads_norm = 5.0464
	sim_grads_norm_tr = -0.0139
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9602
	data_grads_norm = 4.0719
	new_data_grads_norm = 6.0096
	old_data_grads_norm = 5.4288
	sim_grads_norm_tr = -0.0843
-- Starting training on experience 221 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8334
	data_grads_norm = 3.3605
	new_data_grads_norm = 6.2215
	old_data_grads_norm = 5.3064
	sim_grads_norm_tr = -0.0572
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6313
	data_grads_norm = 3.8082
	new_data_grads_norm = 5.9908
	old_data_grads_norm = 5.5497
	sim_grads_norm_tr = -0.0458
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7419
	data_grads_norm = 3.0857
	new_data_grads_norm = 5.8807
	old_data_grads_norm = 4.0095
	sim_grads_norm_tr = -0.0844
-- Starting training on experience 222 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7603
	data_grads_norm = 4.0082
	new_data_grads_norm = 5.9672
	old_data_grads_norm = 4.1656
	sim_grads_norm_tr = 0.0826
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2882
	data_grads_norm = 3.5637
	new_data_grads_norm = 5.7457
	old_data_grads_norm = 5.2573
	sim_grads_norm_tr = 0.0441
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9657
	data_grads_norm = 3.2204
	new_data_grads_norm = 5.7983
	old_data_grads_norm = 3.9959
	sim_grads_norm_tr = 0.1415
-- Starting training on experience 223 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7741
	data_grads_norm = 2.7698
	new_data_grads_norm = 5.8667
	old_data_grads_norm = 3.8488
	sim_grads_norm_tr = 0.0500
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8380
	data_grads_norm = 3.5784
	new_data_grads_norm = 6.4042
	old_data_grads_norm = 4.0044
	sim_grads_norm_tr = 0.0243
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0793
	data_grads_norm = 3.8417
	new_data_grads_norm = 6.5222
	old_data_grads_norm = 5.1452
	sim_grads_norm_tr = 0.0532
-- Starting training on experience 224 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3632
	data_grads_norm = 4.4278
	new_data_grads_norm = 5.5699
	old_data_grads_norm = 5.6483
	sim_grads_norm_tr = 0.1903
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3654
	data_grads_norm = 4.2949
	new_data_grads_norm = 5.9087
	old_data_grads_norm = 6.4632
	sim_grads_norm_tr = -0.0160
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2384
	data_grads_norm = 5.4241
	new_data_grads_norm = 6.4185
	old_data_grads_norm = 7.7811
	sim_grads_norm_tr = -0.0345
-- Starting training on experience 225 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9327
	data_grads_norm = 2.8433
	new_data_grads_norm = 6.0625
	old_data_grads_norm = 3.9424
	sim_grads_norm_tr = -0.0484
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9823
	data_grads_norm = 3.9046
	new_data_grads_norm = 6.2700
	old_data_grads_norm = 4.9137
	sim_grads_norm_tr = 0.1095
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3100
	data_grads_norm = 4.0653
	new_data_grads_norm = 6.3113
	old_data_grads_norm = 5.5675
	sim_grads_norm_tr = 0.0498
-- Starting training on experience 226 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0639
	data_grads_norm = 3.8751
	new_data_grads_norm = 5.6274
	old_data_grads_norm = 4.8437
	sim_grads_norm_tr = 0.1090
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7302
	data_grads_norm = 3.7245
	new_data_grads_norm = 5.5702
	old_data_grads_norm = 5.0062
	sim_grads_norm_tr = 0.1120
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7150
	data_grads_norm = 3.9466
	new_data_grads_norm = 5.0314
	old_data_grads_norm = 5.2225
	sim_grads_norm_tr = 0.0420
-- Starting training on experience 227 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9021
	data_grads_norm = 3.1045
	new_data_grads_norm = 5.0134
	old_data_grads_norm = 4.2899
	sim_grads_norm_tr = -0.0601
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6489
	data_grads_norm = 3.4144
	new_data_grads_norm = 5.2784
	old_data_grads_norm = 4.8333
	sim_grads_norm_tr = -0.1308
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9048
	data_grads_norm = 3.3371
	new_data_grads_norm = 5.9603
	old_data_grads_norm = 4.2069
	sim_grads_norm_tr = 0.0393
-- Starting training on experience 228 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5798
	data_grads_norm = 2.8341
	new_data_grads_norm = 6.0534
	old_data_grads_norm = 4.0460
	sim_grads_norm_tr = -0.0285
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6173
	data_grads_norm = 2.6620
	new_data_grads_norm = 5.9391
	old_data_grads_norm = 3.0922
	sim_grads_norm_tr = 0.1383
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5037
	data_grads_norm = 2.5605
	new_data_grads_norm = 5.7809
	old_data_grads_norm = 3.0411
	sim_grads_norm_tr = 0.0423
-- Starting training on experience 229 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6414
	data_grads_norm = 2.5329
	new_data_grads_norm = 5.2108
	old_data_grads_norm = 3.0411
	sim_grads_norm_tr = -0.0571
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0326
	data_grads_norm = 3.7905
	new_data_grads_norm = 5.2178
	old_data_grads_norm = 5.8150
	sim_grads_norm_tr = 0.0349
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5093
	data_grads_norm = 3.1114
	new_data_grads_norm = 4.9577
	old_data_grads_norm = 3.6176
	sim_grads_norm_tr = -0.1297
-- Starting training on experience 230 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6380
	data_grads_norm = 3.7713
	new_data_grads_norm = 4.9428
	old_data_grads_norm = 5.4006
	sim_grads_norm_tr = 0.0684
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7228
	data_grads_norm = 3.6176
	new_data_grads_norm = 5.1799
	old_data_grads_norm = 5.0574
	sim_grads_norm_tr = 0.1163
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6120
	data_grads_norm = 3.5937
	new_data_grads_norm = 5.2159
	old_data_grads_norm = 4.8310
	sim_grads_norm_tr = 0.1035
-- Starting training on experience 231 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5230
	data_grads_norm = 3.7154
	new_data_grads_norm = 5.0274
	old_data_grads_norm = 4.5260
	sim_grads_norm_tr = 0.0328
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3799
	data_grads_norm = 2.9828
	new_data_grads_norm = 5.1045
	old_data_grads_norm = 3.8459
	sim_grads_norm_tr = -0.1389
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0374
	data_grads_norm = 3.8466
	new_data_grads_norm = 6.0843
	old_data_grads_norm = 4.2146
	sim_grads_norm_tr = 0.1156
-- Starting training on experience 232 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9996
	data_grads_norm = 4.1790
	new_data_grads_norm = 6.2506
	old_data_grads_norm = 5.5155
	sim_grads_norm_tr = 0.0003
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0814
	data_grads_norm = 4.6178
	new_data_grads_norm = 6.4575
	old_data_grads_norm = 6.2543
	sim_grads_norm_tr = 0.0392
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2525
	data_grads_norm = 4.1932
	new_data_grads_norm = 6.0517
	old_data_grads_norm = 6.1100
	sim_grads_norm_tr = 0.0207
-- Starting training on experience 233 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1598
	data_grads_norm = 5.6291
	new_data_grads_norm = 7.0930
	old_data_grads_norm = 8.1631
	sim_grads_norm_tr = -0.0095
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0273
	data_grads_norm = 2.8658
	new_data_grads_norm = 5.9690
	old_data_grads_norm = 3.6058
	sim_grads_norm_tr = -0.0992
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3081
	data_grads_norm = 3.5091
	new_data_grads_norm = 6.5394
	old_data_grads_norm = 4.3010
	sim_grads_norm_tr = 0.1565
-- Starting training on experience 234 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7592
	data_grads_norm = 2.3469
	new_data_grads_norm = 5.0213
	old_data_grads_norm = 2.9866
	sim_grads_norm_tr = -0.0519
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6392
	data_grads_norm = 3.9698
	new_data_grads_norm = 5.7815
	old_data_grads_norm = 6.4064
	sim_grads_norm_tr = 0.0532
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9902
	data_grads_norm = 5.0506
	new_data_grads_norm = 5.5476
	old_data_grads_norm = 5.9999
	sim_grads_norm_tr = 0.0590
-- Starting training on experience 235 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6403
	data_grads_norm = 3.3928
	new_data_grads_norm = 6.6038
	old_data_grads_norm = 5.1500
	sim_grads_norm_tr = -0.2155
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8151
	data_grads_norm = 3.6111
	new_data_grads_norm = 6.2625
	old_data_grads_norm = 5.3275
	sim_grads_norm_tr = 0.0876
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7866
	data_grads_norm = 3.0503
	new_data_grads_norm = 6.5111
	old_data_grads_norm = 3.2996
	sim_grads_norm_tr = -0.0447
-- Starting training on experience 236 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6213
	data_grads_norm = 4.9545
	new_data_grads_norm = 6.5384
	old_data_grads_norm = 6.8343
	sim_grads_norm_tr = 0.0722
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3394
	data_grads_norm = 4.3327
	new_data_grads_norm = 6.4649
	old_data_grads_norm = 5.8647
	sim_grads_norm_tr = 0.0255
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2742
	data_grads_norm = 4.1841
	new_data_grads_norm = 7.0190
	old_data_grads_norm = 4.4470
	sim_grads_norm_tr = 0.0655
-- Starting training on experience 237 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
-- >> End of training phase << --
-- >> Start of eval phase << --
-- Starting eval on experience 0 (Task 0) from test stream --
> Eval on experience 0 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp000 = 2.1297
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.3420
	mb_index = 714
	time = 145.8055
-- Starting eval on experience 1 (Task 0) from test stream --
> Eval on experience 1 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp001 = 0.8349
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.7560
-- Starting eval on experience 2 (Task 0) from test stream --
> Eval on experience 2 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp002 = 2.3447
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.2040
-- >> End of eval phase << --
	CumulativeAccuracy/eval_phase/test_stream/Exp000 = 0.6540
	CumulativeAccuracy/eval_phase/test_stream/Exp001 = 0.5920
	CumulativeAccuracy/eval_phase/test_stream/Exp002 = 0.4340
	Loss_Stream/eval_phase/test_stream/Task000 = 1.7698
	Top1_Acc_Stream/eval_phase/test_stream/Task000 = 0.4340
-- >> Start of training phase << --
-- Starting training on experience 0 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9616
	data_grads_norm = 3.6782
	new_data_grads_norm = 4.7489
	old_data_grads_norm = 5.4391
	sim_grads_norm_tr = 0.0229
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5993
	data_grads_norm = 3.0491
	new_data_grads_norm = 4.4938
	old_data_grads_norm = 4.4464
	sim_grads_norm_tr = -0.0027
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1350
	data_grads_norm = 3.6039
	new_data_grads_norm = 4.5828
	old_data_grads_norm = 5.6351
	sim_grads_norm_tr = 0.0249
-- Starting training on experience 1 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1145
	data_grads_norm = 3.8557
	new_data_grads_norm = 5.7220
	old_data_grads_norm = 4.8892
	sim_grads_norm_tr = 0.0039
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1740
	data_grads_norm = 4.3081
	new_data_grads_norm = 6.3546
	old_data_grads_norm = 7.2514
	sim_grads_norm_tr = -0.0596
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3264
	data_grads_norm = 4.0520
	new_data_grads_norm = 6.1516
	old_data_grads_norm = 4.5857
	sim_grads_norm_tr = 0.0164
-- Starting training on experience 2 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0659
	data_grads_norm = 4.2091
	new_data_grads_norm = 5.5465
	old_data_grads_norm = 4.9048
	sim_grads_norm_tr = -0.0627
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8556
	data_grads_norm = 3.2802
	new_data_grads_norm = 5.7879
	old_data_grads_norm = 3.1981
	sim_grads_norm_tr = -0.0684
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3635
	data_grads_norm = 4.5451
	new_data_grads_norm = 5.9607
	old_data_grads_norm = 6.8795
	sim_grads_norm_tr = 0.0123
-- Starting training on experience 3 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3303
	data_grads_norm = 4.2911
	new_data_grads_norm = 5.4905
	old_data_grads_norm = 6.6812
	sim_grads_norm_tr = -0.0573
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1788
	data_grads_norm = 4.2425
	new_data_grads_norm = 5.7835
	old_data_grads_norm = 4.7365
	sim_grads_norm_tr = 0.0349
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2763
	data_grads_norm = 3.8964
	new_data_grads_norm = 5.6462
	old_data_grads_norm = 4.6685
	sim_grads_norm_tr = 0.0406
-- Starting training on experience 4 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2762
	data_grads_norm = 3.7267
	new_data_grads_norm = 5.7219
	old_data_grads_norm = 4.5243
	sim_grads_norm_tr = 0.0700
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3150
	data_grads_norm = 4.7907
	new_data_grads_norm = 5.7675
	old_data_grads_norm = 6.7194
	sim_grads_norm_tr = -0.0109
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4967
	data_grads_norm = 3.8630
	new_data_grads_norm = 5.7298
	old_data_grads_norm = 4.7874
	sim_grads_norm_tr = -0.0039
-- Starting training on experience 5 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9512
	data_grads_norm = 4.9716
	new_data_grads_norm = 7.6275
	old_data_grads_norm = 5.6106
	sim_grads_norm_tr = -0.0093
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6028
	data_grads_norm = 4.5066
	new_data_grads_norm = 7.2046
	old_data_grads_norm = 5.1156
	sim_grads_norm_tr = 0.0387
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4639
	data_grads_norm = 4.4239
	new_data_grads_norm = 7.4858
	old_data_grads_norm = 4.0511
	sim_grads_norm_tr = 0.0126
-- Starting training on experience 6 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4983
	data_grads_norm = 4.4898
	new_data_grads_norm = 6.1381
	old_data_grads_norm = 5.1886
	sim_grads_norm_tr = 0.0553
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4514
	data_grads_norm = 4.0016
	new_data_grads_norm = 6.3205
	old_data_grads_norm = 4.0815
	sim_grads_norm_tr = -0.0967
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4641
	data_grads_norm = 4.1661
	new_data_grads_norm = 6.6026
	old_data_grads_norm = 4.2956
	sim_grads_norm_tr = -0.0032
-- Starting training on experience 7 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4820
	data_grads_norm = 4.2306
	new_data_grads_norm = 6.6191
	old_data_grads_norm = 4.7793
	sim_grads_norm_tr = 0.0397
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9820
	data_grads_norm = 3.9454
	new_data_grads_norm = 5.9888
	old_data_grads_norm = 4.2533
	sim_grads_norm_tr = -0.0640
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3042
	data_grads_norm = 4.5736
	new_data_grads_norm = 6.5310
	old_data_grads_norm = 5.1759
	sim_grads_norm_tr = 0.1205
-- Starting training on experience 8 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4184
	data_grads_norm = 4.5981
	new_data_grads_norm = 6.2129
	old_data_grads_norm = 5.4410
	sim_grads_norm_tr = 0.1143
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7042
	data_grads_norm = 4.3029
	new_data_grads_norm = 5.6868
	old_data_grads_norm = 5.4232
	sim_grads_norm_tr = 0.2163
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8834
	data_grads_norm = 3.5011
	new_data_grads_norm = 5.3273
	old_data_grads_norm = 4.4460
	sim_grads_norm_tr = -0.0713
-- Starting training on experience 9 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2021
	data_grads_norm = 4.0258
	new_data_grads_norm = 6.3948
	old_data_grads_norm = 4.8944
	sim_grads_norm_tr = 0.1474
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1157
	data_grads_norm = 3.2506
	new_data_grads_norm = 6.1430
	old_data_grads_norm = 3.7051
	sim_grads_norm_tr = -0.0201
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5769
	data_grads_norm = 3.9823
	new_data_grads_norm = 6.1482
	old_data_grads_norm = 5.4914
	sim_grads_norm_tr = -0.0303
-- Starting training on experience 10 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9595
	data_grads_norm = 3.1474
	new_data_grads_norm = 5.2627
	old_data_grads_norm = 4.0468
	sim_grads_norm_tr = -0.0769
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9403
	data_grads_norm = 3.6131
	new_data_grads_norm = 5.8325
	old_data_grads_norm = 4.5597
	sim_grads_norm_tr = -0.0394
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0952
	data_grads_norm = 3.9019
	new_data_grads_norm = 5.5219
	old_data_grads_norm = 5.1893
	sim_grads_norm_tr = 0.0474
-- Starting training on experience 11 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6122
	data_grads_norm = 4.2122
	new_data_grads_norm = 5.4896
	old_data_grads_norm = 6.0292
	sim_grads_norm_tr = 0.0080
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3716
	data_grads_norm = 4.3535
	new_data_grads_norm = 5.5854
	old_data_grads_norm = 5.3412
	sim_grads_norm_tr = 0.1116
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6534
	data_grads_norm = 4.7264
	new_data_grads_norm = 6.0847
	old_data_grads_norm = 5.5294
	sim_grads_norm_tr = 0.1170
-- Starting training on experience 12 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7033
	data_grads_norm = 3.1690
	new_data_grads_norm = 5.0700
	old_data_grads_norm = 4.1392
	sim_grads_norm_tr = -0.0682
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8182
	data_grads_norm = 4.7007
	new_data_grads_norm = 5.8236
	old_data_grads_norm = 6.3302
	sim_grads_norm_tr = 0.1105
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3360
	data_grads_norm = 4.0088
	new_data_grads_norm = 4.7877
	old_data_grads_norm = 5.6273
	sim_grads_norm_tr = 0.1079
-- Starting training on experience 13 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8881
	data_grads_norm = 3.3879
	new_data_grads_norm = 5.1366
	old_data_grads_norm = 4.1442
	sim_grads_norm_tr = -0.0196
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6496
	data_grads_norm = 3.0472
	new_data_grads_norm = 5.6392
	old_data_grads_norm = 3.7928
	sim_grads_norm_tr = -0.0467
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6393
	data_grads_norm = 4.0766
	new_data_grads_norm = 5.8168
	old_data_grads_norm = 5.4501
	sim_grads_norm_tr = 0.0974
-- Starting training on experience 14 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6893
	data_grads_norm = 3.9836
	new_data_grads_norm = 5.7244
	old_data_grads_norm = 4.7605
	sim_grads_norm_tr = 0.0478
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3375
	data_grads_norm = 3.8645
	new_data_grads_norm = 5.7899
	old_data_grads_norm = 4.2697
	sim_grads_norm_tr = -0.0229
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5097
	data_grads_norm = 4.2881
	new_data_grads_norm = 5.7150
	old_data_grads_norm = 8.1695
	sim_grads_norm_tr = 0.1471
-- Starting training on experience 15 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4739
	data_grads_norm = 3.8121
	new_data_grads_norm = 5.3464
	old_data_grads_norm = 5.0173
	sim_grads_norm_tr = 0.0636
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7899
	data_grads_norm = 2.6835
	new_data_grads_norm = 5.0569
	old_data_grads_norm = 2.5863
	sim_grads_norm_tr = 0.0669
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4066
	data_grads_norm = 3.9237
	new_data_grads_norm = 5.2676
	old_data_grads_norm = 5.9373
	sim_grads_norm_tr = 0.0893
-- Starting training on experience 16 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3372
	data_grads_norm = 3.7649
	new_data_grads_norm = 6.0846
	old_data_grads_norm = 4.7202
	sim_grads_norm_tr = 0.0490
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7605
	data_grads_norm = 2.9154
	new_data_grads_norm = 6.1134
	old_data_grads_norm = 3.3476
	sim_grads_norm_tr = -0.0021
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0382
	data_grads_norm = 3.8664
	new_data_grads_norm = 6.4641
	old_data_grads_norm = 4.8573
	sim_grads_norm_tr = 0.0119
-- Starting training on experience 17 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5243
	data_grads_norm = 4.3957
	new_data_grads_norm = 6.1256
	old_data_grads_norm = 6.1737
	sim_grads_norm_tr = 0.0751
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1020
	data_grads_norm = 3.9238
	new_data_grads_norm = 5.8490
	old_data_grads_norm = 5.1373
	sim_grads_norm_tr = 0.0196
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4046
	data_grads_norm = 3.9075
	new_data_grads_norm = 5.9840
	old_data_grads_norm = 4.1877
	sim_grads_norm_tr = 0.0641
-- Starting training on experience 18 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2345
	data_grads_norm = 3.4329
	new_data_grads_norm = 5.2886
	old_data_grads_norm = 4.3277
	sim_grads_norm_tr = -0.0493
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4589
	data_grads_norm = 3.9764
	new_data_grads_norm = 5.5964
	old_data_grads_norm = 4.6057
	sim_grads_norm_tr = 0.2534
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1074
	data_grads_norm = 3.6436
	new_data_grads_norm = 5.2857
	old_data_grads_norm = 6.0490
	sim_grads_norm_tr = -0.0235
-- Starting training on experience 19 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9080
	data_grads_norm = 3.9119
	new_data_grads_norm = 5.8712
	old_data_grads_norm = 5.1327
	sim_grads_norm_tr = 0.0314
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9383
	data_grads_norm = 3.9174
	new_data_grads_norm = 6.2290
	old_data_grads_norm = 4.3373
	sim_grads_norm_tr = 0.0192
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6013
	data_grads_norm = 3.6920
	new_data_grads_norm = 6.1267
	old_data_grads_norm = 4.1889
	sim_grads_norm_tr = -0.1143
-- Starting training on experience 20 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9551
	data_grads_norm = 4.8390
	new_data_grads_norm = 6.3397
	old_data_grads_norm = 5.7556
	sim_grads_norm_tr = 0.2035
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7761
	data_grads_norm = 4.7235
	new_data_grads_norm = 6.2205
	old_data_grads_norm = 5.0585
	sim_grads_norm_tr = 0.0866
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3492
	data_grads_norm = 3.8189
	new_data_grads_norm = 5.6342
	old_data_grads_norm = 3.6317
	sim_grads_norm_tr = 0.1329
-- Starting training on experience 21 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0219
	data_grads_norm = 4.0272
	new_data_grads_norm = 4.9056
	old_data_grads_norm = 4.6754
	sim_grads_norm_tr = 0.3262
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6042
	data_grads_norm = 3.2147
	new_data_grads_norm = 5.3566
	old_data_grads_norm = 3.9778
	sim_grads_norm_tr = -0.0035
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5182
	data_grads_norm = 3.1517
	new_data_grads_norm = 4.9395
	old_data_grads_norm = 3.8453
	sim_grads_norm_tr = 0.0373
-- Starting training on experience 22 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8822
	data_grads_norm = 3.6970
	new_data_grads_norm = 5.2922
	old_data_grads_norm = 4.9907
	sim_grads_norm_tr = 0.0575
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7077
	data_grads_norm = 3.8263
	new_data_grads_norm = 5.5902
	old_data_grads_norm = 5.9516
	sim_grads_norm_tr = -0.0006
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3275
	data_grads_norm = 4.2552
	new_data_grads_norm = 5.6434
	old_data_grads_norm = 5.1548
	sim_grads_norm_tr = 0.1664
-- Starting training on experience 23 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1910
	data_grads_norm = 3.7846
	new_data_grads_norm = 4.9843
	old_data_grads_norm = 4.6123
	sim_grads_norm_tr = 0.2675
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8576
	data_grads_norm = 3.4568
	new_data_grads_norm = 4.5070
	old_data_grads_norm = 4.2085
	sim_grads_norm_tr = 0.2159
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2874
	data_grads_norm = 2.5175
	new_data_grads_norm = 4.0935
	old_data_grads_norm = 2.8365
	sim_grads_norm_tr = -0.0298
-- Starting training on experience 24 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5649
	data_grads_norm = 3.1847
	new_data_grads_norm = 4.6168
	old_data_grads_norm = 4.4781
	sim_grads_norm_tr = 0.1406
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0800
	data_grads_norm = 3.8110
	new_data_grads_norm = 5.2521
	old_data_grads_norm = 5.2220
	sim_grads_norm_tr = 0.0070
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2011
	data_grads_norm = 2.8222
	new_data_grads_norm = 4.9197
	old_data_grads_norm = 3.5624
	sim_grads_norm_tr = -0.1827
-- Starting training on experience 25 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8214
	data_grads_norm = 3.7894
	new_data_grads_norm = 5.0901
	old_data_grads_norm = 4.5564
	sim_grads_norm_tr = 0.1074
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7000
	data_grads_norm = 3.1205
	new_data_grads_norm = 4.6267
	old_data_grads_norm = 4.2615
	sim_grads_norm_tr = -0.0416
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3392
	data_grads_norm = 3.3970
	new_data_grads_norm = 4.9244
	old_data_grads_norm = 4.7828
	sim_grads_norm_tr = -0.0187
-- Starting training on experience 26 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8692
	data_grads_norm = 3.1987
	new_data_grads_norm = 6.0222
	old_data_grads_norm = 3.4907
	sim_grads_norm_tr = 0.0587
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9457
	data_grads_norm = 3.7218
	new_data_grads_norm = 5.9811
	old_data_grads_norm = 4.7825
	sim_grads_norm_tr = 0.0973
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1210
	data_grads_norm = 3.5704
	new_data_grads_norm = 5.8376
	old_data_grads_norm = 4.9865
	sim_grads_norm_tr = 0.2155
-- Starting training on experience 27 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3628
	data_grads_norm = 3.3602
	new_data_grads_norm = 4.8362
	old_data_grads_norm = 4.3863
	sim_grads_norm_tr = 0.0359
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3751
	data_grads_norm = 3.0501
	new_data_grads_norm = 4.8082
	old_data_grads_norm = 3.7822
	sim_grads_norm_tr = 0.0190
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7994
	data_grads_norm = 3.6324
	new_data_grads_norm = 4.8054
	old_data_grads_norm = 5.4731
	sim_grads_norm_tr = -0.0162
-- Starting training on experience 28 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7741
	data_grads_norm = 3.3402
	new_data_grads_norm = 4.5469
	old_data_grads_norm = 4.8031
	sim_grads_norm_tr = -0.0378
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5816
	data_grads_norm = 3.5552
	new_data_grads_norm = 4.4398
	old_data_grads_norm = 5.6037
	sim_grads_norm_tr = -0.0537
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4824
	data_grads_norm = 3.3014
	new_data_grads_norm = 4.8783
	old_data_grads_norm = 5.2845
	sim_grads_norm_tr = 0.0711
-- Starting training on experience 29 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8459
	data_grads_norm = 4.0533
	new_data_grads_norm = 5.1587
	old_data_grads_norm = 5.2281
	sim_grads_norm_tr = 0.0281
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7408
	data_grads_norm = 3.2200
	new_data_grads_norm = 4.9483
	old_data_grads_norm = 4.0028
	sim_grads_norm_tr = 0.0760
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5973
	data_grads_norm = 3.8037
	new_data_grads_norm = 4.6513
	old_data_grads_norm = 6.5425
	sim_grads_norm_tr = 0.0123
-- Starting training on experience 30 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4713
	data_grads_norm = 2.6050
	new_data_grads_norm = 4.7819
	old_data_grads_norm = 3.1594
	sim_grads_norm_tr = 0.0425
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5587
	data_grads_norm = 2.9095
	new_data_grads_norm = 4.3840
	old_data_grads_norm = 4.1558
	sim_grads_norm_tr = 0.0330
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8621
	data_grads_norm = 3.6324
	new_data_grads_norm = 4.4686
	old_data_grads_norm = 6.2990
	sim_grads_norm_tr = -0.0017
-- Starting training on experience 31 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0030
	data_grads_norm = 3.6167
	new_data_grads_norm = 4.7635
	old_data_grads_norm = 4.3895
	sim_grads_norm_tr = 0.1298
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7470
	data_grads_norm = 3.4218
	new_data_grads_norm = 4.7548
	old_data_grads_norm = 4.0632
	sim_grads_norm_tr = 0.1471
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2857
	data_grads_norm = 2.5065
	new_data_grads_norm = 4.3812
	old_data_grads_norm = 3.3457
	sim_grads_norm_tr = -0.1967
-- Starting training on experience 32 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3960
	data_grads_norm = 3.2900
	new_data_grads_norm = 4.6089
	old_data_grads_norm = 4.3312
	sim_grads_norm_tr = -0.0180
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4317
	data_grads_norm = 3.5728
	new_data_grads_norm = 5.3427
	old_data_grads_norm = 4.4292
	sim_grads_norm_tr = 0.0013
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2109
	data_grads_norm = 3.4865
	new_data_grads_norm = 5.2656
	old_data_grads_norm = 4.4329
	sim_grads_norm_tr = 0.0196
-- Starting training on experience 33 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8399
	data_grads_norm = 3.7116
	new_data_grads_norm = 5.7864
	old_data_grads_norm = 4.1498
	sim_grads_norm_tr = -0.0442
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7676
	data_grads_norm = 3.9436
	new_data_grads_norm = 5.3344
	old_data_grads_norm = 5.6174
	sim_grads_norm_tr = -0.0079
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9557
	data_grads_norm = 3.9944
	new_data_grads_norm = 5.3905
	old_data_grads_norm = 5.5960
	sim_grads_norm_tr = 0.0685
-- Starting training on experience 34 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5841
	data_grads_norm = 3.9181
	new_data_grads_norm = 4.7494
	old_data_grads_norm = 5.1855
	sim_grads_norm_tr = 0.1299
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4960
	data_grads_norm = 2.9380
	new_data_grads_norm = 4.5842
	old_data_grads_norm = 4.1079
	sim_grads_norm_tr = -0.0574
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9615
	data_grads_norm = 3.6300
	new_data_grads_norm = 5.2397
	old_data_grads_norm = 5.1958
	sim_grads_norm_tr = 0.0654
-- Starting training on experience 35 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5613
	data_grads_norm = 3.7095
	new_data_grads_norm = 5.4730
	old_data_grads_norm = 4.2449
	sim_grads_norm_tr = 0.1426
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3224
	data_grads_norm = 3.6721
	new_data_grads_norm = 5.3816
	old_data_grads_norm = 4.2574
	sim_grads_norm_tr = 0.0406
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7925
	data_grads_norm = 4.3612
	new_data_grads_norm = 6.1843
	old_data_grads_norm = 5.5880
	sim_grads_norm_tr = 0.2208
-- Starting training on experience 36 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6446
	data_grads_norm = 2.9171
	new_data_grads_norm = 4.8085
	old_data_grads_norm = 3.4385
	sim_grads_norm_tr = 0.0999
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4386
	data_grads_norm = 3.5179
	new_data_grads_norm = 4.8766
	old_data_grads_norm = 4.0387
	sim_grads_norm_tr = 0.0136
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6109
	data_grads_norm = 3.8839
	new_data_grads_norm = 4.6422
	old_data_grads_norm = 4.9214
	sim_grads_norm_tr = 0.2804
-- Starting training on experience 37 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1632
	data_grads_norm = 3.0422
	new_data_grads_norm = 4.4630
	old_data_grads_norm = 3.6544
	sim_grads_norm_tr = 0.0547
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3499
	data_grads_norm = 3.2298
	new_data_grads_norm = 4.5338
	old_data_grads_norm = 4.2746
	sim_grads_norm_tr = 0.1761
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6471
	data_grads_norm = 3.3074
	new_data_grads_norm = 4.3674
	old_data_grads_norm = 4.3294
	sim_grads_norm_tr = 0.0727
-- Starting training on experience 38 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4728
	data_grads_norm = 3.3670
	new_data_grads_norm = 5.2909
	old_data_grads_norm = 3.2841
	sim_grads_norm_tr = 0.0803
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4895
	data_grads_norm = 2.9408
	new_data_grads_norm = 5.1411
	old_data_grads_norm = 3.5976
	sim_grads_norm_tr = 0.1104
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6845
	data_grads_norm = 4.0847
	new_data_grads_norm = 5.1445
	old_data_grads_norm = 5.9077
	sim_grads_norm_tr = 0.1239
-- Starting training on experience 39 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6666
	data_grads_norm = 3.1638
	new_data_grads_norm = 4.5671
	old_data_grads_norm = 3.9146
	sim_grads_norm_tr = 0.0431
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0001
	data_grads_norm = 2.8936
	new_data_grads_norm = 4.7028
	old_data_grads_norm = 3.8140
	sim_grads_norm_tr = 0.0196
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9386
	data_grads_norm = 2.6909
	new_data_grads_norm = 4.3248
	old_data_grads_norm = 3.5249
	sim_grads_norm_tr = -0.1101
-- Starting training on experience 40 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3919
	data_grads_norm = 2.9327
	new_data_grads_norm = 5.8952
	old_data_grads_norm = 3.0919
	sim_grads_norm_tr = -0.0814
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3736
	data_grads_norm = 3.2956
	new_data_grads_norm = 6.1923
	old_data_grads_norm = 3.5021
	sim_grads_norm_tr = 0.0930
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6862
	data_grads_norm = 3.9736
	new_data_grads_norm = 5.6735
	old_data_grads_norm = 4.1716
	sim_grads_norm_tr = 0.1808
-- Starting training on experience 41 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5674
	data_grads_norm = 3.6910
	new_data_grads_norm = 5.3211
	old_data_grads_norm = 5.1723
	sim_grads_norm_tr = -0.0253
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5153
	data_grads_norm = 3.5866
	new_data_grads_norm = 5.3926
	old_data_grads_norm = 4.4378
	sim_grads_norm_tr = 0.0818
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5825
	data_grads_norm = 3.2370
	new_data_grads_norm = 5.1220
	old_data_grads_norm = 3.5151
	sim_grads_norm_tr = 0.0209
-- Starting training on experience 42 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1379
	data_grads_norm = 2.8853
	new_data_grads_norm = 4.3256
	old_data_grads_norm = 3.9468
	sim_grads_norm_tr = -0.0313
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3063
	data_grads_norm = 3.3046
	new_data_grads_norm = 4.6127
	old_data_grads_norm = 4.1362
	sim_grads_norm_tr = 0.1054
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6238
	data_grads_norm = 3.9918
	new_data_grads_norm = 4.7732
	old_data_grads_norm = 4.9669
	sim_grads_norm_tr = 0.1349
-- Starting training on experience 43 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3722
	data_grads_norm = 3.5538
	new_data_grads_norm = 4.4533
	old_data_grads_norm = 4.8755
	sim_grads_norm_tr = 0.1612
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2644
	data_grads_norm = 3.3149
	new_data_grads_norm = 4.1946
	old_data_grads_norm = 4.4253
	sim_grads_norm_tr = 0.0392
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0673
	data_grads_norm = 2.8201
	new_data_grads_norm = 3.9584
	old_data_grads_norm = 3.6173
	sim_grads_norm_tr = 0.0508
-- Starting training on experience 44 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0721
	data_grads_norm = 2.9968
	new_data_grads_norm = 4.4123
	old_data_grads_norm = 4.2990
	sim_grads_norm_tr = 0.1500
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9622
	data_grads_norm = 3.1915
	new_data_grads_norm = 4.4402
	old_data_grads_norm = 4.5250
	sim_grads_norm_tr = -0.0320
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4629
	data_grads_norm = 4.1247
	new_data_grads_norm = 4.5566
	old_data_grads_norm = 5.6558
	sim_grads_norm_tr = 0.0902
-- Starting training on experience 45 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5990
	data_grads_norm = 4.2141
	new_data_grads_norm = 4.9735
	old_data_grads_norm = 6.2025
	sim_grads_norm_tr = 0.2225
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1471
	data_grads_norm = 3.7521
	new_data_grads_norm = 4.5238
	old_data_grads_norm = 5.6723
	sim_grads_norm_tr = 0.1015
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9127
	data_grads_norm = 2.9101
	new_data_grads_norm = 4.5809
	old_data_grads_norm = 4.8062
	sim_grads_norm_tr = -0.1402
-- Starting training on experience 46 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7242
	data_grads_norm = 3.2214
	new_data_grads_norm = 5.2190
	old_data_grads_norm = 3.9193
	sim_grads_norm_tr = -0.0694
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1828
	data_grads_norm = 3.7616
	new_data_grads_norm = 5.5050
	old_data_grads_norm = 4.2516
	sim_grads_norm_tr = -0.0108
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2933
	data_grads_norm = 4.0075
	new_data_grads_norm = 5.2826
	old_data_grads_norm = 5.3072
	sim_grads_norm_tr = -0.0299
-- Starting training on experience 47 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6731
	data_grads_norm = 4.0076
	new_data_grads_norm = 5.0295
	old_data_grads_norm = 4.9795
	sim_grads_norm_tr = 0.0581
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5303
	data_grads_norm = 3.3749
	new_data_grads_norm = 5.1247
	old_data_grads_norm = 5.3780
	sim_grads_norm_tr = -0.0525
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7070
	data_grads_norm = 4.1005
	new_data_grads_norm = 5.7821
	old_data_grads_norm = 5.5544
	sim_grads_norm_tr = 0.0681
-- Starting training on experience 48 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1245
	data_grads_norm = 3.3093
	new_data_grads_norm = 4.7899
	old_data_grads_norm = 4.1681
	sim_grads_norm_tr = -0.0556
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2484
	data_grads_norm = 3.6363
	new_data_grads_norm = 4.7716
	old_data_grads_norm = 4.7285
	sim_grads_norm_tr = 0.0034
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0588
	data_grads_norm = 3.8051
	new_data_grads_norm = 5.0726
	old_data_grads_norm = 4.5127
	sim_grads_norm_tr = 0.1675
-- Starting training on experience 49 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3704
	data_grads_norm = 3.8635
	new_data_grads_norm = 5.8003
	old_data_grads_norm = 5.2106
	sim_grads_norm_tr = 0.0964
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2446
	data_grads_norm = 2.6809
	new_data_grads_norm = 6.1532
	old_data_grads_norm = 3.2096
	sim_grads_norm_tr = 0.1466
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1248
	data_grads_norm = 3.5812
	new_data_grads_norm = 5.3780
	old_data_grads_norm = 4.2022
	sim_grads_norm_tr = 0.1145
-- Starting training on experience 50 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9315
	data_grads_norm = 3.1173
	new_data_grads_norm = 5.0057
	old_data_grads_norm = 4.2951
	sim_grads_norm_tr = -0.0401
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0866
	data_grads_norm = 3.7558
	new_data_grads_norm = 5.3719
	old_data_grads_norm = 4.6248
	sim_grads_norm_tr = 0.0747
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0349
	data_grads_norm = 2.9946
	new_data_grads_norm = 5.1245
	old_data_grads_norm = 3.7539
	sim_grads_norm_tr = -0.0532
-- Starting training on experience 51 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6735
	data_grads_norm = 3.8839
	new_data_grads_norm = 5.4739
	old_data_grads_norm = 4.3407
	sim_grads_norm_tr = 0.2407
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1752
	data_grads_norm = 3.9701
	new_data_grads_norm = 5.1817
	old_data_grads_norm = 5.3739
	sim_grads_norm_tr = 0.0202
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6868
	data_grads_norm = 3.1138
	new_data_grads_norm = 4.7153
	old_data_grads_norm = 3.8830
	sim_grads_norm_tr = 0.0754
-- Starting training on experience 52 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0057
	data_grads_norm = 3.2571
	new_data_grads_norm = 5.0513
	old_data_grads_norm = 3.7435
	sim_grads_norm_tr = 0.1006
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9293
	data_grads_norm = 4.0967
	new_data_grads_norm = 5.0607
	old_data_grads_norm = 5.4299
	sim_grads_norm_tr = 0.1783
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8797
	data_grads_norm = 3.7527
	new_data_grads_norm = 4.9203
	old_data_grads_norm = 5.6583
	sim_grads_norm_tr = -0.0423
-- Starting training on experience 53 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3014
	data_grads_norm = 4.1953
	new_data_grads_norm = 5.4273
	old_data_grads_norm = 5.2449
	sim_grads_norm_tr = 0.1965
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1981
	data_grads_norm = 3.5509
	new_data_grads_norm = 4.5646
	old_data_grads_norm = 4.3411
	sim_grads_norm_tr = 0.0627
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1521
	data_grads_norm = 3.3632
	new_data_grads_norm = 4.5004
	old_data_grads_norm = 4.7278
	sim_grads_norm_tr = 0.1125
-- Starting training on experience 54 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9662
	data_grads_norm = 3.5592
	new_data_grads_norm = 4.2602
	old_data_grads_norm = 5.8892
	sim_grads_norm_tr = -0.0794
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9215
	data_grads_norm = 3.2852
	new_data_grads_norm = 4.7051
	old_data_grads_norm = 4.3310
	sim_grads_norm_tr = 0.0171
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1054
	data_grads_norm = 3.7691
	new_data_grads_norm = 4.7850
	old_data_grads_norm = 6.0822
	sim_grads_norm_tr = -0.0577
-- Starting training on experience 55 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8144
	data_grads_norm = 4.5019
	new_data_grads_norm = 6.4319
	old_data_grads_norm = 5.3575
	sim_grads_norm_tr = -0.0058
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3753
	data_grads_norm = 3.6097
	new_data_grads_norm = 6.0559
	old_data_grads_norm = 4.1691
	sim_grads_norm_tr = 0.1286
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0658
	data_grads_norm = 3.4379
	new_data_grads_norm = 5.6409
	old_data_grads_norm = 3.7049
	sim_grads_norm_tr = 0.0014
-- Starting training on experience 56 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7374
	data_grads_norm = 3.9156
	new_data_grads_norm = 6.1439
	old_data_grads_norm = 5.0319
	sim_grads_norm_tr = 0.0108
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6250
	data_grads_norm = 3.7276
	new_data_grads_norm = 6.2946
	old_data_grads_norm = 3.8199
	sim_grads_norm_tr = 0.0483
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4780
	data_grads_norm = 4.8490
	new_data_grads_norm = 6.2600
	old_data_grads_norm = 8.1192
	sim_grads_norm_tr = 0.0289
-- Starting training on experience 57 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3094
	data_grads_norm = 4.3074
	new_data_grads_norm = 6.4006
	old_data_grads_norm = 4.3354
	sim_grads_norm_tr = 0.0388
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9745
	data_grads_norm = 3.5722
	new_data_grads_norm = 6.5328
	old_data_grads_norm = 4.8522
	sim_grads_norm_tr = -0.0884
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0818
	data_grads_norm = 4.3855
	new_data_grads_norm = 6.9622
	old_data_grads_norm = 5.7885
	sim_grads_norm_tr = -0.0142
-- Starting training on experience 58 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3155
	data_grads_norm = 3.9025
	new_data_grads_norm = 5.9474
	old_data_grads_norm = 5.2088
	sim_grads_norm_tr = -0.0663
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1620
	data_grads_norm = 3.6098
	new_data_grads_norm = 5.8961
	old_data_grads_norm = 4.4177
	sim_grads_norm_tr = 0.0687
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1495
	data_grads_norm = 3.6125
	new_data_grads_norm = 5.7908
	old_data_grads_norm = 4.3383
	sim_grads_norm_tr = -0.0660
-- Starting training on experience 59 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2687
	data_grads_norm = 3.7085
	new_data_grads_norm = 5.0771
	old_data_grads_norm = 4.5638
	sim_grads_norm_tr = 0.1417
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8420
	data_grads_norm = 3.6220
	new_data_grads_norm = 5.1434
	old_data_grads_norm = 4.5404
	sim_grads_norm_tr = -0.0278
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1675
	data_grads_norm = 4.1323
	new_data_grads_norm = 5.7640
	old_data_grads_norm = 4.4325
	sim_grads_norm_tr = 0.3180
-- Starting training on experience 60 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9935
	data_grads_norm = 3.5702
	new_data_grads_norm = 5.3236
	old_data_grads_norm = 4.2772
	sim_grads_norm_tr = 0.0589
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0668
	data_grads_norm = 3.6983
	new_data_grads_norm = 5.0240
	old_data_grads_norm = 4.9644
	sim_grads_norm_tr = 0.0559
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1523
	data_grads_norm = 3.4732
	new_data_grads_norm = 4.9442
	old_data_grads_norm = 4.5344
	sim_grads_norm_tr = -0.0251
-- Starting training on experience 61 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5290
	data_grads_norm = 3.5821
	new_data_grads_norm = 4.8510
	old_data_grads_norm = 5.4089
	sim_grads_norm_tr = -0.0380
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1492
	data_grads_norm = 3.5350
	new_data_grads_norm = 4.9712
	old_data_grads_norm = 4.4719
	sim_grads_norm_tr = 0.1112
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2989
	data_grads_norm = 3.7318
	new_data_grads_norm = 4.6861
	old_data_grads_norm = 5.6337
	sim_grads_norm_tr = -0.0584
-- Starting training on experience 62 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2444
	data_grads_norm = 3.4004
	new_data_grads_norm = 5.5876
	old_data_grads_norm = 4.9628
	sim_grads_norm_tr = -0.1239
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3771
	data_grads_norm = 4.0304
	new_data_grads_norm = 5.8916
	old_data_grads_norm = 5.8725
	sim_grads_norm_tr = 0.0045
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5143
	data_grads_norm = 4.4615
	new_data_grads_norm = 6.4981
	old_data_grads_norm = 5.8558
	sim_grads_norm_tr = 0.1551
-- Starting training on experience 63 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1260
	data_grads_norm = 4.0227
	new_data_grads_norm = 5.7695
	old_data_grads_norm = 5.6165
	sim_grads_norm_tr = -0.1098
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4142
	data_grads_norm = 4.0229
	new_data_grads_norm = 6.9437
	old_data_grads_norm = 3.7138
	sim_grads_norm_tr = 0.0706
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1156
	data_grads_norm = 3.7404
	new_data_grads_norm = 6.4260
	old_data_grads_norm = 3.8499
	sim_grads_norm_tr = 0.0208
-- Starting training on experience 64 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6757
	data_grads_norm = 4.3644
	new_data_grads_norm = 6.3911
	old_data_grads_norm = 4.4502
	sim_grads_norm_tr = 0.2351
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6578
	data_grads_norm = 4.6317
	new_data_grads_norm = 5.7963
	old_data_grads_norm = 6.8943
	sim_grads_norm_tr = 0.0812
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5648
	data_grads_norm = 4.2563
	new_data_grads_norm = 5.7641
	old_data_grads_norm = 5.0455
	sim_grads_norm_tr = 0.1478
-- Starting training on experience 65 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2977
	data_grads_norm = 3.9962
	new_data_grads_norm = 6.2505
	old_data_grads_norm = 4.3084
	sim_grads_norm_tr = -0.0368
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4347
	data_grads_norm = 4.3874
	new_data_grads_norm = 7.1943
	old_data_grads_norm = 5.0718
	sim_grads_norm_tr = 0.0222
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5530
	data_grads_norm = 4.3627
	new_data_grads_norm = 6.0534
	old_data_grads_norm = 4.9416
	sim_grads_norm_tr = -0.0047
-- Starting training on experience 66 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4272
	data_grads_norm = 4.1453
	new_data_grads_norm = 6.0487
	old_data_grads_norm = 5.0008
	sim_grads_norm_tr = 0.0580
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4088
	data_grads_norm = 3.8671
	new_data_grads_norm = 5.2028
	old_data_grads_norm = 5.1233
	sim_grads_norm_tr = 0.0647
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1601
	data_grads_norm = 3.8539
	new_data_grads_norm = 5.1876
	old_data_grads_norm = 5.7720
	sim_grads_norm_tr = 0.0066
-- Starting training on experience 67 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4244
	data_grads_norm = 3.9436
	new_data_grads_norm = 5.3910
	old_data_grads_norm = 4.7221
	sim_grads_norm_tr = 0.1665
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4226
	data_grads_norm = 3.5879
	new_data_grads_norm = 5.0401
	old_data_grads_norm = 6.0767
	sim_grads_norm_tr = -0.0398
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4403
	data_grads_norm = 3.7037
	new_data_grads_norm = 5.1709
	old_data_grads_norm = 3.9071
	sim_grads_norm_tr = 0.2277
-- Starting training on experience 68 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2890
	data_grads_norm = 3.5860
	new_data_grads_norm = 5.5350
	old_data_grads_norm = 4.5853
	sim_grads_norm_tr = 0.0374
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1955
	data_grads_norm = 3.7659
	new_data_grads_norm = 5.6678
	old_data_grads_norm = 4.7654
	sim_grads_norm_tr = -0.0571
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5345
	data_grads_norm = 4.1066
	new_data_grads_norm = 6.1654
	old_data_grads_norm = 4.2236
	sim_grads_norm_tr = 0.0208
-- Starting training on experience 69 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1657
	data_grads_norm = 3.7025
	new_data_grads_norm = 4.9185
	old_data_grads_norm = 4.9677
	sim_grads_norm_tr = 0.1126
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0956
	data_grads_norm = 3.7958
	new_data_grads_norm = 4.4840
	old_data_grads_norm = 6.7003
	sim_grads_norm_tr = -0.0297
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7701
	data_grads_norm = 3.2843
	new_data_grads_norm = 5.3977
	old_data_grads_norm = 4.6664
	sim_grads_norm_tr = -0.0013
-- Starting training on experience 70 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9503
	data_grads_norm = 3.4691
	new_data_grads_norm = 5.5221
	old_data_grads_norm = 6.5057
	sim_grads_norm_tr = -0.1038
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4094
	data_grads_norm = 4.3951
	new_data_grads_norm = 6.3282
	old_data_grads_norm = 5.4684
	sim_grads_norm_tr = 0.1102
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2342
	data_grads_norm = 4.1707
	new_data_grads_norm = 6.0890
	old_data_grads_norm = 4.8287
	sim_grads_norm_tr = 0.2250
-- Starting training on experience 71 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9660
	data_grads_norm = 3.1675
	new_data_grads_norm = 4.2783
	old_data_grads_norm = 4.4872
	sim_grads_norm_tr = -0.0228
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7853
	data_grads_norm = 3.2551
	new_data_grads_norm = 4.3987
	old_data_grads_norm = 4.6510
	sim_grads_norm_tr = 0.1575
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9688
	data_grads_norm = 3.1156
	new_data_grads_norm = 4.3150
	old_data_grads_norm = 5.0204
	sim_grads_norm_tr = 0.0119
-- Starting training on experience 72 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4194
	data_grads_norm = 4.3064
	new_data_grads_norm = 5.1187
	old_data_grads_norm = 5.4809
	sim_grads_norm_tr = 0.2577
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7875
	data_grads_norm = 2.8652
	new_data_grads_norm = 3.9274
	old_data_grads_norm = 4.0351
	sim_grads_norm_tr = 0.0409
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8350
	data_grads_norm = 3.1618
	new_data_grads_norm = 3.9742
	old_data_grads_norm = 6.2378
	sim_grads_norm_tr = -0.0484
-- Starting training on experience 73 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2789
	data_grads_norm = 3.6233
	new_data_grads_norm = 5.0592
	old_data_grads_norm = 4.5409
	sim_grads_norm_tr = 0.0722
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1858
	data_grads_norm = 3.5653
	new_data_grads_norm = 5.0268
	old_data_grads_norm = 5.2882
	sim_grads_norm_tr = -0.0368
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4384
	data_grads_norm = 3.4237
	new_data_grads_norm = 5.0685
	old_data_grads_norm = 4.0682
	sim_grads_norm_tr = 0.0853
-- Starting training on experience 74 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4576
	data_grads_norm = 4.0976
	new_data_grads_norm = 5.9572
	old_data_grads_norm = 4.9499
	sim_grads_norm_tr = 0.1155
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5456
	data_grads_norm = 3.9744
	new_data_grads_norm = 5.7637
	old_data_grads_norm = 5.9686
	sim_grads_norm_tr = -0.0230
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4625
	data_grads_norm = 3.8308
	new_data_grads_norm = 5.8574
	old_data_grads_norm = 4.1919
	sim_grads_norm_tr = 0.0393
-- Starting training on experience 75 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3795
	data_grads_norm = 3.8531
	new_data_grads_norm = 4.9736
	old_data_grads_norm = 4.9996
	sim_grads_norm_tr = 0.0728
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1413
	data_grads_norm = 3.2979
	new_data_grads_norm = 4.2204
	old_data_grads_norm = 5.4694
	sim_grads_norm_tr = 0.0920
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0251
	data_grads_norm = 3.5995
	new_data_grads_norm = 4.5428
	old_data_grads_norm = 6.0252
	sim_grads_norm_tr = -0.0542
-- Starting training on experience 76 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0351
	data_grads_norm = 3.5953
	new_data_grads_norm = 4.9215
	old_data_grads_norm = 3.6892
	sim_grads_norm_tr = 0.3157
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9240
	data_grads_norm = 2.8300
	new_data_grads_norm = 4.3419
	old_data_grads_norm = 4.0069
	sim_grads_norm_tr = -0.1061
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9502
	data_grads_norm = 3.0792
	new_data_grads_norm = 5.0949
	old_data_grads_norm = 3.1161
	sim_grads_norm_tr = 0.0627
-- Starting training on experience 77 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5210
	data_grads_norm = 3.5252
	new_data_grads_norm = 4.7751
	old_data_grads_norm = 4.4708
	sim_grads_norm_tr = 0.1128
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1613
	data_grads_norm = 3.3943
	new_data_grads_norm = 4.5125
	old_data_grads_norm = 5.4940
	sim_grads_norm_tr = -0.1273
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3007
	data_grads_norm = 3.6107
	new_data_grads_norm = 4.7536
	old_data_grads_norm = 5.9943
	sim_grads_norm_tr = 0.1506
-- Starting training on experience 78 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0348
	data_grads_norm = 3.7868
	new_data_grads_norm = 6.1623
	old_data_grads_norm = 3.9498
	sim_grads_norm_tr = -0.0573
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8650
	data_grads_norm = 3.8188
	new_data_grads_norm = 5.7387
	old_data_grads_norm = 5.2051
	sim_grads_norm_tr = -0.0162
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1572
	data_grads_norm = 4.5611
	new_data_grads_norm = 6.1848
	old_data_grads_norm = 4.6528
	sim_grads_norm_tr = 0.1919
-- Starting training on experience 79 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1042
	data_grads_norm = 3.4790
	new_data_grads_norm = 5.9929
	old_data_grads_norm = 4.2806
	sim_grads_norm_tr = -0.1576
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9959
	data_grads_norm = 3.9256
	new_data_grads_norm = 6.2913
	old_data_grads_norm = 4.2975
	sim_grads_norm_tr = -0.0407
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0354
	data_grads_norm = 4.2054
	new_data_grads_norm = 6.6485
	old_data_grads_norm = 5.6733
	sim_grads_norm_tr = 0.0993
-- Starting training on experience 80 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2117
	data_grads_norm = 4.1611
	new_data_grads_norm = 5.3066
	old_data_grads_norm = 5.2597
	sim_grads_norm_tr = 0.1918
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0426
	data_grads_norm = 3.3144
	new_data_grads_norm = 4.7074
	old_data_grads_norm = 4.8926
	sim_grads_norm_tr = 0.0030
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9866
	data_grads_norm = 3.4255
	new_data_grads_norm = 4.9317
	old_data_grads_norm = 4.2998
	sim_grads_norm_tr = -0.0253
-- Starting training on experience 81 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9323
	data_grads_norm = 3.6082
	new_data_grads_norm = 4.9094
	old_data_grads_norm = 4.5127
	sim_grads_norm_tr = 0.0987
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2987
	data_grads_norm = 4.0603
	new_data_grads_norm = 5.0720
	old_data_grads_norm = 6.1733
	sim_grads_norm_tr = 0.0722
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0401
	data_grads_norm = 3.2182
	new_data_grads_norm = 4.8291
	old_data_grads_norm = 5.3168
	sim_grads_norm_tr = -0.0265
-- Starting training on experience 82 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4129
	data_grads_norm = 2.6546
	new_data_grads_norm = 4.2251
	old_data_grads_norm = 3.7899
	sim_grads_norm_tr = -0.0150
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2537
	data_grads_norm = 3.9524
	new_data_grads_norm = 4.7056
	old_data_grads_norm = 5.3162
	sim_grads_norm_tr = -0.0706
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0284
	data_grads_norm = 3.4401
	new_data_grads_norm = 4.7074
	old_data_grads_norm = 4.7390
	sim_grads_norm_tr = 0.0307
-- Starting training on experience 83 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1685
	data_grads_norm = 3.7350
	new_data_grads_norm = 4.6847
	old_data_grads_norm = 5.0755
	sim_grads_norm_tr = 0.0965
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8283
	data_grads_norm = 3.4030
	new_data_grads_norm = 4.7865
	old_data_grads_norm = 3.8494
	sim_grads_norm_tr = 0.1822
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5474
	data_grads_norm = 3.0003
	new_data_grads_norm = 4.5201
	old_data_grads_norm = 3.5232
	sim_grads_norm_tr = 0.0821
-- Starting training on experience 84 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0099
	data_grads_norm = 3.7515
	new_data_grads_norm = 5.8962
	old_data_grads_norm = 3.7553
	sim_grads_norm_tr = 0.0989
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8590
	data_grads_norm = 3.8725
	new_data_grads_norm = 6.0598
	old_data_grads_norm = 3.4051
	sim_grads_norm_tr = 0.1412
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7868
	data_grads_norm = 3.3400
	new_data_grads_norm = 4.8677
	old_data_grads_norm = 5.6910
	sim_grads_norm_tr = -0.0645
-- Starting training on experience 85 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0253
	data_grads_norm = 4.5873
	new_data_grads_norm = 5.9857
	old_data_grads_norm = 5.6720
	sim_grads_norm_tr = 0.0853
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8198
	data_grads_norm = 3.4320
	new_data_grads_norm = 4.9081
	old_data_grads_norm = 4.3201
	sim_grads_norm_tr = -0.0385
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8120
	data_grads_norm = 3.2369
	new_data_grads_norm = 4.6749
	old_data_grads_norm = 4.8202
	sim_grads_norm_tr = -0.0045
-- Starting training on experience 86 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9749
	data_grads_norm = 3.7433
	new_data_grads_norm = 6.0707
	old_data_grads_norm = 5.2038
	sim_grads_norm_tr = -0.0248
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0724
	data_grads_norm = 3.9730
	new_data_grads_norm = 6.7787
	old_data_grads_norm = 4.0978
	sim_grads_norm_tr = 0.0206
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9720
	data_grads_norm = 3.9846
	new_data_grads_norm = 5.7670
	old_data_grads_norm = 4.1684
	sim_grads_norm_tr = -0.0442
-- Starting training on experience 87 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9879
	data_grads_norm = 3.8260
	new_data_grads_norm = 5.5182
	old_data_grads_norm = 5.7263
	sim_grads_norm_tr = -0.0399
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3239
	data_grads_norm = 4.6752
	new_data_grads_norm = 5.0094
	old_data_grads_norm = 6.0067
	sim_grads_norm_tr = 0.1618
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1369
	data_grads_norm = 3.9520
	new_data_grads_norm = 5.2309
	old_data_grads_norm = 4.8005
	sim_grads_norm_tr = 0.1619
-- Starting training on experience 88 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6412
	data_grads_norm = 4.4392
	new_data_grads_norm = 6.1684
	old_data_grads_norm = 6.3274
	sim_grads_norm_tr = -0.0834
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3685
	data_grads_norm = 3.4709
	new_data_grads_norm = 5.5984
	old_data_grads_norm = 4.1497
	sim_grads_norm_tr = 0.0891
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7941
	data_grads_norm = 4.0511
	new_data_grads_norm = 5.8300
	old_data_grads_norm = 5.4552
	sim_grads_norm_tr = 0.0232
-- Starting training on experience 89 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5898
	data_grads_norm = 4.6578
	new_data_grads_norm = 5.6987
	old_data_grads_norm = 6.8274
	sim_grads_norm_tr = 0.1338
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0838
	data_grads_norm = 3.8874
	new_data_grads_norm = 6.0956
	old_data_grads_norm = 3.9964
	sim_grads_norm_tr = 0.2249
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2723
	data_grads_norm = 3.8660
	new_data_grads_norm = 5.3057
	old_data_grads_norm = 5.5136
	sim_grads_norm_tr = 0.0478
-- Starting training on experience 90 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8908
	data_grads_norm = 3.2830
	new_data_grads_norm = 4.6719
	old_data_grads_norm = 4.7441
	sim_grads_norm_tr = 0.0837
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3305
	data_grads_norm = 4.0210
	new_data_grads_norm = 5.0063
	old_data_grads_norm = 6.1615
	sim_grads_norm_tr = 0.0623
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8289
	data_grads_norm = 3.2855
	new_data_grads_norm = 4.4005
	old_data_grads_norm = 3.9948
	sim_grads_norm_tr = 0.2205
-- Starting training on experience 91 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8772
	data_grads_norm = 3.0047
	new_data_grads_norm = 4.2326
	old_data_grads_norm = 4.4822
	sim_grads_norm_tr = 0.0189
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6069
	data_grads_norm = 2.6319
	new_data_grads_norm = 4.3684
	old_data_grads_norm = 2.8025
	sim_grads_norm_tr = -0.0920
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5306
	data_grads_norm = 3.0095
	new_data_grads_norm = 4.8490
	old_data_grads_norm = 3.7928
	sim_grads_norm_tr = 0.0678
-- Starting training on experience 92 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6916
	data_grads_norm = 2.6901
	new_data_grads_norm = 4.0312
	old_data_grads_norm = 4.1215
	sim_grads_norm_tr = -0.1588
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9064
	data_grads_norm = 3.2663
	new_data_grads_norm = 4.5760
	old_data_grads_norm = 4.2332
	sim_grads_norm_tr = 0.0710
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4935
	data_grads_norm = 3.1085
	new_data_grads_norm = 4.5808
	old_data_grads_norm = 4.7034
	sim_grads_norm_tr = -0.1734
-- Starting training on experience 93 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5942
	data_grads_norm = 4.1912
	new_data_grads_norm = 5.0603
	old_data_grads_norm = 4.9893
	sim_grads_norm_tr = 0.3304
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7571
	data_grads_norm = 3.9146
	new_data_grads_norm = 5.1942
	old_data_grads_norm = 5.7132
	sim_grads_norm_tr = -0.0310
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5348
	data_grads_norm = 3.4820
	new_data_grads_norm = 5.0144
	old_data_grads_norm = 4.8228
	sim_grads_norm_tr = 0.0374
-- Starting training on experience 94 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8580
	data_grads_norm = 3.7538
	new_data_grads_norm = 5.1100
	old_data_grads_norm = 5.4242
	sim_grads_norm_tr = 0.0007
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0465
	data_grads_norm = 3.8305
	new_data_grads_norm = 5.0441
	old_data_grads_norm = 6.0118
	sim_grads_norm_tr = 0.0988
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2699
	data_grads_norm = 4.4936
	new_data_grads_norm = 5.4835
	old_data_grads_norm = 5.5628
	sim_grads_norm_tr = 0.3716
-- Starting training on experience 95 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9836
	data_grads_norm = 4.1086
	new_data_grads_norm = 4.5038
	old_data_grads_norm = 6.3904
	sim_grads_norm_tr = -0.0953
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9790
	data_grads_norm = 3.7294
	new_data_grads_norm = 5.3296
	old_data_grads_norm = 4.2904
	sim_grads_norm_tr = 0.1829
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9648
	data_grads_norm = 3.3966
	new_data_grads_norm = 4.3792
	old_data_grads_norm = 5.9764
	sim_grads_norm_tr = -0.1261
-- Starting training on experience 96 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0810
	data_grads_norm = 3.9681
	new_data_grads_norm = 5.7590
	old_data_grads_norm = 5.0004
	sim_grads_norm_tr = -0.0136
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1095
	data_grads_norm = 3.5641
	new_data_grads_norm = 5.6281
	old_data_grads_norm = 4.1670
	sim_grads_norm_tr = 0.0218
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1821
	data_grads_norm = 4.3791
	new_data_grads_norm = 5.9650
	old_data_grads_norm = 5.4569
	sim_grads_norm_tr = 0.1814
-- Starting training on experience 97 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4264
	data_grads_norm = 4.7756
	new_data_grads_norm = 5.6913
	old_data_grads_norm = 6.8732
	sim_grads_norm_tr = 0.1920
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7853
	data_grads_norm = 3.2659
	new_data_grads_norm = 5.0403
	old_data_grads_norm = 5.0182
	sim_grads_norm_tr = -0.0732
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7258
	data_grads_norm = 3.8404
	new_data_grads_norm = 5.2867
	old_data_grads_norm = 5.6272
	sim_grads_norm_tr = 0.0058
-- Starting training on experience 98 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3884
	data_grads_norm = 4.0469
	new_data_grads_norm = 6.4459
	old_data_grads_norm = 4.7210
	sim_grads_norm_tr = 0.1049
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0431
	data_grads_norm = 4.5368
	new_data_grads_norm = 6.5240
	old_data_grads_norm = 5.4585
	sim_grads_norm_tr = 0.0688
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2916
	data_grads_norm = 4.4224
	new_data_grads_norm = 5.8353
	old_data_grads_norm = 5.2511
	sim_grads_norm_tr = 0.1098
-- Starting training on experience 99 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1208
	data_grads_norm = 3.7967
	new_data_grads_norm = 5.0168
	old_data_grads_norm = 4.6752
	sim_grads_norm_tr = 0.1606
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8451
	data_grads_norm = 3.6156
	new_data_grads_norm = 4.9398
	old_data_grads_norm = 4.7070
	sim_grads_norm_tr = 0.1034
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1645
	data_grads_norm = 2.9457
	new_data_grads_norm = 4.1559
	old_data_grads_norm = 4.7087
	sim_grads_norm_tr = -0.0373
-- Starting training on experience 100 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7816
	data_grads_norm = 3.8191
	new_data_grads_norm = 5.5113
	old_data_grads_norm = 5.5723
	sim_grads_norm_tr = -0.0119
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1909
	data_grads_norm = 3.4167
	new_data_grads_norm = 5.2613
	old_data_grads_norm = 4.0798
	sim_grads_norm_tr = 0.1032
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0367
	data_grads_norm = 2.9644
	new_data_grads_norm = 5.2890
	old_data_grads_norm = 3.8707
	sim_grads_norm_tr = -0.1700
-- Starting training on experience 101 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8075
	data_grads_norm = 4.0485
	new_data_grads_norm = 7.4435
	old_data_grads_norm = 3.8414
	sim_grads_norm_tr = -0.1314
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7263
	data_grads_norm = 3.9431
	new_data_grads_norm = 6.1139
	old_data_grads_norm = 4.5671
	sim_grads_norm_tr = 0.0012
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1219
	data_grads_norm = 4.1253
	new_data_grads_norm = 6.6652
	old_data_grads_norm = 5.1048
	sim_grads_norm_tr = -0.0713
-- Starting training on experience 102 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9503
	data_grads_norm = 3.7877
	new_data_grads_norm = 5.4051
	old_data_grads_norm = 5.2915
	sim_grads_norm_tr = 0.0983
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2170
	data_grads_norm = 3.7932
	new_data_grads_norm = 4.9484
	old_data_grads_norm = 4.1779
	sim_grads_norm_tr = 0.2731
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6040
	data_grads_norm = 3.3038
	new_data_grads_norm = 3.8443
	old_data_grads_norm = 4.4388
	sim_grads_norm_tr = 0.1772
-- Starting training on experience 103 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5102
	data_grads_norm = 3.8042
	new_data_grads_norm = 4.7543
	old_data_grads_norm = 5.5676
	sim_grads_norm_tr = -0.0189
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1304
	data_grads_norm = 3.4787
	new_data_grads_norm = 4.7988
	old_data_grads_norm = 4.2924
	sim_grads_norm_tr = 0.1648
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1520
	data_grads_norm = 3.8167
	new_data_grads_norm = 5.1166
	old_data_grads_norm = 5.6079
	sim_grads_norm_tr = 0.0264
-- Starting training on experience 104 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1414
	data_grads_norm = 3.1105
	new_data_grads_norm = 4.5795
	old_data_grads_norm = 3.4540
	sim_grads_norm_tr = 0.1937
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0720
	data_grads_norm = 3.2171
	new_data_grads_norm = 4.0719
	old_data_grads_norm = 4.6877
	sim_grads_norm_tr = -0.0376
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9928
	data_grads_norm = 3.2287
	new_data_grads_norm = 4.1848
	old_data_grads_norm = 5.1184
	sim_grads_norm_tr = -0.0094
-- Starting training on experience 105 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0302
	data_grads_norm = 4.0572
	new_data_grads_norm = 5.8711
	old_data_grads_norm = 4.7453
	sim_grads_norm_tr = 0.0746
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9398
	data_grads_norm = 3.3996
	new_data_grads_norm = 5.7283
	old_data_grads_norm = 5.2645
	sim_grads_norm_tr = -0.1157
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8410
	data_grads_norm = 4.0273
	new_data_grads_norm = 6.0873
	old_data_grads_norm = 5.1174
	sim_grads_norm_tr = 0.0405
-- Starting training on experience 106 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7963
	data_grads_norm = 2.8186
	new_data_grads_norm = 6.3089
	old_data_grads_norm = 3.3831
	sim_grads_norm_tr = -0.0505
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2871
	data_grads_norm = 4.1095
	new_data_grads_norm = 7.1357
	old_data_grads_norm = 4.2688
	sim_grads_norm_tr = 0.2264
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8552
	data_grads_norm = 3.7292
	new_data_grads_norm = 6.2814
	old_data_grads_norm = 4.1045
	sim_grads_norm_tr = 0.0103
-- Starting training on experience 107 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9394
	data_grads_norm = 3.2128
	new_data_grads_norm = 5.5235
	old_data_grads_norm = 3.8125
	sim_grads_norm_tr = -0.0105
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7577
	data_grads_norm = 2.9556
	new_data_grads_norm = 5.0129
	old_data_grads_norm = 4.3613
	sim_grads_norm_tr = -0.0292
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2526
	data_grads_norm = 3.8839
	new_data_grads_norm = 5.7696
	old_data_grads_norm = 4.9419
	sim_grads_norm_tr = -0.0212
-- Starting training on experience 108 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0613
	data_grads_norm = 3.9454
	new_data_grads_norm = 5.5645
	old_data_grads_norm = 4.8578
	sim_grads_norm_tr = 0.1538
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7432
	data_grads_norm = 3.6657
	new_data_grads_norm = 5.4967
	old_data_grads_norm = 5.4989
	sim_grads_norm_tr = -0.0152
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1500
	data_grads_norm = 4.1900
	new_data_grads_norm = 5.7907
	old_data_grads_norm = 6.9622
	sim_grads_norm_tr = 0.0029
-- Starting training on experience 109 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3383
	data_grads_norm = 3.4971
	new_data_grads_norm = 6.4229
	old_data_grads_norm = 4.5594
	sim_grads_norm_tr = -0.0148
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8565
	data_grads_norm = 4.0283
	new_data_grads_norm = 6.4523
	old_data_grads_norm = 5.3474
	sim_grads_norm_tr = 0.0219
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5267
	data_grads_norm = 4.0258
	new_data_grads_norm = 6.5150
	old_data_grads_norm = 5.1534
	sim_grads_norm_tr = 0.0781
-- Starting training on experience 110 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8470
	data_grads_norm = 3.9596
	new_data_grads_norm = 6.5477
	old_data_grads_norm = 4.1708
	sim_grads_norm_tr = -0.0124
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0367
	data_grads_norm = 4.4008
	new_data_grads_norm = 6.7835
	old_data_grads_norm = 4.7486
	sim_grads_norm_tr = 0.1735
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6580
	data_grads_norm = 3.5176
	new_data_grads_norm = 5.6604
	old_data_grads_norm = 3.8076
	sim_grads_norm_tr = -0.0595
-- Starting training on experience 111 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2349
	data_grads_norm = 3.4297
	new_data_grads_norm = 5.0942
	old_data_grads_norm = 4.2716
	sim_grads_norm_tr = 0.1134
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4725
	data_grads_norm = 3.8629
	new_data_grads_norm = 5.6789
	old_data_grads_norm = 5.2110
	sim_grads_norm_tr = 0.0558
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5025
	data_grads_norm = 3.5578
	new_data_grads_norm = 4.9972
	old_data_grads_norm = 4.4529
	sim_grads_norm_tr = 0.0429
-- Starting training on experience 112 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6961
	data_grads_norm = 3.3869
	new_data_grads_norm = 5.0392
	old_data_grads_norm = 5.3409
	sim_grads_norm_tr = 0.0175
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9191
	data_grads_norm = 3.4026
	new_data_grads_norm = 5.0427
	old_data_grads_norm = 4.2353
	sim_grads_norm_tr = 0.0500
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7208
	data_grads_norm = 4.1155
	new_data_grads_norm = 5.7102
	old_data_grads_norm = 4.4415
	sim_grads_norm_tr = 0.2633
-- Starting training on experience 113 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1940
	data_grads_norm = 4.1645
	new_data_grads_norm = 5.4592
	old_data_grads_norm = 4.9080
	sim_grads_norm_tr = 0.0139
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9498
	data_grads_norm = 3.8666
	new_data_grads_norm = 5.4956
	old_data_grads_norm = 4.3186
	sim_grads_norm_tr = -0.0521
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9359
	data_grads_norm = 3.5453
	new_data_grads_norm = 5.5476
	old_data_grads_norm = 4.1463
	sim_grads_norm_tr = -0.0357
-- Starting training on experience 114 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9032
	data_grads_norm = 4.1804
	new_data_grads_norm = 6.3353
	old_data_grads_norm = 4.1695
	sim_grads_norm_tr = 0.2960
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9744
	data_grads_norm = 3.2617
	new_data_grads_norm = 4.7352
	old_data_grads_norm = 3.9232
	sim_grads_norm_tr = 0.0764
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0793
	data_grads_norm = 3.7698
	new_data_grads_norm = 5.0532
	old_data_grads_norm = 6.6358
	sim_grads_norm_tr = -0.1680
-- Starting training on experience 115 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1152
	data_grads_norm = 3.5932
	new_data_grads_norm = 5.9768
	old_data_grads_norm = 3.7380
	sim_grads_norm_tr = 0.0806
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0866
	data_grads_norm = 3.9747
	new_data_grads_norm = 5.8000
	old_data_grads_norm = 5.7107
	sim_grads_norm_tr = 0.0187
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3138
	data_grads_norm = 3.8052
	new_data_grads_norm = 5.2988
	old_data_grads_norm = 4.6351
	sim_grads_norm_tr = 0.1965
-- Starting training on experience 116 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1880
	data_grads_norm = 3.7417
	new_data_grads_norm = 5.1369
	old_data_grads_norm = 4.7090
	sim_grads_norm_tr = 0.0873
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9445
	data_grads_norm = 3.0716
	new_data_grads_norm = 4.5499
	old_data_grads_norm = 4.5576
	sim_grads_norm_tr = -0.1655
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0213
	data_grads_norm = 3.8968
	new_data_grads_norm = 5.2951
	old_data_grads_norm = 5.3228
	sim_grads_norm_tr = 0.0179
-- Starting training on experience 117 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2076
	data_grads_norm = 4.5723
	new_data_grads_norm = 6.5659
	old_data_grads_norm = 6.0734
	sim_grads_norm_tr = 0.0823
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2518
	data_grads_norm = 3.8638
	new_data_grads_norm = 6.0013
	old_data_grads_norm = 4.8663
	sim_grads_norm_tr = 0.0447
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2742
	data_grads_norm = 3.6892
	new_data_grads_norm = 6.2605
	old_data_grads_norm = 4.5078
	sim_grads_norm_tr = 0.1063
-- Starting training on experience 118 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0040
	data_grads_norm = 3.3584
	new_data_grads_norm = 4.2207
	old_data_grads_norm = 5.0236
	sim_grads_norm_tr = -0.0755
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0490
	data_grads_norm = 3.9449
	new_data_grads_norm = 5.5326
	old_data_grads_norm = 5.2948
	sim_grads_norm_tr = -0.0009
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9984
	data_grads_norm = 3.8322
	new_data_grads_norm = 5.3014
	old_data_grads_norm = 4.7027
	sim_grads_norm_tr = 0.1734
-- Starting training on experience 119 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0245
	data_grads_norm = 4.0525
	new_data_grads_norm = 5.0548
	old_data_grads_norm = 4.9119
	sim_grads_norm_tr = 0.1466
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8999
	data_grads_norm = 2.8043
	new_data_grads_norm = 4.1154
	old_data_grads_norm = 3.6997
	sim_grads_norm_tr = -0.0242
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0295
	data_grads_norm = 3.1355
	new_data_grads_norm = 5.0817
	old_data_grads_norm = 4.2759
	sim_grads_norm_tr = -0.0297
-- Starting training on experience 120 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0366
	data_grads_norm = 3.6299
	new_data_grads_norm = 4.9806
	old_data_grads_norm = 5.5724
	sim_grads_norm_tr = -0.0279
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3118
	data_grads_norm = 4.0988
	new_data_grads_norm = 5.4891
	old_data_grads_norm = 5.8452
	sim_grads_norm_tr = 0.1822
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0637
	data_grads_norm = 4.2639
	new_data_grads_norm = 5.4378
	old_data_grads_norm = 6.5519
	sim_grads_norm_tr = 0.0811
-- Starting training on experience 121 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5347
	data_grads_norm = 4.9037
	new_data_grads_norm = 6.1119
	old_data_grads_norm = 7.5697
	sim_grads_norm_tr = 0.0272
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4760
	data_grads_norm = 4.5715
	new_data_grads_norm = 6.3387
	old_data_grads_norm = 5.7224
	sim_grads_norm_tr = 0.1243
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1664
	data_grads_norm = 3.4923
	new_data_grads_norm = 6.3577
	old_data_grads_norm = 4.4758
	sim_grads_norm_tr = -0.0081
-- Starting training on experience 122 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9167
	data_grads_norm = 3.1862
	new_data_grads_norm = 3.7682
	old_data_grads_norm = 4.6588
	sim_grads_norm_tr = 0.0507
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9140
	data_grads_norm = 2.4491
	new_data_grads_norm = 3.5038
	old_data_grads_norm = 3.7737
	sim_grads_norm_tr = -0.1146
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7527
	data_grads_norm = 2.6121
	new_data_grads_norm = 3.7259
	old_data_grads_norm = 4.1503
	sim_grads_norm_tr = -0.1337
-- Starting training on experience 123 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0431
	data_grads_norm = 3.7591
	new_data_grads_norm = 5.1729
	old_data_grads_norm = 6.4748
	sim_grads_norm_tr = -0.0598
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1123
	data_grads_norm = 3.2674
	new_data_grads_norm = 5.4714
	old_data_grads_norm = 3.6527
	sim_grads_norm_tr = -0.0168
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8506
	data_grads_norm = 3.2907
	new_data_grads_norm = 5.5507
	old_data_grads_norm = 4.2102
	sim_grads_norm_tr = -0.0432
-- Starting training on experience 124 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3451
	data_grads_norm = 4.0882
	new_data_grads_norm = 5.6844
	old_data_grads_norm = 5.8554
	sim_grads_norm_tr = 0.1230
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1549
	data_grads_norm = 3.7886
	new_data_grads_norm = 5.4662
	old_data_grads_norm = 5.6340
	sim_grads_norm_tr = 0.0577
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8749
	data_grads_norm = 3.7068
	new_data_grads_norm = 5.0871
	old_data_grads_norm = 4.1493
	sim_grads_norm_tr = 0.3287
-- Starting training on experience 125 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6390
	data_grads_norm = 3.3884
	new_data_grads_norm = 5.1609
	old_data_grads_norm = 4.1446
	sim_grads_norm_tr = -0.0372
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9746
	data_grads_norm = 4.3819
	new_data_grads_norm = 5.8722
	old_data_grads_norm = 6.9517
	sim_grads_norm_tr = -0.0282
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9277
	data_grads_norm = 3.8888
	new_data_grads_norm = 5.5275
	old_data_grads_norm = 4.6143
	sim_grads_norm_tr = 0.2499
-- Starting training on experience 126 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1957
	data_grads_norm = 3.7609
	new_data_grads_norm = 5.1911
	old_data_grads_norm = 5.5508
	sim_grads_norm_tr = 0.0580
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2848
	data_grads_norm = 3.6419
	new_data_grads_norm = 5.1224
	old_data_grads_norm = 4.7295
	sim_grads_norm_tr = 0.0883
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7426
	data_grads_norm = 2.8616
	new_data_grads_norm = 4.7863
	old_data_grads_norm = 4.3957
	sim_grads_norm_tr = -0.1220
-- Starting training on experience 127 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8372
	data_grads_norm = 3.7853
	new_data_grads_norm = 5.0897
	old_data_grads_norm = 4.6493
	sim_grads_norm_tr = 0.1948
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7360
	data_grads_norm = 3.2368
	new_data_grads_norm = 4.1642
	old_data_grads_norm = 5.4738
	sim_grads_norm_tr = -0.0416
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6895
	data_grads_norm = 3.1476
	new_data_grads_norm = 4.3332
	old_data_grads_norm = 4.4677
	sim_grads_norm_tr = -0.0194
-- Starting training on experience 128 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6282
	data_grads_norm = 4.4581
	new_data_grads_norm = 6.1841
	old_data_grads_norm = 5.3044
	sim_grads_norm_tr = 0.1569
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3293
	data_grads_norm = 3.9335
	new_data_grads_norm = 5.8421
	old_data_grads_norm = 5.0681
	sim_grads_norm_tr = 0.0499
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8883
	data_grads_norm = 3.0919
	new_data_grads_norm = 5.3639
	old_data_grads_norm = 3.7330
	sim_grads_norm_tr = -0.0570
-- Starting training on experience 129 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7378
	data_grads_norm = 3.5421
	new_data_grads_norm = 5.3091
	old_data_grads_norm = 3.7192
	sim_grads_norm_tr = 0.1256
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9296
	data_grads_norm = 3.8580
	new_data_grads_norm = 5.3216
	old_data_grads_norm = 5.5875
	sim_grads_norm_tr = 0.1215
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7692
	data_grads_norm = 3.3601
	new_data_grads_norm = 4.6970
	old_data_grads_norm = 4.6076
	sim_grads_norm_tr = -0.0883
-- Starting training on experience 130 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1274
	data_grads_norm = 3.8733
	new_data_grads_norm = 4.8949
	old_data_grads_norm = 5.4163
	sim_grads_norm_tr = 0.0693
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1614
	data_grads_norm = 3.6868
	new_data_grads_norm = 5.4568
	old_data_grads_norm = 3.9828
	sim_grads_norm_tr = 0.0676
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2512
	data_grads_norm = 3.6844
	new_data_grads_norm = 5.0758
	old_data_grads_norm = 5.7317
	sim_grads_norm_tr = -0.0397
-- Starting training on experience 131 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2239
	data_grads_norm = 5.2068
	new_data_grads_norm = 5.7091
	old_data_grads_norm = 6.6550
	sim_grads_norm_tr = 0.0968
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1420
	data_grads_norm = 4.4991
	new_data_grads_norm = 5.3874
	old_data_grads_norm = 5.8787
	sim_grads_norm_tr = 0.1268
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8517
	data_grads_norm = 3.8274
	new_data_grads_norm = 4.7524
	old_data_grads_norm = 5.6757
	sim_grads_norm_tr = 0.0381
-- Starting training on experience 132 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9458
	data_grads_norm = 3.5793
	new_data_grads_norm = 5.3858
	old_data_grads_norm = 3.7605
	sim_grads_norm_tr = 0.0726
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8371
	data_grads_norm = 3.6246
	new_data_grads_norm = 5.8507
	old_data_grads_norm = 4.0951
	sim_grads_norm_tr = -0.1336
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0643
	data_grads_norm = 3.8740
	new_data_grads_norm = 5.7950
	old_data_grads_norm = 5.1716
	sim_grads_norm_tr = -0.1027
-- Starting training on experience 133 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9173
	data_grads_norm = 3.1006
	new_data_grads_norm = 4.9033
	old_data_grads_norm = 4.2643
	sim_grads_norm_tr = -0.1641
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3591
	data_grads_norm = 4.0468
	new_data_grads_norm = 5.9418
	old_data_grads_norm = 5.1552
	sim_grads_norm_tr = 0.1122
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0950
	data_grads_norm = 3.3408
	new_data_grads_norm = 5.4387
	old_data_grads_norm = 4.5462
	sim_grads_norm_tr = -0.0174
-- Starting training on experience 134 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1870
	data_grads_norm = 4.5972
	new_data_grads_norm = 5.6841
	old_data_grads_norm = 7.4545
	sim_grads_norm_tr = 0.0553
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0121
	data_grads_norm = 4.5697
	new_data_grads_norm = 5.8498
	old_data_grads_norm = 6.5032
	sim_grads_norm_tr = 0.0866
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9384
	data_grads_norm = 4.0676
	new_data_grads_norm = 5.3857
	old_data_grads_norm = 3.6467
	sim_grads_norm_tr = 0.1147
-- Starting training on experience 135 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0661
	data_grads_norm = 3.4477
	new_data_grads_norm = 4.8676
	old_data_grads_norm = 5.5027
	sim_grads_norm_tr = 0.0040
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0649
	data_grads_norm = 3.1993
	new_data_grads_norm = 4.5108
	old_data_grads_norm = 4.0273
	sim_grads_norm_tr = -0.0474
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5143
	data_grads_norm = 2.8168
	new_data_grads_norm = 4.6125
	old_data_grads_norm = 4.0870
	sim_grads_norm_tr = -0.1335
-- Starting training on experience 136 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3600
	data_grads_norm = 4.3394
	new_data_grads_norm = 5.7840
	old_data_grads_norm = 5.4760
	sim_grads_norm_tr = 0.0904
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0079
	data_grads_norm = 3.1347
	new_data_grads_norm = 4.2693
	old_data_grads_norm = 4.6944
	sim_grads_norm_tr = -0.0689
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1300
	data_grads_norm = 4.0631
	new_data_grads_norm = 5.2493
	old_data_grads_norm = 4.3237
	sim_grads_norm_tr = 0.0800
-- Starting training on experience 137 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3760
	data_grads_norm = 4.5922
	new_data_grads_norm = 7.3634
	old_data_grads_norm = 5.4430
	sim_grads_norm_tr = 0.0195
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0190
	data_grads_norm = 3.8085
	new_data_grads_norm = 6.3080
	old_data_grads_norm = 3.8432
	sim_grads_norm_tr = 0.0847
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1593
	data_grads_norm = 4.3515
	new_data_grads_norm = 6.7432
	old_data_grads_norm = 5.3390
	sim_grads_norm_tr = -0.0160
-- Starting training on experience 138 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0100
	data_grads_norm = 4.4828
	new_data_grads_norm = 5.5483
	old_data_grads_norm = 5.3925
	sim_grads_norm_tr = -0.0371
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9132
	data_grads_norm = 3.7348
	new_data_grads_norm = 5.3874
	old_data_grads_norm = 5.3868
	sim_grads_norm_tr = 0.0874
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7763
	data_grads_norm = 3.5472
	new_data_grads_norm = 5.4153
	old_data_grads_norm = 4.8169
	sim_grads_norm_tr = -0.0675
-- Starting training on experience 139 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3835
	data_grads_norm = 4.1822
	new_data_grads_norm = 5.6324
	old_data_grads_norm = 6.3923
	sim_grads_norm_tr = -0.0021
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8952
	data_grads_norm = 3.6313
	new_data_grads_norm = 5.6837
	old_data_grads_norm = 4.1977
	sim_grads_norm_tr = -0.0341
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1440
	data_grads_norm = 3.9895
	new_data_grads_norm = 5.5377
	old_data_grads_norm = 5.2788
	sim_grads_norm_tr = -0.0246
-- Starting training on experience 140 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0142
	data_grads_norm = 3.4331
	new_data_grads_norm = 5.0369
	old_data_grads_norm = 5.8860
	sim_grads_norm_tr = 0.0153
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3157
	data_grads_norm = 3.8810
	new_data_grads_norm = 4.6743
	old_data_grads_norm = 5.8868
	sim_grads_norm_tr = 0.0582
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2659
	data_grads_norm = 3.3849
	new_data_grads_norm = 5.0377
	old_data_grads_norm = 5.3188
	sim_grads_norm_tr = -0.0626
-- Starting training on experience 141 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8968
	data_grads_norm = 3.2515
	new_data_grads_norm = 4.6180
	old_data_grads_norm = 4.5452
	sim_grads_norm_tr = 0.1117
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8572
	data_grads_norm = 3.9845
	new_data_grads_norm = 5.5490
	old_data_grads_norm = 5.2497
	sim_grads_norm_tr = 0.1173
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8232
	data_grads_norm = 3.4130
	new_data_grads_norm = 5.2615
	old_data_grads_norm = 3.4252
	sim_grads_norm_tr = -0.0122
-- Starting training on experience 142 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0824
	data_grads_norm = 3.4189
	new_data_grads_norm = 5.1974
	old_data_grads_norm = 4.5051
	sim_grads_norm_tr = -0.0004
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4955
	data_grads_norm = 4.2322
	new_data_grads_norm = 5.4046
	old_data_grads_norm = 5.4884
	sim_grads_norm_tr = 0.2309
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3478
	data_grads_norm = 3.9623
	new_data_grads_norm = 4.9345
	old_data_grads_norm = 5.6386
	sim_grads_norm_tr = -0.0751
-- Starting training on experience 143 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9390
	data_grads_norm = 3.4869
	new_data_grads_norm = 4.7748
	old_data_grads_norm = 5.8529
	sim_grads_norm_tr = -0.0774
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0771
	data_grads_norm = 3.4284
	new_data_grads_norm = 5.3352
	old_data_grads_norm = 4.2462
	sim_grads_norm_tr = -0.0131
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0655
	data_grads_norm = 3.4484
	new_data_grads_norm = 4.7084
	old_data_grads_norm = 5.5693
	sim_grads_norm_tr = 0.0037
-- Starting training on experience 144 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2282
	data_grads_norm = 4.0008
	new_data_grads_norm = 5.9955
	old_data_grads_norm = 5.0863
	sim_grads_norm_tr = 0.0355
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2514
	data_grads_norm = 4.9594
	new_data_grads_norm = 5.6058
	old_data_grads_norm = 6.7660
	sim_grads_norm_tr = 0.2178
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1798
	data_grads_norm = 4.3995
	new_data_grads_norm = 6.0517
	old_data_grads_norm = 5.2532
	sim_grads_norm_tr = 0.1669
-- Starting training on experience 145 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8036
	data_grads_norm = 3.4419
	new_data_grads_norm = 4.8112
	old_data_grads_norm = 4.8350
	sim_grads_norm_tr = 0.1000
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2629
	data_grads_norm = 3.6361
	new_data_grads_norm = 4.6954
	old_data_grads_norm = 5.6449
	sim_grads_norm_tr = -0.0086
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5073
	data_grads_norm = 3.1507
	new_data_grads_norm = 4.5161
	old_data_grads_norm = 4.3398
	sim_grads_norm_tr = 0.0905
-- Starting training on experience 146 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5634
	data_grads_norm = 4.4316
	new_data_grads_norm = 6.7599
	old_data_grads_norm = 5.3695
	sim_grads_norm_tr = 0.0486
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9158
	data_grads_norm = 4.3885
	new_data_grads_norm = 6.1140
	old_data_grads_norm = 5.9312
	sim_grads_norm_tr = 0.0965
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9110
	data_grads_norm = 4.2991
	new_data_grads_norm = 6.5984
	old_data_grads_norm = 4.7157
	sim_grads_norm_tr = -0.0832
-- Starting training on experience 147 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4364
	data_grads_norm = 3.4571
	new_data_grads_norm = 6.0839
	old_data_grads_norm = 3.9273
	sim_grads_norm_tr = 0.0614
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7174
	data_grads_norm = 3.5831
	new_data_grads_norm = 5.4564
	old_data_grads_norm = 4.0528
	sim_grads_norm_tr = 0.2057
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4578
	data_grads_norm = 2.9140
	new_data_grads_norm = 4.8222
	old_data_grads_norm = 3.8421
	sim_grads_norm_tr = -0.1435
-- Starting training on experience 148 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1772
	data_grads_norm = 4.3935
	new_data_grads_norm = 5.3068
	old_data_grads_norm = 6.2286
	sim_grads_norm_tr = 0.1281
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4986
	data_grads_norm = 2.9346
	new_data_grads_norm = 5.0117
	old_data_grads_norm = 4.6496
	sim_grads_norm_tr = -0.0090
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9918
	data_grads_norm = 3.4993
	new_data_grads_norm = 4.9661
	old_data_grads_norm = 5.1073
	sim_grads_norm_tr = -0.0307
-- Starting training on experience 149 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6895
	data_grads_norm = 2.7959
	new_data_grads_norm = 3.9437
	old_data_grads_norm = 4.2287
	sim_grads_norm_tr = -0.0620
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7007
	data_grads_norm = 3.5017
	new_data_grads_norm = 4.3469
	old_data_grads_norm = 7.1569
	sim_grads_norm_tr = 0.1044
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4942
	data_grads_norm = 3.0600
	new_data_grads_norm = 4.5211
	old_data_grads_norm = 3.7086
	sim_grads_norm_tr = 0.1226
-- Starting training on experience 150 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8150
	data_grads_norm = 4.0748
	new_data_grads_norm = 5.9869
	old_data_grads_norm = 5.3986
	sim_grads_norm_tr = -0.1424
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3016
	data_grads_norm = 4.5684
	new_data_grads_norm = 6.3878
	old_data_grads_norm = 6.1441
	sim_grads_norm_tr = -0.0797
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4412
	data_grads_norm = 5.1999
	new_data_grads_norm = 7.0021
	old_data_grads_norm = 5.4188
	sim_grads_norm_tr = 0.4310
-- Starting training on experience 151 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9203
	data_grads_norm = 3.0011
	new_data_grads_norm = 4.9737
	old_data_grads_norm = 3.6789
	sim_grads_norm_tr = 0.0093
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0361
	data_grads_norm = 3.6614
	new_data_grads_norm = 4.8440
	old_data_grads_norm = 5.0374
	sim_grads_norm_tr = -0.0189
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0819
	data_grads_norm = 3.9125
	new_data_grads_norm = 4.5053
	old_data_grads_norm = 6.2439
	sim_grads_norm_tr = -0.0271
-- Starting training on experience 152 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7381
	data_grads_norm = 3.5997
	new_data_grads_norm = 5.3040
	old_data_grads_norm = 4.8156
	sim_grads_norm_tr = 0.1113
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8649
	data_grads_norm = 3.5902
	new_data_grads_norm = 5.9865
	old_data_grads_norm = 3.9806
	sim_grads_norm_tr = 0.0764
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1880
	data_grads_norm = 3.8081
	new_data_grads_norm = 5.8480
	old_data_grads_norm = 4.8800
	sim_grads_norm_tr = 0.1278
-- Starting training on experience 153 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8920
	data_grads_norm = 4.0193
	new_data_grads_norm = 4.9865
	old_data_grads_norm = 6.4376
	sim_grads_norm_tr = -0.0684
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7345
	data_grads_norm = 4.6333
	new_data_grads_norm = 4.9680
	old_data_grads_norm = 6.7672
	sim_grads_norm_tr = 0.1186
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9195
	data_grads_norm = 3.8958
	new_data_grads_norm = 5.1149
	old_data_grads_norm = 5.2968
	sim_grads_norm_tr = 0.0363
-- Starting training on experience 154 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8792
	data_grads_norm = 3.5403
	new_data_grads_norm = 4.3386
	old_data_grads_norm = 5.8179
	sim_grads_norm_tr = 0.0271
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9217
	data_grads_norm = 3.0712
	new_data_grads_norm = 4.5303
	old_data_grads_norm = 4.4366
	sim_grads_norm_tr = -0.0503
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6693
	data_grads_norm = 3.2201
	new_data_grads_norm = 4.0073
	old_data_grads_norm = 4.6776
	sim_grads_norm_tr = -0.0551
-- Starting training on experience 155 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3860
	data_grads_norm = 3.6529
	new_data_grads_norm = 4.1350
	old_data_grads_norm = 6.7298
	sim_grads_norm_tr = -0.0236
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0226
	data_grads_norm = 3.7592
	new_data_grads_norm = 4.5246
	old_data_grads_norm = 5.1727
	sim_grads_norm_tr = 0.0902
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9418
	data_grads_norm = 4.4396
	new_data_grads_norm = 5.7272
	old_data_grads_norm = 6.0676
	sim_grads_norm_tr = 0.0874
-- Starting training on experience 156 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5003
	data_grads_norm = 5.2857
	new_data_grads_norm = 6.4276
	old_data_grads_norm = 7.9924
	sim_grads_norm_tr = 0.1604
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9495
	data_grads_norm = 4.0207
	new_data_grads_norm = 6.3737
	old_data_grads_norm = 5.3818
	sim_grads_norm_tr = -0.0542
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7996
	data_grads_norm = 4.4665
	new_data_grads_norm = 6.1104
	old_data_grads_norm = 5.4985
	sim_grads_norm_tr = 0.1697
-- Starting training on experience 157 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5669
	data_grads_norm = 3.6497
	new_data_grads_norm = 4.5458
	old_data_grads_norm = 5.8766
	sim_grads_norm_tr = -0.0146
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6469
	data_grads_norm = 3.5013
	new_data_grads_norm = 5.4848
	old_data_grads_norm = 4.7700
	sim_grads_norm_tr = -0.0795
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8123
	data_grads_norm = 4.2351
	new_data_grads_norm = 5.7916
	old_data_grads_norm = 5.5227
	sim_grads_norm_tr = 0.1654
-- Starting training on experience 158 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5014
	data_grads_norm = 4.2047
	new_data_grads_norm = 5.3507
	old_data_grads_norm = 6.0242
	sim_grads_norm_tr = 0.1087
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1155
	data_grads_norm = 4.2554
	new_data_grads_norm = 5.1580
	old_data_grads_norm = 5.4826
	sim_grads_norm_tr = 0.2093
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8243
	data_grads_norm = 3.3316
	new_data_grads_norm = 5.1558
	old_data_grads_norm = 4.3333
	sim_grads_norm_tr = -0.1075
-- Starting training on experience 159 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8496
	data_grads_norm = 4.0423
	new_data_grads_norm = 5.8066
	old_data_grads_norm = 5.7562
	sim_grads_norm_tr = 0.0119
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9851
	data_grads_norm = 3.5108
	new_data_grads_norm = 4.9402
	old_data_grads_norm = 4.6156
	sim_grads_norm_tr = -0.0004
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1830
	data_grads_norm = 3.9342
	new_data_grads_norm = 5.6643
	old_data_grads_norm = 5.1939
	sim_grads_norm_tr = 0.0141
-- Starting training on experience 160 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2017
	data_grads_norm = 4.1705
	new_data_grads_norm = 5.7938
	old_data_grads_norm = 5.8715
	sim_grads_norm_tr = -0.0485
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1912
	data_grads_norm = 4.2122
	new_data_grads_norm = 5.8058
	old_data_grads_norm = 5.7191
	sim_grads_norm_tr = -0.0196
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9025
	data_grads_norm = 3.6527
	new_data_grads_norm = 5.9660
	old_data_grads_norm = 3.7810
	sim_grads_norm_tr = 0.1497
-- Starting training on experience 161 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1111
	data_grads_norm = 3.7601
	new_data_grads_norm = 5.1229
	old_data_grads_norm = 4.4594
	sim_grads_norm_tr = 0.0872
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6810
	data_grads_norm = 3.3783
	new_data_grads_norm = 5.4383
	old_data_grads_norm = 3.2499
	sim_grads_norm_tr = 0.0280
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1219
	data_grads_norm = 4.0678
	new_data_grads_norm = 5.5291
	old_data_grads_norm = 5.0988
	sim_grads_norm_tr = 0.0431
-- Starting training on experience 162 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4977
	data_grads_norm = 3.3540
	new_data_grads_norm = 4.6898
	old_data_grads_norm = 5.6928
	sim_grads_norm_tr = -0.0129
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6156
	data_grads_norm = 3.5629
	new_data_grads_norm = 5.1697
	old_data_grads_norm = 4.6317
	sim_grads_norm_tr = 0.1313
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6251
	data_grads_norm = 3.5230
	new_data_grads_norm = 4.2311
	old_data_grads_norm = 7.0542
	sim_grads_norm_tr = -0.0700
-- Starting training on experience 163 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2382
	data_grads_norm = 4.3395
	new_data_grads_norm = 5.7624
	old_data_grads_norm = 5.8084
	sim_grads_norm_tr = 0.0513
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1389
	data_grads_norm = 3.9081
	new_data_grads_norm = 5.0992
	old_data_grads_norm = 5.9936
	sim_grads_norm_tr = 0.0428
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6345
	data_grads_norm = 3.0977
	new_data_grads_norm = 5.1863
	old_data_grads_norm = 3.5259
	sim_grads_norm_tr = -0.0197
-- Starting training on experience 164 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9452
	data_grads_norm = 3.5244
	new_data_grads_norm = 5.0906
	old_data_grads_norm = 5.6520
	sim_grads_norm_tr = -0.0581
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1083
	data_grads_norm = 3.5308
	new_data_grads_norm = 4.9048
	old_data_grads_norm = 5.7252
	sim_grads_norm_tr = 0.0043
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9010
	data_grads_norm = 3.6731
	new_data_grads_norm = 5.5120
	old_data_grads_norm = 4.9062
	sim_grads_norm_tr = 0.0507
-- Starting training on experience 165 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4798
	data_grads_norm = 3.4726
	new_data_grads_norm = 5.1417
	old_data_grads_norm = 4.8496
	sim_grads_norm_tr = 0.0395
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7610
	data_grads_norm = 3.3988
	new_data_grads_norm = 5.3781
	old_data_grads_norm = 3.9320
	sim_grads_norm_tr = 0.0845
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8471
	data_grads_norm = 3.7834
	new_data_grads_norm = 5.5213
	old_data_grads_norm = 5.5412
	sim_grads_norm_tr = 0.0028
-- Starting training on experience 166 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1235
	data_grads_norm = 4.1158
	new_data_grads_norm = 6.9186
	old_data_grads_norm = 4.6341
	sim_grads_norm_tr = -0.1258
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8673
	data_grads_norm = 3.9349
	new_data_grads_norm = 7.0162
	old_data_grads_norm = 4.4689
	sim_grads_norm_tr = -0.0615
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9300
	data_grads_norm = 3.8429
	new_data_grads_norm = 6.4105
	old_data_grads_norm = 5.0314
	sim_grads_norm_tr = 0.0659
-- Starting training on experience 167 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9416
	data_grads_norm = 4.1335
	new_data_grads_norm = 5.9593
	old_data_grads_norm = 4.6042
	sim_grads_norm_tr = 0.1444
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1829
	data_grads_norm = 3.9975
	new_data_grads_norm = 5.7023
	old_data_grads_norm = 4.9290
	sim_grads_norm_tr = 0.1682
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9521
	data_grads_norm = 3.6847
	new_data_grads_norm = 5.7777
	old_data_grads_norm = 4.9545
	sim_grads_norm_tr = -0.0389
-- Starting training on experience 168 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0013
	data_grads_norm = 3.6594
	new_data_grads_norm = 6.0352
	old_data_grads_norm = 3.8787
	sim_grads_norm_tr = 0.0229
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3327
	data_grads_norm = 4.7254
	new_data_grads_norm = 6.0883
	old_data_grads_norm = 6.4212
	sim_grads_norm_tr = -0.0049
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1838
	data_grads_norm = 3.9911
	new_data_grads_norm = 6.3165
	old_data_grads_norm = 4.1722
	sim_grads_norm_tr = 0.0147
-- Starting training on experience 169 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0368
	data_grads_norm = 3.9381
	new_data_grads_norm = 5.9362
	old_data_grads_norm = 4.2282
	sim_grads_norm_tr = 0.2583
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6876
	data_grads_norm = 3.3795
	new_data_grads_norm = 4.8989
	old_data_grads_norm = 5.1897
	sim_grads_norm_tr = 0.0048
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6326
	data_grads_norm = 3.5923
	new_data_grads_norm = 5.3183
	old_data_grads_norm = 6.0994
	sim_grads_norm_tr = -0.0251
-- Starting training on experience 170 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9261
	data_grads_norm = 3.8474
	new_data_grads_norm = 5.6692
	old_data_grads_norm = 4.7187
	sim_grads_norm_tr = 0.0656
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8820
	data_grads_norm = 3.9154
	new_data_grads_norm = 5.1641
	old_data_grads_norm = 4.8932
	sim_grads_norm_tr = 0.0670
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8274
	data_grads_norm = 4.3676
	new_data_grads_norm = 5.8992
	old_data_grads_norm = 5.0494
	sim_grads_norm_tr = 0.0757
-- Starting training on experience 171 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7275
	data_grads_norm = 4.0277
	new_data_grads_norm = 5.8289
	old_data_grads_norm = 6.0684
	sim_grads_norm_tr = 0.0414
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4570
	data_grads_norm = 3.7048
	new_data_grads_norm = 4.6821
	old_data_grads_norm = 5.2942
	sim_grads_norm_tr = 0.0252
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5796
	data_grads_norm = 3.7517
	new_data_grads_norm = 5.1319
	old_data_grads_norm = 5.2098
	sim_grads_norm_tr = 0.0553
-- Starting training on experience 172 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1728
	data_grads_norm = 4.6071
	new_data_grads_norm = 6.2265
	old_data_grads_norm = 5.9459
	sim_grads_norm_tr = 0.1191
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5987
	data_grads_norm = 3.8444
	new_data_grads_norm = 6.1771
	old_data_grads_norm = 4.3011
	sim_grads_norm_tr = -0.0746
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3422
	data_grads_norm = 3.8886
	new_data_grads_norm = 6.8753
	old_data_grads_norm = 3.7956
	sim_grads_norm_tr = 0.0776
-- Starting training on experience 173 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8093
	data_grads_norm = 4.1670
	new_data_grads_norm = 6.6093
	old_data_grads_norm = 4.9330
	sim_grads_norm_tr = 0.0593
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8777
	data_grads_norm = 4.2146
	new_data_grads_norm = 6.5044
	old_data_grads_norm = 5.5736
	sim_grads_norm_tr = -0.0842
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8849
	data_grads_norm = 4.2335
	new_data_grads_norm = 7.1982
	old_data_grads_norm = 4.4710
	sim_grads_norm_tr = 0.0153
-- Starting training on experience 174 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4336
	data_grads_norm = 4.4614
	new_data_grads_norm = 6.1039
	old_data_grads_norm = 6.2588
	sim_grads_norm_tr = 0.0731
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3141
	data_grads_norm = 4.3134
	new_data_grads_norm = 5.5881
	old_data_grads_norm = 6.6396
	sim_grads_norm_tr = -0.0897
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2063
	data_grads_norm = 3.5672
	new_data_grads_norm = 5.8694
	old_data_grads_norm = 4.7076
	sim_grads_norm_tr = -0.0053
-- Starting training on experience 175 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0382
	data_grads_norm = 5.4085
	new_data_grads_norm = 6.8893
	old_data_grads_norm = 6.6341
	sim_grads_norm_tr = 0.2003
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9911
	data_grads_norm = 5.0901
	new_data_grads_norm = 6.8399
	old_data_grads_norm = 5.8624
	sim_grads_norm_tr = 0.1327
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1066
	data_grads_norm = 4.8226
	new_data_grads_norm = 6.6157
	old_data_grads_norm = 5.4421
	sim_grads_norm_tr = 0.2097
-- Starting training on experience 176 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7570
	data_grads_norm = 3.3621
	new_data_grads_norm = 5.3664
	old_data_grads_norm = 4.2629
	sim_grads_norm_tr = -0.0698
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0151
	data_grads_norm = 3.5371
	new_data_grads_norm = 5.3833
	old_data_grads_norm = 4.5185
	sim_grads_norm_tr = 0.1321
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8743
	data_grads_norm = 3.7464
	new_data_grads_norm = 5.2272
	old_data_grads_norm = 4.4606
	sim_grads_norm_tr = 0.0501
-- Starting training on experience 177 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9385
	data_grads_norm = 3.0966
	new_data_grads_norm = 4.8644
	old_data_grads_norm = 3.8599
	sim_grads_norm_tr = 0.0406
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8984
	data_grads_norm = 3.6855
	new_data_grads_norm = 4.7824
	old_data_grads_norm = 5.0794
	sim_grads_norm_tr = 0.1923
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5932
	data_grads_norm = 2.9797
	new_data_grads_norm = 4.4939
	old_data_grads_norm = 4.5697
	sim_grads_norm_tr = -0.0464
-- Starting training on experience 178 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4531
	data_grads_norm = 3.2491
	new_data_grads_norm = 4.7748
	old_data_grads_norm = 3.6488
	sim_grads_norm_tr = -0.0733
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7630
	data_grads_norm = 3.7506
	new_data_grads_norm = 5.4753
	old_data_grads_norm = 5.3684
	sim_grads_norm_tr = -0.0469
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3940
	data_grads_norm = 3.4561
	new_data_grads_norm = 5.2906
	old_data_grads_norm = 3.9990
	sim_grads_norm_tr = 0.0984
-- Starting training on experience 179 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9289
	data_grads_norm = 3.5906
	new_data_grads_norm = 4.4038
	old_data_grads_norm = 6.9737
	sim_grads_norm_tr = -0.0264
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7429
	data_grads_norm = 3.5075
	new_data_grads_norm = 4.9526
	old_data_grads_norm = 4.5972
	sim_grads_norm_tr = 0.0445
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8223
	data_grads_norm = 4.0185
	new_data_grads_norm = 4.6292
	old_data_grads_norm = 6.7489
	sim_grads_norm_tr = 0.0304
-- Starting training on experience 180 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1053
	data_grads_norm = 4.2662
	new_data_grads_norm = 6.2267
	old_data_grads_norm = 4.7032
	sim_grads_norm_tr = 0.1732
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7964
	data_grads_norm = 3.9560
	new_data_grads_norm = 6.1227
	old_data_grads_norm = 5.2442
	sim_grads_norm_tr = -0.0512
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8743
	data_grads_norm = 3.8328
	new_data_grads_norm = 5.8985
	old_data_grads_norm = 5.5233
	sim_grads_norm_tr = -0.0064
-- Starting training on experience 181 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3290
	data_grads_norm = 3.6869
	new_data_grads_norm = 5.3257
	old_data_grads_norm = 5.5392
	sim_grads_norm_tr = 0.0046
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0331
	data_grads_norm = 4.2057
	new_data_grads_norm = 6.0220
	old_data_grads_norm = 6.5336
	sim_grads_norm_tr = 0.0787
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7434
	data_grads_norm = 3.5830
	new_data_grads_norm = 5.0603
	old_data_grads_norm = 5.3389
	sim_grads_norm_tr = 0.1490
-- Starting training on experience 182 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9311
	data_grads_norm = 3.8906
	new_data_grads_norm = 5.8744
	old_data_grads_norm = 5.2137
	sim_grads_norm_tr = 0.0734
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9677
	data_grads_norm = 3.6724
	new_data_grads_norm = 6.0408
	old_data_grads_norm = 4.1637
	sim_grads_norm_tr = 0.0182
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8307
	data_grads_norm = 3.8135
	new_data_grads_norm = 5.7708
	old_data_grads_norm = 5.7878
	sim_grads_norm_tr = -0.1222
-- Starting training on experience 183 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1488
	data_grads_norm = 4.2002
	new_data_grads_norm = 6.6088
	old_data_grads_norm = 4.7178
	sim_grads_norm_tr = 0.0179
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3764
	data_grads_norm = 5.2923
	new_data_grads_norm = 6.5110
	old_data_grads_norm = 7.2010
	sim_grads_norm_tr = 0.1085
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3430
	data_grads_norm = 4.0718
	new_data_grads_norm = 5.9168
	old_data_grads_norm = 4.7996
	sim_grads_norm_tr = 0.0463
-- Starting training on experience 184 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9366
	data_grads_norm = 3.5740
	new_data_grads_norm = 4.2462
	old_data_grads_norm = 5.9116
	sim_grads_norm_tr = 0.1422
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7062
	data_grads_norm = 2.8902
	new_data_grads_norm = 4.1165
	old_data_grads_norm = 5.6413
	sim_grads_norm_tr = -0.1205
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4823
	data_grads_norm = 2.9788
	new_data_grads_norm = 5.0823
	old_data_grads_norm = 3.4252
	sim_grads_norm_tr = -0.0008
-- Starting training on experience 185 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9590
	data_grads_norm = 3.9855
	new_data_grads_norm = 6.2410
	old_data_grads_norm = 4.2779
	sim_grads_norm_tr = -0.0129
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6487
	data_grads_norm = 4.8199
	new_data_grads_norm = 6.4483
	old_data_grads_norm = 6.4347
	sim_grads_norm_tr = 0.0724
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9795
	data_grads_norm = 3.5803
	new_data_grads_norm = 5.3391
	old_data_grads_norm = 4.9785
	sim_grads_norm_tr = 0.0223
-- Starting training on experience 186 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7397
	data_grads_norm = 3.4174
	new_data_grads_norm = 4.9492
	old_data_grads_norm = 5.1852
	sim_grads_norm_tr = -0.0718
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6751
	data_grads_norm = 4.1489
	new_data_grads_norm = 5.3498
	old_data_grads_norm = 6.1405
	sim_grads_norm_tr = 0.0897
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5704
	data_grads_norm = 3.7729
	new_data_grads_norm = 5.5159
	old_data_grads_norm = 5.0979
	sim_grads_norm_tr = -0.0276
-- Starting training on experience 187 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7438
	data_grads_norm = 3.6043
	new_data_grads_norm = 5.9183
	old_data_grads_norm = 3.5059
	sim_grads_norm_tr = 0.0172
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7635
	data_grads_norm = 3.6325
	new_data_grads_norm = 5.7788
	old_data_grads_norm = 4.8048
	sim_grads_norm_tr = -0.0737
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0564
	data_grads_norm = 4.4108
	new_data_grads_norm = 6.8930
	old_data_grads_norm = 4.7535
	sim_grads_norm_tr = 0.1387
-- Starting training on experience 188 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1697
	data_grads_norm = 5.3835
	new_data_grads_norm = 7.7167
	old_data_grads_norm = 5.6925
	sim_grads_norm_tr = 0.1545
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6866
	data_grads_norm = 3.9494
	new_data_grads_norm = 7.2492
	old_data_grads_norm = 4.6685
	sim_grads_norm_tr = -0.0602
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2455
	data_grads_norm = 5.0146
	new_data_grads_norm = 7.3377
	old_data_grads_norm = 6.4472
	sim_grads_norm_tr = 0.0400
-- Starting training on experience 189 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0871
	data_grads_norm = 3.9897
	new_data_grads_norm = 5.0624
	old_data_grads_norm = 5.4489
	sim_grads_norm_tr = 0.2342
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4755
	data_grads_norm = 3.0776
	new_data_grads_norm = 4.9601
	old_data_grads_norm = 4.1133
	sim_grads_norm_tr = -0.1379
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9959
	data_grads_norm = 4.0271
	new_data_grads_norm = 5.2181
	old_data_grads_norm = 5.9507
	sim_grads_norm_tr = 0.0336
-- Starting training on experience 190 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5930
	data_grads_norm = 3.6056
	new_data_grads_norm = 4.9866
	old_data_grads_norm = 4.0634
	sim_grads_norm_tr = 0.1080
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5745
	data_grads_norm = 3.0259
	new_data_grads_norm = 4.0564
	old_data_grads_norm = 3.8962
	sim_grads_norm_tr = 0.0910
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7161
	data_grads_norm = 3.4900
	new_data_grads_norm = 4.5262
	old_data_grads_norm = 5.6421
	sim_grads_norm_tr = -0.0703
-- Starting training on experience 191 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7350
	data_grads_norm = 3.6202
	new_data_grads_norm = 6.2431
	old_data_grads_norm = 3.4040
	sim_grads_norm_tr = -0.0369
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4068
	data_grads_norm = 4.4037
	new_data_grads_norm = 5.5421
	old_data_grads_norm = 6.7291
	sim_grads_norm_tr = -0.0542
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2141
	data_grads_norm = 4.4597
	new_data_grads_norm = 5.9842
	old_data_grads_norm = 6.6798
	sim_grads_norm_tr = 0.0105
-- Starting training on experience 192 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6504
	data_grads_norm = 4.7281
	new_data_grads_norm = 7.3330
	old_data_grads_norm = 5.2948
	sim_grads_norm_tr = 0.0833
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7354
	data_grads_norm = 4.0309
	new_data_grads_norm = 6.7900
	old_data_grads_norm = 5.3605
	sim_grads_norm_tr = 0.0318
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0536
	data_grads_norm = 4.9310
	new_data_grads_norm = 6.4293
	old_data_grads_norm = 7.9709
	sim_grads_norm_tr = 0.1638
-- Starting training on experience 193 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6088
	data_grads_norm = 2.9187
	new_data_grads_norm = 4.3828
	old_data_grads_norm = 3.6636
	sim_grads_norm_tr = 0.0293
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9826
	data_grads_norm = 3.3024
	new_data_grads_norm = 4.8961
	old_data_grads_norm = 5.1441
	sim_grads_norm_tr = -0.0453
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9455
	data_grads_norm = 3.2723
	new_data_grads_norm = 4.7959
	old_data_grads_norm = 4.3484
	sim_grads_norm_tr = 0.1017
-- Starting training on experience 194 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9325
	data_grads_norm = 3.3633
	new_data_grads_norm = 4.5391
	old_data_grads_norm = 4.5985
	sim_grads_norm_tr = 0.0659
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9751
	data_grads_norm = 3.4383
	new_data_grads_norm = 4.6081
	old_data_grads_norm = 5.4965
	sim_grads_norm_tr = 0.0084
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3785
	data_grads_norm = 4.3890
	new_data_grads_norm = 5.2914
	old_data_grads_norm = 4.9734
	sim_grads_norm_tr = 0.3733
-- Starting training on experience 195 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6800
	data_grads_norm = 3.2359
	new_data_grads_norm = 4.5537
	old_data_grads_norm = 5.2482
	sim_grads_norm_tr = -0.0300
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8840
	data_grads_norm = 3.7902
	new_data_grads_norm = 4.8678
	old_data_grads_norm = 5.4628
	sim_grads_norm_tr = -0.0868
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8448
	data_grads_norm = 3.8678
	new_data_grads_norm = 6.9152
	old_data_grads_norm = 4.2127
	sim_grads_norm_tr = -0.0121
-- Starting training on experience 196 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8834
	data_grads_norm = 3.7826
	new_data_grads_norm = 5.1375
	old_data_grads_norm = 5.6776
	sim_grads_norm_tr = 0.0434
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9004
	data_grads_norm = 3.9325
	new_data_grads_norm = 4.5380
	old_data_grads_norm = 6.8991
	sim_grads_norm_tr = 0.0227
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5698
	data_grads_norm = 3.8719
	new_data_grads_norm = 5.1770
	old_data_grads_norm = 5.8280
	sim_grads_norm_tr = -0.0774
-- Starting training on experience 197 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7741
	data_grads_norm = 3.9620
	new_data_grads_norm = 5.7276
	old_data_grads_norm = 5.3614
	sim_grads_norm_tr = 0.0297
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7834
	data_grads_norm = 3.6287
	new_data_grads_norm = 5.4241
	old_data_grads_norm = 4.9764
	sim_grads_norm_tr = -0.0131
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9897
	data_grads_norm = 4.0360
	new_data_grads_norm = 5.5751
	old_data_grads_norm = 4.9254
	sim_grads_norm_tr = 0.0612
-- Starting training on experience 198 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0015
	data_grads_norm = 4.0896
	new_data_grads_norm = 4.8631
	old_data_grads_norm = 5.9134
	sim_grads_norm_tr = 0.0850
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6549
	data_grads_norm = 4.1547
	new_data_grads_norm = 4.9271
	old_data_grads_norm = 6.6614
	sim_grads_norm_tr = -0.0513
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5686
	data_grads_norm = 3.5488
	new_data_grads_norm = 4.6767
	old_data_grads_norm = 5.0354
	sim_grads_norm_tr = 0.1430
-- Starting training on experience 199 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0029
	data_grads_norm = 4.6160
	new_data_grads_norm = 6.7140
	old_data_grads_norm = 4.6831
	sim_grads_norm_tr = 0.0594
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2284
	data_grads_norm = 4.9908
	new_data_grads_norm = 6.9399
	old_data_grads_norm = 4.9978
	sim_grads_norm_tr = 0.1800
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8024
	data_grads_norm = 4.0143
	new_data_grads_norm = 5.7814
	old_data_grads_norm = 7.6663
	sim_grads_norm_tr = 0.0046
-- Starting training on experience 200 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0739
	data_grads_norm = 5.1517
	new_data_grads_norm = 7.4767
	old_data_grads_norm = 5.7267
	sim_grads_norm_tr = 0.0860
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9324
	data_grads_norm = 5.3988
	new_data_grads_norm = 7.5048
	old_data_grads_norm = 6.7573
	sim_grads_norm_tr = 0.2041
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7783
	data_grads_norm = 3.9585
	new_data_grads_norm = 6.8145
	old_data_grads_norm = 6.5195
	sim_grads_norm_tr = -0.0044
-- Starting training on experience 201 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6254
	data_grads_norm = 3.1882
	new_data_grads_norm = 4.7927
	old_data_grads_norm = 5.0232
	sim_grads_norm_tr = -0.0030
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1279
	data_grads_norm = 4.0515
	new_data_grads_norm = 4.9545
	old_data_grads_norm = 5.4897
	sim_grads_norm_tr = 0.1084
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8058
	data_grads_norm = 3.6993
	new_data_grads_norm = 5.0387
	old_data_grads_norm = 5.5262
	sim_grads_norm_tr = 0.0048
-- Starting training on experience 202 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5868
	data_grads_norm = 4.2563
	new_data_grads_norm = 6.0432
	old_data_grads_norm = 4.4578
	sim_grads_norm_tr = 0.1461
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5707
	data_grads_norm = 3.8603
	new_data_grads_norm = 5.7325
	old_data_grads_norm = 4.8233
	sim_grads_norm_tr = -0.0516
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7989
	data_grads_norm = 4.3141
	new_data_grads_norm = 6.4850
	old_data_grads_norm = 4.5251
	sim_grads_norm_tr = 0.0584
-- Starting training on experience 203 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7463
	data_grads_norm = 4.2085
	new_data_grads_norm = 7.2009
	old_data_grads_norm = 4.9160
	sim_grads_norm_tr = 0.0465
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4882
	data_grads_norm = 5.0559
	new_data_grads_norm = 7.4149
	old_data_grads_norm = 6.0115
	sim_grads_norm_tr = -0.0704
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4953
	data_grads_norm = 5.5150
	new_data_grads_norm = 7.5679
	old_data_grads_norm = 6.0800
	sim_grads_norm_tr = 0.1970
-- Starting training on experience 204 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0058
	data_grads_norm = 4.2332
	new_data_grads_norm = 6.6586
	old_data_grads_norm = 5.1822
	sim_grads_norm_tr = -0.0111
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8498
	data_grads_norm = 4.8690
	new_data_grads_norm = 7.3695
	old_data_grads_norm = 6.1586
	sim_grads_norm_tr = 0.0658
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8286
	data_grads_norm = 4.2353
	new_data_grads_norm = 6.1355
	old_data_grads_norm = 4.1785
	sim_grads_norm_tr = 0.1518
-- Starting training on experience 205 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6115
	data_grads_norm = 3.3623
	new_data_grads_norm = 5.0058
	old_data_grads_norm = 3.8865
	sim_grads_norm_tr = 0.0900
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9921
	data_grads_norm = 4.5994
	new_data_grads_norm = 5.5935
	old_data_grads_norm = 6.3420
	sim_grads_norm_tr = 0.0985
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6688
	data_grads_norm = 3.8803
	new_data_grads_norm = 5.4728
	old_data_grads_norm = 5.3766
	sim_grads_norm_tr = -0.0038
-- Starting training on experience 206 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6229
	data_grads_norm = 3.4952
	new_data_grads_norm = 4.8259
	old_data_grads_norm = 5.7988
	sim_grads_norm_tr = -0.0340
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2817
	data_grads_norm = 4.9018
	new_data_grads_norm = 5.8621
	old_data_grads_norm = 7.4389
	sim_grads_norm_tr = 0.0567
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0392
	data_grads_norm = 4.3143
	new_data_grads_norm = 5.7984
	old_data_grads_norm = 5.2172
	sim_grads_norm_tr = 0.1292
-- Starting training on experience 207 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9597
	data_grads_norm = 3.4916
	new_data_grads_norm = 5.2609
	old_data_grads_norm = 5.1391
	sim_grads_norm_tr = -0.0633
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9502
	data_grads_norm = 4.0239
	new_data_grads_norm = 5.3324
	old_data_grads_norm = 5.2696
	sim_grads_norm_tr = 0.0957
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8292
	data_grads_norm = 3.4335
	new_data_grads_norm = 5.2820
	old_data_grads_norm = 4.5528
	sim_grads_norm_tr = -0.0381
-- Starting training on experience 208 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2154
	data_grads_norm = 4.5010
	new_data_grads_norm = 6.6975
	old_data_grads_norm = 5.3784
	sim_grads_norm_tr = -0.0098
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7280
	data_grads_norm = 5.4966
	new_data_grads_norm = 6.2959
	old_data_grads_norm = 7.0539
	sim_grads_norm_tr = 0.2570
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0275
	data_grads_norm = 4.5388
	new_data_grads_norm = 5.4224
	old_data_grads_norm = 8.1170
	sim_grads_norm_tr = -0.0208
-- Starting training on experience 209 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1174
	data_grads_norm = 4.7691
	new_data_grads_norm = 5.8386
	old_data_grads_norm = 6.2441
	sim_grads_norm_tr = 0.0092
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9541
	data_grads_norm = 4.1595
	new_data_grads_norm = 5.3160
	old_data_grads_norm = 5.9683
	sim_grads_norm_tr = 0.0913
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7836
	data_grads_norm = 3.9609
	new_data_grads_norm = 5.0322
	old_data_grads_norm = 5.7395
	sim_grads_norm_tr = 0.0168
-- Starting training on experience 210 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5907
	data_grads_norm = 3.0837
	new_data_grads_norm = 4.6041
	old_data_grads_norm = 4.3369
	sim_grads_norm_tr = 0.0323
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8613
	data_grads_norm = 4.3540
	new_data_grads_norm = 4.7040
	old_data_grads_norm = 6.5840
	sim_grads_norm_tr = 0.1098
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4482
	data_grads_norm = 3.2151
	new_data_grads_norm = 4.4347
	old_data_grads_norm = 4.6449
	sim_grads_norm_tr = 0.0688
-- Starting training on experience 211 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7113
	data_grads_norm = 3.7898
	new_data_grads_norm = 6.3805
	old_data_grads_norm = 4.5065
	sim_grads_norm_tr = 0.0354
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9000
	data_grads_norm = 4.0744
	new_data_grads_norm = 5.6149
	old_data_grads_norm = 4.5883
	sim_grads_norm_tr = 0.1380
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4911
	data_grads_norm = 3.4243
	new_data_grads_norm = 5.4568
	old_data_grads_norm = 4.4031
	sim_grads_norm_tr = -0.0480
-- Starting training on experience 212 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9429
	data_grads_norm = 4.4019
	new_data_grads_norm = 6.1743
	old_data_grads_norm = 5.7193
	sim_grads_norm_tr = 0.1137
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6000
	data_grads_norm = 3.4770
	new_data_grads_norm = 6.2386
	old_data_grads_norm = 3.9326
	sim_grads_norm_tr = -0.0781
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5915
	data_grads_norm = 4.1931
	new_data_grads_norm = 5.9064
	old_data_grads_norm = 5.4764
	sim_grads_norm_tr = 0.0897
-- Starting training on experience 213 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9338
	data_grads_norm = 4.4043
	new_data_grads_norm = 8.0357
	old_data_grads_norm = 5.9890
	sim_grads_norm_tr = 0.0757
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8028
	data_grads_norm = 3.6897
	new_data_grads_norm = 7.0472
	old_data_grads_norm = 4.8387
	sim_grads_norm_tr = 0.0384
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8759
	data_grads_norm = 4.1445
	new_data_grads_norm = 6.4237
	old_data_grads_norm = 4.6734
	sim_grads_norm_tr = 0.0339
-- Starting training on experience 214 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8192
	data_grads_norm = 3.8868
	new_data_grads_norm = 5.1305
	old_data_grads_norm = 5.0772
	sim_grads_norm_tr = 0.1390
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7650
	data_grads_norm = 3.9071
	new_data_grads_norm = 5.3978
	old_data_grads_norm = 5.1980
	sim_grads_norm_tr = 0.0580
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8538
	data_grads_norm = 3.9700
	new_data_grads_norm = 4.9974
	old_data_grads_norm = 5.9597
	sim_grads_norm_tr = 0.0655
-- Starting training on experience 215 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4652
	data_grads_norm = 3.4214
	new_data_grads_norm = 5.4788
	old_data_grads_norm = 4.5450
	sim_grads_norm_tr = 0.0099
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3583
	data_grads_norm = 3.2095
	new_data_grads_norm = 5.1061
	old_data_grads_norm = 4.4590
	sim_grads_norm_tr = -0.0929
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6434
	data_grads_norm = 4.0975
	new_data_grads_norm = 5.4475
	old_data_grads_norm = 5.0682
	sim_grads_norm_tr = 0.0668
-- Starting training on experience 216 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5774
	data_grads_norm = 3.7163
	new_data_grads_norm = 5.1944
	old_data_grads_norm = 5.6867
	sim_grads_norm_tr = -0.0993
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9758
	data_grads_norm = 3.8587
	new_data_grads_norm = 4.8771
	old_data_grads_norm = 5.4056
	sim_grads_norm_tr = 0.0863
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9637
	data_grads_norm = 4.2046
	new_data_grads_norm = 5.5610
	old_data_grads_norm = 5.7590
	sim_grads_norm_tr = -0.0109
-- Starting training on experience 217 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1427
	data_grads_norm = 4.3423
	new_data_grads_norm = 6.0997
	old_data_grads_norm = 5.7467
	sim_grads_norm_tr = 0.0300
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1338
	data_grads_norm = 4.1063
	new_data_grads_norm = 5.7151
	old_data_grads_norm = 5.8097
	sim_grads_norm_tr = 0.0195
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4679
	data_grads_norm = 4.9373
	new_data_grads_norm = 6.5747
	old_data_grads_norm = 5.8792
	sim_grads_norm_tr = -0.0333
-- Starting training on experience 218 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9149
	data_grads_norm = 4.3933
	new_data_grads_norm = 6.5767
	old_data_grads_norm = 4.7572
	sim_grads_norm_tr = 0.1043
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8295
	data_grads_norm = 4.2009
	new_data_grads_norm = 6.1880
	old_data_grads_norm = 5.7265
	sim_grads_norm_tr = 0.0053
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5316
	data_grads_norm = 3.4653
	new_data_grads_norm = 5.7924
	old_data_grads_norm = 3.6019
	sim_grads_norm_tr = 0.0108
-- Starting training on experience 219 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4901
	data_grads_norm = 2.9686
	new_data_grads_norm = 3.7563
	old_data_grads_norm = 6.2361
	sim_grads_norm_tr = -0.1058
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8106
	data_grads_norm = 3.5624
	new_data_grads_norm = 5.2303
	old_data_grads_norm = 4.4137
	sim_grads_norm_tr = 0.1178
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6293
	data_grads_norm = 3.5043
	new_data_grads_norm = 4.1922
	old_data_grads_norm = 5.3498
	sim_grads_norm_tr = 0.0561
-- Starting training on experience 220 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4649
	data_grads_norm = 3.7009
	new_data_grads_norm = 5.6070
	old_data_grads_norm = 6.2266
	sim_grads_norm_tr = 0.1208
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4045
	data_grads_norm = 2.9088
	new_data_grads_norm = 4.6010
	old_data_grads_norm = 4.4491
	sim_grads_norm_tr = -0.0569
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8199
	data_grads_norm = 3.6664
	new_data_grads_norm = 5.3277
	old_data_grads_norm = 5.1029
	sim_grads_norm_tr = -0.0438
-- Starting training on experience 221 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1127
	data_grads_norm = 4.5766
	new_data_grads_norm = 6.4979
	old_data_grads_norm = 5.3026
	sim_grads_norm_tr = 0.0960
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7597
	data_grads_norm = 3.9465
	new_data_grads_norm = 5.6368
	old_data_grads_norm = 5.7221
	sim_grads_norm_tr = 0.0799
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7400
	data_grads_norm = 3.5754
	new_data_grads_norm = 5.1961
	old_data_grads_norm = 5.4841
	sim_grads_norm_tr = -0.0017
-- Starting training on experience 222 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5195
	data_grads_norm = 3.3081
	new_data_grads_norm = 4.5594
	old_data_grads_norm = 5.4712
	sim_grads_norm_tr = -0.0402
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9611
	data_grads_norm = 4.2103
	new_data_grads_norm = 5.1261
	old_data_grads_norm = 5.9442
	sim_grads_norm_tr = 0.1609
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2208
	data_grads_norm = 3.2752
	new_data_grads_norm = 4.6664
	old_data_grads_norm = 5.0037
	sim_grads_norm_tr = 0.0051
-- Starting training on experience 223 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5639
	data_grads_norm = 3.2736
	new_data_grads_norm = 3.8673
	old_data_grads_norm = 6.0221
	sim_grads_norm_tr = -0.0658
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7263
	data_grads_norm = 3.6006
	new_data_grads_norm = 4.5562
	old_data_grads_norm = 6.3364
	sim_grads_norm_tr = -0.0001
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1367
	data_grads_norm = 4.1886
	new_data_grads_norm = 5.8962
	old_data_grads_norm = 4.8438
	sim_grads_norm_tr = 0.0494
-- Starting training on experience 224 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8103
	data_grads_norm = 4.8444
	new_data_grads_norm = 7.1126
	old_data_grads_norm = 6.4206
	sim_grads_norm_tr = 0.0429
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8119
	data_grads_norm = 4.0057
	new_data_grads_norm = 6.5712
	old_data_grads_norm = 4.1362
	sim_grads_norm_tr = 0.0911
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6159
	data_grads_norm = 4.6319
	new_data_grads_norm = 6.2897
	old_data_grads_norm = 5.8131
	sim_grads_norm_tr = 0.2371
-- Starting training on experience 225 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3069
	data_grads_norm = 4.6906
	new_data_grads_norm = 6.3383
	old_data_grads_norm = 5.9439
	sim_grads_norm_tr = 0.0619
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1292
	data_grads_norm = 4.2065
	new_data_grads_norm = 6.0777
	old_data_grads_norm = 5.9622
	sim_grads_norm_tr = 0.0692
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4066
	data_grads_norm = 4.2269
	new_data_grads_norm = 6.0265
	old_data_grads_norm = 5.4263
	sim_grads_norm_tr = 0.0116
-- Starting training on experience 226 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7044
	data_grads_norm = 3.8403
	new_data_grads_norm = 5.1782
	old_data_grads_norm = 5.1377
	sim_grads_norm_tr = 0.0837
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8086
	data_grads_norm = 3.4959
	new_data_grads_norm = 5.6265
	old_data_grads_norm = 4.3987
	sim_grads_norm_tr = 0.0832
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7076
	data_grads_norm = 3.3230
	new_data_grads_norm = 5.2092
	old_data_grads_norm = 4.4316
	sim_grads_norm_tr = 0.0560
-- Starting training on experience 227 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9500
	data_grads_norm = 4.3368
	new_data_grads_norm = 6.2277
	old_data_grads_norm = 5.0439
	sim_grads_norm_tr = 0.1080
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2009
	data_grads_norm = 2.9468
	new_data_grads_norm = 5.1044
	old_data_grads_norm = 4.4208
	sim_grads_norm_tr = -0.1670
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5416
	data_grads_norm = 3.6607
	new_data_grads_norm = 6.0672
	old_data_grads_norm = 4.3181
	sim_grads_norm_tr = 0.0551
-- Starting training on experience 228 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7529
	data_grads_norm = 3.7679
	new_data_grads_norm = 5.2420
	old_data_grads_norm = 6.1354
	sim_grads_norm_tr = -0.0762
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0793
	data_grads_norm = 4.8467
	new_data_grads_norm = 7.6459
	old_data_grads_norm = 5.2326
	sim_grads_norm_tr = 0.0826
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6725
	data_grads_norm = 4.1084
	new_data_grads_norm = 6.0312
	old_data_grads_norm = 5.3467
	sim_grads_norm_tr = 0.1287
-- Starting training on experience 229 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7844
	data_grads_norm = 3.5615
	new_data_grads_norm = 6.0378
	old_data_grads_norm = 4.7892
	sim_grads_norm_tr = -0.0544
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1257
	data_grads_norm = 4.6439
	new_data_grads_norm = 5.9243
	old_data_grads_norm = 7.1356
	sim_grads_norm_tr = 0.0314
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2804
	data_grads_norm = 4.4927
	new_data_grads_norm = 6.4101
	old_data_grads_norm = 5.2449
	sim_grads_norm_tr = -0.0189
-- Starting training on experience 230 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9916
	data_grads_norm = 3.8262
	new_data_grads_norm = 6.1530
	old_data_grads_norm = 4.6372
	sim_grads_norm_tr = -0.0456
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0301
	data_grads_norm = 3.8458
	new_data_grads_norm = 6.9898
	old_data_grads_norm = 4.7643
	sim_grads_norm_tr = 0.0063
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2492
	data_grads_norm = 4.5835
	new_data_grads_norm = 7.2641
	old_data_grads_norm = 5.5598
	sim_grads_norm_tr = 0.0790
-- Starting training on experience 231 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2981
	data_grads_norm = 4.1078
	new_data_grads_norm = 6.8314
	old_data_grads_norm = 4.3449
	sim_grads_norm_tr = 0.0811
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8127
	data_grads_norm = 5.2607
	new_data_grads_norm = 6.4658
	old_data_grads_norm = 7.6343
	sim_grads_norm_tr = -0.0661
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3342
	data_grads_norm = 4.6265
	new_data_grads_norm = 6.7159
	old_data_grads_norm = 6.0442
	sim_grads_norm_tr = 0.0270
-- Starting training on experience 232 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9406
	data_grads_norm = 4.5247
	new_data_grads_norm = 7.9706
	old_data_grads_norm = 5.2842
	sim_grads_norm_tr = -0.0154
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0991
	data_grads_norm = 4.7894
	new_data_grads_norm = 7.7633
	old_data_grads_norm = 5.4938
	sim_grads_norm_tr = 0.0057
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0112
	data_grads_norm = 5.0356
	new_data_grads_norm = 7.8615
	old_data_grads_norm = 5.4596
	sim_grads_norm_tr = 0.1081
-- Starting training on experience 233 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4365
	data_grads_norm = 3.4928
	new_data_grads_norm = 5.7444
	old_data_grads_norm = 4.2346
	sim_grads_norm_tr = 0.0627
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8673
	data_grads_norm = 4.0288
	new_data_grads_norm = 6.2544
	old_data_grads_norm = 5.9956
	sim_grads_norm_tr = -0.0104
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1228
	data_grads_norm = 4.4708
	new_data_grads_norm = 5.8249
	old_data_grads_norm = 6.0520
	sim_grads_norm_tr = 0.0067
-- Starting training on experience 234 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3676
	data_grads_norm = 4.9952
	new_data_grads_norm = 5.3985
	old_data_grads_norm = 7.9278
	sim_grads_norm_tr = 0.1060
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8691
	data_grads_norm = 4.3122
	new_data_grads_norm = 6.0597
	old_data_grads_norm = 5.5989
	sim_grads_norm_tr = 0.0361
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0288
	data_grads_norm = 4.3454
	new_data_grads_norm = 6.1694
	old_data_grads_norm = 4.7714
	sim_grads_norm_tr = 0.1302
-- Starting training on experience 235 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3230
	data_grads_norm = 5.2988
	new_data_grads_norm = 7.8145
	old_data_grads_norm = 6.1669
	sim_grads_norm_tr = 0.1281
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5088
	data_grads_norm = 3.2069
	new_data_grads_norm = 5.8370
	old_data_grads_norm = 3.3619
	sim_grads_norm_tr = -0.1039
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6261
	data_grads_norm = 3.7049
	new_data_grads_norm = 6.0777
	old_data_grads_norm = 4.0514
	sim_grads_norm_tr = 0.0012
-- Starting training on experience 236 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8109
	data_grads_norm = 3.9063
	new_data_grads_norm = 5.8705
	old_data_grads_norm = 5.1256
	sim_grads_norm_tr = -0.0688
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7208
	data_grads_norm = 4.6684
	new_data_grads_norm = 6.8578
	old_data_grads_norm = 5.1483
	sim_grads_norm_tr = 0.2192
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9409
	data_grads_norm = 4.5710
	new_data_grads_norm = 5.8717
	old_data_grads_norm = 6.4793
	sim_grads_norm_tr = -0.0703
-- Starting training on experience 237 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
-- >> End of training phase << --
-- >> Start of eval phase << --
-- Starting eval on experience 0 (Task 0) from test stream --
> Eval on experience 0 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp000 = 1.8800
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.4320
	mb_index = 952
	time = 207.5469
-- Starting eval on experience 1 (Task 0) from test stream --
> Eval on experience 1 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp001 = 1.3410
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.6240
-- Starting eval on experience 2 (Task 0) from test stream --
> Eval on experience 2 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp002 = 2.3317
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.2800
-- Starting eval on experience 3 (Task 0) from test stream --
> Eval on experience 3 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp003 = 1.7991
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.4400
-- >> End of eval phase << --
	CumulativeAccuracy/eval_phase/test_stream/Exp000 = 0.7380
	CumulativeAccuracy/eval_phase/test_stream/Exp001 = 0.6300
	CumulativeAccuracy/eval_phase/test_stream/Exp002 = 0.4880
	CumulativeAccuracy/eval_phase/test_stream/Exp003 = 0.4440
	Loss_Stream/eval_phase/test_stream/Task000 = 1.8380
	Top1_Acc_Stream/eval_phase/test_stream/Task000 = 0.4440
-- >> Start of training phase << --
-- Starting training on experience 0 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1579
	data_grads_norm = 4.1253
	new_data_grads_norm = 6.3517
	old_data_grads_norm = 4.7694
	sim_grads_norm_tr = -0.0051
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4604
	data_grads_norm = 4.1980
	new_data_grads_norm = 6.2022
	old_data_grads_norm = 4.9092
	sim_grads_norm_tr = 0.0033
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4023
	data_grads_norm = 3.9935
	new_data_grads_norm = 5.7998
	old_data_grads_norm = 4.9821
	sim_grads_norm_tr = -0.0487
-- Starting training on experience 1 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7022
	data_grads_norm = 4.1041
	new_data_grads_norm = 6.5905
	old_data_grads_norm = 5.6221
	sim_grads_norm_tr = -0.0158
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1412
	data_grads_norm = 4.2485
	new_data_grads_norm = 6.6563
	old_data_grads_norm = 5.3744
	sim_grads_norm_tr = 0.0444
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0412
	data_grads_norm = 4.5113
	new_data_grads_norm = 6.5882
	old_data_grads_norm = 4.8742
	sim_grads_norm_tr = -0.0525
-- Starting training on experience 2 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4250
	data_grads_norm = 4.7116
	new_data_grads_norm = 6.1409
	old_data_grads_norm = 6.2923
	sim_grads_norm_tr = 0.0275
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8271
	data_grads_norm = 3.7146
	new_data_grads_norm = 6.5758
	old_data_grads_norm = 3.4450
	sim_grads_norm_tr = 0.0011
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4768
	data_grads_norm = 4.7258
	new_data_grads_norm = 6.3466
	old_data_grads_norm = 7.3506
	sim_grads_norm_tr = 0.0248
-- Starting training on experience 3 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7968
	data_grads_norm = 5.2131
	new_data_grads_norm = 5.7638
	old_data_grads_norm = 8.0663
	sim_grads_norm_tr = 0.1000
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1215
	data_grads_norm = 3.9685
	new_data_grads_norm = 6.1198
	old_data_grads_norm = 4.3494
	sim_grads_norm_tr = 0.0178
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6081
	data_grads_norm = 4.6231
	new_data_grads_norm = 6.2151
	old_data_grads_norm = 6.6668
	sim_grads_norm_tr = 0.0089
-- Starting training on experience 4 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5636
	data_grads_norm = 4.1491
	new_data_grads_norm = 5.1393
	old_data_grads_norm = 6.4305
	sim_grads_norm_tr = -0.0186
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4548
	data_grads_norm = 4.4988
	new_data_grads_norm = 5.5458
	old_data_grads_norm = 5.5289
	sim_grads_norm_tr = 0.0655
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7346
	data_grads_norm = 3.2685
	new_data_grads_norm = 5.1048
	old_data_grads_norm = 3.2512
	sim_grads_norm_tr = -0.1013
-- Starting training on experience 5 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1500
	data_grads_norm = 4.6218
	new_data_grads_norm = 5.8016
	old_data_grads_norm = 6.1293
	sim_grads_norm_tr = -0.0167
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2010
	data_grads_norm = 4.2807
	new_data_grads_norm = 5.5107
	old_data_grads_norm = 6.3155
	sim_grads_norm_tr = 0.0392
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8038
	data_grads_norm = 4.6129
	new_data_grads_norm = 5.7777
	old_data_grads_norm = 6.5925
	sim_grads_norm_tr = 0.1422
-- Starting training on experience 6 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4094
	data_grads_norm = 4.4089
	new_data_grads_norm = 5.9428
	old_data_grads_norm = 5.8798
	sim_grads_norm_tr = -0.0227
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2150
	data_grads_norm = 3.8485
	new_data_grads_norm = 5.9032
	old_data_grads_norm = 4.7753
	sim_grads_norm_tr = -0.0019
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4020
	data_grads_norm = 4.1027
	new_data_grads_norm = 6.4972
	old_data_grads_norm = 4.3674
	sim_grads_norm_tr = -0.0255
-- Starting training on experience 7 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1509
	data_grads_norm = 3.6261
	new_data_grads_norm = 4.9035
	old_data_grads_norm = 5.7743
	sim_grads_norm_tr = -0.0293
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6271
	data_grads_norm = 4.2690
	new_data_grads_norm = 5.0767
	old_data_grads_norm = 5.9717
	sim_grads_norm_tr = 0.0489
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0602
	data_grads_norm = 3.9319
	new_data_grads_norm = 4.7841
	old_data_grads_norm = 4.9700
	sim_grads_norm_tr = -0.0686
-- Starting training on experience 8 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6781
	data_grads_norm = 4.3716
	new_data_grads_norm = 6.1777
	old_data_grads_norm = 3.5506
	sim_grads_norm_tr = -0.0498
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4550
	data_grads_norm = 4.1821
	new_data_grads_norm = 6.3147
	old_data_grads_norm = 4.0724
	sim_grads_norm_tr = 0.0104
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7142
	data_grads_norm = 4.9558
	new_data_grads_norm = 6.0425
	old_data_grads_norm = 4.6917
	sim_grads_norm_tr = 0.0271
-- Starting training on experience 9 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7394
	data_grads_norm = 4.6249
	new_data_grads_norm = 5.9337
	old_data_grads_norm = 5.2707
	sim_grads_norm_tr = 0.1669
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5307
	data_grads_norm = 4.3748
	new_data_grads_norm = 5.6187
	old_data_grads_norm = 6.7017
	sim_grads_norm_tr = 0.0351
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2684
	data_grads_norm = 3.8971
	new_data_grads_norm = 5.2039
	old_data_grads_norm = 5.7519
	sim_grads_norm_tr = -0.0157
-- Starting training on experience 10 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4304
	data_grads_norm = 3.9871
	new_data_grads_norm = 6.3883
	old_data_grads_norm = 4.2081
	sim_grads_norm_tr = 0.0612
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6836
	data_grads_norm = 4.6602
	new_data_grads_norm = 6.8863
	old_data_grads_norm = 5.3408
	sim_grads_norm_tr = 0.0581
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4243
	data_grads_norm = 4.1293
	new_data_grads_norm = 6.6440
	old_data_grads_norm = 4.3997
	sim_grads_norm_tr = 0.0370
-- Starting training on experience 11 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5377
	data_grads_norm = 3.8808
	new_data_grads_norm = 5.4378
	old_data_grads_norm = 4.6498
	sim_grads_norm_tr = 0.0445
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6298
	data_grads_norm = 4.3397
	new_data_grads_norm = 5.6588
	old_data_grads_norm = 6.4795
	sim_grads_norm_tr = 0.0228
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7420
	data_grads_norm = 4.5839
	new_data_grads_norm = 5.7871
	old_data_grads_norm = 5.6043
	sim_grads_norm_tr = 0.1906
-- Starting training on experience 12 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2826
	data_grads_norm = 4.5423
	new_data_grads_norm = 5.5516
	old_data_grads_norm = 5.9014
	sim_grads_norm_tr = 0.1420
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0724
	data_grads_norm = 4.1292
	new_data_grads_norm = 6.1716
	old_data_grads_norm = 5.3988
	sim_grads_norm_tr = 0.0461
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8345
	data_grads_norm = 3.8064
	new_data_grads_norm = 5.8159
	old_data_grads_norm = 4.2188
	sim_grads_norm_tr = -0.0277
-- Starting training on experience 13 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2944
	data_grads_norm = 4.4394
	new_data_grads_norm = 5.8625
	old_data_grads_norm = 6.7784
	sim_grads_norm_tr = 0.0421
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6985
	data_grads_norm = 4.8554
	new_data_grads_norm = 5.5191
	old_data_grads_norm = 6.2885
	sim_grads_norm_tr = 0.1138
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3217
	data_grads_norm = 4.6624
	new_data_grads_norm = 5.3808
	old_data_grads_norm = 6.0903
	sim_grads_norm_tr = 0.0384
-- Starting training on experience 14 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4068
	data_grads_norm = 4.3010
	new_data_grads_norm = 5.7530
	old_data_grads_norm = 5.2041
	sim_grads_norm_tr = 0.0741
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1621
	data_grads_norm = 4.2073
	new_data_grads_norm = 5.5463
	old_data_grads_norm = 5.8754
	sim_grads_norm_tr = 0.0815
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2833
	data_grads_norm = 3.9004
	new_data_grads_norm = 5.6551
	old_data_grads_norm = 4.7835
	sim_grads_norm_tr = 0.0405
-- Starting training on experience 15 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4430
	data_grads_norm = 4.2226
	new_data_grads_norm = 5.2441
	old_data_grads_norm = 5.2373
	sim_grads_norm_tr = 0.1845
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5178
	data_grads_norm = 4.0620
	new_data_grads_norm = 5.1670
	old_data_grads_norm = 5.3814
	sim_grads_norm_tr = 0.2275
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7934
	data_grads_norm = 3.5650
	new_data_grads_norm = 4.8831
	old_data_grads_norm = 4.5180
	sim_grads_norm_tr = 0.0813
-- Starting training on experience 16 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8501
	data_grads_norm = 4.0018
	new_data_grads_norm = 5.6983
	old_data_grads_norm = 5.2721
	sim_grads_norm_tr = -0.1373
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3957
	data_grads_norm = 4.2515
	new_data_grads_norm = 5.7787
	old_data_grads_norm = 4.5361
	sim_grads_norm_tr = 0.1293
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0724
	data_grads_norm = 4.1425
	new_data_grads_norm = 5.9210
	old_data_grads_norm = 4.8627
	sim_grads_norm_tr = 0.0168
-- Starting training on experience 17 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7625
	data_grads_norm = 3.7248
	new_data_grads_norm = 5.3094
	old_data_grads_norm = 4.8138
	sim_grads_norm_tr = -0.0085
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7518
	data_grads_norm = 3.7598
	new_data_grads_norm = 5.5803
	old_data_grads_norm = 4.6136
	sim_grads_norm_tr = 0.0032
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7284
	data_grads_norm = 4.1108
	new_data_grads_norm = 5.4085
	old_data_grads_norm = 5.7109
	sim_grads_norm_tr = -0.0011
-- Starting training on experience 18 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0974
	data_grads_norm = 4.8356
	new_data_grads_norm = 6.8680
	old_data_grads_norm = 6.1411
	sim_grads_norm_tr = 0.0863
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8773
	data_grads_norm = 4.1308
	new_data_grads_norm = 6.2872
	old_data_grads_norm = 4.6223
	sim_grads_norm_tr = -0.0342
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6749
	data_grads_norm = 3.6972
	new_data_grads_norm = 6.2277
	old_data_grads_norm = 5.0617
	sim_grads_norm_tr = -0.0742
-- Starting training on experience 19 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1130
	data_grads_norm = 3.7250
	new_data_grads_norm = 5.5643
	old_data_grads_norm = 4.4200
	sim_grads_norm_tr = 0.0455
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9273
	data_grads_norm = 4.0929
	new_data_grads_norm = 5.5421
	old_data_grads_norm = 5.4097
	sim_grads_norm_tr = 0.1631
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0700
	data_grads_norm = 4.6547
	new_data_grads_norm = 5.8365
	old_data_grads_norm = 8.2919
	sim_grads_norm_tr = -0.0416
-- Starting training on experience 20 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8949
	data_grads_norm = 4.0181
	new_data_grads_norm = 5.7731
	old_data_grads_norm = 4.4278
	sim_grads_norm_tr = 0.0459
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1951
	data_grads_norm = 5.5055
	new_data_grads_norm = 5.3708
	old_data_grads_norm = 8.3503
	sim_grads_norm_tr = 0.0827
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1705
	data_grads_norm = 4.2764
	new_data_grads_norm = 5.3940
	old_data_grads_norm = 6.2674
	sim_grads_norm_tr = 0.1167
-- Starting training on experience 21 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2458
	data_grads_norm = 4.1080
	new_data_grads_norm = 6.0288
	old_data_grads_norm = 5.0999
	sim_grads_norm_tr = 0.0250
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1303
	data_grads_norm = 3.9305
	new_data_grads_norm = 5.8580
	old_data_grads_norm = 4.8133
	sim_grads_norm_tr = 0.0414
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1879
	data_grads_norm = 4.3230
	new_data_grads_norm = 6.0070
	old_data_grads_norm = 5.9294
	sim_grads_norm_tr = 0.0099
-- Starting training on experience 22 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9599
	data_grads_norm = 3.9964
	new_data_grads_norm = 5.6463
	old_data_grads_norm = 4.7264
	sim_grads_norm_tr = 0.1999
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9109
	data_grads_norm = 3.3518
	new_data_grads_norm = 4.9097
	old_data_grads_norm = 4.0704
	sim_grads_norm_tr = 0.1587
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9329
	data_grads_norm = 3.7445
	new_data_grads_norm = 5.2662
	old_data_grads_norm = 4.6107
	sim_grads_norm_tr = 0.0917
-- Starting training on experience 23 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3050
	data_grads_norm = 3.0690
	new_data_grads_norm = 4.7802
	old_data_grads_norm = 3.4589
	sim_grads_norm_tr = -0.0186
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8431
	data_grads_norm = 3.5469
	new_data_grads_norm = 4.9965
	old_data_grads_norm = 5.2649
	sim_grads_norm_tr = -0.0072
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1421
	data_grads_norm = 4.4891
	new_data_grads_norm = 5.7733
	old_data_grads_norm = 5.2506
	sim_grads_norm_tr = 0.1489
-- Starting training on experience 24 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7443
	data_grads_norm = 3.6651
	new_data_grads_norm = 4.6916
	old_data_grads_norm = 5.1030
	sim_grads_norm_tr = 0.1599
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4409
	data_grads_norm = 3.1810
	new_data_grads_norm = 4.6113
	old_data_grads_norm = 4.4014
	sim_grads_norm_tr = -0.0229
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2990
	data_grads_norm = 3.4545
	new_data_grads_norm = 4.9286
	old_data_grads_norm = 4.9369
	sim_grads_norm_tr = 0.0272
-- Starting training on experience 25 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7598
	data_grads_norm = 3.9261
	new_data_grads_norm = 5.4182
	old_data_grads_norm = 4.8597
	sim_grads_norm_tr = -0.0671
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8172
	data_grads_norm = 3.9383
	new_data_grads_norm = 5.3875
	old_data_grads_norm = 4.1540
	sim_grads_norm_tr = 0.0346
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0278
	data_grads_norm = 4.2936
	new_data_grads_norm = 5.0136
	old_data_grads_norm = 5.5903
	sim_grads_norm_tr = 0.1242
-- Starting training on experience 26 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7451
	data_grads_norm = 3.4832
	new_data_grads_norm = 4.9378
	old_data_grads_norm = 4.1932
	sim_grads_norm_tr = -0.0118
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0692
	data_grads_norm = 4.3080
	new_data_grads_norm = 5.2400
	old_data_grads_norm = 5.8445
	sim_grads_norm_tr = 0.0300
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5201
	data_grads_norm = 3.2922
	new_data_grads_norm = 5.0924
	old_data_grads_norm = 4.2057
	sim_grads_norm_tr = -0.0463
-- Starting training on experience 27 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9600
	data_grads_norm = 3.6769
	new_data_grads_norm = 5.0896
	old_data_grads_norm = 4.6385
	sim_grads_norm_tr = 0.1973
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0213
	data_grads_norm = 4.3633
	new_data_grads_norm = 5.0426
	old_data_grads_norm = 7.0249
	sim_grads_norm_tr = 0.0084
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4190
	data_grads_norm = 2.8530
	new_data_grads_norm = 5.0190
	old_data_grads_norm = 3.1929
	sim_grads_norm_tr = 0.0272
-- Starting training on experience 28 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6806
	data_grads_norm = 3.9326
	new_data_grads_norm = 5.8329
	old_data_grads_norm = 4.5417
	sim_grads_norm_tr = 0.0518
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8361
	data_grads_norm = 3.8961
	new_data_grads_norm = 5.7934
	old_data_grads_norm = 5.4462
	sim_grads_norm_tr = 0.0188
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6643
	data_grads_norm = 3.7287
	new_data_grads_norm = 5.9211
	old_data_grads_norm = 4.3969
	sim_grads_norm_tr = 0.0223
-- Starting training on experience 29 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7213
	data_grads_norm = 4.3297
	new_data_grads_norm = 4.7739
	old_data_grads_norm = 5.9519
	sim_grads_norm_tr = 0.1622
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1463
	data_grads_norm = 3.0977
	new_data_grads_norm = 4.6092
	old_data_grads_norm = 4.2204
	sim_grads_norm_tr = -0.0104
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5520
	data_grads_norm = 3.7953
	new_data_grads_norm = 4.4802
	old_data_grads_norm = 6.1245
	sim_grads_norm_tr = -0.0499
-- Starting training on experience 30 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9242
	data_grads_norm = 3.8980
	new_data_grads_norm = 5.1081
	old_data_grads_norm = 5.1825
	sim_grads_norm_tr = -0.1297
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5833
	data_grads_norm = 3.6681
	new_data_grads_norm = 5.5894
	old_data_grads_norm = 3.9993
	sim_grads_norm_tr = 0.0368
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2274
	data_grads_norm = 4.3657
	new_data_grads_norm = 5.7814
	old_data_grads_norm = 4.9712
	sim_grads_norm_tr = 0.1055
-- Starting training on experience 31 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9129
	data_grads_norm = 3.7717
	new_data_grads_norm = 5.0455
	old_data_grads_norm = 5.0959
	sim_grads_norm_tr = 0.1193
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2244
	data_grads_norm = 3.1863
	new_data_grads_norm = 4.6101
	old_data_grads_norm = 5.0952
	sim_grads_norm_tr = -0.0833
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7659
	data_grads_norm = 3.7705
	new_data_grads_norm = 5.2782
	old_data_grads_norm = 4.9272
	sim_grads_norm_tr = 0.0189
-- Starting training on experience 32 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3188
	data_grads_norm = 3.2318
	new_data_grads_norm = 5.0286
	old_data_grads_norm = 5.2636
	sim_grads_norm_tr = -0.0457
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5676
	data_grads_norm = 3.9383
	new_data_grads_norm = 5.1960
	old_data_grads_norm = 4.9638
	sim_grads_norm_tr = 0.0548
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6788
	data_grads_norm = 3.7508
	new_data_grads_norm = 4.9322
	old_data_grads_norm = 5.1253
	sim_grads_norm_tr = -0.0175
-- Starting training on experience 33 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6737
	data_grads_norm = 3.6866
	new_data_grads_norm = 5.4164
	old_data_grads_norm = 4.7439
	sim_grads_norm_tr = 0.1160
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6941
	data_grads_norm = 4.0792
	new_data_grads_norm = 5.5229
	old_data_grads_norm = 5.9872
	sim_grads_norm_tr = -0.0489
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6899
	data_grads_norm = 4.2826
	new_data_grads_norm = 5.6804
	old_data_grads_norm = 5.8075
	sim_grads_norm_tr = 0.0299
-- Starting training on experience 34 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6070
	data_grads_norm = 4.0891
	new_data_grads_norm = 5.6370
	old_data_grads_norm = 5.6608
	sim_grads_norm_tr = -0.0522
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8606
	data_grads_norm = 3.9965
	new_data_grads_norm = 5.5447
	old_data_grads_norm = 5.1761
	sim_grads_norm_tr = 0.0257
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5452
	data_grads_norm = 3.8330
	new_data_grads_norm = 5.4797
	old_data_grads_norm = 4.4039
	sim_grads_norm_tr = 0.1766
-- Starting training on experience 35 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6279
	data_grads_norm = 4.0133
	new_data_grads_norm = 5.0439
	old_data_grads_norm = 5.1435
	sim_grads_norm_tr = 0.3174
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6132
	data_grads_norm = 3.7785
	new_data_grads_norm = 4.6867
	old_data_grads_norm = 5.9342
	sim_grads_norm_tr = -0.1234
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7435
	data_grads_norm = 3.7529
	new_data_grads_norm = 4.8752
	old_data_grads_norm = 5.6005
	sim_grads_norm_tr = 0.0298
-- Starting training on experience 36 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4955
	data_grads_norm = 3.7807
	new_data_grads_norm = 5.3091
	old_data_grads_norm = 5.0899
	sim_grads_norm_tr = 0.0499
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3877
	data_grads_norm = 3.7735
	new_data_grads_norm = 5.6012
	old_data_grads_norm = 5.0221
	sim_grads_norm_tr = -0.0040
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5402
	data_grads_norm = 3.8938
	new_data_grads_norm = 5.4172
	old_data_grads_norm = 5.5524
	sim_grads_norm_tr = -0.0412
-- Starting training on experience 37 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5429
	data_grads_norm = 3.7360
	new_data_grads_norm = 5.1189
	old_data_grads_norm = 4.2484
	sim_grads_norm_tr = 0.3204
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4475
	data_grads_norm = 3.5608
	new_data_grads_norm = 5.1868
	old_data_grads_norm = 4.9026
	sim_grads_norm_tr = -0.0424
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0874
	data_grads_norm = 3.7951
	new_data_grads_norm = 5.1756
	old_data_grads_norm = 4.6072
	sim_grads_norm_tr = 0.1528
-- Starting training on experience 38 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0846
	data_grads_norm = 3.6278
	new_data_grads_norm = 4.8951
	old_data_grads_norm = 5.5844
	sim_grads_norm_tr = -0.0737
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0539
	data_grads_norm = 3.4504
	new_data_grads_norm = 5.0982
	old_data_grads_norm = 5.9459
	sim_grads_norm_tr = -0.1284
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3731
	data_grads_norm = 3.5435
	new_data_grads_norm = 5.5741
	old_data_grads_norm = 3.8233
	sim_grads_norm_tr = 0.1262
-- Starting training on experience 39 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8021
	data_grads_norm = 3.9244
	new_data_grads_norm = 4.6323
	old_data_grads_norm = 5.7927
	sim_grads_norm_tr = 0.1160
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4306
	data_grads_norm = 3.3992
	new_data_grads_norm = 4.4593
	old_data_grads_norm = 4.7181
	sim_grads_norm_tr = 0.0370
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5575
	data_grads_norm = 4.2669
	new_data_grads_norm = 4.8748
	old_data_grads_norm = 5.5591
	sim_grads_norm_tr = -0.0618
-- Starting training on experience 40 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9086
	data_grads_norm = 4.8115
	new_data_grads_norm = 6.5798
	old_data_grads_norm = 7.1762
	sim_grads_norm_tr = 0.0766
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0041
	data_grads_norm = 4.9774
	new_data_grads_norm = 5.9544
	old_data_grads_norm = 6.9204
	sim_grads_norm_tr = 0.0267
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4711
	data_grads_norm = 3.6910
	new_data_grads_norm = 5.5530
	old_data_grads_norm = 4.5367
	sim_grads_norm_tr = 0.0508
-- Starting training on experience 41 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8903
	data_grads_norm = 3.8194
	new_data_grads_norm = 4.7890
	old_data_grads_norm = 4.6506
	sim_grads_norm_tr = 0.1465
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2666
	data_grads_norm = 4.1310
	new_data_grads_norm = 4.6121
	old_data_grads_norm = 5.5675
	sim_grads_norm_tr = 0.1838
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5582
	data_grads_norm = 4.0649
	new_data_grads_norm = 4.4335
	old_data_grads_norm = 6.0654
	sim_grads_norm_tr = -0.0104
-- Starting training on experience 42 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1072
	data_grads_norm = 3.2378
	new_data_grads_norm = 4.9042
	old_data_grads_norm = 3.9866
	sim_grads_norm_tr = 0.0158
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9558
	data_grads_norm = 4.1370
	new_data_grads_norm = 5.1165
	old_data_grads_norm = 6.0282
	sim_grads_norm_tr = 0.0845
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9034
	data_grads_norm = 3.9938
	new_data_grads_norm = 5.0029
	old_data_grads_norm = 6.1991
	sim_grads_norm_tr = -0.0144
-- Starting training on experience 43 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6137
	data_grads_norm = 3.8313
	new_data_grads_norm = 5.3428
	old_data_grads_norm = 5.4320
	sim_grads_norm_tr = -0.1064
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8135
	data_grads_norm = 4.2775
	new_data_grads_norm = 5.2238
	old_data_grads_norm = 5.3682
	sim_grads_norm_tr = 0.1961
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4875
	data_grads_norm = 3.7669
	new_data_grads_norm = 5.5449
	old_data_grads_norm = 5.0710
	sim_grads_norm_tr = 0.0374
-- Starting training on experience 44 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4123
	data_grads_norm = 3.3143
	new_data_grads_norm = 4.8297
	old_data_grads_norm = 4.2038
	sim_grads_norm_tr = -0.0350
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6018
	data_grads_norm = 4.1187
	new_data_grads_norm = 5.2486
	old_data_grads_norm = 5.4366
	sim_grads_norm_tr = 0.0482
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8076
	data_grads_norm = 3.9826
	new_data_grads_norm = 5.6644
	old_data_grads_norm = 5.2483
	sim_grads_norm_tr = -0.0192
-- Starting training on experience 45 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6893
	data_grads_norm = 4.3141
	new_data_grads_norm = 6.3970
	old_data_grads_norm = 6.1955
	sim_grads_norm_tr = 0.0382
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7979
	data_grads_norm = 4.5928
	new_data_grads_norm = 6.0392
	old_data_grads_norm = 5.8284
	sim_grads_norm_tr = 0.1653
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7132
	data_grads_norm = 4.4149
	new_data_grads_norm = 5.6851
	old_data_grads_norm = 5.6058
	sim_grads_norm_tr = 0.1445
-- Starting training on experience 46 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6530
	data_grads_norm = 3.5276
	new_data_grads_norm = 4.7031
	old_data_grads_norm = 5.4248
	sim_grads_norm_tr = 0.0610
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6421
	data_grads_norm = 3.9153
	new_data_grads_norm = 5.2501
	old_data_grads_norm = 5.1920
	sim_grads_norm_tr = 0.1393
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5549
	data_grads_norm = 3.6950
	new_data_grads_norm = 4.6301
	old_data_grads_norm = 5.2756
	sim_grads_norm_tr = 0.0921
-- Starting training on experience 47 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1433
	data_grads_norm = 3.5241
	new_data_grads_norm = 4.9735
	old_data_grads_norm = 5.4949
	sim_grads_norm_tr = -0.1024
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7171
	data_grads_norm = 4.4738
	new_data_grads_norm = 5.0106
	old_data_grads_norm = 6.3597
	sim_grads_norm_tr = 0.0612
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4433
	data_grads_norm = 3.6417
	new_data_grads_norm = 5.0464
	old_data_grads_norm = 4.4962
	sim_grads_norm_tr = 0.0196
-- Starting training on experience 48 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2261
	data_grads_norm = 3.3524
	new_data_grads_norm = 4.5310
	old_data_grads_norm = 4.3229
	sim_grads_norm_tr = 0.0733
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2576
	data_grads_norm = 3.9829
	new_data_grads_norm = 4.8725
	old_data_grads_norm = 6.2484
	sim_grads_norm_tr = 0.0120
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4083
	data_grads_norm = 4.3339
	new_data_grads_norm = 4.9130
	old_data_grads_norm = 6.4653
	sim_grads_norm_tr = 0.1172
-- Starting training on experience 49 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6961
	data_grads_norm = 3.7133
	new_data_grads_norm = 5.0118
	old_data_grads_norm = 5.1312
	sim_grads_norm_tr = 0.1063
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2492
	data_grads_norm = 3.3910
	new_data_grads_norm = 4.6958
	old_data_grads_norm = 5.1985
	sim_grads_norm_tr = -0.0795
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2474
	data_grads_norm = 3.5629
	new_data_grads_norm = 5.1396
	old_data_grads_norm = 5.1375
	sim_grads_norm_tr = 0.0555
-- Starting training on experience 50 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4896
	data_grads_norm = 3.8284
	new_data_grads_norm = 6.0445
	old_data_grads_norm = 4.8809
	sim_grads_norm_tr = 0.0380
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2589
	data_grads_norm = 3.9576
	new_data_grads_norm = 5.2135
	old_data_grads_norm = 5.8182
	sim_grads_norm_tr = -0.0758
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9301
	data_grads_norm = 4.0383
	new_data_grads_norm = 5.3377
	old_data_grads_norm = 5.7814
	sim_grads_norm_tr = 0.0623
-- Starting training on experience 51 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6053
	data_grads_norm = 3.8501
	new_data_grads_norm = 5.0707
	old_data_grads_norm = 5.7415
	sim_grads_norm_tr = 0.0498
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3875
	data_grads_norm = 3.4155
	new_data_grads_norm = 4.8728
	old_data_grads_norm = 4.5137
	sim_grads_norm_tr = 0.1351
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6287
	data_grads_norm = 3.7436
	new_data_grads_norm = 5.0773
	old_data_grads_norm = 5.4005
	sim_grads_norm_tr = -0.0092
-- Starting training on experience 52 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1355
	data_grads_norm = 3.8880
	new_data_grads_norm = 6.1502
	old_data_grads_norm = 5.6326
	sim_grads_norm_tr = -0.0698
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2307
	data_grads_norm = 3.8568
	new_data_grads_norm = 6.3321
	old_data_grads_norm = 4.7241
	sim_grads_norm_tr = 0.0543
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6969
	data_grads_norm = 4.1213
	new_data_grads_norm = 6.2707
	old_data_grads_norm = 4.6949
	sim_grads_norm_tr = 0.0855
-- Starting training on experience 53 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6370
	data_grads_norm = 3.7198
	new_data_grads_norm = 4.3714
	old_data_grads_norm = 5.9545
	sim_grads_norm_tr = 0.1107
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1708
	data_grads_norm = 3.2733
	new_data_grads_norm = 4.3421
	old_data_grads_norm = 4.6693
	sim_grads_norm_tr = -0.0292
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4033
	data_grads_norm = 3.5165
	new_data_grads_norm = 4.3052
	old_data_grads_norm = 5.2599
	sim_grads_norm_tr = 0.0865
-- Starting training on experience 54 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4251
	data_grads_norm = 3.7725
	new_data_grads_norm = 5.2864
	old_data_grads_norm = 4.6096
	sim_grads_norm_tr = 0.1196
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8310
	data_grads_norm = 4.5720
	new_data_grads_norm = 6.0417
	old_data_grads_norm = 6.4357
	sim_grads_norm_tr = -0.0029
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6517
	data_grads_norm = 4.3789
	new_data_grads_norm = 5.4048
	old_data_grads_norm = 6.3170
	sim_grads_norm_tr = 0.0851
-- Starting training on experience 55 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8267
	data_grads_norm = 3.9552
	new_data_grads_norm = 5.8670
	old_data_grads_norm = 4.3593
	sim_grads_norm_tr = -0.0291
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7754
	data_grads_norm = 4.2452
	new_data_grads_norm = 5.7524
	old_data_grads_norm = 5.5724
	sim_grads_norm_tr = 0.0961
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5665
	data_grads_norm = 4.0607
	new_data_grads_norm = 5.7152
	old_data_grads_norm = 5.7547
	sim_grads_norm_tr = 0.0228
-- Starting training on experience 56 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1782
	data_grads_norm = 3.0373
	new_data_grads_norm = 4.3026
	old_data_grads_norm = 3.9587
	sim_grads_norm_tr = 0.0908
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2028
	data_grads_norm = 3.1908
	new_data_grads_norm = 4.6250
	old_data_grads_norm = 4.0674
	sim_grads_norm_tr = 0.0017
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2077
	data_grads_norm = 3.5080
	new_data_grads_norm = 4.9529
	old_data_grads_norm = 4.9878
	sim_grads_norm_tr = -0.1169
-- Starting training on experience 57 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8162
	data_grads_norm = 4.5335
	new_data_grads_norm = 5.9954
	old_data_grads_norm = 5.9888
	sim_grads_norm_tr = 0.0973
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7842
	data_grads_norm = 3.7544
	new_data_grads_norm = 5.6256
	old_data_grads_norm = 4.8023
	sim_grads_norm_tr = 0.0628
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4758
	data_grads_norm = 4.2190
	new_data_grads_norm = 5.8879
	old_data_grads_norm = 5.2421
	sim_grads_norm_tr = 0.1336
-- Starting training on experience 58 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7323
	data_grads_norm = 3.9468
	new_data_grads_norm = 5.7983
	old_data_grads_norm = 3.8996
	sim_grads_norm_tr = 0.1178
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3530
	data_grads_norm = 3.6398
	new_data_grads_norm = 5.3225
	old_data_grads_norm = 4.5907
	sim_grads_norm_tr = 0.0432
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7898
	data_grads_norm = 4.1092
	new_data_grads_norm = 5.3952
	old_data_grads_norm = 5.0982
	sim_grads_norm_tr = 0.0882
-- Starting training on experience 59 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3120
	data_grads_norm = 3.3302
	new_data_grads_norm = 4.7639
	old_data_grads_norm = 4.9865
	sim_grads_norm_tr = -0.1172
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2904
	data_grads_norm = 3.2144
	new_data_grads_norm = 5.0399
	old_data_grads_norm = 3.5843
	sim_grads_norm_tr = 0.0788
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2597
	data_grads_norm = 3.5455
	new_data_grads_norm = 5.1577
	old_data_grads_norm = 4.1505
	sim_grads_norm_tr = 0.1619
-- Starting training on experience 60 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2623
	data_grads_norm = 3.7711
	new_data_grads_norm = 4.5285
	old_data_grads_norm = 5.4641
	sim_grads_norm_tr = 0.0844
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6085
	data_grads_norm = 4.0394
	new_data_grads_norm = 5.0349
	old_data_grads_norm = 6.4696
	sim_grads_norm_tr = -0.0528
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3193
	data_grads_norm = 3.8377
	new_data_grads_norm = 4.9592
	old_data_grads_norm = 6.1558
	sim_grads_norm_tr = -0.0004
-- Starting training on experience 61 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7096
	data_grads_norm = 3.5089
	new_data_grads_norm = 5.0857
	old_data_grads_norm = 5.1194
	sim_grads_norm_tr = 0.0200
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5401
	data_grads_norm = 3.5841
	new_data_grads_norm = 4.9743
	old_data_grads_norm = 4.6265
	sim_grads_norm_tr = 0.1357
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3830
	data_grads_norm = 3.8599
	new_data_grads_norm = 4.7655
	old_data_grads_norm = 5.1696
	sim_grads_norm_tr = 0.1598
-- Starting training on experience 62 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3271
	data_grads_norm = 3.9446
	new_data_grads_norm = 5.8350
	old_data_grads_norm = 5.0741
	sim_grads_norm_tr = -0.0758
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7177
	data_grads_norm = 3.9611
	new_data_grads_norm = 5.6793
	old_data_grads_norm = 5.3480
	sim_grads_norm_tr = -0.0522
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7744
	data_grads_norm = 4.4460
	new_data_grads_norm = 5.5559
	old_data_grads_norm = 6.1442
	sim_grads_norm_tr = -0.0010
-- Starting training on experience 63 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2346
	data_grads_norm = 4.0507
	new_data_grads_norm = 5.3805
	old_data_grads_norm = 6.3303
	sim_grads_norm_tr = 0.0106
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6500
	data_grads_norm = 3.6188
	new_data_grads_norm = 5.0134
	old_data_grads_norm = 4.8843
	sim_grads_norm_tr = -0.0423
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7328
	data_grads_norm = 4.0214
	new_data_grads_norm = 5.0316
	old_data_grads_norm = 5.9593
	sim_grads_norm_tr = 0.0443
-- Starting training on experience 64 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2729
	data_grads_norm = 3.6811
	new_data_grads_norm = 4.8718
	old_data_grads_norm = 5.3055
	sim_grads_norm_tr = -0.0280
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3775
	data_grads_norm = 3.8578
	new_data_grads_norm = 4.7773
	old_data_grads_norm = 5.5161
	sim_grads_norm_tr = 0.0208
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4882
	data_grads_norm = 3.8062
	new_data_grads_norm = 5.4866
	old_data_grads_norm = 4.6404
	sim_grads_norm_tr = -0.0192
-- Starting training on experience 65 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3385
	data_grads_norm = 3.8221
	new_data_grads_norm = 5.2498
	old_data_grads_norm = 6.4343
	sim_grads_norm_tr = 0.0089
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4279
	data_grads_norm = 4.0673
	new_data_grads_norm = 5.5570
	old_data_grads_norm = 6.7741
	sim_grads_norm_tr = 0.0142
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8844
	data_grads_norm = 4.0529
	new_data_grads_norm = 5.2082
	old_data_grads_norm = 4.7405
	sim_grads_norm_tr = 0.1076
-- Starting training on experience 66 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1079
	data_grads_norm = 3.8102
	new_data_grads_norm = 5.2862
	old_data_grads_norm = 4.7195
	sim_grads_norm_tr = -0.0069
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2522
	data_grads_norm = 3.9422
	new_data_grads_norm = 5.4978
	old_data_grads_norm = 4.8274
	sim_grads_norm_tr = 0.1059
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1535
	data_grads_norm = 3.5561
	new_data_grads_norm = 5.8529
	old_data_grads_norm = 4.3479
	sim_grads_norm_tr = 0.0574
-- Starting training on experience 67 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8987
	data_grads_norm = 3.7824
	new_data_grads_norm = 4.9062
	old_data_grads_norm = 5.8441
	sim_grads_norm_tr = -0.0194
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7327
	data_grads_norm = 3.9051
	new_data_grads_norm = 4.7734
	old_data_grads_norm = 4.5975
	sim_grads_norm_tr = 0.0640
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6205
	data_grads_norm = 3.6482
	new_data_grads_norm = 5.0872
	old_data_grads_norm = 5.1195
	sim_grads_norm_tr = -0.1310
-- Starting training on experience 68 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8120
	data_grads_norm = 4.0726
	new_data_grads_norm = 5.6279
	old_data_grads_norm = 4.9850
	sim_grads_norm_tr = 0.1182
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3602
	data_grads_norm = 3.7041
	new_data_grads_norm = 5.0237
	old_data_grads_norm = 5.2565
	sim_grads_norm_tr = 0.0899
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4561
	data_grads_norm = 4.0793
	new_data_grads_norm = 5.3411
	old_data_grads_norm = 5.6399
	sim_grads_norm_tr = -0.0261
-- Starting training on experience 69 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1398
	data_grads_norm = 3.5779
	new_data_grads_norm = 5.0851
	old_data_grads_norm = 5.0882
	sim_grads_norm_tr = 0.0800
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4021
	data_grads_norm = 3.7322
	new_data_grads_norm = 5.0961
	old_data_grads_norm = 5.7580
	sim_grads_norm_tr = 0.0157
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1060
	data_grads_norm = 3.2706
	new_data_grads_norm = 4.8294
	old_data_grads_norm = 4.2485
	sim_grads_norm_tr = 0.0688
-- Starting training on experience 70 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3247
	data_grads_norm = 3.4191
	new_data_grads_norm = 5.5556
	old_data_grads_norm = 4.7060
	sim_grads_norm_tr = -0.0618
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0900
	data_grads_norm = 4.7179
	new_data_grads_norm = 5.7802
	old_data_grads_norm = 6.8073
	sim_grads_norm_tr = 0.1426
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4805
	data_grads_norm = 3.7139
	new_data_grads_norm = 4.8967
	old_data_grads_norm = 4.7727
	sim_grads_norm_tr = 0.1479
-- Starting training on experience 71 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5374
	data_grads_norm = 3.6020
	new_data_grads_norm = 4.7676
	old_data_grads_norm = 5.1138
	sim_grads_norm_tr = -0.0996
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2850
	data_grads_norm = 3.5023
	new_data_grads_norm = 5.1103
	old_data_grads_norm = 4.8157
	sim_grads_norm_tr = -0.0779
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2618
	data_grads_norm = 3.7843
	new_data_grads_norm = 5.1181
	old_data_grads_norm = 5.2064
	sim_grads_norm_tr = 0.0211
-- Starting training on experience 72 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6751
	data_grads_norm = 4.0655
	new_data_grads_norm = 5.4165
	old_data_grads_norm = 5.5114
	sim_grads_norm_tr = 0.1515
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4100
	data_grads_norm = 3.7458
	new_data_grads_norm = 5.2550
	old_data_grads_norm = 6.3918
	sim_grads_norm_tr = -0.0844
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6002
	data_grads_norm = 3.8364
	new_data_grads_norm = 5.8425
	old_data_grads_norm = 4.7827
	sim_grads_norm_tr = -0.0322
-- Starting training on experience 73 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5973
	data_grads_norm = 4.3441
	new_data_grads_norm = 5.1939
	old_data_grads_norm = 6.3089
	sim_grads_norm_tr = -0.0840
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4886
	data_grads_norm = 3.7987
	new_data_grads_norm = 5.3984
	old_data_grads_norm = 5.0660
	sim_grads_norm_tr = -0.0756
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8120
	data_grads_norm = 4.8456
	new_data_grads_norm = 5.2230
	old_data_grads_norm = 7.0438
	sim_grads_norm_tr = 0.0502
-- Starting training on experience 74 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4524
	data_grads_norm = 4.0358
	new_data_grads_norm = 5.9852
	old_data_grads_norm = 5.2058
	sim_grads_norm_tr = 0.0152
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6839
	data_grads_norm = 4.1768
	new_data_grads_norm = 5.7333
	old_data_grads_norm = 5.9678
	sim_grads_norm_tr = 0.0647
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7664
	data_grads_norm = 3.9552
	new_data_grads_norm = 6.1460
	old_data_grads_norm = 5.1427
	sim_grads_norm_tr = -0.0329
-- Starting training on experience 75 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5666
	data_grads_norm = 4.6086
	new_data_grads_norm = 5.7942
	old_data_grads_norm = 6.2311
	sim_grads_norm_tr = -0.0209
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3636
	data_grads_norm = 3.8850
	new_data_grads_norm = 5.9878
	old_data_grads_norm = 5.3327
	sim_grads_norm_tr = -0.1329
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0349
	data_grads_norm = 4.5791
	new_data_grads_norm = 6.1112
	old_data_grads_norm = 5.8575
	sim_grads_norm_tr = 0.1464
-- Starting training on experience 76 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1558
	data_grads_norm = 4.0725
	new_data_grads_norm = 5.4722
	old_data_grads_norm = 5.5428
	sim_grads_norm_tr = 0.0816
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3387
	data_grads_norm = 3.5072
	new_data_grads_norm = 5.1794
	old_data_grads_norm = 4.4559
	sim_grads_norm_tr = 0.0676
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1827
	data_grads_norm = 3.2103
	new_data_grads_norm = 4.7223
	old_data_grads_norm = 4.4990
	sim_grads_norm_tr = -0.0906
-- Starting training on experience 77 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5869
	data_grads_norm = 3.7543
	new_data_grads_norm = 4.9370
	old_data_grads_norm = 4.4739
	sim_grads_norm_tr = 0.0392
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5755
	data_grads_norm = 3.5833
	new_data_grads_norm = 5.2201
	old_data_grads_norm = 4.5282
	sim_grads_norm_tr = 0.0365
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6009
	data_grads_norm = 3.6921
	new_data_grads_norm = 4.9550
	old_data_grads_norm = 5.2718
	sim_grads_norm_tr = -0.0847
-- Starting training on experience 78 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8823
	data_grads_norm = 3.4002
	new_data_grads_norm = 4.3752
	old_data_grads_norm = 5.7221
	sim_grads_norm_tr = -0.1215
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2055
	data_grads_norm = 3.3091
	new_data_grads_norm = 4.8644
	old_data_grads_norm = 4.5131
	sim_grads_norm_tr = -0.0104
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4414
	data_grads_norm = 4.1846
	new_data_grads_norm = 5.2426
	old_data_grads_norm = 6.2643
	sim_grads_norm_tr = 0.1293
-- Starting training on experience 79 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3026
	data_grads_norm = 3.3067
	new_data_grads_norm = 4.9034
	old_data_grads_norm = 4.1440
	sim_grads_norm_tr = -0.0397
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5793
	data_grads_norm = 3.8024
	new_data_grads_norm = 4.8059
	old_data_grads_norm = 4.3585
	sim_grads_norm_tr = 0.2200
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1915
	data_grads_norm = 3.4697
	new_data_grads_norm = 4.6899
	old_data_grads_norm = 4.9217
	sim_grads_norm_tr = -0.0003
-- Starting training on experience 80 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2417
	data_grads_norm = 3.8481
	new_data_grads_norm = 5.6303
	old_data_grads_norm = 5.3563
	sim_grads_norm_tr = -0.0893
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5677
	data_grads_norm = 4.2084
	new_data_grads_norm = 5.8234
	old_data_grads_norm = 5.0046
	sim_grads_norm_tr = 0.1617
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9417
	data_grads_norm = 3.2785
	new_data_grads_norm = 5.7476
	old_data_grads_norm = 4.0694
	sim_grads_norm_tr = -0.1264
-- Starting training on experience 81 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4583
	data_grads_norm = 3.7321
	new_data_grads_norm = 5.0100
	old_data_grads_norm = 4.9747
	sim_grads_norm_tr = 0.1703
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8796
	data_grads_norm = 4.1452
	new_data_grads_norm = 5.1236
	old_data_grads_norm = 5.5556
	sim_grads_norm_tr = 0.1483
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3140
	data_grads_norm = 3.8372
	new_data_grads_norm = 5.2948
	old_data_grads_norm = 5.7062
	sim_grads_norm_tr = -0.0392
-- Starting training on experience 82 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5387
	data_grads_norm = 4.0999
	new_data_grads_norm = 5.6720
	old_data_grads_norm = 6.1468
	sim_grads_norm_tr = 0.0602
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3894
	data_grads_norm = 3.6763
	new_data_grads_norm = 6.1890
	old_data_grads_norm = 4.6841
	sim_grads_norm_tr = 0.0150
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1572
	data_grads_norm = 4.1142
	new_data_grads_norm = 6.8725
	old_data_grads_norm = 5.2561
	sim_grads_norm_tr = 0.1111
-- Starting training on experience 83 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8926
	data_grads_norm = 4.8477
	new_data_grads_norm = 6.5601
	old_data_grads_norm = 5.8824
	sim_grads_norm_tr = 0.0233
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0098
	data_grads_norm = 4.1173
	new_data_grads_norm = 5.8376
	old_data_grads_norm = 4.8102
	sim_grads_norm_tr = 0.1101
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9576
	data_grads_norm = 4.6673
	new_data_grads_norm = 6.1124
	old_data_grads_norm = 5.5823
	sim_grads_norm_tr = 0.0108
-- Starting training on experience 84 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9387
	data_grads_norm = 4.1531
	new_data_grads_norm = 5.3617
	old_data_grads_norm = 4.9580
	sim_grads_norm_tr = 0.0011
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7646
	data_grads_norm = 3.2553
	new_data_grads_norm = 5.0432
	old_data_grads_norm = 4.0594
	sim_grads_norm_tr = -0.0022
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3167
	data_grads_norm = 3.9749
	new_data_grads_norm = 4.6804
	old_data_grads_norm = 5.0333
	sim_grads_norm_tr = 0.0185
-- Starting training on experience 85 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4359
	data_grads_norm = 4.3859
	new_data_grads_norm = 4.5936
	old_data_grads_norm = 6.4003
	sim_grads_norm_tr = 0.1525
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5029
	data_grads_norm = 3.8655
	new_data_grads_norm = 4.2863
	old_data_grads_norm = 6.4611
	sim_grads_norm_tr = -0.0725
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1275
	data_grads_norm = 3.7072
	new_data_grads_norm = 4.9922
	old_data_grads_norm = 5.4311
	sim_grads_norm_tr = -0.0248
-- Starting training on experience 86 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2045
	data_grads_norm = 3.3355
	new_data_grads_norm = 5.4098
	old_data_grads_norm = 4.3588
	sim_grads_norm_tr = -0.0804
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3598
	data_grads_norm = 3.9397
	new_data_grads_norm = 5.7903
	old_data_grads_norm = 5.0532
	sim_grads_norm_tr = 0.0688
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5346
	data_grads_norm = 4.1468
	new_data_grads_norm = 6.2439
	old_data_grads_norm = 4.6687
	sim_grads_norm_tr = 0.0453
-- Starting training on experience 87 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1466
	data_grads_norm = 3.4091
	new_data_grads_norm = 5.0244
	old_data_grads_norm = 5.0505
	sim_grads_norm_tr = -0.0994
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4617
	data_grads_norm = 3.7562
	new_data_grads_norm = 4.7193
	old_data_grads_norm = 5.1786
	sim_grads_norm_tr = 0.0295
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2080
	data_grads_norm = 3.4949
	new_data_grads_norm = 5.4946
	old_data_grads_norm = 4.4315
	sim_grads_norm_tr = -0.0686
-- Starting training on experience 88 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3829
	data_grads_norm = 3.7020
	new_data_grads_norm = 5.3088
	old_data_grads_norm = 4.2145
	sim_grads_norm_tr = 0.0813
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8116
	data_grads_norm = 4.3900
	new_data_grads_norm = 5.2059
	old_data_grads_norm = 6.0400
	sim_grads_norm_tr = 0.1973
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4647
	data_grads_norm = 4.5084
	new_data_grads_norm = 5.3921
	old_data_grads_norm = 6.0501
	sim_grads_norm_tr = 0.0124
-- Starting training on experience 89 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2025
	data_grads_norm = 3.4368
	new_data_grads_norm = 4.9890
	old_data_grads_norm = 4.8894
	sim_grads_norm_tr = 0.0135
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4147
	data_grads_norm = 3.9484
	new_data_grads_norm = 5.4100
	old_data_grads_norm = 5.8712
	sim_grads_norm_tr = 0.0625
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2785
	data_grads_norm = 3.7785
	new_data_grads_norm = 5.0797
	old_data_grads_norm = 4.1806
	sim_grads_norm_tr = -0.0821
-- Starting training on experience 90 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3976
	data_grads_norm = 3.8437
	new_data_grads_norm = 5.7895
	old_data_grads_norm = 3.8523
	sim_grads_norm_tr = -0.0165
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8688
	data_grads_norm = 4.0463
	new_data_grads_norm = 5.9276
	old_data_grads_norm = 4.9541
	sim_grads_norm_tr = 0.0524
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4686
	data_grads_norm = 4.1118
	new_data_grads_norm = 5.3939
	old_data_grads_norm = 5.9518
	sim_grads_norm_tr = 0.0919
-- Starting training on experience 91 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2110
	data_grads_norm = 3.5291
	new_data_grads_norm = 5.8522
	old_data_grads_norm = 3.8114
	sim_grads_norm_tr = 0.1944
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9610
	data_grads_norm = 3.7432
	new_data_grads_norm = 5.2728
	old_data_grads_norm = 5.2928
	sim_grads_norm_tr = 0.0276
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3266
	data_grads_norm = 3.6967
	new_data_grads_norm = 5.0679
	old_data_grads_norm = 4.6950
	sim_grads_norm_tr = 0.0622
-- Starting training on experience 92 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5097
	data_grads_norm = 3.8817
	new_data_grads_norm = 5.5316
	old_data_grads_norm = 4.7178
	sim_grads_norm_tr = -0.0058
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1994
	data_grads_norm = 3.8529
	new_data_grads_norm = 5.1745
	old_data_grads_norm = 4.9815
	sim_grads_norm_tr = 0.0637
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1647
	data_grads_norm = 3.4298
	new_data_grads_norm = 5.3852
	old_data_grads_norm = 4.8258
	sim_grads_norm_tr = -0.1045
-- Starting training on experience 93 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4396
	data_grads_norm = 4.5630
	new_data_grads_norm = 5.9228
	old_data_grads_norm = 4.8703
	sim_grads_norm_tr = 0.3883
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0655
	data_grads_norm = 3.4310
	new_data_grads_norm = 5.2147
	old_data_grads_norm = 4.2061
	sim_grads_norm_tr = 0.0919
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0537
	data_grads_norm = 4.3005
	new_data_grads_norm = 5.1877
	old_data_grads_norm = 6.4634
	sim_grads_norm_tr = -0.0391
-- Starting training on experience 94 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1515
	data_grads_norm = 3.9840
	new_data_grads_norm = 5.3537
	old_data_grads_norm = 4.9708
	sim_grads_norm_tr = -0.0260
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3693
	data_grads_norm = 3.9995
	new_data_grads_norm = 5.6498
	old_data_grads_norm = 4.5381
	sim_grads_norm_tr = 0.0627
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7304
	data_grads_norm = 4.2656
	new_data_grads_norm = 5.4995
	old_data_grads_norm = 5.2773
	sim_grads_norm_tr = 0.0516
-- Starting training on experience 95 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8081
	data_grads_norm = 3.1720
	new_data_grads_norm = 4.9538
	old_data_grads_norm = 4.8273
	sim_grads_norm_tr = -0.0316
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4929
	data_grads_norm = 4.3640
	new_data_grads_norm = 5.0306
	old_data_grads_norm = 5.7485
	sim_grads_norm_tr = 0.0493
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8334
	data_grads_norm = 3.3664
	new_data_grads_norm = 5.4032
	old_data_grads_norm = 4.4807
	sim_grads_norm_tr = -0.0565
-- Starting training on experience 96 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5029
	data_grads_norm = 4.0034
	new_data_grads_norm = 5.8013
	old_data_grads_norm = 6.6779
	sim_grads_norm_tr = -0.0696
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2490
	data_grads_norm = 3.9124
	new_data_grads_norm = 5.1860
	old_data_grads_norm = 5.3623
	sim_grads_norm_tr = -0.0156
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6115
	data_grads_norm = 4.4141
	new_data_grads_norm = 5.1962
	old_data_grads_norm = 5.5441
	sim_grads_norm_tr = 0.1993
-- Starting training on experience 97 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3220
	data_grads_norm = 4.2807
	new_data_grads_norm = 5.2306
	old_data_grads_norm = 6.0330
	sim_grads_norm_tr = -0.0036
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7027
	data_grads_norm = 4.0763
	new_data_grads_norm = 5.4015
	old_data_grads_norm = 6.0849
	sim_grads_norm_tr = 0.0292
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6435
	data_grads_norm = 4.3018
	new_data_grads_norm = 6.1427
	old_data_grads_norm = 5.5678
	sim_grads_norm_tr = 0.1294
-- Starting training on experience 98 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0636
	data_grads_norm = 3.7288
	new_data_grads_norm = 5.5412
	old_data_grads_norm = 5.0255
	sim_grads_norm_tr = 0.0232
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0541
	data_grads_norm = 3.6122
	new_data_grads_norm = 6.2013
	old_data_grads_norm = 3.7977
	sim_grads_norm_tr = -0.0844
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2559
	data_grads_norm = 3.9374
	new_data_grads_norm = 5.9925
	old_data_grads_norm = 4.5108
	sim_grads_norm_tr = -0.0071
-- Starting training on experience 99 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1640
	data_grads_norm = 3.5073
	new_data_grads_norm = 4.2908
	old_data_grads_norm = 5.1918
	sim_grads_norm_tr = -0.0355
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3671
	data_grads_norm = 3.9074
	new_data_grads_norm = 4.7270
	old_data_grads_norm = 5.7798
	sim_grads_norm_tr = 0.0680
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4471
	data_grads_norm = 3.8077
	new_data_grads_norm = 4.4366
	old_data_grads_norm = 5.9491
	sim_grads_norm_tr = 0.0573
-- Starting training on experience 100 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3699
	data_grads_norm = 4.0980
	new_data_grads_norm = 5.6095
	old_data_grads_norm = 6.2348
	sim_grads_norm_tr = -0.0073
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4017
	data_grads_norm = 4.7323
	new_data_grads_norm = 5.5083
	old_data_grads_norm = 6.0459
	sim_grads_norm_tr = 0.0939
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3932
	data_grads_norm = 4.2566
	new_data_grads_norm = 5.5088
	old_data_grads_norm = 5.2121
	sim_grads_norm_tr = -0.0065
-- Starting training on experience 101 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3350
	data_grads_norm = 4.1558
	new_data_grads_norm = 6.3433
	old_data_grads_norm = 5.4633
	sim_grads_norm_tr = -0.0113
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4412
	data_grads_norm = 4.3160
	new_data_grads_norm = 5.7705
	old_data_grads_norm = 5.5508
	sim_grads_norm_tr = 0.0602
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3279
	data_grads_norm = 4.2513
	new_data_grads_norm = 6.0344
	old_data_grads_norm = 5.9631
	sim_grads_norm_tr = -0.0271
-- Starting training on experience 102 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2391
	data_grads_norm = 3.4204
	new_data_grads_norm = 5.1175
	old_data_grads_norm = 4.1296
	sim_grads_norm_tr = 0.0903
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5134
	data_grads_norm = 3.7515
	new_data_grads_norm = 5.2610
	old_data_grads_norm = 5.6477
	sim_grads_norm_tr = 0.0151
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1275
	data_grads_norm = 3.2169
	new_data_grads_norm = 5.1833
	old_data_grads_norm = 3.4895
	sim_grads_norm_tr = -0.0515
-- Starting training on experience 103 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6695
	data_grads_norm = 3.9874
	new_data_grads_norm = 5.2349
	old_data_grads_norm = 5.3232
	sim_grads_norm_tr = 0.0997
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3706
	data_grads_norm = 4.4304
	new_data_grads_norm = 5.3720
	old_data_grads_norm = 5.8662
	sim_grads_norm_tr = 0.0856
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4237
	data_grads_norm = 4.1069
	new_data_grads_norm = 5.3785
	old_data_grads_norm = 5.5369
	sim_grads_norm_tr = -0.0646
-- Starting training on experience 104 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4072
	data_grads_norm = 4.1460
	new_data_grads_norm = 5.3015
	old_data_grads_norm = 5.0982
	sim_grads_norm_tr = 0.1592
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3654
	data_grads_norm = 3.8704
	new_data_grads_norm = 4.9626
	old_data_grads_norm = 4.8845
	sim_grads_norm_tr = 0.0868
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3931
	data_grads_norm = 4.1956
	new_data_grads_norm = 4.5300
	old_data_grads_norm = 6.8378
	sim_grads_norm_tr = 0.0740
-- Starting training on experience 105 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3294
	data_grads_norm = 4.5020
	new_data_grads_norm = 6.0980
	old_data_grads_norm = 6.3741
	sim_grads_norm_tr = 0.1438
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1045
	data_grads_norm = 3.9317
	new_data_grads_norm = 5.9539
	old_data_grads_norm = 4.4052
	sim_grads_norm_tr = 0.0572
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4376
	data_grads_norm = 4.3588
	new_data_grads_norm = 5.8214
	old_data_grads_norm = 5.7208
	sim_grads_norm_tr = 0.1313
-- Starting training on experience 106 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2359
	data_grads_norm = 3.5549
	new_data_grads_norm = 4.9641
	old_data_grads_norm = 5.0430
	sim_grads_norm_tr = 0.0380
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8825
	data_grads_norm = 3.5740
	new_data_grads_norm = 4.6621
	old_data_grads_norm = 6.5335
	sim_grads_norm_tr = -0.1147
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1471
	data_grads_norm = 3.9038
	new_data_grads_norm = 5.4737
	old_data_grads_norm = 6.0219
	sim_grads_norm_tr = -0.0165
-- Starting training on experience 107 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7565
	data_grads_norm = 4.6273
	new_data_grads_norm = 6.0903
	old_data_grads_norm = 5.7705
	sim_grads_norm_tr = 0.1595
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9093
	data_grads_norm = 3.1657
	new_data_grads_norm = 5.6431
	old_data_grads_norm = 3.5164
	sim_grads_norm_tr = -0.0602
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4876
	data_grads_norm = 4.1727
	new_data_grads_norm = 6.0331
	old_data_grads_norm = 6.2082
	sim_grads_norm_tr = -0.0042
-- Starting training on experience 108 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2351
	data_grads_norm = 3.7037
	new_data_grads_norm = 6.0614
	old_data_grads_norm = 4.8622
	sim_grads_norm_tr = -0.0589
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6035
	data_grads_norm = 4.6019
	new_data_grads_norm = 6.0989
	old_data_grads_norm = 5.6248
	sim_grads_norm_tr = 0.0839
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5525
	data_grads_norm = 4.3344
	new_data_grads_norm = 6.1150
	old_data_grads_norm = 5.7975
	sim_grads_norm_tr = -0.0202
-- Starting training on experience 109 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7829
	data_grads_norm = 4.5540
	new_data_grads_norm = 6.2193
	old_data_grads_norm = 5.6404
	sim_grads_norm_tr = 0.0863
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1883
	data_grads_norm = 3.9594
	new_data_grads_norm = 5.4518
	old_data_grads_norm = 5.1258
	sim_grads_norm_tr = 0.0244
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8226
	data_grads_norm = 3.5315
	new_data_grads_norm = 5.5089
	old_data_grads_norm = 4.7266
	sim_grads_norm_tr = -0.0257
-- Starting training on experience 110 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5930
	data_grads_norm = 4.1779
	new_data_grads_norm = 5.2532
	old_data_grads_norm = 4.7577
	sim_grads_norm_tr = 0.0924
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1624
	data_grads_norm = 3.3722
	new_data_grads_norm = 4.9310
	old_data_grads_norm = 4.2852
	sim_grads_norm_tr = 0.0272
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5350
	data_grads_norm = 4.0261
	new_data_grads_norm = 5.2269
	old_data_grads_norm = 6.2574
	sim_grads_norm_tr = -0.0394
-- Starting training on experience 111 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1637
	data_grads_norm = 3.9009
	new_data_grads_norm = 4.7972
	old_data_grads_norm = 5.9844
	sim_grads_norm_tr = 0.0924
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8376
	data_grads_norm = 3.5329
	new_data_grads_norm = 5.1969
	old_data_grads_norm = 5.0080
	sim_grads_norm_tr = 0.0518
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3771
	data_grads_norm = 4.2415
	new_data_grads_norm = 5.5461
	old_data_grads_norm = 6.4347
	sim_grads_norm_tr = 0.0164
-- Starting training on experience 112 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3071
	data_grads_norm = 3.5700
	new_data_grads_norm = 5.2880
	old_data_grads_norm = 5.3985
	sim_grads_norm_tr = -0.0612
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2294
	data_grads_norm = 4.1021
	new_data_grads_norm = 5.3355
	old_data_grads_norm = 5.2707
	sim_grads_norm_tr = 0.0005
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2481
	data_grads_norm = 3.6724
	new_data_grads_norm = 5.8262
	old_data_grads_norm = 4.8067
	sim_grads_norm_tr = 0.0069
-- Starting training on experience 113 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3676
	data_grads_norm = 4.3972
	new_data_grads_norm = 5.0156
	old_data_grads_norm = 6.4403
	sim_grads_norm_tr = -0.0325
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1187
	data_grads_norm = 4.1282
	new_data_grads_norm = 5.0397
	old_data_grads_norm = 5.7220
	sim_grads_norm_tr = 0.1704
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7913
	data_grads_norm = 3.3885
	new_data_grads_norm = 5.0555
	old_data_grads_norm = 4.6375
	sim_grads_norm_tr = 0.0111
-- Starting training on experience 114 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0904
	data_grads_norm = 3.5835
	new_data_grads_norm = 6.0565
	old_data_grads_norm = 4.6009
	sim_grads_norm_tr = -0.1474
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2433
	data_grads_norm = 4.1046
	new_data_grads_norm = 6.5346
	old_data_grads_norm = 4.7359
	sim_grads_norm_tr = -0.1050
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1907
	data_grads_norm = 4.4818
	new_data_grads_norm = 6.7804
	old_data_grads_norm = 3.7812
	sim_grads_norm_tr = -0.0603
-- Starting training on experience 115 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5092
	data_grads_norm = 4.0083
	new_data_grads_norm = 7.1449
	old_data_grads_norm = 4.2237
	sim_grads_norm_tr = -0.0429
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3579
	data_grads_norm = 4.1432
	new_data_grads_norm = 6.8408
	old_data_grads_norm = 3.5688
	sim_grads_norm_tr = -0.0790
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4119
	data_grads_norm = 5.5060
	new_data_grads_norm = 7.0230
	old_data_grads_norm = 7.2061
	sim_grads_norm_tr = 0.0896
-- Starting training on experience 116 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2219
	data_grads_norm = 4.7842
	new_data_grads_norm = 6.3346
	old_data_grads_norm = 7.8919
	sim_grads_norm_tr = -0.0117
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4323
	data_grads_norm = 4.8174
	new_data_grads_norm = 6.5477
	old_data_grads_norm = 5.9259
	sim_grads_norm_tr = 0.0842
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1627
	data_grads_norm = 3.7038
	new_data_grads_norm = 5.8004
	old_data_grads_norm = 4.9094
	sim_grads_norm_tr = 0.0121
-- Starting training on experience 117 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5647
	data_grads_norm = 4.0075
	new_data_grads_norm = 5.9842
	old_data_grads_norm = 5.3272
	sim_grads_norm_tr = 0.0086
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8846
	data_grads_norm = 4.9913
	new_data_grads_norm = 6.1271
	old_data_grads_norm = 7.0381
	sim_grads_norm_tr = 0.0633
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4359
	data_grads_norm = 5.2642
	new_data_grads_norm = 5.9664
	old_data_grads_norm = 7.0234
	sim_grads_norm_tr = 0.1280
-- Starting training on experience 118 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8065
	data_grads_norm = 4.6368
	new_data_grads_norm = 6.3775
	old_data_grads_norm = 6.0132
	sim_grads_norm_tr = 0.0009
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4944
	data_grads_norm = 4.1300
	new_data_grads_norm = 6.1879
	old_data_grads_norm = 5.1520
	sim_grads_norm_tr = -0.0024
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7370
	data_grads_norm = 4.4960
	new_data_grads_norm = 6.2819
	old_data_grads_norm = 5.9320
	sim_grads_norm_tr = 0.0320
-- Starting training on experience 119 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8952
	data_grads_norm = 4.8254
	new_data_grads_norm = 5.1327
	old_data_grads_norm = 6.4594
	sim_grads_norm_tr = 0.0381
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5616
	data_grads_norm = 4.4329
	new_data_grads_norm = 5.1764
	old_data_grads_norm = 5.8859
	sim_grads_norm_tr = 0.0336
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3205
	data_grads_norm = 3.4393
	new_data_grads_norm = 4.9180
	old_data_grads_norm = 4.6708
	sim_grads_norm_tr = -0.0232
-- Starting training on experience 120 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1196
	data_grads_norm = 3.9523
	new_data_grads_norm = 6.0347
	old_data_grads_norm = 4.2793
	sim_grads_norm_tr = 0.0892
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1704
	data_grads_norm = 3.7871
	new_data_grads_norm = 6.3257
	old_data_grads_norm = 5.5239
	sim_grads_norm_tr = 0.1149
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2937
	data_grads_norm = 4.6582
	new_data_grads_norm = 5.9792
	old_data_grads_norm = 6.3945
	sim_grads_norm_tr = 0.0453
-- Starting training on experience 121 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7216
	data_grads_norm = 4.3177
	new_data_grads_norm = 6.1292
	old_data_grads_norm = 5.7573
	sim_grads_norm_tr = 0.1074
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3708
	data_grads_norm = 4.0303
	new_data_grads_norm = 5.4811
	old_data_grads_norm = 4.7200
	sim_grads_norm_tr = 0.1115
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0501
	data_grads_norm = 3.6151
	new_data_grads_norm = 5.2860
	old_data_grads_norm = 4.9924
	sim_grads_norm_tr = -0.0641
-- Starting training on experience 122 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9900
	data_grads_norm = 3.7994
	new_data_grads_norm = 5.1193
	old_data_grads_norm = 6.1603
	sim_grads_norm_tr = -0.0012
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9014
	data_grads_norm = 3.8782
	new_data_grads_norm = 5.4166
	old_data_grads_norm = 4.8480
	sim_grads_norm_tr = 0.0839
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1466
	data_grads_norm = 3.6767
	new_data_grads_norm = 4.7695
	old_data_grads_norm = 6.1324
	sim_grads_norm_tr = -0.1083
-- Starting training on experience 123 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6404
	data_grads_norm = 4.4194
	new_data_grads_norm = 5.5615
	old_data_grads_norm = 6.4281
	sim_grads_norm_tr = -0.0428
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6489
	data_grads_norm = 3.9780
	new_data_grads_norm = 5.2750
	old_data_grads_norm = 5.6255
	sim_grads_norm_tr = 0.1037
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3287
	data_grads_norm = 4.0993
	new_data_grads_norm = 5.8032
	old_data_grads_norm = 5.9656
	sim_grads_norm_tr = 0.0758
-- Starting training on experience 124 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5515
	data_grads_norm = 4.5033
	new_data_grads_norm = 5.9243
	old_data_grads_norm = 5.5930
	sim_grads_norm_tr = -0.0288
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7903
	data_grads_norm = 4.5997
	new_data_grads_norm = 6.2147
	old_data_grads_norm = 5.6792
	sim_grads_norm_tr = 0.1167
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2261
	data_grads_norm = 3.8377
	new_data_grads_norm = 5.8887
	old_data_grads_norm = 4.6258
	sim_grads_norm_tr = 0.0394
-- Starting training on experience 125 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0824
	data_grads_norm = 3.7522
	new_data_grads_norm = 5.9486
	old_data_grads_norm = 4.2587
	sim_grads_norm_tr = 0.0479
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3556
	data_grads_norm = 3.8450
	new_data_grads_norm = 5.6094
	old_data_grads_norm = 5.0925
	sim_grads_norm_tr = 0.0379
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5728
	data_grads_norm = 4.2591
	new_data_grads_norm = 5.2518
	old_data_grads_norm = 5.4395
	sim_grads_norm_tr = -0.0157
-- Starting training on experience 126 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2751
	data_grads_norm = 3.6797
	new_data_grads_norm = 5.0581
	old_data_grads_norm = 4.5276
	sim_grads_norm_tr = 0.0926
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5394
	data_grads_norm = 4.2309
	new_data_grads_norm = 5.5798
	old_data_grads_norm = 5.5910
	sim_grads_norm_tr = -0.0355
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1067
	data_grads_norm = 4.0836
	new_data_grads_norm = 5.2548
	old_data_grads_norm = 4.9927
	sim_grads_norm_tr = -0.0067
-- Starting training on experience 127 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3430
	data_grads_norm = 4.4464
	new_data_grads_norm = 6.0223
	old_data_grads_norm = 5.9061
	sim_grads_norm_tr = 0.0473
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3080
	data_grads_norm = 3.8876
	new_data_grads_norm = 5.9896
	old_data_grads_norm = 5.3131
	sim_grads_norm_tr = -0.0206
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2017
	data_grads_norm = 4.1054
	new_data_grads_norm = 6.2148
	old_data_grads_norm = 5.7261
	sim_grads_norm_tr = 0.0264
-- Starting training on experience 128 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3555
	data_grads_norm = 3.8608
	new_data_grads_norm = 5.2340
	old_data_grads_norm = 5.1624
	sim_grads_norm_tr = 0.1982
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2071
	data_grads_norm = 3.2101
	new_data_grads_norm = 4.9763
	old_data_grads_norm = 4.3995
	sim_grads_norm_tr = -0.0453
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5231
	data_grads_norm = 3.7448
	new_data_grads_norm = 5.3486
	old_data_grads_norm = 3.7004
	sim_grads_norm_tr = 0.0253
-- Starting training on experience 129 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4903
	data_grads_norm = 4.6382
	new_data_grads_norm = 6.0413
	old_data_grads_norm = 6.2810
	sim_grads_norm_tr = -0.0201
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6453
	data_grads_norm = 4.9405
	new_data_grads_norm = 5.6944
	old_data_grads_norm = 6.6936
	sim_grads_norm_tr = 0.0689
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0781
	data_grads_norm = 3.8491
	new_data_grads_norm = 5.7147
	old_data_grads_norm = 5.4735
	sim_grads_norm_tr = -0.0914
-- Starting training on experience 130 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3493
	data_grads_norm = 3.7341
	new_data_grads_norm = 6.1243
	old_data_grads_norm = 5.0985
	sim_grads_norm_tr = -0.1638
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5963
	data_grads_norm = 4.6940
	new_data_grads_norm = 6.3991
	old_data_grads_norm = 5.2510
	sim_grads_norm_tr = 0.1969
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3642
	data_grads_norm = 4.1919
	new_data_grads_norm = 5.9510
	old_data_grads_norm = 5.6072
	sim_grads_norm_tr = 0.0990
-- Starting training on experience 131 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0086
	data_grads_norm = 3.5992
	new_data_grads_norm = 6.1614
	old_data_grads_norm = 4.4784
	sim_grads_norm_tr = -0.0184
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5475
	data_grads_norm = 4.4183
	new_data_grads_norm = 6.4722
	old_data_grads_norm = 5.8029
	sim_grads_norm_tr = 0.0204
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9803
	data_grads_norm = 4.3300
	new_data_grads_norm = 6.4275
	old_data_grads_norm = 6.0790
	sim_grads_norm_tr = -0.0239
-- Starting training on experience 132 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4985
	data_grads_norm = 4.2050
	new_data_grads_norm = 5.9381
	old_data_grads_norm = 6.3657
	sim_grads_norm_tr = -0.0547
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0494
	data_grads_norm = 3.7562
	new_data_grads_norm = 6.0873
	old_data_grads_norm = 4.5614
	sim_grads_norm_tr = 0.0344
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1479
	data_grads_norm = 3.9509
	new_data_grads_norm = 6.3644
	old_data_grads_norm = 4.8214
	sim_grads_norm_tr = -0.0624
-- Starting training on experience 133 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1389
	data_grads_norm = 4.3023
	new_data_grads_norm = 5.4119
	old_data_grads_norm = 6.3635
	sim_grads_norm_tr = -0.0293
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0223
	data_grads_norm = 3.9522
	new_data_grads_norm = 5.7003
	old_data_grads_norm = 4.6048
	sim_grads_norm_tr = 0.0271
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3896
	data_grads_norm = 4.4333
	new_data_grads_norm = 5.9804
	old_data_grads_norm = 5.3377
	sim_grads_norm_tr = -0.0449
-- Starting training on experience 134 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4879
	data_grads_norm = 4.4755
	new_data_grads_norm = 6.3792
	old_data_grads_norm = 5.4325
	sim_grads_norm_tr = -0.0035
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1830
	data_grads_norm = 4.0937
	new_data_grads_norm = 6.3171
	old_data_grads_norm = 5.0737
	sim_grads_norm_tr = 0.0031
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0056
	data_grads_norm = 4.5459
	new_data_grads_norm = 5.8355
	old_data_grads_norm = 5.9099
	sim_grads_norm_tr = -0.0092
-- Starting training on experience 135 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7622
	data_grads_norm = 4.5130
	new_data_grads_norm = 5.9967
	old_data_grads_norm = 5.9802
	sim_grads_norm_tr = 0.0947
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5815
	data_grads_norm = 3.7919
	new_data_grads_norm = 5.7444
	old_data_grads_norm = 5.0027
	sim_grads_norm_tr = -0.0042
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1570
	data_grads_norm = 5.1834
	new_data_grads_norm = 6.2324
	old_data_grads_norm = 6.8125
	sim_grads_norm_tr = 0.2728
-- Starting training on experience 136 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4439
	data_grads_norm = 3.9633
	new_data_grads_norm = 5.9938
	old_data_grads_norm = 4.9197
	sim_grads_norm_tr = 0.0433
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5827
	data_grads_norm = 4.1891
	new_data_grads_norm = 6.3096
	old_data_grads_norm = 5.3293
	sim_grads_norm_tr = 0.0780
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7862
	data_grads_norm = 4.4375
	new_data_grads_norm = 6.1273
	old_data_grads_norm = 5.3542
	sim_grads_norm_tr = 0.1159
-- Starting training on experience 137 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0337
	data_grads_norm = 4.6314
	new_data_grads_norm = 5.9701
	old_data_grads_norm = 6.7350
	sim_grads_norm_tr = -0.0801
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3570
	data_grads_norm = 4.3136
	new_data_grads_norm = 6.3180
	old_data_grads_norm = 5.0336
	sim_grads_norm_tr = 0.1088
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5142
	data_grads_norm = 4.7682
	new_data_grads_norm = 6.0761
	old_data_grads_norm = 7.2876
	sim_grads_norm_tr = 0.0545
-- Starting training on experience 138 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8592
	data_grads_norm = 3.6076
	new_data_grads_norm = 4.8450
	old_data_grads_norm = 5.0057
	sim_grads_norm_tr = -0.0389
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3441
	data_grads_norm = 3.5974
	new_data_grads_norm = 5.0140
	old_data_grads_norm = 6.1447
	sim_grads_norm_tr = -0.0020
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3924
	data_grads_norm = 4.0753
	new_data_grads_norm = 5.1075
	old_data_grads_norm = 6.0952
	sim_grads_norm_tr = 0.0033
-- Starting training on experience 139 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2416
	data_grads_norm = 3.7745
	new_data_grads_norm = 5.7735
	old_data_grads_norm = 4.3159
	sim_grads_norm_tr = 0.0235
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4283
	data_grads_norm = 4.6844
	new_data_grads_norm = 6.1771
	old_data_grads_norm = 5.2357
	sim_grads_norm_tr = 0.1584
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2200
	data_grads_norm = 3.8514
	new_data_grads_norm = 5.4493
	old_data_grads_norm = 5.7646
	sim_grads_norm_tr = -0.0862
-- Starting training on experience 140 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2367
	data_grads_norm = 5.3860
	new_data_grads_norm = 6.9248
	old_data_grads_norm = 6.3141
	sim_grads_norm_tr = 0.0751
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3342
	data_grads_norm = 4.6725
	new_data_grads_norm = 6.4349
	old_data_grads_norm = 5.0626
	sim_grads_norm_tr = 0.0678
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5580
	data_grads_norm = 4.7448
	new_data_grads_norm = 6.5455
	old_data_grads_norm = 7.1472
	sim_grads_norm_tr = -0.0173
-- Starting training on experience 141 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4462
	data_grads_norm = 4.0874
	new_data_grads_norm = 5.7812
	old_data_grads_norm = 5.3034
	sim_grads_norm_tr = 0.0465
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9287
	data_grads_norm = 4.3458
	new_data_grads_norm = 5.8159
	old_data_grads_norm = 5.5396
	sim_grads_norm_tr = 0.1018
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5889
	data_grads_norm = 3.6026
	new_data_grads_norm = 5.8474
	old_data_grads_norm = 4.5125
	sim_grads_norm_tr = -0.0340
-- Starting training on experience 142 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0956
	data_grads_norm = 4.1484
	new_data_grads_norm = 5.3804
	old_data_grads_norm = 6.2940
	sim_grads_norm_tr = 0.0739
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4789
	data_grads_norm = 4.0018
	new_data_grads_norm = 5.0936
	old_data_grads_norm = 5.6617
	sim_grads_norm_tr = 0.0483
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8985
	data_grads_norm = 3.2943
	new_data_grads_norm = 5.0199
	old_data_grads_norm = 3.9209
	sim_grads_norm_tr = 0.0863
-- Starting training on experience 143 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1700
	data_grads_norm = 3.2549
	new_data_grads_norm = 5.7645
	old_data_grads_norm = 4.5239
	sim_grads_norm_tr = -0.0237
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3649
	data_grads_norm = 4.3634
	new_data_grads_norm = 5.7417
	old_data_grads_norm = 6.0441
	sim_grads_norm_tr = 0.1055
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2169
	data_grads_norm = 3.8204
	new_data_grads_norm = 6.1080
	old_data_grads_norm = 5.3835
	sim_grads_norm_tr = -0.0170
-- Starting training on experience 144 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0718
	data_grads_norm = 3.3605
	new_data_grads_norm = 5.6061
	old_data_grads_norm = 3.9747
	sim_grads_norm_tr = -0.0463
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5227
	data_grads_norm = 4.6262
	new_data_grads_norm = 5.7288
	old_data_grads_norm = 5.6044
	sim_grads_norm_tr = 0.1908
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7184
	data_grads_norm = 4.3178
	new_data_grads_norm = 5.6939
	old_data_grads_norm = 5.5782
	sim_grads_norm_tr = 0.1562
-- Starting training on experience 145 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3554
	data_grads_norm = 4.1982
	new_data_grads_norm = 5.3861
	old_data_grads_norm = 6.5555
	sim_grads_norm_tr = -0.0790
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9172
	data_grads_norm = 3.5779
	new_data_grads_norm = 5.8253
	old_data_grads_norm = 4.2106
	sim_grads_norm_tr = 0.0877
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2689
	data_grads_norm = 3.7816
	new_data_grads_norm = 6.1496
	old_data_grads_norm = 4.7625
	sim_grads_norm_tr = -0.0643
-- Starting training on experience 146 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4713
	data_grads_norm = 4.3814
	new_data_grads_norm = 5.3831
	old_data_grads_norm = 5.2483
	sim_grads_norm_tr = 0.0687
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4486
	data_grads_norm = 4.0391
	new_data_grads_norm = 5.6844
	old_data_grads_norm = 5.7966
	sim_grads_norm_tr = 0.0045
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4089
	data_grads_norm = 4.3631
	new_data_grads_norm = 5.2692
	old_data_grads_norm = 5.5509
	sim_grads_norm_tr = 0.2335
-- Starting training on experience 147 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1907
	data_grads_norm = 3.6830
	new_data_grads_norm = 5.4135
	old_data_grads_norm = 4.5123
	sim_grads_norm_tr = -0.1018
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8035
	data_grads_norm = 4.4072
	new_data_grads_norm = 6.3921
	old_data_grads_norm = 6.5463
	sim_grads_norm_tr = 0.0308
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6372
	data_grads_norm = 3.8009
	new_data_grads_norm = 6.1365
	old_data_grads_norm = 4.0707
	sim_grads_norm_tr = 0.1258
-- Starting training on experience 148 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7367
	data_grads_norm = 2.7852
	new_data_grads_norm = 4.6471
	old_data_grads_norm = 3.8897
	sim_grads_norm_tr = -0.1107
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3927
	data_grads_norm = 3.8942
	new_data_grads_norm = 5.1380
	old_data_grads_norm = 5.8915
	sim_grads_norm_tr = -0.0079
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1778
	data_grads_norm = 4.1226
	new_data_grads_norm = 5.8433
	old_data_grads_norm = 4.3176
	sim_grads_norm_tr = 0.0393
-- Starting training on experience 149 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3104
	data_grads_norm = 4.1071
	new_data_grads_norm = 5.6431
	old_data_grads_norm = 4.6191
	sim_grads_norm_tr = 0.1604
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1266
	data_grads_norm = 3.6760
	new_data_grads_norm = 5.9360
	old_data_grads_norm = 4.1878
	sim_grads_norm_tr = -0.0363
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4537
	data_grads_norm = 4.3849
	new_data_grads_norm = 5.5326
	old_data_grads_norm = 6.2450
	sim_grads_norm_tr = 0.0753
-- Starting training on experience 150 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5950
	data_grads_norm = 4.1834
	new_data_grads_norm = 5.8815
	old_data_grads_norm = 5.8402
	sim_grads_norm_tr = -0.0117
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2652
	data_grads_norm = 4.0559
	new_data_grads_norm = 5.4975
	old_data_grads_norm = 5.1485
	sim_grads_norm_tr = -0.0000
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9704
	data_grads_norm = 4.0973
	new_data_grads_norm = 6.0533
	old_data_grads_norm = 4.9020
	sim_grads_norm_tr = 0.0826
-- Starting training on experience 151 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5963
	data_grads_norm = 4.7867
	new_data_grads_norm = 6.2268
	old_data_grads_norm = 5.8688
	sim_grads_norm_tr = -0.0091
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1763
	data_grads_norm = 4.2424
	new_data_grads_norm = 6.4489
	old_data_grads_norm = 5.5451
	sim_grads_norm_tr = 0.0800
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1446
	data_grads_norm = 3.8550
	new_data_grads_norm = 6.8335
	old_data_grads_norm = 4.8523
	sim_grads_norm_tr = -0.0476
-- Starting training on experience 152 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0147
	data_grads_norm = 4.9792
	new_data_grads_norm = 7.6255
	old_data_grads_norm = 6.5680
	sim_grads_norm_tr = 0.0331
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0137
	data_grads_norm = 5.4664
	new_data_grads_norm = 7.3095
	old_data_grads_norm = 6.5747
	sim_grads_norm_tr = 0.1970
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1684
	data_grads_norm = 4.3326
	new_data_grads_norm = 6.5723
	old_data_grads_norm = 5.8262
	sim_grads_norm_tr = 0.0257
-- Starting training on experience 153 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9053
	data_grads_norm = 4.0327
	new_data_grads_norm = 5.9394
	old_data_grads_norm = 5.3516
	sim_grads_norm_tr = 0.0382
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3005
	data_grads_norm = 4.0842
	new_data_grads_norm = 5.5161
	old_data_grads_norm = 4.7647
	sim_grads_norm_tr = 0.2283
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9601
	data_grads_norm = 4.0204
	new_data_grads_norm = 5.5385
	old_data_grads_norm = 4.7918
	sim_grads_norm_tr = 0.0330
-- Starting training on experience 154 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9061
	data_grads_norm = 3.9664
	new_data_grads_norm = 5.6398
	old_data_grads_norm = 4.5655
	sim_grads_norm_tr = 0.0490
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4896
	data_grads_norm = 3.3268
	new_data_grads_norm = 4.9585
	old_data_grads_norm = 4.2559
	sim_grads_norm_tr = -0.0825
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9102
	data_grads_norm = 4.1736
	new_data_grads_norm = 5.7347
	old_data_grads_norm = 5.5505
	sim_grads_norm_tr = 0.0307
-- Starting training on experience 155 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6042
	data_grads_norm = 4.3667
	new_data_grads_norm = 6.9014
	old_data_grads_norm = 5.3727
	sim_grads_norm_tr = 0.0239
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7646
	data_grads_norm = 5.2979
	new_data_grads_norm = 6.9183
	old_data_grads_norm = 7.6275
	sim_grads_norm_tr = 0.0064
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7499
	data_grads_norm = 4.5831
	new_data_grads_norm = 6.3729
	old_data_grads_norm = 5.1410
	sim_grads_norm_tr = 0.0886
-- Starting training on experience 156 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4096
	data_grads_norm = 4.9037
	new_data_grads_norm = 6.4865
	old_data_grads_norm = 6.9269
	sim_grads_norm_tr = 0.0227
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5895
	data_grads_norm = 4.4323
	new_data_grads_norm = 7.0392
	old_data_grads_norm = 5.9578
	sim_grads_norm_tr = -0.0279
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6183
	data_grads_norm = 4.2758
	new_data_grads_norm = 6.7263
	old_data_grads_norm = 4.3894
	sim_grads_norm_tr = 0.0987
-- Starting training on experience 157 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1741
	data_grads_norm = 4.5340
	new_data_grads_norm = 6.1727
	old_data_grads_norm = 6.2575
	sim_grads_norm_tr = 0.0340
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1080
	data_grads_norm = 3.7624
	new_data_grads_norm = 5.7279
	old_data_grads_norm = 3.9106
	sim_grads_norm_tr = 0.2850
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1989
	data_grads_norm = 3.5414
	new_data_grads_norm = 4.9998
	old_data_grads_norm = 5.1736
	sim_grads_norm_tr = -0.0113
-- Starting training on experience 158 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5748
	data_grads_norm = 3.0714
	new_data_grads_norm = 4.8202
	old_data_grads_norm = 3.4442
	sim_grads_norm_tr = -0.0061
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1769
	data_grads_norm = 4.2427
	new_data_grads_norm = 5.1316
	old_data_grads_norm = 6.7515
	sim_grads_norm_tr = 0.0311
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4263
	data_grads_norm = 4.7667
	new_data_grads_norm = 5.7805
	old_data_grads_norm = 7.3712
	sim_grads_norm_tr = 0.0629
-- Starting training on experience 159 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7834
	data_grads_norm = 3.9792
	new_data_grads_norm = 5.4698
	old_data_grads_norm = 4.5108
	sim_grads_norm_tr = -0.0078
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2847
	data_grads_norm = 4.3754
	new_data_grads_norm = 6.0318
	old_data_grads_norm = 5.9762
	sim_grads_norm_tr = -0.0539
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3197
	data_grads_norm = 5.0531
	new_data_grads_norm = 6.0339
	old_data_grads_norm = 7.0247
	sim_grads_norm_tr = 0.0918
-- Starting training on experience 160 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1168
	data_grads_norm = 3.8316
	new_data_grads_norm = 6.0990
	old_data_grads_norm = 5.3239
	sim_grads_norm_tr = -0.0333
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3893
	data_grads_norm = 3.9692
	new_data_grads_norm = 6.2127
	old_data_grads_norm = 5.8013
	sim_grads_norm_tr = 0.0182
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1988
	data_grads_norm = 4.0653
	new_data_grads_norm = 6.4167
	old_data_grads_norm = 4.4370
	sim_grads_norm_tr = -0.0210
-- Starting training on experience 161 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1242
	data_grads_norm = 3.9265
	new_data_grads_norm = 6.2284
	old_data_grads_norm = 4.6034
	sim_grads_norm_tr = 0.2127
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9501
	data_grads_norm = 3.2073
	new_data_grads_norm = 5.2575
	old_data_grads_norm = 3.4388
	sim_grads_norm_tr = 0.1061
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6963
	data_grads_norm = 3.5936
	new_data_grads_norm = 5.0173
	old_data_grads_norm = 5.6429
	sim_grads_norm_tr = 0.0228
-- Starting training on experience 162 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0944
	data_grads_norm = 3.2741
	new_data_grads_norm = 5.3954
	old_data_grads_norm = 4.4533
	sim_grads_norm_tr = -0.0065
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4157
	data_grads_norm = 4.2731
	new_data_grads_norm = 5.5975
	old_data_grads_norm = 5.7639
	sim_grads_norm_tr = -0.0638
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6825
	data_grads_norm = 4.1632
	new_data_grads_norm = 5.9023
	old_data_grads_norm = 5.0990
	sim_grads_norm_tr = 0.1022
-- Starting training on experience 163 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8409
	data_grads_norm = 4.4386
	new_data_grads_norm = 5.6059
	old_data_grads_norm = 6.3455
	sim_grads_norm_tr = 0.0003
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4466
	data_grads_norm = 4.4816
	new_data_grads_norm = 6.7100
	old_data_grads_norm = 4.8757
	sim_grads_norm_tr = 0.1853
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3112
	data_grads_norm = 4.4056
	new_data_grads_norm = 6.1723
	old_data_grads_norm = 5.8585
	sim_grads_norm_tr = 0.0527
-- Starting training on experience 164 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1307
	data_grads_norm = 4.5096
	new_data_grads_norm = 6.2540
	old_data_grads_norm = 4.4871
	sim_grads_norm_tr = 0.0327
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6096
	data_grads_norm = 5.1699
	new_data_grads_norm = 6.3360
	old_data_grads_norm = 6.6131
	sim_grads_norm_tr = -0.0281
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6390
	data_grads_norm = 4.7865
	new_data_grads_norm = 6.1144
	old_data_grads_norm = 5.1379
	sim_grads_norm_tr = 0.1079
-- Starting training on experience 165 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9984
	data_grads_norm = 4.5249
	new_data_grads_norm = 7.0275
	old_data_grads_norm = 5.3392
	sim_grads_norm_tr = -0.0492
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4827
	data_grads_norm = 4.1772
	new_data_grads_norm = 6.8165
	old_data_grads_norm = 6.4336
	sim_grads_norm_tr = -0.0253
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4386
	data_grads_norm = 4.1269
	new_data_grads_norm = 6.5850
	old_data_grads_norm = 5.0047
	sim_grads_norm_tr = 0.0486
-- Starting training on experience 166 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5321
	data_grads_norm = 4.6137
	new_data_grads_norm = 5.7149
	old_data_grads_norm = 7.3134
	sim_grads_norm_tr = -0.0017
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3277
	data_grads_norm = 4.0026
	new_data_grads_norm = 5.7377
	old_data_grads_norm = 6.1684
	sim_grads_norm_tr = -0.0176
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9663
	data_grads_norm = 4.6267
	new_data_grads_norm = 5.7364
	old_data_grads_norm = 6.2820
	sim_grads_norm_tr = 0.1814
-- Starting training on experience 167 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9816
	data_grads_norm = 3.7666
	new_data_grads_norm = 5.1891
	old_data_grads_norm = 5.4372
	sim_grads_norm_tr = -0.0161
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1460
	data_grads_norm = 4.6507
	new_data_grads_norm = 5.8718
	old_data_grads_norm = 7.0080
	sim_grads_norm_tr = 0.0882
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0676
	data_grads_norm = 3.7016
	new_data_grads_norm = 5.3495
	old_data_grads_norm = 5.0354
	sim_grads_norm_tr = -0.0081
-- Starting training on experience 168 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0405
	data_grads_norm = 3.9864
	new_data_grads_norm = 6.2383
	old_data_grads_norm = 5.1265
	sim_grads_norm_tr = -0.0745
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0425
	data_grads_norm = 5.5480
	new_data_grads_norm = 6.4018
	old_data_grads_norm = 8.1368
	sim_grads_norm_tr = 0.1736
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8557
	data_grads_norm = 3.7375
	new_data_grads_norm = 5.2606
	old_data_grads_norm = 5.4621
	sim_grads_norm_tr = 0.0242
-- Starting training on experience 169 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1856
	data_grads_norm = 4.1085
	new_data_grads_norm = 5.5445
	old_data_grads_norm = 5.7815
	sim_grads_norm_tr = -0.0836
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2480
	data_grads_norm = 4.2830
	new_data_grads_norm = 5.9001
	old_data_grads_norm = 5.5396
	sim_grads_norm_tr = -0.0525
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3069
	data_grads_norm = 4.7840
	new_data_grads_norm = 6.3185
	old_data_grads_norm = 5.1995
	sim_grads_norm_tr = 0.1104
-- Starting training on experience 170 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6362
	data_grads_norm = 4.1552
	new_data_grads_norm = 6.0567
	old_data_grads_norm = 5.1374
	sim_grads_norm_tr = 0.1109
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5895
	data_grads_norm = 4.5262
	new_data_grads_norm = 5.7491
	old_data_grads_norm = 6.3358
	sim_grads_norm_tr = 0.0302
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7515
	data_grads_norm = 4.2879
	new_data_grads_norm = 5.6355
	old_data_grads_norm = 5.7280
	sim_grads_norm_tr = 0.0718
-- Starting training on experience 171 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5192
	data_grads_norm = 4.2010
	new_data_grads_norm = 5.7350
	old_data_grads_norm = 4.7841
	sim_grads_norm_tr = 0.1757
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1038
	data_grads_norm = 3.5196
	new_data_grads_norm = 5.3600
	old_data_grads_norm = 4.2904
	sim_grads_norm_tr = -0.0008
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3743
	data_grads_norm = 4.5908
	new_data_grads_norm = 6.0086
	old_data_grads_norm = 6.2883
	sim_grads_norm_tr = 0.0003
-- Starting training on experience 172 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0415
	data_grads_norm = 3.5228
	new_data_grads_norm = 5.2808
	old_data_grads_norm = 5.0881
	sim_grads_norm_tr = -0.0244
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2564
	data_grads_norm = 4.2817
	new_data_grads_norm = 5.9606
	old_data_grads_norm = 5.5123
	sim_grads_norm_tr = 0.0154
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4404
	data_grads_norm = 4.1591
	new_data_grads_norm = 6.1990
	old_data_grads_norm = 5.3959
	sim_grads_norm_tr = 0.0705
-- Starting training on experience 173 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9146
	data_grads_norm = 4.2686
	new_data_grads_norm = 5.6842
	old_data_grads_norm = 5.7376
	sim_grads_norm_tr = 0.0363
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9284
	data_grads_norm = 4.4051
	new_data_grads_norm = 5.6388
	old_data_grads_norm = 5.7193
	sim_grads_norm_tr = 0.0979
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6633
	data_grads_norm = 4.2909
	new_data_grads_norm = 5.4964
	old_data_grads_norm = 5.6451
	sim_grads_norm_tr = -0.0392
-- Starting training on experience 174 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3812
	data_grads_norm = 4.1531
	new_data_grads_norm = 5.4797
	old_data_grads_norm = 5.6847
	sim_grads_norm_tr = 0.1089
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1135
	data_grads_norm = 3.3340
	new_data_grads_norm = 4.9747
	old_data_grads_norm = 4.3955
	sim_grads_norm_tr = -0.0025
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4353
	data_grads_norm = 3.6442
	new_data_grads_norm = 5.4680
	old_data_grads_norm = 4.2727
	sim_grads_norm_tr = 0.0113
-- Starting training on experience 175 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1589
	data_grads_norm = 4.0245
	new_data_grads_norm = 5.9508
	old_data_grads_norm = 3.6228
	sim_grads_norm_tr = -0.0249
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2882
	data_grads_norm = 4.2746
	new_data_grads_norm = 5.4321
	old_data_grads_norm = 5.5210
	sim_grads_norm_tr = 0.0169
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4643
	data_grads_norm = 4.2547
	new_data_grads_norm = 5.8275
	old_data_grads_norm = 5.9046
	sim_grads_norm_tr = 0.0149
-- Starting training on experience 176 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3320
	data_grads_norm = 3.9968
	new_data_grads_norm = 5.8083
	old_data_grads_norm = 5.4392
	sim_grads_norm_tr = -0.0791
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6095
	data_grads_norm = 4.7353
	new_data_grads_norm = 6.3413
	old_data_grads_norm = 6.1519
	sim_grads_norm_tr = -0.0620
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7486
	data_grads_norm = 4.5128
	new_data_grads_norm = 6.7360
	old_data_grads_norm = 5.0826
	sim_grads_norm_tr = 0.1202
-- Starting training on experience 177 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9312
	data_grads_norm = 4.1500
	new_data_grads_norm = 6.2817
	old_data_grads_norm = 5.6165
	sim_grads_norm_tr = 0.0009
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8617
	data_grads_norm = 3.8725
	new_data_grads_norm = 6.3495
	old_data_grads_norm = 4.3869
	sim_grads_norm_tr = -0.0270
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2790
	data_grads_norm = 4.4761
	new_data_grads_norm = 6.4063
	old_data_grads_norm = 5.2055
	sim_grads_norm_tr = 0.0819
-- Starting training on experience 178 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4082
	data_grads_norm = 4.2741
	new_data_grads_norm = 5.6675
	old_data_grads_norm = 5.9322
	sim_grads_norm_tr = 0.0208
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8191
	data_grads_norm = 3.4203
	new_data_grads_norm = 5.3934
	old_data_grads_norm = 5.3653
	sim_grads_norm_tr = 0.0078
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9603
	data_grads_norm = 3.7139
	new_data_grads_norm = 5.2992
	old_data_grads_norm = 5.0429
	sim_grads_norm_tr = 0.0302
-- Starting training on experience 179 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5405
	data_grads_norm = 5.1960
	new_data_grads_norm = 6.9840
	old_data_grads_norm = 6.9367
	sim_grads_norm_tr = 0.0252
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6420
	data_grads_norm = 4.8568
	new_data_grads_norm = 6.5958
	old_data_grads_norm = 6.7253
	sim_grads_norm_tr = 0.0688
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1456
	data_grads_norm = 4.4152
	new_data_grads_norm = 6.9719
	old_data_grads_norm = 5.1411
	sim_grads_norm_tr = 0.0068
-- Starting training on experience 180 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2221
	data_grads_norm = 3.9755
	new_data_grads_norm = 5.7403
	old_data_grads_norm = 4.6339
	sim_grads_norm_tr = 0.0938
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6170
	data_grads_norm = 4.7654
	new_data_grads_norm = 6.0583
	old_data_grads_norm = 6.5410
	sim_grads_norm_tr = -0.0640
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8492
	data_grads_norm = 4.8440
	new_data_grads_norm = 5.9619
	old_data_grads_norm = 6.4124
	sim_grads_norm_tr = 0.0565
-- Starting training on experience 181 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3484
	data_grads_norm = 4.3936
	new_data_grads_norm = 6.1069
	old_data_grads_norm = 6.2302
	sim_grads_norm_tr = 0.0145
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9602
	data_grads_norm = 4.0308
	new_data_grads_norm = 5.7133
	old_data_grads_norm = 4.2005
	sim_grads_norm_tr = 0.1736
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1170
	data_grads_norm = 4.0984
	new_data_grads_norm = 5.7620
	old_data_grads_norm = 5.3886
	sim_grads_norm_tr = 0.0549
-- Starting training on experience 182 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7788
	data_grads_norm = 4.7260
	new_data_grads_norm = 6.4949
	old_data_grads_norm = 5.7466
	sim_grads_norm_tr = 0.0633
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3232
	data_grads_norm = 4.5894
	new_data_grads_norm = 6.7756
	old_data_grads_norm = 6.6265
	sim_grads_norm_tr = -0.0018
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1123
	data_grads_norm = 4.3586
	new_data_grads_norm = 7.1584
	old_data_grads_norm = 6.2741
	sim_grads_norm_tr = -0.0194
-- Starting training on experience 183 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2097
	data_grads_norm = 4.2016
	new_data_grads_norm = 5.4338
	old_data_grads_norm = 6.8391
	sim_grads_norm_tr = 0.0740
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0192
	data_grads_norm = 4.0519
	new_data_grads_norm = 5.2220
	old_data_grads_norm = 5.6980
	sim_grads_norm_tr = 0.0173
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1279
	data_grads_norm = 4.1442
	new_data_grads_norm = 5.3312
	old_data_grads_norm = 6.9086
	sim_grads_norm_tr = -0.0195
-- Starting training on experience 184 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7805
	data_grads_norm = 3.9137
	new_data_grads_norm = 6.2468
	old_data_grads_norm = 7.3551
	sim_grads_norm_tr = -0.0425
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3313
	data_grads_norm = 4.7474
	new_data_grads_norm = 5.7691
	old_data_grads_norm = 6.2834
	sim_grads_norm_tr = 0.0706
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1667
	data_grads_norm = 3.7661
	new_data_grads_norm = 5.8920
	old_data_grads_norm = 4.9535
	sim_grads_norm_tr = 0.0719
-- Starting training on experience 185 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4259
	data_grads_norm = 4.4716
	new_data_grads_norm = 5.8471
	old_data_grads_norm = 5.3486
	sim_grads_norm_tr = 0.0677
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3725
	data_grads_norm = 3.8362
	new_data_grads_norm = 5.8740
	old_data_grads_norm = 4.8125
	sim_grads_norm_tr = -0.0047
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9867
	data_grads_norm = 4.0213
	new_data_grads_norm = 5.4839
	old_data_grads_norm = 6.2770
	sim_grads_norm_tr = -0.0301
-- Starting training on experience 186 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2789
	data_grads_norm = 3.7092
	new_data_grads_norm = 5.9570
	old_data_grads_norm = 4.3163
	sim_grads_norm_tr = 0.1391
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0892
	data_grads_norm = 4.0793
	new_data_grads_norm = 5.3733
	old_data_grads_norm = 5.7571
	sim_grads_norm_tr = 0.0538
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1064
	data_grads_norm = 3.3861
	new_data_grads_norm = 5.0060
	old_data_grads_norm = 3.8943
	sim_grads_norm_tr = 0.0744
-- Starting training on experience 187 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9270
	data_grads_norm = 3.9119
	new_data_grads_norm = 5.7468
	old_data_grads_norm = 5.6509
	sim_grads_norm_tr = -0.0458
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0230
	data_grads_norm = 3.8279
	new_data_grads_norm = 5.2091
	old_data_grads_norm = 4.5421
	sim_grads_norm_tr = -0.0052
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4500
	data_grads_norm = 4.6693
	new_data_grads_norm = 5.7953
	old_data_grads_norm = 6.4654
	sim_grads_norm_tr = 0.0179
-- Starting training on experience 188 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3847
	data_grads_norm = 3.5381
	new_data_grads_norm = 5.6835
	old_data_grads_norm = 3.8307
	sim_grads_norm_tr = 0.0368
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9175
	data_grads_norm = 3.9911
	new_data_grads_norm = 6.0707
	old_data_grads_norm = 4.7118
	sim_grads_norm_tr = 0.1503
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0820
	data_grads_norm = 3.9105
	new_data_grads_norm = 5.6293
	old_data_grads_norm = 5.1236
	sim_grads_norm_tr = -0.0033
-- Starting training on experience 189 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2233
	data_grads_norm = 4.2151
	new_data_grads_norm = 5.9518
	old_data_grads_norm = 5.2492
	sim_grads_norm_tr = 0.0198
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9968
	data_grads_norm = 3.7371
	new_data_grads_norm = 6.1095
	old_data_grads_norm = 5.6199
	sim_grads_norm_tr = -0.1064
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7909
	data_grads_norm = 5.0645
	new_data_grads_norm = 6.5954
	old_data_grads_norm = 6.7423
	sim_grads_norm_tr = -0.0244
-- Starting training on experience 190 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2337
	data_grads_norm = 3.7532
	new_data_grads_norm = 5.8160
	old_data_grads_norm = 4.8315
	sim_grads_norm_tr = -0.0214
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9192
	data_grads_norm = 4.4549
	new_data_grads_norm = 6.2501
	old_data_grads_norm = 6.0619
	sim_grads_norm_tr = -0.0024
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5891
	data_grads_norm = 4.0512
	new_data_grads_norm = 6.0083
	old_data_grads_norm = 5.3389
	sim_grads_norm_tr = 0.0045
-- Starting training on experience 191 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9872
	data_grads_norm = 3.6735
	new_data_grads_norm = 5.6014
	old_data_grads_norm = 3.6422
	sim_grads_norm_tr = 0.0112
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2038
	data_grads_norm = 3.6799
	new_data_grads_norm = 6.0210
	old_data_grads_norm = 4.2421
	sim_grads_norm_tr = 0.0346
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1288
	data_grads_norm = 5.2571
	new_data_grads_norm = 5.8392
	old_data_grads_norm = 6.2303
	sim_grads_norm_tr = 0.0921
-- Starting training on experience 192 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2209
	data_grads_norm = 3.9618
	new_data_grads_norm = 6.4380
	old_data_grads_norm = 5.0737
	sim_grads_norm_tr = -0.1381
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1862
	data_grads_norm = 4.1537
	new_data_grads_norm = 6.3267
	old_data_grads_norm = 5.3265
	sim_grads_norm_tr = -0.0043
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1064
	data_grads_norm = 3.7092
	new_data_grads_norm = 5.5379
	old_data_grads_norm = 4.7203
	sim_grads_norm_tr = -0.0640
-- Starting training on experience 193 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8165
	data_grads_norm = 3.9639
	new_data_grads_norm = 5.1751
	old_data_grads_norm = 5.8195
	sim_grads_norm_tr = 0.0350
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8904
	data_grads_norm = 3.6821
	new_data_grads_norm = 5.4167
	old_data_grads_norm = 5.1322
	sim_grads_norm_tr = -0.0816
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0733
	data_grads_norm = 3.3274
	new_data_grads_norm = 5.4893
	old_data_grads_norm = 3.2438
	sim_grads_norm_tr = 0.1031
-- Starting training on experience 194 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3065
	data_grads_norm = 4.4711
	new_data_grads_norm = 6.3046
	old_data_grads_norm = 5.4216
	sim_grads_norm_tr = 0.0638
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2421
	data_grads_norm = 4.3539
	new_data_grads_norm = 6.0184
	old_data_grads_norm = 5.8997
	sim_grads_norm_tr = 0.0015
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0772
	data_grads_norm = 5.1100
	new_data_grads_norm = 5.8278
	old_data_grads_norm = 7.8375
	sim_grads_norm_tr = -0.0445
-- Starting training on experience 195 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2748
	data_grads_norm = 4.0099
	new_data_grads_norm = 5.9618
	old_data_grads_norm = 4.8204
	sim_grads_norm_tr = 0.0235
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3636
	data_grads_norm = 4.5184
	new_data_grads_norm = 6.1721
	old_data_grads_norm = 5.5428
	sim_grads_norm_tr = 0.0300
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1021
	data_grads_norm = 3.9891
	new_data_grads_norm = 5.8170
	old_data_grads_norm = 4.6602
	sim_grads_norm_tr = 0.0262
-- Starting training on experience 196 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8804
	data_grads_norm = 5.2332
	new_data_grads_norm = 6.2785
	old_data_grads_norm = 8.1491
	sim_grads_norm_tr = 0.1218
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8162
	data_grads_norm = 4.6890
	new_data_grads_norm = 6.3611
	old_data_grads_norm = 6.5912
	sim_grads_norm_tr = 0.0438
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4286
	data_grads_norm = 4.3979
	new_data_grads_norm = 5.1009
	old_data_grads_norm = 6.9237
	sim_grads_norm_tr = 0.0171
-- Starting training on experience 197 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1185
	data_grads_norm = 3.4917
	new_data_grads_norm = 5.3869
	old_data_grads_norm = 5.1156
	sim_grads_norm_tr = 0.0004
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5035
	data_grads_norm = 4.4301
	new_data_grads_norm = 5.9177
	old_data_grads_norm = 6.2285
	sim_grads_norm_tr = -0.0345
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3072
	data_grads_norm = 3.7267
	new_data_grads_norm = 5.9361
	old_data_grads_norm = 4.6584
	sim_grads_norm_tr = -0.0858
-- Starting training on experience 198 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2057
	data_grads_norm = 4.1889
	new_data_grads_norm = 5.5476
	old_data_grads_norm = 5.4619
	sim_grads_norm_tr = -0.0260
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7513
	data_grads_norm = 3.6829
	new_data_grads_norm = 5.8961
	old_data_grads_norm = 4.8099
	sim_grads_norm_tr = 0.0205
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1404
	data_grads_norm = 3.9649
	new_data_grads_norm = 5.5306
	old_data_grads_norm = 6.0139
	sim_grads_norm_tr = 0.0380
-- Starting training on experience 199 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3815
	data_grads_norm = 4.4400
	new_data_grads_norm = 5.4373
	old_data_grads_norm = 5.7304
	sim_grads_norm_tr = 0.0307
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4495
	data_grads_norm = 3.8958
	new_data_grads_norm = 5.1910
	old_data_grads_norm = 4.8847
	sim_grads_norm_tr = 0.1391
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9853
	data_grads_norm = 3.9273
	new_data_grads_norm = 5.3693
	old_data_grads_norm = 5.7777
	sim_grads_norm_tr = 0.0290
-- Starting training on experience 200 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7614
	data_grads_norm = 4.2840
	new_data_grads_norm = 6.4204
	old_data_grads_norm = 5.2344
	sim_grads_norm_tr = 0.0950
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4039
	data_grads_norm = 3.9785
	new_data_grads_norm = 5.8563
	old_data_grads_norm = 4.0522
	sim_grads_norm_tr = 0.2084
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2279
	data_grads_norm = 4.3083
	new_data_grads_norm = 5.6909
	old_data_grads_norm = 7.0572
	sim_grads_norm_tr = 0.0494
-- Starting training on experience 201 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5268
	data_grads_norm = 3.3334
	new_data_grads_norm = 5.3729
	old_data_grads_norm = 4.7801
	sim_grads_norm_tr = -0.0089
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8862
	data_grads_norm = 3.6115
	new_data_grads_norm = 5.1605
	old_data_grads_norm = 4.6494
	sim_grads_norm_tr = 0.0294
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3328
	data_grads_norm = 4.4696
	new_data_grads_norm = 6.2492
	old_data_grads_norm = 6.3524
	sim_grads_norm_tr = -0.0320
-- Starting training on experience 202 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1961
	data_grads_norm = 4.5929
	new_data_grads_norm = 5.7121
	old_data_grads_norm = 5.5590
	sim_grads_norm_tr = 0.0880
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3454
	data_grads_norm = 4.6455
	new_data_grads_norm = 6.2076
	old_data_grads_norm = 6.0481
	sim_grads_norm_tr = 0.1389
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9002
	data_grads_norm = 4.0653
	new_data_grads_norm = 5.0550
	old_data_grads_norm = 5.9001
	sim_grads_norm_tr = -0.0974
-- Starting training on experience 203 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5527
	data_grads_norm = 4.6629
	new_data_grads_norm = 6.1432
	old_data_grads_norm = 5.9187
	sim_grads_norm_tr = 0.1111
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9737
	data_grads_norm = 4.3333
	new_data_grads_norm = 6.0227
	old_data_grads_norm = 5.3633
	sim_grads_norm_tr = 0.0340
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7262
	data_grads_norm = 3.7012
	new_data_grads_norm = 6.0012
	old_data_grads_norm = 4.9233
	sim_grads_norm_tr = 0.0314
-- Starting training on experience 204 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6091
	data_grads_norm = 3.2895
	new_data_grads_norm = 4.8933
	old_data_grads_norm = 4.4347
	sim_grads_norm_tr = -0.0110
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5244
	data_grads_norm = 4.1843
	new_data_grads_norm = 4.9399
	old_data_grads_norm = 6.4455
	sim_grads_norm_tr = 0.0872
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7997
	data_grads_norm = 3.5463
	new_data_grads_norm = 5.2147
	old_data_grads_norm = 4.8368
	sim_grads_norm_tr = 0.0272
-- Starting training on experience 205 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7482
	data_grads_norm = 4.6161
	new_data_grads_norm = 6.0850
	old_data_grads_norm = 6.3215
	sim_grads_norm_tr = 0.0814
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9681
	data_grads_norm = 5.0633
	new_data_grads_norm = 6.5378
	old_data_grads_norm = 6.2711
	sim_grads_norm_tr = 0.0201
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5071
	data_grads_norm = 4.6857
	new_data_grads_norm = 5.7906
	old_data_grads_norm = 5.5649
	sim_grads_norm_tr = 0.0124
-- Starting training on experience 206 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2306
	data_grads_norm = 4.0025
	new_data_grads_norm = 5.8619
	old_data_grads_norm = 5.4214
	sim_grads_norm_tr = -0.0154
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4329
	data_grads_norm = 4.1798
	new_data_grads_norm = 6.0213
	old_data_grads_norm = 5.0893
	sim_grads_norm_tr = 0.0721
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6938
	data_grads_norm = 4.4438
	new_data_grads_norm = 5.8706
	old_data_grads_norm = 6.5253
	sim_grads_norm_tr = -0.0141
-- Starting training on experience 207 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1170
	data_grads_norm = 4.0370
	new_data_grads_norm = 6.1831
	old_data_grads_norm = 5.2484
	sim_grads_norm_tr = -0.0180
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0355
	data_grads_norm = 3.8997
	new_data_grads_norm = 5.7959
	old_data_grads_norm = 5.6763
	sim_grads_norm_tr = -0.0286
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5072
	data_grads_norm = 4.3815
	new_data_grads_norm = 5.5367
	old_data_grads_norm = 5.6988
	sim_grads_norm_tr = -0.0605
-- Starting training on experience 208 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3005
	data_grads_norm = 4.7161
	new_data_grads_norm = 5.7267
	old_data_grads_norm = 6.5133
	sim_grads_norm_tr = 0.1281
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3151
	data_grads_norm = 4.2450
	new_data_grads_norm = 5.4594
	old_data_grads_norm = 5.7858
	sim_grads_norm_tr = 0.0694
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5924
	data_grads_norm = 3.9565
	new_data_grads_norm = 5.4432
	old_data_grads_norm = 7.2737
	sim_grads_norm_tr = -0.0824
-- Starting training on experience 209 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1398
	data_grads_norm = 3.9727
	new_data_grads_norm = 6.1183
	old_data_grads_norm = 4.7926
	sim_grads_norm_tr = -0.0175
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4699
	data_grads_norm = 4.6277
	new_data_grads_norm = 6.3508
	old_data_grads_norm = 6.3803
	sim_grads_norm_tr = 0.0776
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5840
	data_grads_norm = 4.4472
	new_data_grads_norm = 6.0061
	old_data_grads_norm = 6.0320
	sim_grads_norm_tr = 0.2301
-- Starting training on experience 210 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9100
	data_grads_norm = 3.5094
	new_data_grads_norm = 5.0129
	old_data_grads_norm = 4.6418
	sim_grads_norm_tr = -0.0428
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0658
	data_grads_norm = 4.3516
	new_data_grads_norm = 5.3152
	old_data_grads_norm = 5.7502
	sim_grads_norm_tr = 0.0878
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0859
	data_grads_norm = 3.7025
	new_data_grads_norm = 5.2887
	old_data_grads_norm = 4.8122
	sim_grads_norm_tr = 0.0714
-- Starting training on experience 211 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0167
	data_grads_norm = 3.5139
	new_data_grads_norm = 5.4638
	old_data_grads_norm = 5.2601
	sim_grads_norm_tr = -0.0173
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6452
	data_grads_norm = 4.6614
	new_data_grads_norm = 5.9553
	old_data_grads_norm = 7.5678
	sim_grads_norm_tr = 0.0789
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3575
	data_grads_norm = 4.1998
	new_data_grads_norm = 5.3584
	old_data_grads_norm = 5.9384
	sim_grads_norm_tr = 0.1269
-- Starting training on experience 212 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3896
	data_grads_norm = 4.2288
	new_data_grads_norm = 5.7992
	old_data_grads_norm = 4.9896
	sim_grads_norm_tr = 0.1280
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5061
	data_grads_norm = 4.2777
	new_data_grads_norm = 5.8279
	old_data_grads_norm = 5.1235
	sim_grads_norm_tr = 0.0622
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1620
	data_grads_norm = 4.0865
	new_data_grads_norm = 5.7174
	old_data_grads_norm = 6.4524
	sim_grads_norm_tr = -0.0819
-- Starting training on experience 213 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8920
	data_grads_norm = 3.3153
	new_data_grads_norm = 5.2002
	old_data_grads_norm = 3.9646
	sim_grads_norm_tr = 0.0942
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1260
	data_grads_norm = 4.1969
	new_data_grads_norm = 5.4080
	old_data_grads_norm = 7.2278
	sim_grads_norm_tr = -0.0559
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9783
	data_grads_norm = 3.7037
	new_data_grads_norm = 5.6258
	old_data_grads_norm = 5.0625
	sim_grads_norm_tr = -0.0199
-- Starting training on experience 214 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7349
	data_grads_norm = 4.8036
	new_data_grads_norm = 6.2983
	old_data_grads_norm = 7.2135
	sim_grads_norm_tr = 0.0771
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3130
	data_grads_norm = 4.1603
	new_data_grads_norm = 5.8819
	old_data_grads_norm = 5.7488
	sim_grads_norm_tr = -0.0784
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6968
	data_grads_norm = 4.6198
	new_data_grads_norm = 6.2456
	old_data_grads_norm = 6.5058
	sim_grads_norm_tr = 0.1118
-- Starting training on experience 215 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9537
	data_grads_norm = 3.9117
	new_data_grads_norm = 5.7002
	old_data_grads_norm = 5.1648
	sim_grads_norm_tr = 0.0346
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8501
	data_grads_norm = 3.8410
	new_data_grads_norm = 5.4769
	old_data_grads_norm = 4.4408
	sim_grads_norm_tr = 0.0999
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2628
	data_grads_norm = 3.9327
	new_data_grads_norm = 5.3325
	old_data_grads_norm = 5.2115
	sim_grads_norm_tr = 0.0371
-- Starting training on experience 216 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9608
	data_grads_norm = 3.7492
	new_data_grads_norm = 5.6306
	old_data_grads_norm = 4.3722
	sim_grads_norm_tr = 0.0267
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0424
	data_grads_norm = 4.3391
	new_data_grads_norm = 5.6324
	old_data_grads_norm = 5.5259
	sim_grads_norm_tr = 0.0228
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0396
	data_grads_norm = 3.5923
	new_data_grads_norm = 5.5830
	old_data_grads_norm = 4.9743
	sim_grads_norm_tr = -0.1331
-- Starting training on experience 217 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9483
	data_grads_norm = 3.6103
	new_data_grads_norm = 5.5749
	old_data_grads_norm = 5.8845
	sim_grads_norm_tr = 0.0596
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3101
	data_grads_norm = 4.2298
	new_data_grads_norm = 5.6545
	old_data_grads_norm = 5.5259
	sim_grads_norm_tr = 0.0441
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9826
	data_grads_norm = 4.0541
	new_data_grads_norm = 5.9810
	old_data_grads_norm = 5.3846
	sim_grads_norm_tr = -0.0704
-- Starting training on experience 218 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5550
	data_grads_norm = 3.0214
	new_data_grads_norm = 4.8932
	old_data_grads_norm = 4.8796
	sim_grads_norm_tr = -0.0404
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8808
	data_grads_norm = 3.5075
	new_data_grads_norm = 4.6460
	old_data_grads_norm = 5.5698
	sim_grads_norm_tr = -0.0285
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4394
	data_grads_norm = 4.1230
	new_data_grads_norm = 4.9330
	old_data_grads_norm = 6.7624
	sim_grads_norm_tr = 0.0676
-- Starting training on experience 219 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3068
	data_grads_norm = 3.8498
	new_data_grads_norm = 6.0161
	old_data_grads_norm = 5.5461
	sim_grads_norm_tr = 0.0153
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3127
	data_grads_norm = 4.4213
	new_data_grads_norm = 6.0628
	old_data_grads_norm = 6.3752
	sim_grads_norm_tr = 0.0574
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9241
	data_grads_norm = 4.0177
	new_data_grads_norm = 6.0200
	old_data_grads_norm = 4.9779
	sim_grads_norm_tr = 0.0242
-- Starting training on experience 220 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3446
	data_grads_norm = 4.6392
	new_data_grads_norm = 7.3999
	old_data_grads_norm = 4.6933
	sim_grads_norm_tr = -0.0324
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2840
	data_grads_norm = 4.3511
	new_data_grads_norm = 6.7225
	old_data_grads_norm = 4.4100
	sim_grads_norm_tr = 0.0306
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2075
	data_grads_norm = 4.7774
	new_data_grads_norm = 6.8435
	old_data_grads_norm = 5.5471
	sim_grads_norm_tr = 0.0377
-- Starting training on experience 221 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3551
	data_grads_norm = 4.1243
	new_data_grads_norm = 5.6477
	old_data_grads_norm = 5.9564
	sim_grads_norm_tr = 0.0802
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0078
	data_grads_norm = 3.8602
	new_data_grads_norm = 5.8352
	old_data_grads_norm = 4.5803
	sim_grads_norm_tr = -0.0341
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7419
	data_grads_norm = 3.4204
	new_data_grads_norm = 6.0993
	old_data_grads_norm = 3.8257
	sim_grads_norm_tr = -0.0452
-- Starting training on experience 222 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5213
	data_grads_norm = 4.4864
	new_data_grads_norm = 6.5412
	old_data_grads_norm = 4.5858
	sim_grads_norm_tr = 0.0022
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2998
	data_grads_norm = 4.8504
	new_data_grads_norm = 6.4602
	old_data_grads_norm = 5.8419
	sim_grads_norm_tr = 0.0424
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5384
	data_grads_norm = 4.5391
	new_data_grads_norm = 6.6852
	old_data_grads_norm = 4.3150
	sim_grads_norm_tr = 0.0694
-- Starting training on experience 223 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3227
	data_grads_norm = 4.5033
	new_data_grads_norm = 6.7743
	old_data_grads_norm = 5.7403
	sim_grads_norm_tr = -0.0333
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0052
	data_grads_norm = 5.3755
	new_data_grads_norm = 6.4551
	old_data_grads_norm = 6.4478
	sim_grads_norm_tr = 0.3104
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9713
	data_grads_norm = 3.8761
	new_data_grads_norm = 5.8267
	old_data_grads_norm = 4.6319
	sim_grads_norm_tr = -0.0427
-- Starting training on experience 224 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4274
	data_grads_norm = 4.4122
	new_data_grads_norm = 6.6840
	old_data_grads_norm = 5.4376
	sim_grads_norm_tr = 0.0768
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1795
	data_grads_norm = 4.4043
	new_data_grads_norm = 6.2446
	old_data_grads_norm = 6.5002
	sim_grads_norm_tr = 0.0026
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0961
	data_grads_norm = 4.2596
	new_data_grads_norm = 5.9021
	old_data_grads_norm = 5.6499
	sim_grads_norm_tr = -0.0764
-- Starting training on experience 225 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4367
	data_grads_norm = 4.8599
	new_data_grads_norm = 7.2909
	old_data_grads_norm = 5.0512
	sim_grads_norm_tr = -0.0862
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3962
	data_grads_norm = 4.9254
	new_data_grads_norm = 8.0603
	old_data_grads_norm = 4.2583
	sim_grads_norm_tr = -0.0208
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2498
	data_grads_norm = 5.5236
	new_data_grads_norm = 8.3880
	old_data_grads_norm = 5.9527
	sim_grads_norm_tr = 0.0561
-- Starting training on experience 226 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4560
	data_grads_norm = 4.7394
	new_data_grads_norm = 7.7028
	old_data_grads_norm = 6.0653
	sim_grads_norm_tr = -0.0157
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9806
	data_grads_norm = 5.1524
	new_data_grads_norm = 7.2480
	old_data_grads_norm = 6.9237
	sim_grads_norm_tr = 0.1219
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3398
	data_grads_norm = 4.2420
	new_data_grads_norm = 7.0800
	old_data_grads_norm = 4.9280
	sim_grads_norm_tr = -0.0245
-- Starting training on experience 227 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0792
	data_grads_norm = 4.2288
	new_data_grads_norm = 5.5585
	old_data_grads_norm = 7.0237
	sim_grads_norm_tr = -0.0561
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3204
	data_grads_norm = 4.4448
	new_data_grads_norm = 5.5901
	old_data_grads_norm = 5.9423
	sim_grads_norm_tr = -0.0244
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7312
	data_grads_norm = 3.4952
	new_data_grads_norm = 5.4094
	old_data_grads_norm = 3.9238
	sim_grads_norm_tr = -0.0616
-- Starting training on experience 228 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0811
	data_grads_norm = 4.5734
	new_data_grads_norm = 6.3528
	old_data_grads_norm = 5.8568
	sim_grads_norm_tr = 0.0359
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8542
	data_grads_norm = 4.4953
	new_data_grads_norm = 6.5876
	old_data_grads_norm = 4.6694
	sim_grads_norm_tr = -0.0039
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0630
	data_grads_norm = 4.8824
	new_data_grads_norm = 6.4695
	old_data_grads_norm = 6.9132
	sim_grads_norm_tr = 0.0280
-- Starting training on experience 229 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1295
	data_grads_norm = 4.2721
	new_data_grads_norm = 5.7430
	old_data_grads_norm = 5.2587
	sim_grads_norm_tr = 0.0651
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0930
	data_grads_norm = 3.9907
	new_data_grads_norm = 6.0506
	old_data_grads_norm = 4.9767
	sim_grads_norm_tr = 0.0246
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8231
	data_grads_norm = 3.9787
	new_data_grads_norm = 6.3409
	old_data_grads_norm = 4.9404
	sim_grads_norm_tr = -0.0208
-- Starting training on experience 230 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5906
	data_grads_norm = 4.7214
	new_data_grads_norm = 6.4134
	old_data_grads_norm = 5.5930
	sim_grads_norm_tr = 0.0189
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2060
	data_grads_norm = 4.4207
	new_data_grads_norm = 6.1178
	old_data_grads_norm = 4.8905
	sim_grads_norm_tr = 0.1575
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6644
	data_grads_norm = 3.6041
	new_data_grads_norm = 5.7014
	old_data_grads_norm = 4.4244
	sim_grads_norm_tr = -0.1063
-- Starting training on experience 231 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5376
	data_grads_norm = 4.3111
	new_data_grads_norm = 6.7976
	old_data_grads_norm = 4.6795
	sim_grads_norm_tr = 0.1949
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3879
	data_grads_norm = 5.3456
	new_data_grads_norm = 6.5329
	old_data_grads_norm = 8.2230
	sim_grads_norm_tr = -0.0449
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9032
	data_grads_norm = 4.3952
	new_data_grads_norm = 7.8134
	old_data_grads_norm = 4.7725
	sim_grads_norm_tr = 0.0376
-- Starting training on experience 232 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0583
	data_grads_norm = 4.4704
	new_data_grads_norm = 6.4378
	old_data_grads_norm = 6.5136
	sim_grads_norm_tr = -0.0214
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1102
	data_grads_norm = 3.8114
	new_data_grads_norm = 5.9713
	old_data_grads_norm = 5.1410
	sim_grads_norm_tr = -0.1202
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1805
	data_grads_norm = 4.1049
	new_data_grads_norm = 6.3037
	old_data_grads_norm = 5.7475
	sim_grads_norm_tr = 0.0060
-- Starting training on experience 233 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5910
	data_grads_norm = 4.5474
	new_data_grads_norm = 5.9832
	old_data_grads_norm = 6.1976
	sim_grads_norm_tr = 0.0499
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9655
	data_grads_norm = 3.5403
	new_data_grads_norm = 5.3245
	old_data_grads_norm = 4.8082
	sim_grads_norm_tr = 0.0402
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1002
	data_grads_norm = 3.9829
	new_data_grads_norm = 5.3889
	old_data_grads_norm = 4.9669
	sim_grads_norm_tr = 0.1395
-- Starting training on experience 234 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0870
	data_grads_norm = 5.1924
	new_data_grads_norm = 7.1531
	old_data_grads_norm = 6.9248
	sim_grads_norm_tr = -0.0571
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5391
	data_grads_norm = 4.6269
	new_data_grads_norm = 7.6258
	old_data_grads_norm = 5.2216
	sim_grads_norm_tr = 0.0029
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3334
	data_grads_norm = 4.5172
	new_data_grads_norm = 6.7374
	old_data_grads_norm = 6.5393
	sim_grads_norm_tr = 0.0575
-- Starting training on experience 235 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4126
	data_grads_norm = 4.1574
	new_data_grads_norm = 5.2892
	old_data_grads_norm = 6.4507
	sim_grads_norm_tr = 0.0118
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3359
	data_grads_norm = 4.9407
	new_data_grads_norm = 6.3430
	old_data_grads_norm = 6.8369
	sim_grads_norm_tr = -0.0074
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3071
	data_grads_norm = 4.4282
	new_data_grads_norm = 6.2718
	old_data_grads_norm = 5.4663
	sim_grads_norm_tr = 0.0870
-- Starting training on experience 236 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5661
	data_grads_norm = 4.4102
	new_data_grads_norm = 6.2245
	old_data_grads_norm = 5.7677
	sim_grads_norm_tr = -0.0190
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8023
	data_grads_norm = 4.1121
	new_data_grads_norm = 6.8943
	old_data_grads_norm = 4.8347
	sim_grads_norm_tr = 0.0216
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2414
	data_grads_norm = 4.5132
	new_data_grads_norm = 6.2704
	old_data_grads_norm = 5.8759
	sim_grads_norm_tr = 0.0267
-- Starting training on experience 237 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
-- >> End of training phase << --
-- >> Start of eval phase << --
-- Starting eval on experience 0 (Task 0) from test stream --
> Eval on experience 0 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp000 = 1.9002
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.4640
	mb_index = 1190
	time = 271.7664
-- Starting eval on experience 1 (Task 0) from test stream --
> Eval on experience 1 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp001 = 1.4073
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.6080
-- Starting eval on experience 2 (Task 0) from test stream --
> Eval on experience 2 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp002 = 2.4340
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.2860
-- Starting eval on experience 3 (Task 0) from test stream --
> Eval on experience 3 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp003 = 1.4271
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.5900
-- Starting eval on experience 4 (Task 0) from test stream --
> Eval on experience 4 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp004 = 2.6256
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.1780
-- >> End of eval phase << --
	CumulativeAccuracy/eval_phase/test_stream/Exp000 = 0.7380
	CumulativeAccuracy/eval_phase/test_stream/Exp001 = 0.6730
	CumulativeAccuracy/eval_phase/test_stream/Exp002 = 0.5333
	CumulativeAccuracy/eval_phase/test_stream/Exp003 = 0.5010
	CumulativeAccuracy/eval_phase/test_stream/Exp004 = 0.4252
	Loss_Stream/eval_phase/test_stream/Task000 = 1.9588
	Top1_Acc_Stream/eval_phase/test_stream/Task000 = 0.4252
-- >> Start of training phase << --
-- Starting training on experience 0 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1509
	data_grads_norm = 4.5528
	new_data_grads_norm = 6.9868
	old_data_grads_norm = 6.1320
	sim_grads_norm_tr = -0.0202
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7657
	data_grads_norm = 6.0447
	new_data_grads_norm = 6.6603
	old_data_grads_norm = 8.3772
	sim_grads_norm_tr = 0.0936
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4701
	data_grads_norm = 4.6744
	new_data_grads_norm = 6.5018
	old_data_grads_norm = 6.6340
	sim_grads_norm_tr = -0.0271
-- Starting training on experience 1 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1868
	data_grads_norm = 4.2964
	new_data_grads_norm = 6.4708
	old_data_grads_norm = 4.9343
	sim_grads_norm_tr = 0.0170
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4400
	data_grads_norm = 4.6956
	new_data_grads_norm = 6.4257
	old_data_grads_norm = 5.8910
	sim_grads_norm_tr = 0.0095
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0811
	data_grads_norm = 3.7878
	new_data_grads_norm = 6.4486
	old_data_grads_norm = 5.0030
	sim_grads_norm_tr = -0.0123
-- Starting training on experience 2 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3173
	data_grads_norm = 4.0837
	new_data_grads_norm = 6.2778
	old_data_grads_norm = 5.3910
	sim_grads_norm_tr = -0.0469
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8203
	data_grads_norm = 3.2606
	new_data_grads_norm = 5.8388
	old_data_grads_norm = 3.9891
	sim_grads_norm_tr = 0.0342
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9580
	data_grads_norm = 3.6485
	new_data_grads_norm = 6.2204
	old_data_grads_norm = 4.1077
	sim_grads_norm_tr = 0.0026
-- Starting training on experience 3 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4693
	data_grads_norm = 4.2738
	new_data_grads_norm = 6.2474
	old_data_grads_norm = 5.6303
	sim_grads_norm_tr = 0.0016
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9217
	data_grads_norm = 4.2437
	new_data_grads_norm = 6.1468
	old_data_grads_norm = 5.6070
	sim_grads_norm_tr = 0.0365
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6181
	data_grads_norm = 4.9628
	new_data_grads_norm = 6.0691
	old_data_grads_norm = 6.6280
	sim_grads_norm_tr = 0.0201
-- Starting training on experience 4 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5558
	data_grads_norm = 4.6486
	new_data_grads_norm = 6.4944
	old_data_grads_norm = 5.3012
	sim_grads_norm_tr = 0.0636
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8202
	data_grads_norm = 4.8221
	new_data_grads_norm = 6.0900
	old_data_grads_norm = 6.3903
	sim_grads_norm_tr = 0.0266
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6486
	data_grads_norm = 4.3041
	new_data_grads_norm = 5.6468
	old_data_grads_norm = 6.4069
	sim_grads_norm_tr = -0.0201
-- Starting training on experience 5 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2975
	data_grads_norm = 4.7209
	new_data_grads_norm = 5.8772
	old_data_grads_norm = 5.6132
	sim_grads_norm_tr = 0.0353
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4476
	data_grads_norm = 3.9972
	new_data_grads_norm = 5.7968
	old_data_grads_norm = 4.7638
	sim_grads_norm_tr = 0.0372
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8328
	data_grads_norm = 3.3060
	new_data_grads_norm = 5.8698
	old_data_grads_norm = 3.8232
	sim_grads_norm_tr = -0.0293
-- Starting training on experience 6 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7732
	data_grads_norm = 4.4231
	new_data_grads_norm = 6.0517
	old_data_grads_norm = 6.3668
	sim_grads_norm_tr = -0.0530
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0737
	data_grads_norm = 4.2945
	new_data_grads_norm = 6.2108
	old_data_grads_norm = 6.1006
	sim_grads_norm_tr = 0.0703
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2168
	data_grads_norm = 4.2063
	new_data_grads_norm = 6.2406
	old_data_grads_norm = 5.2811
	sim_grads_norm_tr = -0.0035
-- Starting training on experience 7 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4736
	data_grads_norm = 4.3466
	new_data_grads_norm = 6.3905
	old_data_grads_norm = 5.8273
	sim_grads_norm_tr = 0.0292
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1571
	data_grads_norm = 3.7743
	new_data_grads_norm = 6.6597
	old_data_grads_norm = 4.7055
	sim_grads_norm_tr = -0.1155
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4765
	data_grads_norm = 4.3976
	new_data_grads_norm = 6.7751
	old_data_grads_norm = 4.8895
	sim_grads_norm_tr = 0.0463
-- Starting training on experience 8 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1021
	data_grads_norm = 3.8210
	new_data_grads_norm = 5.3262
	old_data_grads_norm = 5.2178
	sim_grads_norm_tr = -0.0077
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3639
	data_grads_norm = 4.4674
	new_data_grads_norm = 5.2700
	old_data_grads_norm = 7.6637
	sim_grads_norm_tr = -0.0183
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9329
	data_grads_norm = 3.7820
	new_data_grads_norm = 5.9052
	old_data_grads_norm = 3.8469
	sim_grads_norm_tr = -0.0283
-- Starting training on experience 9 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5782
	data_grads_norm = 4.2557
	new_data_grads_norm = 6.6291
	old_data_grads_norm = 5.8201
	sim_grads_norm_tr = 0.0313
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7588
	data_grads_norm = 4.5774
	new_data_grads_norm = 6.3872
	old_data_grads_norm = 6.1736
	sim_grads_norm_tr = 0.0646
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4568
	data_grads_norm = 4.6082
	new_data_grads_norm = 6.2701
	old_data_grads_norm = 5.7538
	sim_grads_norm_tr = 0.0482
-- Starting training on experience 10 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3036
	data_grads_norm = 4.1061
	new_data_grads_norm = 6.5507
	old_data_grads_norm = 5.9463
	sim_grads_norm_tr = 0.0037
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9012
	data_grads_norm = 4.9920
	new_data_grads_norm = 7.1236
	old_data_grads_norm = 6.2444
	sim_grads_norm_tr = 0.0793
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2178
	data_grads_norm = 4.7429
	new_data_grads_norm = 6.0844
	old_data_grads_norm = 6.8584
	sim_grads_norm_tr = -0.0249
-- Starting training on experience 11 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8258
	data_grads_norm = 4.9593
	new_data_grads_norm = 5.9541
	old_data_grads_norm = 6.0135
	sim_grads_norm_tr = 0.0509
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7930
	data_grads_norm = 3.3332
	new_data_grads_norm = 5.7794
	old_data_grads_norm = 4.2781
	sim_grads_norm_tr = -0.0474
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3577
	data_grads_norm = 4.5512
	new_data_grads_norm = 6.0973
	old_data_grads_norm = 5.7223
	sim_grads_norm_tr = -0.0123
-- Starting training on experience 12 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9146
	data_grads_norm = 4.5330
	new_data_grads_norm = 6.9786
	old_data_grads_norm = 5.2700
	sim_grads_norm_tr = 0.0782
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9538
	data_grads_norm = 3.9124
	new_data_grads_norm = 6.9008
	old_data_grads_norm = 3.6514
	sim_grads_norm_tr = -0.0242
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2966
	data_grads_norm = 4.1517
	new_data_grads_norm = 6.3471
	old_data_grads_norm = 5.3678
	sim_grads_norm_tr = -0.0305
-- Starting training on experience 13 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4472
	data_grads_norm = 4.4746
	new_data_grads_norm = 7.5933
	old_data_grads_norm = 4.8423
	sim_grads_norm_tr = 0.0534
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3186
	data_grads_norm = 4.3299
	new_data_grads_norm = 6.4474
	old_data_grads_norm = 5.5262
	sim_grads_norm_tr = 0.0456
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2848
	data_grads_norm = 4.1431
	new_data_grads_norm = 6.8844
	old_data_grads_norm = 5.1052
	sim_grads_norm_tr = 0.0329
-- Starting training on experience 14 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4116
	data_grads_norm = 4.5863
	new_data_grads_norm = 6.6429
	old_data_grads_norm = 5.5924
	sim_grads_norm_tr = -0.0088
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0813
	data_grads_norm = 4.5792
	new_data_grads_norm = 6.1380
	old_data_grads_norm = 5.3117
	sim_grads_norm_tr = 0.1670
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2272
	data_grads_norm = 4.1687
	new_data_grads_norm = 6.1321
	old_data_grads_norm = 5.6893
	sim_grads_norm_tr = 0.0148
-- Starting training on experience 15 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4710
	data_grads_norm = 4.4747
	new_data_grads_norm = 5.0227
	old_data_grads_norm = 6.9198
	sim_grads_norm_tr = 0.0327
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2136
	data_grads_norm = 4.0504
	new_data_grads_norm = 5.3362
	old_data_grads_norm = 4.8329
	sim_grads_norm_tr = -0.0260
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8435
	data_grads_norm = 3.1933
	new_data_grads_norm = 5.6954
	old_data_grads_norm = 4.0147
	sim_grads_norm_tr = -0.0397
-- Starting training on experience 16 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2795
	data_grads_norm = 4.1027
	new_data_grads_norm = 5.7379
	old_data_grads_norm = 5.7309
	sim_grads_norm_tr = 0.0172
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0293
	data_grads_norm = 4.6563
	new_data_grads_norm = 6.0380
	old_data_grads_norm = 6.3038
	sim_grads_norm_tr = 0.0576
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8577
	data_grads_norm = 3.3783
	new_data_grads_norm = 5.9214
	old_data_grads_norm = 3.9560
	sim_grads_norm_tr = 0.0011
-- Starting training on experience 17 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4832
	data_grads_norm = 4.0497
	new_data_grads_norm = 5.4930
	old_data_grads_norm = 5.9467
	sim_grads_norm_tr = 0.0173
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6285
	data_grads_norm = 4.1518
	new_data_grads_norm = 5.3628
	old_data_grads_norm = 6.0925
	sim_grads_norm_tr = 0.0840
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5610
	data_grads_norm = 4.1741
	new_data_grads_norm = 5.4073
	old_data_grads_norm = 6.1741
	sim_grads_norm_tr = 0.0628
-- Starting training on experience 18 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6914
	data_grads_norm = 3.4276
	new_data_grads_norm = 5.4441
	old_data_grads_norm = 4.3684
	sim_grads_norm_tr = -0.0275
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1055
	data_grads_norm = 3.9250
	new_data_grads_norm = 5.8412
	old_data_grads_norm = 4.8809
	sim_grads_norm_tr = -0.0288
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1501
	data_grads_norm = 4.2689
	new_data_grads_norm = 5.6954
	old_data_grads_norm = 5.0746
	sim_grads_norm_tr = -0.0595
-- Starting training on experience 19 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0135
	data_grads_norm = 4.0377
	new_data_grads_norm = 5.3790
	old_data_grads_norm = 6.6346
	sim_grads_norm_tr = 0.0833
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7774
	data_grads_norm = 5.0210
	new_data_grads_norm = 5.6801
	old_data_grads_norm = 5.4384
	sim_grads_norm_tr = 0.0548
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8895
	data_grads_norm = 3.6090
	new_data_grads_norm = 5.0597
	old_data_grads_norm = 4.1269
	sim_grads_norm_tr = 0.0395
-- Starting training on experience 20 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2769
	data_grads_norm = 4.0470
	new_data_grads_norm = 6.0844
	old_data_grads_norm = 4.8869
	sim_grads_norm_tr = 0.0583
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4569
	data_grads_norm = 4.3804
	new_data_grads_norm = 5.8816
	old_data_grads_norm = 5.5683
	sim_grads_norm_tr = 0.0584
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5308
	data_grads_norm = 4.3904
	new_data_grads_norm = 5.4410
	old_data_grads_norm = 6.3842
	sim_grads_norm_tr = 0.0882
-- Starting training on experience 21 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7171
	data_grads_norm = 3.6023
	new_data_grads_norm = 5.3240
	old_data_grads_norm = 4.9204
	sim_grads_norm_tr = 0.0332
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9785
	data_grads_norm = 3.8155
	new_data_grads_norm = 5.4090
	old_data_grads_norm = 4.7318
	sim_grads_norm_tr = 0.0984
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5910
	data_grads_norm = 3.6832
	new_data_grads_norm = 5.3280
	old_data_grads_norm = 5.4475
	sim_grads_norm_tr = -0.0626
-- Starting training on experience 22 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2168
	data_grads_norm = 4.8031
	new_data_grads_norm = 6.1761
	old_data_grads_norm = 6.2069
	sim_grads_norm_tr = 0.0591
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3779
	data_grads_norm = 4.3654
	new_data_grads_norm = 6.1705
	old_data_grads_norm = 5.6080
	sim_grads_norm_tr = 0.0365
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1147
	data_grads_norm = 4.9899
	new_data_grads_norm = 6.1961
	old_data_grads_norm = 7.4380
	sim_grads_norm_tr = -0.0069
-- Starting training on experience 23 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8487
	data_grads_norm = 4.0152
	new_data_grads_norm = 5.8720
	old_data_grads_norm = 5.6997
	sim_grads_norm_tr = 0.1068
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8752
	data_grads_norm = 3.8475
	new_data_grads_norm = 5.2846
	old_data_grads_norm = 5.2781
	sim_grads_norm_tr = -0.0059
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7059
	data_grads_norm = 4.0184
	new_data_grads_norm = 5.3905
	old_data_grads_norm = 7.1146
	sim_grads_norm_tr = -0.0818
-- Starting training on experience 24 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2036
	data_grads_norm = 4.4891
	new_data_grads_norm = 6.2023
	old_data_grads_norm = 5.6756
	sim_grads_norm_tr = -0.0242
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3297
	data_grads_norm = 4.1937
	new_data_grads_norm = 5.2123
	old_data_grads_norm = 5.8062
	sim_grads_norm_tr = -0.0088
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4364
	data_grads_norm = 4.5789
	new_data_grads_norm = 6.1300
	old_data_grads_norm = 5.8687
	sim_grads_norm_tr = 0.0775
-- Starting training on experience 25 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1209
	data_grads_norm = 3.8196
	new_data_grads_norm = 5.4263
	old_data_grads_norm = 5.2277
	sim_grads_norm_tr = -0.0155
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4376
	data_grads_norm = 4.3283
	new_data_grads_norm = 5.4039
	old_data_grads_norm = 5.6844
	sim_grads_norm_tr = 0.1497
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2591
	data_grads_norm = 3.9785
	new_data_grads_norm = 5.5790
	old_data_grads_norm = 5.5272
	sim_grads_norm_tr = -0.0120
-- Starting training on experience 26 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6179
	data_grads_norm = 4.0254
	new_data_grads_norm = 4.6452
	old_data_grads_norm = 5.7199
	sim_grads_norm_tr = 0.1133
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2856
	data_grads_norm = 3.0207
	new_data_grads_norm = 4.1493
	old_data_grads_norm = 4.9551
	sim_grads_norm_tr = -0.0543
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7373
	data_grads_norm = 3.6774
	new_data_grads_norm = 4.3239
	old_data_grads_norm = 5.6998
	sim_grads_norm_tr = 0.0231
-- Starting training on experience 27 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8753
	data_grads_norm = 4.3800
	new_data_grads_norm = 5.6802
	old_data_grads_norm = 6.1421
	sim_grads_norm_tr = 0.0203
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4753
	data_grads_norm = 3.4664
	new_data_grads_norm = 5.2645
	old_data_grads_norm = 4.3088
	sim_grads_norm_tr = 0.0161
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7421
	data_grads_norm = 3.9607
	new_data_grads_norm = 5.5450
	old_data_grads_norm = 5.4171
	sim_grads_norm_tr = 0.0014
-- Starting training on experience 28 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9258
	data_grads_norm = 3.4338
	new_data_grads_norm = 3.9911
	old_data_grads_norm = 4.7409
	sim_grads_norm_tr = 0.0910
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7936
	data_grads_norm = 3.4854
	new_data_grads_norm = 4.1079
	old_data_grads_norm = 4.0600
	sim_grads_norm_tr = 0.1130
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6652
	data_grads_norm = 3.0283
	new_data_grads_norm = 4.1671
	old_data_grads_norm = 4.2207
	sim_grads_norm_tr = -0.0309
-- Starting training on experience 29 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0228
	data_grads_norm = 4.3608
	new_data_grads_norm = 5.4537
	old_data_grads_norm = 6.2573
	sim_grads_norm_tr = 0.0346
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5484
	data_grads_norm = 3.9841
	new_data_grads_norm = 5.0750
	old_data_grads_norm = 6.3870
	sim_grads_norm_tr = -0.0313
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9441
	data_grads_norm = 3.5532
	new_data_grads_norm = 5.4818
	old_data_grads_norm = 4.1159
	sim_grads_norm_tr = 0.1087
-- Starting training on experience 30 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9789
	data_grads_norm = 3.8510
	new_data_grads_norm = 5.6781
	old_data_grads_norm = 4.8611
	sim_grads_norm_tr = 0.0472
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8867
	data_grads_norm = 3.8348
	new_data_grads_norm = 5.7627
	old_data_grads_norm = 4.4650
	sim_grads_norm_tr = 0.0116
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3195
	data_grads_norm = 3.4305
	new_data_grads_norm = 5.9257
	old_data_grads_norm = 4.9223
	sim_grads_norm_tr = 0.0405
-- Starting training on experience 31 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5609
	data_grads_norm = 3.6988
	new_data_grads_norm = 5.4781
	old_data_grads_norm = 4.5061
	sim_grads_norm_tr = 0.0208
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6837
	data_grads_norm = 3.6515
	new_data_grads_norm = 5.3897
	old_data_grads_norm = 4.7829
	sim_grads_norm_tr = -0.0495
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7468
	data_grads_norm = 3.4532
	new_data_grads_norm = 5.4320
	old_data_grads_norm = 4.4055
	sim_grads_norm_tr = -0.0697
-- Starting training on experience 32 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7822
	data_grads_norm = 3.9588
	new_data_grads_norm = 4.6406
	old_data_grads_norm = 4.9758
	sim_grads_norm_tr = 0.0955
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6093
	data_grads_norm = 3.6199
	new_data_grads_norm = 5.6300
	old_data_grads_norm = 5.1491
	sim_grads_norm_tr = -0.0432
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5486
	data_grads_norm = 3.6882
	new_data_grads_norm = 5.8115
	old_data_grads_norm = 4.9859
	sim_grads_norm_tr = -0.0090
-- Starting training on experience 33 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3057
	data_grads_norm = 4.5331
	new_data_grads_norm = 5.9422
	old_data_grads_norm = 5.9707
	sim_grads_norm_tr = 0.0397
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6641
	data_grads_norm = 3.7255
	new_data_grads_norm = 4.9334
	old_data_grads_norm = 5.3980
	sim_grads_norm_tr = -0.0097
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1566
	data_grads_norm = 3.6542
	new_data_grads_norm = 5.1961
	old_data_grads_norm = 4.4631
	sim_grads_norm_tr = 0.1037
-- Starting training on experience 34 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8126
	data_grads_norm = 3.8430
	new_data_grads_norm = 4.8566
	old_data_grads_norm = 5.5133
	sim_grads_norm_tr = 0.0685
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4127
	data_grads_norm = 4.5424
	new_data_grads_norm = 5.5654
	old_data_grads_norm = 6.5212
	sim_grads_norm_tr = 0.0827
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8287
	data_grads_norm = 3.5763
	new_data_grads_norm = 5.3336
	old_data_grads_norm = 4.8162
	sim_grads_norm_tr = 0.0085
-- Starting training on experience 35 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6677
	data_grads_norm = 3.7227
	new_data_grads_norm = 5.1260
	old_data_grads_norm = 4.5446
	sim_grads_norm_tr = 0.0531
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8233
	data_grads_norm = 4.0058
	new_data_grads_norm = 4.9948
	old_data_grads_norm = 5.5121
	sim_grads_norm_tr = -0.0169
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9546
	data_grads_norm = 4.3090
	new_data_grads_norm = 5.2453
	old_data_grads_norm = 5.8430
	sim_grads_norm_tr = 0.0548
-- Starting training on experience 36 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9316
	data_grads_norm = 3.9141
	new_data_grads_norm = 4.4111
	old_data_grads_norm = 5.8527
	sim_grads_norm_tr = -0.0030
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6007
	data_grads_norm = 3.6644
	new_data_grads_norm = 5.2524
	old_data_grads_norm = 4.7731
	sim_grads_norm_tr = -0.0010
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7922
	data_grads_norm = 4.1170
	new_data_grads_norm = 4.6969
	old_data_grads_norm = 6.3144
	sim_grads_norm_tr = 0.0144
-- Starting training on experience 37 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6057
	data_grads_norm = 3.5652
	new_data_grads_norm = 5.1129
	old_data_grads_norm = 5.6228
	sim_grads_norm_tr = -0.0889
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8558
	data_grads_norm = 4.1661
	new_data_grads_norm = 5.7308
	old_data_grads_norm = 5.7124
	sim_grads_norm_tr = 0.1231
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8509
	data_grads_norm = 3.8712
	new_data_grads_norm = 5.2404
	old_data_grads_norm = 5.0054
	sim_grads_norm_tr = 0.0690
-- Starting training on experience 38 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9656
	data_grads_norm = 3.8825
	new_data_grads_norm = 5.7749
	old_data_grads_norm = 4.2416
	sim_grads_norm_tr = 0.2109
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5496
	data_grads_norm = 3.6882
	new_data_grads_norm = 5.3774
	old_data_grads_norm = 5.4596
	sim_grads_norm_tr = 0.0015
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9647
	data_grads_norm = 4.1231
	new_data_grads_norm = 5.9058
	old_data_grads_norm = 6.2775
	sim_grads_norm_tr = -0.0307
-- Starting training on experience 39 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7040
	data_grads_norm = 3.7098
	new_data_grads_norm = 5.0516
	old_data_grads_norm = 5.3627
	sim_grads_norm_tr = 0.0245
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7474
	data_grads_norm = 3.6968
	new_data_grads_norm = 5.2269
	old_data_grads_norm = 5.1119
	sim_grads_norm_tr = -0.0306
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9092
	data_grads_norm = 4.5026
	new_data_grads_norm = 5.6515
	old_data_grads_norm = 6.7174
	sim_grads_norm_tr = -0.0017
-- Starting training on experience 40 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6909
	data_grads_norm = 3.5853
	new_data_grads_norm = 5.3446
	old_data_grads_norm = 5.2755
	sim_grads_norm_tr = -0.0668
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9598
	data_grads_norm = 4.4907
	new_data_grads_norm = 5.3995
	old_data_grads_norm = 6.6268
	sim_grads_norm_tr = 0.0020
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8404
	data_grads_norm = 3.8110
	new_data_grads_norm = 5.5859
	old_data_grads_norm = 4.6657
	sim_grads_norm_tr = 0.0414
-- Starting training on experience 41 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8729
	data_grads_norm = 4.7234
	new_data_grads_norm = 5.6293
	old_data_grads_norm = 6.7035
	sim_grads_norm_tr = -0.0172
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5966
	data_grads_norm = 3.8163
	new_data_grads_norm = 5.6271
	old_data_grads_norm = 5.2205
	sim_grads_norm_tr = 0.0458
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8895
	data_grads_norm = 4.5529
	new_data_grads_norm = 5.9225
	old_data_grads_norm = 5.2485
	sim_grads_norm_tr = 0.1274
-- Starting training on experience 42 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3714
	data_grads_norm = 4.3344
	new_data_grads_norm = 5.8169
	old_data_grads_norm = 6.1245
	sim_grads_norm_tr = 0.0246
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4390
	data_grads_norm = 3.8978
	new_data_grads_norm = 5.2675
	old_data_grads_norm = 5.6720
	sim_grads_norm_tr = -0.0657
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7283
	data_grads_norm = 4.5250
	new_data_grads_norm = 5.9669
	old_data_grads_norm = 6.1993
	sim_grads_norm_tr = 0.0440
-- Starting training on experience 43 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1574
	data_grads_norm = 3.3121
	new_data_grads_norm = 5.4768
	old_data_grads_norm = 3.9659
	sim_grads_norm_tr = 0.2036
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2168
	data_grads_norm = 3.6967
	new_data_grads_norm = 5.3007
	old_data_grads_norm = 5.6462
	sim_grads_norm_tr = -0.0250
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4007
	data_grads_norm = 4.0337
	new_data_grads_norm = 5.6024
	old_data_grads_norm = 5.6735
	sim_grads_norm_tr = -0.0433
-- Starting training on experience 44 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0506
	data_grads_norm = 4.7450
	new_data_grads_norm = 6.0033
	old_data_grads_norm = 7.7254
	sim_grads_norm_tr = 0.0105
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9771
	data_grads_norm = 4.1637
	new_data_grads_norm = 5.9076
	old_data_grads_norm = 5.7164
	sim_grads_norm_tr = -0.0144
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6245
	data_grads_norm = 3.7400
	new_data_grads_norm = 6.2430
	old_data_grads_norm = 4.2267
	sim_grads_norm_tr = -0.0194
-- Starting training on experience 45 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8512
	data_grads_norm = 4.9013
	new_data_grads_norm = 5.5944
	old_data_grads_norm = 6.9831
	sim_grads_norm_tr = 0.1150
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5930
	data_grads_norm = 3.8303
	new_data_grads_norm = 5.5138
	old_data_grads_norm = 5.3837
	sim_grads_norm_tr = -0.0276
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5950
	data_grads_norm = 4.6645
	new_data_grads_norm = 5.5065
	old_data_grads_norm = 6.4379
	sim_grads_norm_tr = -0.0069
-- Starting training on experience 46 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4971
	data_grads_norm = 4.2046
	new_data_grads_norm = 5.4000
	old_data_grads_norm = 6.3082
	sim_grads_norm_tr = 0.0138
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5491
	data_grads_norm = 4.5578
	new_data_grads_norm = 5.2653
	old_data_grads_norm = 5.5530
	sim_grads_norm_tr = -0.0421
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1593
	data_grads_norm = 4.7235
	new_data_grads_norm = 5.7059
	old_data_grads_norm = 6.4263
	sim_grads_norm_tr = 0.0673
-- Starting training on experience 47 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9440
	data_grads_norm = 3.8854
	new_data_grads_norm = 5.4375
	old_data_grads_norm = 5.3599
	sim_grads_norm_tr = 0.0470
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0791
	data_grads_norm = 4.1176
	new_data_grads_norm = 5.7171
	old_data_grads_norm = 5.3813
	sim_grads_norm_tr = 0.0725
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8236
	data_grads_norm = 4.4484
	new_data_grads_norm = 5.0352
	old_data_grads_norm = 6.5262
	sim_grads_norm_tr = -0.0151
-- Starting training on experience 48 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8367
	data_grads_norm = 4.7276
	new_data_grads_norm = 5.3948
	old_data_grads_norm = 7.1573
	sim_grads_norm_tr = -0.0341
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1381
	data_grads_norm = 4.4223
	new_data_grads_norm = 5.4063
	old_data_grads_norm = 6.1840
	sim_grads_norm_tr = 0.1333
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7717
	data_grads_norm = 4.2909
	new_data_grads_norm = 5.2267
	old_data_grads_norm = 5.9220
	sim_grads_norm_tr = 0.1273
-- Starting training on experience 49 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2404
	data_grads_norm = 3.3607
	new_data_grads_norm = 4.5497
	old_data_grads_norm = 4.8329
	sim_grads_norm_tr = 0.0711
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6749
	data_grads_norm = 3.6200
	new_data_grads_norm = 5.0918
	old_data_grads_norm = 5.0414
	sim_grads_norm_tr = -0.0282
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3963
	data_grads_norm = 3.2597
	new_data_grads_norm = 4.7332
	old_data_grads_norm = 4.6706
	sim_grads_norm_tr = 0.0111
-- Starting training on experience 50 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6884
	data_grads_norm = 3.7240
	new_data_grads_norm = 5.3455
	old_data_grads_norm = 5.0123
	sim_grads_norm_tr = 0.0557
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9666
	data_grads_norm = 3.9180
	new_data_grads_norm = 5.7804
	old_data_grads_norm = 4.8507
	sim_grads_norm_tr = 0.1291
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2447
	data_grads_norm = 3.5871
	new_data_grads_norm = 5.4545
	old_data_grads_norm = 4.9388
	sim_grads_norm_tr = -0.0496
-- Starting training on experience 51 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8506
	data_grads_norm = 3.9342
	new_data_grads_norm = 4.5425
	old_data_grads_norm = 5.6511
	sim_grads_norm_tr = 0.1008
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5045
	data_grads_norm = 3.7737
	new_data_grads_norm = 4.1823
	old_data_grads_norm = 5.7959
	sim_grads_norm_tr = -0.0425
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5458
	data_grads_norm = 4.3124
	new_data_grads_norm = 4.4455
	old_data_grads_norm = 5.8690
	sim_grads_norm_tr = 0.1031
-- Starting training on experience 52 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7545
	data_grads_norm = 3.6749
	new_data_grads_norm = 5.0556
	old_data_grads_norm = 5.1633
	sim_grads_norm_tr = -0.0046
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6416
	data_grads_norm = 4.0854
	new_data_grads_norm = 4.8018
	old_data_grads_norm = 5.4865
	sim_grads_norm_tr = 0.2043
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7128
	data_grads_norm = 3.9647
	new_data_grads_norm = 4.6994
	old_data_grads_norm = 5.5792
	sim_grads_norm_tr = 0.0297
-- Starting training on experience 53 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9695
	data_grads_norm = 3.5920
	new_data_grads_norm = 5.0823
	old_data_grads_norm = 5.3005
	sim_grads_norm_tr = -0.0270
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5666
	data_grads_norm = 4.6419
	new_data_grads_norm = 5.6185
	old_data_grads_norm = 6.3189
	sim_grads_norm_tr = 0.0303
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3356
	data_grads_norm = 3.6665
	new_data_grads_norm = 4.9362
	old_data_grads_norm = 4.9378
	sim_grads_norm_tr = 0.0815
-- Starting training on experience 54 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4283
	data_grads_norm = 4.2586
	new_data_grads_norm = 5.2706
	old_data_grads_norm = 5.9810
	sim_grads_norm_tr = 0.0573
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1717
	data_grads_norm = 3.6068
	new_data_grads_norm = 5.0969
	old_data_grads_norm = 4.4695
	sim_grads_norm_tr = -0.0451
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1537
	data_grads_norm = 3.4710
	new_data_grads_norm = 4.9087
	old_data_grads_norm = 5.9846
	sim_grads_norm_tr = -0.0431
-- Starting training on experience 55 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0732
	data_grads_norm = 4.1183
	new_data_grads_norm = 4.9639
	old_data_grads_norm = 5.6369
	sim_grads_norm_tr = 0.1172
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9023
	data_grads_norm = 4.6474
	new_data_grads_norm = 4.8421
	old_data_grads_norm = 6.1717
	sim_grads_norm_tr = 0.0047
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1616
	data_grads_norm = 3.1852
	new_data_grads_norm = 5.1354
	old_data_grads_norm = 4.4478
	sim_grads_norm_tr = -0.1162
-- Starting training on experience 56 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9798
	data_grads_norm = 4.2808
	new_data_grads_norm = 5.4548
	old_data_grads_norm = 6.7597
	sim_grads_norm_tr = -0.0189
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8010
	data_grads_norm = 4.0018
	new_data_grads_norm = 5.4598
	old_data_grads_norm = 5.3014
	sim_grads_norm_tr = -0.0276
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6754
	data_grads_norm = 4.4353
	new_data_grads_norm = 5.6123
	old_data_grads_norm = 5.5233
	sim_grads_norm_tr = 0.0652
-- Starting training on experience 57 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5572
	data_grads_norm = 3.6944
	new_data_grads_norm = 4.5771
	old_data_grads_norm = 5.6828
	sim_grads_norm_tr = 0.0713
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4436
	data_grads_norm = 3.8950
	new_data_grads_norm = 3.9675
	old_data_grads_norm = 6.8374
	sim_grads_norm_tr = 0.0176
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0877
	data_grads_norm = 2.7201
	new_data_grads_norm = 4.2092
	old_data_grads_norm = 3.5230
	sim_grads_norm_tr = -0.0587
-- Starting training on experience 58 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0893
	data_grads_norm = 3.4741
	new_data_grads_norm = 4.8981
	old_data_grads_norm = 4.9436
	sim_grads_norm_tr = -0.0431
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8371
	data_grads_norm = 4.1778
	new_data_grads_norm = 5.1106
	old_data_grads_norm = 5.9523
	sim_grads_norm_tr = 0.0962
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3703
	data_grads_norm = 4.1213
	new_data_grads_norm = 5.0651
	old_data_grads_norm = 6.4377
	sim_grads_norm_tr = -0.0449
-- Starting training on experience 59 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7070
	data_grads_norm = 4.3243
	new_data_grads_norm = 4.8555
	old_data_grads_norm = 6.6094
	sim_grads_norm_tr = 0.0889
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4284
	data_grads_norm = 3.7134
	new_data_grads_norm = 5.2079
	old_data_grads_norm = 4.6669
	sim_grads_norm_tr = 0.0422
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9334
	data_grads_norm = 3.9984
	new_data_grads_norm = 5.1103
	old_data_grads_norm = 7.1588
	sim_grads_norm_tr = -0.0385
-- Starting training on experience 60 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2737
	data_grads_norm = 3.5649
	new_data_grads_norm = 4.8128
	old_data_grads_norm = 5.8003
	sim_grads_norm_tr = -0.0232
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0755
	data_grads_norm = 3.4757
	new_data_grads_norm = 5.3930
	old_data_grads_norm = 4.6667
	sim_grads_norm_tr = -0.0688
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7609
	data_grads_norm = 4.0617
	new_data_grads_norm = 5.7653
	old_data_grads_norm = 5.6410
	sim_grads_norm_tr = 0.1113
-- Starting training on experience 61 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6031
	data_grads_norm = 3.6913
	new_data_grads_norm = 5.0004
	old_data_grads_norm = 5.5240
	sim_grads_norm_tr = -0.0523
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4151
	data_grads_norm = 3.5641
	new_data_grads_norm = 5.8037
	old_data_grads_norm = 5.4683
	sim_grads_norm_tr = 0.0377
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5937
	data_grads_norm = 4.2218
	new_data_grads_norm = 5.1735
	old_data_grads_norm = 6.8729
	sim_grads_norm_tr = -0.0957
-- Starting training on experience 62 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3811
	data_grads_norm = 4.1596
	new_data_grads_norm = 4.6847
	old_data_grads_norm = 5.5291
	sim_grads_norm_tr = 0.0109
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7745
	data_grads_norm = 3.9812
	new_data_grads_norm = 4.9780
	old_data_grads_norm = 5.7824
	sim_grads_norm_tr = -0.0175
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4884
	data_grads_norm = 3.6859
	new_data_grads_norm = 4.7065
	old_data_grads_norm = 5.4058
	sim_grads_norm_tr = -0.0142
-- Starting training on experience 63 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0811
	data_grads_norm = 2.9769
	new_data_grads_norm = 4.8735
	old_data_grads_norm = 3.7858
	sim_grads_norm_tr = -0.0798
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5496
	data_grads_norm = 4.2371
	new_data_grads_norm = 5.4238
	old_data_grads_norm = 6.1657
	sim_grads_norm_tr = -0.0851
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3907
	data_grads_norm = 4.0036
	new_data_grads_norm = 5.1960
	old_data_grads_norm = 6.1942
	sim_grads_norm_tr = 0.0491
-- Starting training on experience 64 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6962
	data_grads_norm = 3.6078
	new_data_grads_norm = 5.3320
	old_data_grads_norm = 4.5278
	sim_grads_norm_tr = 0.2083
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3866
	data_grads_norm = 3.4320
	new_data_grads_norm = 4.8334
	old_data_grads_norm = 4.2245
	sim_grads_norm_tr = 0.0750
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5633
	data_grads_norm = 3.3175
	new_data_grads_norm = 4.6584
	old_data_grads_norm = 4.8441
	sim_grads_norm_tr = 0.0342
-- Starting training on experience 65 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2881
	data_grads_norm = 3.6117
	new_data_grads_norm = 5.6906
	old_data_grads_norm = 5.3208
	sim_grads_norm_tr = -0.0230
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4485
	data_grads_norm = 3.8688
	new_data_grads_norm = 5.4871
	old_data_grads_norm = 4.8385
	sim_grads_norm_tr = 0.1759
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5698
	data_grads_norm = 3.4766
	new_data_grads_norm = 4.8011
	old_data_grads_norm = 4.7501
	sim_grads_norm_tr = 0.0274
-- Starting training on experience 66 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5376
	data_grads_norm = 3.6812
	new_data_grads_norm = 4.7993
	old_data_grads_norm = 5.9420
	sim_grads_norm_tr = -0.0395
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2699
	data_grads_norm = 3.4250
	new_data_grads_norm = 4.6112
	old_data_grads_norm = 4.8044
	sim_grads_norm_tr = 0.0914
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4447
	data_grads_norm = 3.6708
	new_data_grads_norm = 4.9656
	old_data_grads_norm = 4.8551
	sim_grads_norm_tr = 0.0432
-- Starting training on experience 67 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4356
	data_grads_norm = 3.5259
	new_data_grads_norm = 4.6930
	old_data_grads_norm = 4.8052
	sim_grads_norm_tr = -0.0228
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4704
	data_grads_norm = 3.7009
	new_data_grads_norm = 5.0903
	old_data_grads_norm = 4.0570
	sim_grads_norm_tr = 0.0963
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5343
	data_grads_norm = 3.8744
	new_data_grads_norm = 5.2555
	old_data_grads_norm = 6.0272
	sim_grads_norm_tr = -0.0874
-- Starting training on experience 68 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8783
	data_grads_norm = 4.2388
	new_data_grads_norm = 5.1794
	old_data_grads_norm = 5.7856
	sim_grads_norm_tr = -0.0274
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3579
	data_grads_norm = 3.6182
	new_data_grads_norm = 5.7812
	old_data_grads_norm = 5.0732
	sim_grads_norm_tr = -0.0052
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1006
	data_grads_norm = 5.2437
	new_data_grads_norm = 5.5006
	old_data_grads_norm = 8.1200
	sim_grads_norm_tr = 0.0493
-- Starting training on experience 69 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7889
	data_grads_norm = 4.3401
	new_data_grads_norm = 5.0209
	old_data_grads_norm = 6.3691
	sim_grads_norm_tr = 0.0538
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8121
	data_grads_norm = 4.1135
	new_data_grads_norm = 5.2714
	old_data_grads_norm = 6.3638
	sim_grads_norm_tr = 0.0598
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3356
	data_grads_norm = 3.2830
	new_data_grads_norm = 4.6606
	old_data_grads_norm = 4.3450
	sim_grads_norm_tr = -0.0242
-- Starting training on experience 70 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7498
	data_grads_norm = 3.9673
	new_data_grads_norm = 5.4256
	old_data_grads_norm = 5.7767
	sim_grads_norm_tr = -0.0180
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8890
	data_grads_norm = 3.6804
	new_data_grads_norm = 5.3178
	old_data_grads_norm = 4.9754
	sim_grads_norm_tr = 0.0377
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9377
	data_grads_norm = 4.7017
	new_data_grads_norm = 5.4805
	old_data_grads_norm = 6.7035
	sim_grads_norm_tr = 0.1395
-- Starting training on experience 71 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3303
	data_grads_norm = 3.4742
	new_data_grads_norm = 4.9868
	old_data_grads_norm = 4.3505
	sim_grads_norm_tr = -0.0172
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6428
	data_grads_norm = 3.9866
	new_data_grads_norm = 4.7266
	old_data_grads_norm = 5.7812
	sim_grads_norm_tr = 0.0903
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2760
	data_grads_norm = 3.6893
	new_data_grads_norm = 5.4776
	old_data_grads_norm = 4.6975
	sim_grads_norm_tr = 0.0114
-- Starting training on experience 72 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7278
	data_grads_norm = 4.3082
	new_data_grads_norm = 5.5463
	old_data_grads_norm = 6.3627
	sim_grads_norm_tr = 0.0123
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5083
	data_grads_norm = 3.7645
	new_data_grads_norm = 4.9552
	old_data_grads_norm = 5.1649
	sim_grads_norm_tr = 0.0617
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3617
	data_grads_norm = 3.6982
	new_data_grads_norm = 5.0766
	old_data_grads_norm = 5.7079
	sim_grads_norm_tr = 0.0154
-- Starting training on experience 73 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4214
	data_grads_norm = 4.0232
	new_data_grads_norm = 5.2985
	old_data_grads_norm = 5.8265
	sim_grads_norm_tr = 0.0044
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1792
	data_grads_norm = 3.5584
	new_data_grads_norm = 5.3002
	old_data_grads_norm = 4.7145
	sim_grads_norm_tr = -0.0187
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2664
	data_grads_norm = 3.6914
	new_data_grads_norm = 5.1724
	old_data_grads_norm = 5.0791
	sim_grads_norm_tr = 0.0039
-- Starting training on experience 74 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4300
	data_grads_norm = 3.8224
	new_data_grads_norm = 4.8622
	old_data_grads_norm = 5.2998
	sim_grads_norm_tr = 0.0348
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4731
	data_grads_norm = 3.0411
	new_data_grads_norm = 4.4824
	old_data_grads_norm = 3.9925
	sim_grads_norm_tr = -0.0289
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4388
	data_grads_norm = 3.7640
	new_data_grads_norm = 5.2600
	old_data_grads_norm = 6.5994
	sim_grads_norm_tr = -0.0214
-- Starting training on experience 75 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2314
	data_grads_norm = 3.5244
	new_data_grads_norm = 5.7616
	old_data_grads_norm = 4.3534
	sim_grads_norm_tr = 0.0966
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3188
	data_grads_norm = 3.9463
	new_data_grads_norm = 5.2062
	old_data_grads_norm = 5.4601
	sim_grads_norm_tr = -0.0552
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2370
	data_grads_norm = 3.1637
	new_data_grads_norm = 5.6150
	old_data_grads_norm = 3.4889
	sim_grads_norm_tr = -0.0215
-- Starting training on experience 76 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2332
	data_grads_norm = 3.5603
	new_data_grads_norm = 5.2090
	old_data_grads_norm = 4.6676
	sim_grads_norm_tr = 0.0679
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3076
	data_grads_norm = 3.6017
	new_data_grads_norm = 4.9421
	old_data_grads_norm = 4.5201
	sim_grads_norm_tr = 0.0225
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3304
	data_grads_norm = 3.7938
	new_data_grads_norm = 5.0626
	old_data_grads_norm = 5.9655
	sim_grads_norm_tr = -0.0057
-- Starting training on experience 77 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3591
	data_grads_norm = 3.6101
	new_data_grads_norm = 5.1007
	old_data_grads_norm = 4.3659
	sim_grads_norm_tr = 0.1356
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6883
	data_grads_norm = 4.6463
	new_data_grads_norm = 4.3569
	old_data_grads_norm = 7.8774
	sim_grads_norm_tr = -0.0528
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5071
	data_grads_norm = 3.5969
	new_data_grads_norm = 4.3493
	old_data_grads_norm = 5.2189
	sim_grads_norm_tr = -0.0013
-- Starting training on experience 78 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7131
	data_grads_norm = 4.4168
	new_data_grads_norm = 4.7107
	old_data_grads_norm = 6.0599
	sim_grads_norm_tr = 0.1726
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5610
	data_grads_norm = 3.6912
	new_data_grads_norm = 4.6531
	old_data_grads_norm = 4.8522
	sim_grads_norm_tr = 0.0643
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2973
	data_grads_norm = 3.5107
	new_data_grads_norm = 4.6133
	old_data_grads_norm = 4.4391
	sim_grads_norm_tr = 0.1245
-- Starting training on experience 79 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2320
	data_grads_norm = 3.5520
	new_data_grads_norm = 4.6027
	old_data_grads_norm = 5.1007
	sim_grads_norm_tr = -0.0636
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5954
	data_grads_norm = 4.0877
	new_data_grads_norm = 5.9365
	old_data_grads_norm = 5.7437
	sim_grads_norm_tr = 0.0017
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3970
	data_grads_norm = 3.5995
	new_data_grads_norm = 4.5233
	old_data_grads_norm = 5.3082
	sim_grads_norm_tr = -0.0378
-- Starting training on experience 80 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7038
	data_grads_norm = 3.8936
	new_data_grads_norm = 5.2164
	old_data_grads_norm = 6.0172
	sim_grads_norm_tr = 0.0022
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7805
	data_grads_norm = 3.8177
	new_data_grads_norm = 4.9460
	old_data_grads_norm = 5.4691
	sim_grads_norm_tr = 0.0513
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4619
	data_grads_norm = 3.9011
	new_data_grads_norm = 5.1899
	old_data_grads_norm = 5.9270
	sim_grads_norm_tr = -0.0349
-- Starting training on experience 81 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1606
	data_grads_norm = 3.2586
	new_data_grads_norm = 4.2175
	old_data_grads_norm = 4.7171
	sim_grads_norm_tr = 0.1086
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2803
	data_grads_norm = 3.9570
	new_data_grads_norm = 4.2543
	old_data_grads_norm = 5.8553
	sim_grads_norm_tr = 0.0063
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3730
	data_grads_norm = 3.7408
	new_data_grads_norm = 4.3225
	old_data_grads_norm = 5.8911
	sim_grads_norm_tr = -0.0901
-- Starting training on experience 82 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8360
	data_grads_norm = 4.0384
	new_data_grads_norm = 4.9153
	old_data_grads_norm = 5.4357
	sim_grads_norm_tr = 0.0198
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2201
	data_grads_norm = 3.6073
	new_data_grads_norm = 4.9332
	old_data_grads_norm = 5.8388
	sim_grads_norm_tr = 0.0583
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4496
	data_grads_norm = 4.0837
	new_data_grads_norm = 4.7566
	old_data_grads_norm = 5.2367
	sim_grads_norm_tr = 0.0913
-- Starting training on experience 83 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9740
	data_grads_norm = 3.4228
	new_data_grads_norm = 3.9931
	old_data_grads_norm = 4.7165
	sim_grads_norm_tr = -0.0381
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4226
	data_grads_norm = 4.5417
	new_data_grads_norm = 3.9292
	old_data_grads_norm = 6.3462
	sim_grads_norm_tr = 0.0410
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4695
	data_grads_norm = 3.4269
	new_data_grads_norm = 4.8506
	old_data_grads_norm = 4.4934
	sim_grads_norm_tr = 0.0986
-- Starting training on experience 84 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0723
	data_grads_norm = 3.5884
	new_data_grads_norm = 4.8190
	old_data_grads_norm = 5.6584
	sim_grads_norm_tr = -0.0683
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5224
	data_grads_norm = 4.2158
	new_data_grads_norm = 5.2095
	old_data_grads_norm = 5.9381
	sim_grads_norm_tr = 0.0552
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1281
	data_grads_norm = 3.9982
	new_data_grads_norm = 5.0969
	old_data_grads_norm = 5.0384
	sim_grads_norm_tr = 0.0075
-- Starting training on experience 85 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5480
	data_grads_norm = 3.5780
	new_data_grads_norm = 5.9177
	old_data_grads_norm = 3.9319
	sim_grads_norm_tr = 0.0512
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5058
	data_grads_norm = 3.7181
	new_data_grads_norm = 5.7883
	old_data_grads_norm = 4.4858
	sim_grads_norm_tr = -0.0086
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9156
	data_grads_norm = 4.5178
	new_data_grads_norm = 6.0714
	old_data_grads_norm = 4.9312
	sim_grads_norm_tr = 0.1391
-- Starting training on experience 86 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1346
	data_grads_norm = 3.4739
	new_data_grads_norm = 4.9321
	old_data_grads_norm = 5.1162
	sim_grads_norm_tr = 0.0028
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0673
	data_grads_norm = 4.0383
	new_data_grads_norm = 5.6048
	old_data_grads_norm = 4.8376
	sim_grads_norm_tr = -0.0119
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9555
	data_grads_norm = 2.9745
	new_data_grads_norm = 5.5786
	old_data_grads_norm = 3.8893
	sim_grads_norm_tr = -0.0183
-- Starting training on experience 87 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2358
	data_grads_norm = 3.8015
	new_data_grads_norm = 5.9578
	old_data_grads_norm = 4.9701
	sim_grads_norm_tr = 0.0086
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9546
	data_grads_norm = 3.0868
	new_data_grads_norm = 5.3614
	old_data_grads_norm = 2.9519
	sim_grads_norm_tr = 0.0322
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3517
	data_grads_norm = 4.6033
	new_data_grads_norm = 5.5144
	old_data_grads_norm = 6.6293
	sim_grads_norm_tr = 0.0723
-- Starting training on experience 88 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2149
	data_grads_norm = 3.5389
	new_data_grads_norm = 4.7846
	old_data_grads_norm = 4.2662
	sim_grads_norm_tr = 0.1280
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3817
	data_grads_norm = 3.6778
	new_data_grads_norm = 4.6430
	old_data_grads_norm = 5.3868
	sim_grads_norm_tr = -0.0671
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0748
	data_grads_norm = 3.4503
	new_data_grads_norm = 4.8143
	old_data_grads_norm = 5.3663
	sim_grads_norm_tr = 0.0176
-- Starting training on experience 89 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1017
	data_grads_norm = 3.4820
	new_data_grads_norm = 4.7894
	old_data_grads_norm = 4.9178
	sim_grads_norm_tr = 0.0040
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4501
	data_grads_norm = 4.0036
	new_data_grads_norm = 5.7222
	old_data_grads_norm = 5.3213
	sim_grads_norm_tr = 0.0440
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9741
	data_grads_norm = 3.9111
	new_data_grads_norm = 5.8460
	old_data_grads_norm = 4.9764
	sim_grads_norm_tr = -0.0052
-- Starting training on experience 90 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0302
	data_grads_norm = 4.5653
	new_data_grads_norm = 5.6182
	old_data_grads_norm = 6.0990
	sim_grads_norm_tr = 0.0908
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4625
	data_grads_norm = 4.3559
	new_data_grads_norm = 4.9832
	old_data_grads_norm = 6.5013
	sim_grads_norm_tr = 0.0196
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3237
	data_grads_norm = 3.7639
	new_data_grads_norm = 4.9482
	old_data_grads_norm = 5.0216
	sim_grads_norm_tr = 0.1247
-- Starting training on experience 91 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0874
	data_grads_norm = 3.9890
	new_data_grads_norm = 5.0862
	old_data_grads_norm = 6.4497
	sim_grads_norm_tr = -0.0817
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0175
	data_grads_norm = 4.5997
	new_data_grads_norm = 6.3472
	old_data_grads_norm = 6.1300
	sim_grads_norm_tr = -0.0564
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4185
	data_grads_norm = 5.1281
	new_data_grads_norm = 6.1892
	old_data_grads_norm = 7.4723
	sim_grads_norm_tr = 0.0321
-- Starting training on experience 92 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1629
	data_grads_norm = 3.7062
	new_data_grads_norm = 6.1548
	old_data_grads_norm = 4.4121
	sim_grads_norm_tr = -0.0341
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8736
	data_grads_norm = 4.5558
	new_data_grads_norm = 7.0201
	old_data_grads_norm = 5.9278
	sim_grads_norm_tr = -0.0120
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4414
	data_grads_norm = 4.1188
	new_data_grads_norm = 6.7389
	old_data_grads_norm = 5.3736
	sim_grads_norm_tr = -0.0262
-- Starting training on experience 93 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6104
	data_grads_norm = 4.8497
	new_data_grads_norm = 6.4595
	old_data_grads_norm = 5.7497
	sim_grads_norm_tr = 0.1051
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3624
	data_grads_norm = 4.6121
	new_data_grads_norm = 5.5638
	old_data_grads_norm = 6.1579
	sim_grads_norm_tr = -0.0554
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3282
	data_grads_norm = 4.3732
	new_data_grads_norm = 5.4690
	old_data_grads_norm = 5.9144
	sim_grads_norm_tr = 0.0103
-- Starting training on experience 94 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4131
	data_grads_norm = 3.7948
	new_data_grads_norm = 5.1660
	old_data_grads_norm = 5.0060
	sim_grads_norm_tr = 0.0616
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5996
	data_grads_norm = 4.0045
	new_data_grads_norm = 5.1772
	old_data_grads_norm = 6.2079
	sim_grads_norm_tr = -0.0304
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1816
	data_grads_norm = 3.6839
	new_data_grads_norm = 5.3373
	old_data_grads_norm = 4.0543
	sim_grads_norm_tr = 0.0564
-- Starting training on experience 95 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9493
	data_grads_norm = 4.8700
	new_data_grads_norm = 6.4623
	old_data_grads_norm = 5.5183
	sim_grads_norm_tr = 0.0384
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8892
	data_grads_norm = 4.1460
	new_data_grads_norm = 5.9195
	old_data_grads_norm = 5.0412
	sim_grads_norm_tr = 0.1287
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5035
	data_grads_norm = 4.7558
	new_data_grads_norm = 6.5448
	old_data_grads_norm = 6.0079
	sim_grads_norm_tr = 0.0413
-- Starting training on experience 96 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9959
	data_grads_norm = 3.5602
	new_data_grads_norm = 5.3093
	old_data_grads_norm = 4.5347
	sim_grads_norm_tr = 0.0916
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3809
	data_grads_norm = 4.4909
	new_data_grads_norm = 4.9169
	old_data_grads_norm = 6.6752
	sim_grads_norm_tr = -0.0661
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2768
	data_grads_norm = 3.7720
	new_data_grads_norm = 5.6091
	old_data_grads_norm = 5.8082
	sim_grads_norm_tr = -0.0382
-- Starting training on experience 97 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2968
	data_grads_norm = 3.5440
	new_data_grads_norm = 5.1960
	old_data_grads_norm = 4.5555
	sim_grads_norm_tr = 0.0005
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3184
	data_grads_norm = 4.0785
	new_data_grads_norm = 5.0519
	old_data_grads_norm = 6.2148
	sim_grads_norm_tr = 0.0032
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7467
	data_grads_norm = 3.9431
	new_data_grads_norm = 5.2633
	old_data_grads_norm = 4.8473
	sim_grads_norm_tr = 0.1295
-- Starting training on experience 98 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3810
	data_grads_norm = 3.6735
	new_data_grads_norm = 5.3632
	old_data_grads_norm = 4.7698
	sim_grads_norm_tr = 0.0072
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6267
	data_grads_norm = 4.1789
	new_data_grads_norm = 5.1050
	old_data_grads_norm = 5.5442
	sim_grads_norm_tr = -0.0128
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1566
	data_grads_norm = 3.8293
	new_data_grads_norm = 5.4449
	old_data_grads_norm = 5.3077
	sim_grads_norm_tr = 0.0213
-- Starting training on experience 99 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0645
	data_grads_norm = 3.6716
	new_data_grads_norm = 5.0817
	old_data_grads_norm = 4.9753
	sim_grads_norm_tr = -0.0215
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6018
	data_grads_norm = 3.9939
	new_data_grads_norm = 5.4362
	old_data_grads_norm = 6.4842
	sim_grads_norm_tr = -0.0113
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4680
	data_grads_norm = 4.1532
	new_data_grads_norm = 5.2627
	old_data_grads_norm = 6.6221
	sim_grads_norm_tr = -0.0638
-- Starting training on experience 100 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7522
	data_grads_norm = 4.7157
	new_data_grads_norm = 6.4283
	old_data_grads_norm = 5.3621
	sim_grads_norm_tr = 0.1762
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3494
	data_grads_norm = 4.3044
	new_data_grads_norm = 6.1007
	old_data_grads_norm = 4.4275
	sim_grads_norm_tr = 0.2372
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2618
	data_grads_norm = 4.0891
	new_data_grads_norm = 5.6907
	old_data_grads_norm = 5.6961
	sim_grads_norm_tr = -0.0093
-- Starting training on experience 101 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1269
	data_grads_norm = 4.3537
	new_data_grads_norm = 4.9477
	old_data_grads_norm = 6.8406
	sim_grads_norm_tr = -0.0115
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2319
	data_grads_norm = 5.0767
	new_data_grads_norm = 4.9709
	old_data_grads_norm = 7.5786
	sim_grads_norm_tr = 0.1526
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1019
	data_grads_norm = 3.5791
	new_data_grads_norm = 4.3423
	old_data_grads_norm = 5.4816
	sim_grads_norm_tr = -0.0367
-- Starting training on experience 102 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2337
	data_grads_norm = 4.0724
	new_data_grads_norm = 4.5805
	old_data_grads_norm = 6.5476
	sim_grads_norm_tr = 0.0069
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9318
	data_grads_norm = 4.7676
	new_data_grads_norm = 4.8944
	old_data_grads_norm = 7.7637
	sim_grads_norm_tr = 0.0073
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1400
	data_grads_norm = 3.7164
	new_data_grads_norm = 4.6609
	old_data_grads_norm = 5.2111
	sim_grads_norm_tr = 0.0225
-- Starting training on experience 103 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4360
	data_grads_norm = 3.7270
	new_data_grads_norm = 4.9287
	old_data_grads_norm = 5.3923
	sim_grads_norm_tr = -0.0068
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2511
	data_grads_norm = 4.2458
	new_data_grads_norm = 5.2498
	old_data_grads_norm = 6.4329
	sim_grads_norm_tr = -0.0031
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1914
	data_grads_norm = 3.7901
	new_data_grads_norm = 4.9751
	old_data_grads_norm = 4.3925
	sim_grads_norm_tr = 0.1179
-- Starting training on experience 104 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8153
	data_grads_norm = 3.2563
	new_data_grads_norm = 5.3373
	old_data_grads_norm = 3.4843
	sim_grads_norm_tr = 0.1018
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2129
	data_grads_norm = 3.5480
	new_data_grads_norm = 5.3946
	old_data_grads_norm = 5.6659
	sim_grads_norm_tr = -0.0877
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6735
	data_grads_norm = 4.5931
	new_data_grads_norm = 5.7353
	old_data_grads_norm = 6.5437
	sim_grads_norm_tr = 0.0218
-- Starting training on experience 105 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2317
	data_grads_norm = 4.0079
	new_data_grads_norm = 5.7383
	old_data_grads_norm = 5.2180
	sim_grads_norm_tr = 0.0322
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2484
	data_grads_norm = 4.0731
	new_data_grads_norm = 5.5834
	old_data_grads_norm = 5.9721
	sim_grads_norm_tr = -0.0378
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5256
	data_grads_norm = 3.9582
	new_data_grads_norm = 6.0240
	old_data_grads_norm = 6.0127
	sim_grads_norm_tr = 0.0458
-- Starting training on experience 106 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3633
	data_grads_norm = 4.9408
	new_data_grads_norm = 6.8114
	old_data_grads_norm = 5.8222
	sim_grads_norm_tr = 0.0760
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3763
	data_grads_norm = 4.5802
	new_data_grads_norm = 6.5468
	old_data_grads_norm = 5.6511
	sim_grads_norm_tr = 0.0585
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2426
	data_grads_norm = 4.8828
	new_data_grads_norm = 5.4907
	old_data_grads_norm = 7.5676
	sim_grads_norm_tr = -0.0311
-- Starting training on experience 107 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2462
	data_grads_norm = 4.1397
	new_data_grads_norm = 5.7633
	old_data_grads_norm = 4.5225
	sim_grads_norm_tr = 0.0789
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2825
	data_grads_norm = 3.9579
	new_data_grads_norm = 5.6509
	old_data_grads_norm = 5.3949
	sim_grads_norm_tr = 0.0260
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5144
	data_grads_norm = 4.7359
	new_data_grads_norm = 5.5354
	old_data_grads_norm = 6.9966
	sim_grads_norm_tr = 0.0253
-- Starting training on experience 108 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1896
	data_grads_norm = 4.0739
	new_data_grads_norm = 5.7891
	old_data_grads_norm = 6.0024
	sim_grads_norm_tr = -0.0632
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5542
	data_grads_norm = 4.2650
	new_data_grads_norm = 5.6998
	old_data_grads_norm = 5.3525
	sim_grads_norm_tr = 0.1960
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1538
	data_grads_norm = 4.1306
	new_data_grads_norm = 5.2363
	old_data_grads_norm = 6.3894
	sim_grads_norm_tr = -0.0093
-- Starting training on experience 109 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5323
	data_grads_norm = 4.0690
	new_data_grads_norm = 5.5610
	old_data_grads_norm = 5.9527
	sim_grads_norm_tr = -0.0120
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2423
	data_grads_norm = 4.2228
	new_data_grads_norm = 5.4540
	old_data_grads_norm = 4.4492
	sim_grads_norm_tr = 0.0784
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3883
	data_grads_norm = 4.2718
	new_data_grads_norm = 5.2910
	old_data_grads_norm = 5.9901
	sim_grads_norm_tr = 0.0601
-- Starting training on experience 110 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4560
	data_grads_norm = 3.8654
	new_data_grads_norm = 5.8152
	old_data_grads_norm = 4.8743
	sim_grads_norm_tr = 0.0267
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7601
	data_grads_norm = 4.1560
	new_data_grads_norm = 5.8404
	old_data_grads_norm = 5.3791
	sim_grads_norm_tr = -0.0127
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4247
	data_grads_norm = 4.1955
	new_data_grads_norm = 5.9402
	old_data_grads_norm = 5.2700
	sim_grads_norm_tr = 0.0244
-- Starting training on experience 111 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5141
	data_grads_norm = 4.4224
	new_data_grads_norm = 5.7638
	old_data_grads_norm = 5.6167
	sim_grads_norm_tr = 0.1858
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1067
	data_grads_norm = 3.8263
	new_data_grads_norm = 5.3902
	old_data_grads_norm = 5.5276
	sim_grads_norm_tr = -0.0122
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5117
	data_grads_norm = 4.2549
	new_data_grads_norm = 5.5186
	old_data_grads_norm = 6.0462
	sim_grads_norm_tr = -0.0458
-- Starting training on experience 112 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0135
	data_grads_norm = 3.9413
	new_data_grads_norm = 5.0322
	old_data_grads_norm = 5.5122
	sim_grads_norm_tr = 0.0623
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1393
	data_grads_norm = 3.8597
	new_data_grads_norm = 5.1942
	old_data_grads_norm = 6.7378
	sim_grads_norm_tr = -0.0841
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3172
	data_grads_norm = 4.2349
	new_data_grads_norm = 5.0108
	old_data_grads_norm = 6.1162
	sim_grads_norm_tr = 0.0383
-- Starting training on experience 113 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0168
	data_grads_norm = 3.9070
	new_data_grads_norm = 5.4171
	old_data_grads_norm = 5.1112
	sim_grads_norm_tr = 0.0275
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9771
	data_grads_norm = 3.6752
	new_data_grads_norm = 4.8108
	old_data_grads_norm = 5.7602
	sim_grads_norm_tr = 0.0276
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1674
	data_grads_norm = 4.2996
	new_data_grads_norm = 5.1139
	old_data_grads_norm = 6.4883
	sim_grads_norm_tr = -0.0273
-- Starting training on experience 114 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1062
	data_grads_norm = 3.7269
	new_data_grads_norm = 6.0427
	old_data_grads_norm = 5.2792
	sim_grads_norm_tr = 0.0045
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1870
	data_grads_norm = 4.1364
	new_data_grads_norm = 5.9720
	old_data_grads_norm = 4.3945
	sim_grads_norm_tr = 0.1995
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0943
	data_grads_norm = 4.0985
	new_data_grads_norm = 5.8399
	old_data_grads_norm = 5.1869
	sim_grads_norm_tr = -0.0256
-- Starting training on experience 115 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1642
	data_grads_norm = 3.7800
	new_data_grads_norm = 5.5210
	old_data_grads_norm = 4.3369
	sim_grads_norm_tr = 0.1644
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0262
	data_grads_norm = 3.6312
	new_data_grads_norm = 5.1123
	old_data_grads_norm = 5.9336
	sim_grads_norm_tr = 0.0063
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2240
	data_grads_norm = 3.6249
	new_data_grads_norm = 4.9434
	old_data_grads_norm = 5.0576
	sim_grads_norm_tr = 0.0441
-- Starting training on experience 116 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0179
	data_grads_norm = 3.8263
	new_data_grads_norm = 5.0540
	old_data_grads_norm = 6.0836
	sim_grads_norm_tr = 0.0134
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8558
	data_grads_norm = 3.2804
	new_data_grads_norm = 4.6836
	old_data_grads_norm = 4.7497
	sim_grads_norm_tr = -0.0700
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7993
	data_grads_norm = 3.5316
	new_data_grads_norm = 5.1556
	old_data_grads_norm = 4.8699
	sim_grads_norm_tr = -0.0448
-- Starting training on experience 117 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4001
	data_grads_norm = 4.2781
	new_data_grads_norm = 6.2330
	old_data_grads_norm = 5.6178
	sim_grads_norm_tr = 0.0218
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5481
	data_grads_norm = 4.1179
	new_data_grads_norm = 5.7096
	old_data_grads_norm = 5.1906
	sim_grads_norm_tr = -0.0440
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9876
	data_grads_norm = 3.3959
	new_data_grads_norm = 6.2199
	old_data_grads_norm = 3.5468
	sim_grads_norm_tr = -0.0571
-- Starting training on experience 118 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3720
	data_grads_norm = 3.9770
	new_data_grads_norm = 5.9289
	old_data_grads_norm = 4.7270
	sim_grads_norm_tr = 0.1012
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2518
	data_grads_norm = 4.3348
	new_data_grads_norm = 6.0542
	old_data_grads_norm = 5.6213
	sim_grads_norm_tr = 0.0337
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1286
	data_grads_norm = 3.7195
	new_data_grads_norm = 5.8623
	old_data_grads_norm = 4.6608
	sim_grads_norm_tr = 0.0350
-- Starting training on experience 119 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3656
	data_grads_norm = 4.3701
	new_data_grads_norm = 4.9621
	old_data_grads_norm = 6.7882
	sim_grads_norm_tr = 0.0222
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1135
	data_grads_norm = 4.0814
	new_data_grads_norm = 5.5982
	old_data_grads_norm = 5.7737
	sim_grads_norm_tr = 0.0090
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8355
	data_grads_norm = 3.2970
	new_data_grads_norm = 5.3201
	old_data_grads_norm = 4.2370
	sim_grads_norm_tr = -0.0377
-- Starting training on experience 120 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4899
	data_grads_norm = 4.9563
	new_data_grads_norm = 7.1393
	old_data_grads_norm = 7.7807
	sim_grads_norm_tr = 0.0273
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9853
	data_grads_norm = 5.5693
	new_data_grads_norm = 7.5677
	old_data_grads_norm = 7.7360
	sim_grads_norm_tr = 0.0311
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2771
	data_grads_norm = 4.3242
	new_data_grads_norm = 6.2584
	old_data_grads_norm = 5.9162
	sim_grads_norm_tr = -0.0081
-- Starting training on experience 121 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4994
	data_grads_norm = 4.5126
	new_data_grads_norm = 5.9398
	old_data_grads_norm = 6.0732
	sim_grads_norm_tr = 0.0113
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2663
	data_grads_norm = 4.3633
	new_data_grads_norm = 5.7215
	old_data_grads_norm = 5.7767
	sim_grads_norm_tr = 0.0313
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1284
	data_grads_norm = 4.1506
	new_data_grads_norm = 5.7918
	old_data_grads_norm = 5.0686
	sim_grads_norm_tr = 0.0748
-- Starting training on experience 122 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6437
	data_grads_norm = 4.2172
	new_data_grads_norm = 6.2707
	old_data_grads_norm = 5.8464
	sim_grads_norm_tr = -0.0121
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0857
	data_grads_norm = 4.1235
	new_data_grads_norm = 5.9545
	old_data_grads_norm = 6.0399
	sim_grads_norm_tr = -0.0577
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1090
	data_grads_norm = 4.8889
	new_data_grads_norm = 6.7513
	old_data_grads_norm = 6.7069
	sim_grads_norm_tr = -0.0815
-- Starting training on experience 123 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2310
	data_grads_norm = 4.3577
	new_data_grads_norm = 6.1305
	old_data_grads_norm = 5.2282
	sim_grads_norm_tr = 0.0219
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5202
	data_grads_norm = 3.8869
	new_data_grads_norm = 5.7915
	old_data_grads_norm = 4.4970
	sim_grads_norm_tr = 0.0710
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6121
	data_grads_norm = 4.6169
	new_data_grads_norm = 5.6828
	old_data_grads_norm = 6.3905
	sim_grads_norm_tr = 0.0704
-- Starting training on experience 124 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2442
	data_grads_norm = 3.9105
	new_data_grads_norm = 5.3412
	old_data_grads_norm = 4.7428
	sim_grads_norm_tr = 0.1731
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9894
	data_grads_norm = 3.5348
	new_data_grads_norm = 4.7234
	old_data_grads_norm = 6.3817
	sim_grads_norm_tr = -0.0381
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2726
	data_grads_norm = 4.4638
	new_data_grads_norm = 5.5441
	old_data_grads_norm = 5.6748
	sim_grads_norm_tr = 0.1158
-- Starting training on experience 125 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3799
	data_grads_norm = 4.2459
	new_data_grads_norm = 6.3107
	old_data_grads_norm = 5.7821
	sim_grads_norm_tr = -0.0029
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5722
	data_grads_norm = 4.5374
	new_data_grads_norm = 6.5670
	old_data_grads_norm = 5.5357
	sim_grads_norm_tr = 0.0946
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0442
	data_grads_norm = 3.9173
	new_data_grads_norm = 6.3074
	old_data_grads_norm = 5.7607
	sim_grads_norm_tr = -0.0305
-- Starting training on experience 126 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0817
	data_grads_norm = 4.2256
	new_data_grads_norm = 5.3910
	old_data_grads_norm = 6.5194
	sim_grads_norm_tr = 0.0334
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2602
	data_grads_norm = 3.8584
	new_data_grads_norm = 5.0952
	old_data_grads_norm = 5.4389
	sim_grads_norm_tr = 0.0180
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1582
	data_grads_norm = 3.9835
	new_data_grads_norm = 4.8544
	old_data_grads_norm = 4.8390
	sim_grads_norm_tr = 0.1613
-- Starting training on experience 127 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0652
	data_grads_norm = 3.4677
	new_data_grads_norm = 4.9388
	old_data_grads_norm = 5.7386
	sim_grads_norm_tr = -0.0323
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3703
	data_grads_norm = 4.4953
	new_data_grads_norm = 4.9490
	old_data_grads_norm = 6.6593
	sim_grads_norm_tr = -0.0098
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4458
	data_grads_norm = 4.2423
	new_data_grads_norm = 5.3587
	old_data_grads_norm = 5.9856
	sim_grads_norm_tr = -0.0007
-- Starting training on experience 128 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5502
	data_grads_norm = 3.8555
	new_data_grads_norm = 6.1142
	old_data_grads_norm = 5.3952
	sim_grads_norm_tr = -0.0102
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3036
	data_grads_norm = 4.5145
	new_data_grads_norm = 7.1999
	old_data_grads_norm = 4.7895
	sim_grads_norm_tr = 0.0913
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2871
	data_grads_norm = 3.7536
	new_data_grads_norm = 6.3547
	old_data_grads_norm = 4.4706
	sim_grads_norm_tr = 0.0967
-- Starting training on experience 129 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2043
	data_grads_norm = 3.8278
	new_data_grads_norm = 5.5708
	old_data_grads_norm = 4.9754
	sim_grads_norm_tr = 0.1118
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8700
	data_grads_norm = 4.4829
	new_data_grads_norm = 5.3678
	old_data_grads_norm = 5.2306
	sim_grads_norm_tr = 0.1175
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5696
	data_grads_norm = 4.1063
	new_data_grads_norm = 5.3309
	old_data_grads_norm = 6.4841
	sim_grads_norm_tr = -0.0646
-- Starting training on experience 130 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3068
	data_grads_norm = 4.4465
	new_data_grads_norm = 6.2941
	old_data_grads_norm = 5.2041
	sim_grads_norm_tr = 0.1286
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2772
	data_grads_norm = 4.3271
	new_data_grads_norm = 6.0163
	old_data_grads_norm = 6.0548
	sim_grads_norm_tr = -0.0747
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5504
	data_grads_norm = 5.6428
	new_data_grads_norm = 6.5437
	old_data_grads_norm = 8.2448
	sim_grads_norm_tr = 0.0608
-- Starting training on experience 131 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7551
	data_grads_norm = 5.2599
	new_data_grads_norm = 6.8864
	old_data_grads_norm = 5.9747
	sim_grads_norm_tr = 0.2844
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0738
	data_grads_norm = 3.9922
	new_data_grads_norm = 5.3446
	old_data_grads_norm = 5.7049
	sim_grads_norm_tr = 0.0882
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8090
	data_grads_norm = 4.2927
	new_data_grads_norm = 5.7187
	old_data_grads_norm = 6.8460
	sim_grads_norm_tr = -0.0600
-- Starting training on experience 132 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6302
	data_grads_norm = 4.8136
	new_data_grads_norm = 5.9268
	old_data_grads_norm = 6.5678
	sim_grads_norm_tr = 0.1905
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1383
	data_grads_norm = 3.8833
	new_data_grads_norm = 5.4030
	old_data_grads_norm = 5.6119
	sim_grads_norm_tr = -0.0192
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0813
	data_grads_norm = 3.3341
	new_data_grads_norm = 5.0832
	old_data_grads_norm = 4.7111
	sim_grads_norm_tr = -0.0124
-- Starting training on experience 133 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1784
	data_grads_norm = 3.6481
	new_data_grads_norm = 5.6357
	old_data_grads_norm = 5.1894
	sim_grads_norm_tr = -0.0979
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9931
	data_grads_norm = 4.4334
	new_data_grads_norm = 6.0647
	old_data_grads_norm = 6.5898
	sim_grads_norm_tr = 0.0066
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7213
	data_grads_norm = 4.6482
	new_data_grads_norm = 5.9316
	old_data_grads_norm = 6.8693
	sim_grads_norm_tr = 0.0649
-- Starting training on experience 134 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9879
	data_grads_norm = 3.8631
	new_data_grads_norm = 6.1255
	old_data_grads_norm = 5.1057
	sim_grads_norm_tr = 0.0261
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9101
	data_grads_norm = 4.1563
	new_data_grads_norm = 5.6265
	old_data_grads_norm = 5.4887
	sim_grads_norm_tr = -0.0259
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1837
	data_grads_norm = 4.3777
	new_data_grads_norm = 5.9456
	old_data_grads_norm = 6.2939
	sim_grads_norm_tr = 0.0018
-- Starting training on experience 135 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3799
	data_grads_norm = 4.8614
	new_data_grads_norm = 6.5013
	old_data_grads_norm = 5.5723
	sim_grads_norm_tr = 0.2683
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1481
	data_grads_norm = 4.3351
	new_data_grads_norm = 5.4815
	old_data_grads_norm = 6.3811
	sim_grads_norm_tr = -0.0702
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7179
	data_grads_norm = 3.2040
	new_data_grads_norm = 5.6053
	old_data_grads_norm = 4.0027
	sim_grads_norm_tr = -0.1246
-- Starting training on experience 136 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0336
	data_grads_norm = 4.1262
	new_data_grads_norm = 5.6641
	old_data_grads_norm = 5.6925
	sim_grads_norm_tr = 0.0577
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8939
	data_grads_norm = 3.2061
	new_data_grads_norm = 6.0089
	old_data_grads_norm = 4.1689
	sim_grads_norm_tr = -0.0346
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6799
	data_grads_norm = 3.4088
	new_data_grads_norm = 6.1164
	old_data_grads_norm = 4.8100
	sim_grads_norm_tr = -0.0345
-- Starting training on experience 137 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5988
	data_grads_norm = 5.3556
	new_data_grads_norm = 6.1149
	old_data_grads_norm = 7.9404
	sim_grads_norm_tr = 0.0755
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3446
	data_grads_norm = 5.0580
	new_data_grads_norm = 5.8426
	old_data_grads_norm = 6.5717
	sim_grads_norm_tr = 0.1127
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9591
	data_grads_norm = 3.6169
	new_data_grads_norm = 5.2227
	old_data_grads_norm = 4.7899
	sim_grads_norm_tr = -0.0509
-- Starting training on experience 138 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4379
	data_grads_norm = 4.3307
	new_data_grads_norm = 5.9222
	old_data_grads_norm = 5.8579
	sim_grads_norm_tr = 0.0241
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5854
	data_grads_norm = 4.2892
	new_data_grads_norm = 6.3568
	old_data_grads_norm = 6.0899
	sim_grads_norm_tr = -0.0350
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0480
	data_grads_norm = 4.4890
	new_data_grads_norm = 6.0648
	old_data_grads_norm = 6.0429
	sim_grads_norm_tr = -0.0301
-- Starting training on experience 139 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3713
	data_grads_norm = 4.6323
	new_data_grads_norm = 5.9307
	old_data_grads_norm = 5.4331
	sim_grads_norm_tr = 0.1558
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2162
	data_grads_norm = 4.8294
	new_data_grads_norm = 6.8799
	old_data_grads_norm = 6.8522
	sim_grads_norm_tr = -0.0019
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3871
	data_grads_norm = 4.5462
	new_data_grads_norm = 5.9187
	old_data_grads_norm = 7.0068
	sim_grads_norm_tr = -0.0396
-- Starting training on experience 140 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4462
	data_grads_norm = 3.9469
	new_data_grads_norm = 6.2020
	old_data_grads_norm = 4.8331
	sim_grads_norm_tr = 0.0555
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0608
	data_grads_norm = 4.0010
	new_data_grads_norm = 6.1234
	old_data_grads_norm = 4.9761
	sim_grads_norm_tr = 0.0671
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2582
	data_grads_norm = 3.9171
	new_data_grads_norm = 6.4220
	old_data_grads_norm = 5.3969
	sim_grads_norm_tr = -0.0720
-- Starting training on experience 141 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5136
	data_grads_norm = 4.2295
	new_data_grads_norm = 5.7682
	old_data_grads_norm = 5.6337
	sim_grads_norm_tr = 0.0197
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0509
	data_grads_norm = 3.7477
	new_data_grads_norm = 6.1114
	old_data_grads_norm = 4.5391
	sim_grads_norm_tr = -0.0510
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3660
	data_grads_norm = 4.2360
	new_data_grads_norm = 6.5113
	old_data_grads_norm = 5.2822
	sim_grads_norm_tr = 0.1446
-- Starting training on experience 142 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3798
	data_grads_norm = 4.6395
	new_data_grads_norm = 6.7855
	old_data_grads_norm = 6.3396
	sim_grads_norm_tr = 0.0440
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8232
	data_grads_norm = 4.9530
	new_data_grads_norm = 6.4734
	old_data_grads_norm = 7.0222
	sim_grads_norm_tr = 0.1960
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6809
	data_grads_norm = 5.2456
	new_data_grads_norm = 5.4494
	old_data_grads_norm = 7.2341
	sim_grads_norm_tr = -0.0108
-- Starting training on experience 143 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0740
	data_grads_norm = 4.3217
	new_data_grads_norm = 5.7484
	old_data_grads_norm = 5.9983
	sim_grads_norm_tr = 0.0228
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1125
	data_grads_norm = 4.7332
	new_data_grads_norm = 5.3130
	old_data_grads_norm = 7.1445
	sim_grads_norm_tr = 0.0688
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1991
	data_grads_norm = 4.0798
	new_data_grads_norm = 5.3311
	old_data_grads_norm = 5.8513
	sim_grads_norm_tr = -0.0569
-- Starting training on experience 144 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4023
	data_grads_norm = 4.0956
	new_data_grads_norm = 5.8537
	old_data_grads_norm = 5.6765
	sim_grads_norm_tr = 0.0212
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3736
	data_grads_norm = 4.5218
	new_data_grads_norm = 6.4566
	old_data_grads_norm = 6.2935
	sim_grads_norm_tr = 0.0043
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4172
	data_grads_norm = 4.6018
	new_data_grads_norm = 6.3803
	old_data_grads_norm = 7.0656
	sim_grads_norm_tr = 0.0184
-- Starting training on experience 145 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4575
	data_grads_norm = 4.0376
	new_data_grads_norm = 5.6104
	old_data_grads_norm = 5.1255
	sim_grads_norm_tr = 0.1394
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3134
	data_grads_norm = 4.6226
	new_data_grads_norm = 6.0676
	old_data_grads_norm = 6.6320
	sim_grads_norm_tr = 0.0426
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1498
	data_grads_norm = 4.1105
	new_data_grads_norm = 5.1457
	old_data_grads_norm = 6.4431
	sim_grads_norm_tr = -0.0526
-- Starting training on experience 146 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1939
	data_grads_norm = 3.7605
	new_data_grads_norm = 5.0574
	old_data_grads_norm = 4.9570
	sim_grads_norm_tr = 0.0083
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3498
	data_grads_norm = 3.7988
	new_data_grads_norm = 5.2183
	old_data_grads_norm = 4.9964
	sim_grads_norm_tr = 0.1263
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1085
	data_grads_norm = 3.7582
	new_data_grads_norm = 5.6021
	old_data_grads_norm = 5.4066
	sim_grads_norm_tr = 0.0114
-- Starting training on experience 147 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1213
	data_grads_norm = 4.3128
	new_data_grads_norm = 5.6295
	old_data_grads_norm = 5.6814
	sim_grads_norm_tr = 0.0771
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2066
	data_grads_norm = 3.8812
	new_data_grads_norm = 4.9739
	old_data_grads_norm = 5.8328
	sim_grads_norm_tr = 0.0054
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0618
	data_grads_norm = 3.6298
	new_data_grads_norm = 5.2376
	old_data_grads_norm = 5.0179
	sim_grads_norm_tr = -0.0609
-- Starting training on experience 148 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2850
	data_grads_norm = 3.8756
	new_data_grads_norm = 5.4057
	old_data_grads_norm = 5.2745
	sim_grads_norm_tr = 0.0180
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1131
	data_grads_norm = 3.8458
	new_data_grads_norm = 5.6133
	old_data_grads_norm = 5.0376
	sim_grads_norm_tr = 0.0077
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6080
	data_grads_norm = 4.3011
	new_data_grads_norm = 5.6944
	old_data_grads_norm = 5.5198
	sim_grads_norm_tr = 0.0837
-- Starting training on experience 149 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2165
	data_grads_norm = 4.0124
	new_data_grads_norm = 5.6351
	old_data_grads_norm = 5.6240
	sim_grads_norm_tr = -0.0245
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1708
	data_grads_norm = 4.1084
	new_data_grads_norm = 5.9730
	old_data_grads_norm = 5.3713
	sim_grads_norm_tr = 0.0055
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2183
	data_grads_norm = 3.9653
	new_data_grads_norm = 5.4443
	old_data_grads_norm = 5.3800
	sim_grads_norm_tr = -0.0763
-- Starting training on experience 150 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2577
	data_grads_norm = 4.1933
	new_data_grads_norm = 5.8631
	old_data_grads_norm = 5.8498
	sim_grads_norm_tr = 0.0507
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3464
	data_grads_norm = 4.9649
	new_data_grads_norm = 6.1564
	old_data_grads_norm = 6.5578
	sim_grads_norm_tr = -0.0129
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9186
	data_grads_norm = 3.2876
	new_data_grads_norm = 5.2131
	old_data_grads_norm = 4.3331
	sim_grads_norm_tr = -0.0102
-- Starting training on experience 151 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7877
	data_grads_norm = 4.5157
	new_data_grads_norm = 6.4698
	old_data_grads_norm = 5.4859
	sim_grads_norm_tr = 0.0730
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3737
	data_grads_norm = 3.7809
	new_data_grads_norm = 6.4741
	old_data_grads_norm = 4.1327
	sim_grads_norm_tr = 0.0193
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3661
	data_grads_norm = 4.4575
	new_data_grads_norm = 6.4057
	old_data_grads_norm = 6.3572
	sim_grads_norm_tr = -0.0459
-- Starting training on experience 152 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9770
	data_grads_norm = 3.7887
	new_data_grads_norm = 5.6120
	old_data_grads_norm = 4.9480
	sim_grads_norm_tr = 0.0187
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6391
	data_grads_norm = 4.6833
	new_data_grads_norm = 6.0858
	old_data_grads_norm = 7.4018
	sim_grads_norm_tr = -0.0104
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3796
	data_grads_norm = 4.7388
	new_data_grads_norm = 6.3296
	old_data_grads_norm = 7.5308
	sim_grads_norm_tr = 0.0075
-- Starting training on experience 153 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1983
	data_grads_norm = 3.9815
	new_data_grads_norm = 5.7111
	old_data_grads_norm = 4.7758
	sim_grads_norm_tr = 0.0845
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5456
	data_grads_norm = 3.9420
	new_data_grads_norm = 5.8159
	old_data_grads_norm = 5.4286
	sim_grads_norm_tr = -0.0461
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2895
	data_grads_norm = 4.4796
	new_data_grads_norm = 6.2267
	old_data_grads_norm = 5.3695
	sim_grads_norm_tr = 0.1248
-- Starting training on experience 154 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4102
	data_grads_norm = 4.0650
	new_data_grads_norm = 6.0101
	old_data_grads_norm = 5.4919
	sim_grads_norm_tr = 0.0313
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6484
	data_grads_norm = 4.0728
	new_data_grads_norm = 5.9906
	old_data_grads_norm = 5.4178
	sim_grads_norm_tr = -0.0131
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4680
	data_grads_norm = 4.3808
	new_data_grads_norm = 5.4863
	old_data_grads_norm = 5.3312
	sim_grads_norm_tr = 0.0568
-- Starting training on experience 155 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5266
	data_grads_norm = 4.0581
	new_data_grads_norm = 5.9684
	old_data_grads_norm = 5.8089
	sim_grads_norm_tr = 0.0534
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4784
	data_grads_norm = 4.8276
	new_data_grads_norm = 6.2841
	old_data_grads_norm = 6.1877
	sim_grads_norm_tr = 0.0211
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1782
	data_grads_norm = 3.8848
	new_data_grads_norm = 6.1161
	old_data_grads_norm = 5.2416
	sim_grads_norm_tr = -0.1209
-- Starting training on experience 156 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5598
	data_grads_norm = 4.7881
	new_data_grads_norm = 6.4211
	old_data_grads_norm = 6.9324
	sim_grads_norm_tr = -0.0034
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1811
	data_grads_norm = 4.4194
	new_data_grads_norm = 6.7671
	old_data_grads_norm = 5.8529
	sim_grads_norm_tr = 0.0541
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7602
	data_grads_norm = 4.8099
	new_data_grads_norm = 7.1904
	old_data_grads_norm = 5.4639
	sim_grads_norm_tr = 0.0820
-- Starting training on experience 157 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4098
	data_grads_norm = 4.3023
	new_data_grads_norm = 5.8776
	old_data_grads_norm = 5.3969
	sim_grads_norm_tr = 0.0925
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4811
	data_grads_norm = 4.4160
	new_data_grads_norm = 5.7923
	old_data_grads_norm = 5.6984
	sim_grads_norm_tr = -0.0069
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0503
	data_grads_norm = 4.0421
	new_data_grads_norm = 5.8109
	old_data_grads_norm = 5.5165
	sim_grads_norm_tr = -0.0538
-- Starting training on experience 158 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7535
	data_grads_norm = 4.0047
	new_data_grads_norm = 6.2359
	old_data_grads_norm = 4.6916
	sim_grads_norm_tr = 0.1229
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5756
	data_grads_norm = 3.7729
	new_data_grads_norm = 5.4174
	old_data_grads_norm = 4.7315
	sim_grads_norm_tr = 0.0055
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9344
	data_grads_norm = 4.4711
	new_data_grads_norm = 5.6544
	old_data_grads_norm = 6.4901
	sim_grads_norm_tr = 0.0168
-- Starting training on experience 159 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3277
	data_grads_norm = 3.9202
	new_data_grads_norm = 5.2404
	old_data_grads_norm = 5.5702
	sim_grads_norm_tr = 0.0041
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2494
	data_grads_norm = 3.9719
	new_data_grads_norm = 5.6988
	old_data_grads_norm = 5.6497
	sim_grads_norm_tr = 0.0364
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1305
	data_grads_norm = 3.9190
	new_data_grads_norm = 5.4693
	old_data_grads_norm = 5.3945
	sim_grads_norm_tr = 0.0379
-- Starting training on experience 160 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1930
	data_grads_norm = 4.1262
	new_data_grads_norm = 5.6563
	old_data_grads_norm = 5.7833
	sim_grads_norm_tr = 0.0434
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6847
	data_grads_norm = 3.5490
	new_data_grads_norm = 5.1338
	old_data_grads_norm = 5.6674
	sim_grads_norm_tr = 0.0688
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8333
	data_grads_norm = 3.4475
	new_data_grads_norm = 5.4934
	old_data_grads_norm = 4.2675
	sim_grads_norm_tr = -0.0009
-- Starting training on experience 161 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2578
	data_grads_norm = 3.7976
	new_data_grads_norm = 6.4437
	old_data_grads_norm = 4.3734
	sim_grads_norm_tr = 0.0710
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1218
	data_grads_norm = 4.0571
	new_data_grads_norm = 6.5051
	old_data_grads_norm = 5.4876
	sim_grads_norm_tr = -0.0189
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9481
	data_grads_norm = 3.6637
	new_data_grads_norm = 5.7226
	old_data_grads_norm = 4.5807
	sim_grads_norm_tr = -0.0235
-- Starting training on experience 162 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6487
	data_grads_norm = 4.7237
	new_data_grads_norm = 5.5196
	old_data_grads_norm = 6.1728
	sim_grads_norm_tr = 0.1873
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1096
	data_grads_norm = 3.7204
	new_data_grads_norm = 5.7052
	old_data_grads_norm = 5.2183
	sim_grads_norm_tr = -0.0140
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3741
	data_grads_norm = 4.3208
	new_data_grads_norm = 5.5925
	old_data_grads_norm = 6.0003
	sim_grads_norm_tr = 0.0081
-- Starting training on experience 163 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4004
	data_grads_norm = 4.2920
	new_data_grads_norm = 6.1538
	old_data_grads_norm = 5.4793
	sim_grads_norm_tr = 0.0794
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2106
	data_grads_norm = 4.0998
	new_data_grads_norm = 6.1851
	old_data_grads_norm = 5.7585
	sim_grads_norm_tr = 0.0056
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4718
	data_grads_norm = 5.3551
	new_data_grads_norm = 5.9928
	old_data_grads_norm = 6.4245
	sim_grads_norm_tr = -0.0456
-- Starting training on experience 164 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3779
	data_grads_norm = 4.6275
	new_data_grads_norm = 5.5315
	old_data_grads_norm = 5.8463
	sim_grads_norm_tr = 0.0653
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2062
	data_grads_norm = 4.2553
	new_data_grads_norm = 5.9899
	old_data_grads_norm = 6.3261
	sim_grads_norm_tr = -0.1016
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9097
	data_grads_norm = 4.3476
	new_data_grads_norm = 6.9410
	old_data_grads_norm = 5.4809
	sim_grads_norm_tr = 0.0390
-- Starting training on experience 165 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4936
	data_grads_norm = 4.8783
	new_data_grads_norm = 7.1539
	old_data_grads_norm = 6.8280
	sim_grads_norm_tr = -0.0111
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5343
	data_grads_norm = 4.5295
	new_data_grads_norm = 7.0468
	old_data_grads_norm = 5.5866
	sim_grads_norm_tr = -0.0368
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1203
	data_grads_norm = 4.7106
	new_data_grads_norm = 6.4916
	old_data_grads_norm = 6.2953
	sim_grads_norm_tr = 0.0873
-- Starting training on experience 166 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4258
	data_grads_norm = 4.9939
	new_data_grads_norm = 6.1996
	old_data_grads_norm = 6.2110
	sim_grads_norm_tr = 0.0208
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6487
	data_grads_norm = 4.2914
	new_data_grads_norm = 5.7683
	old_data_grads_norm = 5.4279
	sim_grads_norm_tr = 0.1134
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2666
	data_grads_norm = 4.1521
	new_data_grads_norm = 5.4953
	old_data_grads_norm = 5.4876
	sim_grads_norm_tr = -0.0446
-- Starting training on experience 167 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3458
	data_grads_norm = 3.8955
	new_data_grads_norm = 5.5216
	old_data_grads_norm = 5.1915
	sim_grads_norm_tr = 0.0207
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8476
	data_grads_norm = 3.4931
	new_data_grads_norm = 5.5679
	old_data_grads_norm = 4.8660
	sim_grads_norm_tr = 0.0142
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0098
	data_grads_norm = 3.6520
	new_data_grads_norm = 5.7567
	old_data_grads_norm = 4.9907
	sim_grads_norm_tr = -0.0137
-- Starting training on experience 168 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0786
	data_grads_norm = 4.1220
	new_data_grads_norm = 5.8124
	old_data_grads_norm = 5.4955
	sim_grads_norm_tr = -0.0168
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7253
	data_grads_norm = 4.5613
	new_data_grads_norm = 5.9208
	old_data_grads_norm = 6.6778
	sim_grads_norm_tr = 0.0444
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5191
	data_grads_norm = 4.6081
	new_data_grads_norm = 5.8442
	old_data_grads_norm = 7.0627
	sim_grads_norm_tr = -0.0261
-- Starting training on experience 169 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9984
	data_grads_norm = 5.7292
	new_data_grads_norm = 7.2940
	old_data_grads_norm = 8.9414
	sim_grads_norm_tr = 0.1111
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3310
	data_grads_norm = 5.5443
	new_data_grads_norm = 6.7364
	old_data_grads_norm = 8.1651
	sim_grads_norm_tr = -0.0147
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7525
	data_grads_norm = 5.1926
	new_data_grads_norm = 6.6278
	old_data_grads_norm = 6.1734
	sim_grads_norm_tr = 0.0339
-- Starting training on experience 170 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3842
	data_grads_norm = 4.1474
	new_data_grads_norm = 5.5229
	old_data_grads_norm = 5.5906
	sim_grads_norm_tr = 0.0872
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5332
	data_grads_norm = 3.9740
	new_data_grads_norm = 5.5248
	old_data_grads_norm = 5.1540
	sim_grads_norm_tr = 0.0284
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2512
	data_grads_norm = 3.8294
	new_data_grads_norm = 4.9343
	old_data_grads_norm = 5.1878
	sim_grads_norm_tr = -0.0114
-- Starting training on experience 171 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1405
	data_grads_norm = 4.3450
	new_data_grads_norm = 5.9655
	old_data_grads_norm = 6.8661
	sim_grads_norm_tr = 0.0295
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1646
	data_grads_norm = 3.8485
	new_data_grads_norm = 6.0414
	old_data_grads_norm = 5.7599
	sim_grads_norm_tr = -0.0944
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4323
	data_grads_norm = 4.2256
	new_data_grads_norm = 6.4122
	old_data_grads_norm = 5.2101
	sim_grads_norm_tr = 0.1059
-- Starting training on experience 172 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7864
	data_grads_norm = 4.5585
	new_data_grads_norm = 6.7639
	old_data_grads_norm = 6.0694
	sim_grads_norm_tr = 0.0939
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7694
	data_grads_norm = 4.5952
	new_data_grads_norm = 6.2946
	old_data_grads_norm = 5.9892
	sim_grads_norm_tr = 0.0176
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3681
	data_grads_norm = 4.3332
	new_data_grads_norm = 6.5054
	old_data_grads_norm = 4.6711
	sim_grads_norm_tr = 0.0328
-- Starting training on experience 173 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5712
	data_grads_norm = 4.1946
	new_data_grads_norm = 5.8975
	old_data_grads_norm = 4.8654
	sim_grads_norm_tr = 0.1009
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7654
	data_grads_norm = 4.8418
	new_data_grads_norm = 6.0910
	old_data_grads_norm = 6.6352
	sim_grads_norm_tr = 0.0452
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4021
	data_grads_norm = 4.0764
	new_data_grads_norm = 5.5982
	old_data_grads_norm = 5.2888
	sim_grads_norm_tr = -0.0464
-- Starting training on experience 174 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2137
	data_grads_norm = 3.7382
	new_data_grads_norm = 5.3112
	old_data_grads_norm = 5.2386
	sim_grads_norm_tr = -0.0329
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3971
	data_grads_norm = 4.1601
	new_data_grads_norm = 6.0213
	old_data_grads_norm = 5.6507
	sim_grads_norm_tr = -0.0211
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0444
	data_grads_norm = 4.4253
	new_data_grads_norm = 6.1541
	old_data_grads_norm = 6.2778
	sim_grads_norm_tr = 0.0256
-- Starting training on experience 175 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1148
	data_grads_norm = 4.2535
	new_data_grads_norm = 5.9771
	old_data_grads_norm = 5.4650
	sim_grads_norm_tr = 0.0176
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9213
	data_grads_norm = 3.6727
	new_data_grads_norm = 6.1307
	old_data_grads_norm = 4.1157
	sim_grads_norm_tr = 0.0149
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8430
	data_grads_norm = 4.0482
	new_data_grads_norm = 5.8838
	old_data_grads_norm = 5.4595
	sim_grads_norm_tr = -0.0095
-- Starting training on experience 176 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2193
	data_grads_norm = 4.5552
	new_data_grads_norm = 6.0882
	old_data_grads_norm = 6.7135
	sim_grads_norm_tr = -0.0588
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2182
	data_grads_norm = 4.3639
	new_data_grads_norm = 6.5386
	old_data_grads_norm = 4.7057
	sim_grads_norm_tr = 0.1660
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1503
	data_grads_norm = 4.5825
	new_data_grads_norm = 6.0271
	old_data_grads_norm = 7.2374
	sim_grads_norm_tr = -0.0117
-- Starting training on experience 177 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8714
	data_grads_norm = 3.5865
	new_data_grads_norm = 6.3723
	old_data_grads_norm = 4.7277
	sim_grads_norm_tr = -0.0276
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4822
	data_grads_norm = 4.8660
	new_data_grads_norm = 6.0016
	old_data_grads_norm = 6.6694
	sim_grads_norm_tr = 0.1281
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6132
	data_grads_norm = 4.3239
	new_data_grads_norm = 6.3294
	old_data_grads_norm = 5.6557
	sim_grads_norm_tr = 0.0434
-- Starting training on experience 178 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6638
	data_grads_norm = 4.0742
	new_data_grads_norm = 6.2850
	old_data_grads_norm = 4.9279
	sim_grads_norm_tr = 0.0884
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7659
	data_grads_norm = 4.7174
	new_data_grads_norm = 5.7556
	old_data_grads_norm = 7.2091
	sim_grads_norm_tr = -0.0239
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3781
	data_grads_norm = 3.9507
	new_data_grads_norm = 6.1880
	old_data_grads_norm = 4.7745
	sim_grads_norm_tr = 0.2029
-- Starting training on experience 179 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0335
	data_grads_norm = 4.2468
	new_data_grads_norm = 6.0457
	old_data_grads_norm = 5.6723
	sim_grads_norm_tr = 0.0155
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0588
	data_grads_norm = 4.6142
	new_data_grads_norm = 6.3425
	old_data_grads_norm = 5.8564
	sim_grads_norm_tr = 0.0212
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0387
	data_grads_norm = 4.2569
	new_data_grads_norm = 6.6980
	old_data_grads_norm = 4.8031
	sim_grads_norm_tr = 0.0460
-- Starting training on experience 180 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6029
	data_grads_norm = 4.6978
	new_data_grads_norm = 6.4742
	old_data_grads_norm = 6.6723
	sim_grads_norm_tr = -0.0120
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8705
	data_grads_norm = 5.1264
	new_data_grads_norm = 6.5245
	old_data_grads_norm = 6.9835
	sim_grads_norm_tr = 0.0349
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2050
	data_grads_norm = 4.0422
	new_data_grads_norm = 6.2919
	old_data_grads_norm = 5.1402
	sim_grads_norm_tr = 0.0725
-- Starting training on experience 181 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1606
	data_grads_norm = 4.2624
	new_data_grads_norm = 5.6872
	old_data_grads_norm = 6.0911
	sim_grads_norm_tr = 0.1082
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3112
	data_grads_norm = 4.2943
	new_data_grads_norm = 5.8826
	old_data_grads_norm = 5.9156
	sim_grads_norm_tr = -0.0254
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4873
	data_grads_norm = 4.2648
	new_data_grads_norm = 6.0968
	old_data_grads_norm = 6.2442
	sim_grads_norm_tr = 0.0780
-- Starting training on experience 182 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6125
	data_grads_norm = 4.2484
	new_data_grads_norm = 5.8299
	old_data_grads_norm = 6.5857
	sim_grads_norm_tr = -0.0080
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7590
	data_grads_norm = 4.7267
	new_data_grads_norm = 6.7131
	old_data_grads_norm = 6.0132
	sim_grads_norm_tr = 0.0052
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4348
	data_grads_norm = 4.2845
	new_data_grads_norm = 5.8128
	old_data_grads_norm = 7.1843
	sim_grads_norm_tr = 0.0202
-- Starting training on experience 183 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4211
	data_grads_norm = 4.5289
	new_data_grads_norm = 6.2976
	old_data_grads_norm = 5.3242
	sim_grads_norm_tr = 0.0193
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2479
	data_grads_norm = 5.0144
	new_data_grads_norm = 6.5329
	old_data_grads_norm = 6.7199
	sim_grads_norm_tr = 0.0117
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8141
	data_grads_norm = 4.6854
	new_data_grads_norm = 6.7653
	old_data_grads_norm = 4.7241
	sim_grads_norm_tr = 0.2718
-- Starting training on experience 184 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8904
	data_grads_norm = 4.0665
	new_data_grads_norm = 6.1025
	old_data_grads_norm = 5.4691
	sim_grads_norm_tr = -0.0390
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4655
	data_grads_norm = 4.2915
	new_data_grads_norm = 6.0969
	old_data_grads_norm = 5.1604
	sim_grads_norm_tr = -0.0394
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1593
	data_grads_norm = 4.1587
	new_data_grads_norm = 6.1967
	old_data_grads_norm = 5.3442
	sim_grads_norm_tr = 0.0109
-- Starting training on experience 185 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1162
	data_grads_norm = 4.8021
	new_data_grads_norm = 7.2613
	old_data_grads_norm = 6.0386
	sim_grads_norm_tr = 0.1069
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2517
	data_grads_norm = 4.6405
	new_data_grads_norm = 6.9625
	old_data_grads_norm = 7.2321
	sim_grads_norm_tr = 0.0062
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1162
	data_grads_norm = 4.3876
	new_data_grads_norm = 7.1978
	old_data_grads_norm = 4.3348
	sim_grads_norm_tr = 0.0064
-- Starting training on experience 186 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2332
	data_grads_norm = 3.6696
	new_data_grads_norm = 6.1233
	old_data_grads_norm = 5.0501
	sim_grads_norm_tr = 0.0361
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5682
	data_grads_norm = 4.6552
	new_data_grads_norm = 5.3937
	old_data_grads_norm = 5.2576
	sim_grads_norm_tr = 0.1945
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7527
	data_grads_norm = 3.6364
	new_data_grads_norm = 5.7166
	old_data_grads_norm = 3.8603
	sim_grads_norm_tr = -0.0988
-- Starting training on experience 187 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1140
	data_grads_norm = 3.8912
	new_data_grads_norm = 6.0986
	old_data_grads_norm = 4.1755
	sim_grads_norm_tr = 0.0466
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1923
	data_grads_norm = 3.9581
	new_data_grads_norm = 5.6843
	old_data_grads_norm = 5.9931
	sim_grads_norm_tr = -0.0272
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1938
	data_grads_norm = 4.3408
	new_data_grads_norm = 5.2063
	old_data_grads_norm = 6.9663
	sim_grads_norm_tr = 0.0326
-- Starting training on experience 188 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3652
	data_grads_norm = 4.8393
	new_data_grads_norm = 6.0347
	old_data_grads_norm = 5.7622
	sim_grads_norm_tr = 0.1069
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4595
	data_grads_norm = 4.8264
	new_data_grads_norm = 5.8535
	old_data_grads_norm = 6.3309
	sim_grads_norm_tr = 0.0928
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8727
	data_grads_norm = 3.8570
	new_data_grads_norm = 5.4945
	old_data_grads_norm = 5.7085
	sim_grads_norm_tr = -0.0656
-- Starting training on experience 189 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9604
	data_grads_norm = 3.7727
	new_data_grads_norm = 5.8372
	old_data_grads_norm = 4.9989
	sim_grads_norm_tr = -0.0976
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3363
	data_grads_norm = 5.4711
	new_data_grads_norm = 6.3125
	old_data_grads_norm = 6.6860
	sim_grads_norm_tr = 0.1658
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1259
	data_grads_norm = 4.6179
	new_data_grads_norm = 5.6347
	old_data_grads_norm = 6.5112
	sim_grads_norm_tr = 0.0864
-- Starting training on experience 190 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4986
	data_grads_norm = 3.3375
	new_data_grads_norm = 5.3374
	old_data_grads_norm = 5.5545
	sim_grads_norm_tr = -0.1479
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6681
	data_grads_norm = 3.9284
	new_data_grads_norm = 6.2991
	old_data_grads_norm = 4.8217
	sim_grads_norm_tr = 0.0172
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8767
	data_grads_norm = 4.5638
	new_data_grads_norm = 6.8537
	old_data_grads_norm = 6.4162
	sim_grads_norm_tr = 0.0678
-- Starting training on experience 191 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4057
	data_grads_norm = 3.9998
	new_data_grads_norm = 6.5283
	old_data_grads_norm = 4.7180
	sim_grads_norm_tr = 0.0375
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5794
	data_grads_norm = 4.3265
	new_data_grads_norm = 7.0137
	old_data_grads_norm = 5.1781
	sim_grads_norm_tr = 0.0473
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3776
	data_grads_norm = 4.0822
	new_data_grads_norm = 6.2499
	old_data_grads_norm = 5.7302
	sim_grads_norm_tr = -0.0267
-- Starting training on experience 192 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0729
	data_grads_norm = 4.1310
	new_data_grads_norm = 6.3416
	old_data_grads_norm = 6.0423
	sim_grads_norm_tr = -0.0599
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4202
	data_grads_norm = 4.7259
	new_data_grads_norm = 6.9133
	old_data_grads_norm = 5.5981
	sim_grads_norm_tr = 0.0114
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2552
	data_grads_norm = 4.3626
	new_data_grads_norm = 6.3547
	old_data_grads_norm = 6.0819
	sim_grads_norm_tr = -0.0732
-- Starting training on experience 193 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0804
	data_grads_norm = 4.6993
	new_data_grads_norm = 7.2660
	old_data_grads_norm = 5.5785
	sim_grads_norm_tr = 0.0186
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7097
	data_grads_norm = 4.0126
	new_data_grads_norm = 7.9128
	old_data_grads_norm = 4.6548
	sim_grads_norm_tr = -0.0228
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3066
	data_grads_norm = 4.7079
	new_data_grads_norm = 7.2141
	old_data_grads_norm = 6.7950
	sim_grads_norm_tr = -0.0542
-- Starting training on experience 194 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3268
	data_grads_norm = 4.6386
	new_data_grads_norm = 6.9511
	old_data_grads_norm = 6.2685
	sim_grads_norm_tr = 0.0017
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5062
	data_grads_norm = 4.3837
	new_data_grads_norm = 6.8275
	old_data_grads_norm = 5.3256
	sim_grads_norm_tr = 0.0926
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7016
	data_grads_norm = 4.6989
	new_data_grads_norm = 6.7811
	old_data_grads_norm = 5.5993
	sim_grads_norm_tr = 0.1008
-- Starting training on experience 195 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4913
	data_grads_norm = 5.4202
	new_data_grads_norm = 5.9729
	old_data_grads_norm = 7.1876
	sim_grads_norm_tr = 0.0102
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9559
	data_grads_norm = 3.7775
	new_data_grads_norm = 5.2956
	old_data_grads_norm = 4.7507
	sim_grads_norm_tr = 0.0827
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2105
	data_grads_norm = 4.6393
	new_data_grads_norm = 5.5727
	old_data_grads_norm = 6.2469
	sim_grads_norm_tr = 0.0911
-- Starting training on experience 196 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0904
	data_grads_norm = 3.9160
	new_data_grads_norm = 6.2968
	old_data_grads_norm = 4.2957
	sim_grads_norm_tr = 0.1463
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8818
	data_grads_norm = 3.6726
	new_data_grads_norm = 5.6096
	old_data_grads_norm = 5.1141
	sim_grads_norm_tr = -0.0317
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8228
	data_grads_norm = 3.6760
	new_data_grads_norm = 6.1087
	old_data_grads_norm = 4.4852
	sim_grads_norm_tr = 0.0160
-- Starting training on experience 197 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7732
	data_grads_norm = 4.7539
	new_data_grads_norm = 6.2237
	old_data_grads_norm = 6.7583
	sim_grads_norm_tr = 0.0160
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0717
	data_grads_norm = 4.0267
	new_data_grads_norm = 5.9771
	old_data_grads_norm = 5.2718
	sim_grads_norm_tr = 0.0437
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2947
	data_grads_norm = 4.4181
	new_data_grads_norm = 6.4560
	old_data_grads_norm = 5.0749
	sim_grads_norm_tr = 0.0613
-- Starting training on experience 198 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1804
	data_grads_norm = 4.3921
	new_data_grads_norm = 5.6598
	old_data_grads_norm = 5.3968
	sim_grads_norm_tr = 0.0506
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5699
	data_grads_norm = 4.5521
	new_data_grads_norm = 6.2723
	old_data_grads_norm = 6.6611
	sim_grads_norm_tr = 0.0529
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0622
	data_grads_norm = 3.8253
	new_data_grads_norm = 5.2970
	old_data_grads_norm = 4.9305
	sim_grads_norm_tr = -0.0498
-- Starting training on experience 199 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3033
	data_grads_norm = 3.7552
	new_data_grads_norm = 5.5047
	old_data_grads_norm = 4.8324
	sim_grads_norm_tr = 0.0191
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4333
	data_grads_norm = 4.2204
	new_data_grads_norm = 5.5386
	old_data_grads_norm = 6.0612
	sim_grads_norm_tr = 0.0170
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1312
	data_grads_norm = 4.1365
	new_data_grads_norm = 5.8414
	old_data_grads_norm = 5.5856
	sim_grads_norm_tr = 0.0247
-- Starting training on experience 200 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0987
	data_grads_norm = 4.3808
	new_data_grads_norm = 6.4454
	old_data_grads_norm = 5.4878
	sim_grads_norm_tr = 0.0648
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8641
	data_grads_norm = 4.7671
	new_data_grads_norm = 6.6178
	old_data_grads_norm = 6.8634
	sim_grads_norm_tr = -0.0870
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4257
	data_grads_norm = 4.5022
	new_data_grads_norm = 6.0923
	old_data_grads_norm = 6.2903
	sim_grads_norm_tr = -0.0497
-- Starting training on experience 201 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1549
	data_grads_norm = 3.6940
	new_data_grads_norm = 5.6889
	old_data_grads_norm = 4.9938
	sim_grads_norm_tr = 0.0295
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9835
	data_grads_norm = 4.3751
	new_data_grads_norm = 5.5966
	old_data_grads_norm = 6.6448
	sim_grads_norm_tr = -0.0193
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2618
	data_grads_norm = 4.5324
	new_data_grads_norm = 6.0882
	old_data_grads_norm = 6.0460
	sim_grads_norm_tr = 0.0375
-- Starting training on experience 202 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6136
	data_grads_norm = 5.2186
	new_data_grads_norm = 6.1263
	old_data_grads_norm = 7.6949
	sim_grads_norm_tr = 0.0429
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0092
	data_grads_norm = 4.7033
	new_data_grads_norm = 6.8751
	old_data_grads_norm = 4.5764
	sim_grads_norm_tr = -0.0051
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0580
	data_grads_norm = 5.0297
	new_data_grads_norm = 6.9057
	old_data_grads_norm = 7.7135
	sim_grads_norm_tr = 0.0614
-- Starting training on experience 203 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7895
	data_grads_norm = 4.6784
	new_data_grads_norm = 6.7651
	old_data_grads_norm = 6.2654
	sim_grads_norm_tr = 0.1565
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4915
	data_grads_norm = 4.5310
	new_data_grads_norm = 5.6964
	old_data_grads_norm = 7.4854
	sim_grads_norm_tr = 0.0416
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4428
	data_grads_norm = 5.0064
	new_data_grads_norm = 6.3402
	old_data_grads_norm = 7.2799
	sim_grads_norm_tr = -0.0837
-- Starting training on experience 204 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7079
	data_grads_norm = 4.8878
	new_data_grads_norm = 6.4129
	old_data_grads_norm = 7.2795
	sim_grads_norm_tr = 0.0901
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8552
	data_grads_norm = 4.7496
	new_data_grads_norm = 6.3718
	old_data_grads_norm = 7.5244
	sim_grads_norm_tr = 0.0281
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2424
	data_grads_norm = 3.4826
	new_data_grads_norm = 5.8098
	old_data_grads_norm = 5.0946
	sim_grads_norm_tr = -0.0488
-- Starting training on experience 205 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5474
	data_grads_norm = 4.1730
	new_data_grads_norm = 5.4065
	old_data_grads_norm = 6.2915
	sim_grads_norm_tr = -0.0069
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1875
	data_grads_norm = 4.3797
	new_data_grads_norm = 5.5639
	old_data_grads_norm = 6.5166
	sim_grads_norm_tr = 0.0322
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1819
	data_grads_norm = 4.5267
	new_data_grads_norm = 5.8705
	old_data_grads_norm = 6.0630
	sim_grads_norm_tr = 0.0797
-- Starting training on experience 206 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2310
	data_grads_norm = 4.2289
	new_data_grads_norm = 5.9521
	old_data_grads_norm = 6.2175
	sim_grads_norm_tr = 0.0278
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6947
	data_grads_norm = 3.9225
	new_data_grads_norm = 5.2995
	old_data_grads_norm = 5.2930
	sim_grads_norm_tr = 0.1540
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0781
	data_grads_norm = 4.1079
	new_data_grads_norm = 5.1520
	old_data_grads_norm = 6.6392
	sim_grads_norm_tr = 0.0395
-- Starting training on experience 207 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7802
	data_grads_norm = 3.7906
	new_data_grads_norm = 5.4758
	old_data_grads_norm = 5.3680
	sim_grads_norm_tr = 0.0016
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2235
	data_grads_norm = 4.1135
	new_data_grads_norm = 5.8558
	old_data_grads_norm = 4.7103
	sim_grads_norm_tr = -0.0692
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6949
	data_grads_norm = 3.5862
	new_data_grads_norm = 5.1898
	old_data_grads_norm = 4.8659
	sim_grads_norm_tr = 0.0323
-- Starting training on experience 208 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3709
	data_grads_norm = 4.3012
	new_data_grads_norm = 5.4218
	old_data_grads_norm = 6.8857
	sim_grads_norm_tr = -0.0364
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4771
	data_grads_norm = 5.0526
	new_data_grads_norm = 5.8094
	old_data_grads_norm = 7.9099
	sim_grads_norm_tr = 0.1669
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2048
	data_grads_norm = 4.2267
	new_data_grads_norm = 5.3764
	old_data_grads_norm = 5.7292
	sim_grads_norm_tr = 0.1064
-- Starting training on experience 209 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2413
	data_grads_norm = 3.7725
	new_data_grads_norm = 5.6487
	old_data_grads_norm = 4.2377
	sim_grads_norm_tr = -0.0050
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3368
	data_grads_norm = 3.8955
	new_data_grads_norm = 5.9138
	old_data_grads_norm = 4.6646
	sim_grads_norm_tr = 0.0272
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0016
	data_grads_norm = 3.7673
	new_data_grads_norm = 5.6207
	old_data_grads_norm = 4.5757
	sim_grads_norm_tr = -0.0550
-- Starting training on experience 210 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8777
	data_grads_norm = 4.2809
	new_data_grads_norm = 5.6849
	old_data_grads_norm = 6.4358
	sim_grads_norm_tr = -0.0044
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0547
	data_grads_norm = 3.8433
	new_data_grads_norm = 5.8993
	old_data_grads_norm = 4.9388
	sim_grads_norm_tr = 0.0803
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7424
	data_grads_norm = 3.7867
	new_data_grads_norm = 5.0851
	old_data_grads_norm = 5.1297
	sim_grads_norm_tr = 0.1119
-- Starting training on experience 211 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9217
	data_grads_norm = 4.0934
	new_data_grads_norm = 5.5248
	old_data_grads_norm = 5.4682
	sim_grads_norm_tr = 0.0470
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8678
	data_grads_norm = 3.7297
	new_data_grads_norm = 5.8486
	old_data_grads_norm = 5.3684
	sim_grads_norm_tr = -0.0816
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9370
	data_grads_norm = 4.0147
	new_data_grads_norm = 5.9416
	old_data_grads_norm = 4.6094
	sim_grads_norm_tr = 0.0203
-- Starting training on experience 212 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8503
	data_grads_norm = 3.7839
	new_data_grads_norm = 5.2900
	old_data_grads_norm = 5.1612
	sim_grads_norm_tr = -0.0952
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7447
	data_grads_norm = 3.5542
	new_data_grads_norm = 5.5232
	old_data_grads_norm = 4.6271
	sim_grads_norm_tr = -0.0735
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1704
	data_grads_norm = 4.8760
	new_data_grads_norm = 5.3305
	old_data_grads_norm = 7.2529
	sim_grads_norm_tr = -0.0135
-- Starting training on experience 213 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4495
	data_grads_norm = 4.4282
	new_data_grads_norm = 6.3556
	old_data_grads_norm = 5.3829
	sim_grads_norm_tr = 0.0322
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8073
	data_grads_norm = 3.7614
	new_data_grads_norm = 6.0854
	old_data_grads_norm = 5.0761
	sim_grads_norm_tr = -0.0434
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8319
	data_grads_norm = 3.9863
	new_data_grads_norm = 6.5774
	old_data_grads_norm = 4.7271
	sim_grads_norm_tr = -0.0481
-- Starting training on experience 214 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3305
	data_grads_norm = 4.7653
	new_data_grads_norm = 6.7194
	old_data_grads_norm = 7.2763
	sim_grads_norm_tr = 0.0019
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7174
	data_grads_norm = 4.7599
	new_data_grads_norm = 6.2780
	old_data_grads_norm = 6.3640
	sim_grads_norm_tr = 0.0620
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3963
	data_grads_norm = 4.5073
	new_data_grads_norm = 6.2901
	old_data_grads_norm = 5.6336
	sim_grads_norm_tr = 0.0554
-- Starting training on experience 215 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0977
	data_grads_norm = 4.2259
	new_data_grads_norm = 7.0300
	old_data_grads_norm = 4.6275
	sim_grads_norm_tr = 0.0684
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4763
	data_grads_norm = 5.0135
	new_data_grads_norm = 7.2177
	old_data_grads_norm = 6.7884
	sim_grads_norm_tr = 0.0394
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6847
	data_grads_norm = 3.9699
	new_data_grads_norm = 6.7076
	old_data_grads_norm = 4.3960
	sim_grads_norm_tr = 0.1314
-- Starting training on experience 216 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7644
	data_grads_norm = 3.2310
	new_data_grads_norm = 5.8776
	old_data_grads_norm = 4.3014
	sim_grads_norm_tr = -0.0597
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0384
	data_grads_norm = 4.3126
	new_data_grads_norm = 6.1923
	old_data_grads_norm = 5.7485
	sim_grads_norm_tr = 0.0382
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0010
	data_grads_norm = 4.6835
	new_data_grads_norm = 7.0168
	old_data_grads_norm = 6.1688
	sim_grads_norm_tr = -0.1056
-- Starting training on experience 217 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0354
	data_grads_norm = 4.5982
	new_data_grads_norm = 5.8678
	old_data_grads_norm = 5.7949
	sim_grads_norm_tr = 0.0502
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4460
	data_grads_norm = 4.7624
	new_data_grads_norm = 6.4460
	old_data_grads_norm = 7.3724
	sim_grads_norm_tr = -0.0126
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0200
	data_grads_norm = 4.0589
	new_data_grads_norm = 5.9177
	old_data_grads_norm = 5.1306
	sim_grads_norm_tr = 0.0706
-- Starting training on experience 218 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1357
	data_grads_norm = 4.5886
	new_data_grads_norm = 6.6509
	old_data_grads_norm = 6.1200
	sim_grads_norm_tr = 0.1095
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8987
	data_grads_norm = 3.9255
	new_data_grads_norm = 6.0074
	old_data_grads_norm = 4.6971
	sim_grads_norm_tr = 0.0373
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9824
	data_grads_norm = 4.4623
	new_data_grads_norm = 6.1816
	old_data_grads_norm = 6.4273
	sim_grads_norm_tr = 0.0110
-- Starting training on experience 219 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5759
	data_grads_norm = 4.4098
	new_data_grads_norm = 6.2197
	old_data_grads_norm = 5.6428
	sim_grads_norm_tr = 0.0444
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4507
	data_grads_norm = 3.7818
	new_data_grads_norm = 5.9775
	old_data_grads_norm = 4.9284
	sim_grads_norm_tr = -0.0527
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5950
	data_grads_norm = 4.5192
	new_data_grads_norm = 6.3107
	old_data_grads_norm = 6.6576
	sim_grads_norm_tr = -0.0492
-- Starting training on experience 220 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9249
	data_grads_norm = 3.8219
	new_data_grads_norm = 5.7964
	old_data_grads_norm = 4.7081
	sim_grads_norm_tr = 0.0729
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5511
	data_grads_norm = 4.7866
	new_data_grads_norm = 4.9690
	old_data_grads_norm = 7.8445
	sim_grads_norm_tr = 0.0388
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6283
	data_grads_norm = 3.6143
	new_data_grads_norm = 5.5970
	old_data_grads_norm = 4.8261
	sim_grads_norm_tr = -0.0301
-- Starting training on experience 221 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8684
	data_grads_norm = 3.6961
	new_data_grads_norm = 5.9636
	old_data_grads_norm = 5.4368
	sim_grads_norm_tr = -0.0546
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1434
	data_grads_norm = 4.3112
	new_data_grads_norm = 5.6171
	old_data_grads_norm = 6.1604
	sim_grads_norm_tr = -0.0032
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3489
	data_grads_norm = 4.2873
	new_data_grads_norm = 5.5979
	old_data_grads_norm = 6.0289
	sim_grads_norm_tr = 0.0727
-- Starting training on experience 222 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5036
	data_grads_norm = 4.3719
	new_data_grads_norm = 5.2560
	old_data_grads_norm = 6.9582
	sim_grads_norm_tr = 0.0311
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3711
	data_grads_norm = 3.7941
	new_data_grads_norm = 5.6094
	old_data_grads_norm = 4.8219
	sim_grads_norm_tr = 0.0523
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5594
	data_grads_norm = 3.8378
	new_data_grads_norm = 5.6442
	old_data_grads_norm = 5.3279
	sim_grads_norm_tr = -0.0161
-- Starting training on experience 223 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5154
	data_grads_norm = 4.6974
	new_data_grads_norm = 6.8953
	old_data_grads_norm = 6.3453
	sim_grads_norm_tr = 0.0645
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8040
	data_grads_norm = 4.5331
	new_data_grads_norm = 6.4191
	old_data_grads_norm = 6.4501
	sim_grads_norm_tr = 0.0727
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1232
	data_grads_norm = 4.9669
	new_data_grads_norm = 6.9504
	old_data_grads_norm = 7.4757
	sim_grads_norm_tr = 0.0728
-- Starting training on experience 224 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9488
	data_grads_norm = 4.2733
	new_data_grads_norm = 6.4568
	old_data_grads_norm = 4.8415
	sim_grads_norm_tr = -0.0335
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6377
	data_grads_norm = 4.3884
	new_data_grads_norm = 6.1393
	old_data_grads_norm = 6.7530
	sim_grads_norm_tr = -0.0586
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8084
	data_grads_norm = 4.4153
	new_data_grads_norm = 6.1562
	old_data_grads_norm = 5.9559
	sim_grads_norm_tr = 0.0428
-- Starting training on experience 225 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1418
	data_grads_norm = 4.6425
	new_data_grads_norm = 5.8020
	old_data_grads_norm = 7.2949
	sim_grads_norm_tr = 0.0340
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8125
	data_grads_norm = 3.8670
	new_data_grads_norm = 5.8656
	old_data_grads_norm = 5.8457
	sim_grads_norm_tr = -0.0345
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4929
	data_grads_norm = 3.9812
	new_data_grads_norm = 5.4035
	old_data_grads_norm = 5.4248
	sim_grads_norm_tr = -0.0502
-- Starting training on experience 226 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8103
	data_grads_norm = 3.7176
	new_data_grads_norm = 6.0610
	old_data_grads_norm = 4.9307
	sim_grads_norm_tr = 0.0274
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4266
	data_grads_norm = 4.7316
	new_data_grads_norm = 5.8919
	old_data_grads_norm = 6.4836
	sim_grads_norm_tr = 0.1699
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0645
	data_grads_norm = 4.3644
	new_data_grads_norm = 5.3361
	old_data_grads_norm = 7.0200
	sim_grads_norm_tr = -0.0368
-- Starting training on experience 227 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9928
	data_grads_norm = 3.9670
	new_data_grads_norm = 5.1766
	old_data_grads_norm = 6.2984
	sim_grads_norm_tr = 0.0413
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1806
	data_grads_norm = 3.9772
	new_data_grads_norm = 5.4920
	old_data_grads_norm = 5.5439
	sim_grads_norm_tr = -0.0112
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2268
	data_grads_norm = 4.3504
	new_data_grads_norm = 5.5725
	old_data_grads_norm = 5.6467
	sim_grads_norm_tr = 0.0249
-- Starting training on experience 228 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0904
	data_grads_norm = 3.7500
	new_data_grads_norm = 5.2845
	old_data_grads_norm = 4.7846
	sim_grads_norm_tr = 0.1184
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3354
	data_grads_norm = 4.3759
	new_data_grads_norm = 5.9120
	old_data_grads_norm = 6.1457
	sim_grads_norm_tr = -0.0431
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2411
	data_grads_norm = 4.4796
	new_data_grads_norm = 6.3624
	old_data_grads_norm = 6.7030
	sim_grads_norm_tr = 0.0346
-- Starting training on experience 229 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0467
	data_grads_norm = 3.9539
	new_data_grads_norm = 6.4137
	old_data_grads_norm = 5.0874
	sim_grads_norm_tr = -0.0766
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9501
	data_grads_norm = 3.8420
	new_data_grads_norm = 6.8799
	old_data_grads_norm = 4.8194
	sim_grads_norm_tr = -0.0582
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1741
	data_grads_norm = 4.0586
	new_data_grads_norm = 6.7948
	old_data_grads_norm = 4.5902
	sim_grads_norm_tr = -0.0246
-- Starting training on experience 230 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0968
	data_grads_norm = 4.4636
	new_data_grads_norm = 5.9727
	old_data_grads_norm = 5.7619
	sim_grads_norm_tr = 0.0462
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1412
	data_grads_norm = 4.6099
	new_data_grads_norm = 6.2538
	old_data_grads_norm = 5.8508
	sim_grads_norm_tr = 0.0496
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2922
	data_grads_norm = 4.3223
	new_data_grads_norm = 6.3653
	old_data_grads_norm = 5.0252
	sim_grads_norm_tr = 0.0820
-- Starting training on experience 231 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0807
	data_grads_norm = 3.9886
	new_data_grads_norm = 6.6253
	old_data_grads_norm = 4.6568
	sim_grads_norm_tr = 0.0177
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9130
	data_grads_norm = 4.0692
	new_data_grads_norm = 6.6698
	old_data_grads_norm = 5.3115
	sim_grads_norm_tr = -0.0363
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8112
	data_grads_norm = 3.8107
	new_data_grads_norm = 7.1220
	old_data_grads_norm = 4.5757
	sim_grads_norm_tr = -0.0138
-- Starting training on experience 232 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1427
	data_grads_norm = 4.5313
	new_data_grads_norm = 6.2619
	old_data_grads_norm = 6.4132
	sim_grads_norm_tr = -0.0431
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4600
	data_grads_norm = 4.7524
	new_data_grads_norm = 5.5169
	old_data_grads_norm = 7.2571
	sim_grads_norm_tr = -0.0193
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1895
	data_grads_norm = 4.0690
	new_data_grads_norm = 5.9945
	old_data_grads_norm = 4.7602
	sim_grads_norm_tr = 0.1131
-- Starting training on experience 233 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8028
	data_grads_norm = 5.2793
	new_data_grads_norm = 6.8188
	old_data_grads_norm = 7.1763
	sim_grads_norm_tr = 0.0719
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3767
	data_grads_norm = 4.4795
	new_data_grads_norm = 6.3720
	old_data_grads_norm = 6.7205
	sim_grads_norm_tr = -0.0025
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9022
	data_grads_norm = 3.9800
	new_data_grads_norm = 6.1621
	old_data_grads_norm = 5.8860
	sim_grads_norm_tr = 0.0438
-- Starting training on experience 234 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1079
	data_grads_norm = 4.4809
	new_data_grads_norm = 5.5024
	old_data_grads_norm = 6.2597
	sim_grads_norm_tr = -0.0135
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7959
	data_grads_norm = 4.5174
	new_data_grads_norm = 5.5397
	old_data_grads_norm = 5.6031
	sim_grads_norm_tr = 0.0400
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8981
	data_grads_norm = 3.7715
	new_data_grads_norm = 5.0625
	old_data_grads_norm = 5.0726
	sim_grads_norm_tr = -0.0670
-- Starting training on experience 235 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3038
	data_grads_norm = 4.8258
	new_data_grads_norm = 6.6160
	old_data_grads_norm = 7.5455
	sim_grads_norm_tr = -0.0188
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9456
	data_grads_norm = 4.3211
	new_data_grads_norm = 6.9076
	old_data_grads_norm = 5.2393
	sim_grads_norm_tr = 0.0712
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0398
	data_grads_norm = 4.1043
	new_data_grads_norm = 6.7528
	old_data_grads_norm = 6.2355
	sim_grads_norm_tr = -0.0535
-- Starting training on experience 236 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7103
	data_grads_norm = 4.6446
	new_data_grads_norm = 6.6322
	old_data_grads_norm = 5.8791
	sim_grads_norm_tr = 0.0338
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9411
	data_grads_norm = 4.9109
	new_data_grads_norm = 7.0530
	old_data_grads_norm = 6.6602
	sim_grads_norm_tr = 0.0203
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6888
	data_grads_norm = 4.5435
	new_data_grads_norm = 6.8185
	old_data_grads_norm = 5.4771
	sim_grads_norm_tr = 0.0132
-- Starting training on experience 237 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
-- >> End of training phase << --
-- >> Start of eval phase << --
-- Starting eval on experience 0 (Task 0) from test stream --
> Eval on experience 0 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp000 = 1.7510
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.4880
	mb_index = 1428
	time = 342.2625
-- Starting eval on experience 1 (Task 0) from test stream --
> Eval on experience 1 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp001 = 1.8021
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.5140
-- Starting eval on experience 2 (Task 0) from test stream --
> Eval on experience 2 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp002 = 2.4625
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.3140
-- Starting eval on experience 3 (Task 0) from test stream --
> Eval on experience 3 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp003 = 1.8807
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.4900
-- Starting eval on experience 4 (Task 0) from test stream --
> Eval on experience 4 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp004 = 2.4564
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.3000
-- Starting eval on experience 5 (Task 0) from test stream --
> Eval on experience 5 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp005 = 2.9774
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.1720
-- >> End of eval phase << --
	CumulativeAccuracy/eval_phase/test_stream/Exp000 = 0.7140
	CumulativeAccuracy/eval_phase/test_stream/Exp001 = 0.6480
	CumulativeAccuracy/eval_phase/test_stream/Exp002 = 0.5220
	CumulativeAccuracy/eval_phase/test_stream/Exp003 = 0.4960
	CumulativeAccuracy/eval_phase/test_stream/Exp004 = 0.4328
	CumulativeAccuracy/eval_phase/test_stream/Exp005 = 0.3797
	Loss_Stream/eval_phase/test_stream/Task000 = 2.2217
	Top1_Acc_Stream/eval_phase/test_stream/Task000 = 0.3797
-- >> Start of training phase << --
-- Starting training on experience 0 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9708
	data_grads_norm = 3.4056
	new_data_grads_norm = 5.4898
	old_data_grads_norm = 4.4111
	sim_grads_norm_tr = -0.0345
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3851
	data_grads_norm = 4.5494
	new_data_grads_norm = 6.0071
	old_data_grads_norm = 5.9370
	sim_grads_norm_tr = 0.0046
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8994
	data_grads_norm = 4.4997
	new_data_grads_norm = 5.7431
	old_data_grads_norm = 7.0914
	sim_grads_norm_tr = -0.0031
-- Starting training on experience 1 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3354
	data_grads_norm = 4.2926
	new_data_grads_norm = 6.1898
	old_data_grads_norm = 6.3239
	sim_grads_norm_tr = 0.0091
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9106
	data_grads_norm = 4.7523
	new_data_grads_norm = 6.5283
	old_data_grads_norm = 6.2495
	sim_grads_norm_tr = 0.0331
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6379
	data_grads_norm = 4.8773
	new_data_grads_norm = 6.4633
	old_data_grads_norm = 6.3230
	sim_grads_norm_tr = 0.0641
-- Starting training on experience 2 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4538
	data_grads_norm = 4.4379
	new_data_grads_norm = 6.3359
	old_data_grads_norm = 5.1441
	sim_grads_norm_tr = 0.0331
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6471
	data_grads_norm = 4.5769
	new_data_grads_norm = 5.7163
	old_data_grads_norm = 6.7130
	sim_grads_norm_tr = 0.0020
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7451
	data_grads_norm = 5.1059
	new_data_grads_norm = 6.3275
	old_data_grads_norm = 5.8943
	sim_grads_norm_tr = 0.0461
-- Starting training on experience 3 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5090
	data_grads_norm = 3.9378
	new_data_grads_norm = 5.7560
	old_data_grads_norm = 5.0892
	sim_grads_norm_tr = -0.0284
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4213
	data_grads_norm = 4.0852
	new_data_grads_norm = 6.3662
	old_data_grads_norm = 5.2010
	sim_grads_norm_tr = -0.0226
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9296
	data_grads_norm = 4.3752
	new_data_grads_norm = 5.8877
	old_data_grads_norm = 5.9171
	sim_grads_norm_tr = 0.0818
-- Starting training on experience 4 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2459
	data_grads_norm = 4.0429
	new_data_grads_norm = 5.5375
	old_data_grads_norm = 5.4966
	sim_grads_norm_tr = -0.0291
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3476
	data_grads_norm = 4.1954
	new_data_grads_norm = 5.8144
	old_data_grads_norm = 5.5597
	sim_grads_norm_tr = -0.0262
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3703
	data_grads_norm = 4.3542
	new_data_grads_norm = 5.7984
	old_data_grads_norm = 6.0376
	sim_grads_norm_tr = -0.0064
-- Starting training on experience 5 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5040
	data_grads_norm = 4.6393
	new_data_grads_norm = 5.9420
	old_data_grads_norm = 7.0815
	sim_grads_norm_tr = -0.0246
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3477
	data_grads_norm = 3.9081
	new_data_grads_norm = 5.9703
	old_data_grads_norm = 4.3218
	sim_grads_norm_tr = 0.0470
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7903
	data_grads_norm = 4.6006
	new_data_grads_norm = 5.9745
	old_data_grads_norm = 6.1659
	sim_grads_norm_tr = 0.0656
-- Starting training on experience 6 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7900
	data_grads_norm = 4.5188
	new_data_grads_norm = 6.4494
	old_data_grads_norm = 5.9408
	sim_grads_norm_tr = -0.0192
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7364
	data_grads_norm = 4.5792
	new_data_grads_norm = 7.0251
	old_data_grads_norm = 5.2389
	sim_grads_norm_tr = 0.0328
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4805
	data_grads_norm = 4.3089
	new_data_grads_norm = 6.2287
	old_data_grads_norm = 6.3524
	sim_grads_norm_tr = 0.0016
-- Starting training on experience 7 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0506
	data_grads_norm = 4.7495
	new_data_grads_norm = 5.8502
	old_data_grads_norm = 6.7810
	sim_grads_norm_tr = 0.0288
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9462
	data_grads_norm = 4.4599
	new_data_grads_norm = 5.9808
	old_data_grads_norm = 5.7166
	sim_grads_norm_tr = 0.0497
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4393
	data_grads_norm = 3.8750
	new_data_grads_norm = 5.5638
	old_data_grads_norm = 4.5960
	sim_grads_norm_tr = 0.0628
-- Starting training on experience 8 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7247
	data_grads_norm = 4.3911
	new_data_grads_norm = 6.2153
	old_data_grads_norm = 5.9472
	sim_grads_norm_tr = 0.0030
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6805
	data_grads_norm = 4.9016
	new_data_grads_norm = 6.4563
	old_data_grads_norm = 7.7161
	sim_grads_norm_tr = 0.0039
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8664
	data_grads_norm = 4.1756
	new_data_grads_norm = 6.4809
	old_data_grads_norm = 4.7488
	sim_grads_norm_tr = 0.0169
-- Starting training on experience 9 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1394
	data_grads_norm = 5.0861
	new_data_grads_norm = 6.0081
	old_data_grads_norm = 6.7541
	sim_grads_norm_tr = 0.0133
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3610
	data_grads_norm = 4.2618
	new_data_grads_norm = 5.9608
	old_data_grads_norm = 5.5897
	sim_grads_norm_tr = 0.0152
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3971
	data_grads_norm = 3.9832
	new_data_grads_norm = 5.9146
	old_data_grads_norm = 5.2256
	sim_grads_norm_tr = -0.0281
-- Starting training on experience 10 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7036
	data_grads_norm = 4.4194
	new_data_grads_norm = 5.8615
	old_data_grads_norm = 6.1806
	sim_grads_norm_tr = 0.0178
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3915
	data_grads_norm = 4.0978
	new_data_grads_norm = 5.5007
	old_data_grads_norm = 5.9718
	sim_grads_norm_tr = 0.0014
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8023
	data_grads_norm = 4.7182
	new_data_grads_norm = 6.0019
	old_data_grads_norm = 6.9795
	sim_grads_norm_tr = 0.0509
-- Starting training on experience 11 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1786
	data_grads_norm = 4.1480
	new_data_grads_norm = 5.9707
	old_data_grads_norm = 4.9878
	sim_grads_norm_tr = -0.0230
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2337
	data_grads_norm = 4.1772
	new_data_grads_norm = 6.1664
	old_data_grads_norm = 6.1422
	sim_grads_norm_tr = 0.0152
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2193
	data_grads_norm = 4.9017
	new_data_grads_norm = 6.8568
	old_data_grads_norm = 5.6908
	sim_grads_norm_tr = 0.0296
-- Starting training on experience 12 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6633
	data_grads_norm = 5.7649
	new_data_grads_norm = 6.4493
	old_data_grads_norm = 8.3170
	sim_grads_norm_tr = 0.0390
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5040
	data_grads_norm = 4.1732
	new_data_grads_norm = 6.8655
	old_data_grads_norm = 5.4271
	sim_grads_norm_tr = -0.0365
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5505
	data_grads_norm = 4.6747
	new_data_grads_norm = 6.8565
	old_data_grads_norm = 6.1433
	sim_grads_norm_tr = -0.0099
-- Starting training on experience 13 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7659
	data_grads_norm = 5.8890
	new_data_grads_norm = 7.5077
	old_data_grads_norm = 8.1995
	sim_grads_norm_tr = 0.0331
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6881
	data_grads_norm = 4.9341
	new_data_grads_norm = 7.0930
	old_data_grads_norm = 5.1422
	sim_grads_norm_tr = 0.0934
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4769
	data_grads_norm = 4.8947
	new_data_grads_norm = 7.0719
	old_data_grads_norm = 6.9325
	sim_grads_norm_tr = -0.0445
-- Starting training on experience 14 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9546
	data_grads_norm = 5.1048
	new_data_grads_norm = 6.7864
	old_data_grads_norm = 6.4513
	sim_grads_norm_tr = 0.0481
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2162
	data_grads_norm = 4.4794
	new_data_grads_norm = 6.5841
	old_data_grads_norm = 5.8150
	sim_grads_norm_tr = -0.0673
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0817
	data_grads_norm = 5.2081
	new_data_grads_norm = 7.3609
	old_data_grads_norm = 7.0716
	sim_grads_norm_tr = 0.0504
-- Starting training on experience 15 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9287
	data_grads_norm = 4.7942
	new_data_grads_norm = 6.7518
	old_data_grads_norm = 6.1445
	sim_grads_norm_tr = 0.0157
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1450
	data_grads_norm = 5.3557
	new_data_grads_norm = 7.4281
	old_data_grads_norm = 6.3802
	sim_grads_norm_tr = 0.0374
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6059
	data_grads_norm = 4.2723
	new_data_grads_norm = 7.2109
	old_data_grads_norm = 4.9736
	sim_grads_norm_tr = -0.0176
-- Starting training on experience 16 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6239
	data_grads_norm = 4.0958
	new_data_grads_norm = 6.5315
	old_data_grads_norm = 3.6891
	sim_grads_norm_tr = 0.0126
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6557
	data_grads_norm = 4.3724
	new_data_grads_norm = 6.0618
	old_data_grads_norm = 4.6022
	sim_grads_norm_tr = 0.0539
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2635
	data_grads_norm = 4.9953
	new_data_grads_norm = 6.3703
	old_data_grads_norm = 6.2156
	sim_grads_norm_tr = 0.1351
-- Starting training on experience 17 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2282
	data_grads_norm = 3.8486
	new_data_grads_norm = 6.3043
	old_data_grads_norm = 3.9527
	sim_grads_norm_tr = 0.0368
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0827
	data_grads_norm = 5.1498
	new_data_grads_norm = 6.3517
	old_data_grads_norm = 6.8680
	sim_grads_norm_tr = -0.0169
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4709
	data_grads_norm = 4.6875
	new_data_grads_norm = 6.7441
	old_data_grads_norm = 6.1876
	sim_grads_norm_tr = -0.0274
-- Starting training on experience 18 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4771
	data_grads_norm = 4.3841
	new_data_grads_norm = 6.5001
	old_data_grads_norm = 5.6659
	sim_grads_norm_tr = 0.0279
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7092
	data_grads_norm = 4.5245
	new_data_grads_norm = 6.3391
	old_data_grads_norm = 5.8871
	sim_grads_norm_tr = 0.0479
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8655
	data_grads_norm = 4.7268
	new_data_grads_norm = 6.5165
	old_data_grads_norm = 5.9063
	sim_grads_norm_tr = -0.0193
-- Starting training on experience 19 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8688
	data_grads_norm = 5.3023
	new_data_grads_norm = 7.7636
	old_data_grads_norm = 6.8382
	sim_grads_norm_tr = -0.0377
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7378
	data_grads_norm = 5.2314
	new_data_grads_norm = 7.6028
	old_data_grads_norm = 5.5102
	sim_grads_norm_tr = 0.1055
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5459
	data_grads_norm = 5.0840
	new_data_grads_norm = 7.3938
	old_data_grads_norm = 5.7426
	sim_grads_norm_tr = 0.1049
-- Starting training on experience 20 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5675
	data_grads_norm = 4.6927
	new_data_grads_norm = 5.8719
	old_data_grads_norm = 6.1618
	sim_grads_norm_tr = -0.0007
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2170
	data_grads_norm = 4.2682
	new_data_grads_norm = 5.8652
	old_data_grads_norm = 5.2212
	sim_grads_norm_tr = 0.0105
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6676
	data_grads_norm = 4.3703
	new_data_grads_norm = 5.9595
	old_data_grads_norm = 6.0433
	sim_grads_norm_tr = 0.0712
-- Starting training on experience 21 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4498
	data_grads_norm = 4.0708
	new_data_grads_norm = 5.6578
	old_data_grads_norm = 5.3523
	sim_grads_norm_tr = 0.0361
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3135
	data_grads_norm = 4.7588
	new_data_grads_norm = 6.1504
	old_data_grads_norm = 6.5805
	sim_grads_norm_tr = 0.0895
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5994
	data_grads_norm = 4.5175
	new_data_grads_norm = 5.3835
	old_data_grads_norm = 6.1691
	sim_grads_norm_tr = 0.0960
-- Starting training on experience 22 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6480
	data_grads_norm = 5.0417
	new_data_grads_norm = 5.9914
	old_data_grads_norm = 5.9048
	sim_grads_norm_tr = 0.0893
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4419
	data_grads_norm = 4.5581
	new_data_grads_norm = 6.0230
	old_data_grads_norm = 6.8483
	sim_grads_norm_tr = 0.0162
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3152
	data_grads_norm = 4.3834
	new_data_grads_norm = 6.2309
	old_data_grads_norm = 6.6321
	sim_grads_norm_tr = -0.0329
-- Starting training on experience 23 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6706
	data_grads_norm = 4.4560
	new_data_grads_norm = 5.7965
	old_data_grads_norm = 5.7271
	sim_grads_norm_tr = 0.1306
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7805
	data_grads_norm = 3.3679
	new_data_grads_norm = 5.5866
	old_data_grads_norm = 3.8867
	sim_grads_norm_tr = 0.0500
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3164
	data_grads_norm = 4.8924
	new_data_grads_norm = 5.5475
	old_data_grads_norm = 6.7349
	sim_grads_norm_tr = 0.1475
-- Starting training on experience 24 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4855
	data_grads_norm = 3.4721
	new_data_grads_norm = 5.2785
	old_data_grads_norm = 4.6517
	sim_grads_norm_tr = -0.0556
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5932
	data_grads_norm = 3.4199
	new_data_grads_norm = 5.4945
	old_data_grads_norm = 4.3499
	sim_grads_norm_tr = -0.0224
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1589
	data_grads_norm = 4.7904
	new_data_grads_norm = 5.9181
	old_data_grads_norm = 6.6096
	sim_grads_norm_tr = 0.0058
-- Starting training on experience 25 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6811
	data_grads_norm = 3.5846
	new_data_grads_norm = 5.9069
	old_data_grads_norm = 5.0795
	sim_grads_norm_tr = 0.0266
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1729
	data_grads_norm = 4.5042
	new_data_grads_norm = 5.9380
	old_data_grads_norm = 5.5527
	sim_grads_norm_tr = 0.0384
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9653
	data_grads_norm = 4.1595
	new_data_grads_norm = 5.6881
	old_data_grads_norm = 6.0555
	sim_grads_norm_tr = 0.0302
-- Starting training on experience 26 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7986
	data_grads_norm = 3.8585
	new_data_grads_norm = 5.4393
	old_data_grads_norm = 4.9465
	sim_grads_norm_tr = 0.0440
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7684
	data_grads_norm = 4.1435
	new_data_grads_norm = 6.1368
	old_data_grads_norm = 5.8751
	sim_grads_norm_tr = 0.0473
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0668
	data_grads_norm = 4.4177
	new_data_grads_norm = 6.2594
	old_data_grads_norm = 5.4426
	sim_grads_norm_tr = 0.1378
-- Starting training on experience 27 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1184
	data_grads_norm = 4.4645
	new_data_grads_norm = 5.9315
	old_data_grads_norm = 4.9601
	sim_grads_norm_tr = 0.0480
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9906
	data_grads_norm = 4.5482
	new_data_grads_norm = 6.0030
	old_data_grads_norm = 6.1006
	sim_grads_norm_tr = 0.0699
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8281
	data_grads_norm = 4.2950
	new_data_grads_norm = 6.0259
	old_data_grads_norm = 5.4607
	sim_grads_norm_tr = 0.0112
-- Starting training on experience 28 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8385
	data_grads_norm = 3.9361
	new_data_grads_norm = 5.2760
	old_data_grads_norm = 5.4865
	sim_grads_norm_tr = -0.0368
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6897
	data_grads_norm = 4.2467
	new_data_grads_norm = 5.3789
	old_data_grads_norm = 6.6580
	sim_grads_norm_tr = -0.0012
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9663
	data_grads_norm = 4.4832
	new_data_grads_norm = 5.5555
	old_data_grads_norm = 6.0371
	sim_grads_norm_tr = -0.0168
-- Starting training on experience 29 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2583
	data_grads_norm = 4.7843
	new_data_grads_norm = 6.0764
	old_data_grads_norm = 6.2431
	sim_grads_norm_tr = 0.1836
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9969
	data_grads_norm = 4.4972
	new_data_grads_norm = 5.2601
	old_data_grads_norm = 5.7289
	sim_grads_norm_tr = 0.1590
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7676
	data_grads_norm = 4.3029
	new_data_grads_norm = 5.4320
	old_data_grads_norm = 6.2236
	sim_grads_norm_tr = -0.0252
-- Starting training on experience 30 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6740
	data_grads_norm = 4.1544
	new_data_grads_norm = 5.5899
	old_data_grads_norm = 6.1656
	sim_grads_norm_tr = -0.0067
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6870
	data_grads_norm = 4.3810
	new_data_grads_norm = 5.2882
	old_data_grads_norm = 6.2947
	sim_grads_norm_tr = 0.0157
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8343
	data_grads_norm = 5.2479
	new_data_grads_norm = 5.5718
	old_data_grads_norm = 7.3974
	sim_grads_norm_tr = 0.0591
-- Starting training on experience 31 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6204
	data_grads_norm = 3.3967
	new_data_grads_norm = 5.6999
	old_data_grads_norm = 4.0744
	sim_grads_norm_tr = -0.0168
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5135
	data_grads_norm = 4.2502
	new_data_grads_norm = 5.4153
	old_data_grads_norm = 6.3478
	sim_grads_norm_tr = 0.0193
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3776
	data_grads_norm = 3.3795
	new_data_grads_norm = 5.2151
	old_data_grads_norm = 5.7479
	sim_grads_norm_tr = 0.0431
-- Starting training on experience 32 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4081
	data_grads_norm = 3.7597
	new_data_grads_norm = 5.4910
	old_data_grads_norm = 5.7918
	sim_grads_norm_tr = -0.0110
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5602
	data_grads_norm = 4.1200
	new_data_grads_norm = 5.1280
	old_data_grads_norm = 6.3335
	sim_grads_norm_tr = 0.0711
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7267
	data_grads_norm = 4.5822
	new_data_grads_norm = 5.4185
	old_data_grads_norm = 6.3770
	sim_grads_norm_tr = -0.0190
-- Starting training on experience 33 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4648
	data_grads_norm = 3.4793
	new_data_grads_norm = 5.5607
	old_data_grads_norm = 3.8590
	sim_grads_norm_tr = 0.0251
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6101
	data_grads_norm = 4.3157
	new_data_grads_norm = 5.5006
	old_data_grads_norm = 6.8989
	sim_grads_norm_tr = 0.0064
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7955
	data_grads_norm = 4.1850
	new_data_grads_norm = 6.1479
	old_data_grads_norm = 5.8011
	sim_grads_norm_tr = -0.0150
-- Starting training on experience 34 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3924
	data_grads_norm = 3.6551
	new_data_grads_norm = 5.2500
	old_data_grads_norm = 4.9455
	sim_grads_norm_tr = -0.0218
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6536
	data_grads_norm = 3.9226
	new_data_grads_norm = 5.6633
	old_data_grads_norm = 4.9346
	sim_grads_norm_tr = 0.0558
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8494
	data_grads_norm = 4.1245
	new_data_grads_norm = 5.3763
	old_data_grads_norm = 5.0214
	sim_grads_norm_tr = 0.1508
-- Starting training on experience 35 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9758
	data_grads_norm = 4.1084
	new_data_grads_norm = 5.1118
	old_data_grads_norm = 6.3209
	sim_grads_norm_tr = 0.0153
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7653
	data_grads_norm = 4.0192
	new_data_grads_norm = 5.2136
	old_data_grads_norm = 4.7010
	sim_grads_norm_tr = 0.1976
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0286
	data_grads_norm = 4.1251
	new_data_grads_norm = 5.4238
	old_data_grads_norm = 6.4377
	sim_grads_norm_tr = 0.0501
-- Starting training on experience 36 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4657
	data_grads_norm = 3.5804
	new_data_grads_norm = 4.8357
	old_data_grads_norm = 5.2281
	sim_grads_norm_tr = -0.0068
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5156
	data_grads_norm = 3.2665
	new_data_grads_norm = 4.9102
	old_data_grads_norm = 4.2047
	sim_grads_norm_tr = 0.0287
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6907
	data_grads_norm = 3.9761
	new_data_grads_norm = 4.8155
	old_data_grads_norm = 5.3107
	sim_grads_norm_tr = 0.1337
-- Starting training on experience 37 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4279
	data_grads_norm = 4.2780
	new_data_grads_norm = 4.9721
	old_data_grads_norm = 6.2903
	sim_grads_norm_tr = -0.0710
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5475
	data_grads_norm = 4.1515
	new_data_grads_norm = 5.5898
	old_data_grads_norm = 4.9048
	sim_grads_norm_tr = -0.0089
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0208
	data_grads_norm = 4.9767
	new_data_grads_norm = 5.4910
	old_data_grads_norm = 7.0901
	sim_grads_norm_tr = -0.0076
-- Starting training on experience 38 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8281
	data_grads_norm = 4.4155
	new_data_grads_norm = 6.3770
	old_data_grads_norm = 5.2640
	sim_grads_norm_tr = -0.0660
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2808
	data_grads_norm = 4.7760
	new_data_grads_norm = 5.8248
	old_data_grads_norm = 5.7332
	sim_grads_norm_tr = 0.0897
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0091
	data_grads_norm = 4.3700
	new_data_grads_norm = 6.0548
	old_data_grads_norm = 6.0554
	sim_grads_norm_tr = 0.1036
-- Starting training on experience 39 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4832
	data_grads_norm = 4.1480
	new_data_grads_norm = 5.6593
	old_data_grads_norm = 5.8664
	sim_grads_norm_tr = -0.0619
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5062
	data_grads_norm = 3.8217
	new_data_grads_norm = 5.8892
	old_data_grads_norm = 4.2103
	sim_grads_norm_tr = 0.0340
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3957
	data_grads_norm = 4.1626
	new_data_grads_norm = 6.0811
	old_data_grads_norm = 4.5541
	sim_grads_norm_tr = 0.0589
-- Starting training on experience 40 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9285
	data_grads_norm = 4.7086
	new_data_grads_norm = 6.1874
	old_data_grads_norm = 5.2407
	sim_grads_norm_tr = 0.1492
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2555
	data_grads_norm = 4.6595
	new_data_grads_norm = 7.2136
	old_data_grads_norm = 5.8051
	sim_grads_norm_tr = 0.0387
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6739
	data_grads_norm = 5.1752
	new_data_grads_norm = 7.1338
	old_data_grads_norm = 6.1975
	sim_grads_norm_tr = 0.0683
-- Starting training on experience 41 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7628
	data_grads_norm = 5.5021
	new_data_grads_norm = 6.5845
	old_data_grads_norm = 8.3038
	sim_grads_norm_tr = -0.0162
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7787
	data_grads_norm = 4.8771
	new_data_grads_norm = 6.3556
	old_data_grads_norm = 5.6756
	sim_grads_norm_tr = 0.1873
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1971
	data_grads_norm = 4.2302
	new_data_grads_norm = 5.5898
	old_data_grads_norm = 5.8284
	sim_grads_norm_tr = -0.0212
-- Starting training on experience 42 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7794
	data_grads_norm = 4.3712
	new_data_grads_norm = 5.8710
	old_data_grads_norm = 5.9120
	sim_grads_norm_tr = 0.1033
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8766
	data_grads_norm = 4.5320
	new_data_grads_norm = 5.7780
	old_data_grads_norm = 6.9866
	sim_grads_norm_tr = 0.0048
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8791
	data_grads_norm = 4.8883
	new_data_grads_norm = 6.4996
	old_data_grads_norm = 6.7825
	sim_grads_norm_tr = 0.0041
-- Starting training on experience 43 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8836
	data_grads_norm = 4.3910
	new_data_grads_norm = 5.8655
	old_data_grads_norm = 6.0829
	sim_grads_norm_tr = 0.0090
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6224
	data_grads_norm = 3.8310
	new_data_grads_norm = 5.9359
	old_data_grads_norm = 5.0914
	sim_grads_norm_tr = 0.0267
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1732
	data_grads_norm = 4.7316
	new_data_grads_norm = 6.1698
	old_data_grads_norm = 6.6311
	sim_grads_norm_tr = 0.2033
-- Starting training on experience 44 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5020
	data_grads_norm = 3.7080
	new_data_grads_norm = 5.6164
	old_data_grads_norm = 5.6101
	sim_grads_norm_tr = -0.0562
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8067
	data_grads_norm = 4.1410
	new_data_grads_norm = 6.3175
	old_data_grads_norm = 5.3614
	sim_grads_norm_tr = -0.0236
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1256
	data_grads_norm = 5.0035
	new_data_grads_norm = 6.8605
	old_data_grads_norm = 6.9808
	sim_grads_norm_tr = 0.0134
-- Starting training on experience 45 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1866
	data_grads_norm = 3.6787
	new_data_grads_norm = 5.5949
	old_data_grads_norm = 4.6564
	sim_grads_norm_tr = -0.0322
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6220
	data_grads_norm = 4.4363
	new_data_grads_norm = 5.3816
	old_data_grads_norm = 6.4881
	sim_grads_norm_tr = 0.0410
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4864
	data_grads_norm = 3.3352
	new_data_grads_norm = 5.0937
	old_data_grads_norm = 4.1633
	sim_grads_norm_tr = -0.0379
-- Starting training on experience 46 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4224
	data_grads_norm = 4.2487
	new_data_grads_norm = 5.5088
	old_data_grads_norm = 5.3576
	sim_grads_norm_tr = 0.1049
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4744
	data_grads_norm = 4.4008
	new_data_grads_norm = 6.0162
	old_data_grads_norm = 5.5134
	sim_grads_norm_tr = 0.0999
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8910
	data_grads_norm = 3.2606
	new_data_grads_norm = 5.7517
	old_data_grads_norm = 4.5112
	sim_grads_norm_tr = -0.0188
-- Starting training on experience 47 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3875
	data_grads_norm = 4.1749
	new_data_grads_norm = 5.6698
	old_data_grads_norm = 5.0983
	sim_grads_norm_tr = 0.1379
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8672
	data_grads_norm = 4.4107
	new_data_grads_norm = 5.5191
	old_data_grads_norm = 7.3121
	sim_grads_norm_tr = -0.0160
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1128
	data_grads_norm = 3.4545
	new_data_grads_norm = 6.2463
	old_data_grads_norm = 4.4216
	sim_grads_norm_tr = 0.0171
-- Starting training on experience 48 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5089
	data_grads_norm = 3.7496
	new_data_grads_norm = 5.0412
	old_data_grads_norm = 4.8040
	sim_grads_norm_tr = 0.0759
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2763
	data_grads_norm = 3.3061
	new_data_grads_norm = 4.7238
	old_data_grads_norm = 4.7248
	sim_grads_norm_tr = -0.1285
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0625
	data_grads_norm = 2.9784
	new_data_grads_norm = 5.2057
	old_data_grads_norm = 2.7720
	sim_grads_norm_tr = 0.2435
-- Starting training on experience 49 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3811
	data_grads_norm = 4.2358
	new_data_grads_norm = 5.8270
	old_data_grads_norm = 6.5944
	sim_grads_norm_tr = 0.0153
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3456
	data_grads_norm = 3.9931
	new_data_grads_norm = 5.7767
	old_data_grads_norm = 4.9386
	sim_grads_norm_tr = -0.1244
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4270
	data_grads_norm = 5.0563
	new_data_grads_norm = 6.2166
	old_data_grads_norm = 7.2351
	sim_grads_norm_tr = 0.0147
-- Starting training on experience 50 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6228
	data_grads_norm = 4.2775
	new_data_grads_norm = 6.1125
	old_data_grads_norm = 5.7366
	sim_grads_norm_tr = 0.0704
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5492
	data_grads_norm = 4.0295
	new_data_grads_norm = 5.5822
	old_data_grads_norm = 5.5714
	sim_grads_norm_tr = 0.0269
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7286
	data_grads_norm = 4.3256
	new_data_grads_norm = 6.1657
	old_data_grads_norm = 5.6897
	sim_grads_norm_tr = 0.0342
-- Starting training on experience 51 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8628
	data_grads_norm = 4.3647
	new_data_grads_norm = 5.6217
	old_data_grads_norm = 5.9405
	sim_grads_norm_tr = 0.0424
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4359
	data_grads_norm = 4.4733
	new_data_grads_norm = 6.3549
	old_data_grads_norm = 5.5739
	sim_grads_norm_tr = 0.0056
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5412
	data_grads_norm = 4.4871
	new_data_grads_norm = 5.6858
	old_data_grads_norm = 6.1156
	sim_grads_norm_tr = 0.0185
-- Starting training on experience 52 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4080
	data_grads_norm = 4.6551
	new_data_grads_norm = 6.2438
	old_data_grads_norm = 7.2944
	sim_grads_norm_tr = -0.0289
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6480
	data_grads_norm = 4.6049
	new_data_grads_norm = 6.2073
	old_data_grads_norm = 6.2791
	sim_grads_norm_tr = 0.0746
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7731
	data_grads_norm = 4.2543
	new_data_grads_norm = 5.3457
	old_data_grads_norm = 6.1857
	sim_grads_norm_tr = 0.0681
-- Starting training on experience 53 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0332
	data_grads_norm = 3.5582
	new_data_grads_norm = 5.8918
	old_data_grads_norm = 4.5060
	sim_grads_norm_tr = -0.0458
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4334
	data_grads_norm = 4.1106
	new_data_grads_norm = 5.4009
	old_data_grads_norm = 4.7658
	sim_grads_norm_tr = 0.1795
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3119
	data_grads_norm = 3.9458
	new_data_grads_norm = 5.6812
	old_data_grads_norm = 6.2776
	sim_grads_norm_tr = 0.0743
-- Starting training on experience 54 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6592
	data_grads_norm = 4.5211
	new_data_grads_norm = 6.3968
	old_data_grads_norm = 5.9447
	sim_grads_norm_tr = 0.1040
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2285
	data_grads_norm = 3.8263
	new_data_grads_norm = 5.4643
	old_data_grads_norm = 5.6310
	sim_grads_norm_tr = -0.0431
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0137
	data_grads_norm = 5.0731
	new_data_grads_norm = 5.9213
	old_data_grads_norm = 7.6235
	sim_grads_norm_tr = 0.0220
-- Starting training on experience 55 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7897
	data_grads_norm = 4.3393
	new_data_grads_norm = 5.6363
	old_data_grads_norm = 5.7246
	sim_grads_norm_tr = 0.0593
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4239
	data_grads_norm = 3.7601
	new_data_grads_norm = 5.8997
	old_data_grads_norm = 4.0140
	sim_grads_norm_tr = -0.0182
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0303
	data_grads_norm = 4.2708
	new_data_grads_norm = 6.3032
	old_data_grads_norm = 5.2574
	sim_grads_norm_tr = 0.0332
-- Starting training on experience 56 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6722
	data_grads_norm = 3.8470
	new_data_grads_norm = 5.8234
	old_data_grads_norm = 4.8527
	sim_grads_norm_tr = 0.0638
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7131
	data_grads_norm = 4.0135
	new_data_grads_norm = 5.6832
	old_data_grads_norm = 4.7324
	sim_grads_norm_tr = 0.0684
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8507
	data_grads_norm = 4.6617
	new_data_grads_norm = 5.9317
	old_data_grads_norm = 6.7862
	sim_grads_norm_tr = -0.0096
-- Starting training on experience 57 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1695
	data_grads_norm = 4.0503
	new_data_grads_norm = 5.9159
	old_data_grads_norm = 5.7636
	sim_grads_norm_tr = -0.0484
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6482
	data_grads_norm = 4.5027
	new_data_grads_norm = 6.5483
	old_data_grads_norm = 4.6129
	sim_grads_norm_tr = -0.0088
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0822
	data_grads_norm = 5.1698
	new_data_grads_norm = 6.7644
	old_data_grads_norm = 6.3824
	sim_grads_norm_tr = 0.0620
-- Starting training on experience 58 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2225
	data_grads_norm = 3.9624
	new_data_grads_norm = 5.4520
	old_data_grads_norm = 5.3585
	sim_grads_norm_tr = 0.0988
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1912
	data_grads_norm = 4.3792
	new_data_grads_norm = 5.0785
	old_data_grads_norm = 6.5799
	sim_grads_norm_tr = 0.0943
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5664
	data_grads_norm = 4.3290
	new_data_grads_norm = 4.6757
	old_data_grads_norm = 6.2288
	sim_grads_norm_tr = 0.0838
-- Starting training on experience 59 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1299
	data_grads_norm = 3.5526
	new_data_grads_norm = 5.4303
	old_data_grads_norm = 4.8058
	sim_grads_norm_tr = -0.0621
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4027
	data_grads_norm = 4.3545
	new_data_grads_norm = 5.6197
	old_data_grads_norm = 6.0077
	sim_grads_norm_tr = 0.1469
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4236
	data_grads_norm = 4.1596
	new_data_grads_norm = 5.7798
	old_data_grads_norm = 5.3188
	sim_grads_norm_tr = 0.0555
-- Starting training on experience 60 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1441
	data_grads_norm = 4.1221
	new_data_grads_norm = 5.2178
	old_data_grads_norm = 6.0504
	sim_grads_norm_tr = 0.0265
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5772
	data_grads_norm = 4.3768
	new_data_grads_norm = 5.4996
	old_data_grads_norm = 6.0657
	sim_grads_norm_tr = 0.0542
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3463
	data_grads_norm = 3.9801
	new_data_grads_norm = 5.3849
	old_data_grads_norm = 5.5635
	sim_grads_norm_tr = -0.0528
-- Starting training on experience 61 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4971
	data_grads_norm = 4.5146
	new_data_grads_norm = 6.0576
	old_data_grads_norm = 6.0820
	sim_grads_norm_tr = 0.1310
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3836
	data_grads_norm = 4.2636
	new_data_grads_norm = 5.7771
	old_data_grads_norm = 5.8722
	sim_grads_norm_tr = -0.0168
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4910
	data_grads_norm = 4.4106
	new_data_grads_norm = 6.1450
	old_data_grads_norm = 6.1895
	sim_grads_norm_tr = 0.0133
-- Starting training on experience 62 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1493
	data_grads_norm = 3.7975
	new_data_grads_norm = 5.9418
	old_data_grads_norm = 5.1630
	sim_grads_norm_tr = -0.0170
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3421
	data_grads_norm = 4.5110
	new_data_grads_norm = 6.2115
	old_data_grads_norm = 5.9532
	sim_grads_norm_tr = 0.0149
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0051
	data_grads_norm = 4.0730
	new_data_grads_norm = 5.9626
	old_data_grads_norm = 5.6627
	sim_grads_norm_tr = 0.0332
-- Starting training on experience 63 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0566
	data_grads_norm = 3.5398
	new_data_grads_norm = 5.6742
	old_data_grads_norm = 4.0241
	sim_grads_norm_tr = -0.0051
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7005
	data_grads_norm = 4.0731
	new_data_grads_norm = 5.4243
	old_data_grads_norm = 6.5649
	sim_grads_norm_tr = -0.0061
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0119
	data_grads_norm = 3.8843
	new_data_grads_norm = 5.4710
	old_data_grads_norm = 5.5585
	sim_grads_norm_tr = -0.0119
-- Starting training on experience 64 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4064
	data_grads_norm = 4.2287
	new_data_grads_norm = 6.0687
	old_data_grads_norm = 6.2861
	sim_grads_norm_tr = -0.0830
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7383
	data_grads_norm = 4.7259
	new_data_grads_norm = 6.3522
	old_data_grads_norm = 5.8076
	sim_grads_norm_tr = 0.1021
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5302
	data_grads_norm = 4.1751
	new_data_grads_norm = 6.2111
	old_data_grads_norm = 4.4254
	sim_grads_norm_tr = 0.0838
-- Starting training on experience 65 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1709
	data_grads_norm = 3.9869
	new_data_grads_norm = 5.3420
	old_data_grads_norm = 4.7259
	sim_grads_norm_tr = -0.0479
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5807
	data_grads_norm = 4.8275
	new_data_grads_norm = 4.8516
	old_data_grads_norm = 6.1509
	sim_grads_norm_tr = 0.0216
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7886
	data_grads_norm = 3.2440
	new_data_grads_norm = 5.2549
	old_data_grads_norm = 3.5659
	sim_grads_norm_tr = -0.0946
-- Starting training on experience 66 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4289
	data_grads_norm = 4.2672
	new_data_grads_norm = 5.4341
	old_data_grads_norm = 6.0634
	sim_grads_norm_tr = 0.0812
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9039
	data_grads_norm = 4.5780
	new_data_grads_norm = 5.3635
	old_data_grads_norm = 7.0974
	sim_grads_norm_tr = 0.0549
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5021
	data_grads_norm = 3.9528
	new_data_grads_norm = 5.2463
	old_data_grads_norm = 5.3101
	sim_grads_norm_tr = -0.0516
-- Starting training on experience 67 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3892
	data_grads_norm = 4.2987
	new_data_grads_norm = 4.9365
	old_data_grads_norm = 6.8022
	sim_grads_norm_tr = -0.0223
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3921
	data_grads_norm = 4.5645
	new_data_grads_norm = 5.1636
	old_data_grads_norm = 6.3470
	sim_grads_norm_tr = 0.0546
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0734
	data_grads_norm = 3.9515
	new_data_grads_norm = 5.0606
	old_data_grads_norm = 5.4313
	sim_grads_norm_tr = 0.1870
-- Starting training on experience 68 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3893
	data_grads_norm = 4.7656
	new_data_grads_norm = 6.8210
	old_data_grads_norm = 6.5262
	sim_grads_norm_tr = 0.0562
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1769
	data_grads_norm = 4.2641
	new_data_grads_norm = 6.8771
	old_data_grads_norm = 5.4292
	sim_grads_norm_tr = 0.0253
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3120
	data_grads_norm = 3.9956
	new_data_grads_norm = 6.0011
	old_data_grads_norm = 5.0944
	sim_grads_norm_tr = 0.0136
-- Starting training on experience 69 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8502
	data_grads_norm = 4.2026
	new_data_grads_norm = 6.0516
	old_data_grads_norm = 5.4317
	sim_grads_norm_tr = 0.0365
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3891
	data_grads_norm = 4.5541
	new_data_grads_norm = 7.0498
	old_data_grads_norm = 5.1905
	sim_grads_norm_tr = 0.0406
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2941
	data_grads_norm = 4.4809
	new_data_grads_norm = 6.8227
	old_data_grads_norm = 4.7764
	sim_grads_norm_tr = 0.0060
-- Starting training on experience 70 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8008
	data_grads_norm = 4.6406
	new_data_grads_norm = 6.6224
	old_data_grads_norm = 5.7639
	sim_grads_norm_tr = -0.0618
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4776
	data_grads_norm = 4.1602
	new_data_grads_norm = 6.3107
	old_data_grads_norm = 5.1538
	sim_grads_norm_tr = 0.0087
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8847
	data_grads_norm = 5.1996
	new_data_grads_norm = 6.7669
	old_data_grads_norm = 6.5202
	sim_grads_norm_tr = 0.0682
-- Starting training on experience 71 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1286
	data_grads_norm = 3.6746
	new_data_grads_norm = 6.3844
	old_data_grads_norm = 4.0865
	sim_grads_norm_tr = 0.0526
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4545
	data_grads_norm = 4.2274
	new_data_grads_norm = 6.3847
	old_data_grads_norm = 5.2370
	sim_grads_norm_tr = -0.0558
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4860
	data_grads_norm = 4.4486
	new_data_grads_norm = 6.4344
	old_data_grads_norm = 6.2943
	sim_grads_norm_tr = -0.0581
-- Starting training on experience 72 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7089
	data_grads_norm = 5.1333
	new_data_grads_norm = 7.5435
	old_data_grads_norm = 6.8527
	sim_grads_norm_tr = 0.0061
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8039
	data_grads_norm = 4.6047
	new_data_grads_norm = 7.0198
	old_data_grads_norm = 5.2801
	sim_grads_norm_tr = 0.0118
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9746
	data_grads_norm = 5.1090
	new_data_grads_norm = 7.1817
	old_data_grads_norm = 5.4234
	sim_grads_norm_tr = 0.1515
-- Starting training on experience 73 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0241
	data_grads_norm = 3.2603
	new_data_grads_norm = 5.4800
	old_data_grads_norm = 4.6982
	sim_grads_norm_tr = -0.1487
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5789
	data_grads_norm = 4.1235
	new_data_grads_norm = 6.1603
	old_data_grads_norm = 5.8039
	sim_grads_norm_tr = 0.0216
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6669
	data_grads_norm = 3.9479
	new_data_grads_norm = 5.9057
	old_data_grads_norm = 5.3884
	sim_grads_norm_tr = -0.0152
-- Starting training on experience 74 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4613
	data_grads_norm = 4.2421
	new_data_grads_norm = 6.5668
	old_data_grads_norm = 5.8632
	sim_grads_norm_tr = 0.0325
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5805
	data_grads_norm = 4.5165
	new_data_grads_norm = 5.9709
	old_data_grads_norm = 5.7413
	sim_grads_norm_tr = 0.0080
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2853
	data_grads_norm = 3.7327
	new_data_grads_norm = 6.0490
	old_data_grads_norm = 3.7458
	sim_grads_norm_tr = 0.0240
-- Starting training on experience 75 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5042
	data_grads_norm = 4.0597
	new_data_grads_norm = 5.7995
	old_data_grads_norm = 5.0534
	sim_grads_norm_tr = 0.1224
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3803
	data_grads_norm = 4.2195
	new_data_grads_norm = 5.6494
	old_data_grads_norm = 5.4236
	sim_grads_norm_tr = 0.0719
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4965
	data_grads_norm = 4.3104
	new_data_grads_norm = 5.1365
	old_data_grads_norm = 6.2858
	sim_grads_norm_tr = 0.0105
-- Starting training on experience 76 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3268
	data_grads_norm = 4.4919
	new_data_grads_norm = 5.7141
	old_data_grads_norm = 6.3910
	sim_grads_norm_tr = 0.0744
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7601
	data_grads_norm = 4.8212
	new_data_grads_norm = 6.3603
	old_data_grads_norm = 5.8369
	sim_grads_norm_tr = 0.1797
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2632
	data_grads_norm = 4.7590
	new_data_grads_norm = 5.5897
	old_data_grads_norm = 6.2617
	sim_grads_norm_tr = 0.0372
-- Starting training on experience 77 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0501
	data_grads_norm = 3.7592
	new_data_grads_norm = 6.0230
	old_data_grads_norm = 4.4102
	sim_grads_norm_tr = 0.0125
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1752
	data_grads_norm = 4.2855
	new_data_grads_norm = 6.2857
	old_data_grads_norm = 5.7521
	sim_grads_norm_tr = 0.0246
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6204
	data_grads_norm = 4.3865
	new_data_grads_norm = 5.8409
	old_data_grads_norm = 6.5244
	sim_grads_norm_tr = 0.0110
-- Starting training on experience 78 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1787
	data_grads_norm = 4.4578
	new_data_grads_norm = 6.8020
	old_data_grads_norm = 4.1241
	sim_grads_norm_tr = -0.0122
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8993
	data_grads_norm = 5.0253
	new_data_grads_norm = 6.5455
	old_data_grads_norm = 5.5748
	sim_grads_norm_tr = 0.0872
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3277
	data_grads_norm = 4.8634
	new_data_grads_norm = 6.4391
	old_data_grads_norm = 7.3488
	sim_grads_norm_tr = -0.0560
-- Starting training on experience 79 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6355
	data_grads_norm = 5.5512
	new_data_grads_norm = 5.5327
	old_data_grads_norm = 6.8972
	sim_grads_norm_tr = 0.0078
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3108
	data_grads_norm = 4.4589
	new_data_grads_norm = 6.3278
	old_data_grads_norm = 6.5308
	sim_grads_norm_tr = -0.0015
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6619
	data_grads_norm = 4.3603
	new_data_grads_norm = 5.9243
	old_data_grads_norm = 6.2531
	sim_grads_norm_tr = -0.0783
-- Starting training on experience 80 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4001
	data_grads_norm = 4.4864
	new_data_grads_norm = 7.7183
	old_data_grads_norm = 5.7409
	sim_grads_norm_tr = 0.0457
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7183
	data_grads_norm = 4.6161
	new_data_grads_norm = 7.7331
	old_data_grads_norm = 5.7875
	sim_grads_norm_tr = -0.0411
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7336
	data_grads_norm = 5.0338
	new_data_grads_norm = 7.4336
	old_data_grads_norm = 5.1166
	sim_grads_norm_tr = 0.0939
-- Starting training on experience 81 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9001
	data_grads_norm = 5.5148
	new_data_grads_norm = 7.4750
	old_data_grads_norm = 7.1864
	sim_grads_norm_tr = 0.1504
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1691
	data_grads_norm = 3.7145
	new_data_grads_norm = 6.5763
	old_data_grads_norm = 4.5315
	sim_grads_norm_tr = -0.0620
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6527
	data_grads_norm = 4.6912
	new_data_grads_norm = 6.2822
	old_data_grads_norm = 7.4504
	sim_grads_norm_tr = -0.0245
-- Starting training on experience 82 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7168
	data_grads_norm = 5.0937
	new_data_grads_norm = 5.9504
	old_data_grads_norm = 7.3509
	sim_grads_norm_tr = 0.0845
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2927
	data_grads_norm = 4.2188
	new_data_grads_norm = 6.2735
	old_data_grads_norm = 5.8511
	sim_grads_norm_tr = 0.0190
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4084
	data_grads_norm = 4.1757
	new_data_grads_norm = 6.0398
	old_data_grads_norm = 5.4634
	sim_grads_norm_tr = 0.0655
-- Starting training on experience 83 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8940
	data_grads_norm = 4.4511
	new_data_grads_norm = 5.8819
	old_data_grads_norm = 5.6840
	sim_grads_norm_tr = 0.0494
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5111
	data_grads_norm = 3.8456
	new_data_grads_norm = 5.1965
	old_data_grads_norm = 4.8843
	sim_grads_norm_tr = 0.1227
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7465
	data_grads_norm = 4.1606
	new_data_grads_norm = 5.7996
	old_data_grads_norm = 5.6674
	sim_grads_norm_tr = -0.0274
-- Starting training on experience 84 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0800
	data_grads_norm = 4.9589
	new_data_grads_norm = 5.8496
	old_data_grads_norm = 6.2905
	sim_grads_norm_tr = -0.0149
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4647
	data_grads_norm = 5.4245
	new_data_grads_norm = 6.3086
	old_data_grads_norm = 7.5777
	sim_grads_norm_tr = 0.0024
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5377
	data_grads_norm = 5.7245
	new_data_grads_norm = 6.1626
	old_data_grads_norm = 8.1236
	sim_grads_norm_tr = 0.0227
-- Starting training on experience 85 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4529
	data_grads_norm = 4.6958
	new_data_grads_norm = 6.6561
	old_data_grads_norm = 6.7362
	sim_grads_norm_tr = -0.0054
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5175
	data_grads_norm = 4.5309
	new_data_grads_norm = 6.6030
	old_data_grads_norm = 5.9097
	sim_grads_norm_tr = -0.0346
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5017
	data_grads_norm = 4.6796
	new_data_grads_norm = 6.5805
	old_data_grads_norm = 6.1224
	sim_grads_norm_tr = 0.1618
-- Starting training on experience 86 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2904
	data_grads_norm = 4.2055
	new_data_grads_norm = 6.1033
	old_data_grads_norm = 5.8751
	sim_grads_norm_tr = -0.0145
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9486
	data_grads_norm = 4.7529
	new_data_grads_norm = 6.0142
	old_data_grads_norm = 6.9329
	sim_grads_norm_tr = 0.0908
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6565
	data_grads_norm = 4.4337
	new_data_grads_norm = 5.9474
	old_data_grads_norm = 5.9408
	sim_grads_norm_tr = 0.0159
-- Starting training on experience 87 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2940
	data_grads_norm = 3.8145
	new_data_grads_norm = 5.0228
	old_data_grads_norm = 5.1284
	sim_grads_norm_tr = 0.0388
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1007
	data_grads_norm = 4.4017
	new_data_grads_norm = 5.4507
	old_data_grads_norm = 5.6960
	sim_grads_norm_tr = 0.0505
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2658
	data_grads_norm = 4.1572
	new_data_grads_norm = 4.9515
	old_data_grads_norm = 6.8205
	sim_grads_norm_tr = -0.0118
-- Starting training on experience 88 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0215
	data_grads_norm = 4.6662
	new_data_grads_norm = 6.1343
	old_data_grads_norm = 6.0519
	sim_grads_norm_tr = -0.0051
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2263
	data_grads_norm = 4.7242
	new_data_grads_norm = 6.1977
	old_data_grads_norm = 6.5703
	sim_grads_norm_tr = 0.0092
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5074
	data_grads_norm = 4.5358
	new_data_grads_norm = 6.3263
	old_data_grads_norm = 4.7279
	sim_grads_norm_tr = 0.1449
-- Starting training on experience 89 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1911
	data_grads_norm = 4.6579
	new_data_grads_norm = 7.1464
	old_data_grads_norm = 4.9673
	sim_grads_norm_tr = 0.0424
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0939
	data_grads_norm = 3.7660
	new_data_grads_norm = 5.7960
	old_data_grads_norm = 4.4681
	sim_grads_norm_tr = -0.0603
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9118
	data_grads_norm = 4.3762
	new_data_grads_norm = 6.1944
	old_data_grads_norm = 4.9067
	sim_grads_norm_tr = 0.0933
-- Starting training on experience 90 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8325
	data_grads_norm = 4.0220
	new_data_grads_norm = 5.0483
	old_data_grads_norm = 5.8431
	sim_grads_norm_tr = -0.0339
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8174
	data_grads_norm = 4.7116
	new_data_grads_norm = 6.2910
	old_data_grads_norm = 6.7294
	sim_grads_norm_tr = -0.0141
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6229
	data_grads_norm = 4.0973
	new_data_grads_norm = 5.9607
	old_data_grads_norm = 6.0539
	sim_grads_norm_tr = -0.0447
-- Starting training on experience 91 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6701
	data_grads_norm = 4.4008
	new_data_grads_norm = 5.7847
	old_data_grads_norm = 5.4527
	sim_grads_norm_tr = 0.1634
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0121
	data_grads_norm = 4.1143
	new_data_grads_norm = 6.3014
	old_data_grads_norm = 6.1818
	sim_grads_norm_tr = -0.0186
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4128
	data_grads_norm = 4.3719
	new_data_grads_norm = 5.8433
	old_data_grads_norm = 6.0754
	sim_grads_norm_tr = -0.0002
-- Starting training on experience 92 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6380
	data_grads_norm = 4.7925
	new_data_grads_norm = 7.2250
	old_data_grads_norm = 6.1020
	sim_grads_norm_tr = -0.0151
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4704
	data_grads_norm = 4.5996
	new_data_grads_norm = 7.0897
	old_data_grads_norm = 4.8513
	sim_grads_norm_tr = -0.0283
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5798
	data_grads_norm = 4.8161
	new_data_grads_norm = 6.8018
	old_data_grads_norm = 5.4734
	sim_grads_norm_tr = 0.2130
-- Starting training on experience 93 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2972
	data_grads_norm = 4.3092
	new_data_grads_norm = 6.5424
	old_data_grads_norm = 4.8216
	sim_grads_norm_tr = 0.0306
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2113
	data_grads_norm = 4.3196
	new_data_grads_norm = 6.0811
	old_data_grads_norm = 6.0766
	sim_grads_norm_tr = 0.0238
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0459
	data_grads_norm = 4.3509
	new_data_grads_norm = 6.2126
	old_data_grads_norm = 4.3946
	sim_grads_norm_tr = 0.0830
-- Starting training on experience 94 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7016
	data_grads_norm = 3.6034
	new_data_grads_norm = 5.2417
	old_data_grads_norm = 5.3357
	sim_grads_norm_tr = -0.0505
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3593
	data_grads_norm = 4.4475
	new_data_grads_norm = 5.8825
	old_data_grads_norm = 6.5753
	sim_grads_norm_tr = -0.0321
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1917
	data_grads_norm = 3.8772
	new_data_grads_norm = 5.4120
	old_data_grads_norm = 5.0717
	sim_grads_norm_tr = -0.0162
-- Starting training on experience 95 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3372
	data_grads_norm = 4.3664
	new_data_grads_norm = 5.6935
	old_data_grads_norm = 5.7221
	sim_grads_norm_tr = 0.0260
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7360
	data_grads_norm = 4.5313
	new_data_grads_norm = 5.5657
	old_data_grads_norm = 6.3954
	sim_grads_norm_tr = -0.0053
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9550
	data_grads_norm = 4.6201
	new_data_grads_norm = 5.9639
	old_data_grads_norm = 6.1882
	sim_grads_norm_tr = 0.1618
-- Starting training on experience 96 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1718
	data_grads_norm = 4.4450
	new_data_grads_norm = 5.6984
	old_data_grads_norm = 5.8525
	sim_grads_norm_tr = -0.0307
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3537
	data_grads_norm = 4.3923
	new_data_grads_norm = 6.1068
	old_data_grads_norm = 6.1186
	sim_grads_norm_tr = -0.0050
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8047
	data_grads_norm = 5.1316
	new_data_grads_norm = 6.5366
	old_data_grads_norm = 6.6614
	sim_grads_norm_tr = 0.0875
-- Starting training on experience 97 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2647
	data_grads_norm = 4.3515
	new_data_grads_norm = 6.1178
	old_data_grads_norm = 5.8978
	sim_grads_norm_tr = 0.0424
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2397
	data_grads_norm = 5.1740
	new_data_grads_norm = 6.7077
	old_data_grads_norm = 8.3805
	sim_grads_norm_tr = 0.0772
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2012
	data_grads_norm = 4.7753
	new_data_grads_norm = 5.7751
	old_data_grads_norm = 6.4340
	sim_grads_norm_tr = 0.0048
-- Starting training on experience 98 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2545
	data_grads_norm = 3.9311
	new_data_grads_norm = 5.7853
	old_data_grads_norm = 4.8715
	sim_grads_norm_tr = 0.0941
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3380
	data_grads_norm = 4.0101
	new_data_grads_norm = 5.4166
	old_data_grads_norm = 5.2579
	sim_grads_norm_tr = 0.0239
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0316
	data_grads_norm = 3.5917
	new_data_grads_norm = 5.1669
	old_data_grads_norm = 5.5918
	sim_grads_norm_tr = -0.0006
-- Starting training on experience 99 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1704
	data_grads_norm = 4.0421
	new_data_grads_norm = 6.9215
	old_data_grads_norm = 4.3932
	sim_grads_norm_tr = 0.0185
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7827
	data_grads_norm = 5.0880
	new_data_grads_norm = 6.4822
	old_data_grads_norm = 7.7244
	sim_grads_norm_tr = 0.0964
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2013
	data_grads_norm = 4.4895
	new_data_grads_norm = 7.1017
	old_data_grads_norm = 5.4875
	sim_grads_norm_tr = 0.0219
-- Starting training on experience 100 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3666
	data_grads_norm = 4.7667
	new_data_grads_norm = 6.3282
	old_data_grads_norm = 6.8575
	sim_grads_norm_tr = 0.0201
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8434
	data_grads_norm = 3.6047
	new_data_grads_norm = 6.3709
	old_data_grads_norm = 4.7248
	sim_grads_norm_tr = -0.0098
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3190
	data_grads_norm = 5.1947
	new_data_grads_norm = 7.3929
	old_data_grads_norm = 7.2757
	sim_grads_norm_tr = 0.0536
-- Starting training on experience 101 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2591
	data_grads_norm = 5.3480
	new_data_grads_norm = 8.0249
	old_data_grads_norm = 6.6702
	sim_grads_norm_tr = -0.0157
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5988
	data_grads_norm = 5.3472
	new_data_grads_norm = 7.7273
	old_data_grads_norm = 6.8494
	sim_grads_norm_tr = -0.0036
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1737
	data_grads_norm = 5.2640
	new_data_grads_norm = 7.6166
	old_data_grads_norm = 5.6811
	sim_grads_norm_tr = -0.0734
-- Starting training on experience 102 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2458
	data_grads_norm = 4.3690
	new_data_grads_norm = 7.0633
	old_data_grads_norm = 6.5029
	sim_grads_norm_tr = 0.0124
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7887
	data_grads_norm = 5.2455
	new_data_grads_norm = 7.4527
	old_data_grads_norm = 7.7127
	sim_grads_norm_tr = -0.0865
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5965
	data_grads_norm = 4.9011
	new_data_grads_norm = 7.2711
	old_data_grads_norm = 5.5431
	sim_grads_norm_tr = 0.0389
-- Starting training on experience 103 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5898
	data_grads_norm = 4.8354
	new_data_grads_norm = 6.0590
	old_data_grads_norm = 6.0784
	sim_grads_norm_tr = 0.0730
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8152
	data_grads_norm = 4.9319
	new_data_grads_norm = 6.4585
	old_data_grads_norm = 7.3284
	sim_grads_norm_tr = -0.0690
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2767
	data_grads_norm = 4.4301
	new_data_grads_norm = 6.3443
	old_data_grads_norm = 5.9883
	sim_grads_norm_tr = 0.0662
-- Starting training on experience 104 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4411
	data_grads_norm = 4.2119
	new_data_grads_norm = 5.6298
	old_data_grads_norm = 6.1510
	sim_grads_norm_tr = 0.0689
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0652
	data_grads_norm = 3.8810
	new_data_grads_norm = 5.7453
	old_data_grads_norm = 5.0732
	sim_grads_norm_tr = 0.0140
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8946
	data_grads_norm = 4.2683
	new_data_grads_norm = 6.2227
	old_data_grads_norm = 5.1373
	sim_grads_norm_tr = 0.0329
-- Starting training on experience 105 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9569
	data_grads_norm = 3.7421
	new_data_grads_norm = 5.6868
	old_data_grads_norm = 5.3361
	sim_grads_norm_tr = -0.0273
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4098
	data_grads_norm = 3.8774
	new_data_grads_norm = 6.0746
	old_data_grads_norm = 4.4299
	sim_grads_norm_tr = -0.0406
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1902
	data_grads_norm = 5.1384
	new_data_grads_norm = 6.9826
	old_data_grads_norm = 6.5146
	sim_grads_norm_tr = 0.1399
-- Starting training on experience 106 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7951
	data_grads_norm = 3.1649
	new_data_grads_norm = 4.6737
	old_data_grads_norm = 4.5318
	sim_grads_norm_tr = -0.0792
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9776
	data_grads_norm = 4.0873
	new_data_grads_norm = 5.9572
	old_data_grads_norm = 5.1521
	sim_grads_norm_tr = 0.0521
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9847
	data_grads_norm = 3.7246
	new_data_grads_norm = 5.1794
	old_data_grads_norm = 4.7818
	sim_grads_norm_tr = -0.0515
-- Starting training on experience 107 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6377
	data_grads_norm = 4.5556
	new_data_grads_norm = 6.6274
	old_data_grads_norm = 6.1562
	sim_grads_norm_tr = 0.0153
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0062
	data_grads_norm = 4.1171
	new_data_grads_norm = 6.1078
	old_data_grads_norm = 5.4621
	sim_grads_norm_tr = 0.0359
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1755
	data_grads_norm = 4.3772
	new_data_grads_norm = 5.8077
	old_data_grads_norm = 5.6725
	sim_grads_norm_tr = 0.0894
-- Starting training on experience 108 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1729
	data_grads_norm = 3.8743
	new_data_grads_norm = 5.9495
	old_data_grads_norm = 4.6998
	sim_grads_norm_tr = 0.0022
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5541
	data_grads_norm = 5.4116
	new_data_grads_norm = 5.5028
	old_data_grads_norm = 8.3665
	sim_grads_norm_tr = 0.1489
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2194
	data_grads_norm = 3.8801
	new_data_grads_norm = 5.4079
	old_data_grads_norm = 5.3390
	sim_grads_norm_tr = 0.0003
-- Starting training on experience 109 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5170
	data_grads_norm = 3.9128
	new_data_grads_norm = 5.9818
	old_data_grads_norm = 4.8278
	sim_grads_norm_tr = 0.0121
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6572
	data_grads_norm = 4.6671
	new_data_grads_norm = 5.9844
	old_data_grads_norm = 6.3253
	sim_grads_norm_tr = 0.0695
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1417
	data_grads_norm = 4.1310
	new_data_grads_norm = 5.8015
	old_data_grads_norm = 6.3171
	sim_grads_norm_tr = 0.0009
-- Starting training on experience 110 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5876
	data_grads_norm = 3.3052
	new_data_grads_norm = 5.0797
	old_data_grads_norm = 5.0529
	sim_grads_norm_tr = -0.0231
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0152
	data_grads_norm = 3.6621
	new_data_grads_norm = 5.1095
	old_data_grads_norm = 4.9934
	sim_grads_norm_tr = -0.0258
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4177
	data_grads_norm = 4.6766
	new_data_grads_norm = 5.6788
	old_data_grads_norm = 6.7021
	sim_grads_norm_tr = 0.0195
-- Starting training on experience 111 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4212
	data_grads_norm = 4.2662
	new_data_grads_norm = 5.2744
	old_data_grads_norm = 5.6351
	sim_grads_norm_tr = 0.0920
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2847
	data_grads_norm = 3.6908
	new_data_grads_norm = 5.0037
	old_data_grads_norm = 5.3015
	sim_grads_norm_tr = 0.0447
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2154
	data_grads_norm = 3.8452
	new_data_grads_norm = 5.8006
	old_data_grads_norm = 4.7469
	sim_grads_norm_tr = 0.2015
-- Starting training on experience 112 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2292
	data_grads_norm = 3.9058
	new_data_grads_norm = 5.3818
	old_data_grads_norm = 5.7031
	sim_grads_norm_tr = 0.0130
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8269
	data_grads_norm = 3.9423
	new_data_grads_norm = 5.9712
	old_data_grads_norm = 5.5966
	sim_grads_norm_tr = 0.0013
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4984
	data_grads_norm = 4.1435
	new_data_grads_norm = 6.0001
	old_data_grads_norm = 4.6950
	sim_grads_norm_tr = 0.0821
-- Starting training on experience 113 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5692
	data_grads_norm = 4.8628
	new_data_grads_norm = 6.3034
	old_data_grads_norm = 7.8847
	sim_grads_norm_tr = 0.0155
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2656
	data_grads_norm = 4.5129
	new_data_grads_norm = 6.7206
	old_data_grads_norm = 6.1125
	sim_grads_norm_tr = 0.0045
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5166
	data_grads_norm = 5.2555
	new_data_grads_norm = 5.7088
	old_data_grads_norm = 7.9096
	sim_grads_norm_tr = 0.0700
-- Starting training on experience 114 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3675
	data_grads_norm = 4.7439
	new_data_grads_norm = 5.3026
	old_data_grads_norm = 7.7343
	sim_grads_norm_tr = -0.0254
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0621
	data_grads_norm = 3.7277
	new_data_grads_norm = 5.8939
	old_data_grads_norm = 3.9087
	sim_grads_norm_tr = 0.0734
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0264
	data_grads_norm = 3.9475
	new_data_grads_norm = 5.5273
	old_data_grads_norm = 5.6954
	sim_grads_norm_tr = 0.0305
-- Starting training on experience 115 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1222
	data_grads_norm = 3.8490
	new_data_grads_norm = 4.5872
	old_data_grads_norm = 5.2881
	sim_grads_norm_tr = 0.0290
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7725
	data_grads_norm = 3.4972
	new_data_grads_norm = 4.5272
	old_data_grads_norm = 5.0315
	sim_grads_norm_tr = -0.0411
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3367
	data_grads_norm = 4.2135
	new_data_grads_norm = 4.6927
	old_data_grads_norm = 5.9835
	sim_grads_norm_tr = 0.0985
-- Starting training on experience 116 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2613
	data_grads_norm = 4.8763
	new_data_grads_norm = 6.8709
	old_data_grads_norm = 6.5022
	sim_grads_norm_tr = 0.0690
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2010
	data_grads_norm = 4.1770
	new_data_grads_norm = 7.0144
	old_data_grads_norm = 5.4765
	sim_grads_norm_tr = 0.0257
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0877
	data_grads_norm = 3.8600
	new_data_grads_norm = 6.4074
	old_data_grads_norm = 4.8801
	sim_grads_norm_tr = -0.1411
-- Starting training on experience 117 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9464
	data_grads_norm = 4.3464
	new_data_grads_norm = 6.3943
	old_data_grads_norm = 5.1936
	sim_grads_norm_tr = -0.0816
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1088
	data_grads_norm = 4.7415
	new_data_grads_norm = 7.0038
	old_data_grads_norm = 6.1426
	sim_grads_norm_tr = 0.0301
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8325
	data_grads_norm = 5.4572
	new_data_grads_norm = 6.5613
	old_data_grads_norm = 6.9099
	sim_grads_norm_tr = 0.1080
-- Starting training on experience 118 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2375
	data_grads_norm = 4.5146
	new_data_grads_norm = 5.3893
	old_data_grads_norm = 6.7439
	sim_grads_norm_tr = 0.0374
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9373
	data_grads_norm = 3.5273
	new_data_grads_norm = 5.2498
	old_data_grads_norm = 3.5282
	sim_grads_norm_tr = 0.0071
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8392
	data_grads_norm = 4.9135
	new_data_grads_norm = 5.3700
	old_data_grads_norm = 6.8570
	sim_grads_norm_tr = 0.1186
-- Starting training on experience 119 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2868
	data_grads_norm = 3.6548
	new_data_grads_norm = 5.1992
	old_data_grads_norm = 5.1473
	sim_grads_norm_tr = -0.0860
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6789
	data_grads_norm = 4.4875
	new_data_grads_norm = 5.9186
	old_data_grads_norm = 6.2798
	sim_grads_norm_tr = 0.0619
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4787
	data_grads_norm = 4.2176
	new_data_grads_norm = 4.9870
	old_data_grads_norm = 5.6258
	sim_grads_norm_tr = 0.1638
-- Starting training on experience 120 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2606
	data_grads_norm = 4.3115
	new_data_grads_norm = 5.6057
	old_data_grads_norm = 6.1983
	sim_grads_norm_tr = -0.1203
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1742
	data_grads_norm = 4.2002
	new_data_grads_norm = 6.4001
	old_data_grads_norm = 5.6625
	sim_grads_norm_tr = -0.0526
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2448
	data_grads_norm = 4.3252
	new_data_grads_norm = 6.1250
	old_data_grads_norm = 5.7129
	sim_grads_norm_tr = 0.1197
-- Starting training on experience 121 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0186
	data_grads_norm = 5.4766
	new_data_grads_norm = 6.3838
	old_data_grads_norm = 7.9563
	sim_grads_norm_tr = 0.0540
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0253
	data_grads_norm = 4.3487
	new_data_grads_norm = 6.4348
	old_data_grads_norm = 5.2128
	sim_grads_norm_tr = -0.0015
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7783
	data_grads_norm = 3.9554
	new_data_grads_norm = 6.5742
	old_data_grads_norm = 5.2063
	sim_grads_norm_tr = 0.0373
-- Starting training on experience 122 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7047
	data_grads_norm = 3.7726
	new_data_grads_norm = 5.6438
	old_data_grads_norm = 4.9380
	sim_grads_norm_tr = 0.0605
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2058
	data_grads_norm = 4.0107
	new_data_grads_norm = 5.3194
	old_data_grads_norm = 5.5137
	sim_grads_norm_tr = 0.0673
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8602
	data_grads_norm = 3.5589
	new_data_grads_norm = 4.5676
	old_data_grads_norm = 5.7252
	sim_grads_norm_tr = -0.1609
-- Starting training on experience 123 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1411
	data_grads_norm = 4.1839
	new_data_grads_norm = 5.2963
	old_data_grads_norm = 6.3697
	sim_grads_norm_tr = -0.0305
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2126
	data_grads_norm = 4.3602
	new_data_grads_norm = 5.9573
	old_data_grads_norm = 5.8449
	sim_grads_norm_tr = 0.0359
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4636
	data_grads_norm = 4.7046
	new_data_grads_norm = 5.3296
	old_data_grads_norm = 6.0709
	sim_grads_norm_tr = -0.0197
-- Starting training on experience 124 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5304
	data_grads_norm = 4.7258
	new_data_grads_norm = 5.3376
	old_data_grads_norm = 7.0426
	sim_grads_norm_tr = 0.0874
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9858
	data_grads_norm = 3.4983
	new_data_grads_norm = 5.3738
	old_data_grads_norm = 3.3637
	sim_grads_norm_tr = 0.1425
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0730
	data_grads_norm = 4.0985
	new_data_grads_norm = 5.3933
	old_data_grads_norm = 6.1368
	sim_grads_norm_tr = 0.0888
-- Starting training on experience 125 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4549
	data_grads_norm = 4.9002
	new_data_grads_norm = 6.5422
	old_data_grads_norm = 6.0707
	sim_grads_norm_tr = 0.0321
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0503
	data_grads_norm = 4.4885
	new_data_grads_norm = 6.4826
	old_data_grads_norm = 5.5986
	sim_grads_norm_tr = 0.0029
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2862
	data_grads_norm = 4.3501
	new_data_grads_norm = 6.3090
	old_data_grads_norm = 5.7072
	sim_grads_norm_tr = 0.0495
-- Starting training on experience 126 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3894
	data_grads_norm = 5.3046
	new_data_grads_norm = 6.0073
	old_data_grads_norm = 6.8998
	sim_grads_norm_tr = 0.0545
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6651
	data_grads_norm = 3.8739
	new_data_grads_norm = 6.3573
	old_data_grads_norm = 4.8801
	sim_grads_norm_tr = 0.0198
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7186
	data_grads_norm = 4.0275
	new_data_grads_norm = 6.3164
	old_data_grads_norm = 5.1456
	sim_grads_norm_tr = -0.0143
-- Starting training on experience 127 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7802
	data_grads_norm = 4.3825
	new_data_grads_norm = 5.1428
	old_data_grads_norm = 6.1643
	sim_grads_norm_tr = -0.0050
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9454
	data_grads_norm = 3.9369
	new_data_grads_norm = 5.3191
	old_data_grads_norm = 5.4610
	sim_grads_norm_tr = 0.1133
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5115
	data_grads_norm = 4.0271
	new_data_grads_norm = 5.6683
	old_data_grads_norm = 5.9691
	sim_grads_norm_tr = -0.0435
-- Starting training on experience 128 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7194
	data_grads_norm = 3.8698
	new_data_grads_norm = 6.0138
	old_data_grads_norm = 5.4736
	sim_grads_norm_tr = 0.0586
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9746
	data_grads_norm = 3.8670
	new_data_grads_norm = 6.3768
	old_data_grads_norm = 5.0919
	sim_grads_norm_tr = 0.0645
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7287
	data_grads_norm = 3.4817
	new_data_grads_norm = 5.2661
	old_data_grads_norm = 5.2473
	sim_grads_norm_tr = -0.0291
-- Starting training on experience 129 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3157
	data_grads_norm = 4.1980
	new_data_grads_norm = 6.8137
	old_data_grads_norm = 4.4487
	sim_grads_norm_tr = -0.0581
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2319
	data_grads_norm = 4.1999
	new_data_grads_norm = 6.0209
	old_data_grads_norm = 5.9270
	sim_grads_norm_tr = -0.0757
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8267
	data_grads_norm = 4.9499
	new_data_grads_norm = 6.4165
	old_data_grads_norm = 6.3419
	sim_grads_norm_tr = 0.1653
-- Starting training on experience 130 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5056
	data_grads_norm = 4.4450
	new_data_grads_norm = 5.8418
	old_data_grads_norm = 6.3960
	sim_grads_norm_tr = 0.0146
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2851
	data_grads_norm = 4.1835
	new_data_grads_norm = 6.5344
	old_data_grads_norm = 5.4185
	sim_grads_norm_tr = 0.0251
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4472
	data_grads_norm = 4.4986
	new_data_grads_norm = 6.4333
	old_data_grads_norm = 5.2404
	sim_grads_norm_tr = 0.0668
-- Starting training on experience 131 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2534
	data_grads_norm = 4.6627
	new_data_grads_norm = 5.2621
	old_data_grads_norm = 6.8400
	sim_grads_norm_tr = 0.0308
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7185
	data_grads_norm = 4.0131
	new_data_grads_norm = 5.5761
	old_data_grads_norm = 5.0657
	sim_grads_norm_tr = 0.0875
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5061
	data_grads_norm = 3.4887
	new_data_grads_norm = 5.1531
	old_data_grads_norm = 4.4161
	sim_grads_norm_tr = -0.0039
-- Starting training on experience 132 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9028
	data_grads_norm = 3.9252
	new_data_grads_norm = 6.5260
	old_data_grads_norm = 3.9913
	sim_grads_norm_tr = 0.1313
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8306
	data_grads_norm = 3.7191
	new_data_grads_norm = 6.0111
	old_data_grads_norm = 4.7770
	sim_grads_norm_tr = -0.0644
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2869
	data_grads_norm = 4.3956
	new_data_grads_norm = 6.8491
	old_data_grads_norm = 5.8127
	sim_grads_norm_tr = -0.0278
-- Starting training on experience 133 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0702
	data_grads_norm = 3.6581
	new_data_grads_norm = 6.1589
	old_data_grads_norm = 4.8832
	sim_grads_norm_tr = -0.0114
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9676
	data_grads_norm = 3.3175
	new_data_grads_norm = 6.3103
	old_data_grads_norm = 3.7923
	sim_grads_norm_tr = 0.0067
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0901
	data_grads_norm = 4.2004
	new_data_grads_norm = 5.6008
	old_data_grads_norm = 5.6781
	sim_grads_norm_tr = 0.0397
-- Starting training on experience 134 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2488
	data_grads_norm = 4.1764
	new_data_grads_norm = 6.8093
	old_data_grads_norm = 4.9174
	sim_grads_norm_tr = -0.0420
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3522
	data_grads_norm = 4.1862
	new_data_grads_norm = 5.9268
	old_data_grads_norm = 6.2297
	sim_grads_norm_tr = 0.0760
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1187
	data_grads_norm = 4.5319
	new_data_grads_norm = 5.6072
	old_data_grads_norm = 7.4148
	sim_grads_norm_tr = 0.0205
-- Starting training on experience 135 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5414
	data_grads_norm = 4.1810
	new_data_grads_norm = 7.2267
	old_data_grads_norm = 6.4416
	sim_grads_norm_tr = -0.0077
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8967
	data_grads_norm = 4.7789
	new_data_grads_norm = 7.7750
	old_data_grads_norm = 7.1000
	sim_grads_norm_tr = 0.0317
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2413
	data_grads_norm = 4.4680
	new_data_grads_norm = 7.3855
	old_data_grads_norm = 5.1291
	sim_grads_norm_tr = 0.0201
-- Starting training on experience 136 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2021
	data_grads_norm = 4.6704
	new_data_grads_norm = 6.8282
	old_data_grads_norm = 5.4738
	sim_grads_norm_tr = 0.1542
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3944
	data_grads_norm = 4.5987
	new_data_grads_norm = 6.9075
	old_data_grads_norm = 6.2310
	sim_grads_norm_tr = -0.0843
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9873
	data_grads_norm = 5.1219
	new_data_grads_norm = 7.3677
	old_data_grads_norm = 6.3398
	sim_grads_norm_tr = 0.0523
-- Starting training on experience 137 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4571
	data_grads_norm = 4.4928
	new_data_grads_norm = 5.5744
	old_data_grads_norm = 6.5262
	sim_grads_norm_tr = -0.0086
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0732
	data_grads_norm = 4.0441
	new_data_grads_norm = 5.5858
	old_data_grads_norm = 5.3149
	sim_grads_norm_tr = 0.0567
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1963
	data_grads_norm = 3.9430
	new_data_grads_norm = 4.8292
	old_data_grads_norm = 6.5156
	sim_grads_norm_tr = -0.0799
-- Starting training on experience 138 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4021
	data_grads_norm = 4.3238
	new_data_grads_norm = 5.0950
	old_data_grads_norm = 7.2301
	sim_grads_norm_tr = 0.0100
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3284
	data_grads_norm = 4.5347
	new_data_grads_norm = 6.1445
	old_data_grads_norm = 6.6202
	sim_grads_norm_tr = -0.0100
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3382
	data_grads_norm = 4.1190
	new_data_grads_norm = 5.5328
	old_data_grads_norm = 5.9921
	sim_grads_norm_tr = 0.0149
-- Starting training on experience 139 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8064
	data_grads_norm = 5.0513
	new_data_grads_norm = 6.6040
	old_data_grads_norm = 6.9591
	sim_grads_norm_tr = 0.0164
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4927
	data_grads_norm = 4.7929
	new_data_grads_norm = 6.1174
	old_data_grads_norm = 6.7308
	sim_grads_norm_tr = 0.0982
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2619
	data_grads_norm = 4.8639
	new_data_grads_norm = 6.8293
	old_data_grads_norm = 6.1237
	sim_grads_norm_tr = 0.0981
-- Starting training on experience 140 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3022
	data_grads_norm = 4.0070
	new_data_grads_norm = 5.7359
	old_data_grads_norm = 5.6289
	sim_grads_norm_tr = 0.0491
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3733
	data_grads_norm = 4.6303
	new_data_grads_norm = 6.6750
	old_data_grads_norm = 7.0985
	sim_grads_norm_tr = 0.0530
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8597
	data_grads_norm = 3.7754
	new_data_grads_norm = 6.0899
	old_data_grads_norm = 5.0079
	sim_grads_norm_tr = -0.0564
-- Starting training on experience 141 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8003
	data_grads_norm = 4.5383
	new_data_grads_norm = 5.9764
	old_data_grads_norm = 6.5071
	sim_grads_norm_tr = 0.0243
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1196
	data_grads_norm = 4.7879
	new_data_grads_norm = 6.5839
	old_data_grads_norm = 6.3773
	sim_grads_norm_tr = -0.0112
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6124
	data_grads_norm = 4.5600
	new_data_grads_norm = 6.0284
	old_data_grads_norm = 5.4346
	sim_grads_norm_tr = 0.0731
-- Starting training on experience 142 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2415
	data_grads_norm = 4.1935
	new_data_grads_norm = 6.7278
	old_data_grads_norm = 6.0285
	sim_grads_norm_tr = 0.0434
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3200
	data_grads_norm = 4.3614
	new_data_grads_norm = 6.6959
	old_data_grads_norm = 5.6910
	sim_grads_norm_tr = 0.1015
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1351
	data_grads_norm = 4.0985
	new_data_grads_norm = 6.5835
	old_data_grads_norm = 5.6816
	sim_grads_norm_tr = -0.0988
-- Starting training on experience 143 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0713
	data_grads_norm = 3.9655
	new_data_grads_norm = 5.4703
	old_data_grads_norm = 5.4354
	sim_grads_norm_tr = -0.0480
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1212
	data_grads_norm = 4.1247
	new_data_grads_norm = 5.4018
	old_data_grads_norm = 6.0669
	sim_grads_norm_tr = 0.0383
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9106
	data_grads_norm = 3.8355
	new_data_grads_norm = 5.6853
	old_data_grads_norm = 4.4759
	sim_grads_norm_tr = -0.0042
-- Starting training on experience 144 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2294
	data_grads_norm = 4.4440
	new_data_grads_norm = 6.3337
	old_data_grads_norm = 6.0677
	sim_grads_norm_tr = 0.0107
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7368
	data_grads_norm = 5.0119
	new_data_grads_norm = 6.4706
	old_data_grads_norm = 6.7669
	sim_grads_norm_tr = 0.0726
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8193
	data_grads_norm = 3.9597
	new_data_grads_norm = 6.2070
	old_data_grads_norm = 4.7315
	sim_grads_norm_tr = 0.0930
-- Starting training on experience 145 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2498
	data_grads_norm = 3.7166
	new_data_grads_norm = 6.1757
	old_data_grads_norm = 4.6157
	sim_grads_norm_tr = -0.0891
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5653
	data_grads_norm = 4.5987
	new_data_grads_norm = 5.7933
	old_data_grads_norm = 6.4818
	sim_grads_norm_tr = -0.0429
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5738
	data_grads_norm = 4.1552
	new_data_grads_norm = 6.7329
	old_data_grads_norm = 4.8352
	sim_grads_norm_tr = -0.0656
-- Starting training on experience 146 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1296
	data_grads_norm = 3.9892
	new_data_grads_norm = 5.8576
	old_data_grads_norm = 5.1940
	sim_grads_norm_tr = 0.0627
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2428
	data_grads_norm = 4.0651
	new_data_grads_norm = 5.9903
	old_data_grads_norm = 5.0183
	sim_grads_norm_tr = -0.0495
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4745
	data_grads_norm = 4.3538
	new_data_grads_norm = 5.7316
	old_data_grads_norm = 6.1113
	sim_grads_norm_tr = 0.0976
-- Starting training on experience 147 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0740
	data_grads_norm = 3.6852
	new_data_grads_norm = 5.1129
	old_data_grads_norm = 6.2296
	sim_grads_norm_tr = -0.0613
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4517
	data_grads_norm = 4.1330
	new_data_grads_norm = 5.7097
	old_data_grads_norm = 5.0252
	sim_grads_norm_tr = 0.1109
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3281
	data_grads_norm = 4.0216
	new_data_grads_norm = 5.4466
	old_data_grads_norm = 5.2696
	sim_grads_norm_tr = -0.0198
-- Starting training on experience 148 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0386
	data_grads_norm = 4.3211
	new_data_grads_norm = 6.9607
	old_data_grads_norm = 4.5165
	sim_grads_norm_tr = 0.1144
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7246
	data_grads_norm = 4.0347
	new_data_grads_norm = 7.0454
	old_data_grads_norm = 5.2835
	sim_grads_norm_tr = -0.0814
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8838
	data_grads_norm = 3.7924
	new_data_grads_norm = 6.4260
	old_data_grads_norm = 4.3260
	sim_grads_norm_tr = -0.0177
-- Starting training on experience 149 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2845
	data_grads_norm = 3.5290
	new_data_grads_norm = 5.1910
	old_data_grads_norm = 5.2776
	sim_grads_norm_tr = 0.0040
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8908
	data_grads_norm = 4.3568
	new_data_grads_norm = 5.3263
	old_data_grads_norm = 6.5437
	sim_grads_norm_tr = -0.0090
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5421
	data_grads_norm = 3.9893
	new_data_grads_norm = 5.2926
	old_data_grads_norm = 6.4987
	sim_grads_norm_tr = -0.0016
-- Starting training on experience 150 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1389
	data_grads_norm = 4.3009
	new_data_grads_norm = 5.8438
	old_data_grads_norm = 6.1663
	sim_grads_norm_tr = -0.0060
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2979
	data_grads_norm = 4.7870
	new_data_grads_norm = 6.1467
	old_data_grads_norm = 6.4330
	sim_grads_norm_tr = 0.0653
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1723
	data_grads_norm = 4.3996
	new_data_grads_norm = 6.4575
	old_data_grads_norm = 5.8685
	sim_grads_norm_tr = -0.0512
-- Starting training on experience 151 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1629
	data_grads_norm = 4.2993
	new_data_grads_norm = 6.6849
	old_data_grads_norm = 5.3207
	sim_grads_norm_tr = 0.1019
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0105
	data_grads_norm = 3.3119
	new_data_grads_norm = 5.2152
	old_data_grads_norm = 4.5652
	sim_grads_norm_tr = -0.0102
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2988
	data_grads_norm = 4.6498
	new_data_grads_norm = 5.2467
	old_data_grads_norm = 6.5849
	sim_grads_norm_tr = 0.0662
-- Starting training on experience 152 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2330
	data_grads_norm = 4.2304
	new_data_grads_norm = 6.7358
	old_data_grads_norm = 6.0413
	sim_grads_norm_tr = -0.1300
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7031
	data_grads_norm = 5.1137
	new_data_grads_norm = 7.9066
	old_data_grads_norm = 6.2613
	sim_grads_norm_tr = -0.0486
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9873
	data_grads_norm = 5.5301
	new_data_grads_norm = 7.9722
	old_data_grads_norm = 6.8262
	sim_grads_norm_tr = -0.0301
-- Starting training on experience 153 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8017
	data_grads_norm = 4.1726
	new_data_grads_norm = 6.0303
	old_data_grads_norm = 4.8354
	sim_grads_norm_tr = 0.0977
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4635
	data_grads_norm = 3.9778
	new_data_grads_norm = 5.8001
	old_data_grads_norm = 4.9663
	sim_grads_norm_tr = 0.0924
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6793
	data_grads_norm = 4.4255
	new_data_grads_norm = 5.8662
	old_data_grads_norm = 6.0619
	sim_grads_norm_tr = -0.0473
-- Starting training on experience 154 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5393
	data_grads_norm = 4.6750
	new_data_grads_norm = 7.0456
	old_data_grads_norm = 5.3795
	sim_grads_norm_tr = 0.0301
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8025
	data_grads_norm = 4.7914
	new_data_grads_norm = 7.4406
	old_data_grads_norm = 5.6195
	sim_grads_norm_tr = -0.0214
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9831
	data_grads_norm = 5.0089
	new_data_grads_norm = 7.6709
	old_data_grads_norm = 6.3097
	sim_grads_norm_tr = 0.0236
-- Starting training on experience 155 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2851
	data_grads_norm = 4.2856
	new_data_grads_norm = 5.7070
	old_data_grads_norm = 6.5307
	sim_grads_norm_tr = -0.0119
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0759
	data_grads_norm = 3.9783
	new_data_grads_norm = 6.1339
	old_data_grads_norm = 5.2036
	sim_grads_norm_tr = 0.0100
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2858
	data_grads_norm = 4.8689
	new_data_grads_norm = 6.5380
	old_data_grads_norm = 7.5042
	sim_grads_norm_tr = 0.0450
-- Starting training on experience 156 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9555
	data_grads_norm = 3.9933
	new_data_grads_norm = 6.6994
	old_data_grads_norm = 4.3132
	sim_grads_norm_tr = -0.0152
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5309
	data_grads_norm = 5.2630
	new_data_grads_norm = 7.4103
	old_data_grads_norm = 6.9800
	sim_grads_norm_tr = 0.0087
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1049
	data_grads_norm = 3.7802
	new_data_grads_norm = 6.3817
	old_data_grads_norm = 4.8503
	sim_grads_norm_tr = 0.1242
-- Starting training on experience 157 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3431
	data_grads_norm = 4.4519
	new_data_grads_norm = 6.1762
	old_data_grads_norm = 6.4368
	sim_grads_norm_tr = 0.0981
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0333
	data_grads_norm = 4.0479
	new_data_grads_norm = 5.2908
	old_data_grads_norm = 5.0524
	sim_grads_norm_tr = 0.0993
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0900
	data_grads_norm = 4.3768
	new_data_grads_norm = 5.2592
	old_data_grads_norm = 6.2434
	sim_grads_norm_tr = 0.0172
-- Starting training on experience 158 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2960
	data_grads_norm = 3.6292
	new_data_grads_norm = 5.7828
	old_data_grads_norm = 4.1798
	sim_grads_norm_tr = -0.0326
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1670
	data_grads_norm = 3.9326
	new_data_grads_norm = 5.7958
	old_data_grads_norm = 5.5690
	sim_grads_norm_tr = -0.0257
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3692
	data_grads_norm = 4.0349
	new_data_grads_norm = 5.9318
	old_data_grads_norm = 5.4609
	sim_grads_norm_tr = 0.0253
-- Starting training on experience 159 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3285
	data_grads_norm = 5.2756
	new_data_grads_norm = 6.5500
	old_data_grads_norm = 6.3141
	sim_grads_norm_tr = 0.0911
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1120
	data_grads_norm = 4.8711
	new_data_grads_norm = 7.1527
	old_data_grads_norm = 7.6844
	sim_grads_norm_tr = -0.1410
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1299
	data_grads_norm = 5.1325
	new_data_grads_norm = 7.0493
	old_data_grads_norm = 6.1714
	sim_grads_norm_tr = 0.0244
-- Starting training on experience 160 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0106
	data_grads_norm = 3.7331
	new_data_grads_norm = 6.9679
	old_data_grads_norm = 4.1629
	sim_grads_norm_tr = -0.0521
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7368
	data_grads_norm = 5.1034
	new_data_grads_norm = 7.9416
	old_data_grads_norm = 6.8291
	sim_grads_norm_tr = 0.0872
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2033
	data_grads_norm = 4.5704
	new_data_grads_norm = 7.3000
	old_data_grads_norm = 6.1422
	sim_grads_norm_tr = -0.0098
-- Starting training on experience 161 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2193
	data_grads_norm = 5.5594
	new_data_grads_norm = 7.1841
	old_data_grads_norm = 6.2093
	sim_grads_norm_tr = 0.1490
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6789
	data_grads_norm = 4.2378
	new_data_grads_norm = 5.7244
	old_data_grads_norm = 5.6429
	sim_grads_norm_tr = 0.0182
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1248
	data_grads_norm = 4.2537
	new_data_grads_norm = 5.9510
	old_data_grads_norm = 5.5245
	sim_grads_norm_tr = 0.0219
-- Starting training on experience 162 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3385
	data_grads_norm = 4.0024
	new_data_grads_norm = 5.3676
	old_data_grads_norm = 6.6605
	sim_grads_norm_tr = -0.0481
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7609
	data_grads_norm = 5.1144
	new_data_grads_norm = 6.0301
	old_data_grads_norm = 7.6192
	sim_grads_norm_tr = 0.0167
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3398
	data_grads_norm = 4.6213
	new_data_grads_norm = 5.6026
	old_data_grads_norm = 6.5010
	sim_grads_norm_tr = 0.0769
-- Starting training on experience 163 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3929
	data_grads_norm = 4.0157
	new_data_grads_norm = 5.4256
	old_data_grads_norm = 5.1591
	sim_grads_norm_tr = 0.0374
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6382
	data_grads_norm = 4.2900
	new_data_grads_norm = 5.8916
	old_data_grads_norm = 5.3656
	sim_grads_norm_tr = 0.0810
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6510
	data_grads_norm = 4.7525
	new_data_grads_norm = 6.2211
	old_data_grads_norm = 5.8839
	sim_grads_norm_tr = 0.1109
-- Starting training on experience 164 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4038
	data_grads_norm = 4.7316
	new_data_grads_norm = 6.1946
	old_data_grads_norm = 6.8436
	sim_grads_norm_tr = 0.0887
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4561
	data_grads_norm = 4.2669
	new_data_grads_norm = 6.0054
	old_data_grads_norm = 5.0075
	sim_grads_norm_tr = 0.0565
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4395
	data_grads_norm = 4.0472
	new_data_grads_norm = 6.2644
	old_data_grads_norm = 5.1592
	sim_grads_norm_tr = -0.0251
-- Starting training on experience 165 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6790
	data_grads_norm = 4.7296
	new_data_grads_norm = 5.7166
	old_data_grads_norm = 6.8974
	sim_grads_norm_tr = -0.0122
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3589
	data_grads_norm = 4.9194
	new_data_grads_norm = 5.7652
	old_data_grads_norm = 7.0379
	sim_grads_norm_tr = 0.0488
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4604
	data_grads_norm = 4.6993
	new_data_grads_norm = 6.2989
	old_data_grads_norm = 6.9438
	sim_grads_norm_tr = -0.0072
-- Starting training on experience 166 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7797
	data_grads_norm = 3.6604
	new_data_grads_norm = 5.3955
	old_data_grads_norm = 5.3878
	sim_grads_norm_tr = -0.0073
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2129
	data_grads_norm = 4.4052
	new_data_grads_norm = 6.2281
	old_data_grads_norm = 6.2604
	sim_grads_norm_tr = -0.0222
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2673
	data_grads_norm = 4.1901
	new_data_grads_norm = 5.4094
	old_data_grads_norm = 6.2136
	sim_grads_norm_tr = 0.0731
-- Starting training on experience 167 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3909
	data_grads_norm = 4.4075
	new_data_grads_norm = 6.0016
	old_data_grads_norm = 6.4298
	sim_grads_norm_tr = -0.0069
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3615
	data_grads_norm = 4.3433
	new_data_grads_norm = 6.0346
	old_data_grads_norm = 5.9553
	sim_grads_norm_tr = 0.0202
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6310
	data_grads_norm = 4.8315
	new_data_grads_norm = 6.5576
	old_data_grads_norm = 6.7931
	sim_grads_norm_tr = 0.0830
-- Starting training on experience 168 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4488
	data_grads_norm = 4.4658
	new_data_grads_norm = 5.6307
	old_data_grads_norm = 7.2567
	sim_grads_norm_tr = 0.0717
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5872
	data_grads_norm = 4.8952
	new_data_grads_norm = 5.8177
	old_data_grads_norm = 7.5427
	sim_grads_norm_tr = 0.0129
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9033
	data_grads_norm = 4.0560
	new_data_grads_norm = 6.2235
	old_data_grads_norm = 4.4573
	sim_grads_norm_tr = 0.0153
-- Starting training on experience 169 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3477
	data_grads_norm = 5.0439
	new_data_grads_norm = 6.4115
	old_data_grads_norm = 6.8948
	sim_grads_norm_tr = 0.0664
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0910
	data_grads_norm = 4.5789
	new_data_grads_norm = 6.1884
	old_data_grads_norm = 6.4899
	sim_grads_norm_tr = 0.0470
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6860
	data_grads_norm = 4.7812
	new_data_grads_norm = 5.1804
	old_data_grads_norm = 7.3209
	sim_grads_norm_tr = 0.0467
-- Starting training on experience 170 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6971
	data_grads_norm = 3.8681
	new_data_grads_norm = 5.5065
	old_data_grads_norm = 5.5984
	sim_grads_norm_tr = -0.0506
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3847
	data_grads_norm = 4.0196
	new_data_grads_norm = 6.1805
	old_data_grads_norm = 6.2117
	sim_grads_norm_tr = -0.0425
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1250
	data_grads_norm = 3.9564
	new_data_grads_norm = 5.8264
	old_data_grads_norm = 6.5627
	sim_grads_norm_tr = 0.0000
-- Starting training on experience 171 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9241
	data_grads_norm = 4.0642
	new_data_grads_norm = 6.2137
	old_data_grads_norm = 5.5513
	sim_grads_norm_tr = -0.0157
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5742
	data_grads_norm = 5.1246
	new_data_grads_norm = 7.5997
	old_data_grads_norm = 5.7816
	sim_grads_norm_tr = -0.0295
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3861
	data_grads_norm = 4.9661
	new_data_grads_norm = 7.8103
	old_data_grads_norm = 4.8017
	sim_grads_norm_tr = 0.1326
-- Starting training on experience 172 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4456
	data_grads_norm = 4.2061
	new_data_grads_norm = 6.4774
	old_data_grads_norm = 4.9353
	sim_grads_norm_tr = -0.0145
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1307
	data_grads_norm = 4.4492
	new_data_grads_norm = 7.1120
	old_data_grads_norm = 5.5188
	sim_grads_norm_tr = 0.0666
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8021
	data_grads_norm = 4.0397
	new_data_grads_norm = 6.8152
	old_data_grads_norm = 5.6400
	sim_grads_norm_tr = -0.0423
-- Starting training on experience 173 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3600
	data_grads_norm = 3.9557
	new_data_grads_norm = 5.6721
	old_data_grads_norm = 4.5634
	sim_grads_norm_tr = 0.0827
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6958
	data_grads_norm = 4.9513
	new_data_grads_norm = 5.6781
	old_data_grads_norm = 7.8247
	sim_grads_norm_tr = 0.0259
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8988
	data_grads_norm = 4.1185
	new_data_grads_norm = 5.5386
	old_data_grads_norm = 5.3591
	sim_grads_norm_tr = 0.0356
-- Starting training on experience 174 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5890
	data_grads_norm = 4.6291
	new_data_grads_norm = 7.1237
	old_data_grads_norm = 5.2687
	sim_grads_norm_tr = 0.0396
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5494
	data_grads_norm = 4.8591
	new_data_grads_norm = 6.8497
	old_data_grads_norm = 5.2694
	sim_grads_norm_tr = 0.0340
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3213
	data_grads_norm = 4.5256
	new_data_grads_norm = 7.3859
	old_data_grads_norm = 5.8112
	sim_grads_norm_tr = 0.0795
-- Starting training on experience 175 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8393
	data_grads_norm = 3.9288
	new_data_grads_norm = 5.6732
	old_data_grads_norm = 4.9551
	sim_grads_norm_tr = 0.0252
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2760
	data_grads_norm = 4.3528
	new_data_grads_norm = 5.7036
	old_data_grads_norm = 6.0920
	sim_grads_norm_tr = 0.0141
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6842
	data_grads_norm = 3.7986
	new_data_grads_norm = 5.3178
	old_data_grads_norm = 4.3620
	sim_grads_norm_tr = 0.1462
-- Starting training on experience 176 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2743
	data_grads_norm = 4.4027
	new_data_grads_norm = 5.6720
	old_data_grads_norm = 6.1691
	sim_grads_norm_tr = 0.0330
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7404
	data_grads_norm = 3.5009
	new_data_grads_norm = 5.2208
	old_data_grads_norm = 4.6426
	sim_grads_norm_tr = -0.0840
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7202
	data_grads_norm = 3.8663
	new_data_grads_norm = 5.5888
	old_data_grads_norm = 6.1123
	sim_grads_norm_tr = 0.0099
-- Starting training on experience 177 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0339
	data_grads_norm = 3.9036
	new_data_grads_norm = 5.8346
	old_data_grads_norm = 4.6251
	sim_grads_norm_tr = -0.0073
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2286
	data_grads_norm = 4.9039
	new_data_grads_norm = 5.6801
	old_data_grads_norm = 7.9125
	sim_grads_norm_tr = -0.0304
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6727
	data_grads_norm = 4.2632
	new_data_grads_norm = 5.5864
	old_data_grads_norm = 6.1318
	sim_grads_norm_tr = -0.0666
-- Starting training on experience 178 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7420
	data_grads_norm = 5.2979
	new_data_grads_norm = 7.3206
	old_data_grads_norm = 6.9004
	sim_grads_norm_tr = 0.0769
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4017
	data_grads_norm = 4.8260
	new_data_grads_norm = 7.4017
	old_data_grads_norm = 6.9377
	sim_grads_norm_tr = -0.0764
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6823
	data_grads_norm = 3.9193
	new_data_grads_norm = 7.7232
	old_data_grads_norm = 4.4971
	sim_grads_norm_tr = -0.0475
-- Starting training on experience 179 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0638
	data_grads_norm = 4.3011
	new_data_grads_norm = 7.2742
	old_data_grads_norm = 5.3094
	sim_grads_norm_tr = -0.0014
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9448
	data_grads_norm = 4.6364
	new_data_grads_norm = 6.7732
	old_data_grads_norm = 5.5454
	sim_grads_norm_tr = 0.1079
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2933
	data_grads_norm = 4.8873
	new_data_grads_norm = 6.5385
	old_data_grads_norm = 6.1579
	sim_grads_norm_tr = 0.0060
-- Starting training on experience 180 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7978
	data_grads_norm = 5.2840
	new_data_grads_norm = 6.8927
	old_data_grads_norm = 6.7170
	sim_grads_norm_tr = 0.1155
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1294
	data_grads_norm = 4.8372
	new_data_grads_norm = 6.8597
	old_data_grads_norm = 7.9858
	sim_grads_norm_tr = 0.1786
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0346
	data_grads_norm = 4.1831
	new_data_grads_norm = 6.3559
	old_data_grads_norm = 5.7261
	sim_grads_norm_tr = 0.0075
-- Starting training on experience 181 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4126
	data_grads_norm = 4.3191
	new_data_grads_norm = 6.4038
	old_data_grads_norm = 6.2760
	sim_grads_norm_tr = -0.0089
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2944
	data_grads_norm = 4.7407
	new_data_grads_norm = 6.5043
	old_data_grads_norm = 6.6267
	sim_grads_norm_tr = 0.0723
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3776
	data_grads_norm = 3.9577
	new_data_grads_norm = 6.0617
	old_data_grads_norm = 4.6624
	sim_grads_norm_tr = 0.0343
-- Starting training on experience 182 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3147
	data_grads_norm = 4.1829
	new_data_grads_norm = 5.8707
	old_data_grads_norm = 5.2088
	sim_grads_norm_tr = 0.1348
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6171
	data_grads_norm = 5.0540
	new_data_grads_norm = 5.9836
	old_data_grads_norm = 7.2584
	sim_grads_norm_tr = 0.0717
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5859
	data_grads_norm = 4.9959
	new_data_grads_norm = 6.1704
	old_data_grads_norm = 6.6781
	sim_grads_norm_tr = 0.0657
-- Starting training on experience 183 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1879
	data_grads_norm = 4.0009
	new_data_grads_norm = 6.6685
	old_data_grads_norm = 4.9823
	sim_grads_norm_tr = -0.0585
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3640
	data_grads_norm = 4.4477
	new_data_grads_norm = 7.2025
	old_data_grads_norm = 4.3905
	sim_grads_norm_tr = 0.0134
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7369
	data_grads_norm = 4.6073
	new_data_grads_norm = 6.9155
	old_data_grads_norm = 5.8119
	sim_grads_norm_tr = 0.0736
-- Starting training on experience 184 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7442
	data_grads_norm = 4.5645
	new_data_grads_norm = 6.1623
	old_data_grads_norm = 7.1312
	sim_grads_norm_tr = 0.0022
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8105
	data_grads_norm = 4.6494
	new_data_grads_norm = 5.8486
	old_data_grads_norm = 6.4826
	sim_grads_norm_tr = 0.0808
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8919
	data_grads_norm = 4.7102
	new_data_grads_norm = 6.2138
	old_data_grads_norm = 6.7529
	sim_grads_norm_tr = 0.0616
-- Starting training on experience 185 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1202
	data_grads_norm = 3.9321
	new_data_grads_norm = 4.9824
	old_data_grads_norm = 6.2484
	sim_grads_norm_tr = -0.0028
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1581
	data_grads_norm = 4.2223
	new_data_grads_norm = 5.5858
	old_data_grads_norm = 6.0847
	sim_grads_norm_tr = -0.1058
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0826
	data_grads_norm = 4.0997
	new_data_grads_norm = 6.1031
	old_data_grads_norm = 5.1675
	sim_grads_norm_tr = 0.0022
-- Starting training on experience 186 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8966
	data_grads_norm = 4.1434
	new_data_grads_norm = 5.8779
	old_data_grads_norm = 5.9288
	sim_grads_norm_tr = -0.0161
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1283
	data_grads_norm = 4.8393
	new_data_grads_norm = 6.0741
	old_data_grads_norm = 6.7189
	sim_grads_norm_tr = 0.1014
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6925
	data_grads_norm = 3.9700
	new_data_grads_norm = 6.0307
	old_data_grads_norm = 5.5529
	sim_grads_norm_tr = 0.0251
-- Starting training on experience 187 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3655
	data_grads_norm = 4.5529
	new_data_grads_norm = 6.5142
	old_data_grads_norm = 6.3347
	sim_grads_norm_tr = 0.0292
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4255
	data_grads_norm = 4.0977
	new_data_grads_norm = 5.7003
	old_data_grads_norm = 5.1291
	sim_grads_norm_tr = 0.0128
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5053
	data_grads_norm = 4.9966
	new_data_grads_norm = 5.9377
	old_data_grads_norm = 7.0027
	sim_grads_norm_tr = 0.0886
-- Starting training on experience 188 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9986
	data_grads_norm = 4.3801
	new_data_grads_norm = 6.6525
	old_data_grads_norm = 5.3765
	sim_grads_norm_tr = -0.0036
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9053
	data_grads_norm = 4.7685
	new_data_grads_norm = 7.5064
	old_data_grads_norm = 4.4081
	sim_grads_norm_tr = 0.1516
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1563
	data_grads_norm = 4.1776
	new_data_grads_norm = 6.4374
	old_data_grads_norm = 5.0087
	sim_grads_norm_tr = -0.0377
-- Starting training on experience 189 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9878
	data_grads_norm = 3.7830
	new_data_grads_norm = 6.6856
	old_data_grads_norm = 5.1925
	sim_grads_norm_tr = -0.0126
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2993
	data_grads_norm = 4.6774
	new_data_grads_norm = 6.6931
	old_data_grads_norm = 6.2688
	sim_grads_norm_tr = 0.0073
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5661
	data_grads_norm = 4.9538
	new_data_grads_norm = 6.4638
	old_data_grads_norm = 6.9474
	sim_grads_norm_tr = 0.0190
-- Starting training on experience 190 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7809
	data_grads_norm = 4.6645
	new_data_grads_norm = 7.1318
	old_data_grads_norm = 5.5651
	sim_grads_norm_tr = 0.0295
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6281
	data_grads_norm = 4.7208
	new_data_grads_norm = 6.8986
	old_data_grads_norm = 6.0369
	sim_grads_norm_tr = -0.0204
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4959
	data_grads_norm = 4.8508
	new_data_grads_norm = 7.7694
	old_data_grads_norm = 4.6346
	sim_grads_norm_tr = 0.0187
-- Starting training on experience 191 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6407
	data_grads_norm = 4.7126
	new_data_grads_norm = 6.3401
	old_data_grads_norm = 5.5070
	sim_grads_norm_tr = 0.0475
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5510
	data_grads_norm = 5.2339
	new_data_grads_norm = 6.6355
	old_data_grads_norm = 5.8671
	sim_grads_norm_tr = 0.0673
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4878
	data_grads_norm = 4.8122
	new_data_grads_norm = 6.3756
	old_data_grads_norm = 6.4964
	sim_grads_norm_tr = 0.0771
-- Starting training on experience 192 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3791
	data_grads_norm = 4.9692
	new_data_grads_norm = 6.3252
	old_data_grads_norm = 8.2677
	sim_grads_norm_tr = -0.0360
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0258
	data_grads_norm = 4.3613
	new_data_grads_norm = 6.4669
	old_data_grads_norm = 5.6385
	sim_grads_norm_tr = 0.0742
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1931
	data_grads_norm = 4.1085
	new_data_grads_norm = 6.5134
	old_data_grads_norm = 5.4473
	sim_grads_norm_tr = -0.0453
-- Starting training on experience 193 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5551
	data_grads_norm = 4.2462
	new_data_grads_norm = 5.9042
	old_data_grads_norm = 6.1102
	sim_grads_norm_tr = -0.0365
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4729
	data_grads_norm = 4.0132
	new_data_grads_norm = 6.4765
	old_data_grads_norm = 4.1891
	sim_grads_norm_tr = 0.0335
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4407
	data_grads_norm = 4.9350
	new_data_grads_norm = 6.2590
	old_data_grads_norm = 6.7688
	sim_grads_norm_tr = 0.0752
-- Starting training on experience 194 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8389
	data_grads_norm = 3.7557
	new_data_grads_norm = 6.5447
	old_data_grads_norm = 4.9914
	sim_grads_norm_tr = -0.0194
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0678
	data_grads_norm = 4.1572
	new_data_grads_norm = 6.5087
	old_data_grads_norm = 5.3301
	sim_grads_norm_tr = -0.0468
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1449
	data_grads_norm = 4.2637
	new_data_grads_norm = 6.1988
	old_data_grads_norm = 5.0599
	sim_grads_norm_tr = 0.0705
-- Starting training on experience 195 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2598
	data_grads_norm = 3.5369
	new_data_grads_norm = 6.1464
	old_data_grads_norm = 4.2306
	sim_grads_norm_tr = -0.0515
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3917
	data_grads_norm = 3.7909
	new_data_grads_norm = 6.0993
	old_data_grads_norm = 4.4314
	sim_grads_norm_tr = 0.0611
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8246
	data_grads_norm = 3.2000
	new_data_grads_norm = 6.0469
	old_data_grads_norm = 3.2329
	sim_grads_norm_tr = -0.0202
-- Starting training on experience 196 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3195
	data_grads_norm = 4.1564
	new_data_grads_norm = 5.7785
	old_data_grads_norm = 5.7162
	sim_grads_norm_tr = -0.0249
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7733
	data_grads_norm = 4.8899
	new_data_grads_norm = 5.9349
	old_data_grads_norm = 6.0458
	sim_grads_norm_tr = 0.0819
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6701
	data_grads_norm = 4.6854
	new_data_grads_norm = 6.0242
	old_data_grads_norm = 6.7353
	sim_grads_norm_tr = 0.0094
-- Starting training on experience 197 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2960
	data_grads_norm = 4.6543
	new_data_grads_norm = 6.7604
	old_data_grads_norm = 7.3475
	sim_grads_norm_tr = 0.0164
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3654
	data_grads_norm = 4.4476
	new_data_grads_norm = 7.0914
	old_data_grads_norm = 4.9361
	sim_grads_norm_tr = 0.0496
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3307
	data_grads_norm = 4.1829
	new_data_grads_norm = 6.5048
	old_data_grads_norm = 5.1937
	sim_grads_norm_tr = 0.0176
-- Starting training on experience 198 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4352
	data_grads_norm = 4.8313
	new_data_grads_norm = 6.9572
	old_data_grads_norm = 6.6602
	sim_grads_norm_tr = 0.0399
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2594
	data_grads_norm = 4.4337
	new_data_grads_norm = 7.5831
	old_data_grads_norm = 5.4457
	sim_grads_norm_tr = -0.0555
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7216
	data_grads_norm = 5.2447
	new_data_grads_norm = 7.3016
	old_data_grads_norm = 5.9512
	sim_grads_norm_tr = 0.0506
-- Starting training on experience 199 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3651
	data_grads_norm = 5.0472
	new_data_grads_norm = 6.8021
	old_data_grads_norm = 6.3802
	sim_grads_norm_tr = 0.0760
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0476
	data_grads_norm = 4.4293
	new_data_grads_norm = 6.7557
	old_data_grads_norm = 5.7692
	sim_grads_norm_tr = 0.1110
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1137
	data_grads_norm = 4.3329
	new_data_grads_norm = 6.1816
	old_data_grads_norm = 5.9033
	sim_grads_norm_tr = 0.0884
-- Starting training on experience 200 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0531
	data_grads_norm = 4.7638
	new_data_grads_norm = 6.6177
	old_data_grads_norm = 6.1857
	sim_grads_norm_tr = -0.0157
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3729
	data_grads_norm = 5.2417
	new_data_grads_norm = 7.3427
	old_data_grads_norm = 6.7364
	sim_grads_norm_tr = 0.1370
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4032
	data_grads_norm = 5.6778
	new_data_grads_norm = 6.4597
	old_data_grads_norm = 8.2388
	sim_grads_norm_tr = 0.0401
-- Starting training on experience 201 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3166
	data_grads_norm = 4.6011
	new_data_grads_norm = 6.0548
	old_data_grads_norm = 6.7982
	sim_grads_norm_tr = 0.0156
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1947
	data_grads_norm = 4.1035
	new_data_grads_norm = 5.7530
	old_data_grads_norm = 5.7242
	sim_grads_norm_tr = -0.0078
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6127
	data_grads_norm = 4.0874
	new_data_grads_norm = 5.1956
	old_data_grads_norm = 6.6560
	sim_grads_norm_tr = 0.0657
-- Starting training on experience 202 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5384
	data_grads_norm = 4.0157
	new_data_grads_norm = 6.1200
	old_data_grads_norm = 5.1773
	sim_grads_norm_tr = 0.0386
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4343
	data_grads_norm = 3.5418
	new_data_grads_norm = 5.3766
	old_data_grads_norm = 4.8341
	sim_grads_norm_tr = -0.0242
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8151
	data_grads_norm = 4.2955
	new_data_grads_norm = 6.1461
	old_data_grads_norm = 5.8233
	sim_grads_norm_tr = 0.0325
-- Starting training on experience 203 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1899
	data_grads_norm = 4.0679
	new_data_grads_norm = 6.1265
	old_data_grads_norm = 5.0347
	sim_grads_norm_tr = 0.1047
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3327
	data_grads_norm = 4.6805
	new_data_grads_norm = 6.5031
	old_data_grads_norm = 6.6912
	sim_grads_norm_tr = -0.0121
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0811
	data_grads_norm = 4.0966
	new_data_grads_norm = 6.3711
	old_data_grads_norm = 4.9789
	sim_grads_norm_tr = 0.0215
-- Starting training on experience 204 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7983
	data_grads_norm = 4.4796
	new_data_grads_norm = 6.8195
	old_data_grads_norm = 6.2265
	sim_grads_norm_tr = 0.0198
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0295
	data_grads_norm = 4.3670
	new_data_grads_norm = 7.2307
	old_data_grads_norm = 5.3507
	sim_grads_norm_tr = -0.0057
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3216
	data_grads_norm = 5.2123
	new_data_grads_norm = 7.3768
	old_data_grads_norm = 6.3511
	sim_grads_norm_tr = 0.0411
-- Starting training on experience 205 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9323
	data_grads_norm = 3.7145
	new_data_grads_norm = 5.7796
	old_data_grads_norm = 5.0962
	sim_grads_norm_tr = 0.0049
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1960
	data_grads_norm = 4.4116
	new_data_grads_norm = 5.5525
	old_data_grads_norm = 5.8392
	sim_grads_norm_tr = 0.0918
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3945
	data_grads_norm = 4.7148
	new_data_grads_norm = 6.2981
	old_data_grads_norm = 6.0105
	sim_grads_norm_tr = 0.0494
-- Starting training on experience 206 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9563
	data_grads_norm = 4.3624
	new_data_grads_norm = 5.5533
	old_data_grads_norm = 6.7215
	sim_grads_norm_tr = -0.0589
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8762
	data_grads_norm = 3.8363
	new_data_grads_norm = 6.1979
	old_data_grads_norm = 4.6690
	sim_grads_norm_tr = -0.0515
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0799
	data_grads_norm = 4.3930
	new_data_grads_norm = 6.6454
	old_data_grads_norm = 4.4186
	sim_grads_norm_tr = 0.1998
-- Starting training on experience 207 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4066
	data_grads_norm = 4.4308
	new_data_grads_norm = 7.3934
	old_data_grads_norm = 5.0297
	sim_grads_norm_tr = 0.0147
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2548
	data_grads_norm = 4.7101
	new_data_grads_norm = 7.3296
	old_data_grads_norm = 5.7162
	sim_grads_norm_tr = -0.0307
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4958
	data_grads_norm = 4.7390
	new_data_grads_norm = 7.5318
	old_data_grads_norm = 5.6258
	sim_grads_norm_tr = 0.0436
-- Starting training on experience 208 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1073
	data_grads_norm = 4.4905
	new_data_grads_norm = 7.4535
	old_data_grads_norm = 5.2839
	sim_grads_norm_tr = 0.0276
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3335
	data_grads_norm = 4.2010
	new_data_grads_norm = 6.4857
	old_data_grads_norm = 4.7572
	sim_grads_norm_tr = 0.0250
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0254
	data_grads_norm = 4.1533
	new_data_grads_norm = 6.3746
	old_data_grads_norm = 5.3306
	sim_grads_norm_tr = 0.0205
-- Starting training on experience 209 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5122
	data_grads_norm = 4.6349
	new_data_grads_norm = 6.9856
	old_data_grads_norm = 5.6885
	sim_grads_norm_tr = 0.1098
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4662
	data_grads_norm = 4.8210
	new_data_grads_norm = 6.2111
	old_data_grads_norm = 6.4991
	sim_grads_norm_tr = -0.0477
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4425
	data_grads_norm = 4.0423
	new_data_grads_norm = 6.1767
	old_data_grads_norm = 4.4993
	sim_grads_norm_tr = 0.0530
-- Starting training on experience 210 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8456
	data_grads_norm = 5.0689
	new_data_grads_norm = 6.7352
	old_data_grads_norm = 7.5705
	sim_grads_norm_tr = 0.0279
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1279
	data_grads_norm = 4.5598
	new_data_grads_norm = 7.0380
	old_data_grads_norm = 4.2843
	sim_grads_norm_tr = 0.0280
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2379
	data_grads_norm = 4.7542
	new_data_grads_norm = 6.8524
	old_data_grads_norm = 5.7792
	sim_grads_norm_tr = 0.0354
-- Starting training on experience 211 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4287
	data_grads_norm = 4.6276
	new_data_grads_norm = 6.1932
	old_data_grads_norm = 6.7007
	sim_grads_norm_tr = 0.0087
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3271
	data_grads_norm = 4.7380
	new_data_grads_norm = 6.3822
	old_data_grads_norm = 5.7181
	sim_grads_norm_tr = 0.0246
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3519
	data_grads_norm = 4.3759
	new_data_grads_norm = 6.4924
	old_data_grads_norm = 5.7815
	sim_grads_norm_tr = -0.0388
-- Starting training on experience 212 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6116
	data_grads_norm = 4.6094
	new_data_grads_norm = 6.2415
	old_data_grads_norm = 5.7554
	sim_grads_norm_tr = 0.0604
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4229
	data_grads_norm = 4.5213
	new_data_grads_norm = 6.2021
	old_data_grads_norm = 5.1757
	sim_grads_norm_tr = 0.0417
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3268
	data_grads_norm = 4.6184
	new_data_grads_norm = 6.4255
	old_data_grads_norm = 6.1664
	sim_grads_norm_tr = 0.0105
-- Starting training on experience 213 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6590
	data_grads_norm = 4.0943
	new_data_grads_norm = 5.8960
	old_data_grads_norm = 5.1763
	sim_grads_norm_tr = -0.0537
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7392
	data_grads_norm = 4.6538
	new_data_grads_norm = 6.6756
	old_data_grads_norm = 5.1760
	sim_grads_norm_tr = 0.0007
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5373
	data_grads_norm = 4.8492
	new_data_grads_norm = 6.7077
	old_data_grads_norm = 5.8022
	sim_grads_norm_tr = 0.0226
-- Starting training on experience 214 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7294
	data_grads_norm = 5.2338
	new_data_grads_norm = 6.1196
	old_data_grads_norm = 7.4899
	sim_grads_norm_tr = 0.0288
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9699
	data_grads_norm = 5.0599
	new_data_grads_norm = 6.5579
	old_data_grads_norm = 6.6122
	sim_grads_norm_tr = 0.1064
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8064
	data_grads_norm = 3.7912
	new_data_grads_norm = 6.0602
	old_data_grads_norm = 4.8852
	sim_grads_norm_tr = -0.0058
-- Starting training on experience 215 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9756
	data_grads_norm = 3.9286
	new_data_grads_norm = 5.6983
	old_data_grads_norm = 4.9587
	sim_grads_norm_tr = 0.0529
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6398
	data_grads_norm = 3.7858
	new_data_grads_norm = 6.4384
	old_data_grads_norm = 4.5107
	sim_grads_norm_tr = 0.0774
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6544
	data_grads_norm = 3.4667
	new_data_grads_norm = 5.8016
	old_data_grads_norm = 5.1672
	sim_grads_norm_tr = -0.0808
-- Starting training on experience 216 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9577
	data_grads_norm = 4.5078
	new_data_grads_norm = 5.9706
	old_data_grads_norm = 6.2458
	sim_grads_norm_tr = 0.0800
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9908
	data_grads_norm = 4.3809
	new_data_grads_norm = 5.9306
	old_data_grads_norm = 5.8403
	sim_grads_norm_tr = -0.0172
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3975
	data_grads_norm = 5.3554
	new_data_grads_norm = 6.7123
	old_data_grads_norm = 7.8887
	sim_grads_norm_tr = -0.0444
-- Starting training on experience 217 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3762
	data_grads_norm = 5.5803
	new_data_grads_norm = 7.0325
	old_data_grads_norm = 7.5905
	sim_grads_norm_tr = 0.0245
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0107
	data_grads_norm = 4.0423
	new_data_grads_norm = 6.3284
	old_data_grads_norm = 4.6747
	sim_grads_norm_tr = 0.0637
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8163
	data_grads_norm = 3.3720
	new_data_grads_norm = 6.0171
	old_data_grads_norm = 3.6784
	sim_grads_norm_tr = 0.0051
-- Starting training on experience 218 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0063
	data_grads_norm = 4.0125
	new_data_grads_norm = 6.2336
	old_data_grads_norm = 4.5486
	sim_grads_norm_tr = 0.1342
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1769
	data_grads_norm = 4.3110
	new_data_grads_norm = 5.8640
	old_data_grads_norm = 6.9026
	sim_grads_norm_tr = -0.0431
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3211
	data_grads_norm = 4.5848
	new_data_grads_norm = 6.3334
	old_data_grads_norm = 6.3138
	sim_grads_norm_tr = 0.0161
-- Starting training on experience 219 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4510
	data_grads_norm = 4.8291
	new_data_grads_norm = 5.8983
	old_data_grads_norm = 6.4935
	sim_grads_norm_tr = -0.0278
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2107
	data_grads_norm = 4.3816
	new_data_grads_norm = 6.4239
	old_data_grads_norm = 5.5184
	sim_grads_norm_tr = 0.0541
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3825
	data_grads_norm = 4.2398
	new_data_grads_norm = 6.3319
	old_data_grads_norm = 4.7159
	sim_grads_norm_tr = 0.0356
-- Starting training on experience 220 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0723
	data_grads_norm = 4.3713
	new_data_grads_norm = 6.6261
	old_data_grads_norm = 5.1392
	sim_grads_norm_tr = -0.0158
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8513
	data_grads_norm = 4.3485
	new_data_grads_norm = 7.9239
	old_data_grads_norm = 5.2645
	sim_grads_norm_tr = 0.0297
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1159
	data_grads_norm = 4.9265
	new_data_grads_norm = 7.0203
	old_data_grads_norm = 6.7364
	sim_grads_norm_tr = 0.1121
-- Starting training on experience 221 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8878
	data_grads_norm = 3.6227
	new_data_grads_norm = 6.4699
	old_data_grads_norm = 5.0178
	sim_grads_norm_tr = -0.0499
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3143
	data_grads_norm = 4.5476
	new_data_grads_norm = 6.3609
	old_data_grads_norm = 5.8213
	sim_grads_norm_tr = 0.0366
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1489
	data_grads_norm = 4.2770
	new_data_grads_norm = 6.1736
	old_data_grads_norm = 5.6986
	sim_grads_norm_tr = -0.0877
-- Starting training on experience 222 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8484
	data_grads_norm = 3.9300
	new_data_grads_norm = 6.1593
	old_data_grads_norm = 4.8540
	sim_grads_norm_tr = -0.0112
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1619
	data_grads_norm = 4.8473
	new_data_grads_norm = 7.8275
	old_data_grads_norm = 5.2960
	sim_grads_norm_tr = -0.0769
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9473
	data_grads_norm = 4.5760
	new_data_grads_norm = 7.0525
	old_data_grads_norm = 4.8873
	sim_grads_norm_tr = 0.1363
-- Starting training on experience 223 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9302
	data_grads_norm = 3.5485
	new_data_grads_norm = 5.8395
	old_data_grads_norm = 4.4089
	sim_grads_norm_tr = 0.0154
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5001
	data_grads_norm = 4.6983
	new_data_grads_norm = 5.7934
	old_data_grads_norm = 6.8996
	sim_grads_norm_tr = -0.0457
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3461
	data_grads_norm = 4.2115
	new_data_grads_norm = 6.1384
	old_data_grads_norm = 4.6324
	sim_grads_norm_tr = 0.0513
-- Starting training on experience 224 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8162
	data_grads_norm = 4.0527
	new_data_grads_norm = 6.3912
	old_data_grads_norm = 5.1312
	sim_grads_norm_tr = -0.0101
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5700
	data_grads_norm = 4.3852
	new_data_grads_norm = 6.1569
	old_data_grads_norm = 5.9776
	sim_grads_norm_tr = 0.0292
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9514
	data_grads_norm = 3.7773
	new_data_grads_norm = 6.1865
	old_data_grads_norm = 4.0664
	sim_grads_norm_tr = 0.0202
-- Starting training on experience 225 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1506
	data_grads_norm = 4.4674
	new_data_grads_norm = 6.8288
	old_data_grads_norm = 6.0239
	sim_grads_norm_tr = -0.0529
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6453
	data_grads_norm = 5.5278
	new_data_grads_norm = 6.9900
	old_data_grads_norm = 8.8221
	sim_grads_norm_tr = 0.0170
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8472
	data_grads_norm = 4.8987
	new_data_grads_norm = 7.6463
	old_data_grads_norm = 6.6529
	sim_grads_norm_tr = 0.0566
-- Starting training on experience 226 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2457
	data_grads_norm = 5.0335
	new_data_grads_norm = 6.7739
	old_data_grads_norm = 6.6966
	sim_grads_norm_tr = 0.0893
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7937
	data_grads_norm = 4.6193
	new_data_grads_norm = 6.4365
	old_data_grads_norm = 5.5463
	sim_grads_norm_tr = 0.1105
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0297
	data_grads_norm = 4.4102
	new_data_grads_norm = 6.1675
	old_data_grads_norm = 5.4057
	sim_grads_norm_tr = 0.0605
-- Starting training on experience 227 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5989
	data_grads_norm = 3.4082
	new_data_grads_norm = 6.2670
	old_data_grads_norm = 3.8892
	sim_grads_norm_tr = 0.0096
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0590
	data_grads_norm = 3.9120
	new_data_grads_norm = 6.4262
	old_data_grads_norm = 4.9149
	sim_grads_norm_tr = -0.0431
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2836
	data_grads_norm = 4.6461
	new_data_grads_norm = 6.6672
	old_data_grads_norm = 5.8373
	sim_grads_norm_tr = 0.0331
-- Starting training on experience 228 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1012
	data_grads_norm = 5.2679
	new_data_grads_norm = 7.1752
	old_data_grads_norm = 6.1098
	sim_grads_norm_tr = 0.0207
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9260
	data_grads_norm = 4.7890
	new_data_grads_norm = 6.5404
	old_data_grads_norm = 5.8666
	sim_grads_norm_tr = -0.0233
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9054
	data_grads_norm = 4.6900
	new_data_grads_norm = 5.8531
	old_data_grads_norm = 5.7046
	sim_grads_norm_tr = 0.0160
-- Starting training on experience 229 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2063
	data_grads_norm = 4.8594
	new_data_grads_norm = 6.7542
	old_data_grads_norm = 7.0231
	sim_grads_norm_tr = -0.0553
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1640
	data_grads_norm = 4.8066
	new_data_grads_norm = 7.2089
	old_data_grads_norm = 6.2733
	sim_grads_norm_tr = 0.0569
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4201
	data_grads_norm = 4.5367
	new_data_grads_norm = 7.0610
	old_data_grads_norm = 6.3331
	sim_grads_norm_tr = -0.0537
-- Starting training on experience 230 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7739
	data_grads_norm = 4.7395
	new_data_grads_norm = 5.9099
	old_data_grads_norm = 6.8605
	sim_grads_norm_tr = -0.0209
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4316
	data_grads_norm = 4.4085
	new_data_grads_norm = 6.3117
	old_data_grads_norm = 6.1992
	sim_grads_norm_tr = -0.0573
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0188
	data_grads_norm = 4.1935
	new_data_grads_norm = 6.0226
	old_data_grads_norm = 5.4771
	sim_grads_norm_tr = 0.0536
-- Starting training on experience 231 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0548
	data_grads_norm = 4.3933
	new_data_grads_norm = 5.8916
	old_data_grads_norm = 5.2564
	sim_grads_norm_tr = 0.0690
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0372
	data_grads_norm = 4.0122
	new_data_grads_norm = 6.2833
	old_data_grads_norm = 4.7797
	sim_grads_norm_tr = 0.0116
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2349
	data_grads_norm = 4.6603
	new_data_grads_norm = 5.6117
	old_data_grads_norm = 7.0979
	sim_grads_norm_tr = 0.0224
-- Starting training on experience 232 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7582
	data_grads_norm = 4.4702
	new_data_grads_norm = 5.6473
	old_data_grads_norm = 7.5237
	sim_grads_norm_tr = -0.0169
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0008
	data_grads_norm = 5.0484
	new_data_grads_norm = 6.0246
	old_data_grads_norm = 7.0025
	sim_grads_norm_tr = 0.0803
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0600
	data_grads_norm = 4.3944
	new_data_grads_norm = 6.2301
	old_data_grads_norm = 5.9999
	sim_grads_norm_tr = 0.0732
-- Starting training on experience 233 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5042
	data_grads_norm = 4.6710
	new_data_grads_norm = 7.0243
	old_data_grads_norm = 5.8110
	sim_grads_norm_tr = 0.0827
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6740
	data_grads_norm = 5.1594
	new_data_grads_norm = 7.3844
	old_data_grads_norm = 6.6420
	sim_grads_norm_tr = -0.0418
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2245
	data_grads_norm = 4.6629
	new_data_grads_norm = 7.1516
	old_data_grads_norm = 5.5772
	sim_grads_norm_tr = -0.0460
-- Starting training on experience 234 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6383
	data_grads_norm = 4.2541
	new_data_grads_norm = 6.4327
	old_data_grads_norm = 5.1240
	sim_grads_norm_tr = 0.0848
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0581
	data_grads_norm = 4.4434
	new_data_grads_norm = 6.0871
	old_data_grads_norm = 6.7326
	sim_grads_norm_tr = -0.0107
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2384
	data_grads_norm = 4.6029
	new_data_grads_norm = 6.5208
	old_data_grads_norm = 6.7917
	sim_grads_norm_tr = 0.0049
-- Starting training on experience 235 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8450
	data_grads_norm = 4.2396
	new_data_grads_norm = 6.5098
	old_data_grads_norm = 5.1123
	sim_grads_norm_tr = -0.0275
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9235
	data_grads_norm = 4.2181
	new_data_grads_norm = 6.6621
	old_data_grads_norm = 5.8043
	sim_grads_norm_tr = 0.0039
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2845
	data_grads_norm = 4.4089
	new_data_grads_norm = 6.2998
	old_data_grads_norm = 5.4502
	sim_grads_norm_tr = 0.0112
-- Starting training on experience 236 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5438
	data_grads_norm = 4.6498
	new_data_grads_norm = 5.9129
	old_data_grads_norm = 6.2527
	sim_grads_norm_tr = 0.0156
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9676
	data_grads_norm = 4.2142
	new_data_grads_norm = 6.7320
	old_data_grads_norm = 5.0659
	sim_grads_norm_tr = 0.0088
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1110
	data_grads_norm = 4.6143
	new_data_grads_norm = 5.9832
	old_data_grads_norm = 5.7503
	sim_grads_norm_tr = 0.0904
-- Starting training on experience 237 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
-- >> End of training phase << --
-- >> Start of eval phase << --
-- Starting eval on experience 0 (Task 0) from test stream --
> Eval on experience 0 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp000 = 2.5364
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.3380
	mb_index = 1666
	time = 419.9611
-- Starting eval on experience 1 (Task 0) from test stream --
> Eval on experience 1 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp001 = 2.1229
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.4520
-- Starting eval on experience 2 (Task 0) from test stream --
> Eval on experience 2 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp002 = 2.2930
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.3560
-- Starting eval on experience 3 (Task 0) from test stream --
> Eval on experience 3 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp003 = 1.8753
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.5020
-- Starting eval on experience 4 (Task 0) from test stream --
> Eval on experience 4 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp004 = 2.4045
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.3640
-- Starting eval on experience 5 (Task 0) from test stream --
> Eval on experience 5 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp005 = 2.4394
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.2960
-- Starting eval on experience 6 (Task 0) from test stream --
> Eval on experience 6 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp006 = 2.2610
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp006 = 0.3240
-- >> End of eval phase << --
	CumulativeAccuracy/eval_phase/test_stream/Exp000 = 0.7200
	CumulativeAccuracy/eval_phase/test_stream/Exp001 = 0.6430
	CumulativeAccuracy/eval_phase/test_stream/Exp002 = 0.5333
	CumulativeAccuracy/eval_phase/test_stream/Exp003 = 0.4945
	CumulativeAccuracy/eval_phase/test_stream/Exp004 = 0.4464
	CumulativeAccuracy/eval_phase/test_stream/Exp005 = 0.4090
	CumulativeAccuracy/eval_phase/test_stream/Exp006 = 0.3760
	Loss_Stream/eval_phase/test_stream/Task000 = 2.2761
	Top1_Acc_Stream/eval_phase/test_stream/Task000 = 0.3760
-- >> Start of training phase << --
-- Starting training on experience 0 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7738
	data_grads_norm = 4.7989
	new_data_grads_norm = 7.0754
	old_data_grads_norm = 6.3451
	sim_grads_norm_tr = -0.0140
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1303
	data_grads_norm = 4.3691
	new_data_grads_norm = 6.7270
	old_data_grads_norm = 5.6040
	sim_grads_norm_tr = 0.0264
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9911
	data_grads_norm = 4.8887
	new_data_grads_norm = 7.2221
	old_data_grads_norm = 6.2732
	sim_grads_norm_tr = -0.0119
-- Starting training on experience 1 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6530
	data_grads_norm = 4.4374
	new_data_grads_norm = 6.2768
	old_data_grads_norm = 5.4286
	sim_grads_norm_tr = -0.0133
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7732
	data_grads_norm = 4.2349
	new_data_grads_norm = 6.3002
	old_data_grads_norm = 4.8894
	sim_grads_norm_tr = 0.0045
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1199
	data_grads_norm = 4.3507
	new_data_grads_norm = 6.1148
	old_data_grads_norm = 5.5526
	sim_grads_norm_tr = 0.0136
-- Starting training on experience 2 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0955
	data_grads_norm = 4.4489
	new_data_grads_norm = 6.1165
	old_data_grads_norm = 5.6054
	sim_grads_norm_tr = 0.0616
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5820
	data_grads_norm = 4.4392
	new_data_grads_norm = 6.4146
	old_data_grads_norm = 4.7701
	sim_grads_norm_tr = 0.0291
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0206
	data_grads_norm = 4.5708
	new_data_grads_norm = 6.9587
	old_data_grads_norm = 7.5715
	sim_grads_norm_tr = -0.0070
-- Starting training on experience 3 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0462
	data_grads_norm = 4.6322
	new_data_grads_norm = 6.1178
	old_data_grads_norm = 6.2023
	sim_grads_norm_tr = -0.0200
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9191
	data_grads_norm = 4.2375
	new_data_grads_norm = 6.2814
	old_data_grads_norm = 5.1262
	sim_grads_norm_tr = -0.0160
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0311
	data_grads_norm = 4.6337
	new_data_grads_norm = 6.7234
	old_data_grads_norm = 6.7468
	sim_grads_norm_tr = -0.0334
-- Starting training on experience 4 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0420
	data_grads_norm = 4.6473
	new_data_grads_norm = 6.9562
	old_data_grads_norm = 5.6867
	sim_grads_norm_tr = 0.0147
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1708
	data_grads_norm = 4.8827
	new_data_grads_norm = 5.9071
	old_data_grads_norm = 7.5768
	sim_grads_norm_tr = 0.0252
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8453
	data_grads_norm = 4.4186
	new_data_grads_norm = 6.0981
	old_data_grads_norm = 5.3050
	sim_grads_norm_tr = 0.0222
-- Starting training on experience 5 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2604
	data_grads_norm = 4.1283
	new_data_grads_norm = 7.0462
	old_data_grads_norm = 4.4049
	sim_grads_norm_tr = 0.0242
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0473
	data_grads_norm = 5.3306
	new_data_grads_norm = 7.2396
	old_data_grads_norm = 6.7946
	sim_grads_norm_tr = 0.0402
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6454
	data_grads_norm = 4.1429
	new_data_grads_norm = 6.3771
	old_data_grads_norm = 5.3351
	sim_grads_norm_tr = -0.0109
-- Starting training on experience 6 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4607
	data_grads_norm = 4.3352
	new_data_grads_norm = 6.2573
	old_data_grads_norm = 5.5774
	sim_grads_norm_tr = -0.0169
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4189
	data_grads_norm = 4.5441
	new_data_grads_norm = 6.5596
	old_data_grads_norm = 4.1673
	sim_grads_norm_tr = 0.0934
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5704
	data_grads_norm = 4.7614
	new_data_grads_norm = 6.2578
	old_data_grads_norm = 6.5064
	sim_grads_norm_tr = 0.0290
-- Starting training on experience 7 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0552
	data_grads_norm = 5.1563
	new_data_grads_norm = 7.7302
	old_data_grads_norm = 5.5619
	sim_grads_norm_tr = 0.0115
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0398
	data_grads_norm = 4.6164
	new_data_grads_norm = 7.1390
	old_data_grads_norm = 5.3603
	sim_grads_norm_tr = 0.0871
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9140
	data_grads_norm = 4.6733
	new_data_grads_norm = 6.9955
	old_data_grads_norm = 4.8254
	sim_grads_norm_tr = -0.0124
-- Starting training on experience 8 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1676
	data_grads_norm = 4.9125
	new_data_grads_norm = 6.5733
	old_data_grads_norm = 5.5966
	sim_grads_norm_tr = 0.0128
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2600
	data_grads_norm = 5.0682
	new_data_grads_norm = 6.3038
	old_data_grads_norm = 6.7817
	sim_grads_norm_tr = 0.0258
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3697
	data_grads_norm = 5.0738
	new_data_grads_norm = 6.5109
	old_data_grads_norm = 6.5354
	sim_grads_norm_tr = 0.0310
-- Starting training on experience 9 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9083
	data_grads_norm = 4.3584
	new_data_grads_norm = 6.5648
	old_data_grads_norm = 5.0516
	sim_grads_norm_tr = 0.0203
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9517
	data_grads_norm = 4.6068
	new_data_grads_norm = 6.5052
	old_data_grads_norm = 5.8632
	sim_grads_norm_tr = 0.0180
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5933
	data_grads_norm = 4.4117
	new_data_grads_norm = 6.1001
	old_data_grads_norm = 6.0707
	sim_grads_norm_tr = 0.0136
-- Starting training on experience 10 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7519
	data_grads_norm = 5.1610
	new_data_grads_norm = 7.0763
	old_data_grads_norm = 6.1350
	sim_grads_norm_tr = 0.0434
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4181
	data_grads_norm = 4.4275
	new_data_grads_norm = 6.9396
	old_data_grads_norm = 5.4092
	sim_grads_norm_tr = -0.0336
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8393
	data_grads_norm = 4.5990
	new_data_grads_norm = 7.7120
	old_data_grads_norm = 4.2807
	sim_grads_norm_tr = 0.0450
-- Starting training on experience 11 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2563
	data_grads_norm = 4.7007
	new_data_grads_norm = 6.2453
	old_data_grads_norm = 6.5638
	sim_grads_norm_tr = -0.0174
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3450
	data_grads_norm = 4.8062
	new_data_grads_norm = 6.5037
	old_data_grads_norm = 6.4456
	sim_grads_norm_tr = -0.0177
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.7919
	data_grads_norm = 4.9177
	new_data_grads_norm = 6.2500
	old_data_grads_norm = 6.8642
	sim_grads_norm_tr = 0.1426
-- Starting training on experience 12 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9784
	data_grads_norm = 5.1851
	new_data_grads_norm = 7.7847
	old_data_grads_norm = 5.4869
	sim_grads_norm_tr = 0.0283
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6451
	data_grads_norm = 4.4148
	new_data_grads_norm = 6.5755
	old_data_grads_norm = 4.5088
	sim_grads_norm_tr = 0.0301
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0608
	data_grads_norm = 5.4467
	new_data_grads_norm = 7.3156
	old_data_grads_norm = 7.2204
	sim_grads_norm_tr = 0.0260
-- Starting training on experience 13 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1583
	data_grads_norm = 5.1385
	new_data_grads_norm = 6.3891
	old_data_grads_norm = 7.3742
	sim_grads_norm_tr = -0.0122
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0290
	data_grads_norm = 4.9774
	new_data_grads_norm = 6.6380
	old_data_grads_norm = 6.2476
	sim_grads_norm_tr = 0.0555
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6083
	data_grads_norm = 4.2678
	new_data_grads_norm = 6.1203
	old_data_grads_norm = 5.5258
	sim_grads_norm_tr = 0.0195
-- Starting training on experience 14 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8776
	data_grads_norm = 5.3088
	new_data_grads_norm = 6.9652
	old_data_grads_norm = 7.2425
	sim_grads_norm_tr = 0.0298
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1549
	data_grads_norm = 5.1808
	new_data_grads_norm = 7.1438
	old_data_grads_norm = 6.6886
	sim_grads_norm_tr = -0.0590
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6391
	data_grads_norm = 4.7088
	new_data_grads_norm = 6.9415
	old_data_grads_norm = 4.8871
	sim_grads_norm_tr = 0.0224
-- Starting training on experience 15 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6821
	data_grads_norm = 4.5674
	new_data_grads_norm = 6.2068
	old_data_grads_norm = 5.9648
	sim_grads_norm_tr = 0.0207
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0487
	data_grads_norm = 4.9355
	new_data_grads_norm = 6.4220
	old_data_grads_norm = 6.9144
	sim_grads_norm_tr = 0.0456
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3682
	data_grads_norm = 4.4697
	new_data_grads_norm = 6.2776
	old_data_grads_norm = 5.3538
	sim_grads_norm_tr = 0.0574
-- Starting training on experience 16 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8017
	data_grads_norm = 4.6046
	new_data_grads_norm = 5.9938
	old_data_grads_norm = 6.0397
	sim_grads_norm_tr = -0.0337
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7927
	data_grads_norm = 4.4530
	new_data_grads_norm = 6.5082
	old_data_grads_norm = 4.8006
	sim_grads_norm_tr = 0.1549
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3664
	data_grads_norm = 4.6094
	new_data_grads_norm = 6.1937
	old_data_grads_norm = 5.9028
	sim_grads_norm_tr = 0.0493
-- Starting training on experience 17 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1276
	data_grads_norm = 4.9977
	new_data_grads_norm = 7.1540
	old_data_grads_norm = 6.1240
	sim_grads_norm_tr = 0.1276
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7688
	data_grads_norm = 5.3305
	new_data_grads_norm = 6.9487
	old_data_grads_norm = 6.4228
	sim_grads_norm_tr = 0.0548
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8524
	data_grads_norm = 4.8105
	new_data_grads_norm = 6.6283
	old_data_grads_norm = 5.3720
	sim_grads_norm_tr = 0.0177
-- Starting training on experience 18 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3037
	data_grads_norm = 4.4807
	new_data_grads_norm = 6.1916
	old_data_grads_norm = 6.4477
	sim_grads_norm_tr = -0.0023
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4395
	data_grads_norm = 4.3402
	new_data_grads_norm = 6.8111
	old_data_grads_norm = 5.4965
	sim_grads_norm_tr = -0.0763
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4592
	data_grads_norm = 4.4027
	new_data_grads_norm = 6.5680
	old_data_grads_norm = 4.7427
	sim_grads_norm_tr = -0.0014
-- Starting training on experience 19 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2769
	data_grads_norm = 4.3199
	new_data_grads_norm = 5.3161
	old_data_grads_norm = 6.1936
	sim_grads_norm_tr = -0.0248
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1971
	data_grads_norm = 4.2705
	new_data_grads_norm = 5.4837
	old_data_grads_norm = 6.2524
	sim_grads_norm_tr = 0.0430
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5123
	data_grads_norm = 4.7083
	new_data_grads_norm = 6.1152
	old_data_grads_norm = 6.6332
	sim_grads_norm_tr = 0.0207
-- Starting training on experience 20 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6154
	data_grads_norm = 4.6778
	new_data_grads_norm = 6.8705
	old_data_grads_norm = 6.3760
	sim_grads_norm_tr = 0.0385
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8264
	data_grads_norm = 4.5506
	new_data_grads_norm = 6.7246
	old_data_grads_norm = 5.6575
	sim_grads_norm_tr = 0.0069
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8457
	data_grads_norm = 4.6065
	new_data_grads_norm = 7.0127
	old_data_grads_norm = 5.2448
	sim_grads_norm_tr = 0.0347
-- Starting training on experience 21 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7342
	data_grads_norm = 4.5579
	new_data_grads_norm = 5.4706
	old_data_grads_norm = 5.7235
	sim_grads_norm_tr = 0.0040
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1302
	data_grads_norm = 4.5530
	new_data_grads_norm = 5.7424
	old_data_grads_norm = 7.4196
	sim_grads_norm_tr = 0.0375
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4663
	data_grads_norm = 4.3915
	new_data_grads_norm = 6.1029
	old_data_grads_norm = 5.6501
	sim_grads_norm_tr = 0.0127
-- Starting training on experience 22 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0737
	data_grads_norm = 4.4687
	new_data_grads_norm = 5.0071
	old_data_grads_norm = 6.4158
	sim_grads_norm_tr = -0.0265
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1090
	data_grads_norm = 4.5328
	new_data_grads_norm = 5.3514
	old_data_grads_norm = 7.2231
	sim_grads_norm_tr = 0.0266
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4366
	data_grads_norm = 4.1816
	new_data_grads_norm = 5.6200
	old_data_grads_norm = 6.3634
	sim_grads_norm_tr = -0.0128
-- Starting training on experience 23 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0700
	data_grads_norm = 3.8746
	new_data_grads_norm = 5.6648
	old_data_grads_norm = 4.7632
	sim_grads_norm_tr = 0.0056
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8447
	data_grads_norm = 3.1661
	new_data_grads_norm = 5.5625
	old_data_grads_norm = 3.4001
	sim_grads_norm_tr = 0.0089
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0038
	data_grads_norm = 4.0572
	new_data_grads_norm = 5.6131
	old_data_grads_norm = 5.6405
	sim_grads_norm_tr = 0.0405
-- Starting training on experience 24 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8600
	data_grads_norm = 5.2153
	new_data_grads_norm = 7.4918
	old_data_grads_norm = 6.7148
	sim_grads_norm_tr = 0.0811
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1124
	data_grads_norm = 5.0055
	new_data_grads_norm = 6.5779
	old_data_grads_norm = 6.7908
	sim_grads_norm_tr = 0.1180
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0944
	data_grads_norm = 3.8510
	new_data_grads_norm = 6.4275
	old_data_grads_norm = 4.5504
	sim_grads_norm_tr = 0.0978
-- Starting training on experience 25 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3168
	data_grads_norm = 4.3701
	new_data_grads_norm = 6.1776
	old_data_grads_norm = 5.0176
	sim_grads_norm_tr = 0.1877
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6857
	data_grads_norm = 4.7305
	new_data_grads_norm = 5.8253
	old_data_grads_norm = 6.8733
	sim_grads_norm_tr = 0.1489
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6843
	data_grads_norm = 3.9706
	new_data_grads_norm = 5.4733
	old_data_grads_norm = 6.0417
	sim_grads_norm_tr = -0.0293
-- Starting training on experience 26 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9924
	data_grads_norm = 3.8961
	new_data_grads_norm = 6.4951
	old_data_grads_norm = 3.0655
	sim_grads_norm_tr = 0.1893
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9900
	data_grads_norm = 4.5729
	new_data_grads_norm = 6.4805
	old_data_grads_norm = 5.7809
	sim_grads_norm_tr = 0.0291
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6258
	data_grads_norm = 3.6870
	new_data_grads_norm = 6.2476
	old_data_grads_norm = 4.8725
	sim_grads_norm_tr = -0.0240
-- Starting training on experience 27 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5163
	data_grads_norm = 3.5694
	new_data_grads_norm = 5.3020
	old_data_grads_norm = 4.3270
	sim_grads_norm_tr = 0.1265
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5946
	data_grads_norm = 3.6655
	new_data_grads_norm = 5.0441
	old_data_grads_norm = 4.6194
	sim_grads_norm_tr = 0.1352
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5534
	data_grads_norm = 3.7641
	new_data_grads_norm = 5.2869
	old_data_grads_norm = 4.5829
	sim_grads_norm_tr = 0.0163
-- Starting training on experience 28 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9161
	data_grads_norm = 4.1969
	new_data_grads_norm = 5.3787
	old_data_grads_norm = 5.8628
	sim_grads_norm_tr = -0.0085
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6724
	data_grads_norm = 3.7254
	new_data_grads_norm = 5.5884
	old_data_grads_norm = 5.1730
	sim_grads_norm_tr = -0.0880
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5028
	data_grads_norm = 3.6465
	new_data_grads_norm = 5.9672
	old_data_grads_norm = 3.8947
	sim_grads_norm_tr = -0.0835
-- Starting training on experience 29 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4359
	data_grads_norm = 3.8473
	new_data_grads_norm = 6.0062
	old_data_grads_norm = 5.1823
	sim_grads_norm_tr = -0.0896
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6011
	data_grads_norm = 4.3792
	new_data_grads_norm = 6.4336
	old_data_grads_norm = 4.5965
	sim_grads_norm_tr = -0.0221
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6460
	data_grads_norm = 4.0485
	new_data_grads_norm = 6.1757
	old_data_grads_norm = 4.9672
	sim_grads_norm_tr = 0.0039
-- Starting training on experience 30 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6132
	data_grads_norm = 3.9902
	new_data_grads_norm = 6.1207
	old_data_grads_norm = 4.7982
	sim_grads_norm_tr = 0.0327
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9424
	data_grads_norm = 4.1748
	new_data_grads_norm = 6.2731
	old_data_grads_norm = 5.0270
	sim_grads_norm_tr = -0.0076
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2912
	data_grads_norm = 4.7438
	new_data_grads_norm = 6.1501
	old_data_grads_norm = 6.0963
	sim_grads_norm_tr = 0.0953
-- Starting training on experience 31 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8228
	data_grads_norm = 4.0238
	new_data_grads_norm = 5.8603
	old_data_grads_norm = 4.1393
	sim_grads_norm_tr = 0.1560
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7948
	data_grads_norm = 4.2716
	new_data_grads_norm = 5.6362
	old_data_grads_norm = 6.1257
	sim_grads_norm_tr = -0.0567
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9806
	data_grads_norm = 4.6702
	new_data_grads_norm = 5.7876
	old_data_grads_norm = 6.7722
	sim_grads_norm_tr = -0.0227
-- Starting training on experience 32 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7685
	data_grads_norm = 4.0692
	new_data_grads_norm = 5.4351
	old_data_grads_norm = 5.5201
	sim_grads_norm_tr = 0.0136
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9899
	data_grads_norm = 4.0297
	new_data_grads_norm = 5.8265
	old_data_grads_norm = 5.5476
	sim_grads_norm_tr = 0.0256
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9998
	data_grads_norm = 4.6048
	new_data_grads_norm = 6.3212
	old_data_grads_norm = 6.3920
	sim_grads_norm_tr = 0.0236
-- Starting training on experience 33 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4662
	data_grads_norm = 4.5099
	new_data_grads_norm = 4.8002
	old_data_grads_norm = 7.1367
	sim_grads_norm_tr = 0.0652
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4159
	data_grads_norm = 3.6503
	new_data_grads_norm = 5.5527
	old_data_grads_norm = 5.0875
	sim_grads_norm_tr = -0.0418
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9273
	data_grads_norm = 4.6153
	new_data_grads_norm = 5.5274
	old_data_grads_norm = 6.6950
	sim_grads_norm_tr = 0.0654
-- Starting training on experience 34 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7788
	data_grads_norm = 4.2291
	new_data_grads_norm = 5.9832
	old_data_grads_norm = 6.1861
	sim_grads_norm_tr = 0.0023
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3092
	data_grads_norm = 3.7208
	new_data_grads_norm = 6.0445
	old_data_grads_norm = 4.8664
	sim_grads_norm_tr = -0.0803
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6207
	data_grads_norm = 4.3318
	new_data_grads_norm = 5.8328
	old_data_grads_norm = 5.6105
	sim_grads_norm_tr = -0.0141
-- Starting training on experience 35 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5355
	data_grads_norm = 4.1891
	new_data_grads_norm = 6.3185
	old_data_grads_norm = 5.2764
	sim_grads_norm_tr = 0.0348
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2846
	data_grads_norm = 4.1365
	new_data_grads_norm = 6.4347
	old_data_grads_norm = 4.8390
	sim_grads_norm_tr = 0.0494
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6873
	data_grads_norm = 4.4157
	new_data_grads_norm = 5.8436
	old_data_grads_norm = 6.0365
	sim_grads_norm_tr = 0.0016
-- Starting training on experience 36 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3726
	data_grads_norm = 3.8631
	new_data_grads_norm = 5.6927
	old_data_grads_norm = 6.1699
	sim_grads_norm_tr = -0.0221
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1824
	data_grads_norm = 3.5916
	new_data_grads_norm = 5.6174
	old_data_grads_norm = 5.0189
	sim_grads_norm_tr = -0.0405
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9232
	data_grads_norm = 4.3788
	new_data_grads_norm = 6.2079
	old_data_grads_norm = 5.2336
	sim_grads_norm_tr = 0.1455
-- Starting training on experience 37 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3663
	data_grads_norm = 4.0047
	new_data_grads_norm = 6.0439
	old_data_grads_norm = 5.3209
	sim_grads_norm_tr = 0.0118
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6803
	data_grads_norm = 4.1651
	new_data_grads_norm = 6.3810
	old_data_grads_norm = 6.4952
	sim_grads_norm_tr = -0.0007
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6015
	data_grads_norm = 4.6860
	new_data_grads_norm = 7.4020
	old_data_grads_norm = 5.0565
	sim_grads_norm_tr = -0.0236
-- Starting training on experience 38 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0500
	data_grads_norm = 4.4500
	new_data_grads_norm = 5.4604
	old_data_grads_norm = 6.1306
	sim_grads_norm_tr = 0.0832
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0143
	data_grads_norm = 4.1602
	new_data_grads_norm = 5.4311
	old_data_grads_norm = 5.0940
	sim_grads_norm_tr = 0.1135
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5931
	data_grads_norm = 3.7346
	new_data_grads_norm = 5.4644
	old_data_grads_norm = 4.3865
	sim_grads_norm_tr = -0.0143
-- Starting training on experience 39 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4268
	data_grads_norm = 4.2559
	new_data_grads_norm = 5.7974
	old_data_grads_norm = 6.0476
	sim_grads_norm_tr = -0.0230
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5290
	data_grads_norm = 4.9214
	new_data_grads_norm = 5.8707
	old_data_grads_norm = 6.2266
	sim_grads_norm_tr = 0.0116
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4532
	data_grads_norm = 3.7997
	new_data_grads_norm = 5.7576
	old_data_grads_norm = 4.7954
	sim_grads_norm_tr = -0.0282
-- Starting training on experience 40 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6176
	data_grads_norm = 4.1908
	new_data_grads_norm = 6.8184
	old_data_grads_norm = 6.7823
	sim_grads_norm_tr = -0.0194
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6802
	data_grads_norm = 4.1905
	new_data_grads_norm = 6.8703
	old_data_grads_norm = 5.5576
	sim_grads_norm_tr = -0.0343
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8360
	data_grads_norm = 4.3792
	new_data_grads_norm = 7.0844
	old_data_grads_norm = 5.7279
	sim_grads_norm_tr = 0.0170
-- Starting training on experience 41 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1553
	data_grads_norm = 4.4531
	new_data_grads_norm = 6.0765
	old_data_grads_norm = 5.8394
	sim_grads_norm_tr = -0.0716
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4771
	data_grads_norm = 3.7144
	new_data_grads_norm = 6.3464
	old_data_grads_norm = 5.1416
	sim_grads_norm_tr = -0.1044
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3103
	data_grads_norm = 4.6492
	new_data_grads_norm = 6.4849
	old_data_grads_norm = 5.8241
	sim_grads_norm_tr = 0.0683
-- Starting training on experience 42 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8087
	data_grads_norm = 4.5295
	new_data_grads_norm = 6.4911
	old_data_grads_norm = 5.9051
	sim_grads_norm_tr = 0.0069
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9895
	data_grads_norm = 4.3306
	new_data_grads_norm = 6.3415
	old_data_grads_norm = 4.9528
	sim_grads_norm_tr = 0.0945
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8365
	data_grads_norm = 4.4010
	new_data_grads_norm = 6.6057
	old_data_grads_norm = 7.4413
	sim_grads_norm_tr = -0.1563
-- Starting training on experience 43 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2757
	data_grads_norm = 5.1931
	new_data_grads_norm = 7.5234
	old_data_grads_norm = 6.4785
	sim_grads_norm_tr = 0.0054
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2220
	data_grads_norm = 3.8625
	new_data_grads_norm = 5.7647
	old_data_grads_norm = 5.4083
	sim_grads_norm_tr = -0.0384
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8938
	data_grads_norm = 4.8781
	new_data_grads_norm = 5.9406
	old_data_grads_norm = 6.3857
	sim_grads_norm_tr = 0.0516
-- Starting training on experience 44 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5862
	data_grads_norm = 4.0989
	new_data_grads_norm = 6.0419
	old_data_grads_norm = 5.4108
	sim_grads_norm_tr = -0.0297
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4982
	data_grads_norm = 4.0064
	new_data_grads_norm = 6.0754
	old_data_grads_norm = 4.0403
	sim_grads_norm_tr = 0.0029
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9398
	data_grads_norm = 4.7498
	new_data_grads_norm = 5.6108
	old_data_grads_norm = 5.6822
	sim_grads_norm_tr = 0.0071
-- Starting training on experience 45 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6665
	data_grads_norm = 4.6156
	new_data_grads_norm = 6.9139
	old_data_grads_norm = 6.6181
	sim_grads_norm_tr = 0.0331
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9653
	data_grads_norm = 4.6818
	new_data_grads_norm = 6.4004
	old_data_grads_norm = 6.6465
	sim_grads_norm_tr = 0.0921
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8346
	data_grads_norm = 4.6639
	new_data_grads_norm = 5.9890
	old_data_grads_norm = 6.7192
	sim_grads_norm_tr = -0.0271
-- Starting training on experience 46 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5975
	data_grads_norm = 3.7658
	new_data_grads_norm = 5.5640
	old_data_grads_norm = 4.4557
	sim_grads_norm_tr = -0.0108
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9847
	data_grads_norm = 4.4852
	new_data_grads_norm = 5.8799
	old_data_grads_norm = 6.5823
	sim_grads_norm_tr = 0.0616
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4786
	data_grads_norm = 4.4680
	new_data_grads_norm = 5.6435
	old_data_grads_norm = 6.5397
	sim_grads_norm_tr = -0.0038
-- Starting training on experience 47 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7641
	data_grads_norm = 4.7538
	new_data_grads_norm = 6.2874
	old_data_grads_norm = 5.8984
	sim_grads_norm_tr = 0.0854
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4207
	data_grads_norm = 4.6681
	new_data_grads_norm = 6.3104
	old_data_grads_norm = 6.1895
	sim_grads_norm_tr = 0.0197
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3707
	data_grads_norm = 3.9855
	new_data_grads_norm = 5.9484
	old_data_grads_norm = 5.6414
	sim_grads_norm_tr = -0.0277
-- Starting training on experience 48 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8752
	data_grads_norm = 4.3106
	new_data_grads_norm = 6.6559
	old_data_grads_norm = 5.3533
	sim_grads_norm_tr = -0.0095
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6006
	data_grads_norm = 4.3464
	new_data_grads_norm = 6.0752
	old_data_grads_norm = 6.2362
	sim_grads_norm_tr = 0.0172
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8822
	data_grads_norm = 5.2243
	new_data_grads_norm = 6.7126
	old_data_grads_norm = 7.0426
	sim_grads_norm_tr = 0.0321
-- Starting training on experience 49 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5825
	data_grads_norm = 4.0761
	new_data_grads_norm = 5.7617
	old_data_grads_norm = 5.6078
	sim_grads_norm_tr = -0.0346
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4736
	data_grads_norm = 3.6826
	new_data_grads_norm = 5.4871
	old_data_grads_norm = 4.2803
	sim_grads_norm_tr = 0.1125
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8799
	data_grads_norm = 4.5442
	new_data_grads_norm = 5.8442
	old_data_grads_norm = 7.0084
	sim_grads_norm_tr = 0.0671
-- Starting training on experience 50 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5716
	data_grads_norm = 4.2818
	new_data_grads_norm = 7.0012
	old_data_grads_norm = 3.7822
	sim_grads_norm_tr = -0.0165
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2531
	data_grads_norm = 4.7092
	new_data_grads_norm = 7.0621
	old_data_grads_norm = 5.2520
	sim_grads_norm_tr = 0.0563
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0532
	data_grads_norm = 4.9727
	new_data_grads_norm = 6.6923
	old_data_grads_norm = 5.6940
	sim_grads_norm_tr = 0.1163
-- Starting training on experience 51 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8051
	data_grads_norm = 4.9818
	new_data_grads_norm = 6.1399
	old_data_grads_norm = 7.3615
	sim_grads_norm_tr = 0.0411
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8260
	data_grads_norm = 4.6165
	new_data_grads_norm = 5.9882
	old_data_grads_norm = 5.9343
	sim_grads_norm_tr = 0.0342
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7189
	data_grads_norm = 4.1665
	new_data_grads_norm = 6.1291
	old_data_grads_norm = 5.8946
	sim_grads_norm_tr = 0.0865
-- Starting training on experience 52 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3721
	data_grads_norm = 3.5759
	new_data_grads_norm = 5.1718
	old_data_grads_norm = 4.3408
	sim_grads_norm_tr = -0.0372
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2825
	data_grads_norm = 3.9853
	new_data_grads_norm = 5.7446
	old_data_grads_norm = 5.3237
	sim_grads_norm_tr = -0.0549
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4329
	data_grads_norm = 3.5571
	new_data_grads_norm = 5.0993
	old_data_grads_norm = 5.6659
	sim_grads_norm_tr = -0.0070
-- Starting training on experience 53 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9259
	data_grads_norm = 5.2211
	new_data_grads_norm = 6.6510
	old_data_grads_norm = 7.3532
	sim_grads_norm_tr = 0.0422
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4095
	data_grads_norm = 5.0831
	new_data_grads_norm = 6.4424
	old_data_grads_norm = 6.5585
	sim_grads_norm_tr = 0.0252
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6313
	data_grads_norm = 4.0910
	new_data_grads_norm = 6.2792
	old_data_grads_norm = 5.0723
	sim_grads_norm_tr = -0.0474
-- Starting training on experience 54 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7727
	data_grads_norm = 4.4234
	new_data_grads_norm = 6.3394
	old_data_grads_norm = 6.1604
	sim_grads_norm_tr = 0.0467
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6258
	data_grads_norm = 4.5661
	new_data_grads_norm = 6.0881
	old_data_grads_norm = 6.3065
	sim_grads_norm_tr = 0.0082
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9770
	data_grads_norm = 4.5586
	new_data_grads_norm = 5.8358
	old_data_grads_norm = 5.9353
	sim_grads_norm_tr = 0.1429
-- Starting training on experience 55 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6255
	data_grads_norm = 5.0226
	new_data_grads_norm = 7.2419
	old_data_grads_norm = 6.1799
	sim_grads_norm_tr = 0.0542
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4344
	data_grads_norm = 5.6048
	new_data_grads_norm = 7.9816
	old_data_grads_norm = 6.9287
	sim_grads_norm_tr = 0.0189
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4885
	data_grads_norm = 4.3885
	new_data_grads_norm = 6.9247
	old_data_grads_norm = 5.8005
	sim_grads_norm_tr = -0.1020
-- Starting training on experience 56 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7280
	data_grads_norm = 3.8614
	new_data_grads_norm = 5.4160
	old_data_grads_norm = 4.7820
	sim_grads_norm_tr = 0.0654
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3954
	data_grads_norm = 3.4471
	new_data_grads_norm = 5.0160
	old_data_grads_norm = 5.1022
	sim_grads_norm_tr = -0.0828
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5166
	data_grads_norm = 3.6319
	new_data_grads_norm = 5.3150
	old_data_grads_norm = 4.1332
	sim_grads_norm_tr = 0.0460
-- Starting training on experience 57 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3512
	data_grads_norm = 3.7172
	new_data_grads_norm = 5.1324
	old_data_grads_norm = 5.5721
	sim_grads_norm_tr = -0.1298
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9739
	data_grads_norm = 4.9780
	new_data_grads_norm = 5.5724
	old_data_grads_norm = 6.8959
	sim_grads_norm_tr = 0.1453
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5171
	data_grads_norm = 3.9331
	new_data_grads_norm = 4.6308
	old_data_grads_norm = 5.5121
	sim_grads_norm_tr = -0.0272
-- Starting training on experience 58 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2619
	data_grads_norm = 3.5496
	new_data_grads_norm = 5.2930
	old_data_grads_norm = 5.1650
	sim_grads_norm_tr = -0.0598
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6577
	data_grads_norm = 4.4262
	new_data_grads_norm = 6.4549
	old_data_grads_norm = 5.9376
	sim_grads_norm_tr = -0.0142
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4195
	data_grads_norm = 3.7719
	new_data_grads_norm = 6.1888
	old_data_grads_norm = 5.3692
	sim_grads_norm_tr = -0.0801
-- Starting training on experience 59 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4247
	data_grads_norm = 3.7091
	new_data_grads_norm = 5.3666
	old_data_grads_norm = 5.8234
	sim_grads_norm_tr = -0.0687
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1368
	data_grads_norm = 4.9137
	new_data_grads_norm = 6.5407
	old_data_grads_norm = 6.9444
	sim_grads_norm_tr = -0.0093
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7734
	data_grads_norm = 4.5749
	new_data_grads_norm = 6.3221
	old_data_grads_norm = 5.6872
	sim_grads_norm_tr = -0.0244
-- Starting training on experience 60 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6669
	data_grads_norm = 4.7742
	new_data_grads_norm = 6.5296
	old_data_grads_norm = 5.2367
	sim_grads_norm_tr = 0.0608
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1987
	data_grads_norm = 5.0491
	new_data_grads_norm = 6.5199
	old_data_grads_norm = 7.2358
	sim_grads_norm_tr = 0.0565
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8338
	data_grads_norm = 4.5601
	new_data_grads_norm = 5.9536
	old_data_grads_norm = 5.5922
	sim_grads_norm_tr = 0.1487
-- Starting training on experience 61 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3706
	data_grads_norm = 3.7600
	new_data_grads_norm = 4.7423
	old_data_grads_norm = 5.8964
	sim_grads_norm_tr = -0.0306
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9816
	data_grads_norm = 4.4920
	new_data_grads_norm = 5.2213
	old_data_grads_norm = 6.7781
	sim_grads_norm_tr = 0.0625
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7423
	data_grads_norm = 4.1347
	new_data_grads_norm = 5.2076
	old_data_grads_norm = 5.5683
	sim_grads_norm_tr = 0.0778
-- Starting training on experience 62 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5169
	data_grads_norm = 4.2996
	new_data_grads_norm = 5.2346
	old_data_grads_norm = 6.5420
	sim_grads_norm_tr = -0.0308
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1514
	data_grads_norm = 3.9348
	new_data_grads_norm = 5.5659
	old_data_grads_norm = 4.4105
	sim_grads_norm_tr = 0.0534
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0228
	data_grads_norm = 4.7514
	new_data_grads_norm = 5.3837
	old_data_grads_norm = 6.1836
	sim_grads_norm_tr = -0.0021
-- Starting training on experience 63 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6885
	data_grads_norm = 4.4129
	new_data_grads_norm = 6.4041
	old_data_grads_norm = 5.3988
	sim_grads_norm_tr = -0.0376
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7642
	data_grads_norm = 4.5794
	new_data_grads_norm = 6.3650
	old_data_grads_norm = 6.1623
	sim_grads_norm_tr = -0.0982
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7796
	data_grads_norm = 5.0526
	new_data_grads_norm = 7.3400
	old_data_grads_norm = 5.2884
	sim_grads_norm_tr = 0.0829
-- Starting training on experience 64 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4489
	data_grads_norm = 3.6600
	new_data_grads_norm = 5.4279
	old_data_grads_norm = 4.5523
	sim_grads_norm_tr = 0.0256
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3505
	data_grads_norm = 4.0714
	new_data_grads_norm = 5.6276
	old_data_grads_norm = 5.4040
	sim_grads_norm_tr = -0.0035
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2298
	data_grads_norm = 3.2161
	new_data_grads_norm = 5.1591
	old_data_grads_norm = 3.9894
	sim_grads_norm_tr = 0.0302
-- Starting training on experience 65 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1922
	data_grads_norm = 5.0146
	new_data_grads_norm = 6.0133
	old_data_grads_norm = 6.8139
	sim_grads_norm_tr = 0.0167
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8961
	data_grads_norm = 5.2301
	new_data_grads_norm = 6.3774
	old_data_grads_norm = 7.3652
	sim_grads_norm_tr = 0.0367
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6422
	data_grads_norm = 4.4342
	new_data_grads_norm = 5.8760
	old_data_grads_norm = 5.7245
	sim_grads_norm_tr = -0.0434
-- Starting training on experience 66 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5500
	data_grads_norm = 4.4797
	new_data_grads_norm = 6.5691
	old_data_grads_norm = 5.9958
	sim_grads_norm_tr = 0.0021
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8002
	data_grads_norm = 4.2001
	new_data_grads_norm = 6.2131
	old_data_grads_norm = 4.9239
	sim_grads_norm_tr = 0.0317
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3532
	data_grads_norm = 4.1130
	new_data_grads_norm = 6.1852
	old_data_grads_norm = 5.4025
	sim_grads_norm_tr = 0.0360
-- Starting training on experience 67 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8396
	data_grads_norm = 4.7839
	new_data_grads_norm = 6.7954
	old_data_grads_norm = 5.8038
	sim_grads_norm_tr = -0.0142
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7930
	data_grads_norm = 4.3689
	new_data_grads_norm = 6.6354
	old_data_grads_norm = 5.1062
	sim_grads_norm_tr = 0.0146
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9748
	data_grads_norm = 4.8680
	new_data_grads_norm = 6.7774
	old_data_grads_norm = 6.6962
	sim_grads_norm_tr = -0.0236
-- Starting training on experience 68 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0145
	data_grads_norm = 4.2537
	new_data_grads_norm = 6.2952
	old_data_grads_norm = 6.0433
	sim_grads_norm_tr = 0.0280
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4136
	data_grads_norm = 3.8141
	new_data_grads_norm = 6.1340
	old_data_grads_norm = 5.2355
	sim_grads_norm_tr = 0.0374
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2754
	data_grads_norm = 3.7525
	new_data_grads_norm = 6.3417
	old_data_grads_norm = 5.8950
	sim_grads_norm_tr = -0.0577
-- Starting training on experience 69 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7640
	data_grads_norm = 4.2621
	new_data_grads_norm = 5.9820
	old_data_grads_norm = 5.5293
	sim_grads_norm_tr = -0.0644
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8603
	data_grads_norm = 4.9351
	new_data_grads_norm = 5.9913
	old_data_grads_norm = 6.7948
	sim_grads_norm_tr = 0.0021
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9553
	data_grads_norm = 4.3345
	new_data_grads_norm = 5.6851
	old_data_grads_norm = 5.9673
	sim_grads_norm_tr = 0.0160
-- Starting training on experience 70 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7520
	data_grads_norm = 4.3969
	new_data_grads_norm = 5.6075
	old_data_grads_norm = 5.8573
	sim_grads_norm_tr = 0.0754
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3730
	data_grads_norm = 4.2263
	new_data_grads_norm = 6.6299
	old_data_grads_norm = 4.7210
	sim_grads_norm_tr = -0.0074
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6462
	data_grads_norm = 4.6103
	new_data_grads_norm = 6.3691
	old_data_grads_norm = 6.5720
	sim_grads_norm_tr = -0.0042
-- Starting training on experience 71 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7111
	data_grads_norm = 3.7066
	new_data_grads_norm = 5.7500
	old_data_grads_norm = 5.5256
	sim_grads_norm_tr = -0.0332
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8738
	data_grads_norm = 4.0495
	new_data_grads_norm = 5.7104
	old_data_grads_norm = 4.7262
	sim_grads_norm_tr = 0.1318
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0416
	data_grads_norm = 4.9026
	new_data_grads_norm = 5.9964
	old_data_grads_norm = 6.8072
	sim_grads_norm_tr = 0.0902
-- Starting training on experience 72 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4883
	data_grads_norm = 4.9481
	new_data_grads_norm = 6.3331
	old_data_grads_norm = 5.6974
	sim_grads_norm_tr = 0.0149
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7906
	data_grads_norm = 5.9127
	new_data_grads_norm = 7.3237
	old_data_grads_norm = 6.1871
	sim_grads_norm_tr = 0.1371
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4129
	data_grads_norm = 4.8827
	new_data_grads_norm = 6.6119
	old_data_grads_norm = 6.6051
	sim_grads_norm_tr = -0.0276
-- Starting training on experience 73 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9316
	data_grads_norm = 4.4336
	new_data_grads_norm = 5.9333
	old_data_grads_norm = 5.5115
	sim_grads_norm_tr = 0.1543
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8380
	data_grads_norm = 4.5853
	new_data_grads_norm = 5.6214
	old_data_grads_norm = 5.9105
	sim_grads_norm_tr = 0.1850
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8983
	data_grads_norm = 3.9094
	new_data_grads_norm = 5.2147
	old_data_grads_norm = 5.6189
	sim_grads_norm_tr = 0.0356
-- Starting training on experience 74 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7297
	data_grads_norm = 4.5160
	new_data_grads_norm = 5.2784
	old_data_grads_norm = 7.1473
	sim_grads_norm_tr = 0.0424
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0766
	data_grads_norm = 4.2995
	new_data_grads_norm = 5.0392
	old_data_grads_norm = 7.2923
	sim_grads_norm_tr = -0.0220
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4368
	data_grads_norm = 4.4310
	new_data_grads_norm = 5.3754
	old_data_grads_norm = 6.7453
	sim_grads_norm_tr = 0.0191
-- Starting training on experience 75 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2182
	data_grads_norm = 3.8217
	new_data_grads_norm = 6.0446
	old_data_grads_norm = 4.5364
	sim_grads_norm_tr = -0.0018
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5082
	data_grads_norm = 4.3594
	new_data_grads_norm = 5.8650
	old_data_grads_norm = 4.9202
	sim_grads_norm_tr = 0.1239
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6269
	data_grads_norm = 4.5936
	new_data_grads_norm = 5.7975
	old_data_grads_norm = 6.5491
	sim_grads_norm_tr = -0.0209
-- Starting training on experience 76 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9848
	data_grads_norm = 3.9951
	new_data_grads_norm = 5.7127
	old_data_grads_norm = 5.9387
	sim_grads_norm_tr = 0.0108
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3106
	data_grads_norm = 4.0336
	new_data_grads_norm = 5.8775
	old_data_grads_norm = 5.4121
	sim_grads_norm_tr = -0.0308
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7853
	data_grads_norm = 4.4740
	new_data_grads_norm = 5.5882
	old_data_grads_norm = 6.4884
	sim_grads_norm_tr = 0.0509
-- Starting training on experience 77 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1762
	data_grads_norm = 3.7223
	new_data_grads_norm = 6.0696
	old_data_grads_norm = 4.3934
	sim_grads_norm_tr = 0.0007
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3663
	data_grads_norm = 4.0431
	new_data_grads_norm = 6.4844
	old_data_grads_norm = 5.4076
	sim_grads_norm_tr = -0.0827
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7969
	data_grads_norm = 4.7192
	new_data_grads_norm = 6.8062
	old_data_grads_norm = 6.1095
	sim_grads_norm_tr = 0.0420
-- Starting training on experience 78 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2933
	data_grads_norm = 4.2132
	new_data_grads_norm = 6.3162
	old_data_grads_norm = 5.8171
	sim_grads_norm_tr = 0.0495
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4691
	data_grads_norm = 4.1960
	new_data_grads_norm = 5.6046
	old_data_grads_norm = 5.5342
	sim_grads_norm_tr = 0.0135
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2851
	data_grads_norm = 4.1662
	new_data_grads_norm = 6.2057
	old_data_grads_norm = 5.9851
	sim_grads_norm_tr = 0.0144
-- Starting training on experience 79 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7674
	data_grads_norm = 4.7062
	new_data_grads_norm = 5.5360
	old_data_grads_norm = 6.9798
	sim_grads_norm_tr = 0.0482
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4880
	data_grads_norm = 4.3165
	new_data_grads_norm = 5.4556
	old_data_grads_norm = 6.3926
	sim_grads_norm_tr = 0.0401
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4221
	data_grads_norm = 3.9831
	new_data_grads_norm = 5.3313
	old_data_grads_norm = 6.4643
	sim_grads_norm_tr = 0.0420
-- Starting training on experience 80 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8732
	data_grads_norm = 3.9540
	new_data_grads_norm = 5.7534
	old_data_grads_norm = 5.3159
	sim_grads_norm_tr = -0.0212
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0820
	data_grads_norm = 3.8330
	new_data_grads_norm = 6.0721
	old_data_grads_norm = 4.5179
	sim_grads_norm_tr = 0.0798
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1560
	data_grads_norm = 3.9545
	new_data_grads_norm = 5.5139
	old_data_grads_norm = 5.5319
	sim_grads_norm_tr = 0.0486
-- Starting training on experience 81 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6634
	data_grads_norm = 4.5701
	new_data_grads_norm = 5.7109
	old_data_grads_norm = 6.9132
	sim_grads_norm_tr = 0.0796
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6723
	data_grads_norm = 4.6119
	new_data_grads_norm = 6.1787
	old_data_grads_norm = 5.9815
	sim_grads_norm_tr = 0.0285
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9138
	data_grads_norm = 4.6473
	new_data_grads_norm = 5.7700
	old_data_grads_norm = 7.2247
	sim_grads_norm_tr = -0.0343
-- Starting training on experience 82 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2183
	data_grads_norm = 4.4499
	new_data_grads_norm = 5.1924
	old_data_grads_norm = 7.2207
	sim_grads_norm_tr = -0.0053
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5406
	data_grads_norm = 4.4383
	new_data_grads_norm = 5.5338
	old_data_grads_norm = 6.0464
	sim_grads_norm_tr = 0.0521
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5024
	data_grads_norm = 4.5700
	new_data_grads_norm = 5.3430
	old_data_grads_norm = 7.4016
	sim_grads_norm_tr = -0.0688
-- Starting training on experience 83 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1979
	data_grads_norm = 4.8753
	new_data_grads_norm = 5.7962
	old_data_grads_norm = 6.5666
	sim_grads_norm_tr = 0.0254
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6431
	data_grads_norm = 4.3375
	new_data_grads_norm = 5.9985
	old_data_grads_norm = 5.3209
	sim_grads_norm_tr = 0.0913
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8990
	data_grads_norm = 4.8598
	new_data_grads_norm = 5.9672
	old_data_grads_norm = 6.8697
	sim_grads_norm_tr = 0.0563
-- Starting training on experience 84 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8839
	data_grads_norm = 3.7449
	new_data_grads_norm = 5.2393
	old_data_grads_norm = 4.6831
	sim_grads_norm_tr = -0.0270
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6549
	data_grads_norm = 4.5019
	new_data_grads_norm = 5.2143
	old_data_grads_norm = 6.4836
	sim_grads_norm_tr = 0.0285
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1096
	data_grads_norm = 3.4643
	new_data_grads_norm = 5.1833
	old_data_grads_norm = 4.7125
	sim_grads_norm_tr = 0.0319
-- Starting training on experience 85 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6312
	data_grads_norm = 4.7871
	new_data_grads_norm = 7.0280
	old_data_grads_norm = 5.3742
	sim_grads_norm_tr = 0.0524
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2438
	data_grads_norm = 5.5856
	new_data_grads_norm = 7.5008
	old_data_grads_norm = 7.0603
	sim_grads_norm_tr = 0.0283
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3008
	data_grads_norm = 5.0856
	new_data_grads_norm = 6.9846
	old_data_grads_norm = 7.4639
	sim_grads_norm_tr = 0.0141
-- Starting training on experience 86 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0327
	data_grads_norm = 4.2391
	new_data_grads_norm = 5.6320
	old_data_grads_norm = 5.9080
	sim_grads_norm_tr = 0.0405
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3991
	data_grads_norm = 3.6724
	new_data_grads_norm = 5.6797
	old_data_grads_norm = 5.2311
	sim_grads_norm_tr = 0.0132
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7933
	data_grads_norm = 4.5358
	new_data_grads_norm = 5.5306
	old_data_grads_norm = 6.8819
	sim_grads_norm_tr = -0.0126
-- Starting training on experience 87 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4748
	data_grads_norm = 3.8032
	new_data_grads_norm = 5.7178
	old_data_grads_norm = 5.1992
	sim_grads_norm_tr = -0.0275
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6610
	data_grads_norm = 4.0335
	new_data_grads_norm = 5.2781
	old_data_grads_norm = 6.0559
	sim_grads_norm_tr = -0.0113
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1697
	data_grads_norm = 3.6455
	new_data_grads_norm = 5.8244
	old_data_grads_norm = 4.4760
	sim_grads_norm_tr = 0.0936
-- Starting training on experience 88 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7293
	data_grads_norm = 4.9856
	new_data_grads_norm = 5.6501
	old_data_grads_norm = 6.9702
	sim_grads_norm_tr = 0.0094
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7030
	data_grads_norm = 4.0085
	new_data_grads_norm = 6.0943
	old_data_grads_norm = 5.7601
	sim_grads_norm_tr = 0.0309
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7347
	data_grads_norm = 4.1086
	new_data_grads_norm = 5.4488
	old_data_grads_norm = 5.9201
	sim_grads_norm_tr = 0.0847
-- Starting training on experience 89 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4356
	data_grads_norm = 4.3904
	new_data_grads_norm = 5.6318
	old_data_grads_norm = 5.9295
	sim_grads_norm_tr = -0.0250
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1616
	data_grads_norm = 4.2212
	new_data_grads_norm = 5.7812
	old_data_grads_norm = 6.6494
	sim_grads_norm_tr = -0.0569
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4252
	data_grads_norm = 4.2812
	new_data_grads_norm = 5.7356
	old_data_grads_norm = 6.2144
	sim_grads_norm_tr = 0.0067
-- Starting training on experience 90 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1106
	data_grads_norm = 4.4286
	new_data_grads_norm = 6.1305
	old_data_grads_norm = 5.5570
	sim_grads_norm_tr = 0.1815
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3172
	data_grads_norm = 4.8568
	new_data_grads_norm = 5.2717
	old_data_grads_norm = 7.3705
	sim_grads_norm_tr = -0.0142
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2413
	data_grads_norm = 4.4508
	new_data_grads_norm = 6.2612
	old_data_grads_norm = 6.3589
	sim_grads_norm_tr = 0.0148
-- Starting training on experience 91 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3440
	data_grads_norm = 4.5734
	new_data_grads_norm = 6.4112
	old_data_grads_norm = 5.9551
	sim_grads_norm_tr = -0.0580
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9758
	data_grads_norm = 5.4090
	new_data_grads_norm = 6.9779
	old_data_grads_norm = 6.3061
	sim_grads_norm_tr = 0.2501
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8567
	data_grads_norm = 5.1101
	new_data_grads_norm = 5.8718
	old_data_grads_norm = 7.4449
	sim_grads_norm_tr = 0.0199
-- Starting training on experience 92 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7868
	data_grads_norm = 4.3003
	new_data_grads_norm = 5.8065
	old_data_grads_norm = 5.4344
	sim_grads_norm_tr = 0.1529
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0225
	data_grads_norm = 4.6462
	new_data_grads_norm = 6.4486
	old_data_grads_norm = 6.0980
	sim_grads_norm_tr = 0.0476
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7070
	data_grads_norm = 4.4009
	new_data_grads_norm = 6.0529
	old_data_grads_norm = 5.9607
	sim_grads_norm_tr = -0.0108
-- Starting training on experience 93 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1081
	data_grads_norm = 3.9220
	new_data_grads_norm = 4.5461
	old_data_grads_norm = 6.3076
	sim_grads_norm_tr = -0.0757
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4688
	data_grads_norm = 4.0221
	new_data_grads_norm = 4.7912
	old_data_grads_norm = 6.7209
	sim_grads_norm_tr = -0.0294
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4008
	data_grads_norm = 3.8729
	new_data_grads_norm = 5.2434
	old_data_grads_norm = 5.7317
	sim_grads_norm_tr = 0.0034
-- Starting training on experience 94 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2068
	data_grads_norm = 4.5541
	new_data_grads_norm = 5.8139
	old_data_grads_norm = 6.0656
	sim_grads_norm_tr = 0.0234
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5573
	data_grads_norm = 4.4283
	new_data_grads_norm = 6.1346
	old_data_grads_norm = 5.3340
	sim_grads_norm_tr = 0.0642
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4366
	data_grads_norm = 4.2069
	new_data_grads_norm = 6.2697
	old_data_grads_norm = 5.8478
	sim_grads_norm_tr = -0.0550
-- Starting training on experience 95 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5513
	data_grads_norm = 4.5983
	new_data_grads_norm = 5.6985
	old_data_grads_norm = 6.6166
	sim_grads_norm_tr = 0.0268
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9711
	data_grads_norm = 4.6351
	new_data_grads_norm = 6.4428
	old_data_grads_norm = 5.9854
	sim_grads_norm_tr = 0.0823
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0495
	data_grads_norm = 4.2808
	new_data_grads_norm = 5.8851
	old_data_grads_norm = 5.4316
	sim_grads_norm_tr = 0.0028
-- Starting training on experience 96 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4485
	data_grads_norm = 4.0172
	new_data_grads_norm = 5.6786
	old_data_grads_norm = 5.8785
	sim_grads_norm_tr = 0.0088
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4894
	data_grads_norm = 3.9830
	new_data_grads_norm = 5.4707
	old_data_grads_norm = 5.5044
	sim_grads_norm_tr = -0.0366
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5924
	data_grads_norm = 4.2467
	new_data_grads_norm = 6.2879
	old_data_grads_norm = 5.2518
	sim_grads_norm_tr = 0.0382
-- Starting training on experience 97 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7534
	data_grads_norm = 3.6281
	new_data_grads_norm = 6.0389
	old_data_grads_norm = 4.5386
	sim_grads_norm_tr = 0.0120
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7536
	data_grads_norm = 4.8450
	new_data_grads_norm = 6.2593
	old_data_grads_norm = 6.5425
	sim_grads_norm_tr = -0.0543
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3377
	data_grads_norm = 4.3829
	new_data_grads_norm = 6.4444
	old_data_grads_norm = 4.9990
	sim_grads_norm_tr = 0.0014
-- Starting training on experience 98 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3850
	data_grads_norm = 4.1596
	new_data_grads_norm = 5.9453
	old_data_grads_norm = 4.9908
	sim_grads_norm_tr = -0.0267
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8698
	data_grads_norm = 5.3262
	new_data_grads_norm = 5.7830
	old_data_grads_norm = 7.1733
	sim_grads_norm_tr = 0.1218
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1047
	data_grads_norm = 4.2492
	new_data_grads_norm = 5.7270
	old_data_grads_norm = 6.5800
	sim_grads_norm_tr = 0.0068
-- Starting training on experience 99 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0881
	data_grads_norm = 3.7210
	new_data_grads_norm = 5.3209
	old_data_grads_norm = 4.8230
	sim_grads_norm_tr = -0.0445
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8362
	data_grads_norm = 4.5916
	new_data_grads_norm = 5.6367
	old_data_grads_norm = 5.3847
	sim_grads_norm_tr = 0.0054
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8363
	data_grads_norm = 4.6215
	new_data_grads_norm = 5.5980
	old_data_grads_norm = 6.9415
	sim_grads_norm_tr = -0.0110
-- Starting training on experience 100 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2516
	data_grads_norm = 4.1343
	new_data_grads_norm = 6.2585
	old_data_grads_norm = 4.9729
	sim_grads_norm_tr = 0.0447
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0368
	data_grads_norm = 4.5949
	new_data_grads_norm = 6.0601
	old_data_grads_norm = 6.1435
	sim_grads_norm_tr = -0.0395
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9251
	data_grads_norm = 3.8412
	new_data_grads_norm = 6.3644
	old_data_grads_norm = 5.1339
	sim_grads_norm_tr = -0.0564
-- Starting training on experience 101 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1749
	data_grads_norm = 4.0739
	new_data_grads_norm = 6.4374
	old_data_grads_norm = 4.9976
	sim_grads_norm_tr = 0.0491
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2493
	data_grads_norm = 3.7932
	new_data_grads_norm = 6.0726
	old_data_grads_norm = 4.4571
	sim_grads_norm_tr = 0.0110
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6707
	data_grads_norm = 4.4933
	new_data_grads_norm = 6.0722
	old_data_grads_norm = 6.7222
	sim_grads_norm_tr = 0.0273
-- Starting training on experience 102 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5830
	data_grads_norm = 4.3763
	new_data_grads_norm = 5.6936
	old_data_grads_norm = 6.5977
	sim_grads_norm_tr = -0.0559
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3240
	data_grads_norm = 3.8426
	new_data_grads_norm = 5.9910
	old_data_grads_norm = 5.3741
	sim_grads_norm_tr = 0.0127
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3616
	data_grads_norm = 3.8436
	new_data_grads_norm = 5.5054
	old_data_grads_norm = 4.9909
	sim_grads_norm_tr = -0.0371
-- Starting training on experience 103 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4519
	data_grads_norm = 3.6650
	new_data_grads_norm = 5.4895
	old_data_grads_norm = 5.1325
	sim_grads_norm_tr = -0.0037
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7060
	data_grads_norm = 4.0437
	new_data_grads_norm = 5.4311
	old_data_grads_norm = 5.6154
	sim_grads_norm_tr = 0.0590
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5515
	data_grads_norm = 4.7456
	new_data_grads_norm = 5.8837
	old_data_grads_norm = 7.3239
	sim_grads_norm_tr = 0.0227
-- Starting training on experience 104 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6999
	data_grads_norm = 4.7051
	new_data_grads_norm = 6.5591
	old_data_grads_norm = 6.1757
	sim_grads_norm_tr = -0.0500
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7312
	data_grads_norm = 4.6234
	new_data_grads_norm = 6.4573
	old_data_grads_norm = 5.1630
	sim_grads_norm_tr = 0.1244
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6132
	data_grads_norm = 4.7662
	new_data_grads_norm = 6.3386
	old_data_grads_norm = 6.1222
	sim_grads_norm_tr = 0.0357
-- Starting training on experience 105 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7895
	data_grads_norm = 4.7808
	new_data_grads_norm = 5.9781
	old_data_grads_norm = 5.6260
	sim_grads_norm_tr = 0.2341
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3068
	data_grads_norm = 4.7557
	new_data_grads_norm = 6.0031
	old_data_grads_norm = 6.7490
	sim_grads_norm_tr = 0.0194
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8006
	data_grads_norm = 4.4287
	new_data_grads_norm = 5.9041
	old_data_grads_norm = 5.8077
	sim_grads_norm_tr = 0.0462
-- Starting training on experience 106 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3919
	data_grads_norm = 4.4111
	new_data_grads_norm = 6.5937
	old_data_grads_norm = 5.4935
	sim_grads_norm_tr = -0.0338
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1367
	data_grads_norm = 4.2607
	new_data_grads_norm = 6.0890
	old_data_grads_norm = 6.5592
	sim_grads_norm_tr = -0.0666
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1811
	data_grads_norm = 5.0682
	new_data_grads_norm = 7.1826
	old_data_grads_norm = 5.5428
	sim_grads_norm_tr = -0.0046
-- Starting training on experience 107 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1679
	data_grads_norm = 4.5148
	new_data_grads_norm = 6.8912
	old_data_grads_norm = 5.1928
	sim_grads_norm_tr = 0.0486
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6466
	data_grads_norm = 4.7946
	new_data_grads_norm = 6.9508
	old_data_grads_norm = 6.2887
	sim_grads_norm_tr = -0.0014
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9073
	data_grads_norm = 4.7555
	new_data_grads_norm = 6.8036
	old_data_grads_norm = 5.3728
	sim_grads_norm_tr = 0.0352
-- Starting training on experience 108 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6620
	data_grads_norm = 4.4584
	new_data_grads_norm = 6.1173
	old_data_grads_norm = 5.0045
	sim_grads_norm_tr = 0.1786
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5657
	data_grads_norm = 4.3461
	new_data_grads_norm = 5.9857
	old_data_grads_norm = 6.0463
	sim_grads_norm_tr = -0.0227
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7775
	data_grads_norm = 4.7635
	new_data_grads_norm = 6.1058
	old_data_grads_norm = 5.3980
	sim_grads_norm_tr = 0.1628
-- Starting training on experience 109 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6261
	data_grads_norm = 5.3289
	new_data_grads_norm = 6.0175
	old_data_grads_norm = 8.3391
	sim_grads_norm_tr = -0.0364
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4750
	data_grads_norm = 4.4631
	new_data_grads_norm = 6.2826
	old_data_grads_norm = 6.2750
	sim_grads_norm_tr = 0.0015
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5269
	data_grads_norm = 4.4429
	new_data_grads_norm = 6.3736
	old_data_grads_norm = 6.4126
	sim_grads_norm_tr = 0.0543
-- Starting training on experience 110 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5199
	data_grads_norm = 4.2091
	new_data_grads_norm = 5.3310
	old_data_grads_norm = 5.7199
	sim_grads_norm_tr = 0.0323
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8042
	data_grads_norm = 4.9463
	new_data_grads_norm = 5.3448
	old_data_grads_norm = 7.3300
	sim_grads_norm_tr = 0.0313
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2698
	data_grads_norm = 3.7900
	new_data_grads_norm = 5.4068
	old_data_grads_norm = 5.3688
	sim_grads_norm_tr = 0.0269
-- Starting training on experience 111 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2669
	data_grads_norm = 4.6159
	new_data_grads_norm = 5.9374
	old_data_grads_norm = 6.8247
	sim_grads_norm_tr = 0.0209
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2022
	data_grads_norm = 4.6077
	new_data_grads_norm = 6.4089
	old_data_grads_norm = 5.9889
	sim_grads_norm_tr = 0.0205
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2634
	data_grads_norm = 4.7408
	new_data_grads_norm = 6.1060
	old_data_grads_norm = 6.0781
	sim_grads_norm_tr = 0.0266
-- Starting training on experience 112 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2522
	data_grads_norm = 4.1217
	new_data_grads_norm = 5.8451
	old_data_grads_norm = 5.3124
	sim_grads_norm_tr = 0.1127
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7627
	data_grads_norm = 4.0742
	new_data_grads_norm = 5.9416
	old_data_grads_norm = 5.1548
	sim_grads_norm_tr = 0.0251
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9728
	data_grads_norm = 4.2688
	new_data_grads_norm = 5.4145
	old_data_grads_norm = 6.2925
	sim_grads_norm_tr = 0.0733
-- Starting training on experience 113 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1830
	data_grads_norm = 3.3546
	new_data_grads_norm = 5.2211
	old_data_grads_norm = 4.0847
	sim_grads_norm_tr = -0.0509
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3049
	data_grads_norm = 4.2398
	new_data_grads_norm = 5.1163
	old_data_grads_norm = 6.8023
	sim_grads_norm_tr = 0.0190
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1668
	data_grads_norm = 4.2433
	new_data_grads_norm = 5.7651
	old_data_grads_norm = 5.7621
	sim_grads_norm_tr = -0.0203
-- Starting training on experience 114 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9599
	data_grads_norm = 4.1532
	new_data_grads_norm = 5.2657
	old_data_grads_norm = 6.4913
	sim_grads_norm_tr = -0.0416
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9164
	data_grads_norm = 4.3992
	new_data_grads_norm = 4.9122
	old_data_grads_norm = 6.9265
	sim_grads_norm_tr = 0.0143
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6824
	data_grads_norm = 3.8409
	new_data_grads_norm = 4.8298
	old_data_grads_norm = 5.6601
	sim_grads_norm_tr = -0.0011
-- Starting training on experience 115 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1893
	data_grads_norm = 5.5247
	new_data_grads_norm = 6.5101
	old_data_grads_norm = 6.9422
	sim_grads_norm_tr = 0.0231
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4369
	data_grads_norm = 4.5309
	new_data_grads_norm = 6.6955
	old_data_grads_norm = 6.3537
	sim_grads_norm_tr = -0.0020
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9273
	data_grads_norm = 3.8511
	new_data_grads_norm = 5.7382
	old_data_grads_norm = 5.0124
	sim_grads_norm_tr = -0.0534
-- Starting training on experience 116 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8569
	data_grads_norm = 4.7081
	new_data_grads_norm = 6.5589
	old_data_grads_norm = 5.4792
	sim_grads_norm_tr = 0.0040
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9374
	data_grads_norm = 4.0173
	new_data_grads_norm = 6.0410
	old_data_grads_norm = 4.5492
	sim_grads_norm_tr = -0.0663
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8090
	data_grads_norm = 4.9371
	new_data_grads_norm = 6.4939
	old_data_grads_norm = 6.4764
	sim_grads_norm_tr = 0.1422
-- Starting training on experience 117 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6552
	data_grads_norm = 4.3684
	new_data_grads_norm = 5.2536
	old_data_grads_norm = 6.0571
	sim_grads_norm_tr = 0.0141
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0952
	data_grads_norm = 4.1542
	new_data_grads_norm = 5.7032
	old_data_grads_norm = 5.6527
	sim_grads_norm_tr = 0.0926
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3491
	data_grads_norm = 4.0569
	new_data_grads_norm = 5.5006
	old_data_grads_norm = 6.4478
	sim_grads_norm_tr = -0.0678
-- Starting training on experience 118 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7340
	data_grads_norm = 4.8931
	new_data_grads_norm = 6.3188
	old_data_grads_norm = 6.0423
	sim_grads_norm_tr = 0.1543
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1880
	data_grads_norm = 4.2537
	new_data_grads_norm = 5.6311
	old_data_grads_norm = 6.2760
	sim_grads_norm_tr = -0.0454
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1802
	data_grads_norm = 4.0446
	new_data_grads_norm = 6.0332
	old_data_grads_norm = 5.6571
	sim_grads_norm_tr = -0.0329
-- Starting training on experience 119 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3201
	data_grads_norm = 4.3870
	new_data_grads_norm = 5.4459
	old_data_grads_norm = 6.1851
	sim_grads_norm_tr = 0.0873
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2587
	data_grads_norm = 4.4559
	new_data_grads_norm = 5.9032
	old_data_grads_norm = 6.5953
	sim_grads_norm_tr = -0.0477
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3890
	data_grads_norm = 4.5927
	new_data_grads_norm = 6.0116
	old_data_grads_norm = 6.8743
	sim_grads_norm_tr = 0.0035
-- Starting training on experience 120 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0886
	data_grads_norm = 3.6603
	new_data_grads_norm = 5.7017
	old_data_grads_norm = 4.6675
	sim_grads_norm_tr = 0.0114
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2977
	data_grads_norm = 4.8772
	new_data_grads_norm = 5.9661
	old_data_grads_norm = 6.5502
	sim_grads_norm_tr = 0.0856
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1359
	data_grads_norm = 3.9709
	new_data_grads_norm = 5.9180
	old_data_grads_norm = 5.5023
	sim_grads_norm_tr = -0.0914
-- Starting training on experience 121 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3891
	data_grads_norm = 3.7965
	new_data_grads_norm = 5.4575
	old_data_grads_norm = 5.1813
	sim_grads_norm_tr = 0.0022
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9099
	data_grads_norm = 4.4760
	new_data_grads_norm = 6.0019
	old_data_grads_norm = 7.2034
	sim_grads_norm_tr = 0.0121
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4221
	data_grads_norm = 4.0860
	new_data_grads_norm = 5.4540
	old_data_grads_norm = 6.4065
	sim_grads_norm_tr = -0.0283
-- Starting training on experience 122 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3184
	data_grads_norm = 4.9046
	new_data_grads_norm = 7.6784
	old_data_grads_norm = 5.3945
	sim_grads_norm_tr = 0.0930
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7116
	data_grads_norm = 5.4897
	new_data_grads_norm = 6.1840
	old_data_grads_norm = 8.3203
	sim_grads_norm_tr = -0.0112
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7031
	data_grads_norm = 5.4883
	new_data_grads_norm = 6.5329
	old_data_grads_norm = 7.7279
	sim_grads_norm_tr = -0.0208
-- Starting training on experience 123 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3612
	data_grads_norm = 4.9901
	new_data_grads_norm = 6.5224
	old_data_grads_norm = 7.0045
	sim_grads_norm_tr = 0.1153
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9866
	data_grads_norm = 5.0095
	new_data_grads_norm = 5.8074
	old_data_grads_norm = 6.4863
	sim_grads_norm_tr = -0.0189
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0279
	data_grads_norm = 4.5781
	new_data_grads_norm = 5.7344
	old_data_grads_norm = 7.0233
	sim_grads_norm_tr = -0.0666
-- Starting training on experience 124 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4455
	data_grads_norm = 4.3603
	new_data_grads_norm = 5.4976
	old_data_grads_norm = 6.3121
	sim_grads_norm_tr = 0.0622
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8381
	data_grads_norm = 3.2895
	new_data_grads_norm = 5.5614
	old_data_grads_norm = 4.6801
	sim_grads_norm_tr = -0.0696
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3372
	data_grads_norm = 4.2773
	new_data_grads_norm = 5.1051
	old_data_grads_norm = 6.7273
	sim_grads_norm_tr = 0.0644
-- Starting training on experience 125 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6071
	data_grads_norm = 5.0601
	new_data_grads_norm = 6.3631
	old_data_grads_norm = 7.8736
	sim_grads_norm_tr = 0.0669
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1453
	data_grads_norm = 4.1991
	new_data_grads_norm = 6.1722
	old_data_grads_norm = 5.7810
	sim_grads_norm_tr = -0.0164
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0644
	data_grads_norm = 4.3955
	new_data_grads_norm = 6.5633
	old_data_grads_norm = 5.5820
	sim_grads_norm_tr = -0.0194
-- Starting training on experience 126 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7160
	data_grads_norm = 3.8819
	new_data_grads_norm = 4.9198
	old_data_grads_norm = 5.5557
	sim_grads_norm_tr = 0.0138
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2748
	data_grads_norm = 4.2132
	new_data_grads_norm = 5.9114
	old_data_grads_norm = 5.2198
	sim_grads_norm_tr = 0.0153
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7807
	data_grads_norm = 3.7611
	new_data_grads_norm = 5.3430
	old_data_grads_norm = 5.5037
	sim_grads_norm_tr = -0.0519
-- Starting training on experience 127 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1359
	data_grads_norm = 3.7931
	new_data_grads_norm = 5.3457
	old_data_grads_norm = 4.4248
	sim_grads_norm_tr = 0.0999
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1145
	data_grads_norm = 3.5881
	new_data_grads_norm = 4.9620
	old_data_grads_norm = 4.9094
	sim_grads_norm_tr = -0.0105
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0898
	data_grads_norm = 3.8100
	new_data_grads_norm = 5.1416
	old_data_grads_norm = 5.2170
	sim_grads_norm_tr = -0.0896
-- Starting training on experience 128 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8530
	data_grads_norm = 3.9826
	new_data_grads_norm = 5.3559
	old_data_grads_norm = 5.5509
	sim_grads_norm_tr = -0.0323
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0046
	data_grads_norm = 4.1458
	new_data_grads_norm = 6.0271
	old_data_grads_norm = 5.0785
	sim_grads_norm_tr = 0.0202
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3663
	data_grads_norm = 4.6687
	new_data_grads_norm = 6.3319
	old_data_grads_norm = 6.9557
	sim_grads_norm_tr = 0.0675
-- Starting training on experience 129 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3295
	data_grads_norm = 4.6094
	new_data_grads_norm = 5.8354
	old_data_grads_norm = 6.9859
	sim_grads_norm_tr = -0.0457
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5310
	data_grads_norm = 4.3055
	new_data_grads_norm = 6.9198
	old_data_grads_norm = 4.7407
	sim_grads_norm_tr = 0.0369
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4965
	data_grads_norm = 4.0910
	new_data_grads_norm = 6.2271
	old_data_grads_norm = 5.8487
	sim_grads_norm_tr = -0.0565
-- Starting training on experience 130 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1932
	data_grads_norm = 4.4842
	new_data_grads_norm = 5.6454
	old_data_grads_norm = 7.5667
	sim_grads_norm_tr = -0.0126
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6534
	data_grads_norm = 4.5727
	new_data_grads_norm = 6.1119
	old_data_grads_norm = 5.6774
	sim_grads_norm_tr = -0.0058
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4717
	data_grads_norm = 4.8672
	new_data_grads_norm = 6.0997
	old_data_grads_norm = 7.7508
	sim_grads_norm_tr = 0.0233
-- Starting training on experience 131 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6560
	data_grads_norm = 5.4217
	new_data_grads_norm = 7.5386
	old_data_grads_norm = 7.3265
	sim_grads_norm_tr = 0.0721
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7003
	data_grads_norm = 5.5101
	new_data_grads_norm = 6.2687
	old_data_grads_norm = 7.6589
	sim_grads_norm_tr = 0.1520
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1220
	data_grads_norm = 3.9509
	new_data_grads_norm = 6.2199
	old_data_grads_norm = 4.3657
	sim_grads_norm_tr = -0.0867
-- Starting training on experience 132 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3801
	data_grads_norm = 4.5829
	new_data_grads_norm = 6.3352
	old_data_grads_norm = 5.9622
	sim_grads_norm_tr = 0.0959
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2543
	data_grads_norm = 4.3223
	new_data_grads_norm = 5.7256
	old_data_grads_norm = 6.7902
	sim_grads_norm_tr = -0.0107
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0353
	data_grads_norm = 4.2695
	new_data_grads_norm = 5.7424
	old_data_grads_norm = 6.2187
	sim_grads_norm_tr = -0.0740
-- Starting training on experience 133 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1606
	data_grads_norm = 4.1626
	new_data_grads_norm = 6.1873
	old_data_grads_norm = 4.5712
	sim_grads_norm_tr = 0.2325
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5405
	data_grads_norm = 4.6023
	new_data_grads_norm = 5.9749
	old_data_grads_norm = 6.3837
	sim_grads_norm_tr = -0.0359
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7004
	data_grads_norm = 3.6828
	new_data_grads_norm = 5.7411
	old_data_grads_norm = 4.9988
	sim_grads_norm_tr = -0.0103
-- Starting training on experience 134 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8431
	data_grads_norm = 3.9046
	new_data_grads_norm = 4.8486
	old_data_grads_norm = 5.7927
	sim_grads_norm_tr = -0.0368
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1241
	data_grads_norm = 4.1549
	new_data_grads_norm = 5.9001
	old_data_grads_norm = 4.9471
	sim_grads_norm_tr = 0.0206
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1692
	data_grads_norm = 4.3729
	new_data_grads_norm = 5.0286
	old_data_grads_norm = 6.4088
	sim_grads_norm_tr = 0.0167
-- Starting training on experience 135 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8925
	data_grads_norm = 4.3625
	new_data_grads_norm = 5.8348
	old_data_grads_norm = 6.0605
	sim_grads_norm_tr = 0.0068
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9328
	data_grads_norm = 4.0271
	new_data_grads_norm = 6.0425
	old_data_grads_norm = 5.3907
	sim_grads_norm_tr = 0.0169
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6025
	data_grads_norm = 3.8995
	new_data_grads_norm = 5.9848
	old_data_grads_norm = 4.4676
	sim_grads_norm_tr = 0.0658
-- Starting training on experience 136 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4595
	data_grads_norm = 4.8473
	new_data_grads_norm = 6.9379
	old_data_grads_norm = 6.9148
	sim_grads_norm_tr = -0.0505
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7023
	data_grads_norm = 4.9255
	new_data_grads_norm = 7.2646
	old_data_grads_norm = 6.9804
	sim_grads_norm_tr = -0.0588
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6569
	data_grads_norm = 4.8706
	new_data_grads_norm = 7.1602
	old_data_grads_norm = 6.4089
	sim_grads_norm_tr = -0.0700
-- Starting training on experience 137 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7522
	data_grads_norm = 5.0122
	new_data_grads_norm = 6.3779
	old_data_grads_norm = 6.3393
	sim_grads_norm_tr = 0.0420
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6981
	data_grads_norm = 4.5175
	new_data_grads_norm = 6.6532
	old_data_grads_norm = 5.7332
	sim_grads_norm_tr = 0.0488
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1710
	data_grads_norm = 4.0002
	new_data_grads_norm = 5.8684
	old_data_grads_norm = 4.6406
	sim_grads_norm_tr = -0.0186
-- Starting training on experience 138 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8583
	data_grads_norm = 4.6311
	new_data_grads_norm = 6.9538
	old_data_grads_norm = 5.5199
	sim_grads_norm_tr = -0.0063
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2361
	data_grads_norm = 5.3893
	new_data_grads_norm = 6.9816
	old_data_grads_norm = 7.6623
	sim_grads_norm_tr = 0.0721
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5342
	data_grads_norm = 4.5659
	new_data_grads_norm = 6.8394
	old_data_grads_norm = 5.6383
	sim_grads_norm_tr = -0.0160
-- Starting training on experience 139 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2070
	data_grads_norm = 4.3419
	new_data_grads_norm = 6.8611
	old_data_grads_norm = 4.7042
	sim_grads_norm_tr = -0.0384
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3153
	data_grads_norm = 4.2884
	new_data_grads_norm = 6.4830
	old_data_grads_norm = 4.6781
	sim_grads_norm_tr = -0.0087
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4897
	data_grads_norm = 4.7285
	new_data_grads_norm = 6.6189
	old_data_grads_norm = 5.9304
	sim_grads_norm_tr = -0.0359
-- Starting training on experience 140 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4963
	data_grads_norm = 3.9663
	new_data_grads_norm = 5.3008
	old_data_grads_norm = 5.8579
	sim_grads_norm_tr = -0.0097
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6971
	data_grads_norm = 4.3094
	new_data_grads_norm = 6.2365
	old_data_grads_norm = 5.9768
	sim_grads_norm_tr = -0.0268
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8042
	data_grads_norm = 4.9031
	new_data_grads_norm = 6.0935
	old_data_grads_norm = 7.2746
	sim_grads_norm_tr = 0.0288
-- Starting training on experience 141 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9374
	data_grads_norm = 3.8916
	new_data_grads_norm = 5.9933
	old_data_grads_norm = 4.8863
	sim_grads_norm_tr = 0.0436
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0239
	data_grads_norm = 4.8418
	new_data_grads_norm = 6.4574
	old_data_grads_norm = 6.0502
	sim_grads_norm_tr = -0.0413
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9485
	data_grads_norm = 4.4112
	new_data_grads_norm = 6.6306
	old_data_grads_norm = 5.0467
	sim_grads_norm_tr = 0.1307
-- Starting training on experience 142 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5839
	data_grads_norm = 4.4192
	new_data_grads_norm = 6.1439
	old_data_grads_norm = 6.4103
	sim_grads_norm_tr = -0.0002
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3205
	data_grads_norm = 3.8382
	new_data_grads_norm = 6.5045
	old_data_grads_norm = 4.7246
	sim_grads_norm_tr = -0.0485
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4457
	data_grads_norm = 4.2346
	new_data_grads_norm = 6.5977
	old_data_grads_norm = 5.2994
	sim_grads_norm_tr = 0.0891
-- Starting training on experience 143 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2544
	data_grads_norm = 4.8373
	new_data_grads_norm = 7.3709
	old_data_grads_norm = 5.9016
	sim_grads_norm_tr = 0.0123
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1615
	data_grads_norm = 4.3659
	new_data_grads_norm = 7.4208
	old_data_grads_norm = 4.9287
	sim_grads_norm_tr = -0.0362
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2600
	data_grads_norm = 4.6835
	new_data_grads_norm = 7.4451
	old_data_grads_norm = 5.3741
	sim_grads_norm_tr = 0.0211
-- Starting training on experience 144 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0834
	data_grads_norm = 3.9951
	new_data_grads_norm = 5.2120
	old_data_grads_norm = 5.5584
	sim_grads_norm_tr = -0.0632
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1539
	data_grads_norm = 4.0492
	new_data_grads_norm = 5.2857
	old_data_grads_norm = 6.9986
	sim_grads_norm_tr = 0.0894
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2749
	data_grads_norm = 4.0558
	new_data_grads_norm = 5.2258
	old_data_grads_norm = 6.5831
	sim_grads_norm_tr = -0.0148
-- Starting training on experience 145 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8246
	data_grads_norm = 3.7563
	new_data_grads_norm = 5.2409
	old_data_grads_norm = 4.8089
	sim_grads_norm_tr = -0.0128
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4955
	data_grads_norm = 5.1650
	new_data_grads_norm = 5.3376
	old_data_grads_norm = 7.9513
	sim_grads_norm_tr = 0.0576
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4298
	data_grads_norm = 4.7481
	new_data_grads_norm = 5.9793
	old_data_grads_norm = 6.5836
	sim_grads_norm_tr = 0.0494
-- Starting training on experience 146 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9852
	data_grads_norm = 4.2877
	new_data_grads_norm = 5.9029
	old_data_grads_norm = 5.9490
	sim_grads_norm_tr = -0.0480
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8432
	data_grads_norm = 4.0367
	new_data_grads_norm = 6.3664
	old_data_grads_norm = 5.7347
	sim_grads_norm_tr = -0.0558
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1994
	data_grads_norm = 3.8637
	new_data_grads_norm = 6.3196
	old_data_grads_norm = 5.5779
	sim_grads_norm_tr = -0.1035
-- Starting training on experience 147 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4542
	data_grads_norm = 4.2899
	new_data_grads_norm = 7.0048
	old_data_grads_norm = 5.8696
	sim_grads_norm_tr = -0.0412
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0959
	data_grads_norm = 5.9691
	new_data_grads_norm = 7.7629
	old_data_grads_norm = 7.3273
	sim_grads_norm_tr = 0.0053
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9511
	data_grads_norm = 4.8651
	new_data_grads_norm = 7.9282
	old_data_grads_norm = 6.3147
	sim_grads_norm_tr = 0.0153
-- Starting training on experience 148 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1414
	data_grads_norm = 3.9777
	new_data_grads_norm = 6.1435
	old_data_grads_norm = 3.8926
	sim_grads_norm_tr = 0.0295
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5415
	data_grads_norm = 4.3938
	new_data_grads_norm = 6.5754
	old_data_grads_norm = 5.3373
	sim_grads_norm_tr = -0.0359
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7020
	data_grads_norm = 4.6817
	new_data_grads_norm = 6.3922
	old_data_grads_norm = 6.7321
	sim_grads_norm_tr = 0.0073
-- Starting training on experience 149 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6978
	data_grads_norm = 4.6180
	new_data_grads_norm = 5.5168
	old_data_grads_norm = 6.7794
	sim_grads_norm_tr = 0.0700
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2255
	data_grads_norm = 3.9099
	new_data_grads_norm = 5.4887
	old_data_grads_norm = 6.1400
	sim_grads_norm_tr = 0.0074
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2945
	data_grads_norm = 3.7464
	new_data_grads_norm = 5.7963
	old_data_grads_norm = 4.7660
	sim_grads_norm_tr = -0.0983
-- Starting training on experience 150 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9570
	data_grads_norm = 5.2166
	new_data_grads_norm = 6.3945
	old_data_grads_norm = 7.4825
	sim_grads_norm_tr = 0.1037
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4959
	data_grads_norm = 4.7241
	new_data_grads_norm = 6.1986
	old_data_grads_norm = 6.9247
	sim_grads_norm_tr = 0.0002
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1265
	data_grads_norm = 4.5266
	new_data_grads_norm = 5.6361
	old_data_grads_norm = 6.4451
	sim_grads_norm_tr = -0.0263
-- Starting training on experience 151 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0169
	data_grads_norm = 4.4730
	new_data_grads_norm = 7.2366
	old_data_grads_norm = 5.3590
	sim_grads_norm_tr = 0.0017
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8651
	data_grads_norm = 4.3235
	new_data_grads_norm = 7.5223
	old_data_grads_norm = 5.6730
	sim_grads_norm_tr = -0.0047
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2757
	data_grads_norm = 5.4071
	new_data_grads_norm = 8.0267
	old_data_grads_norm = 5.4401
	sim_grads_norm_tr = 0.0552
-- Starting training on experience 152 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5691
	data_grads_norm = 5.0006
	new_data_grads_norm = 7.5161
	old_data_grads_norm = 6.1563
	sim_grads_norm_tr = -0.0134
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6847
	data_grads_norm = 4.9251
	new_data_grads_norm = 7.3159
	old_data_grads_norm = 6.7318
	sim_grads_norm_tr = -0.0195
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5737
	data_grads_norm = 5.1567
	new_data_grads_norm = 7.7986
	old_data_grads_norm = 6.3930
	sim_grads_norm_tr = -0.0166
-- Starting training on experience 153 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4484
	data_grads_norm = 4.7784
	new_data_grads_norm = 6.4589
	old_data_grads_norm = 6.7806
	sim_grads_norm_tr = 0.0307
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7778
	data_grads_norm = 3.6274
	new_data_grads_norm = 6.5719
	old_data_grads_norm = 3.6500
	sim_grads_norm_tr = -0.0663
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9125
	data_grads_norm = 5.4801
	new_data_grads_norm = 7.0103
	old_data_grads_norm = 7.3087
	sim_grads_norm_tr = 0.0463
-- Starting training on experience 154 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3748
	data_grads_norm = 4.8661
	new_data_grads_norm = 5.7019
	old_data_grads_norm = 7.0219
	sim_grads_norm_tr = 0.0123
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8110
	data_grads_norm = 5.1216
	new_data_grads_norm = 6.3396
	old_data_grads_norm = 6.3263
	sim_grads_norm_tr = 0.1523
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0432
	data_grads_norm = 3.4316
	new_data_grads_norm = 5.6238
	old_data_grads_norm = 4.2608
	sim_grads_norm_tr = 0.0104
-- Starting training on experience 155 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7706
	data_grads_norm = 4.0481
	new_data_grads_norm = 6.0112
	old_data_grads_norm = 5.5977
	sim_grads_norm_tr = -0.0069
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1795
	data_grads_norm = 4.3989
	new_data_grads_norm = 6.3176
	old_data_grads_norm = 6.1720
	sim_grads_norm_tr = 0.0013
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7071
	data_grads_norm = 3.6142
	new_data_grads_norm = 6.2411
	old_data_grads_norm = 4.1887
	sim_grads_norm_tr = -0.0208
-- Starting training on experience 156 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2218
	data_grads_norm = 4.2836
	new_data_grads_norm = 6.0626
	old_data_grads_norm = 6.0263
	sim_grads_norm_tr = 0.0197
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0055
	data_grads_norm = 3.8230
	new_data_grads_norm = 5.4005
	old_data_grads_norm = 5.1024
	sim_grads_norm_tr = 0.0165
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9606
	data_grads_norm = 4.3521
	new_data_grads_norm = 6.4643
	old_data_grads_norm = 5.0425
	sim_grads_norm_tr = 0.0110
-- Starting training on experience 157 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8393
	data_grads_norm = 4.1367
	new_data_grads_norm = 5.7232
	old_data_grads_norm = 5.9127
	sim_grads_norm_tr = 0.0339
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9403
	data_grads_norm = 4.0245
	new_data_grads_norm = 6.1787
	old_data_grads_norm = 5.6240
	sim_grads_norm_tr = 0.0977
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9153
	data_grads_norm = 3.6930
	new_data_grads_norm = 5.9006
	old_data_grads_norm = 5.1801
	sim_grads_norm_tr = -0.0509
-- Starting training on experience 158 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7202
	data_grads_norm = 5.5359
	new_data_grads_norm = 7.8345
	old_data_grads_norm = 6.8032
	sim_grads_norm_tr = -0.0529
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5791
	data_grads_norm = 5.3121
	new_data_grads_norm = 7.3244
	old_data_grads_norm = 7.2016
	sim_grads_norm_tr = 0.0800
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4294
	data_grads_norm = 4.9054
	new_data_grads_norm = 7.9147
	old_data_grads_norm = 5.4434
	sim_grads_norm_tr = 0.0959
-- Starting training on experience 159 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4551
	data_grads_norm = 5.0061
	new_data_grads_norm = 7.5967
	old_data_grads_norm = 5.0776
	sim_grads_norm_tr = 0.0665
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3223
	data_grads_norm = 5.2343
	new_data_grads_norm = 7.4648
	old_data_grads_norm = 5.7084
	sim_grads_norm_tr = -0.0129
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6776
	data_grads_norm = 4.7474
	new_data_grads_norm = 7.2096
	old_data_grads_norm = 5.3219
	sim_grads_norm_tr = 0.0045
-- Starting training on experience 160 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1769
	data_grads_norm = 3.6443
	new_data_grads_norm = 5.9353
	old_data_grads_norm = 4.4687
	sim_grads_norm_tr = 0.0374
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1055
	data_grads_norm = 4.5444
	new_data_grads_norm = 6.4215
	old_data_grads_norm = 5.9153
	sim_grads_norm_tr = -0.0512
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0374
	data_grads_norm = 4.3001
	new_data_grads_norm = 7.1966
	old_data_grads_norm = 5.1008
	sim_grads_norm_tr = -0.0249
-- Starting training on experience 161 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4165
	data_grads_norm = 4.1353
	new_data_grads_norm = 6.0811
	old_data_grads_norm = 4.3721
	sim_grads_norm_tr = 0.0864
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0207
	data_grads_norm = 4.6211
	new_data_grads_norm = 6.2753
	old_data_grads_norm = 6.5456
	sim_grads_norm_tr = -0.0398
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6095
	data_grads_norm = 4.8032
	new_data_grads_norm = 6.2184
	old_data_grads_norm = 7.2520
	sim_grads_norm_tr = 0.0338
-- Starting training on experience 162 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9996
	data_grads_norm = 5.9266
	new_data_grads_norm = 5.7291
	old_data_grads_norm = 9.4694
	sim_grads_norm_tr = -0.0107
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7944
	data_grads_norm = 4.1372
	new_data_grads_norm = 6.0550
	old_data_grads_norm = 5.2809
	sim_grads_norm_tr = 0.0173
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8095
	data_grads_norm = 5.0770
	new_data_grads_norm = 5.3540
	old_data_grads_norm = 6.1649
	sim_grads_norm_tr = 0.1933
-- Starting training on experience 163 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0158
	data_grads_norm = 4.4439
	new_data_grads_norm = 7.1072
	old_data_grads_norm = 5.9340
	sim_grads_norm_tr = 0.0541
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9186
	data_grads_norm = 4.5780
	new_data_grads_norm = 7.0771
	old_data_grads_norm = 5.6890
	sim_grads_norm_tr = -0.1187
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7791
	data_grads_norm = 4.7047
	new_data_grads_norm = 7.9121
	old_data_grads_norm = 4.7320
	sim_grads_norm_tr = 0.1213
-- Starting training on experience 164 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9347
	data_grads_norm = 4.0707
	new_data_grads_norm = 7.8495
	old_data_grads_norm = 4.8804
	sim_grads_norm_tr = -0.0022
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5229
	data_grads_norm = 5.4512
	new_data_grads_norm = 6.6383
	old_data_grads_norm = 7.4982
	sim_grads_norm_tr = 0.0006
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4713
	data_grads_norm = 4.7714
	new_data_grads_norm = 6.9641
	old_data_grads_norm = 6.4513
	sim_grads_norm_tr = -0.0667
-- Starting training on experience 165 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0869
	data_grads_norm = 4.7026
	new_data_grads_norm = 7.0229
	old_data_grads_norm = 5.9395
	sim_grads_norm_tr = -0.0122
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1313
	data_grads_norm = 4.6217
	new_data_grads_norm = 6.8882
	old_data_grads_norm = 5.8819
	sim_grads_norm_tr = -0.0284
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3979
	data_grads_norm = 5.3156
	new_data_grads_norm = 7.4818
	old_data_grads_norm = 6.4979
	sim_grads_norm_tr = 0.0325
-- Starting training on experience 166 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0182
	data_grads_norm = 5.2180
	new_data_grads_norm = 7.3194
	old_data_grads_norm = 6.9957
	sim_grads_norm_tr = -0.0087
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0089
	data_grads_norm = 5.5492
	new_data_grads_norm = 8.3673
	old_data_grads_norm = 6.9066
	sim_grads_norm_tr = -0.0162
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9187
	data_grads_norm = 4.8643
	new_data_grads_norm = 7.4821
	old_data_grads_norm = 7.6322
	sim_grads_norm_tr = -0.0202
-- Starting training on experience 167 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8670
	data_grads_norm = 5.7375
	new_data_grads_norm = 7.7947
	old_data_grads_norm = 7.0499
	sim_grads_norm_tr = 0.0468
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8814
	data_grads_norm = 4.0373
	new_data_grads_norm = 6.9534
	old_data_grads_norm = 6.1915
	sim_grads_norm_tr = -0.0437
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7880
	data_grads_norm = 5.4418
	new_data_grads_norm = 6.7809
	old_data_grads_norm = 7.1191
	sim_grads_norm_tr = 0.0809
-- Starting training on experience 168 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1839
	data_grads_norm = 4.1766
	new_data_grads_norm = 5.6082
	old_data_grads_norm = 5.7492
	sim_grads_norm_tr = -0.0029
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0941
	data_grads_norm = 4.3730
	new_data_grads_norm = 5.3393
	old_data_grads_norm = 5.9759
	sim_grads_norm_tr = -0.0567
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2103
	data_grads_norm = 4.0731
	new_data_grads_norm = 6.8284
	old_data_grads_norm = 5.1998
	sim_grads_norm_tr = -0.0786
-- Starting training on experience 169 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1063
	data_grads_norm = 4.3564
	new_data_grads_norm = 6.7738
	old_data_grads_norm = 6.0711
	sim_grads_norm_tr = -0.0394
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3136
	data_grads_norm = 4.9327
	new_data_grads_norm = 6.5572
	old_data_grads_norm = 6.8528
	sim_grads_norm_tr = 0.0010
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6924
	data_grads_norm = 5.3559
	new_data_grads_norm = 6.9507
	old_data_grads_norm = 7.0829
	sim_grads_norm_tr = 0.0627
-- Starting training on experience 170 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4692
	data_grads_norm = 4.1717
	new_data_grads_norm = 6.0142
	old_data_grads_norm = 5.1026
	sim_grads_norm_tr = 0.0131
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3893
	data_grads_norm = 4.4385
	new_data_grads_norm = 6.1893
	old_data_grads_norm = 5.8357
	sim_grads_norm_tr = 0.0894
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4603
	data_grads_norm = 4.4873
	new_data_grads_norm = 5.9927
	old_data_grads_norm = 7.4399
	sim_grads_norm_tr = 0.0648
-- Starting training on experience 171 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5200
	data_grads_norm = 4.3086
	new_data_grads_norm = 5.5811
	old_data_grads_norm = 6.7280
	sim_grads_norm_tr = -0.0830
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7440
	data_grads_norm = 4.2452
	new_data_grads_norm = 6.1549
	old_data_grads_norm = 6.2137
	sim_grads_norm_tr = -0.0366
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7447
	data_grads_norm = 4.8668
	new_data_grads_norm = 6.4037
	old_data_grads_norm = 7.4036
	sim_grads_norm_tr = -0.0211
-- Starting training on experience 172 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1382
	data_grads_norm = 4.1037
	new_data_grads_norm = 5.9183
	old_data_grads_norm = 5.8526
	sim_grads_norm_tr = -0.0052
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9428
	data_grads_norm = 3.7965
	new_data_grads_norm = 5.8499
	old_data_grads_norm = 4.7464
	sim_grads_norm_tr = -0.0763
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1662
	data_grads_norm = 4.0028
	new_data_grads_norm = 5.7077
	old_data_grads_norm = 5.2125
	sim_grads_norm_tr = 0.0359
-- Starting training on experience 173 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8838
	data_grads_norm = 4.2100
	new_data_grads_norm = 6.4196
	old_data_grads_norm = 6.0134
	sim_grads_norm_tr = 0.0660
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5335
	data_grads_norm = 4.8615
	new_data_grads_norm = 6.0389
	old_data_grads_norm = 6.8755
	sim_grads_norm_tr = 0.0690
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9193
	data_grads_norm = 4.3581
	new_data_grads_norm = 6.2513
	old_data_grads_norm = 6.8119
	sim_grads_norm_tr = -0.0198
-- Starting training on experience 174 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0513
	data_grads_norm = 5.1068
	new_data_grads_norm = 7.6215
	old_data_grads_norm = 5.6157
	sim_grads_norm_tr = 0.0379
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0582
	data_grads_norm = 5.0032
	new_data_grads_norm = 7.5380
	old_data_grads_norm = 6.2042
	sim_grads_norm_tr = 0.0034
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1779
	data_grads_norm = 5.3488
	new_data_grads_norm = 7.0702
	old_data_grads_norm = 6.8086
	sim_grads_norm_tr = 0.1027
-- Starting training on experience 175 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0348
	data_grads_norm = 3.9468
	new_data_grads_norm = 7.4907
	old_data_grads_norm = 4.6099
	sim_grads_norm_tr = 0.0070
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3918
	data_grads_norm = 4.6851
	new_data_grads_norm = 6.7492
	old_data_grads_norm = 5.3556
	sim_grads_norm_tr = 0.1124
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6829
	data_grads_norm = 5.4631
	new_data_grads_norm = 7.2225
	old_data_grads_norm = 7.3815
	sim_grads_norm_tr = 0.0285
-- Starting training on experience 176 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5461
	data_grads_norm = 4.0300
	new_data_grads_norm = 5.8110
	old_data_grads_norm = 4.6882
	sim_grads_norm_tr = 0.0056
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3433
	data_grads_norm = 4.2532
	new_data_grads_norm = 5.8053
	old_data_grads_norm = 6.3838
	sim_grads_norm_tr = -0.0558
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7263
	data_grads_norm = 4.5997
	new_data_grads_norm = 6.5109
	old_data_grads_norm = 6.0550
	sim_grads_norm_tr = 0.1070
-- Starting training on experience 177 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9524
	data_grads_norm = 3.4847
	new_data_grads_norm = 4.7260
	old_data_grads_norm = 4.2328
	sim_grads_norm_tr = -0.0530
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6912
	data_grads_norm = 4.5924
	new_data_grads_norm = 5.1602
	old_data_grads_norm = 7.1482
	sim_grads_norm_tr = 0.0825
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3121
	data_grads_norm = 4.0653
	new_data_grads_norm = 4.8601
	old_data_grads_norm = 5.5957
	sim_grads_norm_tr = 0.0631
-- Starting training on experience 178 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4037
	data_grads_norm = 4.3096
	new_data_grads_norm = 5.3863
	old_data_grads_norm = 6.8178
	sim_grads_norm_tr = -0.0260
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5329
	data_grads_norm = 4.6754
	new_data_grads_norm = 6.1384
	old_data_grads_norm = 5.8205
	sim_grads_norm_tr = 0.1036
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9346
	data_grads_norm = 3.9835
	new_data_grads_norm = 5.7061
	old_data_grads_norm = 5.4877
	sim_grads_norm_tr = -0.0138
-- Starting training on experience 179 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6902
	data_grads_norm = 4.4269
	new_data_grads_norm = 5.2561
	old_data_grads_norm = 7.3916
	sim_grads_norm_tr = -0.0672
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2068
	data_grads_norm = 4.3144
	new_data_grads_norm = 5.7693
	old_data_grads_norm = 5.2641
	sim_grads_norm_tr = 0.0662
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2132
	data_grads_norm = 3.9527
	new_data_grads_norm = 6.0834
	old_data_grads_norm = 4.7470
	sim_grads_norm_tr = 0.0152
-- Starting training on experience 180 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1327
	data_grads_norm = 3.8893
	new_data_grads_norm = 5.6393
	old_data_grads_norm = 4.9816
	sim_grads_norm_tr = 0.0622
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6962
	data_grads_norm = 3.7523
	new_data_grads_norm = 6.3997
	old_data_grads_norm = 4.9614
	sim_grads_norm_tr = -0.0145
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1707
	data_grads_norm = 4.3542
	new_data_grads_norm = 6.4293
	old_data_grads_norm = 6.2332
	sim_grads_norm_tr = 0.0306
-- Starting training on experience 181 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2548
	data_grads_norm = 4.3315
	new_data_grads_norm = 6.3109
	old_data_grads_norm = 5.1394
	sim_grads_norm_tr = 0.0020
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2974
	data_grads_norm = 4.3150
	new_data_grads_norm = 6.5607
	old_data_grads_norm = 4.9664
	sim_grads_norm_tr = 0.0703
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1931
	data_grads_norm = 4.6436
	new_data_grads_norm = 6.1724
	old_data_grads_norm = 6.3743
	sim_grads_norm_tr = 0.0563
-- Starting training on experience 182 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1592
	data_grads_norm = 4.4892
	new_data_grads_norm = 6.2774
	old_data_grads_norm = 6.2310
	sim_grads_norm_tr = -0.0346
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1202
	data_grads_norm = 4.5255
	new_data_grads_norm = 6.4389
	old_data_grads_norm = 5.9926
	sim_grads_norm_tr = -0.0256
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0309
	data_grads_norm = 4.2059
	new_data_grads_norm = 6.1598
	old_data_grads_norm = 5.9605
	sim_grads_norm_tr = -0.0276
-- Starting training on experience 183 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6166
	data_grads_norm = 5.1400
	new_data_grads_norm = 7.1031
	old_data_grads_norm = 6.2113
	sim_grads_norm_tr = 0.0542
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7604
	data_grads_norm = 5.3568
	new_data_grads_norm = 7.1596
	old_data_grads_norm = 6.4634
	sim_grads_norm_tr = 0.1677
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7327
	data_grads_norm = 5.1778
	new_data_grads_norm = 7.2962
	old_data_grads_norm = 7.0369
	sim_grads_norm_tr = 0.0438
-- Starting training on experience 184 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0417
	data_grads_norm = 4.1911
	new_data_grads_norm = 6.2767
	old_data_grads_norm = 4.9877
	sim_grads_norm_tr = -0.0039
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0744
	data_grads_norm = 4.3331
	new_data_grads_norm = 6.0376
	old_data_grads_norm = 5.5604
	sim_grads_norm_tr = -0.0257
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7795
	data_grads_norm = 4.1188
	new_data_grads_norm = 5.9634
	old_data_grads_norm = 5.7196
	sim_grads_norm_tr = 0.0400
-- Starting training on experience 185 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0292
	data_grads_norm = 4.8223
	new_data_grads_norm = 6.5662
	old_data_grads_norm = 7.2557
	sim_grads_norm_tr = 0.0238
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6796
	data_grads_norm = 5.6259
	new_data_grads_norm = 6.5825
	old_data_grads_norm = 9.0210
	sim_grads_norm_tr = -0.0232
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8820
	data_grads_norm = 3.9528
	new_data_grads_norm = 6.1774
	old_data_grads_norm = 5.7560
	sim_grads_norm_tr = -0.0297
-- Starting training on experience 186 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3221
	data_grads_norm = 5.0219
	new_data_grads_norm = 6.5918
	old_data_grads_norm = 6.1047
	sim_grads_norm_tr = 0.1938
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9722
	data_grads_norm = 4.2557
	new_data_grads_norm = 5.7876
	old_data_grads_norm = 6.3314
	sim_grads_norm_tr = -0.0222
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7812
	data_grads_norm = 4.3054
	new_data_grads_norm = 5.8962
	old_data_grads_norm = 5.3216
	sim_grads_norm_tr = -0.0381
-- Starting training on experience 187 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2119
	data_grads_norm = 5.2665
	new_data_grads_norm = 8.3285
	old_data_grads_norm = 6.2064
	sim_grads_norm_tr = -0.0157
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5569
	data_grads_norm = 6.5919
	new_data_grads_norm = 9.7000
	old_data_grads_norm = 7.7054
	sim_grads_norm_tr = -0.0076
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9509
	data_grads_norm = 5.2966
	new_data_grads_norm = 8.3288
	old_data_grads_norm = 6.3278
	sim_grads_norm_tr = 0.0427
-- Starting training on experience 188 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3770
	data_grads_norm = 4.7249
	new_data_grads_norm = 6.2292
	old_data_grads_norm = 6.6804
	sim_grads_norm_tr = -0.0449
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5320
	data_grads_norm = 5.7984
	new_data_grads_norm = 8.1508
	old_data_grads_norm = 6.0418
	sim_grads_norm_tr = 0.1434
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5597
	data_grads_norm = 2.9928
	new_data_grads_norm = 6.6759
	old_data_grads_norm = 2.6420
	sim_grads_norm_tr = -0.1339
-- Starting training on experience 189 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0812
	data_grads_norm = 5.2563
	new_data_grads_norm = 6.4718
	old_data_grads_norm = 5.6492
	sim_grads_norm_tr = 0.1176
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6189
	data_grads_norm = 5.0383
	new_data_grads_norm = 6.7701
	old_data_grads_norm = 6.1101
	sim_grads_norm_tr = -0.0296
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4985
	data_grads_norm = 4.5873
	new_data_grads_norm = 5.9232
	old_data_grads_norm = 6.2186
	sim_grads_norm_tr = 0.0108
-- Starting training on experience 190 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4601
	data_grads_norm = 4.5326
	new_data_grads_norm = 5.6583
	old_data_grads_norm = 6.3832
	sim_grads_norm_tr = 0.0477
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4866
	data_grads_norm = 4.8027
	new_data_grads_norm = 5.9373
	old_data_grads_norm = 6.2032
	sim_grads_norm_tr = 0.0293
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3261
	data_grads_norm = 4.3758
	new_data_grads_norm = 5.8537
	old_data_grads_norm = 6.3009
	sim_grads_norm_tr = 0.0264
-- Starting training on experience 191 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0005
	data_grads_norm = 5.0761
	new_data_grads_norm = 7.3515
	old_data_grads_norm = 6.7534
	sim_grads_norm_tr = -0.0592
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3078
	data_grads_norm = 5.0568
	new_data_grads_norm = 7.4020
	old_data_grads_norm = 6.2281
	sim_grads_norm_tr = 0.0361
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3696
	data_grads_norm = 5.5996
	new_data_grads_norm = 7.2536
	old_data_grads_norm = 7.0601
	sim_grads_norm_tr = 0.0789
-- Starting training on experience 192 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9382
	data_grads_norm = 5.0203
	new_data_grads_norm = 7.6456
	old_data_grads_norm = 6.3259
	sim_grads_norm_tr = -0.0590
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3470
	data_grads_norm = 4.7331
	new_data_grads_norm = 8.3270
	old_data_grads_norm = 5.2992
	sim_grads_norm_tr = -0.0088
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9786
	data_grads_norm = 5.6459
	new_data_grads_norm = 7.4745
	old_data_grads_norm = 7.3364
	sim_grads_norm_tr = 0.0590
-- Starting training on experience 193 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6380
	data_grads_norm = 5.0159
	new_data_grads_norm = 8.0416
	old_data_grads_norm = 5.1770
	sim_grads_norm_tr = 0.0833
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3636
	data_grads_norm = 4.7379
	new_data_grads_norm = 7.8469
	old_data_grads_norm = 5.8546
	sim_grads_norm_tr = -0.0861
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4914
	data_grads_norm = 5.0672
	new_data_grads_norm = 8.1558
	old_data_grads_norm = 5.9955
	sim_grads_norm_tr = 0.0518
-- Starting training on experience 194 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3700
	data_grads_norm = 5.6587
	new_data_grads_norm = 6.3437
	old_data_grads_norm = 8.2411
	sim_grads_norm_tr = 0.0304
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0277
	data_grads_norm = 4.7660
	new_data_grads_norm = 6.3362
	old_data_grads_norm = 7.4552
	sim_grads_norm_tr = 0.0238
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4708
	data_grads_norm = 6.2037
	new_data_grads_norm = 6.2438
	old_data_grads_norm = 8.9592
	sim_grads_norm_tr = 0.0938
-- Starting training on experience 195 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1069
	data_grads_norm = 3.9112
	new_data_grads_norm = 6.1004
	old_data_grads_norm = 4.8627
	sim_grads_norm_tr = -0.0149
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1780
	data_grads_norm = 4.3110
	new_data_grads_norm = 6.5805
	old_data_grads_norm = 5.7037
	sim_grads_norm_tr = -0.0238
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0474
	data_grads_norm = 4.1214
	new_data_grads_norm = 6.5031
	old_data_grads_norm = 5.4755
	sim_grads_norm_tr = -0.0005
-- Starting training on experience 196 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3749
	data_grads_norm = 4.4480
	new_data_grads_norm = 6.3100
	old_data_grads_norm = 5.5132
	sim_grads_norm_tr = 0.0744
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7123
	data_grads_norm = 4.6911
	new_data_grads_norm = 6.6505
	old_data_grads_norm = 6.0509
	sim_grads_norm_tr = 0.0745
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3244
	data_grads_norm = 4.4897
	new_data_grads_norm = 5.1656
	old_data_grads_norm = 6.8545
	sim_grads_norm_tr = 0.0435
-- Starting training on experience 197 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2048
	data_grads_norm = 4.6623
	new_data_grads_norm = 6.3878
	old_data_grads_norm = 5.6503
	sim_grads_norm_tr = 0.0026
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0045
	data_grads_norm = 4.2705
	new_data_grads_norm = 6.5569
	old_data_grads_norm = 4.9808
	sim_grads_norm_tr = 0.0090
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2220
	data_grads_norm = 4.3197
	new_data_grads_norm = 6.9244
	old_data_grads_norm = 5.1148
	sim_grads_norm_tr = -0.1018
-- Starting training on experience 198 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2498
	data_grads_norm = 5.1413
	new_data_grads_norm = 6.7261
	old_data_grads_norm = 6.7062
	sim_grads_norm_tr = 0.0152
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9000
	data_grads_norm = 4.4181
	new_data_grads_norm = 6.4689
	old_data_grads_norm = 5.5629
	sim_grads_norm_tr = -0.0233
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2800
	data_grads_norm = 5.7759
	new_data_grads_norm = 7.0085
	old_data_grads_norm = 7.9103
	sim_grads_norm_tr = 0.1547
-- Starting training on experience 199 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5025
	data_grads_norm = 5.0988
	new_data_grads_norm = 6.7101
	old_data_grads_norm = 7.5271
	sim_grads_norm_tr = 0.0367
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3764
	data_grads_norm = 4.8961
	new_data_grads_norm = 7.0167
	old_data_grads_norm = 6.8440
	sim_grads_norm_tr = 0.0458
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0632
	data_grads_norm = 4.3741
	new_data_grads_norm = 7.0164
	old_data_grads_norm = 6.0049
	sim_grads_norm_tr = -0.0489
-- Starting training on experience 200 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7983
	data_grads_norm = 5.4712
	new_data_grads_norm = 6.6322
	old_data_grads_norm = 7.6288
	sim_grads_norm_tr = 0.0870
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1527
	data_grads_norm = 4.7518
	new_data_grads_norm = 6.5016
	old_data_grads_norm = 6.2291
	sim_grads_norm_tr = -0.0220
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5770
	data_grads_norm = 5.3553
	new_data_grads_norm = 6.3231
	old_data_grads_norm = 8.4851
	sim_grads_norm_tr = -0.0446
-- Starting training on experience 201 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4430
	data_grads_norm = 4.9140
	new_data_grads_norm = 6.5513
	old_data_grads_norm = 6.9558
	sim_grads_norm_tr = -0.0100
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9405
	data_grads_norm = 5.0072
	new_data_grads_norm = 6.4243
	old_data_grads_norm = 7.8555
	sim_grads_norm_tr = 0.0039
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6932
	data_grads_norm = 5.1443
	new_data_grads_norm = 6.7320
	old_data_grads_norm = 7.4935
	sim_grads_norm_tr = -0.0432
-- Starting training on experience 202 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3788
	data_grads_norm = 4.7441
	new_data_grads_norm = 7.8733
	old_data_grads_norm = 5.6711
	sim_grads_norm_tr = -0.0370
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8954
	data_grads_norm = 5.5074
	new_data_grads_norm = 7.4406
	old_data_grads_norm = 6.7348
	sim_grads_norm_tr = -0.0233
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7721
	data_grads_norm = 4.7671
	new_data_grads_norm = 7.5290
	old_data_grads_norm = 5.8485
	sim_grads_norm_tr = 0.0317
-- Starting training on experience 203 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9217
	data_grads_norm = 3.8014
	new_data_grads_norm = 6.0891
	old_data_grads_norm = 3.9932
	sim_grads_norm_tr = 0.0802
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9058
	data_grads_norm = 3.7035
	new_data_grads_norm = 5.2871
	old_data_grads_norm = 4.7076
	sim_grads_norm_tr = 0.0179
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5604
	data_grads_norm = 4.8454
	new_data_grads_norm = 5.8762
	old_data_grads_norm = 7.2194
	sim_grads_norm_tr = 0.0318
-- Starting training on experience 204 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8210
	data_grads_norm = 3.8090
	new_data_grads_norm = 5.9580
	old_data_grads_norm = 4.6806
	sim_grads_norm_tr = 0.0188
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1923
	data_grads_norm = 4.1129
	new_data_grads_norm = 6.3374
	old_data_grads_norm = 5.0923
	sim_grads_norm_tr = 0.0490
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3801
	data_grads_norm = 4.4472
	new_data_grads_norm = 6.5390
	old_data_grads_norm = 6.1733
	sim_grads_norm_tr = -0.0099
-- Starting training on experience 205 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0787
	data_grads_norm = 4.2964
	new_data_grads_norm = 6.7193
	old_data_grads_norm = 5.3191
	sim_grads_norm_tr = 0.0820
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4080
	data_grads_norm = 4.7110
	new_data_grads_norm = 6.8328
	old_data_grads_norm = 6.4313
	sim_grads_norm_tr = 0.0687
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3841
	data_grads_norm = 4.4797
	new_data_grads_norm = 6.4752
	old_data_grads_norm = 6.4128
	sim_grads_norm_tr = 0.0383
-- Starting training on experience 206 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3473
	data_grads_norm = 4.3127
	new_data_grads_norm = 6.1235
	old_data_grads_norm = 5.1686
	sim_grads_norm_tr = 0.0052
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1162
	data_grads_norm = 4.4297
	new_data_grads_norm = 6.5809
	old_data_grads_norm = 4.9384
	sim_grads_norm_tr = 0.0549
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4843
	data_grads_norm = 4.8194
	new_data_grads_norm = 6.0864
	old_data_grads_norm = 6.2903
	sim_grads_norm_tr = 0.0397
-- Starting training on experience 207 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5127
	data_grads_norm = 3.9992
	new_data_grads_norm = 5.2966
	old_data_grads_norm = 5.1682
	sim_grads_norm_tr = 0.0318
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2160
	data_grads_norm = 4.2566
	new_data_grads_norm = 6.1381
	old_data_grads_norm = 6.7093
	sim_grads_norm_tr = -0.0161
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3672
	data_grads_norm = 4.1621
	new_data_grads_norm = 5.7051
	old_data_grads_norm = 6.5451
	sim_grads_norm_tr = -0.0257
-- Starting training on experience 208 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3147
	data_grads_norm = 4.6480
	new_data_grads_norm = 5.9915
	old_data_grads_norm = 6.6840
	sim_grads_norm_tr = 0.1048
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6451
	data_grads_norm = 3.9963
	new_data_grads_norm = 6.6153
	old_data_grads_norm = 4.2424
	sim_grads_norm_tr = 0.0183
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8512
	data_grads_norm = 4.5840
	new_data_grads_norm = 5.8682
	old_data_grads_norm = 7.0547
	sim_grads_norm_tr = 0.0170
-- Starting training on experience 209 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9856
	data_grads_norm = 4.5441
	new_data_grads_norm = 5.8683
	old_data_grads_norm = 6.3675
	sim_grads_norm_tr = 0.0062
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0643
	data_grads_norm = 3.9394
	new_data_grads_norm = 5.4102
	old_data_grads_norm = 5.3936
	sim_grads_norm_tr = 0.0219
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8213
	data_grads_norm = 5.0622
	new_data_grads_norm = 6.2049
	old_data_grads_norm = 7.7393
	sim_grads_norm_tr = -0.0002
-- Starting training on experience 210 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8165
	data_grads_norm = 3.6666
	new_data_grads_norm = 5.4756
	old_data_grads_norm = 4.6963
	sim_grads_norm_tr = -0.0773
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1518
	data_grads_norm = 4.2010
	new_data_grads_norm = 5.7510
	old_data_grads_norm = 5.9051
	sim_grads_norm_tr = 0.0194
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1627
	data_grads_norm = 4.2671
	new_data_grads_norm = 5.7937
	old_data_grads_norm = 6.2687
	sim_grads_norm_tr = -0.0229
-- Starting training on experience 211 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8750
	data_grads_norm = 3.4582
	new_data_grads_norm = 5.6836
	old_data_grads_norm = 4.1292
	sim_grads_norm_tr = -0.0722
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6115
	data_grads_norm = 4.5134
	new_data_grads_norm = 5.6364
	old_data_grads_norm = 6.4444
	sim_grads_norm_tr = -0.0549
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3858
	data_grads_norm = 4.6519
	new_data_grads_norm = 7.2367
	old_data_grads_norm = 4.6028
	sim_grads_norm_tr = 0.0696
-- Starting training on experience 212 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7751
	data_grads_norm = 3.6712
	new_data_grads_norm = 6.1657
	old_data_grads_norm = 4.6197
	sim_grads_norm_tr = -0.1288
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0256
	data_grads_norm = 4.2091
	new_data_grads_norm = 6.4904
	old_data_grads_norm = 6.3210
	sim_grads_norm_tr = 0.0272
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1852
	data_grads_norm = 4.8903
	new_data_grads_norm = 6.4800
	old_data_grads_norm = 6.6807
	sim_grads_norm_tr = -0.0475
-- Starting training on experience 213 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8325
	data_grads_norm = 4.2536
	new_data_grads_norm = 5.4773
	old_data_grads_norm = 6.2884
	sim_grads_norm_tr = -0.0045
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1847
	data_grads_norm = 4.4107
	new_data_grads_norm = 5.8903
	old_data_grads_norm = 6.7218
	sim_grads_norm_tr = 0.0436
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0947
	data_grads_norm = 4.2680
	new_data_grads_norm = 5.3870
	old_data_grads_norm = 6.2905
	sim_grads_norm_tr = 0.0018
-- Starting training on experience 214 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2565
	data_grads_norm = 4.8046
	new_data_grads_norm = 7.2277
	old_data_grads_norm = 5.0575
	sim_grads_norm_tr = 0.0153
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7987
	data_grads_norm = 4.4325
	new_data_grads_norm = 7.0161
	old_data_grads_norm = 6.0174
	sim_grads_norm_tr = 0.0398
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0453
	data_grads_norm = 4.3262
	new_data_grads_norm = 6.6089
	old_data_grads_norm = 5.3544
	sim_grads_norm_tr = 0.0177
-- Starting training on experience 215 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1464
	data_grads_norm = 4.5984
	new_data_grads_norm = 6.0928
	old_data_grads_norm = 6.7466
	sim_grads_norm_tr = -0.0551
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2550
	data_grads_norm = 4.2595
	new_data_grads_norm = 6.2762
	old_data_grads_norm = 6.2453
	sim_grads_norm_tr = -0.0594
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9021
	data_grads_norm = 3.9781
	new_data_grads_norm = 6.8278
	old_data_grads_norm = 5.0635
	sim_grads_norm_tr = 0.0279
-- Starting training on experience 216 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9446
	data_grads_norm = 3.8534
	new_data_grads_norm = 5.8579
	old_data_grads_norm = 5.2433
	sim_grads_norm_tr = -0.0057
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8842
	data_grads_norm = 4.1908
	new_data_grads_norm = 7.1385
	old_data_grads_norm = 4.3587
	sim_grads_norm_tr = 0.0282
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0978
	data_grads_norm = 4.6874
	new_data_grads_norm = 6.5884
	old_data_grads_norm = 4.5166
	sim_grads_norm_tr = 0.1529
-- Starting training on experience 217 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0990
	data_grads_norm = 4.7861
	new_data_grads_norm = 6.8916
	old_data_grads_norm = 6.3224
	sim_grads_norm_tr = 0.0395
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8332
	data_grads_norm = 4.2990
	new_data_grads_norm = 6.0220
	old_data_grads_norm = 5.8935
	sim_grads_norm_tr = -0.0721
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2973
	data_grads_norm = 4.3626
	new_data_grads_norm = 7.0914
	old_data_grads_norm = 4.3890
	sim_grads_norm_tr = 0.0820
-- Starting training on experience 218 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5352
	data_grads_norm = 5.2940
	new_data_grads_norm = 6.3022
	old_data_grads_norm = 7.9924
	sim_grads_norm_tr = -0.0038
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1062
	data_grads_norm = 3.7523
	new_data_grads_norm = 5.9449
	old_data_grads_norm = 4.2348
	sim_grads_norm_tr = 0.0803
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0813
	data_grads_norm = 3.8043
	new_data_grads_norm = 5.7767
	old_data_grads_norm = 5.5387
	sim_grads_norm_tr = -0.0464
-- Starting training on experience 219 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9046
	data_grads_norm = 5.1542
	new_data_grads_norm = 7.1378
	old_data_grads_norm = 6.4759
	sim_grads_norm_tr = 0.0460
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2522
	data_grads_norm = 4.7188
	new_data_grads_norm = 7.3698
	old_data_grads_norm = 6.3199
	sim_grads_norm_tr = 0.0476
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0701
	data_grads_norm = 5.0024
	new_data_grads_norm = 6.6386
	old_data_grads_norm = 7.4508
	sim_grads_norm_tr = 0.0338
-- Starting training on experience 220 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7504
	data_grads_norm = 3.7314
	new_data_grads_norm = 6.4682
	old_data_grads_norm = 4.2509
	sim_grads_norm_tr = -0.0391
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1842
	data_grads_norm = 4.2727
	new_data_grads_norm = 6.6682
	old_data_grads_norm = 6.1889
	sim_grads_norm_tr = -0.0059
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9980
	data_grads_norm = 4.6335
	new_data_grads_norm = 6.9750
	old_data_grads_norm = 5.4820
	sim_grads_norm_tr = -0.0005
-- Starting training on experience 221 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4660
	data_grads_norm = 3.7019
	new_data_grads_norm = 6.4148
	old_data_grads_norm = 4.7654
	sim_grads_norm_tr = -0.0344
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2519
	data_grads_norm = 5.7683
	new_data_grads_norm = 6.5863
	old_data_grads_norm = 7.8267
	sim_grads_norm_tr = 0.1123
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7139
	data_grads_norm = 3.8586
	new_data_grads_norm = 5.4826
	old_data_grads_norm = 4.6602
	sim_grads_norm_tr = 0.1139
-- Starting training on experience 222 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2282
	data_grads_norm = 3.8573
	new_data_grads_norm = 6.0406
	old_data_grads_norm = 5.5202
	sim_grads_norm_tr = -0.0082
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5450
	data_grads_norm = 4.2378
	new_data_grads_norm = 5.6064
	old_data_grads_norm = 5.7844
	sim_grads_norm_tr = 0.1221
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6291
	data_grads_norm = 4.7520
	new_data_grads_norm = 4.7407
	old_data_grads_norm = 7.9972
	sim_grads_norm_tr = -0.0307
-- Starting training on experience 223 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1531
	data_grads_norm = 4.2026
	new_data_grads_norm = 6.4376
	old_data_grads_norm = 5.4053
	sim_grads_norm_tr = -0.0146
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8074
	data_grads_norm = 5.0893
	new_data_grads_norm = 6.6291
	old_data_grads_norm = 8.4460
	sim_grads_norm_tr = 0.0317
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6217
	data_grads_norm = 4.6089
	new_data_grads_norm = 5.6928
	old_data_grads_norm = 7.1175
	sim_grads_norm_tr = -0.0088
-- Starting training on experience 224 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1766
	data_grads_norm = 4.4747
	new_data_grads_norm = 6.8948
	old_data_grads_norm = 5.1191
	sim_grads_norm_tr = 0.1351
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3574
	data_grads_norm = 4.4694
	new_data_grads_norm = 6.0529
	old_data_grads_norm = 6.9834
	sim_grads_norm_tr = -0.0155
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1177
	data_grads_norm = 4.5406
	new_data_grads_norm = 6.1555
	old_data_grads_norm = 6.5229
	sim_grads_norm_tr = 0.0273
-- Starting training on experience 225 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8695
	data_grads_norm = 4.7701
	new_data_grads_norm = 6.8235
	old_data_grads_norm = 6.6969
	sim_grads_norm_tr = 0.0035
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8354
	data_grads_norm = 4.1437
	new_data_grads_norm = 6.3122
	old_data_grads_norm = 5.3498
	sim_grads_norm_tr = -0.0452
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8783
	data_grads_norm = 4.6058
	new_data_grads_norm = 6.5653
	old_data_grads_norm = 6.2139
	sim_grads_norm_tr = -0.0175
-- Starting training on experience 226 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7564
	data_grads_norm = 4.9162
	new_data_grads_norm = 6.6315
	old_data_grads_norm = 6.3030
	sim_grads_norm_tr = 0.0675
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5520
	data_grads_norm = 4.8425
	new_data_grads_norm = 5.9973
	old_data_grads_norm = 6.9732
	sim_grads_norm_tr = 0.0402
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1801
	data_grads_norm = 3.9076
	new_data_grads_norm = 6.1833
	old_data_grads_norm = 4.8483
	sim_grads_norm_tr = -0.0603
-- Starting training on experience 227 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8300
	data_grads_norm = 4.3981
	new_data_grads_norm = 5.6920
	old_data_grads_norm = 7.3009
	sim_grads_norm_tr = -0.0424
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0485
	data_grads_norm = 4.4315
	new_data_grads_norm = 5.9222
	old_data_grads_norm = 6.2885
	sim_grads_norm_tr = 0.0381
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7238
	data_grads_norm = 4.0620
	new_data_grads_norm = 6.2903
	old_data_grads_norm = 5.5702
	sim_grads_norm_tr = -0.0481
-- Starting training on experience 228 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9600
	data_grads_norm = 4.7733
	new_data_grads_norm = 7.4473
	old_data_grads_norm = 5.9010
	sim_grads_norm_tr = -0.0419
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8155
	data_grads_norm = 5.0968
	new_data_grads_norm = 7.0644
	old_data_grads_norm = 5.7400
	sim_grads_norm_tr = 0.0806
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9887
	data_grads_norm = 4.2964
	new_data_grads_norm = 6.6670
	old_data_grads_norm = 5.1854
	sim_grads_norm_tr = -0.0124
-- Starting training on experience 229 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6451
	data_grads_norm = 3.8153
	new_data_grads_norm = 5.9675
	old_data_grads_norm = 5.4722
	sim_grads_norm_tr = -0.0819
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5884
	data_grads_norm = 4.3245
	new_data_grads_norm = 5.9669
	old_data_grads_norm = 6.4109
	sim_grads_norm_tr = -0.0267
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8003
	data_grads_norm = 4.7852
	new_data_grads_norm = 5.4947
	old_data_grads_norm = 7.2567
	sim_grads_norm_tr = 0.0394
-- Starting training on experience 230 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7383
	data_grads_norm = 4.4241
	new_data_grads_norm = 5.9639
	old_data_grads_norm = 6.1199
	sim_grads_norm_tr = 0.0043
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4851
	data_grads_norm = 3.4800
	new_data_grads_norm = 5.0587
	old_data_grads_norm = 5.4307
	sim_grads_norm_tr = 0.0233
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3143
	data_grads_norm = 5.3566
	new_data_grads_norm = 5.6661
	old_data_grads_norm = 7.5008
	sim_grads_norm_tr = -0.0402
-- Starting training on experience 231 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4982
	data_grads_norm = 4.6227
	new_data_grads_norm = 6.2874
	old_data_grads_norm = 6.3613
	sim_grads_norm_tr = -0.0258
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2180
	data_grads_norm = 5.3750
	new_data_grads_norm = 7.0982
	old_data_grads_norm = 7.9393
	sim_grads_norm_tr = -0.0360
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5533
	data_grads_norm = 5.6098
	new_data_grads_norm = 8.4316
	old_data_grads_norm = 7.1092
	sim_grads_norm_tr = 0.0349
-- Starting training on experience 232 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1478
	data_grads_norm = 4.3594
	new_data_grads_norm = 6.0519
	old_data_grads_norm = 5.9730
	sim_grads_norm_tr = -0.0008
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6401
	data_grads_norm = 4.8163
	new_data_grads_norm = 5.9574
	old_data_grads_norm = 7.2351
	sim_grads_norm_tr = -0.0581
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2248
	data_grads_norm = 4.8353
	new_data_grads_norm = 6.6984
	old_data_grads_norm = 6.1729
	sim_grads_norm_tr = 0.0089
-- Starting training on experience 233 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3786
	data_grads_norm = 4.4440
	new_data_grads_norm = 6.3746
	old_data_grads_norm = 6.3131
	sim_grads_norm_tr = 0.0201
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3758
	data_grads_norm = 4.5391
	new_data_grads_norm = 5.9913
	old_data_grads_norm = 6.3932
	sim_grads_norm_tr = -0.0026
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1386
	data_grads_norm = 4.3606
	new_data_grads_norm = 6.7097
	old_data_grads_norm = 5.9449
	sim_grads_norm_tr = -0.0322
-- Starting training on experience 234 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9797
	data_grads_norm = 4.5694
	new_data_grads_norm = 6.7927
	old_data_grads_norm = 6.5599
	sim_grads_norm_tr = 0.0325
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4572
	data_grads_norm = 4.9165
	new_data_grads_norm = 7.3242
	old_data_grads_norm = 6.3908
	sim_grads_norm_tr = -0.0243
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8131
	data_grads_norm = 4.1421
	new_data_grads_norm = 7.3496
	old_data_grads_norm = 4.2042
	sim_grads_norm_tr = -0.0375
-- Starting training on experience 235 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1405
	data_grads_norm = 4.5164
	new_data_grads_norm = 7.4064
	old_data_grads_norm = 6.2539
	sim_grads_norm_tr = -0.0338
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3084
	data_grads_norm = 4.6625
	new_data_grads_norm = 7.1702
	old_data_grads_norm = 5.8550
	sim_grads_norm_tr = -0.0391
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4197
	data_grads_norm = 4.4433
	new_data_grads_norm = 7.0486
	old_data_grads_norm = 4.6711
	sim_grads_norm_tr = 0.0787
-- Starting training on experience 236 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6584
	data_grads_norm = 5.3199
	new_data_grads_norm = 7.0901
	old_data_grads_norm = 7.2104
	sim_grads_norm_tr = 0.0137
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0775
	data_grads_norm = 4.2781
	new_data_grads_norm = 7.6404
	old_data_grads_norm = 4.9963
	sim_grads_norm_tr = 0.0020
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8804
	data_grads_norm = 5.9708
	new_data_grads_norm = 7.9837
	old_data_grads_norm = 7.4853
	sim_grads_norm_tr = 0.0780
-- Starting training on experience 237 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
-- >> End of training phase << --
-- >> Start of eval phase << --
-- Starting eval on experience 0 (Task 0) from test stream --
> Eval on experience 0 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp000 = 2.1857
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.4400
	mb_index = 1904
	time = 507.1129
-- Starting eval on experience 1 (Task 0) from test stream --
> Eval on experience 1 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp001 = 1.9208
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.5160
-- Starting eval on experience 2 (Task 0) from test stream --
> Eval on experience 2 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp002 = 2.9098
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.2640
-- Starting eval on experience 3 (Task 0) from test stream --
> Eval on experience 3 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp003 = 1.7746
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.5580
-- Starting eval on experience 4 (Task 0) from test stream --
> Eval on experience 4 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp004 = 3.0265
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.2720
-- Starting eval on experience 5 (Task 0) from test stream --
> Eval on experience 5 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp005 = 2.0357
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.4020
-- Starting eval on experience 6 (Task 0) from test stream --
> Eval on experience 6 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp006 = 2.3342
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp006 = 0.3060
-- Starting eval on experience 7 (Task 0) from test stream --
> Eval on experience 7 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp007 = 2.9601
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp007 = 0.2080
-- >> End of eval phase << --
	CumulativeAccuracy/eval_phase/test_stream/Exp000 = 0.7200
	CumulativeAccuracy/eval_phase/test_stream/Exp001 = 0.6550
	CumulativeAccuracy/eval_phase/test_stream/Exp002 = 0.5400
	CumulativeAccuracy/eval_phase/test_stream/Exp003 = 0.5175
	CumulativeAccuracy/eval_phase/test_stream/Exp004 = 0.4708
	CumulativeAccuracy/eval_phase/test_stream/Exp005 = 0.4317
	CumulativeAccuracy/eval_phase/test_stream/Exp006 = 0.4017
	CumulativeAccuracy/eval_phase/test_stream/Exp007 = 0.3708
	Loss_Stream/eval_phase/test_stream/Task000 = 2.3934
	Top1_Acc_Stream/eval_phase/test_stream/Task000 = 0.3708
-- >> Start of training phase << --
-- Starting training on experience 0 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2795
	data_grads_norm = 5.2632
	new_data_grads_norm = 6.4655
	old_data_grads_norm = 6.8391
	sim_grads_norm_tr = 0.0037
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0984
	data_grads_norm = 4.6904
	new_data_grads_norm = 6.0811
	old_data_grads_norm = 6.3259
	sim_grads_norm_tr = 0.0325
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5786
	data_grads_norm = 4.7602
	new_data_grads_norm = 6.9471
	old_data_grads_norm = 8.0945
	sim_grads_norm_tr = 0.0006
-- Starting training on experience 1 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8397
	data_grads_norm = 5.1244
	new_data_grads_norm = 6.0211
	old_data_grads_norm = 6.8129
	sim_grads_norm_tr = 0.0923
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3845
	data_grads_norm = 3.8798
	new_data_grads_norm = 5.4978
	old_data_grads_norm = 5.1695
	sim_grads_norm_tr = -0.0141
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3247
	data_grads_norm = 4.0118
	new_data_grads_norm = 5.4888
	old_data_grads_norm = 5.3969
	sim_grads_norm_tr = 0.0004
-- Starting training on experience 2 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7754
	data_grads_norm = 4.7624
	new_data_grads_norm = 6.0061
	old_data_grads_norm = 6.9814
	sim_grads_norm_tr = -0.0555
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0343
	data_grads_norm = 4.7735
	new_data_grads_norm = 6.7503
	old_data_grads_norm = 5.7717
	sim_grads_norm_tr = 0.0513
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3798
	data_grads_norm = 4.0409
	new_data_grads_norm = 5.8294
	old_data_grads_norm = 5.9637
	sim_grads_norm_tr = -0.0167
-- Starting training on experience 3 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8254
	data_grads_norm = 4.1746
	new_data_grads_norm = 6.1589
	old_data_grads_norm = 5.0369
	sim_grads_norm_tr = 0.0064
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7464
	data_grads_norm = 4.4170
	new_data_grads_norm = 6.1335
	old_data_grads_norm = 6.1737
	sim_grads_norm_tr = 0.0200
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7408
	data_grads_norm = 4.3036
	new_data_grads_norm = 6.4966
	old_data_grads_norm = 7.0951
	sim_grads_norm_tr = -0.0028
-- Starting training on experience 4 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9217
	data_grads_norm = 4.5061
	new_data_grads_norm = 6.4190
	old_data_grads_norm = 5.0724
	sim_grads_norm_tr = -0.0184
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3660
	data_grads_norm = 4.6619
	new_data_grads_norm = 6.7017
	old_data_grads_norm = 5.4216
	sim_grads_norm_tr = 0.0445
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8787
	data_grads_norm = 4.5851
	new_data_grads_norm = 6.1084
	old_data_grads_norm = 6.3421
	sim_grads_norm_tr = -0.0071
-- Starting training on experience 5 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4192
	data_grads_norm = 3.7309
	new_data_grads_norm = 6.3902
	old_data_grads_norm = 4.4479
	sim_grads_norm_tr = -0.0082
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1482
	data_grads_norm = 5.5956
	new_data_grads_norm = 7.7954
	old_data_grads_norm = 7.4751
	sim_grads_norm_tr = 0.1221
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7935
	data_grads_norm = 4.4089
	new_data_grads_norm = 6.2841
	old_data_grads_norm = 6.1548
	sim_grads_norm_tr = -0.0107
-- Starting training on experience 6 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6034
	data_grads_norm = 5.3491
	new_data_grads_norm = 6.8897
	old_data_grads_norm = 7.0624
	sim_grads_norm_tr = 0.0408
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0694
	data_grads_norm = 4.3368
	new_data_grads_norm = 7.0226
	old_data_grads_norm = 4.3081
	sim_grads_norm_tr = -0.0025
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.7469
	data_grads_norm = 5.5778
	new_data_grads_norm = 6.9605
	old_data_grads_norm = 7.1244
	sim_grads_norm_tr = 0.0048
-- Starting training on experience 7 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7604
	data_grads_norm = 4.7721
	new_data_grads_norm = 6.6684
	old_data_grads_norm = 6.0201
	sim_grads_norm_tr = -0.0352
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3847
	data_grads_norm = 4.5831
	new_data_grads_norm = 6.8262
	old_data_grads_norm = 4.9696
	sim_grads_norm_tr = 0.0456
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6549
	data_grads_norm = 4.6946
	new_data_grads_norm = 6.9226
	old_data_grads_norm = 6.7572
	sim_grads_norm_tr = -0.0004
-- Starting training on experience 8 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9161
	data_grads_norm = 4.7102
	new_data_grads_norm = 6.8797
	old_data_grads_norm = 6.3814
	sim_grads_norm_tr = 0.0106
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5871
	data_grads_norm = 4.2219
	new_data_grads_norm = 6.3480
	old_data_grads_norm = 5.8802
	sim_grads_norm_tr = -0.0003
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7005
	data_grads_norm = 4.4185
	new_data_grads_norm = 6.8752
	old_data_grads_norm = 4.9111
	sim_grads_norm_tr = 0.1006
-- Starting training on experience 9 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7268
	data_grads_norm = 4.7528
	new_data_grads_norm = 7.6268
	old_data_grads_norm = 5.3885
	sim_grads_norm_tr = 0.0300
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8957
	data_grads_norm = 5.0739
	new_data_grads_norm = 7.6509
	old_data_grads_norm = 5.7036
	sim_grads_norm_tr = 0.0194
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7371
	data_grads_norm = 4.1468
	new_data_grads_norm = 6.9746
	old_data_grads_norm = 4.1550
	sim_grads_norm_tr = -0.0281
-- Starting training on experience 10 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5961
	data_grads_norm = 4.5943
	new_data_grads_norm = 5.9606
	old_data_grads_norm = 6.2143
	sim_grads_norm_tr = 0.0706
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0626
	data_grads_norm = 4.1868
	new_data_grads_norm = 6.9179
	old_data_grads_norm = 4.2402
	sim_grads_norm_tr = 0.0692
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2573
	data_grads_norm = 5.1978
	new_data_grads_norm = 6.2701
	old_data_grads_norm = 8.0021
	sim_grads_norm_tr = 0.0884
-- Starting training on experience 11 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0875
	data_grads_norm = 3.8623
	new_data_grads_norm = 5.5735
	old_data_grads_norm = 4.5614
	sim_grads_norm_tr = -0.0367
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2222
	data_grads_norm = 4.1818
	new_data_grads_norm = 5.4822
	old_data_grads_norm = 6.2297
	sim_grads_norm_tr = 0.0062
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7157
	data_grads_norm = 4.0385
	new_data_grads_norm = 5.3848
	old_data_grads_norm = 5.5384
	sim_grads_norm_tr = 0.0275
-- Starting training on experience 12 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4686
	data_grads_norm = 4.3021
	new_data_grads_norm = 6.4630
	old_data_grads_norm = 5.0998
	sim_grads_norm_tr = 0.0109
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1042
	data_grads_norm = 4.5326
	new_data_grads_norm = 6.3228
	old_data_grads_norm = 5.5210
	sim_grads_norm_tr = 0.0819
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2364
	data_grads_norm = 4.2811
	new_data_grads_norm = 7.2545
	old_data_grads_norm = 5.1240
	sim_grads_norm_tr = -0.0726
-- Starting training on experience 13 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3808
	data_grads_norm = 4.6433
	new_data_grads_norm = 6.2584
	old_data_grads_norm = 6.1729
	sim_grads_norm_tr = 0.0422
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5130
	data_grads_norm = 4.2540
	new_data_grads_norm = 7.0213
	old_data_grads_norm = 5.3971
	sim_grads_norm_tr = -0.0380
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6036
	data_grads_norm = 4.9845
	new_data_grads_norm = 6.5519
	old_data_grads_norm = 7.0383
	sim_grads_norm_tr = 0.0004
-- Starting training on experience 14 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9305
	data_grads_norm = 4.6201
	new_data_grads_norm = 6.2371
	old_data_grads_norm = 6.3595
	sim_grads_norm_tr = 0.0250
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7947
	data_grads_norm = 4.3538
	new_data_grads_norm = 6.2732
	old_data_grads_norm = 5.5187
	sim_grads_norm_tr = 0.0575
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5920
	data_grads_norm = 4.6685
	new_data_grads_norm = 6.7601
	old_data_grads_norm = 6.3473
	sim_grads_norm_tr = 0.0286
-- Starting training on experience 15 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5723
	data_grads_norm = 4.7427
	new_data_grads_norm = 5.7242
	old_data_grads_norm = 6.3731
	sim_grads_norm_tr = 0.1247
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1698
	data_grads_norm = 3.9679
	new_data_grads_norm = 5.9993
	old_data_grads_norm = 5.1352
	sim_grads_norm_tr = 0.0510
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0507
	data_grads_norm = 3.9707
	new_data_grads_norm = 5.5959
	old_data_grads_norm = 5.7001
	sim_grads_norm_tr = 0.0571
-- Starting training on experience 16 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9843
	data_grads_norm = 4.1164
	new_data_grads_norm = 6.6296
	old_data_grads_norm = 5.3042
	sim_grads_norm_tr = -0.0582
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6016
	data_grads_norm = 4.2553
	new_data_grads_norm = 6.4797
	old_data_grads_norm = 4.9743
	sim_grads_norm_tr = 0.0465
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3668
	data_grads_norm = 5.0891
	new_data_grads_norm = 6.2881
	old_data_grads_norm = 8.1300
	sim_grads_norm_tr = -0.0008
-- Starting training on experience 17 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1871
	data_grads_norm = 4.7442
	new_data_grads_norm = 6.2174
	old_data_grads_norm = 5.5916
	sim_grads_norm_tr = 0.1794
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0043
	data_grads_norm = 3.9531
	new_data_grads_norm = 6.2582
	old_data_grads_norm = 5.2598
	sim_grads_norm_tr = -0.0455
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8467
	data_grads_norm = 4.5660
	new_data_grads_norm = 6.3253
	old_data_grads_norm = 5.3384
	sim_grads_norm_tr = 0.0668
-- Starting training on experience 18 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6655
	data_grads_norm = 4.6858
	new_data_grads_norm = 7.3919
	old_data_grads_norm = 6.7883
	sim_grads_norm_tr = 0.0451
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3240
	data_grads_norm = 4.4378
	new_data_grads_norm = 7.2683
	old_data_grads_norm = 4.9997
	sim_grads_norm_tr = 0.1304
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9614
	data_grads_norm = 5.8792
	new_data_grads_norm = 7.4161
	old_data_grads_norm = 7.5339
	sim_grads_norm_tr = -0.0247
-- Starting training on experience 19 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3251
	data_grads_norm = 4.8807
	new_data_grads_norm = 6.1035
	old_data_grads_norm = 7.3600
	sim_grads_norm_tr = 0.0742
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2868
	data_grads_norm = 4.2482
	new_data_grads_norm = 5.9945
	old_data_grads_norm = 5.2915
	sim_grads_norm_tr = 0.0577
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2116
	data_grads_norm = 4.1139
	new_data_grads_norm = 5.8840
	old_data_grads_norm = 5.2645
	sim_grads_norm_tr = -0.0144
-- Starting training on experience 20 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2496
	data_grads_norm = 4.1438
	new_data_grads_norm = 5.3691
	old_data_grads_norm = 6.1380
	sim_grads_norm_tr = 0.0046
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0212
	data_grads_norm = 3.9627
	new_data_grads_norm = 5.3985
	old_data_grads_norm = 4.6006
	sim_grads_norm_tr = 0.0208
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9510
	data_grads_norm = 3.8887
	new_data_grads_norm = 5.4222
	old_data_grads_norm = 5.1385
	sim_grads_norm_tr = -0.0029
-- Starting training on experience 21 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1598
	data_grads_norm = 4.6453
	new_data_grads_norm = 6.0105
	old_data_grads_norm = 6.3854
	sim_grads_norm_tr = 0.1073
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2675
	data_grads_norm = 4.5303
	new_data_grads_norm = 5.9151
	old_data_grads_norm = 6.4959
	sim_grads_norm_tr = 0.0209
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6026
	data_grads_norm = 4.6277
	new_data_grads_norm = 6.2702
	old_data_grads_norm = 6.4728
	sim_grads_norm_tr = -0.0082
-- Starting training on experience 22 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3203
	data_grads_norm = 4.3148
	new_data_grads_norm = 7.2864
	old_data_grads_norm = 4.7871
	sim_grads_norm_tr = -0.0826
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4463
	data_grads_norm = 4.8263
	new_data_grads_norm = 7.8434
	old_data_grads_norm = 5.6525
	sim_grads_norm_tr = -0.0436
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6146
	data_grads_norm = 4.8357
	new_data_grads_norm = 7.4878
	old_data_grads_norm = 5.6485
	sim_grads_norm_tr = 0.0375
-- Starting training on experience 23 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8024
	data_grads_norm = 4.6975
	new_data_grads_norm = 6.2045
	old_data_grads_norm = 6.4002
	sim_grads_norm_tr = 0.0611
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1709
	data_grads_norm = 4.4108
	new_data_grads_norm = 6.3581
	old_data_grads_norm = 6.0934
	sim_grads_norm_tr = 0.0235
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3916
	data_grads_norm = 4.8019
	new_data_grads_norm = 5.8678
	old_data_grads_norm = 7.0664
	sim_grads_norm_tr = 0.0783
-- Starting training on experience 24 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0623
	data_grads_norm = 4.7853
	new_data_grads_norm = 5.2830
	old_data_grads_norm = 6.6059
	sim_grads_norm_tr = -0.0083
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6772
	data_grads_norm = 4.9172
	new_data_grads_norm = 5.1820
	old_data_grads_norm = 7.2388
	sim_grads_norm_tr = 0.0179
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2375
	data_grads_norm = 4.3860
	new_data_grads_norm = 5.3430
	old_data_grads_norm = 6.4491
	sim_grads_norm_tr = 0.0029
-- Starting training on experience 25 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1607
	data_grads_norm = 4.6955
	new_data_grads_norm = 6.8629
	old_data_grads_norm = 5.6388
	sim_grads_norm_tr = 0.0051
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1707
	data_grads_norm = 5.2926
	new_data_grads_norm = 6.8593
	old_data_grads_norm = 6.9642
	sim_grads_norm_tr = 0.0107
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4654
	data_grads_norm = 4.8822
	new_data_grads_norm = 7.7981
	old_data_grads_norm = 5.9742
	sim_grads_norm_tr = 0.0885
-- Starting training on experience 26 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7472
	data_grads_norm = 3.5143
	new_data_grads_norm = 5.5837
	old_data_grads_norm = 4.7974
	sim_grads_norm_tr = -0.0350
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0047
	data_grads_norm = 4.3418
	new_data_grads_norm = 5.6316
	old_data_grads_norm = 6.1233
	sim_grads_norm_tr = 0.0414
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0888
	data_grads_norm = 4.2952
	new_data_grads_norm = 6.5712
	old_data_grads_norm = 5.7077
	sim_grads_norm_tr = -0.0205
-- Starting training on experience 27 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2920
	data_grads_norm = 4.7024
	new_data_grads_norm = 6.2610
	old_data_grads_norm = 6.0956
	sim_grads_norm_tr = 0.0914
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9760
	data_grads_norm = 4.1169
	new_data_grads_norm = 6.5669
	old_data_grads_norm = 5.6293
	sim_grads_norm_tr = 0.0172
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9840
	data_grads_norm = 5.1117
	new_data_grads_norm = 6.0641
	old_data_grads_norm = 8.8968
	sim_grads_norm_tr = -0.0722
-- Starting training on experience 28 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9976
	data_grads_norm = 5.0269
	new_data_grads_norm = 6.5275
	old_data_grads_norm = 6.9896
	sim_grads_norm_tr = 0.0590
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5245
	data_grads_norm = 3.8771
	new_data_grads_norm = 5.8718
	old_data_grads_norm = 4.5261
	sim_grads_norm_tr = -0.0595
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9129
	data_grads_norm = 5.2407
	new_data_grads_norm = 6.4447
	old_data_grads_norm = 6.7444
	sim_grads_norm_tr = 0.0615
-- Starting training on experience 29 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8587
	data_grads_norm = 4.2714
	new_data_grads_norm = 5.4590
	old_data_grads_norm = 5.6599
	sim_grads_norm_tr = 0.0124
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4065
	data_grads_norm = 4.7855
	new_data_grads_norm = 6.0313
	old_data_grads_norm = 6.4394
	sim_grads_norm_tr = 0.0516
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3647
	data_grads_norm = 4.4753
	new_data_grads_norm = 5.6210
	old_data_grads_norm = 6.1592
	sim_grads_norm_tr = 0.0217
-- Starting training on experience 30 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8601
	data_grads_norm = 4.4601
	new_data_grads_norm = 5.3801
	old_data_grads_norm = 5.6610
	sim_grads_norm_tr = 0.0663
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6354
	data_grads_norm = 3.8179
	new_data_grads_norm = 5.2321
	old_data_grads_norm = 5.5399
	sim_grads_norm_tr = -0.0350
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7018
	data_grads_norm = 3.8479
	new_data_grads_norm = 5.2719
	old_data_grads_norm = 5.4685
	sim_grads_norm_tr = -0.0039
-- Starting training on experience 31 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0027
	data_grads_norm = 4.2230
	new_data_grads_norm = 5.6076
	old_data_grads_norm = 5.7140
	sim_grads_norm_tr = -0.0168
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9160
	data_grads_norm = 4.2481
	new_data_grads_norm = 5.9212
	old_data_grads_norm = 5.1564
	sim_grads_norm_tr = -0.0300
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9393
	data_grads_norm = 4.1438
	new_data_grads_norm = 5.3576
	old_data_grads_norm = 4.5530
	sim_grads_norm_tr = -0.0201
-- Starting training on experience 32 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4203
	data_grads_norm = 3.6529
	new_data_grads_norm = 5.8161
	old_data_grads_norm = 4.6746
	sim_grads_norm_tr = -0.0188
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1002
	data_grads_norm = 4.6743
	new_data_grads_norm = 6.0990
	old_data_grads_norm = 6.3610
	sim_grads_norm_tr = 0.0529
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1406
	data_grads_norm = 4.6386
	new_data_grads_norm = 6.5029
	old_data_grads_norm = 5.1713
	sim_grads_norm_tr = -0.0037
-- Starting training on experience 33 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0508
	data_grads_norm = 5.1340
	new_data_grads_norm = 7.1821
	old_data_grads_norm = 6.1431
	sim_grads_norm_tr = -0.0309
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4501
	data_grads_norm = 4.8155
	new_data_grads_norm = 6.6537
	old_data_grads_norm = 5.2266
	sim_grads_norm_tr = 0.1814
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0789
	data_grads_norm = 5.0389
	new_data_grads_norm = 6.9194
	old_data_grads_norm = 6.3578
	sim_grads_norm_tr = -0.0139
-- Starting training on experience 34 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9126
	data_grads_norm = 4.5720
	new_data_grads_norm = 6.9703
	old_data_grads_norm = 5.5738
	sim_grads_norm_tr = 0.0692
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0254
	data_grads_norm = 4.8758
	new_data_grads_norm = 6.5322
	old_data_grads_norm = 4.4905
	sim_grads_norm_tr = 0.1067
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7714
	data_grads_norm = 4.1466
	new_data_grads_norm = 6.6616
	old_data_grads_norm = 5.5070
	sim_grads_norm_tr = 0.0944
-- Starting training on experience 35 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5871
	data_grads_norm = 4.2129
	new_data_grads_norm = 6.5259
	old_data_grads_norm = 5.8472
	sim_grads_norm_tr = -0.0290
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3239
	data_grads_norm = 4.0428
	new_data_grads_norm = 5.9269
	old_data_grads_norm = 5.4208
	sim_grads_norm_tr = 0.0668
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9212
	data_grads_norm = 4.2912
	new_data_grads_norm = 5.7965
	old_data_grads_norm = 5.8415
	sim_grads_norm_tr = 0.0314
-- Starting training on experience 36 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2352
	data_grads_norm = 3.6876
	new_data_grads_norm = 5.8614
	old_data_grads_norm = 4.2791
	sim_grads_norm_tr = 0.0055
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7422
	data_grads_norm = 4.6238
	new_data_grads_norm = 5.9670
	old_data_grads_norm = 6.4737
	sim_grads_norm_tr = -0.0695
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9302
	data_grads_norm = 4.3302
	new_data_grads_norm = 6.3166
	old_data_grads_norm = 5.2620
	sim_grads_norm_tr = 0.2114
-- Starting training on experience 37 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3668
	data_grads_norm = 4.8869
	new_data_grads_norm = 6.0189
	old_data_grads_norm = 6.5765
	sim_grads_norm_tr = -0.0250
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7431
	data_grads_norm = 4.0195
	new_data_grads_norm = 5.8782
	old_data_grads_norm = 5.8743
	sim_grads_norm_tr = -0.0171
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9893
	data_grads_norm = 4.0770
	new_data_grads_norm = 6.0344
	old_data_grads_norm = 5.2773
	sim_grads_norm_tr = 0.0013
-- Starting training on experience 38 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7046
	data_grads_norm = 3.7892
	new_data_grads_norm = 5.7989
	old_data_grads_norm = 4.3961
	sim_grads_norm_tr = 0.0786
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7988
	data_grads_norm = 4.2537
	new_data_grads_norm = 5.6982
	old_data_grads_norm = 5.0493
	sim_grads_norm_tr = 0.2214
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2639
	data_grads_norm = 3.9495
	new_data_grads_norm = 5.5982
	old_data_grads_norm = 6.2834
	sim_grads_norm_tr = -0.0242
-- Starting training on experience 39 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5733
	data_grads_norm = 4.0041
	new_data_grads_norm = 5.9825
	old_data_grads_norm = 5.3094
	sim_grads_norm_tr = -0.1207
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4916
	data_grads_norm = 4.4009
	new_data_grads_norm = 5.5824
	old_data_grads_norm = 6.8661
	sim_grads_norm_tr = 0.0500
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3932
	data_grads_norm = 4.5384
	new_data_grads_norm = 5.9421
	old_data_grads_norm = 6.2130
	sim_grads_norm_tr = 0.0616
-- Starting training on experience 40 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6423
	data_grads_norm = 4.4537
	new_data_grads_norm = 6.1575
	old_data_grads_norm = 6.2323
	sim_grads_norm_tr = 0.0201
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3512
	data_grads_norm = 3.5349
	new_data_grads_norm = 5.4661
	old_data_grads_norm = 5.1572
	sim_grads_norm_tr = 0.0748
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9617
	data_grads_norm = 4.1348
	new_data_grads_norm = 6.0516
	old_data_grads_norm = 5.0642
	sim_grads_norm_tr = 0.0107
-- Starting training on experience 41 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5991
	data_grads_norm = 3.7528
	new_data_grads_norm = 5.8862
	old_data_grads_norm = 4.7401
	sim_grads_norm_tr = -0.0600
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4185
	data_grads_norm = 4.4784
	new_data_grads_norm = 6.1253
	old_data_grads_norm = 6.4342
	sim_grads_norm_tr = 0.0462
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7005
	data_grads_norm = 4.3990
	new_data_grads_norm = 6.3955
	old_data_grads_norm = 4.5345
	sim_grads_norm_tr = 0.0501
-- Starting training on experience 42 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9980
	data_grads_norm = 4.6065
	new_data_grads_norm = 5.4758
	old_data_grads_norm = 6.5890
	sim_grads_norm_tr = 0.0770
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9670
	data_grads_norm = 5.3660
	new_data_grads_norm = 5.7622
	old_data_grads_norm = 8.2399
	sim_grads_norm_tr = -0.0534
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4107
	data_grads_norm = 3.7670
	new_data_grads_norm = 5.8646
	old_data_grads_norm = 4.4301
	sim_grads_norm_tr = -0.0169
-- Starting training on experience 43 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7881
	data_grads_norm = 4.1785
	new_data_grads_norm = 6.5129
	old_data_grads_norm = 4.6803
	sim_grads_norm_tr = 0.0945
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5734
	data_grads_norm = 4.1131
	new_data_grads_norm = 6.3581
	old_data_grads_norm = 5.1691
	sim_grads_norm_tr = -0.0132
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9397
	data_grads_norm = 4.5783
	new_data_grads_norm = 6.1136
	old_data_grads_norm = 6.4651
	sim_grads_norm_tr = -0.0172
-- Starting training on experience 44 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9504
	data_grads_norm = 4.4562
	new_data_grads_norm = 5.6049
	old_data_grads_norm = 6.4426
	sim_grads_norm_tr = -0.0099
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4676
	data_grads_norm = 3.5768
	new_data_grads_norm = 5.3364
	old_data_grads_norm = 4.4606
	sim_grads_norm_tr = 0.0888
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8611
	data_grads_norm = 4.4136
	new_data_grads_norm = 5.0706
	old_data_grads_norm = 6.4605
	sim_grads_norm_tr = -0.0193
-- Starting training on experience 45 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9569
	data_grads_norm = 4.0739
	new_data_grads_norm = 6.0398
	old_data_grads_norm = 5.2389
	sim_grads_norm_tr = -0.0031
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5798
	data_grads_norm = 4.0638
	new_data_grads_norm = 6.3358
	old_data_grads_norm = 5.6844
	sim_grads_norm_tr = 0.0239
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2498
	data_grads_norm = 4.5875
	new_data_grads_norm = 6.1167
	old_data_grads_norm = 6.1007
	sim_grads_norm_tr = 0.0945
-- Starting training on experience 46 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5082
	data_grads_norm = 4.0874
	new_data_grads_norm = 5.3536
	old_data_grads_norm = 5.9508
	sim_grads_norm_tr = 0.1265
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8467
	data_grads_norm = 4.7122
	new_data_grads_norm = 5.5599
	old_data_grads_norm = 7.0123
	sim_grads_norm_tr = 0.0213
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4974
	data_grads_norm = 3.7485
	new_data_grads_norm = 5.3017
	old_data_grads_norm = 5.1189
	sim_grads_norm_tr = 0.0228
-- Starting training on experience 47 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5501
	data_grads_norm = 3.9264
	new_data_grads_norm = 5.7530
	old_data_grads_norm = 5.4365
	sim_grads_norm_tr = -0.0830
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6084
	data_grads_norm = 4.2138
	new_data_grads_norm = 5.4894
	old_data_grads_norm = 5.8560
	sim_grads_norm_tr = -0.1307
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5021
	data_grads_norm = 3.9942
	new_data_grads_norm = 5.8090
	old_data_grads_norm = 4.7230
	sim_grads_norm_tr = 0.0873
-- Starting training on experience 48 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8014
	data_grads_norm = 4.0654
	new_data_grads_norm = 5.7409
	old_data_grads_norm = 5.9560
	sim_grads_norm_tr = -0.0681
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0265
	data_grads_norm = 4.3931
	new_data_grads_norm = 5.9601
	old_data_grads_norm = 6.7574
	sim_grads_norm_tr = -0.0166
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5123
	data_grads_norm = 3.8924
	new_data_grads_norm = 6.0609
	old_data_grads_norm = 4.0460
	sim_grads_norm_tr = 0.1996
-- Starting training on experience 49 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1838
	data_grads_norm = 5.2787
	new_data_grads_norm = 5.6806
	old_data_grads_norm = 7.8415
	sim_grads_norm_tr = 0.0000
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5455
	data_grads_norm = 4.1648
	new_data_grads_norm = 6.7588
	old_data_grads_norm = 4.9099
	sim_grads_norm_tr = 0.0140
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4719
	data_grads_norm = 3.8279
	new_data_grads_norm = 6.2216
	old_data_grads_norm = 5.0954
	sim_grads_norm_tr = -0.0002
-- Starting training on experience 50 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1818
	data_grads_norm = 3.4585
	new_data_grads_norm = 5.3208
	old_data_grads_norm = 4.7148
	sim_grads_norm_tr = 0.0876
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6039
	data_grads_norm = 4.4559
	new_data_grads_norm = 5.3579
	old_data_grads_norm = 6.7808
	sim_grads_norm_tr = 0.0668
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3500
	data_grads_norm = 4.0103
	new_data_grads_norm = 5.2641
	old_data_grads_norm = 6.4691
	sim_grads_norm_tr = -0.0489
-- Starting training on experience 51 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9673
	data_grads_norm = 3.6740
	new_data_grads_norm = 6.7003
	old_data_grads_norm = 3.8543
	sim_grads_norm_tr = -0.0650
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0258
	data_grads_norm = 5.1336
	new_data_grads_norm = 6.2531
	old_data_grads_norm = 7.7852
	sim_grads_norm_tr = 0.0034
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5235
	data_grads_norm = 4.8102
	new_data_grads_norm = 6.3990
	old_data_grads_norm = 6.3816
	sim_grads_norm_tr = -0.0265
-- Starting training on experience 52 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4822
	data_grads_norm = 4.7567
	new_data_grads_norm = 6.9778
	old_data_grads_norm = 5.3856
	sim_grads_norm_tr = 0.0771
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5696
	data_grads_norm = 4.8569
	new_data_grads_norm = 7.0747
	old_data_grads_norm = 6.0078
	sim_grads_norm_tr = 0.0034
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1753
	data_grads_norm = 3.7660
	new_data_grads_norm = 6.3002
	old_data_grads_norm = 4.3429
	sim_grads_norm_tr = -0.0553
-- Starting training on experience 53 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7431
	data_grads_norm = 4.7810
	new_data_grads_norm = 6.8381
	old_data_grads_norm = 6.2271
	sim_grads_norm_tr = 0.0227
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0130
	data_grads_norm = 5.1924
	new_data_grads_norm = 8.0625
	old_data_grads_norm = 5.1845
	sim_grads_norm_tr = 0.0832
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0809
	data_grads_norm = 5.6913
	new_data_grads_norm = 7.2674
	old_data_grads_norm = 6.2554
	sim_grads_norm_tr = 0.0759
-- Starting training on experience 54 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5566
	data_grads_norm = 4.4596
	new_data_grads_norm = 5.8261
	old_data_grads_norm = 6.1545
	sim_grads_norm_tr = 0.0400
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0520
	data_grads_norm = 4.2292
	new_data_grads_norm = 4.9652
	old_data_grads_norm = 6.5632
	sim_grads_norm_tr = 0.0090
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0721
	data_grads_norm = 3.7114
	new_data_grads_norm = 5.5550
	old_data_grads_norm = 6.5038
	sim_grads_norm_tr = 0.0178
-- Starting training on experience 55 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3813
	data_grads_norm = 3.7711
	new_data_grads_norm = 5.1972
	old_data_grads_norm = 4.6217
	sim_grads_norm_tr = 0.2065
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5907
	data_grads_norm = 4.5863
	new_data_grads_norm = 5.2150
	old_data_grads_norm = 6.8312
	sim_grads_norm_tr = 0.0006
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4617
	data_grads_norm = 4.3488
	new_data_grads_norm = 5.7751
	old_data_grads_norm = 6.4734
	sim_grads_norm_tr = -0.0009
-- Starting training on experience 56 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3045
	data_grads_norm = 3.4627
	new_data_grads_norm = 5.5901
	old_data_grads_norm = 4.2058
	sim_grads_norm_tr = 0.0464
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4727
	data_grads_norm = 3.9137
	new_data_grads_norm = 5.4999
	old_data_grads_norm = 4.5686
	sim_grads_norm_tr = 0.1004
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0801
	data_grads_norm = 3.4416
	new_data_grads_norm = 5.4318
	old_data_grads_norm = 4.7613
	sim_grads_norm_tr = -0.0578
-- Starting training on experience 57 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6243
	data_grads_norm = 4.0934
	new_data_grads_norm = 5.7374
	old_data_grads_norm = 5.6661
	sim_grads_norm_tr = 0.0035
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4771
	data_grads_norm = 4.0289
	new_data_grads_norm = 5.9706
	old_data_grads_norm = 5.3339
	sim_grads_norm_tr = 0.0429
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9160
	data_grads_norm = 3.6150
	new_data_grads_norm = 5.4305
	old_data_grads_norm = 5.5490
	sim_grads_norm_tr = 0.0219
-- Starting training on experience 58 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8606
	data_grads_norm = 4.8611
	new_data_grads_norm = 5.7172
	old_data_grads_norm = 6.8644
	sim_grads_norm_tr = 0.0678
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4284
	data_grads_norm = 4.3278
	new_data_grads_norm = 5.4065
	old_data_grads_norm = 6.0987
	sim_grads_norm_tr = 0.1392
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4974
	data_grads_norm = 4.1393
	new_data_grads_norm = 5.2991
	old_data_grads_norm = 6.1640
	sim_grads_norm_tr = 0.1026
-- Starting training on experience 59 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5215
	data_grads_norm = 4.4159
	new_data_grads_norm = 5.4633
	old_data_grads_norm = 5.9998
	sim_grads_norm_tr = 0.0409
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9132
	data_grads_norm = 3.7308
	new_data_grads_norm = 5.9571
	old_data_grads_norm = 5.6090
	sim_grads_norm_tr = -0.0939
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6050
	data_grads_norm = 4.5178
	new_data_grads_norm = 5.2231
	old_data_grads_norm = 6.5436
	sim_grads_norm_tr = 0.0064
-- Starting training on experience 60 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0945
	data_grads_norm = 3.8631
	new_data_grads_norm = 5.9923
	old_data_grads_norm = 5.8289
	sim_grads_norm_tr = -0.0464
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4374
	data_grads_norm = 4.2557
	new_data_grads_norm = 6.0762
	old_data_grads_norm = 5.5727
	sim_grads_norm_tr = -0.0463
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3864
	data_grads_norm = 4.1131
	new_data_grads_norm = 6.9944
	old_data_grads_norm = 5.7369
	sim_grads_norm_tr = 0.0292
-- Starting training on experience 61 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4099
	data_grads_norm = 4.4275
	new_data_grads_norm = 5.9046
	old_data_grads_norm = 5.7671
	sim_grads_norm_tr = -0.0504
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7622
	data_grads_norm = 4.5595
	new_data_grads_norm = 6.9812
	old_data_grads_norm = 5.9691
	sim_grads_norm_tr = -0.0162
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7118
	data_grads_norm = 4.4778
	new_data_grads_norm = 6.4845
	old_data_grads_norm = 5.7829
	sim_grads_norm_tr = -0.0171
-- Starting training on experience 62 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6541
	data_grads_norm = 4.1697
	new_data_grads_norm = 5.8787
	old_data_grads_norm = 5.0165
	sim_grads_norm_tr = 0.1610
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9703
	data_grads_norm = 3.7344
	new_data_grads_norm = 5.7897
	old_data_grads_norm = 5.2041
	sim_grads_norm_tr = 0.0325
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8252
	data_grads_norm = 3.4412
	new_data_grads_norm = 5.7797
	old_data_grads_norm = 4.2313
	sim_grads_norm_tr = 0.0386
-- Starting training on experience 63 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5255
	data_grads_norm = 4.3742
	new_data_grads_norm = 6.0154
	old_data_grads_norm = 5.6086
	sim_grads_norm_tr = -0.0125
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7123
	data_grads_norm = 4.4906
	new_data_grads_norm = 6.0215
	old_data_grads_norm = 5.7632
	sim_grads_norm_tr = -0.0195
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5698
	data_grads_norm = 4.4977
	new_data_grads_norm = 6.1985
	old_data_grads_norm = 6.3626
	sim_grads_norm_tr = 0.0165
-- Starting training on experience 64 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1140
	data_grads_norm = 4.0000
	new_data_grads_norm = 5.4725
	old_data_grads_norm = 6.3491
	sim_grads_norm_tr = -0.0156
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7255
	data_grads_norm = 4.3655
	new_data_grads_norm = 5.7433
	old_data_grads_norm = 5.6228
	sim_grads_norm_tr = 0.0885
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6033
	data_grads_norm = 4.6359
	new_data_grads_norm = 5.9867
	old_data_grads_norm = 7.0164
	sim_grads_norm_tr = -0.0014
-- Starting training on experience 65 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4476
	data_grads_norm = 4.1870
	new_data_grads_norm = 6.4893
	old_data_grads_norm = 5.4685
	sim_grads_norm_tr = 0.0090
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3290
	data_grads_norm = 4.9495
	new_data_grads_norm = 6.3216
	old_data_grads_norm = 7.3938
	sim_grads_norm_tr = 0.0052
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3506
	data_grads_norm = 4.4287
	new_data_grads_norm = 6.1502
	old_data_grads_norm = 6.2185
	sim_grads_norm_tr = -0.0170
-- Starting training on experience 66 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3259
	data_grads_norm = 3.7223
	new_data_grads_norm = 5.2153
	old_data_grads_norm = 6.0381
	sim_grads_norm_tr = -0.0384
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6157
	data_grads_norm = 4.1718
	new_data_grads_norm = 5.7932
	old_data_grads_norm = 5.6570
	sim_grads_norm_tr = 0.0086
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3891
	data_grads_norm = 3.9875
	new_data_grads_norm = 5.5022
	old_data_grads_norm = 6.7392
	sim_grads_norm_tr = 0.0445
-- Starting training on experience 67 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0657
	data_grads_norm = 4.1435
	new_data_grads_norm = 5.4829
	old_data_grads_norm = 6.2317
	sim_grads_norm_tr = -0.0163
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3608
	data_grads_norm = 3.9553
	new_data_grads_norm = 5.7401
	old_data_grads_norm = 5.2397
	sim_grads_norm_tr = -0.0101
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8918
	data_grads_norm = 5.0269
	new_data_grads_norm = 6.0928
	old_data_grads_norm = 7.0783
	sim_grads_norm_tr = 0.0225
-- Starting training on experience 68 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6977
	data_grads_norm = 4.3520
	new_data_grads_norm = 6.3463
	old_data_grads_norm = 4.6946
	sim_grads_norm_tr = 0.0381
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8139
	data_grads_norm = 5.3056
	new_data_grads_norm = 6.6172
	old_data_grads_norm = 7.6019
	sim_grads_norm_tr = 0.0391
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4787
	data_grads_norm = 4.2756
	new_data_grads_norm = 6.4441
	old_data_grads_norm = 5.2175
	sim_grads_norm_tr = -0.0360
-- Starting training on experience 69 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7075
	data_grads_norm = 4.4242
	new_data_grads_norm = 5.5550
	old_data_grads_norm = 6.1971
	sim_grads_norm_tr = -0.0396
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4443
	data_grads_norm = 4.3300
	new_data_grads_norm = 5.8657
	old_data_grads_norm = 5.6047
	sim_grads_norm_tr = 0.0477
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8563
	data_grads_norm = 4.6643
	new_data_grads_norm = 5.4501
	old_data_grads_norm = 6.9826
	sim_grads_norm_tr = 0.0647
-- Starting training on experience 70 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5012
	data_grads_norm = 4.4510
	new_data_grads_norm = 5.8915
	old_data_grads_norm = 5.9021
	sim_grads_norm_tr = -0.0014
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3877
	data_grads_norm = 3.5045
	new_data_grads_norm = 5.2217
	old_data_grads_norm = 4.4041
	sim_grads_norm_tr = 0.0786
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9935
	data_grads_norm = 3.3561
	new_data_grads_norm = 5.4800
	old_data_grads_norm = 4.7555
	sim_grads_norm_tr = -0.0306
-- Starting training on experience 71 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1859
	data_grads_norm = 4.4826
	new_data_grads_norm = 5.6191
	old_data_grads_norm = 6.3351
	sim_grads_norm_tr = -0.0016
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0639
	data_grads_norm = 3.3832
	new_data_grads_norm = 5.6452
	old_data_grads_norm = 3.8731
	sim_grads_norm_tr = 0.0278
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6837
	data_grads_norm = 4.2381
	new_data_grads_norm = 5.4318
	old_data_grads_norm = 6.0400
	sim_grads_norm_tr = 0.0206
-- Starting training on experience 72 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2844
	data_grads_norm = 3.9947
	new_data_grads_norm = 6.6314
	old_data_grads_norm = 5.1932
	sim_grads_norm_tr = -0.0663
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1666
	data_grads_norm = 3.9988
	new_data_grads_norm = 6.4330
	old_data_grads_norm = 5.5181
	sim_grads_norm_tr = -0.0406
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2398
	data_grads_norm = 3.9888
	new_data_grads_norm = 6.6576
	old_data_grads_norm = 4.6624
	sim_grads_norm_tr = -0.0176
-- Starting training on experience 73 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5931
	data_grads_norm = 4.2879
	new_data_grads_norm = 6.3098
	old_data_grads_norm = 6.1685
	sim_grads_norm_tr = 0.1070
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6366
	data_grads_norm = 4.1309
	new_data_grads_norm = 5.8209
	old_data_grads_norm = 5.1948
	sim_grads_norm_tr = 0.0511
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6890
	data_grads_norm = 4.1232
	new_data_grads_norm = 5.6710
	old_data_grads_norm = 5.4430
	sim_grads_norm_tr = -0.0236
-- Starting training on experience 74 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9390
	data_grads_norm = 3.5428
	new_data_grads_norm = 5.8292
	old_data_grads_norm = 4.8948
	sim_grads_norm_tr = -0.0859
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1548
	data_grads_norm = 4.5103
	new_data_grads_norm = 6.0959
	old_data_grads_norm = 6.5432
	sim_grads_norm_tr = 0.0106
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5046
	data_grads_norm = 4.5928
	new_data_grads_norm = 6.1299
	old_data_grads_norm = 6.9424
	sim_grads_norm_tr = -0.0207
-- Starting training on experience 75 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9976
	data_grads_norm = 4.7697
	new_data_grads_norm = 7.7387
	old_data_grads_norm = 5.1961
	sim_grads_norm_tr = -0.0205
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3690
	data_grads_norm = 4.6344
	new_data_grads_norm = 7.0138
	old_data_grads_norm = 5.3311
	sim_grads_norm_tr = -0.0054
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4192
	data_grads_norm = 4.4966
	new_data_grads_norm = 6.7220
	old_data_grads_norm = 5.7004
	sim_grads_norm_tr = 0.0481
-- Starting training on experience 76 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2553
	data_grads_norm = 3.7611
	new_data_grads_norm = 6.2261
	old_data_grads_norm = 4.9781
	sim_grads_norm_tr = -0.0511
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2470
	data_grads_norm = 4.4127
	new_data_grads_norm = 6.1752
	old_data_grads_norm = 7.0270
	sim_grads_norm_tr = -0.0284
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6827
	data_grads_norm = 4.0409
	new_data_grads_norm = 6.4218
	old_data_grads_norm = 5.1197
	sim_grads_norm_tr = 0.0106
-- Starting training on experience 77 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7312
	data_grads_norm = 5.2608
	new_data_grads_norm = 6.7338
	old_data_grads_norm = 6.6687
	sim_grads_norm_tr = 0.0341
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6231
	data_grads_norm = 4.3404
	new_data_grads_norm = 6.7265
	old_data_grads_norm = 5.3072
	sim_grads_norm_tr = 0.0174
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4340
	data_grads_norm = 4.5445
	new_data_grads_norm = 6.7253
	old_data_grads_norm = 4.7966
	sim_grads_norm_tr = -0.0282
-- Starting training on experience 78 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4191
	data_grads_norm = 3.7842
	new_data_grads_norm = 6.6146
	old_data_grads_norm = 4.3654
	sim_grads_norm_tr = -0.0050
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9956
	data_grads_norm = 5.1387
	new_data_grads_norm = 7.6640
	old_data_grads_norm = 6.4258
	sim_grads_norm_tr = 0.0352
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2718
	data_grads_norm = 5.1350
	new_data_grads_norm = 5.9540
	old_data_grads_norm = 7.8759
	sim_grads_norm_tr = 0.0540
-- Starting training on experience 79 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7309
	data_grads_norm = 4.7196
	new_data_grads_norm = 5.8548
	old_data_grads_norm = 6.1905
	sim_grads_norm_tr = -0.0079
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6281
	data_grads_norm = 4.5444
	new_data_grads_norm = 5.9494
	old_data_grads_norm = 6.2117
	sim_grads_norm_tr = 0.0334
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0457
	data_grads_norm = 4.9188
	new_data_grads_norm = 5.5667
	old_data_grads_norm = 7.3829
	sim_grads_norm_tr = 0.0057
-- Starting training on experience 80 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7340
	data_grads_norm = 4.2897
	new_data_grads_norm = 5.5546
	old_data_grads_norm = 6.6759
	sim_grads_norm_tr = -0.0063
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9446
	data_grads_norm = 5.0033
	new_data_grads_norm = 6.4228
	old_data_grads_norm = 7.5075
	sim_grads_norm_tr = -0.0347
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3393
	data_grads_norm = 5.2274
	new_data_grads_norm = 6.4847
	old_data_grads_norm = 7.4921
	sim_grads_norm_tr = 0.0678
-- Starting training on experience 81 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3936
	data_grads_norm = 4.2156
	new_data_grads_norm = 5.8060
	old_data_grads_norm = 6.0873
	sim_grads_norm_tr = -0.0108
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5232
	data_grads_norm = 5.0743
	new_data_grads_norm = 6.1187
	old_data_grads_norm = 6.9521
	sim_grads_norm_tr = -0.0201
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1993
	data_grads_norm = 4.0848
	new_data_grads_norm = 6.3646
	old_data_grads_norm = 4.2192
	sim_grads_norm_tr = 0.0027
-- Starting training on experience 82 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2188
	data_grads_norm = 4.7421
	new_data_grads_norm = 6.5516
	old_data_grads_norm = 7.3863
	sim_grads_norm_tr = -0.0249
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5450
	data_grads_norm = 4.7969
	new_data_grads_norm = 6.2729
	old_data_grads_norm = 7.0965
	sim_grads_norm_tr = -0.0289
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6352
	data_grads_norm = 5.2583
	new_data_grads_norm = 6.9520
	old_data_grads_norm = 6.5284
	sim_grads_norm_tr = 0.0998
-- Starting training on experience 83 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8165
	data_grads_norm = 4.7703
	new_data_grads_norm = 6.0004
	old_data_grads_norm = 6.4943
	sim_grads_norm_tr = 0.0376
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3524
	data_grads_norm = 4.2150
	new_data_grads_norm = 6.0516
	old_data_grads_norm = 5.4816
	sim_grads_norm_tr = 0.1119
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6415
	data_grads_norm = 4.7734
	new_data_grads_norm = 6.1705
	old_data_grads_norm = 6.4649
	sim_grads_norm_tr = 0.0269
-- Starting training on experience 84 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5179
	data_grads_norm = 4.7164
	new_data_grads_norm = 6.1452
	old_data_grads_norm = 6.6990
	sim_grads_norm_tr = 0.0608
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7457
	data_grads_norm = 3.3042
	new_data_grads_norm = 5.6228
	old_data_grads_norm = 4.0524
	sim_grads_norm_tr = -0.0194
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4159
	data_grads_norm = 4.1192
	new_data_grads_norm = 5.6531
	old_data_grads_norm = 5.9298
	sim_grads_norm_tr = -0.0176
-- Starting training on experience 85 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1801
	data_grads_norm = 3.9358
	new_data_grads_norm = 6.2467
	old_data_grads_norm = 5.5896
	sim_grads_norm_tr = -0.0348
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5756
	data_grads_norm = 4.5384
	new_data_grads_norm = 6.9822
	old_data_grads_norm = 6.0781
	sim_grads_norm_tr = -0.0852
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6252
	data_grads_norm = 5.3044
	new_data_grads_norm = 7.1492
	old_data_grads_norm = 5.7675
	sim_grads_norm_tr = 0.1107
-- Starting training on experience 86 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5286
	data_grads_norm = 4.1521
	new_data_grads_norm = 6.2121
	old_data_grads_norm = 5.6372
	sim_grads_norm_tr = -0.0044
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9469
	data_grads_norm = 4.7570
	new_data_grads_norm = 6.4047
	old_data_grads_norm = 6.4943
	sim_grads_norm_tr = 0.0334
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2821
	data_grads_norm = 4.5513
	new_data_grads_norm = 6.0379
	old_data_grads_norm = 7.3811
	sim_grads_norm_tr = -0.0021
-- Starting training on experience 87 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5093
	data_grads_norm = 5.3071
	new_data_grads_norm = 6.6342
	old_data_grads_norm = 6.7522
	sim_grads_norm_tr = -0.0004
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4439
	data_grads_norm = 5.0516
	new_data_grads_norm = 6.9176
	old_data_grads_norm = 6.4788
	sim_grads_norm_tr = 0.0265
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7616
	data_grads_norm = 4.7309
	new_data_grads_norm = 6.5484
	old_data_grads_norm = 6.2908
	sim_grads_norm_tr = 0.0384
-- Starting training on experience 88 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0116
	data_grads_norm = 3.7039
	new_data_grads_norm = 5.4478
	old_data_grads_norm = 5.0191
	sim_grads_norm_tr = -0.0138
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3562
	data_grads_norm = 4.3103
	new_data_grads_norm = 5.7630
	old_data_grads_norm = 5.2344
	sim_grads_norm_tr = -0.0176
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0826
	data_grads_norm = 3.6194
	new_data_grads_norm = 5.3008
	old_data_grads_norm = 5.2540
	sim_grads_norm_tr = -0.0282
-- Starting training on experience 89 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2722
	data_grads_norm = 4.5352
	new_data_grads_norm = 6.6079
	old_data_grads_norm = 4.9824
	sim_grads_norm_tr = 0.0190
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2203
	data_grads_norm = 4.3008
	new_data_grads_norm = 6.5315
	old_data_grads_norm = 5.8929
	sim_grads_norm_tr = 0.0159
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6075
	data_grads_norm = 4.8094
	new_data_grads_norm = 6.5537
	old_data_grads_norm = 5.9123
	sim_grads_norm_tr = 0.0107
-- Starting training on experience 90 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6077
	data_grads_norm = 4.5340
	new_data_grads_norm = 6.2823
	old_data_grads_norm = 5.6467
	sim_grads_norm_tr = -0.0261
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2200
	data_grads_norm = 4.5393
	new_data_grads_norm = 6.7075
	old_data_grads_norm = 5.4074
	sim_grads_norm_tr = 0.0390
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2223
	data_grads_norm = 3.9221
	new_data_grads_norm = 5.9649
	old_data_grads_norm = 5.1357
	sim_grads_norm_tr = -0.0529
-- Starting training on experience 91 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1025
	data_grads_norm = 4.5931
	new_data_grads_norm = 7.1483
	old_data_grads_norm = 5.8031
	sim_grads_norm_tr = -0.0490
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6803
	data_grads_norm = 4.8064
	new_data_grads_norm = 7.1541
	old_data_grads_norm = 6.5579
	sim_grads_norm_tr = 0.0419
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6724
	data_grads_norm = 4.6086
	new_data_grads_norm = 6.2259
	old_data_grads_norm = 5.9944
	sim_grads_norm_tr = 0.0273
-- Starting training on experience 92 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9299
	data_grads_norm = 4.8308
	new_data_grads_norm = 6.3655
	old_data_grads_norm = 6.0763
	sim_grads_norm_tr = 0.0618
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0235
	data_grads_norm = 4.9786
	new_data_grads_norm = 6.4777
	old_data_grads_norm = 6.4867
	sim_grads_norm_tr = 0.0152
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4309
	data_grads_norm = 4.5446
	new_data_grads_norm = 6.1458
	old_data_grads_norm = 6.5795
	sim_grads_norm_tr = -0.0458
-- Starting training on experience 93 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9978
	data_grads_norm = 5.4048
	new_data_grads_norm = 6.4554
	old_data_grads_norm = 8.0018
	sim_grads_norm_tr = -0.0299
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0439
	data_grads_norm = 3.8770
	new_data_grads_norm = 6.5267
	old_data_grads_norm = 4.5476
	sim_grads_norm_tr = -0.0441
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1018
	data_grads_norm = 5.1700
	new_data_grads_norm = 6.9379
	old_data_grads_norm = 7.1977
	sim_grads_norm_tr = 0.1040
-- Starting training on experience 94 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6841
	data_grads_norm = 3.6837
	new_data_grads_norm = 5.4714
	old_data_grads_norm = 5.1536
	sim_grads_norm_tr = -0.0212
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3317
	data_grads_norm = 4.7011
	new_data_grads_norm = 5.3155
	old_data_grads_norm = 7.3837
	sim_grads_norm_tr = -0.0012
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5936
	data_grads_norm = 3.4448
	new_data_grads_norm = 5.8191
	old_data_grads_norm = 4.4669
	sim_grads_norm_tr = -0.0097
-- Starting training on experience 95 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7763
	data_grads_norm = 4.2381
	new_data_grads_norm = 5.8042
	old_data_grads_norm = 5.6990
	sim_grads_norm_tr = 0.0296
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6956
	data_grads_norm = 4.2730
	new_data_grads_norm = 6.3453
	old_data_grads_norm = 5.4015
	sim_grads_norm_tr = 0.0705
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7321
	data_grads_norm = 4.5196
	new_data_grads_norm = 6.7997
	old_data_grads_norm = 6.3255
	sim_grads_norm_tr = -0.0087
-- Starting training on experience 96 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9498
	data_grads_norm = 4.1244
	new_data_grads_norm = 6.0632
	old_data_grads_norm = 4.8899
	sim_grads_norm_tr = 0.0959
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1718
	data_grads_norm = 4.1746
	new_data_grads_norm = 6.2547
	old_data_grads_norm = 5.6172
	sim_grads_norm_tr = -0.0324
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8961
	data_grads_norm = 4.3948
	new_data_grads_norm = 6.3496
	old_data_grads_norm = 5.0239
	sim_grads_norm_tr = -0.0089
-- Starting training on experience 97 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2299
	data_grads_norm = 4.5590
	new_data_grads_norm = 5.7814
	old_data_grads_norm = 5.8761
	sim_grads_norm_tr = 0.1039
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1077
	data_grads_norm = 4.0738
	new_data_grads_norm = 5.5664
	old_data_grads_norm = 4.5654
	sim_grads_norm_tr = 0.0438
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1100
	data_grads_norm = 4.0459
	new_data_grads_norm = 5.4647
	old_data_grads_norm = 5.8444
	sim_grads_norm_tr = -0.0015
-- Starting training on experience 98 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3045
	data_grads_norm = 4.3158
	new_data_grads_norm = 6.5092
	old_data_grads_norm = 5.6089
	sim_grads_norm_tr = 0.0917
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9215
	data_grads_norm = 3.9733
	new_data_grads_norm = 5.6032
	old_data_grads_norm = 6.2855
	sim_grads_norm_tr = -0.0047
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3454
	data_grads_norm = 4.5588
	new_data_grads_norm = 5.9730
	old_data_grads_norm = 6.8424
	sim_grads_norm_tr = -0.0021
-- Starting training on experience 99 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1161
	data_grads_norm = 4.3843
	new_data_grads_norm = 7.3005
	old_data_grads_norm = 4.9474
	sim_grads_norm_tr = -0.0451
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2824
	data_grads_norm = 4.7265
	new_data_grads_norm = 7.5726
	old_data_grads_norm = 5.4950
	sim_grads_norm_tr = 0.0748
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0502
	data_grads_norm = 4.5694
	new_data_grads_norm = 7.2154
	old_data_grads_norm = 5.6444
	sim_grads_norm_tr = 0.0028
-- Starting training on experience 100 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2649
	data_grads_norm = 4.5520
	new_data_grads_norm = 7.4017
	old_data_grads_norm = 4.8079
	sim_grads_norm_tr = 0.0226
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2390
	data_grads_norm = 4.7244
	new_data_grads_norm = 7.2250
	old_data_grads_norm = 5.5753
	sim_grads_norm_tr = 0.0467
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4376
	data_grads_norm = 4.9440
	new_data_grads_norm = 7.5870
	old_data_grads_norm = 6.3367
	sim_grads_norm_tr = 0.0225
-- Starting training on experience 101 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5465
	data_grads_norm = 4.6936
	new_data_grads_norm = 7.2895
	old_data_grads_norm = 6.0292
	sim_grads_norm_tr = 0.0178
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2625
	data_grads_norm = 5.2569
	new_data_grads_norm = 7.0572
	old_data_grads_norm = 5.9708
	sim_grads_norm_tr = 0.0463
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1746
	data_grads_norm = 4.8706
	new_data_grads_norm = 7.5818
	old_data_grads_norm = 5.0115
	sim_grads_norm_tr = -0.0197
-- Starting training on experience 102 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7143
	data_grads_norm = 4.0117
	new_data_grads_norm = 6.4263
	old_data_grads_norm = 5.2673
	sim_grads_norm_tr = -0.0510
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4905
	data_grads_norm = 5.2111
	new_data_grads_norm = 6.5928
	old_data_grads_norm = 7.2795
	sim_grads_norm_tr = 0.0723
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8377
	data_grads_norm = 4.7402
	new_data_grads_norm = 6.2352
	old_data_grads_norm = 5.9857
	sim_grads_norm_tr = 0.1118
-- Starting training on experience 103 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4353
	data_grads_norm = 4.4920
	new_data_grads_norm = 6.6127
	old_data_grads_norm = 6.5770
	sim_grads_norm_tr = -0.0128
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0027
	data_grads_norm = 4.8784
	new_data_grads_norm = 6.5495
	old_data_grads_norm = 7.8867
	sim_grads_norm_tr = 0.0533
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8725
	data_grads_norm = 4.0512
	new_data_grads_norm = 6.6468
	old_data_grads_norm = 5.1826
	sim_grads_norm_tr = -0.0403
-- Starting training on experience 104 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3413
	data_grads_norm = 4.9946
	new_data_grads_norm = 6.1395
	old_data_grads_norm = 7.9232
	sim_grads_norm_tr = 0.0259
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0452
	data_grads_norm = 5.0631
	new_data_grads_norm = 6.6511
	old_data_grads_norm = 6.4747
	sim_grads_norm_tr = 0.0779
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5700
	data_grads_norm = 4.7613
	new_data_grads_norm = 6.4077
	old_data_grads_norm = 6.5003
	sim_grads_norm_tr = 0.0572
-- Starting training on experience 105 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0650
	data_grads_norm = 4.3473
	new_data_grads_norm = 6.2086
	old_data_grads_norm = 6.3873
	sim_grads_norm_tr = -0.0253
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8840
	data_grads_norm = 3.7908
	new_data_grads_norm = 6.3582
	old_data_grads_norm = 4.4012
	sim_grads_norm_tr = -0.0045
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0254
	data_grads_norm = 4.3415
	new_data_grads_norm = 6.0939
	old_data_grads_norm = 5.1596
	sim_grads_norm_tr = -0.0130
-- Starting training on experience 106 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2123
	data_grads_norm = 5.0736
	new_data_grads_norm = 6.7345
	old_data_grads_norm = 7.1649
	sim_grads_norm_tr = -0.0504
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4728
	data_grads_norm = 5.0254
	new_data_grads_norm = 7.9500
	old_data_grads_norm = 5.7652
	sim_grads_norm_tr = -0.0206
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0900
	data_grads_norm = 3.7845
	new_data_grads_norm = 7.0346
	old_data_grads_norm = 4.2408
	sim_grads_norm_tr = -0.0199
-- Starting training on experience 107 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3247
	data_grads_norm = 4.4726
	new_data_grads_norm = 5.8212
	old_data_grads_norm = 6.4067
	sim_grads_norm_tr = -0.0231
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3801
	data_grads_norm = 4.4812
	new_data_grads_norm = 5.8144
	old_data_grads_norm = 5.5274
	sim_grads_norm_tr = 0.0210
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6254
	data_grads_norm = 4.7679
	new_data_grads_norm = 5.8832
	old_data_grads_norm = 6.2956
	sim_grads_norm_tr = 0.0735
-- Starting training on experience 108 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4269
	data_grads_norm = 4.0711
	new_data_grads_norm = 5.2765
	old_data_grads_norm = 5.3038
	sim_grads_norm_tr = 0.0570
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8170
	data_grads_norm = 4.7623
	new_data_grads_norm = 5.5892
	old_data_grads_norm = 7.7254
	sim_grads_norm_tr = 0.0168
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8314
	data_grads_norm = 4.4427
	new_data_grads_norm = 5.4561
	old_data_grads_norm = 6.3151
	sim_grads_norm_tr = -0.0163
-- Starting training on experience 109 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7968
	data_grads_norm = 4.4015
	new_data_grads_norm = 6.4608
	old_data_grads_norm = 4.9718
	sim_grads_norm_tr = 0.0343
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6116
	data_grads_norm = 4.8986
	new_data_grads_norm = 6.4271
	old_data_grads_norm = 6.5208
	sim_grads_norm_tr = 0.0215
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5680
	data_grads_norm = 5.0580
	new_data_grads_norm = 7.1376
	old_data_grads_norm = 5.6951
	sim_grads_norm_tr = 0.1362
-- Starting training on experience 110 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0277
	data_grads_norm = 4.5063
	new_data_grads_norm = 6.3104
	old_data_grads_norm = 5.4944
	sim_grads_norm_tr = 0.2494
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1194
	data_grads_norm = 4.3000
	new_data_grads_norm = 6.4887
	old_data_grads_norm = 5.4911
	sim_grads_norm_tr = 0.0550
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4300
	data_grads_norm = 4.1869
	new_data_grads_norm = 5.5252
	old_data_grads_norm = 5.8833
	sim_grads_norm_tr = -0.1125
-- Starting training on experience 111 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6280
	data_grads_norm = 4.1450
	new_data_grads_norm = 6.0854
	old_data_grads_norm = 5.1295
	sim_grads_norm_tr = -0.0434
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2367
	data_grads_norm = 5.0277
	new_data_grads_norm = 6.4078
	old_data_grads_norm = 6.7159
	sim_grads_norm_tr = -0.0272
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2405
	data_grads_norm = 4.5153
	new_data_grads_norm = 6.4421
	old_data_grads_norm = 7.1170
	sim_grads_norm_tr = 0.0274
-- Starting training on experience 112 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1579
	data_grads_norm = 3.6791
	new_data_grads_norm = 5.3654
	old_data_grads_norm = 4.9488
	sim_grads_norm_tr = -0.0301
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8998
	data_grads_norm = 3.9171
	new_data_grads_norm = 5.6435
	old_data_grads_norm = 6.2467
	sim_grads_norm_tr = 0.0793
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2642
	data_grads_norm = 4.4867
	new_data_grads_norm = 6.2378
	old_data_grads_norm = 5.9240
	sim_grads_norm_tr = 0.0482
-- Starting training on experience 113 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2465
	data_grads_norm = 4.2802
	new_data_grads_norm = 5.8212
	old_data_grads_norm = 5.3107
	sim_grads_norm_tr = 0.0661
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4540
	data_grads_norm = 4.4902
	new_data_grads_norm = 5.4648
	old_data_grads_norm = 7.0031
	sim_grads_norm_tr = -0.0014
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1589
	data_grads_norm = 4.2834
	new_data_grads_norm = 5.6433
	old_data_grads_norm = 6.7663
	sim_grads_norm_tr = -0.0709
-- Starting training on experience 114 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0783
	data_grads_norm = 4.9021
	new_data_grads_norm = 7.5321
	old_data_grads_norm = 6.5982
	sim_grads_norm_tr = 0.0379
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5281
	data_grads_norm = 5.1151
	new_data_grads_norm = 6.6470
	old_data_grads_norm = 7.0624
	sim_grads_norm_tr = 0.0165
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9847
	data_grads_norm = 5.1438
	new_data_grads_norm = 5.6615
	old_data_grads_norm = 7.3746
	sim_grads_norm_tr = 0.0859
-- Starting training on experience 115 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9223
	data_grads_norm = 4.0386
	new_data_grads_norm = 5.3306
	old_data_grads_norm = 5.6656
	sim_grads_norm_tr = 0.0610
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8507
	data_grads_norm = 4.1029
	new_data_grads_norm = 5.4871
	old_data_grads_norm = 6.1693
	sim_grads_norm_tr = -0.0012
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1396
	data_grads_norm = 4.0171
	new_data_grads_norm = 5.8976
	old_data_grads_norm = 5.8807
	sim_grads_norm_tr = 0.0249
-- Starting training on experience 116 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0770
	data_grads_norm = 4.3701
	new_data_grads_norm = 6.9504
	old_data_grads_norm = 5.6261
	sim_grads_norm_tr = -0.0194
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3839
	data_grads_norm = 4.2008
	new_data_grads_norm = 5.7588
	old_data_grads_norm = 6.2152
	sim_grads_norm_tr = 0.0117
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9303
	data_grads_norm = 3.8242
	new_data_grads_norm = 5.6620
	old_data_grads_norm = 4.9455
	sim_grads_norm_tr = -0.0480
-- Starting training on experience 117 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1715
	data_grads_norm = 4.6570
	new_data_grads_norm = 5.2587
	old_data_grads_norm = 7.1514
	sim_grads_norm_tr = 0.0208
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3686
	data_grads_norm = 4.9319
	new_data_grads_norm = 5.2219
	old_data_grads_norm = 7.3796
	sim_grads_norm_tr = 0.0150
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4823
	data_grads_norm = 5.0276
	new_data_grads_norm = 5.7788
	old_data_grads_norm = 7.2066
	sim_grads_norm_tr = -0.0087
-- Starting training on experience 118 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7756
	data_grads_norm = 4.1712
	new_data_grads_norm = 5.6625
	old_data_grads_norm = 6.2633
	sim_grads_norm_tr = 0.0081
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6727
	data_grads_norm = 3.6617
	new_data_grads_norm = 5.7978
	old_data_grads_norm = 4.4583
	sim_grads_norm_tr = 0.0478
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7512
	data_grads_norm = 3.9849
	new_data_grads_norm = 6.1377
	old_data_grads_norm = 5.7841
	sim_grads_norm_tr = -0.0537
-- Starting training on experience 119 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9803
	data_grads_norm = 4.3926
	new_data_grads_norm = 6.7862
	old_data_grads_norm = 5.2143
	sim_grads_norm_tr = -0.0195
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2277
	data_grads_norm = 4.4844
	new_data_grads_norm = 6.4138
	old_data_grads_norm = 5.1122
	sim_grads_norm_tr = -0.0219
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6928
	data_grads_norm = 5.2013
	new_data_grads_norm = 6.7183
	old_data_grads_norm = 6.8533
	sim_grads_norm_tr = 0.0715
-- Starting training on experience 120 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0767
	data_grads_norm = 4.4894
	new_data_grads_norm = 6.7033
	old_data_grads_norm = 5.7578
	sim_grads_norm_tr = 0.0729
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9291
	data_grads_norm = 3.8883
	new_data_grads_norm = 5.6897
	old_data_grads_norm = 4.5076
	sim_grads_norm_tr = 0.0879
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0881
	data_grads_norm = 4.3350
	new_data_grads_norm = 5.4152
	old_data_grads_norm = 6.2420
	sim_grads_norm_tr = 0.0852
-- Starting training on experience 121 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1444
	data_grads_norm = 5.0115
	new_data_grads_norm = 5.9529
	old_data_grads_norm = 7.6549
	sim_grads_norm_tr = 0.0241
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1720
	data_grads_norm = 4.3830
	new_data_grads_norm = 7.1047
	old_data_grads_norm = 5.6001
	sim_grads_norm_tr = -0.1092
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6850
	data_grads_norm = 3.9991
	new_data_grads_norm = 5.6560
	old_data_grads_norm = 4.9740
	sim_grads_norm_tr = -0.0236
-- Starting training on experience 122 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6962
	data_grads_norm = 4.7598
	new_data_grads_norm = 6.3747
	old_data_grads_norm = 6.9736
	sim_grads_norm_tr = 0.0466
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2980
	data_grads_norm = 3.9914
	new_data_grads_norm = 5.7498
	old_data_grads_norm = 5.3645
	sim_grads_norm_tr = 0.0239
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2063
	data_grads_norm = 4.2765
	new_data_grads_norm = 6.4671
	old_data_grads_norm = 5.9037
	sim_grads_norm_tr = 0.0230
-- Starting training on experience 123 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9167
	data_grads_norm = 5.3764
	new_data_grads_norm = 6.7885
	old_data_grads_norm = 6.8803
	sim_grads_norm_tr = 0.0254
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6953
	data_grads_norm = 5.1743
	new_data_grads_norm = 6.3994
	old_data_grads_norm = 6.9472
	sim_grads_norm_tr = 0.0905
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1602
	data_grads_norm = 4.4438
	new_data_grads_norm = 6.1116
	old_data_grads_norm = 6.5324
	sim_grads_norm_tr = -0.0509
-- Starting training on experience 124 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6911
	data_grads_norm = 4.8351
	new_data_grads_norm = 6.5048
	old_data_grads_norm = 6.3681
	sim_grads_norm_tr = 0.0016
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2852
	data_grads_norm = 4.5535
	new_data_grads_norm = 6.4265
	old_data_grads_norm = 6.8763
	sim_grads_norm_tr = -0.0199
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2363
	data_grads_norm = 4.1573
	new_data_grads_norm = 6.7940
	old_data_grads_norm = 4.7678
	sim_grads_norm_tr = 0.0192
-- Starting training on experience 125 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3935
	data_grads_norm = 5.1734
	new_data_grads_norm = 6.7273
	old_data_grads_norm = 8.0955
	sim_grads_norm_tr = 0.0766
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5755
	data_grads_norm = 5.2572
	new_data_grads_norm = 5.9733
	old_data_grads_norm = 8.0688
	sim_grads_norm_tr = 0.0677
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7629
	data_grads_norm = 4.6737
	new_data_grads_norm = 6.2574
	old_data_grads_norm = 7.0253
	sim_grads_norm_tr = -0.0270
-- Starting training on experience 126 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2984
	data_grads_norm = 3.8035
	new_data_grads_norm = 5.5560
	old_data_grads_norm = 4.9590
	sim_grads_norm_tr = -0.0017
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1152
	data_grads_norm = 4.5368
	new_data_grads_norm = 6.2347
	old_data_grads_norm = 5.9067
	sim_grads_norm_tr = 0.0255
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9143
	data_grads_norm = 4.5239
	new_data_grads_norm = 5.7672
	old_data_grads_norm = 6.6730
	sim_grads_norm_tr = 0.0013
-- Starting training on experience 127 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8366
	data_grads_norm = 4.2112
	new_data_grads_norm = 5.0896
	old_data_grads_norm = 6.7605
	sim_grads_norm_tr = 0.0346
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8708
	data_grads_norm = 4.0636
	new_data_grads_norm = 4.9888
	old_data_grads_norm = 5.6391
	sim_grads_norm_tr = 0.0207
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1920
	data_grads_norm = 4.2968
	new_data_grads_norm = 5.0222
	old_data_grads_norm = 7.3478
	sim_grads_norm_tr = -0.0087
-- Starting training on experience 128 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1349
	data_grads_norm = 3.9547
	new_data_grads_norm = 5.8672
	old_data_grads_norm = 5.5600
	sim_grads_norm_tr = 0.0171
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1754
	data_grads_norm = 4.3286
	new_data_grads_norm = 6.0822
	old_data_grads_norm = 6.2818
	sim_grads_norm_tr = 0.0450
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2061
	data_grads_norm = 4.6870
	new_data_grads_norm = 5.6519
	old_data_grads_norm = 7.2987
	sim_grads_norm_tr = -0.0311
-- Starting training on experience 129 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7935
	data_grads_norm = 4.2960
	new_data_grads_norm = 6.8421
	old_data_grads_norm = 4.4099
	sim_grads_norm_tr = 0.0712
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9240
	data_grads_norm = 4.3906
	new_data_grads_norm = 7.2897
	old_data_grads_norm = 5.4574
	sim_grads_norm_tr = 0.0096
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8557
	data_grads_norm = 5.0756
	new_data_grads_norm = 8.2627
	old_data_grads_norm = 6.4486
	sim_grads_norm_tr = -0.0189
-- Starting training on experience 130 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3042
	data_grads_norm = 4.1418
	new_data_grads_norm = 6.8527
	old_data_grads_norm = 4.4297
	sim_grads_norm_tr = 0.0783
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3092
	data_grads_norm = 4.6097
	new_data_grads_norm = 6.4393
	old_data_grads_norm = 4.7237
	sim_grads_norm_tr = 0.1536
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3252
	data_grads_norm = 4.8337
	new_data_grads_norm = 6.5176
	old_data_grads_norm = 7.0902
	sim_grads_norm_tr = -0.0667
-- Starting training on experience 131 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2830
	data_grads_norm = 3.8808
	new_data_grads_norm = 7.2499
	old_data_grads_norm = 3.8156
	sim_grads_norm_tr = -0.0461
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6141
	data_grads_norm = 4.6121
	new_data_grads_norm = 7.0544
	old_data_grads_norm = 6.0457
	sim_grads_norm_tr = -0.0038
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6800
	data_grads_norm = 5.2501
	new_data_grads_norm = 6.4816
	old_data_grads_norm = 6.5479
	sim_grads_norm_tr = 0.0435
-- Starting training on experience 132 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0600
	data_grads_norm = 4.2727
	new_data_grads_norm = 5.9845
	old_data_grads_norm = 6.2248
	sim_grads_norm_tr = -0.0076
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0321
	data_grads_norm = 4.5686
	new_data_grads_norm = 7.0394
	old_data_grads_norm = 5.6091
	sim_grads_norm_tr = 0.0076
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4263
	data_grads_norm = 4.9458
	new_data_grads_norm = 6.2087
	old_data_grads_norm = 7.9521
	sim_grads_norm_tr = 0.0146
-- Starting training on experience 133 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2305
	data_grads_norm = 4.9903
	new_data_grads_norm = 5.8254
	old_data_grads_norm = 8.1724
	sim_grads_norm_tr = 0.0418
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0652
	data_grads_norm = 4.0056
	new_data_grads_norm = 5.3616
	old_data_grads_norm = 5.6660
	sim_grads_norm_tr = -0.0143
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4324
	data_grads_norm = 5.3059
	new_data_grads_norm = 5.9270
	old_data_grads_norm = 7.0908
	sim_grads_norm_tr = 0.0851
-- Starting training on experience 134 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2583
	data_grads_norm = 4.9118
	new_data_grads_norm = 6.3907
	old_data_grads_norm = 7.0255
	sim_grads_norm_tr = 0.0114
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3359
	data_grads_norm = 4.5726
	new_data_grads_norm = 6.5190
	old_data_grads_norm = 6.0435
	sim_grads_norm_tr = 0.0802
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4501
	data_grads_norm = 4.1626
	new_data_grads_norm = 6.1129
	old_data_grads_norm = 4.8096
	sim_grads_norm_tr = 0.0451
-- Starting training on experience 135 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8527
	data_grads_norm = 3.9822
	new_data_grads_norm = 6.8716
	old_data_grads_norm = 5.1448
	sim_grads_norm_tr = -0.0610
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4244
	data_grads_norm = 5.2941
	new_data_grads_norm = 6.9074
	old_data_grads_norm = 7.5534
	sim_grads_norm_tr = 0.0535
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4660
	data_grads_norm = 5.3059
	new_data_grads_norm = 6.8689
	old_data_grads_norm = 8.2872
	sim_grads_norm_tr = -0.0842
-- Starting training on experience 136 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3510
	data_grads_norm = 4.6521
	new_data_grads_norm = 7.4592
	old_data_grads_norm = 5.7520
	sim_grads_norm_tr = 0.0691
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3006
	data_grads_norm = 5.5593
	new_data_grads_norm = 7.6393
	old_data_grads_norm = 7.4174
	sim_grads_norm_tr = 0.0579
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6936
	data_grads_norm = 4.9446
	new_data_grads_norm = 6.3593
	old_data_grads_norm = 7.1514
	sim_grads_norm_tr = 0.0193
-- Starting training on experience 137 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2319
	data_grads_norm = 4.0982
	new_data_grads_norm = 6.5122
	old_data_grads_norm = 4.5371
	sim_grads_norm_tr = -0.0422
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9803
	data_grads_norm = 5.4990
	new_data_grads_norm = 6.9510
	old_data_grads_norm = 7.3952
	sim_grads_norm_tr = -0.0465
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4570
	data_grads_norm = 5.1590
	new_data_grads_norm = 7.1715
	old_data_grads_norm = 8.1476
	sim_grads_norm_tr = 0.0755
-- Starting training on experience 138 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7091
	data_grads_norm = 5.0833
	new_data_grads_norm = 7.4696
	old_data_grads_norm = 6.4652
	sim_grads_norm_tr = -0.0298
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1484
	data_grads_norm = 5.3629
	new_data_grads_norm = 8.3718
	old_data_grads_norm = 5.9671
	sim_grads_norm_tr = 0.0641
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4289
	data_grads_norm = 4.3421
	new_data_grads_norm = 7.1942
	old_data_grads_norm = 4.8974
	sim_grads_norm_tr = 0.0438
-- Starting training on experience 139 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8890
	data_grads_norm = 4.9270
	new_data_grads_norm = 7.5176
	old_data_grads_norm = 5.5965
	sim_grads_norm_tr = 0.0502
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4185
	data_grads_norm = 5.4770
	new_data_grads_norm = 7.4547
	old_data_grads_norm = 7.3727
	sim_grads_norm_tr = 0.0576
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1831
	data_grads_norm = 5.1344
	new_data_grads_norm = 7.5042
	old_data_grads_norm = 7.0602
	sim_grads_norm_tr = 0.0439
-- Starting training on experience 140 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5931
	data_grads_norm = 5.2130
	new_data_grads_norm = 7.2373
	old_data_grads_norm = 8.1974
	sim_grads_norm_tr = 0.0852
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1160
	data_grads_norm = 5.3439
	new_data_grads_norm = 7.6849
	old_data_grads_norm = 8.1859
	sim_grads_norm_tr = 0.0348
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3934
	data_grads_norm = 4.8947
	new_data_grads_norm = 7.1735
	old_data_grads_norm = 6.4655
	sim_grads_norm_tr = -0.0149
-- Starting training on experience 141 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8848
	data_grads_norm = 4.5342
	new_data_grads_norm = 6.7370
	old_data_grads_norm = 5.9929
	sim_grads_norm_tr = -0.0160
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2346
	data_grads_norm = 5.0714
	new_data_grads_norm = 6.9476
	old_data_grads_norm = 6.7261
	sim_grads_norm_tr = 0.1061
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4216
	data_grads_norm = 4.8430
	new_data_grads_norm = 6.8596
	old_data_grads_norm = 6.9149
	sim_grads_norm_tr = -0.0670
-- Starting training on experience 142 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5022
	data_grads_norm = 4.7475
	new_data_grads_norm = 6.2537
	old_data_grads_norm = 6.1006
	sim_grads_norm_tr = 0.0905
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6784
	data_grads_norm = 5.3285
	new_data_grads_norm = 6.2843
	old_data_grads_norm = 7.2231
	sim_grads_norm_tr = 0.0293
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7488
	data_grads_norm = 4.8785
	new_data_grads_norm = 6.4657
	old_data_grads_norm = 7.1541
	sim_grads_norm_tr = 0.0012
-- Starting training on experience 143 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7973
	data_grads_norm = 3.9049
	new_data_grads_norm = 6.1913
	old_data_grads_norm = 4.7828
	sim_grads_norm_tr = 0.0333
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0787
	data_grads_norm = 4.4185
	new_data_grads_norm = 6.4505
	old_data_grads_norm = 6.1779
	sim_grads_norm_tr = 0.0111
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1763
	data_grads_norm = 5.3268
	new_data_grads_norm = 6.5074
	old_data_grads_norm = 7.9648
	sim_grads_norm_tr = 0.0525
-- Starting training on experience 144 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1049
	data_grads_norm = 4.8115
	new_data_grads_norm = 7.0741
	old_data_grads_norm = 5.5589
	sim_grads_norm_tr = 0.0718
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7494
	data_grads_norm = 4.8436
	new_data_grads_norm = 7.2308
	old_data_grads_norm = 6.6375
	sim_grads_norm_tr = 0.0352
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2889
	data_grads_norm = 3.9675
	new_data_grads_norm = 6.3368
	old_data_grads_norm = 6.1080
	sim_grads_norm_tr = -0.0744
-- Starting training on experience 145 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9269
	data_grads_norm = 4.9533
	new_data_grads_norm = 7.5775
	old_data_grads_norm = 6.9974
	sim_grads_norm_tr = -0.0127
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8094
	data_grads_norm = 4.2317
	new_data_grads_norm = 7.7471
	old_data_grads_norm = 5.1848
	sim_grads_norm_tr = -0.0206
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0675
	data_grads_norm = 4.9449
	new_data_grads_norm = 6.7266
	old_data_grads_norm = 5.6757
	sim_grads_norm_tr = 0.0105
-- Starting training on experience 146 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5953
	data_grads_norm = 5.1823
	new_data_grads_norm = 7.4259
	old_data_grads_norm = 7.1526
	sim_grads_norm_tr = -0.0445
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4034
	data_grads_norm = 4.9154
	new_data_grads_norm = 7.4259
	old_data_grads_norm = 5.4908
	sim_grads_norm_tr = 0.1133
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4828
	data_grads_norm = 4.7959
	new_data_grads_norm = 7.3476
	old_data_grads_norm = 5.3825
	sim_grads_norm_tr = -0.0500
-- Starting training on experience 147 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8996
	data_grads_norm = 3.9369
	new_data_grads_norm = 6.3083
	old_data_grads_norm = 5.6462
	sim_grads_norm_tr = -0.0420
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0822
	data_grads_norm = 4.8248
	new_data_grads_norm = 7.3843
	old_data_grads_norm = 6.0012
	sim_grads_norm_tr = 0.0363
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6395
	data_grads_norm = 5.7419
	new_data_grads_norm = 7.1533
	old_data_grads_norm = 7.9012
	sim_grads_norm_tr = 0.0554
-- Starting training on experience 148 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1986
	data_grads_norm = 4.3659
	new_data_grads_norm = 7.0514
	old_data_grads_norm = 4.5189
	sim_grads_norm_tr = 0.0006
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4483
	data_grads_norm = 4.8238
	new_data_grads_norm = 6.4811
	old_data_grads_norm = 6.8967
	sim_grads_norm_tr = 0.1167
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2464
	data_grads_norm = 4.2966
	new_data_grads_norm = 6.3299
	old_data_grads_norm = 5.3643
	sim_grads_norm_tr = -0.0149
-- Starting training on experience 149 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5885
	data_grads_norm = 4.8200
	new_data_grads_norm = 6.6620
	old_data_grads_norm = 6.7525
	sim_grads_norm_tr = 0.0366
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7606
	data_grads_norm = 5.2917
	new_data_grads_norm = 6.5359
	old_data_grads_norm = 7.7664
	sim_grads_norm_tr = -0.0147
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4290
	data_grads_norm = 4.6902
	new_data_grads_norm = 6.6932
	old_data_grads_norm = 6.7097
	sim_grads_norm_tr = -0.0163
-- Starting training on experience 150 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6687
	data_grads_norm = 3.4982
	new_data_grads_norm = 6.2259
	old_data_grads_norm = 4.3550
	sim_grads_norm_tr = -0.0645
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1588
	data_grads_norm = 4.3429
	new_data_grads_norm = 6.4638
	old_data_grads_norm = 5.8150
	sim_grads_norm_tr = -0.0125
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6406
	data_grads_norm = 3.4316
	new_data_grads_norm = 6.1349
	old_data_grads_norm = 4.1737
	sim_grads_norm_tr = -0.0369
-- Starting training on experience 151 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2035
	data_grads_norm = 4.6907
	new_data_grads_norm = 6.2993
	old_data_grads_norm = 7.1124
	sim_grads_norm_tr = 0.0090
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5164
	data_grads_norm = 5.4873
	new_data_grads_norm = 7.2933
	old_data_grads_norm = 7.0267
	sim_grads_norm_tr = 0.0890
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9641
	data_grads_norm = 4.4531
	new_data_grads_norm = 6.9425
	old_data_grads_norm = 5.8247
	sim_grads_norm_tr = -0.0197
-- Starting training on experience 152 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6964
	data_grads_norm = 4.9794
	new_data_grads_norm = 7.0862
	old_data_grads_norm = 6.0992
	sim_grads_norm_tr = 0.0652
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4234
	data_grads_norm = 5.0374
	new_data_grads_norm = 6.7292
	old_data_grads_norm = 7.6202
	sim_grads_norm_tr = -0.0194
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5238
	data_grads_norm = 4.5874
	new_data_grads_norm = 7.2475
	old_data_grads_norm = 5.2754
	sim_grads_norm_tr = 0.0151
-- Starting training on experience 153 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7531
	data_grads_norm = 4.9230
	new_data_grads_norm = 6.6662
	old_data_grads_norm = 6.3076
	sim_grads_norm_tr = -0.0241
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8285
	data_grads_norm = 4.9299
	new_data_grads_norm = 6.6554
	old_data_grads_norm = 6.3920
	sim_grads_norm_tr = 0.1104
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0654
	data_grads_norm = 4.2516
	new_data_grads_norm = 6.3345
	old_data_grads_norm = 5.3599
	sim_grads_norm_tr = -0.0173
-- Starting training on experience 154 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3998
	data_grads_norm = 5.0290
	new_data_grads_norm = 6.9291
	old_data_grads_norm = 7.5548
	sim_grads_norm_tr = -0.0249
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1414
	data_grads_norm = 4.9364
	new_data_grads_norm = 7.0179
	old_data_grads_norm = 6.5866
	sim_grads_norm_tr = 0.0096
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3105
	data_grads_norm = 4.5732
	new_data_grads_norm = 6.9898
	old_data_grads_norm = 5.8128
	sim_grads_norm_tr = 0.0347
-- Starting training on experience 155 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5522
	data_grads_norm = 4.8894
	new_data_grads_norm = 6.5295
	old_data_grads_norm = 6.2440
	sim_grads_norm_tr = -0.0145
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9362
	data_grads_norm = 5.0883
	new_data_grads_norm = 7.4795
	old_data_grads_norm = 6.0760
	sim_grads_norm_tr = -0.0415
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5967
	data_grads_norm = 5.0398
	new_data_grads_norm = 7.2723
	old_data_grads_norm = 6.3677
	sim_grads_norm_tr = 0.1305
-- Starting training on experience 156 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8062
	data_grads_norm = 4.4212
	new_data_grads_norm = 6.5242
	old_data_grads_norm = 6.8510
	sim_grads_norm_tr = -0.0187
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0871
	data_grads_norm = 4.2725
	new_data_grads_norm = 6.7142
	old_data_grads_norm = 4.8992
	sim_grads_norm_tr = 0.0051
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9322
	data_grads_norm = 4.9910
	new_data_grads_norm = 7.3029
	old_data_grads_norm = 4.9000
	sim_grads_norm_tr = 0.0147
-- Starting training on experience 157 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2024
	data_grads_norm = 4.4559
	new_data_grads_norm = 6.9251
	old_data_grads_norm = 5.0178
	sim_grads_norm_tr = 0.0281
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7632
	data_grads_norm = 5.1320
	new_data_grads_norm = 6.4133
	old_data_grads_norm = 7.1144
	sim_grads_norm_tr = -0.0176
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2085
	data_grads_norm = 4.0538
	new_data_grads_norm = 6.1044
	old_data_grads_norm = 4.2880
	sim_grads_norm_tr = 0.0661
-- Starting training on experience 158 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1112
	data_grads_norm = 5.2652
	new_data_grads_norm = 6.7725
	old_data_grads_norm = 7.3058
	sim_grads_norm_tr = 0.0617
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7633
	data_grads_norm = 4.5325
	new_data_grads_norm = 6.7607
	old_data_grads_norm = 6.2553
	sim_grads_norm_tr = -0.0565
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1517
	data_grads_norm = 3.9121
	new_data_grads_norm = 6.3554
	old_data_grads_norm = 4.3087
	sim_grads_norm_tr = -0.0053
-- Starting training on experience 159 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7232
	data_grads_norm = 5.4108
	new_data_grads_norm = 7.5409
	old_data_grads_norm = 6.2921
	sim_grads_norm_tr = 0.0691
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4592
	data_grads_norm = 4.8688
	new_data_grads_norm = 6.8074
	old_data_grads_norm = 6.3041
	sim_grads_norm_tr = -0.0168
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6117
	data_grads_norm = 4.3323
	new_data_grads_norm = 6.2304
	old_data_grads_norm = 5.7549
	sim_grads_norm_tr = 0.0149
-- Starting training on experience 160 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7497
	data_grads_norm = 4.8525
	new_data_grads_norm = 6.2501
	old_data_grads_norm = 7.5258
	sim_grads_norm_tr = -0.0064
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0719
	data_grads_norm = 4.6525
	new_data_grads_norm = 6.4248
	old_data_grads_norm = 7.2319
	sim_grads_norm_tr = -0.0163
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1626
	data_grads_norm = 4.1698
	new_data_grads_norm = 6.4457
	old_data_grads_norm = 4.6944
	sim_grads_norm_tr = 0.0197
-- Starting training on experience 161 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0094
	data_grads_norm = 4.2288
	new_data_grads_norm = 6.6926
	old_data_grads_norm = 4.4000
	sim_grads_norm_tr = -0.0024
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9606
	data_grads_norm = 4.3173
	new_data_grads_norm = 6.5143
	old_data_grads_norm = 5.0441
	sim_grads_norm_tr = 0.0956
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9514
	data_grads_norm = 3.8615
	new_data_grads_norm = 6.2510
	old_data_grads_norm = 4.8749
	sim_grads_norm_tr = -0.0250
-- Starting training on experience 162 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1675
	data_grads_norm = 4.1551
	new_data_grads_norm = 7.2549
	old_data_grads_norm = 4.7707
	sim_grads_norm_tr = -0.0116
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1771
	data_grads_norm = 4.2616
	new_data_grads_norm = 7.2037
	old_data_grads_norm = 5.8185
	sim_grads_norm_tr = -0.0088
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5644
	data_grads_norm = 5.0227
	new_data_grads_norm = 7.1032
	old_data_grads_norm = 7.8917
	sim_grads_norm_tr = 0.0269
-- Starting training on experience 163 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3931
	data_grads_norm = 5.4723
	new_data_grads_norm = 5.6892
	old_data_grads_norm = 7.5450
	sim_grads_norm_tr = 0.0457
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0261
	data_grads_norm = 4.4589
	new_data_grads_norm = 6.1436
	old_data_grads_norm = 6.7452
	sim_grads_norm_tr = -0.0157
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2687
	data_grads_norm = 4.8802
	new_data_grads_norm = 6.4413
	old_data_grads_norm = 6.8032
	sim_grads_norm_tr = 0.0140
-- Starting training on experience 164 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8819
	data_grads_norm = 4.2338
	new_data_grads_norm = 6.6815
	old_data_grads_norm = 5.7391
	sim_grads_norm_tr = -0.0074
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0478
	data_grads_norm = 4.7716
	new_data_grads_norm = 7.7284
	old_data_grads_norm = 6.5546
	sim_grads_norm_tr = 0.0451
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1041
	data_grads_norm = 4.4453
	new_data_grads_norm = 6.8398
	old_data_grads_norm = 6.4464
	sim_grads_norm_tr = -0.0479
-- Starting training on experience 165 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5739
	data_grads_norm = 4.4847
	new_data_grads_norm = 6.9042
	old_data_grads_norm = 6.0477
	sim_grads_norm_tr = -0.0379
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9903
	data_grads_norm = 6.2281
	new_data_grads_norm = 7.2206
	old_data_grads_norm = 9.0354
	sim_grads_norm_tr = 0.1006
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4328
	data_grads_norm = 4.8642
	new_data_grads_norm = 6.4538
	old_data_grads_norm = 6.9423
	sim_grads_norm_tr = 0.0346
-- Starting training on experience 166 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0634
	data_grads_norm = 4.7407
	new_data_grads_norm = 6.3045
	old_data_grads_norm = 7.1924
	sim_grads_norm_tr = 0.0125
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1288
	data_grads_norm = 4.5048
	new_data_grads_norm = 6.3244
	old_data_grads_norm = 6.1556
	sim_grads_norm_tr = 0.0054
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4902
	data_grads_norm = 4.7554
	new_data_grads_norm = 7.2292
	old_data_grads_norm = 5.7028
	sim_grads_norm_tr = 0.0120
-- Starting training on experience 167 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1233
	data_grads_norm = 4.0498
	new_data_grads_norm = 6.8132
	old_data_grads_norm = 5.1864
	sim_grads_norm_tr = -0.0043
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3144
	data_grads_norm = 4.7068
	new_data_grads_norm = 6.6420
	old_data_grads_norm = 6.4351
	sim_grads_norm_tr = 0.0154
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6701
	data_grads_norm = 5.1897
	new_data_grads_norm = 6.8460
	old_data_grads_norm = 6.8542
	sim_grads_norm_tr = 0.0276
-- Starting training on experience 168 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9709
	data_grads_norm = 4.3117
	new_data_grads_norm = 5.9411
	old_data_grads_norm = 6.4712
	sim_grads_norm_tr = 0.0095
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2212
	data_grads_norm = 4.2765
	new_data_grads_norm = 6.3961
	old_data_grads_norm = 5.2089
	sim_grads_norm_tr = 0.0494
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1279
	data_grads_norm = 4.1963
	new_data_grads_norm = 5.7746
	old_data_grads_norm = 5.9430
	sim_grads_norm_tr = 0.0059
-- Starting training on experience 169 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3241
	data_grads_norm = 4.9794
	new_data_grads_norm = 7.5847
	old_data_grads_norm = 6.1859
	sim_grads_norm_tr = -0.0797
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8701
	data_grads_norm = 4.3456
	new_data_grads_norm = 7.7283
	old_data_grads_norm = 3.8759
	sim_grads_norm_tr = 0.0520
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5476
	data_grads_norm = 4.8735
	new_data_grads_norm = 7.0002
	old_data_grads_norm = 6.2532
	sim_grads_norm_tr = 0.0176
-- Starting training on experience 170 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8236
	data_grads_norm = 5.0185
	new_data_grads_norm = 7.8474
	old_data_grads_norm = 5.7602
	sim_grads_norm_tr = 0.1065
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8853
	data_grads_norm = 5.7261
	new_data_grads_norm = 7.2769
	old_data_grads_norm = 6.7187
	sim_grads_norm_tr = 0.0677
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0245
	data_grads_norm = 5.1860
	new_data_grads_norm = 6.9711
	old_data_grads_norm = 7.1693
	sim_grads_norm_tr = -0.0002
-- Starting training on experience 171 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3299
	data_grads_norm = 4.2697
	new_data_grads_norm = 6.3394
	old_data_grads_norm = 5.4689
	sim_grads_norm_tr = -0.0339
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0102
	data_grads_norm = 3.5957
	new_data_grads_norm = 6.4623
	old_data_grads_norm = 3.7207
	sim_grads_norm_tr = 0.0047
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9070
	data_grads_norm = 4.2612
	new_data_grads_norm = 6.7995
	old_data_grads_norm = 6.5165
	sim_grads_norm_tr = -0.0453
-- Starting training on experience 172 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2328
	data_grads_norm = 4.4099
	new_data_grads_norm = 6.9564
	old_data_grads_norm = 6.1154
	sim_grads_norm_tr = -0.0418
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3482
	data_grads_norm = 4.5551
	new_data_grads_norm = 7.1216
	old_data_grads_norm = 5.6588
	sim_grads_norm_tr = -0.0409
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7007
	data_grads_norm = 5.1064
	new_data_grads_norm = 7.4520
	old_data_grads_norm = 7.1284
	sim_grads_norm_tr = -0.0316
-- Starting training on experience 173 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2219
	data_grads_norm = 4.4830
	new_data_grads_norm = 6.6617
	old_data_grads_norm = 5.6244
	sim_grads_norm_tr = 0.0097
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4617
	data_grads_norm = 4.8418
	new_data_grads_norm = 6.5803
	old_data_grads_norm = 6.9833
	sim_grads_norm_tr = -0.0199
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8643
	data_grads_norm = 4.7518
	new_data_grads_norm = 6.9200
	old_data_grads_norm = 6.4094
	sim_grads_norm_tr = 0.0173
-- Starting training on experience 174 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9887
	data_grads_norm = 5.0105
	new_data_grads_norm = 6.4751
	old_data_grads_norm = 7.8989
	sim_grads_norm_tr = -0.0586
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7314
	data_grads_norm = 4.6288
	new_data_grads_norm = 5.9741
	old_data_grads_norm = 6.8426
	sim_grads_norm_tr = 0.0331
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4560
	data_grads_norm = 4.2180
	new_data_grads_norm = 5.8683
	old_data_grads_norm = 5.4864
	sim_grads_norm_tr = -0.0117
-- Starting training on experience 175 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4399
	data_grads_norm = 4.6523
	new_data_grads_norm = 6.4966
	old_data_grads_norm = 6.2191
	sim_grads_norm_tr = 0.1125
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9372
	data_grads_norm = 5.0785
	new_data_grads_norm = 5.7442
	old_data_grads_norm = 7.6150
	sim_grads_norm_tr = 0.0433
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3665
	data_grads_norm = 4.2129
	new_data_grads_norm = 5.7177
	old_data_grads_norm = 5.7689
	sim_grads_norm_tr = 0.0666
-- Starting training on experience 176 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5345
	data_grads_norm = 4.5534
	new_data_grads_norm = 6.0536
	old_data_grads_norm = 6.4267
	sim_grads_norm_tr = 0.0314
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1955
	data_grads_norm = 4.1985
	new_data_grads_norm = 6.4507
	old_data_grads_norm = 6.0313
	sim_grads_norm_tr = -0.0073
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0670
	data_grads_norm = 4.4585
	new_data_grads_norm = 6.2063
	old_data_grads_norm = 5.3488
	sim_grads_norm_tr = 0.1136
-- Starting training on experience 177 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7649
	data_grads_norm = 4.7658
	new_data_grads_norm = 6.2846
	old_data_grads_norm = 5.6438
	sim_grads_norm_tr = 0.0590
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3633
	data_grads_norm = 4.5539
	new_data_grads_norm = 6.0234
	old_data_grads_norm = 5.7879
	sim_grads_norm_tr = 0.0410
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1287
	data_grads_norm = 4.3786
	new_data_grads_norm = 6.3959
	old_data_grads_norm = 5.4201
	sim_grads_norm_tr = 0.0589
-- Starting training on experience 178 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7462
	data_grads_norm = 3.9223
	new_data_grads_norm = 6.3190
	old_data_grads_norm = 3.9689
	sim_grads_norm_tr = 0.0170
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9156
	data_grads_norm = 4.6455
	new_data_grads_norm = 6.6348
	old_data_grads_norm = 5.0663
	sim_grads_norm_tr = 0.0751
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7936
	data_grads_norm = 4.2688
	new_data_grads_norm = 5.7010
	old_data_grads_norm = 6.7344
	sim_grads_norm_tr = 0.0878
-- Starting training on experience 179 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2193
	data_grads_norm = 4.6385
	new_data_grads_norm = 5.5319
	old_data_grads_norm = 7.7875
	sim_grads_norm_tr = -0.0537
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8592
	data_grads_norm = 3.9889
	new_data_grads_norm = 6.2429
	old_data_grads_norm = 5.3137
	sim_grads_norm_tr = -0.0341
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1462
	data_grads_norm = 4.2769
	new_data_grads_norm = 5.9500
	old_data_grads_norm = 6.3796
	sim_grads_norm_tr = -0.0393
-- Starting training on experience 180 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4174
	data_grads_norm = 4.4231
	new_data_grads_norm = 6.0704
	old_data_grads_norm = 5.8924
	sim_grads_norm_tr = 0.0174
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6599
	data_grads_norm = 4.3129
	new_data_grads_norm = 6.0810
	old_data_grads_norm = 5.8407
	sim_grads_norm_tr = -0.0399
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4928
	data_grads_norm = 4.9695
	new_data_grads_norm = 6.4872
	old_data_grads_norm = 6.6580
	sim_grads_norm_tr = 0.0428
-- Starting training on experience 181 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8991
	data_grads_norm = 4.5818
	new_data_grads_norm = 6.3093
	old_data_grads_norm = 7.8478
	sim_grads_norm_tr = -0.0348
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4288
	data_grads_norm = 4.9191
	new_data_grads_norm = 6.2893
	old_data_grads_norm = 7.1441
	sim_grads_norm_tr = -0.0360
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5989
	data_grads_norm = 4.2807
	new_data_grads_norm = 5.8349
	old_data_grads_norm = 5.3378
	sim_grads_norm_tr = 0.0496
-- Starting training on experience 182 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9169
	data_grads_norm = 3.8646
	new_data_grads_norm = 6.5435
	old_data_grads_norm = 4.4427
	sim_grads_norm_tr = -0.0042
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6350
	data_grads_norm = 5.0850
	new_data_grads_norm = 6.3258
	old_data_grads_norm = 7.1562
	sim_grads_norm_tr = 0.0735
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3357
	data_grads_norm = 4.0859
	new_data_grads_norm = 6.1597
	old_data_grads_norm = 6.8737
	sim_grads_norm_tr = 0.0399
-- Starting training on experience 183 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2215
	data_grads_norm = 4.3783
	new_data_grads_norm = 7.5885
	old_data_grads_norm = 5.1681
	sim_grads_norm_tr = -0.0580
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9961
	data_grads_norm = 4.2396
	new_data_grads_norm = 7.3620
	old_data_grads_norm = 4.2298
	sim_grads_norm_tr = 0.0089
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3109
	data_grads_norm = 5.3410
	new_data_grads_norm = 8.1692
	old_data_grads_norm = 6.1281
	sim_grads_norm_tr = 0.0062
-- Starting training on experience 184 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8754
	data_grads_norm = 4.2718
	new_data_grads_norm = 6.9929
	old_data_grads_norm = 5.6422
	sim_grads_norm_tr = 0.0551
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2146
	data_grads_norm = 4.9454
	new_data_grads_norm = 6.9833
	old_data_grads_norm = 6.3944
	sim_grads_norm_tr = 0.0180
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6718
	data_grads_norm = 4.2514
	new_data_grads_norm = 7.4139
	old_data_grads_norm = 4.0763
	sim_grads_norm_tr = -0.0654
-- Starting training on experience 185 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9231
	data_grads_norm = 4.2244
	new_data_grads_norm = 5.5893
	old_data_grads_norm = 6.3387
	sim_grads_norm_tr = -0.0024
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7326
	data_grads_norm = 3.7782
	new_data_grads_norm = 6.1467
	old_data_grads_norm = 4.9369
	sim_grads_norm_tr = 0.0831
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8705
	data_grads_norm = 4.3270
	new_data_grads_norm = 5.3926
	old_data_grads_norm = 6.4005
	sim_grads_norm_tr = 0.0610
-- Starting training on experience 186 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5179
	data_grads_norm = 4.6723
	new_data_grads_norm = 6.9545
	old_data_grads_norm = 5.4803
	sim_grads_norm_tr = 0.0002
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6092
	data_grads_norm = 4.6331
	new_data_grads_norm = 6.8532
	old_data_grads_norm = 5.7543
	sim_grads_norm_tr = 0.0632
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5190
	data_grads_norm = 4.9812
	new_data_grads_norm = 6.4955
	old_data_grads_norm = 6.4236
	sim_grads_norm_tr = 0.0616
-- Starting training on experience 187 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0857
	data_grads_norm = 5.4265
	new_data_grads_norm = 8.7082
	old_data_grads_norm = 6.7248
	sim_grads_norm_tr = 0.0014
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0373
	data_grads_norm = 6.0825
	new_data_grads_norm = 8.7590
	old_data_grads_norm = 7.0554
	sim_grads_norm_tr = 0.1386
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7533
	data_grads_norm = 4.5599
	new_data_grads_norm = 7.2041
	old_data_grads_norm = 6.5321
	sim_grads_norm_tr = -0.0383
-- Starting training on experience 188 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1782
	data_grads_norm = 6.2008
	new_data_grads_norm = 9.3157
	old_data_grads_norm = 5.7143
	sim_grads_norm_tr = 0.0406
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9454
	data_grads_norm = 5.9751
	new_data_grads_norm = 8.0166
	old_data_grads_norm = 7.2330
	sim_grads_norm_tr = -0.0528
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7178
	data_grads_norm = 7.1219
	new_data_grads_norm = 9.2589
	old_data_grads_norm = 8.0232
	sim_grads_norm_tr = -0.0257
-- Starting training on experience 189 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5363
	data_grads_norm = 5.2983
	new_data_grads_norm = 7.5943
	old_data_grads_norm = 7.9505
	sim_grads_norm_tr = -0.0317
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4954
	data_grads_norm = 5.0055
	new_data_grads_norm = 8.0046
	old_data_grads_norm = 5.6115
	sim_grads_norm_tr = 0.0120
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2895
	data_grads_norm = 5.1267
	new_data_grads_norm = 8.6012
	old_data_grads_norm = 5.8996
	sim_grads_norm_tr = 0.0637
-- Starting training on experience 190 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2557
	data_grads_norm = 4.4301
	new_data_grads_norm = 6.6651
	old_data_grads_norm = 4.8823
	sim_grads_norm_tr = 0.0833
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1091
	data_grads_norm = 4.8226
	new_data_grads_norm = 6.5514
	old_data_grads_norm = 6.2254
	sim_grads_norm_tr = 0.1276
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1053
	data_grads_norm = 4.4948
	new_data_grads_norm = 6.4316
	old_data_grads_norm = 5.5750
	sim_grads_norm_tr = 0.0259
-- Starting training on experience 191 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9661
	data_grads_norm = 4.1343
	new_data_grads_norm = 6.7290
	old_data_grads_norm = 5.3352
	sim_grads_norm_tr = -0.0266
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8103
	data_grads_norm = 4.3238
	new_data_grads_norm = 5.8504
	old_data_grads_norm = 4.7931
	sim_grads_norm_tr = 0.0313
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2133
	data_grads_norm = 4.3970
	new_data_grads_norm = 6.5977
	old_data_grads_norm = 5.5716
	sim_grads_norm_tr = 0.0175
-- Starting training on experience 192 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3016
	data_grads_norm = 4.7674
	new_data_grads_norm = 5.6729
	old_data_grads_norm = 6.5790
	sim_grads_norm_tr = -0.0252
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9806
	data_grads_norm = 3.9299
	new_data_grads_norm = 5.5988
	old_data_grads_norm = 5.9757
	sim_grads_norm_tr = -0.0352
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2026
	data_grads_norm = 4.7448
	new_data_grads_norm = 5.4315
	old_data_grads_norm = 6.4592
	sim_grads_norm_tr = -0.0322
-- Starting training on experience 193 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7202
	data_grads_norm = 3.9838
	new_data_grads_norm = 6.9185
	old_data_grads_norm = 5.0323
	sim_grads_norm_tr = 0.0137
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8114
	data_grads_norm = 4.4593
	new_data_grads_norm = 6.5358
	old_data_grads_norm = 5.8418
	sim_grads_norm_tr = -0.0036
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1107
	data_grads_norm = 5.0361
	new_data_grads_norm = 6.9015
	old_data_grads_norm = 7.2812
	sim_grads_norm_tr = 0.0144
-- Starting training on experience 194 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5198
	data_grads_norm = 4.0751
	new_data_grads_norm = 7.1197
	old_data_grads_norm = 4.4915
	sim_grads_norm_tr = -0.0343
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5347
	data_grads_norm = 3.8464
	new_data_grads_norm = 6.8975
	old_data_grads_norm = 5.2867
	sim_grads_norm_tr = -0.0028
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9329
	data_grads_norm = 4.4319
	new_data_grads_norm = 7.1415
	old_data_grads_norm = 5.5071
	sim_grads_norm_tr = -0.0248
-- Starting training on experience 195 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4895
	data_grads_norm = 4.9435
	new_data_grads_norm = 7.2872
	old_data_grads_norm = 6.1019
	sim_grads_norm_tr = 0.0174
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4304
	data_grads_norm = 4.8828
	new_data_grads_norm = 7.0416
	old_data_grads_norm = 5.9970
	sim_grads_norm_tr = 0.0312
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9599
	data_grads_norm = 5.1737
	new_data_grads_norm = 8.3179
	old_data_grads_norm = 6.9369
	sim_grads_norm_tr = -0.0829
-- Starting training on experience 196 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1908
	data_grads_norm = 4.4682
	new_data_grads_norm = 6.8494
	old_data_grads_norm = 5.1291
	sim_grads_norm_tr = 0.1029
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8828
	data_grads_norm = 4.1901
	new_data_grads_norm = 6.2426
	old_data_grads_norm = 5.6961
	sim_grads_norm_tr = 0.0112
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2276
	data_grads_norm = 4.7515
	new_data_grads_norm = 6.8366
	old_data_grads_norm = 6.1816
	sim_grads_norm_tr = 0.0102
-- Starting training on experience 197 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6788
	data_grads_norm = 3.6898
	new_data_grads_norm = 6.7168
	old_data_grads_norm = 3.6644
	sim_grads_norm_tr = 0.0163
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2007
	data_grads_norm = 4.2784
	new_data_grads_norm = 6.8279
	old_data_grads_norm = 4.6881
	sim_grads_norm_tr = -0.0488
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4961
	data_grads_norm = 4.9841
	new_data_grads_norm = 6.8698
	old_data_grads_norm = 6.4889
	sim_grads_norm_tr = 0.0836
-- Starting training on experience 198 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1144
	data_grads_norm = 3.9593
	new_data_grads_norm = 6.7537
	old_data_grads_norm = 5.7173
	sim_grads_norm_tr = -0.0064
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6579
	data_grads_norm = 4.8611
	new_data_grads_norm = 7.4140
	old_data_grads_norm = 6.4929
	sim_grads_norm_tr = 0.0206
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5640
	data_grads_norm = 4.1031
	new_data_grads_norm = 6.2785
	old_data_grads_norm = 5.0620
	sim_grads_norm_tr = -0.0292
-- Starting training on experience 199 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0058
	data_grads_norm = 4.7906
	new_data_grads_norm = 8.0276
	old_data_grads_norm = 4.5240
	sim_grads_norm_tr = -0.0016
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3245
	data_grads_norm = 5.5336
	new_data_grads_norm = 8.4019
	old_data_grads_norm = 6.8313
	sim_grads_norm_tr = -0.0120
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1088
	data_grads_norm = 5.1827
	new_data_grads_norm = 7.9052
	old_data_grads_norm = 5.4229
	sim_grads_norm_tr = 0.0275
-- Starting training on experience 200 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3173
	data_grads_norm = 5.2893
	new_data_grads_norm = 6.8116
	old_data_grads_norm = 7.0480
	sim_grads_norm_tr = 0.1042
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9267
	data_grads_norm = 4.3106
	new_data_grads_norm = 5.8434
	old_data_grads_norm = 5.1739
	sim_grads_norm_tr = 0.0999
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0984
	data_grads_norm = 4.3943
	new_data_grads_norm = 5.4366
	old_data_grads_norm = 7.2746
	sim_grads_norm_tr = -0.0600
-- Starting training on experience 201 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7840
	data_grads_norm = 5.6699
	new_data_grads_norm = 7.6526
	old_data_grads_norm = 8.3450
	sim_grads_norm_tr = -0.0130
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7343
	data_grads_norm = 5.9529
	new_data_grads_norm = 9.9497
	old_data_grads_norm = 6.5712
	sim_grads_norm_tr = -0.1151
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8976
	data_grads_norm = 6.5095
	new_data_grads_norm = 10.2149
	old_data_grads_norm = 6.4231
	sim_grads_norm_tr = 0.0381
-- Starting training on experience 202 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2372
	data_grads_norm = 4.6283
	new_data_grads_norm = 5.8315
	old_data_grads_norm = 6.5089
	sim_grads_norm_tr = -0.0005
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0529
	data_grads_norm = 3.8162
	new_data_grads_norm = 6.2861
	old_data_grads_norm = 5.0308
	sim_grads_norm_tr = -0.0710
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0469
	data_grads_norm = 4.3156
	new_data_grads_norm = 5.8506
	old_data_grads_norm = 5.6824
	sim_grads_norm_tr = 0.0452
-- Starting training on experience 203 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8689
	data_grads_norm = 4.2277
	new_data_grads_norm = 7.4415
	old_data_grads_norm = 4.5176
	sim_grads_norm_tr = -0.0199
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7279
	data_grads_norm = 4.1648
	new_data_grads_norm = 7.5328
	old_data_grads_norm = 3.6641
	sim_grads_norm_tr = 0.0151
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0398
	data_grads_norm = 4.8351
	new_data_grads_norm = 7.5161
	old_data_grads_norm = 5.7513
	sim_grads_norm_tr = 0.0573
-- Starting training on experience 204 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4552
	data_grads_norm = 5.2687
	new_data_grads_norm = 7.8800
	old_data_grads_norm = 7.2392
	sim_grads_norm_tr = 0.0025
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7537
	data_grads_norm = 6.1040
	new_data_grads_norm = 8.7768
	old_data_grads_norm = 8.6243
	sim_grads_norm_tr = 0.0232
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3101
	data_grads_norm = 5.0358
	new_data_grads_norm = 7.8536
	old_data_grads_norm = 6.5679
	sim_grads_norm_tr = 0.0307
-- Starting training on experience 205 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4760
	data_grads_norm = 3.7244
	new_data_grads_norm = 6.1419
	old_data_grads_norm = 4.3977
	sim_grads_norm_tr = 0.0248
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9429
	data_grads_norm = 4.5802
	new_data_grads_norm = 6.2695
	old_data_grads_norm = 6.2833
	sim_grads_norm_tr = 0.0274
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1996
	data_grads_norm = 4.5081
	new_data_grads_norm = 5.6260
	old_data_grads_norm = 6.2891
	sim_grads_norm_tr = 0.1393
-- Starting training on experience 206 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1136
	data_grads_norm = 3.6606
	new_data_grads_norm = 6.7085
	old_data_grads_norm = 4.0440
	sim_grads_norm_tr = -0.1105
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7625
	data_grads_norm = 5.3493
	new_data_grads_norm = 7.3367
	old_data_grads_norm = 7.1914
	sim_grads_norm_tr = 0.0433
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5161
	data_grads_norm = 5.4891
	new_data_grads_norm = 7.2430
	old_data_grads_norm = 7.4511
	sim_grads_norm_tr = 0.0312
-- Starting training on experience 207 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7477
	data_grads_norm = 4.3084
	new_data_grads_norm = 6.7098
	old_data_grads_norm = 5.6795
	sim_grads_norm_tr = 0.0341
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8400
	data_grads_norm = 4.3702
	new_data_grads_norm = 5.8829
	old_data_grads_norm = 5.8118
	sim_grads_norm_tr = 0.0491
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3653
	data_grads_norm = 4.7804
	new_data_grads_norm = 6.1413
	old_data_grads_norm = 7.0909
	sim_grads_norm_tr = 0.0872
-- Starting training on experience 208 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4542
	data_grads_norm = 5.4742
	new_data_grads_norm = 7.9958
	old_data_grads_norm = 6.5974
	sim_grads_norm_tr = 0.0010
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5199
	data_grads_norm = 6.4745
	new_data_grads_norm = 7.5450
	old_data_grads_norm = 9.1056
	sim_grads_norm_tr = 0.0112
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6964
	data_grads_norm = 5.6479
	new_data_grads_norm = 7.7957
	old_data_grads_norm = 7.8553
	sim_grads_norm_tr = 0.1035
-- Starting training on experience 209 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1455
	data_grads_norm = 5.1667
	new_data_grads_norm = 6.4642
	old_data_grads_norm = 6.8832
	sim_grads_norm_tr = 0.1077
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0164
	data_grads_norm = 4.3020
	new_data_grads_norm = 6.3408
	old_data_grads_norm = 6.2483
	sim_grads_norm_tr = -0.0224
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3032
	data_grads_norm = 4.9555
	new_data_grads_norm = 7.3523
	old_data_grads_norm = 6.3629
	sim_grads_norm_tr = 0.0351
-- Starting training on experience 210 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9771
	data_grads_norm = 4.4570
	new_data_grads_norm = 6.6802
	old_data_grads_norm = 6.6625
	sim_grads_norm_tr = -0.0384
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1277
	data_grads_norm = 4.9743
	new_data_grads_norm = 7.6017
	old_data_grads_norm = 7.3628
	sim_grads_norm_tr = -0.0065
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3861
	data_grads_norm = 4.8551
	new_data_grads_norm = 7.0479
	old_data_grads_norm = 6.8387
	sim_grads_norm_tr = 0.0030
-- Starting training on experience 211 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4102
	data_grads_norm = 4.7765
	new_data_grads_norm = 6.7235
	old_data_grads_norm = 6.2965
	sim_grads_norm_tr = -0.0284
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2190
	data_grads_norm = 4.8783
	new_data_grads_norm = 7.0158
	old_data_grads_norm = 7.2600
	sim_grads_norm_tr = 0.0157
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6073
	data_grads_norm = 4.9795
	new_data_grads_norm = 6.6026
	old_data_grads_norm = 7.1411
	sim_grads_norm_tr = 0.0027
-- Starting training on experience 212 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6991
	data_grads_norm = 3.8762
	new_data_grads_norm = 7.1220
	old_data_grads_norm = 4.4567
	sim_grads_norm_tr = 0.0063
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9619
	data_grads_norm = 4.8486
	new_data_grads_norm = 5.9593
	old_data_grads_norm = 6.8440
	sim_grads_norm_tr = 0.0249
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0350
	data_grads_norm = 4.4168
	new_data_grads_norm = 6.0950
	old_data_grads_norm = 6.9943
	sim_grads_norm_tr = -0.0303
-- Starting training on experience 213 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1881
	data_grads_norm = 4.4028
	new_data_grads_norm = 6.9084
	old_data_grads_norm = 5.2902
	sim_grads_norm_tr = 0.0002
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0785
	data_grads_norm = 4.0971
	new_data_grads_norm = 7.2589
	old_data_grads_norm = 4.5430
	sim_grads_norm_tr = -0.0300
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6499
	data_grads_norm = 5.4548
	new_data_grads_norm = 7.5077
	old_data_grads_norm = 8.7777
	sim_grads_norm_tr = 0.0657
-- Starting training on experience 214 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9448
	data_grads_norm = 4.0977
	new_data_grads_norm = 5.8720
	old_data_grads_norm = 5.7488
	sim_grads_norm_tr = -0.0308
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2938
	data_grads_norm = 4.3128
	new_data_grads_norm = 5.9421
	old_data_grads_norm = 5.7997
	sim_grads_norm_tr = 0.0755
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2537
	data_grads_norm = 4.7428
	new_data_grads_norm = 5.5924
	old_data_grads_norm = 6.6412
	sim_grads_norm_tr = -0.0253
-- Starting training on experience 215 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3039
	data_grads_norm = 4.5939
	new_data_grads_norm = 8.2830
	old_data_grads_norm = 5.4728
	sim_grads_norm_tr = 0.0513
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0396
	data_grads_norm = 4.4766
	new_data_grads_norm = 8.3422
	old_data_grads_norm = 4.9231
	sim_grads_norm_tr = -0.0267
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6563
	data_grads_norm = 5.2344
	new_data_grads_norm = 8.6488
	old_data_grads_norm = 6.5424
	sim_grads_norm_tr = 0.0410
-- Starting training on experience 216 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1333
	data_grads_norm = 4.8357
	new_data_grads_norm = 7.2417
	old_data_grads_norm = 7.0079
	sim_grads_norm_tr = -0.0539
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3516
	data_grads_norm = 5.5396
	new_data_grads_norm = 7.4537
	old_data_grads_norm = 7.0001
	sim_grads_norm_tr = 0.0990
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4904
	data_grads_norm = 4.9116
	new_data_grads_norm = 7.7716
	old_data_grads_norm = 6.9557
	sim_grads_norm_tr = 0.0068
-- Starting training on experience 217 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8506
	data_grads_norm = 4.1506
	new_data_grads_norm = 7.0224
	old_data_grads_norm = 5.1953
	sim_grads_norm_tr = 0.0413
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0444
	data_grads_norm = 5.2830
	new_data_grads_norm = 6.4405
	old_data_grads_norm = 7.2530
	sim_grads_norm_tr = 0.0476
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2203
	data_grads_norm = 4.6727
	new_data_grads_norm = 6.5622
	old_data_grads_norm = 7.5565
	sim_grads_norm_tr = -0.0127
-- Starting training on experience 218 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8632
	data_grads_norm = 4.5735
	new_data_grads_norm = 7.1700
	old_data_grads_norm = 5.4713
	sim_grads_norm_tr = 0.0296
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8737
	data_grads_norm = 4.4037
	new_data_grads_norm = 6.3395
	old_data_grads_norm = 4.4432
	sim_grads_norm_tr = 0.1012
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7120
	data_grads_norm = 3.7530
	new_data_grads_norm = 5.9224
	old_data_grads_norm = 4.9252
	sim_grads_norm_tr = -0.0120
-- Starting training on experience 219 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0228
	data_grads_norm = 5.5392
	new_data_grads_norm = 8.4362
	old_data_grads_norm = 5.6230
	sim_grads_norm_tr = -0.0202
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6291
	data_grads_norm = 5.8752
	new_data_grads_norm = 8.6129
	old_data_grads_norm = 7.0562
	sim_grads_norm_tr = -0.0330
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1541
	data_grads_norm = 5.5012
	new_data_grads_norm = 8.6954
	old_data_grads_norm = 6.9038
	sim_grads_norm_tr = 0.0688
-- Starting training on experience 220 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7310
	data_grads_norm = 3.5445
	new_data_grads_norm = 6.3480
	old_data_grads_norm = 4.9896
	sim_grads_norm_tr = -0.0452
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9740
	data_grads_norm = 3.9111
	new_data_grads_norm = 6.1998
	old_data_grads_norm = 5.5492
	sim_grads_norm_tr = 0.0291
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8078
	data_grads_norm = 3.5421
	new_data_grads_norm = 7.4044
	old_data_grads_norm = 4.7546
	sim_grads_norm_tr = -0.0085
-- Starting training on experience 221 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8983
	data_grads_norm = 4.6752
	new_data_grads_norm = 9.0038
	old_data_grads_norm = 4.3527
	sim_grads_norm_tr = 0.0088
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4401
	data_grads_norm = 5.8575
	new_data_grads_norm = 8.6920
	old_data_grads_norm = 5.5787
	sim_grads_norm_tr = 0.0035
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8881
	data_grads_norm = 6.0522
	new_data_grads_norm = 9.5185
	old_data_grads_norm = 6.2288
	sim_grads_norm_tr = 0.0199
-- Starting training on experience 222 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8374
	data_grads_norm = 4.0637
	new_data_grads_norm = 6.5275
	old_data_grads_norm = 5.5650
	sim_grads_norm_tr = -0.0097
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3987
	data_grads_norm = 5.5079
	new_data_grads_norm = 7.9219
	old_data_grads_norm = 7.1888
	sim_grads_norm_tr = 0.0133
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6317
	data_grads_norm = 5.4952
	new_data_grads_norm = 8.7791
	old_data_grads_norm = 5.9318
	sim_grads_norm_tr = -0.0208
-- Starting training on experience 223 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6001
	data_grads_norm = 3.8845
	new_data_grads_norm = 6.7485
	old_data_grads_norm = 5.2972
	sim_grads_norm_tr = 0.0464
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7126
	data_grads_norm = 3.9864
	new_data_grads_norm = 5.9105
	old_data_grads_norm = 5.4472
	sim_grads_norm_tr = 0.0515
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4926
	data_grads_norm = 4.4090
	new_data_grads_norm = 6.1469
	old_data_grads_norm = 5.4881
	sim_grads_norm_tr = 0.0191
-- Starting training on experience 224 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6500
	data_grads_norm = 5.1493
	new_data_grads_norm = 7.1308
	old_data_grads_norm = 7.0173
	sim_grads_norm_tr = 0.0109
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6610
	data_grads_norm = 5.1003
	new_data_grads_norm = 7.8247
	old_data_grads_norm = 5.9571
	sim_grads_norm_tr = -0.0114
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7253
	data_grads_norm = 5.5652
	new_data_grads_norm = 7.6402
	old_data_grads_norm = 7.1118
	sim_grads_norm_tr = 0.0040
-- Starting training on experience 225 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6548
	data_grads_norm = 5.2300
	new_data_grads_norm = 7.4845
	old_data_grads_norm = 6.7775
	sim_grads_norm_tr = 0.0008
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5411
	data_grads_norm = 4.9052
	new_data_grads_norm = 6.8864
	old_data_grads_norm = 6.2009
	sim_grads_norm_tr = -0.0163
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3684
	data_grads_norm = 4.9415
	new_data_grads_norm = 7.3881
	old_data_grads_norm = 6.8312
	sim_grads_norm_tr = 0.0368
-- Starting training on experience 226 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9606
	data_grads_norm = 4.4566
	new_data_grads_norm = 6.8267
	old_data_grads_norm = 6.0585
	sim_grads_norm_tr = -0.0081
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3281
	data_grads_norm = 4.5551
	new_data_grads_norm = 7.7421
	old_data_grads_norm = 6.3785
	sim_grads_norm_tr = -0.1294
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5556
	data_grads_norm = 5.4521
	new_data_grads_norm = 8.3877
	old_data_grads_norm = 7.3744
	sim_grads_norm_tr = -0.0408
-- Starting training on experience 227 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8911
	data_grads_norm = 4.6238
	new_data_grads_norm = 7.8733
	old_data_grads_norm = 5.7557
	sim_grads_norm_tr = 0.0901
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5189
	data_grads_norm = 5.3510
	new_data_grads_norm = 7.2855
	old_data_grads_norm = 7.3352
	sim_grads_norm_tr = 0.0674
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4116
	data_grads_norm = 5.2680
	new_data_grads_norm = 7.5281
	old_data_grads_norm = 6.4933
	sim_grads_norm_tr = 0.0249
-- Starting training on experience 228 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8904
	data_grads_norm = 4.7497
	new_data_grads_norm = 7.9868
	old_data_grads_norm = 4.2916
	sim_grads_norm_tr = 0.0009
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1605
	data_grads_norm = 4.6710
	new_data_grads_norm = 7.5963
	old_data_grads_norm = 4.8462
	sim_grads_norm_tr = 0.0255
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9926
	data_grads_norm = 5.5927
	new_data_grads_norm = 8.2713
	old_data_grads_norm = 6.2545
	sim_grads_norm_tr = 0.0501
-- Starting training on experience 229 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3723
	data_grads_norm = 5.4359
	new_data_grads_norm = 6.7777
	old_data_grads_norm = 7.3513
	sim_grads_norm_tr = 0.0028
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1789
	data_grads_norm = 4.2663
	new_data_grads_norm = 6.8204
	old_data_grads_norm = 5.9440
	sim_grads_norm_tr = 0.0171
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9577
	data_grads_norm = 4.6782
	new_data_grads_norm = 5.8719
	old_data_grads_norm = 6.8027
	sim_grads_norm_tr = -0.0185
-- Starting training on experience 230 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5286
	data_grads_norm = 4.8517
	new_data_grads_norm = 7.6909
	old_data_grads_norm = 5.9289
	sim_grads_norm_tr = -0.0063
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2568
	data_grads_norm = 4.8964
	new_data_grads_norm = 7.2368
	old_data_grads_norm = 6.7040
	sim_grads_norm_tr = 0.1508
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4163
	data_grads_norm = 4.8922
	new_data_grads_norm = 7.4451
	old_data_grads_norm = 6.0049
	sim_grads_norm_tr = 0.0281
-- Starting training on experience 231 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9335
	data_grads_norm = 4.4109
	new_data_grads_norm = 7.6642
	old_data_grads_norm = 4.0583
	sim_grads_norm_tr = 0.0002
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0337
	data_grads_norm = 5.3634
	new_data_grads_norm = 8.9329
	old_data_grads_norm = 6.2876
	sim_grads_norm_tr = -0.0061
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3551
	data_grads_norm = 5.9128
	new_data_grads_norm = 9.0442
	old_data_grads_norm = 8.0381
	sim_grads_norm_tr = 0.0165
-- Starting training on experience 232 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7862
	data_grads_norm = 3.7850
	new_data_grads_norm = 6.6658
	old_data_grads_norm = 4.0593
	sim_grads_norm_tr = -0.0406
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5599
	data_grads_norm = 5.0428
	new_data_grads_norm = 7.7495
	old_data_grads_norm = 6.4454
	sim_grads_norm_tr = -0.0245
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5549
	data_grads_norm = 4.6033
	new_data_grads_norm = 7.1708
	old_data_grads_norm = 5.7451
	sim_grads_norm_tr = 0.0016
-- Starting training on experience 233 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5228
	data_grads_norm = 4.0904
	new_data_grads_norm = 7.0786
	old_data_grads_norm = 4.7753
	sim_grads_norm_tr = -0.0100
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7681
	data_grads_norm = 4.2609
	new_data_grads_norm = 6.6490
	old_data_grads_norm = 5.4373
	sim_grads_norm_tr = 0.0158
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1562
	data_grads_norm = 5.3449
	new_data_grads_norm = 7.1671
	old_data_grads_norm = 6.8203
	sim_grads_norm_tr = 0.0586
-- Starting training on experience 234 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9036
	data_grads_norm = 4.6455
	new_data_grads_norm = 6.4238
	old_data_grads_norm = 6.5313
	sim_grads_norm_tr = 0.0216
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8562
	data_grads_norm = 4.8584
	new_data_grads_norm = 7.8608
	old_data_grads_norm = 6.1143
	sim_grads_norm_tr = 0.0102
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2228
	data_grads_norm = 4.9504
	new_data_grads_norm = 6.2617
	old_data_grads_norm = 7.9682
	sim_grads_norm_tr = -0.0164
-- Starting training on experience 235 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4369
	data_grads_norm = 4.8178
	new_data_grads_norm = 6.1706
	old_data_grads_norm = 8.0753
	sim_grads_norm_tr = -0.0316
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2564
	data_grads_norm = 5.5796
	new_data_grads_norm = 6.8072
	old_data_grads_norm = 7.9183
	sim_grads_norm_tr = 0.0519
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3023
	data_grads_norm = 3.9850
	new_data_grads_norm = 6.4766
	old_data_grads_norm = 5.3124
	sim_grads_norm_tr = -0.0984
-- Starting training on experience 236 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2905
	data_grads_norm = 5.0629
	new_data_grads_norm = 6.8481
	old_data_grads_norm = 5.2807
	sim_grads_norm_tr = 0.0007
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3259
	data_grads_norm = 4.3756
	new_data_grads_norm = 6.6211
	old_data_grads_norm = 5.0490
	sim_grads_norm_tr = -0.0528
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3865
	data_grads_norm = 4.7748
	new_data_grads_norm = 7.8867
	old_data_grads_norm = 6.4815
	sim_grads_norm_tr = -0.0965
-- Starting training on experience 237 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
-- >> End of training phase << --
-- >> Start of eval phase << --
-- Starting eval on experience 0 (Task 0) from test stream --
> Eval on experience 0 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp000 = 2.5229
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.4180
	mb_index = 2142
	time = 601.4982
-- Starting eval on experience 1 (Task 0) from test stream --
> Eval on experience 1 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp001 = 1.9404
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.5440
-- Starting eval on experience 2 (Task 0) from test stream --
> Eval on experience 2 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp002 = 2.6812
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.3540
-- Starting eval on experience 3 (Task 0) from test stream --
> Eval on experience 3 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp003 = 2.0890
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.4780
-- Starting eval on experience 4 (Task 0) from test stream --
> Eval on experience 4 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp004 = 3.3048
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.2780
-- Starting eval on experience 5 (Task 0) from test stream --
> Eval on experience 5 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp005 = 2.8796
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.3320
-- Starting eval on experience 6 (Task 0) from test stream --
> Eval on experience 6 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp006 = 3.0279
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp006 = 0.2340
-- Starting eval on experience 7 (Task 0) from test stream --
> Eval on experience 7 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp007 = 2.4180
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp007 = 0.3760
-- Starting eval on experience 8 (Task 0) from test stream --
> Eval on experience 8 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp008 = 3.0297
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp008 = 0.2280
-- >> End of eval phase << --
	CumulativeAccuracy/eval_phase/test_stream/Exp000 = 0.7200
	CumulativeAccuracy/eval_phase/test_stream/Exp001 = 0.6620
	CumulativeAccuracy/eval_phase/test_stream/Exp002 = 0.5587
	CumulativeAccuracy/eval_phase/test_stream/Exp003 = 0.5215
	CumulativeAccuracy/eval_phase/test_stream/Exp004 = 0.4676
	CumulativeAccuracy/eval_phase/test_stream/Exp005 = 0.4310
	CumulativeAccuracy/eval_phase/test_stream/Exp006 = 0.4043
	CumulativeAccuracy/eval_phase/test_stream/Exp007 = 0.3832
	CumulativeAccuracy/eval_phase/test_stream/Exp008 = 0.3602
	Loss_Stream/eval_phase/test_stream/Task000 = 2.6548
	Top1_Acc_Stream/eval_phase/test_stream/Task000 = 0.3602
-- >> Start of training phase << --
-- Starting training on experience 0 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3047
	data_grads_norm = 5.0073
	new_data_grads_norm = 7.5956
	old_data_grads_norm = 5.5987
	sim_grads_norm_tr = 0.0025
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8808
	data_grads_norm = 5.1908
	new_data_grads_norm = 7.6502
	old_data_grads_norm = 6.8075
	sim_grads_norm_tr = -0.0019
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8845
	data_grads_norm = 5.1224
	new_data_grads_norm = 6.8641
	old_data_grads_norm = 7.7924
	sim_grads_norm_tr = 0.0043
-- Starting training on experience 1 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9527
	data_grads_norm = 6.1965
	new_data_grads_norm = 7.0378
	old_data_grads_norm = 8.5111
	sim_grads_norm_tr = 0.0055
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1250
	data_grads_norm = 5.7564
	new_data_grads_norm = 6.5526
	old_data_grads_norm = 9.1543
	sim_grads_norm_tr = -0.0055
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6090
	data_grads_norm = 5.4933
	new_data_grads_norm = 6.8723
	old_data_grads_norm = 7.8234
	sim_grads_norm_tr = 0.0658
-- Starting training on experience 2 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4186
	data_grads_norm = 5.2732
	new_data_grads_norm = 6.6660
	old_data_grads_norm = 6.8100
	sim_grads_norm_tr = -0.0218
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3318
	data_grads_norm = 5.4346
	new_data_grads_norm = 7.2539
	old_data_grads_norm = 6.7016
	sim_grads_norm_tr = 0.0219
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.8747
	data_grads_norm = 6.3787
	new_data_grads_norm = 6.9987
	old_data_grads_norm = 8.5247
	sim_grads_norm_tr = 0.0211
-- Starting training on experience 3 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5827
	data_grads_norm = 4.6409
	new_data_grads_norm = 6.5712
	old_data_grads_norm = 5.8372
	sim_grads_norm_tr = 0.0125
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1479
	data_grads_norm = 4.8536
	new_data_grads_norm = 6.9096
	old_data_grads_norm = 6.1474
	sim_grads_norm_tr = 0.0014
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9452
	data_grads_norm = 4.3548
	new_data_grads_norm = 6.7623
	old_data_grads_norm = 4.4803
	sim_grads_norm_tr = 0.0098
-- Starting training on experience 4 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3514
	data_grads_norm = 4.0492
	new_data_grads_norm = 6.8024
	old_data_grads_norm = 4.2531
	sim_grads_norm_tr = -0.0272
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4901
	data_grads_norm = 5.1212
	new_data_grads_norm = 6.6384
	old_data_grads_norm = 7.0344
	sim_grads_norm_tr = 0.0023
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3915
	data_grads_norm = 5.3648
	new_data_grads_norm = 6.1182
	old_data_grads_norm = 8.6250
	sim_grads_norm_tr = 0.0341
-- Starting training on experience 5 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4671
	data_grads_norm = 4.5575
	new_data_grads_norm = 6.2144
	old_data_grads_norm = 5.7790
	sim_grads_norm_tr = 0.0101
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7041
	data_grads_norm = 3.5818
	new_data_grads_norm = 5.7913
	old_data_grads_norm = 4.0702
	sim_grads_norm_tr = 0.0441
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6893
	data_grads_norm = 4.7483
	new_data_grads_norm = 6.1283
	old_data_grads_norm = 5.9374
	sim_grads_norm_tr = 0.0164
-- Starting training on experience 6 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9572
	data_grads_norm = 4.3428
	new_data_grads_norm = 6.4485
	old_data_grads_norm = 5.7653
	sim_grads_norm_tr = -0.0836
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0908
	data_grads_norm = 5.0884
	new_data_grads_norm = 6.4594
	old_data_grads_norm = 6.7788
	sim_grads_norm_tr = -0.0177
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2075
	data_grads_norm = 4.0091
	new_data_grads_norm = 6.5357
	old_data_grads_norm = 3.9534
	sim_grads_norm_tr = 0.0225
-- Starting training on experience 7 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5751
	data_grads_norm = 4.5436
	new_data_grads_norm = 6.5966
	old_data_grads_norm = 4.1362
	sim_grads_norm_tr = -0.0292
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8771
	data_grads_norm = 5.0550
	new_data_grads_norm = 6.4329
	old_data_grads_norm = 6.0527
	sim_grads_norm_tr = 0.0025
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5687
	data_grads_norm = 5.7568
	new_data_grads_norm = 6.6718
	old_data_grads_norm = 7.1486
	sim_grads_norm_tr = 0.0113
-- Starting training on experience 8 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7801
	data_grads_norm = 4.6505
	new_data_grads_norm = 7.1693
	old_data_grads_norm = 6.8796
	sim_grads_norm_tr = 0.0103
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9695
	data_grads_norm = 5.1087
	new_data_grads_norm = 7.4267
	old_data_grads_norm = 4.7459
	sim_grads_norm_tr = 0.0175
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8074
	data_grads_norm = 5.3587
	new_data_grads_norm = 7.3492
	old_data_grads_norm = 6.9962
	sim_grads_norm_tr = 0.0157
-- Starting training on experience 9 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0202
	data_grads_norm = 4.7375
	new_data_grads_norm = 6.7224
	old_data_grads_norm = 5.9551
	sim_grads_norm_tr = -0.0162
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2255
	data_grads_norm = 5.1477
	new_data_grads_norm = 6.8788
	old_data_grads_norm = 5.1910
	sim_grads_norm_tr = 0.0412
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6588
	data_grads_norm = 5.1831
	new_data_grads_norm = 6.7924
	old_data_grads_norm = 5.8009
	sim_grads_norm_tr = 0.1034
-- Starting training on experience 10 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6453
	data_grads_norm = 4.7225
	new_data_grads_norm = 6.2947
	old_data_grads_norm = 5.7746
	sim_grads_norm_tr = 0.0419
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3546
	data_grads_norm = 5.2674
	new_data_grads_norm = 6.8152
	old_data_grads_norm = 7.4347
	sim_grads_norm_tr = 0.0193
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8713
	data_grads_norm = 4.9212
	new_data_grads_norm = 6.8115
	old_data_grads_norm = 6.7584
	sim_grads_norm_tr = 0.0297
-- Starting training on experience 11 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6054
	data_grads_norm = 4.9491
	new_data_grads_norm = 6.7474
	old_data_grads_norm = 7.4675
	sim_grads_norm_tr = 0.0186
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8228
	data_grads_norm = 4.2844
	new_data_grads_norm = 6.8248
	old_data_grads_norm = 5.3855
	sim_grads_norm_tr = 0.0067
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4272
	data_grads_norm = 4.8391
	new_data_grads_norm = 6.4266
	old_data_grads_norm = 6.6144
	sim_grads_norm_tr = -0.0789
-- Starting training on experience 12 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4777
	data_grads_norm = 4.2424
	new_data_grads_norm = 6.3119
	old_data_grads_norm = 6.3548
	sim_grads_norm_tr = -0.0120
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6249
	data_grads_norm = 4.7838
	new_data_grads_norm = 6.0123
	old_data_grads_norm = 7.6118
	sim_grads_norm_tr = 0.0008
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6010
	data_grads_norm = 5.4944
	new_data_grads_norm = 6.7483
	old_data_grads_norm = 7.8536
	sim_grads_norm_tr = 0.0600
-- Starting training on experience 13 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6489
	data_grads_norm = 5.2243
	new_data_grads_norm = 6.4769
	old_data_grads_norm = 6.9713
	sim_grads_norm_tr = 0.1463
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9413
	data_grads_norm = 4.6848
	new_data_grads_norm = 5.6768
	old_data_grads_norm = 6.7931
	sim_grads_norm_tr = 0.0357
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6455
	data_grads_norm = 4.5932
	new_data_grads_norm = 6.1140
	old_data_grads_norm = 5.7601
	sim_grads_norm_tr = -0.0657
-- Starting training on experience 14 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7673
	data_grads_norm = 5.1777
	new_data_grads_norm = 6.8806
	old_data_grads_norm = 7.3519
	sim_grads_norm_tr = 0.0293
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6702
	data_grads_norm = 5.2675
	new_data_grads_norm = 6.8981
	old_data_grads_norm = 6.7932
	sim_grads_norm_tr = -0.0255
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2382
	data_grads_norm = 4.8756
	new_data_grads_norm = 7.1027
	old_data_grads_norm = 5.5084
	sim_grads_norm_tr = 0.0328
-- Starting training on experience 15 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9002
	data_grads_norm = 4.8609
	new_data_grads_norm = 6.4255
	old_data_grads_norm = 6.5049
	sim_grads_norm_tr = 0.0811
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6671
	data_grads_norm = 4.8038
	new_data_grads_norm = 6.4792
	old_data_grads_norm = 6.7981
	sim_grads_norm_tr = -0.0073
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4365
	data_grads_norm = 4.4643
	new_data_grads_norm = 6.2991
	old_data_grads_norm = 5.5565
	sim_grads_norm_tr = 0.0175
-- Starting training on experience 16 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4662
	data_grads_norm = 4.4736
	new_data_grads_norm = 6.3729
	old_data_grads_norm = 5.6951
	sim_grads_norm_tr = 0.0930
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4449
	data_grads_norm = 4.3934
	new_data_grads_norm = 6.5130
	old_data_grads_norm = 5.2591
	sim_grads_norm_tr = -0.0130
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4782
	data_grads_norm = 4.7767
	new_data_grads_norm = 5.7592
	old_data_grads_norm = 6.5114
	sim_grads_norm_tr = 0.1080
-- Starting training on experience 17 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2713
	data_grads_norm = 4.8993
	new_data_grads_norm = 6.5919
	old_data_grads_norm = 6.4857
	sim_grads_norm_tr = 0.0148
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1275
	data_grads_norm = 4.3318
	new_data_grads_norm = 6.1150
	old_data_grads_norm = 5.4006
	sim_grads_norm_tr = -0.0527
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0992
	data_grads_norm = 4.4603
	new_data_grads_norm = 6.1826
	old_data_grads_norm = 4.8523
	sim_grads_norm_tr = 0.0472
-- Starting training on experience 18 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7906
	data_grads_norm = 4.5011
	new_data_grads_norm = 6.0045
	old_data_grads_norm = 5.1423
	sim_grads_norm_tr = 0.1171
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3676
	data_grads_norm = 5.1680
	new_data_grads_norm = 6.3802
	old_data_grads_norm = 7.4394
	sim_grads_norm_tr = -0.0285
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4152
	data_grads_norm = 4.4149
	new_data_grads_norm = 6.1195
	old_data_grads_norm = 6.0087
	sim_grads_norm_tr = 0.0621
-- Starting training on experience 19 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2349
	data_grads_norm = 5.0187
	new_data_grads_norm = 6.8260
	old_data_grads_norm = 6.5973
	sim_grads_norm_tr = -0.0265
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8175
	data_grads_norm = 4.5427
	new_data_grads_norm = 6.7594
	old_data_grads_norm = 6.1113
	sim_grads_norm_tr = -0.0306
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4168
	data_grads_norm = 4.5365
	new_data_grads_norm = 6.5226
	old_data_grads_norm = 5.9496
	sim_grads_norm_tr = -0.0121
-- Starting training on experience 20 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4789
	data_grads_norm = 4.5743
	new_data_grads_norm = 6.5064
	old_data_grads_norm = 5.0252
	sim_grads_norm_tr = 0.0153
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2895
	data_grads_norm = 5.0598
	new_data_grads_norm = 6.4988
	old_data_grads_norm = 6.1336
	sim_grads_norm_tr = 0.0542
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3087
	data_grads_norm = 4.7260
	new_data_grads_norm = 6.7271
	old_data_grads_norm = 6.2579
	sim_grads_norm_tr = 0.0143
-- Starting training on experience 21 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9626
	data_grads_norm = 4.7695
	new_data_grads_norm = 6.5957
	old_data_grads_norm = 5.8426
	sim_grads_norm_tr = 0.0158
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2182
	data_grads_norm = 4.5676
	new_data_grads_norm = 6.6082
	old_data_grads_norm = 5.7681
	sim_grads_norm_tr = 0.0302
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7463
	data_grads_norm = 4.8323
	new_data_grads_norm = 6.9240
	old_data_grads_norm = 6.0800
	sim_grads_norm_tr = 0.0301
-- Starting training on experience 22 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4623
	data_grads_norm = 4.3387
	new_data_grads_norm = 6.3118
	old_data_grads_norm = 5.0886
	sim_grads_norm_tr = 0.0345
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4891
	data_grads_norm = 4.7631
	new_data_grads_norm = 6.2603
	old_data_grads_norm = 6.4744
	sim_grads_norm_tr = 0.1594
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4677
	data_grads_norm = 4.0647
	new_data_grads_norm = 5.8494
	old_data_grads_norm = 4.9315
	sim_grads_norm_tr = 0.0749
-- Starting training on experience 23 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5487
	data_grads_norm = 4.2027
	new_data_grads_norm = 5.5525
	old_data_grads_norm = 6.3302
	sim_grads_norm_tr = -0.0061
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4685
	data_grads_norm = 3.8821
	new_data_grads_norm = 5.8312
	old_data_grads_norm = 5.3209
	sim_grads_norm_tr = 0.0193
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9344
	data_grads_norm = 4.6978
	new_data_grads_norm = 6.0924
	old_data_grads_norm = 6.4117
	sim_grads_norm_tr = -0.0422
-- Starting training on experience 24 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3510
	data_grads_norm = 5.1618
	new_data_grads_norm = 6.0424
	old_data_grads_norm = 6.0459
	sim_grads_norm_tr = 0.0299
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4980
	data_grads_norm = 5.2430
	new_data_grads_norm = 6.8788
	old_data_grads_norm = 6.4795
	sim_grads_norm_tr = -0.0025
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4373
	data_grads_norm = 5.2410
	new_data_grads_norm = 6.7801
	old_data_grads_norm = 7.7238
	sim_grads_norm_tr = 0.0083
-- Starting training on experience 25 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7621
	data_grads_norm = 3.9510
	new_data_grads_norm = 6.1209
	old_data_grads_norm = 5.0409
	sim_grads_norm_tr = -0.0403
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7417
	data_grads_norm = 4.0152
	new_data_grads_norm = 6.0794
	old_data_grads_norm = 4.8498
	sim_grads_norm_tr = -0.0304
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2927
	data_grads_norm = 4.5498
	new_data_grads_norm = 6.4306
	old_data_grads_norm = 5.9144
	sim_grads_norm_tr = 0.0169
-- Starting training on experience 26 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3249
	data_grads_norm = 4.5655
	new_data_grads_norm = 6.3585
	old_data_grads_norm = 5.6906
	sim_grads_norm_tr = 0.0072
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2273
	data_grads_norm = 4.5041
	new_data_grads_norm = 6.3550
	old_data_grads_norm = 6.0101
	sim_grads_norm_tr = -0.0040
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0698
	data_grads_norm = 4.1604
	new_data_grads_norm = 6.2578
	old_data_grads_norm = 5.2554
	sim_grads_norm_tr = 0.0056
-- Starting training on experience 27 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3993
	data_grads_norm = 4.9241
	new_data_grads_norm = 7.2894
	old_data_grads_norm = 5.6961
	sim_grads_norm_tr = 0.0431
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5404
	data_grads_norm = 4.7706
	new_data_grads_norm = 6.3006
	old_data_grads_norm = 6.2402
	sim_grads_norm_tr = -0.0331
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6026
	data_grads_norm = 5.1975
	new_data_grads_norm = 6.9678
	old_data_grads_norm = 5.7718
	sim_grads_norm_tr = -0.0133
-- Starting training on experience 28 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5068
	data_grads_norm = 4.9671
	new_data_grads_norm = 6.2841
	old_data_grads_norm = 6.7316
	sim_grads_norm_tr = 0.0105
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9807
	data_grads_norm = 4.3219
	new_data_grads_norm = 6.2108
	old_data_grads_norm = 5.2486
	sim_grads_norm_tr = 0.0245
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3940
	data_grads_norm = 4.3187
	new_data_grads_norm = 5.9419
	old_data_grads_norm = 5.6543
	sim_grads_norm_tr = 0.0181
-- Starting training on experience 29 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2735
	data_grads_norm = 4.9047
	new_data_grads_norm = 5.7789
	old_data_grads_norm = 6.2220
	sim_grads_norm_tr = 0.0157
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8094
	data_grads_norm = 4.2760
	new_data_grads_norm = 6.1468
	old_data_grads_norm = 5.5150
	sim_grads_norm_tr = -0.0031
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9402
	data_grads_norm = 4.5744
	new_data_grads_norm = 6.0801
	old_data_grads_norm = 6.8902
	sim_grads_norm_tr = -0.0057
-- Starting training on experience 30 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9008
	data_grads_norm = 4.4147
	new_data_grads_norm = 5.8082
	old_data_grads_norm = 6.1697
	sim_grads_norm_tr = -0.0382
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1767
	data_grads_norm = 4.7028
	new_data_grads_norm = 6.1096
	old_data_grads_norm = 5.9058
	sim_grads_norm_tr = 0.1646
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8989
	data_grads_norm = 4.2411
	new_data_grads_norm = 5.4557
	old_data_grads_norm = 5.7909
	sim_grads_norm_tr = 0.0235
-- Starting training on experience 31 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9144
	data_grads_norm = 4.6752
	new_data_grads_norm = 5.9894
	old_data_grads_norm = 6.8186
	sim_grads_norm_tr = -0.0057
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0456
	data_grads_norm = 4.5790
	new_data_grads_norm = 5.9486
	old_data_grads_norm = 6.5305
	sim_grads_norm_tr = -0.0063
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9866
	data_grads_norm = 4.2955
	new_data_grads_norm = 6.5665
	old_data_grads_norm = 5.4576
	sim_grads_norm_tr = 0.0144
-- Starting training on experience 32 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7097
	data_grads_norm = 4.5662
	new_data_grads_norm = 5.9341
	old_data_grads_norm = 5.8616
	sim_grads_norm_tr = 0.0225
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3766
	data_grads_norm = 4.7138
	new_data_grads_norm = 5.8832
	old_data_grads_norm = 6.9434
	sim_grads_norm_tr = 0.0649
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1141
	data_grads_norm = 5.0866
	new_data_grads_norm = 6.4257
	old_data_grads_norm = 6.9591
	sim_grads_norm_tr = 0.0309
-- Starting training on experience 33 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1487
	data_grads_norm = 4.4862
	new_data_grads_norm = 6.2218
	old_data_grads_norm = 6.1717
	sim_grads_norm_tr = -0.0260
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6238
	data_grads_norm = 4.5451
	new_data_grads_norm = 7.1394
	old_data_grads_norm = 4.9332
	sim_grads_norm_tr = 0.0913
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1957
	data_grads_norm = 5.6945
	new_data_grads_norm = 7.0624
	old_data_grads_norm = 6.9776
	sim_grads_norm_tr = 0.0617
-- Starting training on experience 34 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7771
	data_grads_norm = 4.4295
	new_data_grads_norm = 6.3223
	old_data_grads_norm = 6.2252
	sim_grads_norm_tr = -0.0428
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6569
	data_grads_norm = 4.2006
	new_data_grads_norm = 5.8774
	old_data_grads_norm = 6.0289
	sim_grads_norm_tr = -0.0160
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2039
	data_grads_norm = 4.7531
	new_data_grads_norm = 5.6132
	old_data_grads_norm = 6.5492
	sim_grads_norm_tr = 0.0339
-- Starting training on experience 35 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8298
	data_grads_norm = 4.5666
	new_data_grads_norm = 5.7900
	old_data_grads_norm = 6.3862
	sim_grads_norm_tr = 0.0770
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2592
	data_grads_norm = 4.9874
	new_data_grads_norm = 5.7257
	old_data_grads_norm = 6.5053
	sim_grads_norm_tr = -0.0238
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6036
	data_grads_norm = 4.5902
	new_data_grads_norm = 6.0257
	old_data_grads_norm = 5.3343
	sim_grads_norm_tr = -0.0169
-- Starting training on experience 36 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6946
	data_grads_norm = 4.4928
	new_data_grads_norm = 5.6878
	old_data_grads_norm = 6.2108
	sim_grads_norm_tr = 0.0336
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5243
	data_grads_norm = 4.7179
	new_data_grads_norm = 6.2142
	old_data_grads_norm = 6.0321
	sim_grads_norm_tr = 0.0508
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4865
	data_grads_norm = 3.0302
	new_data_grads_norm = 6.4504
	old_data_grads_norm = 2.5783
	sim_grads_norm_tr = -0.0015
-- Starting training on experience 37 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6092
	data_grads_norm = 4.2028
	new_data_grads_norm = 5.9187
	old_data_grads_norm = 5.2781
	sim_grads_norm_tr = 0.0371
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4092
	data_grads_norm = 4.4914
	new_data_grads_norm = 6.5722
	old_data_grads_norm = 6.4389
	sim_grads_norm_tr = -0.0196
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8650
	data_grads_norm = 4.1925
	new_data_grads_norm = 6.7543
	old_data_grads_norm = 5.2142
	sim_grads_norm_tr = -0.0239
-- Starting training on experience 38 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1262
	data_grads_norm = 4.6987
	new_data_grads_norm = 6.0543
	old_data_grads_norm = 6.5979
	sim_grads_norm_tr = 0.1329
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5077
	data_grads_norm = 4.1009
	new_data_grads_norm = 6.2934
	old_data_grads_norm = 5.6950
	sim_grads_norm_tr = -0.0401
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9346
	data_grads_norm = 4.4316
	new_data_grads_norm = 5.8215
	old_data_grads_norm = 6.3573
	sim_grads_norm_tr = -0.0059
-- Starting training on experience 39 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6954
	data_grads_norm = 4.5228
	new_data_grads_norm = 6.3240
	old_data_grads_norm = 6.3780
	sim_grads_norm_tr = -0.0022
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0570
	data_grads_norm = 4.8153
	new_data_grads_norm = 6.6775
	old_data_grads_norm = 6.8309
	sim_grads_norm_tr = 0.0450
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3329
	data_grads_norm = 3.3197
	new_data_grads_norm = 5.5088
	old_data_grads_norm = 4.2068
	sim_grads_norm_tr = -0.0477
-- Starting training on experience 40 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3401
	data_grads_norm = 5.5516
	new_data_grads_norm = 6.3496
	old_data_grads_norm = 8.1584
	sim_grads_norm_tr = 0.0442
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7897
	data_grads_norm = 4.7764
	new_data_grads_norm = 6.4252
	old_data_grads_norm = 5.1855
	sim_grads_norm_tr = 0.0540
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5301
	data_grads_norm = 4.1099
	new_data_grads_norm = 6.1550
	old_data_grads_norm = 5.0371
	sim_grads_norm_tr = -0.0179
-- Starting training on experience 41 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5335
	data_grads_norm = 3.7425
	new_data_grads_norm = 5.8765
	old_data_grads_norm = 4.7647
	sim_grads_norm_tr = 0.0547
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9241
	data_grads_norm = 4.4702
	new_data_grads_norm = 5.6587
	old_data_grads_norm = 6.2945
	sim_grads_norm_tr = 0.0041
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6635
	data_grads_norm = 4.2056
	new_data_grads_norm = 5.1464
	old_data_grads_norm = 6.6069
	sim_grads_norm_tr = 0.0297
-- Starting training on experience 42 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0140
	data_grads_norm = 4.6438
	new_data_grads_norm = 5.5181
	old_data_grads_norm = 6.4458
	sim_grads_norm_tr = 0.0230
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2440
	data_grads_norm = 4.0458
	new_data_grads_norm = 5.5454
	old_data_grads_norm = 5.2284
	sim_grads_norm_tr = -0.0626
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4770
	data_grads_norm = 4.6307
	new_data_grads_norm = 5.4113
	old_data_grads_norm = 7.3763
	sim_grads_norm_tr = 0.0826
-- Starting training on experience 43 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5167
	data_grads_norm = 3.9750
	new_data_grads_norm = 5.5692
	old_data_grads_norm = 5.3336
	sim_grads_norm_tr = 0.0170
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5543
	data_grads_norm = 4.0311
	new_data_grads_norm = 4.9728
	old_data_grads_norm = 5.5818
	sim_grads_norm_tr = -0.0284
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4763
	data_grads_norm = 4.0229
	new_data_grads_norm = 5.1874
	old_data_grads_norm = 6.3544
	sim_grads_norm_tr = 0.0025
-- Starting training on experience 44 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4859
	data_grads_norm = 4.0340
	new_data_grads_norm = 6.2408
	old_data_grads_norm = 4.9376
	sim_grads_norm_tr = 0.0129
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4335
	data_grads_norm = 4.0112
	new_data_grads_norm = 5.5405
	old_data_grads_norm = 5.8263
	sim_grads_norm_tr = 0.0041
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6996
	data_grads_norm = 4.1953
	new_data_grads_norm = 6.0523
	old_data_grads_norm = 4.7017
	sim_grads_norm_tr = 0.0150
-- Starting training on experience 45 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4349
	data_grads_norm = 4.7910
	new_data_grads_norm = 7.1227
	old_data_grads_norm = 5.4950
	sim_grads_norm_tr = -0.0100
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6244
	data_grads_norm = 4.9162
	new_data_grads_norm = 6.2909
	old_data_grads_norm = 6.3883
	sim_grads_norm_tr = -0.0036
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5796
	data_grads_norm = 4.5928
	new_data_grads_norm = 6.9482
	old_data_grads_norm = 5.6028
	sim_grads_norm_tr = 0.0042
-- Starting training on experience 46 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0250
	data_grads_norm = 5.2316
	new_data_grads_norm = 6.5808
	old_data_grads_norm = 7.5954
	sim_grads_norm_tr = -0.0321
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0803
	data_grads_norm = 4.7867
	new_data_grads_norm = 6.8345
	old_data_grads_norm = 6.5299
	sim_grads_norm_tr = 0.0652
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8202
	data_grads_norm = 4.4693
	new_data_grads_norm = 6.4915
	old_data_grads_norm = 5.7077
	sim_grads_norm_tr = 0.0174
-- Starting training on experience 47 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0396
	data_grads_norm = 4.7141
	new_data_grads_norm = 7.3055
	old_data_grads_norm = 5.9137
	sim_grads_norm_tr = 0.0098
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7320
	data_grads_norm = 4.3053
	new_data_grads_norm = 6.3670
	old_data_grads_norm = 4.6149
	sim_grads_norm_tr = -0.0245
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6494
	data_grads_norm = 5.0367
	new_data_grads_norm = 6.7995
	old_data_grads_norm = 7.0189
	sim_grads_norm_tr = 0.0978
-- Starting training on experience 48 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1962
	data_grads_norm = 4.3513
	new_data_grads_norm = 6.3364
	old_data_grads_norm = 6.5415
	sim_grads_norm_tr = -0.0333
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5990
	data_grads_norm = 4.4466
	new_data_grads_norm = 6.5376
	old_data_grads_norm = 5.0421
	sim_grads_norm_tr = 0.0064
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5356
	data_grads_norm = 4.6222
	new_data_grads_norm = 6.6810
	old_data_grads_norm = 5.3735
	sim_grads_norm_tr = -0.0097
-- Starting training on experience 49 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5945
	data_grads_norm = 4.2069
	new_data_grads_norm = 6.0622
	old_data_grads_norm = 5.9834
	sim_grads_norm_tr = 0.0374
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8893
	data_grads_norm = 4.3553
	new_data_grads_norm = 6.4270
	old_data_grads_norm = 5.7839
	sim_grads_norm_tr = 0.0618
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4129
	data_grads_norm = 4.3231
	new_data_grads_norm = 6.1321
	old_data_grads_norm = 5.6686
	sim_grads_norm_tr = 0.0480
-- Starting training on experience 50 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5952
	data_grads_norm = 4.0300
	new_data_grads_norm = 6.0226
	old_data_grads_norm = 5.4526
	sim_grads_norm_tr = 0.0575
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8487
	data_grads_norm = 4.9128
	new_data_grads_norm = 5.5573
	old_data_grads_norm = 7.2927
	sim_grads_norm_tr = -0.0287
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6584
	data_grads_norm = 4.4375
	new_data_grads_norm = 5.9086
	old_data_grads_norm = 6.7194
	sim_grads_norm_tr = 0.0240
-- Starting training on experience 51 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1058
	data_grads_norm = 4.8043
	new_data_grads_norm = 5.8670
	old_data_grads_norm = 6.6848
	sim_grads_norm_tr = -0.0018
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9344
	data_grads_norm = 4.4473
	new_data_grads_norm = 5.9939
	old_data_grads_norm = 5.9813
	sim_grads_norm_tr = -0.0127
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8180
	data_grads_norm = 4.9829
	new_data_grads_norm = 5.6273
	old_data_grads_norm = 7.7491
	sim_grads_norm_tr = 0.0073
-- Starting training on experience 52 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5554
	data_grads_norm = 4.2840
	new_data_grads_norm = 5.5079
	old_data_grads_norm = 5.1323
	sim_grads_norm_tr = 0.1514
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5246
	data_grads_norm = 4.0143
	new_data_grads_norm = 5.3424
	old_data_grads_norm = 6.6551
	sim_grads_norm_tr = -0.0361
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7265
	data_grads_norm = 4.1794
	new_data_grads_norm = 5.7174
	old_data_grads_norm = 5.4575
	sim_grads_norm_tr = 0.0276
-- Starting training on experience 53 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6949
	data_grads_norm = 4.6690
	new_data_grads_norm = 6.3475
	old_data_grads_norm = 6.2106
	sim_grads_norm_tr = -0.0390
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8882
	data_grads_norm = 4.8130
	new_data_grads_norm = 6.3011
	old_data_grads_norm = 6.7515
	sim_grads_norm_tr = 0.0170
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6129
	data_grads_norm = 4.6494
	new_data_grads_norm = 5.9763
	old_data_grads_norm = 6.4051
	sim_grads_norm_tr = 0.0400
-- Starting training on experience 54 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7919
	data_grads_norm = 4.5414
	new_data_grads_norm = 6.4820
	old_data_grads_norm = 5.9030
	sim_grads_norm_tr = 0.0106
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5140
	data_grads_norm = 4.4516
	new_data_grads_norm = 5.9064
	old_data_grads_norm = 5.9719
	sim_grads_norm_tr = -0.0363
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8013
	data_grads_norm = 4.8195
	new_data_grads_norm = 6.0665
	old_data_grads_norm = 7.3135
	sim_grads_norm_tr = -0.0349
-- Starting training on experience 55 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7666
	data_grads_norm = 5.0091
	new_data_grads_norm = 6.6886
	old_data_grads_norm = 5.5369
	sim_grads_norm_tr = 0.0515
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2654
	data_grads_norm = 3.8805
	new_data_grads_norm = 6.5247
	old_data_grads_norm = 4.2888
	sim_grads_norm_tr = 0.0002
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3755
	data_grads_norm = 4.0565
	new_data_grads_norm = 5.9921
	old_data_grads_norm = 4.7552
	sim_grads_norm_tr = -0.0095
-- Starting training on experience 56 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3490
	data_grads_norm = 4.2400
	new_data_grads_norm = 6.1037
	old_data_grads_norm = 5.2110
	sim_grads_norm_tr = 0.0320
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3056
	data_grads_norm = 4.6391
	new_data_grads_norm = 6.0838
	old_data_grads_norm = 5.9283
	sim_grads_norm_tr = -0.0228
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6757
	data_grads_norm = 4.9812
	new_data_grads_norm = 5.9773
	old_data_grads_norm = 6.3941
	sim_grads_norm_tr = 0.0237
-- Starting training on experience 57 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0788
	data_grads_norm = 3.7769
	new_data_grads_norm = 6.0826
	old_data_grads_norm = 5.2045
	sim_grads_norm_tr = -0.0559
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2640
	data_grads_norm = 4.5840
	new_data_grads_norm = 7.3248
	old_data_grads_norm = 6.3311
	sim_grads_norm_tr = -0.0204
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8927
	data_grads_norm = 4.9525
	new_data_grads_norm = 6.4982
	old_data_grads_norm = 6.6456
	sim_grads_norm_tr = 0.0777
-- Starting training on experience 58 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8197
	data_grads_norm = 4.5552
	new_data_grads_norm = 5.5410
	old_data_grads_norm = 7.0988
	sim_grads_norm_tr = -0.0253
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6052
	data_grads_norm = 4.8594
	new_data_grads_norm = 6.8167
	old_data_grads_norm = 6.4358
	sim_grads_norm_tr = 0.1102
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5770
	data_grads_norm = 4.8599
	new_data_grads_norm = 5.8598
	old_data_grads_norm = 7.0256
	sim_grads_norm_tr = 0.0838
-- Starting training on experience 59 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6000
	data_grads_norm = 4.2502
	new_data_grads_norm = 6.4773
	old_data_grads_norm = 5.2629
	sim_grads_norm_tr = 0.0747
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2026
	data_grads_norm = 3.9477
	new_data_grads_norm = 5.8082
	old_data_grads_norm = 4.7253
	sim_grads_norm_tr = -0.0022
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7359
	data_grads_norm = 4.7901
	new_data_grads_norm = 6.8748
	old_data_grads_norm = 6.2678
	sim_grads_norm_tr = 0.0040
-- Starting training on experience 60 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6230
	data_grads_norm = 4.6998
	new_data_grads_norm = 5.8702
	old_data_grads_norm = 6.5337
	sim_grads_norm_tr = 0.0416
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8336
	data_grads_norm = 5.2954
	new_data_grads_norm = 6.1462
	old_data_grads_norm = 7.5733
	sim_grads_norm_tr = -0.0292
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4344
	data_grads_norm = 4.4636
	new_data_grads_norm = 5.5900
	old_data_grads_norm = 6.6478
	sim_grads_norm_tr = 0.0102
-- Starting training on experience 61 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4408
	data_grads_norm = 4.2912
	new_data_grads_norm = 6.2575
	old_data_grads_norm = 5.8494
	sim_grads_norm_tr = 0.0938
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7166
	data_grads_norm = 4.6520
	new_data_grads_norm = 6.3439
	old_data_grads_norm = 5.9759
	sim_grads_norm_tr = -0.0101
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3769
	data_grads_norm = 5.8958
	new_data_grads_norm = 7.1117
	old_data_grads_norm = 9.0461
	sim_grads_norm_tr = 0.0423
-- Starting training on experience 62 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4391
	data_grads_norm = 5.3044
	new_data_grads_norm = 5.9122
	old_data_grads_norm = 8.4584
	sim_grads_norm_tr = 0.0398
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5914
	data_grads_norm = 4.4104
	new_data_grads_norm = 5.7950
	old_data_grads_norm = 6.0414
	sim_grads_norm_tr = 0.0207
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9789
	data_grads_norm = 3.7134
	new_data_grads_norm = 5.6964
	old_data_grads_norm = 4.7431
	sim_grads_norm_tr = -0.0384
-- Starting training on experience 63 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4948
	data_grads_norm = 5.0158
	new_data_grads_norm = 6.9744
	old_data_grads_norm = 6.4461
	sim_grads_norm_tr = -0.0288
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4096
	data_grads_norm = 4.8756
	new_data_grads_norm = 6.7236
	old_data_grads_norm = 6.1939
	sim_grads_norm_tr = 0.0355
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4277
	data_grads_norm = 4.4813
	new_data_grads_norm = 6.4568
	old_data_grads_norm = 5.4808
	sim_grads_norm_tr = -0.0090
-- Starting training on experience 64 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0395
	data_grads_norm = 3.9496
	new_data_grads_norm = 6.4332
	old_data_grads_norm = 5.0563
	sim_grads_norm_tr = 0.0208
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7263
	data_grads_norm = 4.7039
	new_data_grads_norm = 7.0507
	old_data_grads_norm = 6.0464
	sim_grads_norm_tr = -0.0343
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4317
	data_grads_norm = 4.5240
	new_data_grads_norm = 7.1585
	old_data_grads_norm = 6.6077
	sim_grads_norm_tr = 0.0023
-- Starting training on experience 65 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3325
	data_grads_norm = 5.4654
	new_data_grads_norm = 6.6464
	old_data_grads_norm = 6.9113
	sim_grads_norm_tr = 0.0689
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5578
	data_grads_norm = 4.5319
	new_data_grads_norm = 6.5351
	old_data_grads_norm = 5.4823
	sim_grads_norm_tr = -0.0539
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7654
	data_grads_norm = 4.9781
	new_data_grads_norm = 6.5956
	old_data_grads_norm = 7.2136
	sim_grads_norm_tr = 0.0424
-- Starting training on experience 66 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6807
	data_grads_norm = 4.3125
	new_data_grads_norm = 5.5689
	old_data_grads_norm = 6.0379
	sim_grads_norm_tr = 0.0012
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3112
	data_grads_norm = 3.8495
	new_data_grads_norm = 5.3306
	old_data_grads_norm = 5.3548
	sim_grads_norm_tr = 0.0638
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5367
	data_grads_norm = 4.5998
	new_data_grads_norm = 5.9264
	old_data_grads_norm = 6.2174
	sim_grads_norm_tr = 0.0064
-- Starting training on experience 67 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8319
	data_grads_norm = 4.8364
	new_data_grads_norm = 6.2225
	old_data_grads_norm = 6.7680
	sim_grads_norm_tr = 0.0847
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4760
	data_grads_norm = 4.6560
	new_data_grads_norm = 5.9273
	old_data_grads_norm = 6.5809
	sim_grads_norm_tr = -0.0140
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4556
	data_grads_norm = 3.8823
	new_data_grads_norm = 6.1080
	old_data_grads_norm = 5.6836
	sim_grads_norm_tr = -0.0291
-- Starting training on experience 68 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9629
	data_grads_norm = 4.7566
	new_data_grads_norm = 7.1912
	old_data_grads_norm = 6.6946
	sim_grads_norm_tr = 0.0076
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5152
	data_grads_norm = 4.4601
	new_data_grads_norm = 6.6376
	old_data_grads_norm = 6.5545
	sim_grads_norm_tr = -0.0282
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2063
	data_grads_norm = 5.2455
	new_data_grads_norm = 6.6377
	old_data_grads_norm = 7.2028
	sim_grads_norm_tr = 0.0802
-- Starting training on experience 69 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8095
	data_grads_norm = 4.9617
	new_data_grads_norm = 5.6479
	old_data_grads_norm = 6.8594
	sim_grads_norm_tr = 0.1231
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8159
	data_grads_norm = 4.7102
	new_data_grads_norm = 5.8486
	old_data_grads_norm = 6.7887
	sim_grads_norm_tr = 0.0884
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4798
	data_grads_norm = 5.0142
	new_data_grads_norm = 6.5164
	old_data_grads_norm = 6.5886
	sim_grads_norm_tr = 0.0411
-- Starting training on experience 70 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1882
	data_grads_norm = 4.6444
	new_data_grads_norm = 7.5809
	old_data_grads_norm = 4.6232
	sim_grads_norm_tr = -0.0247
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4632
	data_grads_norm = 5.1314
	new_data_grads_norm = 7.1848
	old_data_grads_norm = 6.5509
	sim_grads_norm_tr = -0.0282
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3678
	data_grads_norm = 4.9281
	new_data_grads_norm = 6.9646
	old_data_grads_norm = 5.4460
	sim_grads_norm_tr = 0.0278
-- Starting training on experience 71 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1238
	data_grads_norm = 4.2410
	new_data_grads_norm = 5.6984
	old_data_grads_norm = 6.0122
	sim_grads_norm_tr = -0.0310
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1042
	data_grads_norm = 4.1425
	new_data_grads_norm = 6.1477
	old_data_grads_norm = 5.5478
	sim_grads_norm_tr = 0.0114
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4458
	data_grads_norm = 4.5616
	new_data_grads_norm = 6.0383
	old_data_grads_norm = 6.4705
	sim_grads_norm_tr = 0.0452
-- Starting training on experience 72 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1425
	data_grads_norm = 4.0271
	new_data_grads_norm = 6.2777
	old_data_grads_norm = 5.3995
	sim_grads_norm_tr = -0.0047
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9746
	data_grads_norm = 5.3892
	new_data_grads_norm = 6.4333
	old_data_grads_norm = 7.2378
	sim_grads_norm_tr = 0.1070
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3886
	data_grads_norm = 4.5767
	new_data_grads_norm = 5.8895
	old_data_grads_norm = 6.0551
	sim_grads_norm_tr = 0.0189
-- Starting training on experience 73 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9675
	data_grads_norm = 5.1438
	new_data_grads_norm = 6.5964
	old_data_grads_norm = 7.7830
	sim_grads_norm_tr = 0.0495
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6536
	data_grads_norm = 5.1930
	new_data_grads_norm = 6.2017
	old_data_grads_norm = 7.9840
	sim_grads_norm_tr = 0.0877
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6101
	data_grads_norm = 4.6720
	new_data_grads_norm = 5.9173
	old_data_grads_norm = 7.0748
	sim_grads_norm_tr = 0.0468
-- Starting training on experience 74 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0722
	data_grads_norm = 4.4904
	new_data_grads_norm = 5.7762
	old_data_grads_norm = 6.4206
	sim_grads_norm_tr = 0.0316
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1833
	data_grads_norm = 4.2046
	new_data_grads_norm = 6.0700
	old_data_grads_norm = 5.4737
	sim_grads_norm_tr = 0.0524
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2612
	data_grads_norm = 4.8014
	new_data_grads_norm = 6.1411
	old_data_grads_norm = 7.4788
	sim_grads_norm_tr = 0.0282
-- Starting training on experience 75 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1356
	data_grads_norm = 4.6634
	new_data_grads_norm = 6.0868
	old_data_grads_norm = 5.9386
	sim_grads_norm_tr = 0.0824
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0095
	data_grads_norm = 3.7345
	new_data_grads_norm = 5.4905
	old_data_grads_norm = 4.5276
	sim_grads_norm_tr = 0.0150
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3136
	data_grads_norm = 4.0572
	new_data_grads_norm = 5.5838
	old_data_grads_norm = 5.1175
	sim_grads_norm_tr = -0.0083
-- Starting training on experience 76 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1777
	data_grads_norm = 4.5650
	new_data_grads_norm = 5.7897
	old_data_grads_norm = 7.9111
	sim_grads_norm_tr = -0.0487
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1420
	data_grads_norm = 4.6248
	new_data_grads_norm = 6.3747
	old_data_grads_norm = 6.5302
	sim_grads_norm_tr = -0.0581
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5858
	data_grads_norm = 4.0918
	new_data_grads_norm = 6.1105
	old_data_grads_norm = 5.2674
	sim_grads_norm_tr = -0.0088
-- Starting training on experience 77 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3541
	data_grads_norm = 5.1681
	new_data_grads_norm = 6.7384
	old_data_grads_norm = 7.1213
	sim_grads_norm_tr = 0.0163
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2724
	data_grads_norm = 3.8168
	new_data_grads_norm = 5.8414
	old_data_grads_norm = 4.9397
	sim_grads_norm_tr = -0.0078
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0117
	data_grads_norm = 4.6626
	new_data_grads_norm = 6.4843
	old_data_grads_norm = 6.0501
	sim_grads_norm_tr = 0.0534
-- Starting training on experience 78 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3151
	data_grads_norm = 4.6934
	new_data_grads_norm = 6.1388
	old_data_grads_norm = 6.5990
	sim_grads_norm_tr = 0.0561
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4381
	data_grads_norm = 4.5358
	new_data_grads_norm = 5.6600
	old_data_grads_norm = 6.2639
	sim_grads_norm_tr = 0.1099
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2225
	data_grads_norm = 4.3143
	new_data_grads_norm = 6.3226
	old_data_grads_norm = 5.2661
	sim_grads_norm_tr = -0.0670
-- Starting training on experience 79 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6766
	data_grads_norm = 4.2697
	new_data_grads_norm = 5.6254
	old_data_grads_norm = 5.9884
	sim_grads_norm_tr = -0.0050
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1641
	data_grads_norm = 3.6660
	new_data_grads_norm = 5.1266
	old_data_grads_norm = 5.2515
	sim_grads_norm_tr = -0.0232
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4138
	data_grads_norm = 4.4698
	new_data_grads_norm = 6.0635
	old_data_grads_norm = 6.1311
	sim_grads_norm_tr = 0.0245
-- Starting training on experience 80 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4775
	data_grads_norm = 4.8293
	new_data_grads_norm = 6.4373
	old_data_grads_norm = 6.5263
	sim_grads_norm_tr = -0.0263
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9044
	data_grads_norm = 4.7659
	new_data_grads_norm = 6.5059
	old_data_grads_norm = 6.3806
	sim_grads_norm_tr = -0.0140
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6044
	data_grads_norm = 4.6921
	new_data_grads_norm = 5.7320
	old_data_grads_norm = 7.3623
	sim_grads_norm_tr = -0.0296
-- Starting training on experience 81 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4331
	data_grads_norm = 4.0551
	new_data_grads_norm = 5.3843
	old_data_grads_norm = 5.6858
	sim_grads_norm_tr = 0.0461
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9874
	data_grads_norm = 4.0720
	new_data_grads_norm = 6.2910
	old_data_grads_norm = 5.2267
	sim_grads_norm_tr = -0.0715
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4644
	data_grads_norm = 4.5756
	new_data_grads_norm = 5.9658
	old_data_grads_norm = 5.7570
	sim_grads_norm_tr = -0.0164
-- Starting training on experience 82 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3603
	data_grads_norm = 4.4737
	new_data_grads_norm = 6.7414
	old_data_grads_norm = 5.9397
	sim_grads_norm_tr = 0.0730
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4209
	data_grads_norm = 4.4928
	new_data_grads_norm = 6.5626
	old_data_grads_norm = 4.9888
	sim_grads_norm_tr = 0.0082
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7948
	data_grads_norm = 5.0134
	new_data_grads_norm = 6.8538
	old_data_grads_norm = 6.5404
	sim_grads_norm_tr = -0.0461
-- Starting training on experience 83 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6064
	data_grads_norm = 4.6989
	new_data_grads_norm = 6.6114
	old_data_grads_norm = 6.1962
	sim_grads_norm_tr = -0.0016
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5191
	data_grads_norm = 4.6487
	new_data_grads_norm = 7.2842
	old_data_grads_norm = 5.4296
	sim_grads_norm_tr = 0.0612
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4627
	data_grads_norm = 4.5576
	new_data_grads_norm = 6.3396
	old_data_grads_norm = 4.7760
	sim_grads_norm_tr = 0.0644
-- Starting training on experience 84 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3230
	data_grads_norm = 5.2543
	new_data_grads_norm = 7.3125
	old_data_grads_norm = 6.4322
	sim_grads_norm_tr = 0.0769
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0792
	data_grads_norm = 5.2227
	new_data_grads_norm = 7.0266
	old_data_grads_norm = 7.7759
	sim_grads_norm_tr = -0.0075
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2231
	data_grads_norm = 5.1247
	new_data_grads_norm = 8.2992
	old_data_grads_norm = 5.3075
	sim_grads_norm_tr = -0.0068
-- Starting training on experience 85 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4427
	data_grads_norm = 4.5215
	new_data_grads_norm = 6.1976
	old_data_grads_norm = 7.1569
	sim_grads_norm_tr = 0.0134
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3942
	data_grads_norm = 4.3531
	new_data_grads_norm = 6.3097
	old_data_grads_norm = 6.5626
	sim_grads_norm_tr = 0.0167
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3855
	data_grads_norm = 4.7279
	new_data_grads_norm = 6.6506
	old_data_grads_norm = 6.2379
	sim_grads_norm_tr = 0.0402
-- Starting training on experience 86 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1468
	data_grads_norm = 4.1556
	new_data_grads_norm = 5.4436
	old_data_grads_norm = 5.7856
	sim_grads_norm_tr = 0.0243
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5016
	data_grads_norm = 4.7553
	new_data_grads_norm = 5.6924
	old_data_grads_norm = 7.0047
	sim_grads_norm_tr = 0.0188
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4918
	data_grads_norm = 4.3953
	new_data_grads_norm = 5.8301
	old_data_grads_norm = 6.4311
	sim_grads_norm_tr = 0.0255
-- Starting training on experience 87 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2588
	data_grads_norm = 4.5006
	new_data_grads_norm = 6.7339
	old_data_grads_norm = 6.7745
	sim_grads_norm_tr = 0.0017
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1122
	data_grads_norm = 3.7875
	new_data_grads_norm = 6.2462
	old_data_grads_norm = 5.3723
	sim_grads_norm_tr = -0.0139
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2691
	data_grads_norm = 5.2067
	new_data_grads_norm = 6.2481
	old_data_grads_norm = 7.8377
	sim_grads_norm_tr = 0.0792
-- Starting training on experience 88 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1484
	data_grads_norm = 4.1419
	new_data_grads_norm = 5.8626
	old_data_grads_norm = 5.8814
	sim_grads_norm_tr = -0.0321
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3976
	data_grads_norm = 4.9249
	new_data_grads_norm = 6.7978
	old_data_grads_norm = 6.0397
	sim_grads_norm_tr = 0.0690
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3752
	data_grads_norm = 4.7988
	new_data_grads_norm = 7.1108
	old_data_grads_norm = 5.7049
	sim_grads_norm_tr = 0.0899
-- Starting training on experience 89 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3946
	data_grads_norm = 4.6709
	new_data_grads_norm = 6.3323
	old_data_grads_norm = 6.3829
	sim_grads_norm_tr = 0.0085
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5709
	data_grads_norm = 4.9986
	new_data_grads_norm = 6.6917
	old_data_grads_norm = 5.6466
	sim_grads_norm_tr = 0.0164
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9554
	data_grads_norm = 4.2036
	new_data_grads_norm = 5.8790
	old_data_grads_norm = 5.1027
	sim_grads_norm_tr = -0.0218
-- Starting training on experience 90 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2862
	data_grads_norm = 4.4306
	new_data_grads_norm = 7.0264
	old_data_grads_norm = 5.5069
	sim_grads_norm_tr = 0.0546
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4347
	data_grads_norm = 4.8226
	new_data_grads_norm = 6.9816
	old_data_grads_norm = 6.4401
	sim_grads_norm_tr = -0.0022
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5837
	data_grads_norm = 4.8890
	new_data_grads_norm = 7.3849
	old_data_grads_norm = 5.5015
	sim_grads_norm_tr = 0.1450
-- Starting training on experience 91 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1602
	data_grads_norm = 4.0619
	new_data_grads_norm = 5.9552
	old_data_grads_norm = 5.0767
	sim_grads_norm_tr = -0.0360
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4966
	data_grads_norm = 4.2318
	new_data_grads_norm = 5.9162
	old_data_grads_norm = 5.5770
	sim_grads_norm_tr = 0.0068
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5733
	data_grads_norm = 4.4335
	new_data_grads_norm = 5.6137
	old_data_grads_norm = 6.0884
	sim_grads_norm_tr = 0.0304
-- Starting training on experience 92 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5844
	data_grads_norm = 4.8058
	new_data_grads_norm = 7.3447
	old_data_grads_norm = 5.8008
	sim_grads_norm_tr = 0.0002
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4828
	data_grads_norm = 4.8180
	new_data_grads_norm = 6.6832
	old_data_grads_norm = 6.3217
	sim_grads_norm_tr = 0.0445
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4228
	data_grads_norm = 4.6963
	new_data_grads_norm = 7.2955
	old_data_grads_norm = 6.1293
	sim_grads_norm_tr = 0.0029
-- Starting training on experience 93 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6448
	data_grads_norm = 4.7303
	new_data_grads_norm = 6.3441
	old_data_grads_norm = 5.9236
	sim_grads_norm_tr = 0.0298
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5695
	data_grads_norm = 4.4110
	new_data_grads_norm = 6.3500
	old_data_grads_norm = 5.1436
	sim_grads_norm_tr = 0.0051
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9004
	data_grads_norm = 4.6835
	new_data_grads_norm = 7.4061
	old_data_grads_norm = 5.9124
	sim_grads_norm_tr = -0.0187
-- Starting training on experience 94 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5247
	data_grads_norm = 4.9032
	new_data_grads_norm = 7.0325
	old_data_grads_norm = 6.0060
	sim_grads_norm_tr = 0.0047
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0641
	data_grads_norm = 4.1729
	new_data_grads_norm = 6.3367
	old_data_grads_norm = 5.1433
	sim_grads_norm_tr = 0.0117
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8801
	data_grads_norm = 5.1162
	new_data_grads_norm = 6.9458
	old_data_grads_norm = 7.3157
	sim_grads_norm_tr = -0.0367
-- Starting training on experience 95 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3570
	data_grads_norm = 4.1748
	new_data_grads_norm = 5.7654
	old_data_grads_norm = 6.5192
	sim_grads_norm_tr = 0.0192
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5831
	data_grads_norm = 4.8021
	new_data_grads_norm = 6.1278
	old_data_grads_norm = 6.9496
	sim_grads_norm_tr = -0.0269
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3125
	data_grads_norm = 4.1193
	new_data_grads_norm = 6.2549
	old_data_grads_norm = 4.8365
	sim_grads_norm_tr = -0.0196
-- Starting training on experience 96 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2177
	data_grads_norm = 4.2587
	new_data_grads_norm = 6.6439
	old_data_grads_norm = 5.7933
	sim_grads_norm_tr = -0.0060
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7339
	data_grads_norm = 5.0327
	new_data_grads_norm = 7.1122
	old_data_grads_norm = 6.8999
	sim_grads_norm_tr = 0.0060
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5449
	data_grads_norm = 5.0087
	new_data_grads_norm = 6.2157
	old_data_grads_norm = 6.7302
	sim_grads_norm_tr = 0.0608
-- Starting training on experience 97 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7797
	data_grads_norm = 4.8038
	new_data_grads_norm = 6.1685
	old_data_grads_norm = 7.1443
	sim_grads_norm_tr = 0.0590
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5927
	data_grads_norm = 5.1835
	new_data_grads_norm = 5.8874
	old_data_grads_norm = 8.2738
	sim_grads_norm_tr = 0.0044
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9649
	data_grads_norm = 5.6983
	new_data_grads_norm = 6.4145
	old_data_grads_norm = 8.9121
	sim_grads_norm_tr = 0.0596
-- Starting training on experience 98 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4083
	data_grads_norm = 3.8558
	new_data_grads_norm = 5.9150
	old_data_grads_norm = 4.8306
	sim_grads_norm_tr = 0.0243
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1722
	data_grads_norm = 4.4264
	new_data_grads_norm = 5.9071
	old_data_grads_norm = 7.0956
	sim_grads_norm_tr = 0.0096
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0189
	data_grads_norm = 3.9386
	new_data_grads_norm = 5.6505
	old_data_grads_norm = 5.4909
	sim_grads_norm_tr = 0.0486
-- Starting training on experience 99 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3898
	data_grads_norm = 4.2175
	new_data_grads_norm = 6.6764
	old_data_grads_norm = 4.8246
	sim_grads_norm_tr = -0.0074
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8707
	data_grads_norm = 4.5697
	new_data_grads_norm = 7.0266
	old_data_grads_norm = 6.3568
	sim_grads_norm_tr = -0.0539
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4135
	data_grads_norm = 4.5004
	new_data_grads_norm = 6.7036
	old_data_grads_norm = 5.3134
	sim_grads_norm_tr = 0.2505
-- Starting training on experience 100 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3554
	data_grads_norm = 4.8855
	new_data_grads_norm = 6.6285
	old_data_grads_norm = 5.9828
	sim_grads_norm_tr = 0.0970
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6695
	data_grads_norm = 3.7496
	new_data_grads_norm = 6.2376
	old_data_grads_norm = 5.5337
	sim_grads_norm_tr = -0.0093
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5098
	data_grads_norm = 5.0106
	new_data_grads_norm = 6.0329
	old_data_grads_norm = 6.7653
	sim_grads_norm_tr = 0.0265
-- Starting training on experience 101 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2873
	data_grads_norm = 4.6323
	new_data_grads_norm = 6.2429
	old_data_grads_norm = 6.5382
	sim_grads_norm_tr = 0.0135
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5835
	data_grads_norm = 3.6433
	new_data_grads_norm = 6.0200
	old_data_grads_norm = 4.6195
	sim_grads_norm_tr = 0.0324
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7900
	data_grads_norm = 3.6826
	new_data_grads_norm = 6.2223
	old_data_grads_norm = 5.8409
	sim_grads_norm_tr = -0.0994
-- Starting training on experience 102 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4127
	data_grads_norm = 4.4510
	new_data_grads_norm = 6.2078
	old_data_grads_norm = 5.9284
	sim_grads_norm_tr = 0.0389
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0661
	data_grads_norm = 4.6067
	new_data_grads_norm = 6.3460
	old_data_grads_norm = 6.7284
	sim_grads_norm_tr = 0.0018
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2840
	data_grads_norm = 4.3223
	new_data_grads_norm = 5.8315
	old_data_grads_norm = 6.5285
	sim_grads_norm_tr = -0.0274
-- Starting training on experience 103 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5861
	data_grads_norm = 4.5196
	new_data_grads_norm = 6.3587
	old_data_grads_norm = 5.9454
	sim_grads_norm_tr = 0.1404
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9970
	data_grads_norm = 4.1734
	new_data_grads_norm = 5.4869
	old_data_grads_norm = 5.9105
	sim_grads_norm_tr = 0.0242
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2035
	data_grads_norm = 4.1975
	new_data_grads_norm = 5.2124
	old_data_grads_norm = 6.5616
	sim_grads_norm_tr = -0.0280
-- Starting training on experience 104 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5013
	data_grads_norm = 4.6073
	new_data_grads_norm = 6.1761
	old_data_grads_norm = 5.6188
	sim_grads_norm_tr = 0.0017
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4128
	data_grads_norm = 4.2515
	new_data_grads_norm = 6.1949
	old_data_grads_norm = 5.3076
	sim_grads_norm_tr = 0.0356
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5043
	data_grads_norm = 4.3649
	new_data_grads_norm = 6.1602
	old_data_grads_norm = 5.6994
	sim_grads_norm_tr = -0.0510
-- Starting training on experience 105 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9533
	data_grads_norm = 5.0070
	new_data_grads_norm = 6.7120
	old_data_grads_norm = 6.8465
	sim_grads_norm_tr = 0.0906
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2954
	data_grads_norm = 3.8786
	new_data_grads_norm = 6.5880
	old_data_grads_norm = 3.6828
	sim_grads_norm_tr = -0.0146
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1261
	data_grads_norm = 3.6605
	new_data_grads_norm = 6.1664
	old_data_grads_norm = 4.6000
	sim_grads_norm_tr = -0.0344
-- Starting training on experience 106 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7244
	data_grads_norm = 4.2514
	new_data_grads_norm = 6.6355
	old_data_grads_norm = 5.5043
	sim_grads_norm_tr = -0.0800
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0445
	data_grads_norm = 4.5430
	new_data_grads_norm = 6.5444
	old_data_grads_norm = 6.6115
	sim_grads_norm_tr = 0.0019
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6563
	data_grads_norm = 4.7266
	new_data_grads_norm = 6.5837
	old_data_grads_norm = 6.0566
	sim_grads_norm_tr = 0.0900
-- Starting training on experience 107 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7301
	data_grads_norm = 3.7995
	new_data_grads_norm = 5.5347
	old_data_grads_norm = 5.4138
	sim_grads_norm_tr = 0.0292
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4616
	data_grads_norm = 4.9017
	new_data_grads_norm = 5.5642
	old_data_grads_norm = 7.8774
	sim_grads_norm_tr = -0.0036
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8802
	data_grads_norm = 3.9358
	new_data_grads_norm = 5.5826
	old_data_grads_norm = 4.5075
	sim_grads_norm_tr = 0.0345
-- Starting training on experience 108 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0078
	data_grads_norm = 4.0275
	new_data_grads_norm = 5.9062
	old_data_grads_norm = 5.4735
	sim_grads_norm_tr = -0.0449
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0876
	data_grads_norm = 4.1606
	new_data_grads_norm = 6.5544
	old_data_grads_norm = 5.4472
	sim_grads_norm_tr = 0.0582
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1413
	data_grads_norm = 4.2927
	new_data_grads_norm = 5.9995
	old_data_grads_norm = 5.8077
	sim_grads_norm_tr = 0.0298
-- Starting training on experience 109 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6498
	data_grads_norm = 5.1169
	new_data_grads_norm = 5.7254
	old_data_grads_norm = 7.7494
	sim_grads_norm_tr = 0.0702
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2669
	data_grads_norm = 4.3976
	new_data_grads_norm = 6.0469
	old_data_grads_norm = 6.7876
	sim_grads_norm_tr = -0.0568
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2662
	data_grads_norm = 4.0523
	new_data_grads_norm = 5.6297
	old_data_grads_norm = 4.9593
	sim_grads_norm_tr = 0.1361
-- Starting training on experience 110 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3648
	data_grads_norm = 4.6862
	new_data_grads_norm = 6.7968
	old_data_grads_norm = 5.7310
	sim_grads_norm_tr = 0.0882
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7097
	data_grads_norm = 5.0501
	new_data_grads_norm = 5.5561
	old_data_grads_norm = 7.0630
	sim_grads_norm_tr = 0.0774
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2907
	data_grads_norm = 4.9148
	new_data_grads_norm = 5.6659
	old_data_grads_norm = 7.0457
	sim_grads_norm_tr = 0.0600
-- Starting training on experience 111 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4737
	data_grads_norm = 5.6942
	new_data_grads_norm = 7.1166
	old_data_grads_norm = 7.8872
	sim_grads_norm_tr = 0.0440
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9115
	data_grads_norm = 4.2625
	new_data_grads_norm = 6.7663
	old_data_grads_norm = 5.2047
	sim_grads_norm_tr = -0.0142
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2138
	data_grads_norm = 4.5689
	new_data_grads_norm = 6.9702
	old_data_grads_norm = 5.3403
	sim_grads_norm_tr = -0.0029
-- Starting training on experience 112 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4039
	data_grads_norm = 4.4385
	new_data_grads_norm = 6.3037
	old_data_grads_norm = 6.6603
	sim_grads_norm_tr = 0.0484
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7321
	data_grads_norm = 4.4338
	new_data_grads_norm = 6.3828
	old_data_grads_norm = 5.6259
	sim_grads_norm_tr = -0.0172
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8616
	data_grads_norm = 3.9611
	new_data_grads_norm = 6.0564
	old_data_grads_norm = 4.3697
	sim_grads_norm_tr = -0.0007
-- Starting training on experience 113 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4532
	data_grads_norm = 4.8659
	new_data_grads_norm = 6.1873
	old_data_grads_norm = 7.0979
	sim_grads_norm_tr = 0.0464
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0809
	data_grads_norm = 3.9803
	new_data_grads_norm = 6.1699
	old_data_grads_norm = 5.3038
	sim_grads_norm_tr = -0.0497
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1308
	data_grads_norm = 4.0058
	new_data_grads_norm = 6.2355
	old_data_grads_norm = 4.9104
	sim_grads_norm_tr = 0.0038
-- Starting training on experience 114 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1079
	data_grads_norm = 4.2165
	new_data_grads_norm = 6.1020
	old_data_grads_norm = 4.7030
	sim_grads_norm_tr = 0.0001
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0635
	data_grads_norm = 4.3019
	new_data_grads_norm = 6.0904
	old_data_grads_norm = 5.4761
	sim_grads_norm_tr = -0.0566
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8283
	data_grads_norm = 3.7478
	new_data_grads_norm = 5.9169
	old_data_grads_norm = 4.4588
	sim_grads_norm_tr = -0.0110
-- Starting training on experience 115 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2409
	data_grads_norm = 3.6737
	new_data_grads_norm = 5.9892
	old_data_grads_norm = 4.3760
	sim_grads_norm_tr = -0.0586
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4450
	data_grads_norm = 4.4801
	new_data_grads_norm = 6.5756
	old_data_grads_norm = 6.1796
	sim_grads_norm_tr = -0.0078
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7913
	data_grads_norm = 4.8699
	new_data_grads_norm = 6.5465
	old_data_grads_norm = 6.6802
	sim_grads_norm_tr = -0.0020
-- Starting training on experience 116 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5774
	data_grads_norm = 5.2840
	new_data_grads_norm = 6.2087
	old_data_grads_norm = 7.6792
	sim_grads_norm_tr = -0.0501
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9799
	data_grads_norm = 5.4828
	new_data_grads_norm = 6.3116
	old_data_grads_norm = 7.5825
	sim_grads_norm_tr = 0.0172
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3540
	data_grads_norm = 4.3359
	new_data_grads_norm = 6.5644
	old_data_grads_norm = 5.4880
	sim_grads_norm_tr = 0.0864
-- Starting training on experience 117 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3173
	data_grads_norm = 4.5039
	new_data_grads_norm = 5.7467
	old_data_grads_norm = 6.4407
	sim_grads_norm_tr = 0.0670
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0300
	data_grads_norm = 4.7196
	new_data_grads_norm = 5.8115
	old_data_grads_norm = 7.6949
	sim_grads_norm_tr = -0.0422
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5944
	data_grads_norm = 5.0118
	new_data_grads_norm = 6.3559
	old_data_grads_norm = 7.2532
	sim_grads_norm_tr = 0.0207
-- Starting training on experience 118 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3809
	data_grads_norm = 4.7604
	new_data_grads_norm = 5.4532
	old_data_grads_norm = 7.2508
	sim_grads_norm_tr = 0.0051
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6356
	data_grads_norm = 5.4234
	new_data_grads_norm = 6.0104
	old_data_grads_norm = 8.4603
	sim_grads_norm_tr = 0.0833
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0397
	data_grads_norm = 3.7860
	new_data_grads_norm = 5.2769
	old_data_grads_norm = 6.0269
	sim_grads_norm_tr = -0.0484
-- Starting training on experience 119 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0761
	data_grads_norm = 4.6022
	new_data_grads_norm = 6.3303
	old_data_grads_norm = 6.7276
	sim_grads_norm_tr = -0.0086
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3473
	data_grads_norm = 4.9417
	new_data_grads_norm = 6.5678
	old_data_grads_norm = 6.5814
	sim_grads_norm_tr = 0.1943
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4161
	data_grads_norm = 4.7243
	new_data_grads_norm = 5.9549
	old_data_grads_norm = 7.6121
	sim_grads_norm_tr = 0.0778
-- Starting training on experience 120 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1757
	data_grads_norm = 4.1461
	new_data_grads_norm = 6.0271
	old_data_grads_norm = 6.3555
	sim_grads_norm_tr = -0.0430
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4581
	data_grads_norm = 4.4516
	new_data_grads_norm = 5.4435
	old_data_grads_norm = 6.1791
	sim_grads_norm_tr = 0.0142
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3216
	data_grads_norm = 4.4116
	new_data_grads_norm = 5.5040
	old_data_grads_norm = 6.2985
	sim_grads_norm_tr = -0.0002
-- Starting training on experience 121 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3678
	data_grads_norm = 4.7614
	new_data_grads_norm = 6.6468
	old_data_grads_norm = 6.4037
	sim_grads_norm_tr = 0.0578
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6666
	data_grads_norm = 4.7981
	new_data_grads_norm = 5.6631
	old_data_grads_norm = 7.1544
	sim_grads_norm_tr = 0.0509
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5105
	data_grads_norm = 4.5920
	new_data_grads_norm = 6.2797
	old_data_grads_norm = 5.7330
	sim_grads_norm_tr = 0.1063
-- Starting training on experience 122 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6774
	data_grads_norm = 3.8530
	new_data_grads_norm = 6.4236
	old_data_grads_norm = 5.1817
	sim_grads_norm_tr = 0.0100
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6063
	data_grads_norm = 5.2064
	new_data_grads_norm = 6.1531
	old_data_grads_norm = 7.6860
	sim_grads_norm_tr = 0.0354
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2859
	data_grads_norm = 4.4921
	new_data_grads_norm = 5.6645
	old_data_grads_norm = 6.5380
	sim_grads_norm_tr = 0.0051
-- Starting training on experience 123 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1146
	data_grads_norm = 4.1823
	new_data_grads_norm = 5.9200
	old_data_grads_norm = 6.1445
	sim_grads_norm_tr = -0.0424
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4321
	data_grads_norm = 4.8248
	new_data_grads_norm = 6.0410
	old_data_grads_norm = 7.2781
	sim_grads_norm_tr = -0.0100
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2888
	data_grads_norm = 4.7015
	new_data_grads_norm = 6.2432
	old_data_grads_norm = 5.9078
	sim_grads_norm_tr = -0.0294
-- Starting training on experience 124 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1509
	data_grads_norm = 4.8387
	new_data_grads_norm = 6.3195
	old_data_grads_norm = 5.9936
	sim_grads_norm_tr = 0.0238
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0670
	data_grads_norm = 4.5805
	new_data_grads_norm = 6.3582
	old_data_grads_norm = 5.2666
	sim_grads_norm_tr = 0.0253
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9866
	data_grads_norm = 4.8183
	new_data_grads_norm = 5.8548
	old_data_grads_norm = 6.8073
	sim_grads_norm_tr = 0.0942
-- Starting training on experience 125 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6808
	data_grads_norm = 4.1473
	new_data_grads_norm = 5.3301
	old_data_grads_norm = 5.4967
	sim_grads_norm_tr = 0.0497
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9730
	data_grads_norm = 4.1426
	new_data_grads_norm = 5.3750
	old_data_grads_norm = 6.8592
	sim_grads_norm_tr = -0.0040
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8760
	data_grads_norm = 4.0147
	new_data_grads_norm = 5.5428
	old_data_grads_norm = 6.3869
	sim_grads_norm_tr = -0.0481
-- Starting training on experience 126 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8689
	data_grads_norm = 4.7198
	new_data_grads_norm = 6.7163
	old_data_grads_norm = 7.1010
	sim_grads_norm_tr = -0.0094
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9122
	data_grads_norm = 4.6354
	new_data_grads_norm = 6.5558
	old_data_grads_norm = 5.7851
	sim_grads_norm_tr = -0.0832
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4478
	data_grads_norm = 5.6316
	new_data_grads_norm = 6.9709
	old_data_grads_norm = 8.4108
	sim_grads_norm_tr = 0.0786
-- Starting training on experience 127 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3902
	data_grads_norm = 5.0228
	new_data_grads_norm = 6.5277
	old_data_grads_norm = 7.8402
	sim_grads_norm_tr = -0.0267
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8089
	data_grads_norm = 4.0956
	new_data_grads_norm = 5.6358
	old_data_grads_norm = 6.4562
	sim_grads_norm_tr = -0.0986
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7668
	data_grads_norm = 5.2293
	new_data_grads_norm = 6.3358
	old_data_grads_norm = 8.0746
	sim_grads_norm_tr = -0.0053
-- Starting training on experience 128 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1793
	data_grads_norm = 4.1483
	new_data_grads_norm = 6.6230
	old_data_grads_norm = 6.0005
	sim_grads_norm_tr = -0.0369
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7076
	data_grads_norm = 5.0365
	new_data_grads_norm = 7.3821
	old_data_grads_norm = 5.2421
	sim_grads_norm_tr = -0.0183
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0888
	data_grads_norm = 5.5598
	new_data_grads_norm = 7.2555
	old_data_grads_norm = 7.9511
	sim_grads_norm_tr = 0.0691
-- Starting training on experience 129 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9572
	data_grads_norm = 3.9284
	new_data_grads_norm = 6.3137
	old_data_grads_norm = 5.2070
	sim_grads_norm_tr = -0.0563
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0079
	data_grads_norm = 4.1763
	new_data_grads_norm = 6.1762
	old_data_grads_norm = 5.4268
	sim_grads_norm_tr = 0.0169
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5007
	data_grads_norm = 4.9458
	new_data_grads_norm = 6.0403
	old_data_grads_norm = 6.6491
	sim_grads_norm_tr = 0.0718
-- Starting training on experience 130 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7446
	data_grads_norm = 4.2816
	new_data_grads_norm = 6.7097
	old_data_grads_norm = 6.1686
	sim_grads_norm_tr = 0.0341
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8730
	data_grads_norm = 3.9498
	new_data_grads_norm = 6.5376
	old_data_grads_norm = 4.7890
	sim_grads_norm_tr = 0.0010
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9540
	data_grads_norm = 4.9670
	new_data_grads_norm = 7.1758
	old_data_grads_norm = 7.2019
	sim_grads_norm_tr = -0.0460
-- Starting training on experience 131 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1839
	data_grads_norm = 4.6597
	new_data_grads_norm = 7.6676
	old_data_grads_norm = 5.8533
	sim_grads_norm_tr = 0.0411
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7181
	data_grads_norm = 6.0837
	new_data_grads_norm = 6.8526
	old_data_grads_norm = 9.0831
	sim_grads_norm_tr = 0.0307
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1163
	data_grads_norm = 4.5667
	new_data_grads_norm = 6.4091
	old_data_grads_norm = 5.2985
	sim_grads_norm_tr = 0.0225
-- Starting training on experience 132 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9519
	data_grads_norm = 3.8659
	new_data_grads_norm = 5.5451
	old_data_grads_norm = 6.5021
	sim_grads_norm_tr = -0.0163
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1022
	data_grads_norm = 5.0342
	new_data_grads_norm = 5.3122
	old_data_grads_norm = 9.8056
	sim_grads_norm_tr = -0.0449
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2690
	data_grads_norm = 4.6474
	new_data_grads_norm = 5.7499
	old_data_grads_norm = 6.8876
	sim_grads_norm_tr = -0.0351
-- Starting training on experience 133 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8680
	data_grads_norm = 4.6970
	new_data_grads_norm = 5.6745
	old_data_grads_norm = 7.5254
	sim_grads_norm_tr = 0.0187
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1221
	data_grads_norm = 4.6010
	new_data_grads_norm = 6.4596
	old_data_grads_norm = 6.5218
	sim_grads_norm_tr = 0.0381
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1640
	data_grads_norm = 4.4948
	new_data_grads_norm = 6.4344
	old_data_grads_norm = 6.7460
	sim_grads_norm_tr = -0.0426
-- Starting training on experience 134 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4708
	data_grads_norm = 4.8176
	new_data_grads_norm = 6.5326
	old_data_grads_norm = 6.5688
	sim_grads_norm_tr = -0.0104
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6399
	data_grads_norm = 5.5801
	new_data_grads_norm = 7.4118
	old_data_grads_norm = 5.6968
	sim_grads_norm_tr = 0.0250
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5918
	data_grads_norm = 4.7942
	new_data_grads_norm = 6.0954
	old_data_grads_norm = 6.9999
	sim_grads_norm_tr = 0.0718
-- Starting training on experience 135 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5001
	data_grads_norm = 5.3375
	new_data_grads_norm = 6.0738
	old_data_grads_norm = 7.6914
	sim_grads_norm_tr = 0.0335
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0673
	data_grads_norm = 3.7895
	new_data_grads_norm = 6.1687
	old_data_grads_norm = 4.5576
	sim_grads_norm_tr = -0.0597
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3685
	data_grads_norm = 5.2938
	new_data_grads_norm = 7.3593
	old_data_grads_norm = 7.0858
	sim_grads_norm_tr = 0.0177
-- Starting training on experience 136 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6854
	data_grads_norm = 5.1978
	new_data_grads_norm = 7.0449
	old_data_grads_norm = 6.5744
	sim_grads_norm_tr = 0.0793
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3959
	data_grads_norm = 4.6247
	new_data_grads_norm = 6.6300
	old_data_grads_norm = 7.2846
	sim_grads_norm_tr = -0.0559
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4999
	data_grads_norm = 5.1957
	new_data_grads_norm = 7.2544
	old_data_grads_norm = 6.4868
	sim_grads_norm_tr = 0.1354
-- Starting training on experience 137 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8874
	data_grads_norm = 6.0338
	new_data_grads_norm = 7.8103
	old_data_grads_norm = 7.7613
	sim_grads_norm_tr = 0.0448
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8653
	data_grads_norm = 4.0071
	new_data_grads_norm = 6.4160
	old_data_grads_norm = 5.3332
	sim_grads_norm_tr = 0.0272
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8955
	data_grads_norm = 4.7077
	new_data_grads_norm = 7.3915
	old_data_grads_norm = 5.0040
	sim_grads_norm_tr = 0.0416
-- Starting training on experience 138 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2057
	data_grads_norm = 4.7321
	new_data_grads_norm = 6.5168
	old_data_grads_norm = 6.7452
	sim_grads_norm_tr = -0.0143
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8414
	data_grads_norm = 5.1203
	new_data_grads_norm = 6.6664
	old_data_grads_norm = 7.4486
	sim_grads_norm_tr = -0.0107
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8219
	data_grads_norm = 5.2270
	new_data_grads_norm = 7.1904
	old_data_grads_norm = 7.4993
	sim_grads_norm_tr = -0.0534
-- Starting training on experience 139 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0438
	data_grads_norm = 5.6045
	new_data_grads_norm = 7.1117
	old_data_grads_norm = 5.9515
	sim_grads_norm_tr = 0.1186
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1173
	data_grads_norm = 4.6505
	new_data_grads_norm = 6.5339
	old_data_grads_norm = 4.7903
	sim_grads_norm_tr = -0.0093
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3879
	data_grads_norm = 4.4775
	new_data_grads_norm = 6.7085
	old_data_grads_norm = 6.5039
	sim_grads_norm_tr = -0.0000
-- Starting training on experience 140 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2839
	data_grads_norm = 5.1405
	new_data_grads_norm = 6.0211
	old_data_grads_norm = 7.6472
	sim_grads_norm_tr = 0.0134
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9977
	data_grads_norm = 4.4578
	new_data_grads_norm = 5.6614
	old_data_grads_norm = 6.6662
	sim_grads_norm_tr = -0.0076
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0370
	data_grads_norm = 4.6108
	new_data_grads_norm = 6.6925
	old_data_grads_norm = 5.9099
	sim_grads_norm_tr = 0.0348
-- Starting training on experience 141 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5803
	data_grads_norm = 3.6273
	new_data_grads_norm = 5.9610
	old_data_grads_norm = 4.8932
	sim_grads_norm_tr = -0.0018
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9046
	data_grads_norm = 3.9019
	new_data_grads_norm = 6.6401
	old_data_grads_norm = 5.0038
	sim_grads_norm_tr = -0.0370
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9302
	data_grads_norm = 4.0212
	new_data_grads_norm = 6.0221
	old_data_grads_norm = 4.7273
	sim_grads_norm_tr = 0.0299
-- Starting training on experience 142 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9812
	data_grads_norm = 4.7613
	new_data_grads_norm = 6.1704
	old_data_grads_norm = 5.2241
	sim_grads_norm_tr = 0.0449
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1739
	data_grads_norm = 4.3601
	new_data_grads_norm = 6.3236
	old_data_grads_norm = 5.6997
	sim_grads_norm_tr = -0.0214
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2866
	data_grads_norm = 4.9025
	new_data_grads_norm = 7.1689
	old_data_grads_norm = 5.5525
	sim_grads_norm_tr = 0.0272
-- Starting training on experience 143 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8600
	data_grads_norm = 3.9107
	new_data_grads_norm = 4.8554
	old_data_grads_norm = 6.1225
	sim_grads_norm_tr = 0.0135
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7409
	data_grads_norm = 3.8115
	new_data_grads_norm = 5.2069
	old_data_grads_norm = 5.1189
	sim_grads_norm_tr = 0.0004
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9761
	data_grads_norm = 4.0607
	new_data_grads_norm = 4.5433
	old_data_grads_norm = 6.9449
	sim_grads_norm_tr = -0.0098
-- Starting training on experience 144 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0012
	data_grads_norm = 4.0885
	new_data_grads_norm = 6.5504
	old_data_grads_norm = 5.2031
	sim_grads_norm_tr = -0.0092
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0478
	data_grads_norm = 4.4824
	new_data_grads_norm = 6.4865
	old_data_grads_norm = 5.5531
	sim_grads_norm_tr = -0.0395
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0087
	data_grads_norm = 4.2350
	new_data_grads_norm = 6.3592
	old_data_grads_norm = 4.8789
	sim_grads_norm_tr = -0.0216
-- Starting training on experience 145 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0640
	data_grads_norm = 4.9842
	new_data_grads_norm = 6.8260
	old_data_grads_norm = 6.6041
	sim_grads_norm_tr = -0.0254
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1252
	data_grads_norm = 4.4661
	new_data_grads_norm = 6.8231
	old_data_grads_norm = 5.2963
	sim_grads_norm_tr = -0.0359
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5483
	data_grads_norm = 5.4491
	new_data_grads_norm = 8.0760
	old_data_grads_norm = 5.5625
	sim_grads_norm_tr = 0.1121
-- Starting training on experience 146 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1361
	data_grads_norm = 4.7651
	new_data_grads_norm = 6.1665
	old_data_grads_norm = 6.6873
	sim_grads_norm_tr = 0.0035
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2351
	data_grads_norm = 4.7603
	new_data_grads_norm = 6.4882
	old_data_grads_norm = 5.2124
	sim_grads_norm_tr = 0.0928
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7269
	data_grads_norm = 3.9157
	new_data_grads_norm = 5.7181
	old_data_grads_norm = 5.3700
	sim_grads_norm_tr = -0.0272
-- Starting training on experience 147 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8178
	data_grads_norm = 3.8412
	new_data_grads_norm = 5.7332
	old_data_grads_norm = 5.0833
	sim_grads_norm_tr = -0.0393
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9508
	data_grads_norm = 4.4549
	new_data_grads_norm = 5.5351
	old_data_grads_norm = 7.6550
	sim_grads_norm_tr = 0.0163
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2902
	data_grads_norm = 4.2977
	new_data_grads_norm = 5.8942
	old_data_grads_norm = 5.6963
	sim_grads_norm_tr = 0.1040
-- Starting training on experience 148 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9035
	data_grads_norm = 4.2976
	new_data_grads_norm = 6.3568
	old_data_grads_norm = 6.1755
	sim_grads_norm_tr = -0.0512
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2396
	data_grads_norm = 5.1715
	new_data_grads_norm = 6.4751
	old_data_grads_norm = 6.3223
	sim_grads_norm_tr = 0.0928
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8818
	data_grads_norm = 3.8863
	new_data_grads_norm = 5.2992
	old_data_grads_norm = 5.9291
	sim_grads_norm_tr = 0.0088
-- Starting training on experience 149 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9445
	data_grads_norm = 4.6757
	new_data_grads_norm = 5.8157
	old_data_grads_norm = 7.3924
	sim_grads_norm_tr = -0.0238
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9818
	data_grads_norm = 4.8100
	new_data_grads_norm = 5.9505
	old_data_grads_norm = 7.4113
	sim_grads_norm_tr = 0.0097
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2131
	data_grads_norm = 4.5753
	new_data_grads_norm = 5.8773
	old_data_grads_norm = 6.4687
	sim_grads_norm_tr = -0.0672
-- Starting training on experience 150 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8930
	data_grads_norm = 4.8343
	new_data_grads_norm = 6.5337
	old_data_grads_norm = 7.1868
	sim_grads_norm_tr = -0.0683
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9944
	data_grads_norm = 4.4634
	new_data_grads_norm = 6.4426
	old_data_grads_norm = 6.6384
	sim_grads_norm_tr = -0.0192
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6126
	data_grads_norm = 5.3200
	new_data_grads_norm = 6.9221
	old_data_grads_norm = 6.7345
	sim_grads_norm_tr = 0.0606
-- Starting training on experience 151 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8736
	data_grads_norm = 5.1307
	new_data_grads_norm = 5.5016
	old_data_grads_norm = 8.4244
	sim_grads_norm_tr = -0.0455
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9651
	data_grads_norm = 4.7422
	new_data_grads_norm = 5.8758
	old_data_grads_norm = 6.4227
	sim_grads_norm_tr = 0.0460
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7827
	data_grads_norm = 4.1399
	new_data_grads_norm = 6.0296
	old_data_grads_norm = 6.3825
	sim_grads_norm_tr = 0.0173
-- Starting training on experience 152 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2990
	data_grads_norm = 4.8412
	new_data_grads_norm = 6.5018
	old_data_grads_norm = 6.6243
	sim_grads_norm_tr = 0.0592
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1241
	data_grads_norm = 4.9185
	new_data_grads_norm = 6.4973
	old_data_grads_norm = 6.6936
	sim_grads_norm_tr = 0.0217
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7390
	data_grads_norm = 5.0978
	new_data_grads_norm = 6.2067
	old_data_grads_norm = 7.5882
	sim_grads_norm_tr = 0.0066
-- Starting training on experience 153 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0145
	data_grads_norm = 3.8809
	new_data_grads_norm = 5.0587
	old_data_grads_norm = 6.2970
	sim_grads_norm_tr = -0.0460
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0251
	data_grads_norm = 4.3340
	new_data_grads_norm = 5.0651
	old_data_grads_norm = 6.6330
	sim_grads_norm_tr = 0.0574
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0907
	data_grads_norm = 4.6546
	new_data_grads_norm = 5.0949
	old_data_grads_norm = 7.3156
	sim_grads_norm_tr = 0.0027
-- Starting training on experience 154 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8651
	data_grads_norm = 3.7478
	new_data_grads_norm = 4.8569
	old_data_grads_norm = 5.1702
	sim_grads_norm_tr = 0.0512
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5935
	data_grads_norm = 4.0021
	new_data_grads_norm = 4.7561
	old_data_grads_norm = 6.2508
	sim_grads_norm_tr = -0.0116
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3540
	data_grads_norm = 4.4760
	new_data_grads_norm = 4.8847
	old_data_grads_norm = 6.3438
	sim_grads_norm_tr = -0.0621
-- Starting training on experience 155 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2655
	data_grads_norm = 4.5375
	new_data_grads_norm = 6.5259
	old_data_grads_norm = 6.3249
	sim_grads_norm_tr = -0.0192
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8399
	data_grads_norm = 4.7542
	new_data_grads_norm = 6.9368
	old_data_grads_norm = 6.5016
	sim_grads_norm_tr = -0.0109
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3856
	data_grads_norm = 4.7852
	new_data_grads_norm = 6.7385
	old_data_grads_norm = 6.6997
	sim_grads_norm_tr = -0.0171
-- Starting training on experience 156 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4593
	data_grads_norm = 5.0628
	new_data_grads_norm = 6.7733
	old_data_grads_norm = 6.7650
	sim_grads_norm_tr = -0.0291
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7016
	data_grads_norm = 3.7798
	new_data_grads_norm = 6.6175
	old_data_grads_norm = 5.0107
	sim_grads_norm_tr = -0.0402
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5011
	data_grads_norm = 4.9901
	new_data_grads_norm = 7.6972
	old_data_grads_norm = 5.0733
	sim_grads_norm_tr = 0.1307
-- Starting training on experience 157 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2060
	data_grads_norm = 4.6156
	new_data_grads_norm = 6.3216
	old_data_grads_norm = 5.7000
	sim_grads_norm_tr = 0.0491
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2956
	data_grads_norm = 4.3019
	new_data_grads_norm = 6.3487
	old_data_grads_norm = 5.9678
	sim_grads_norm_tr = -0.0002
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9299
	data_grads_norm = 3.9744
	new_data_grads_norm = 6.6458
	old_data_grads_norm = 4.9204
	sim_grads_norm_tr = -0.0283
-- Starting training on experience 158 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7806
	data_grads_norm = 4.6876
	new_data_grads_norm = 6.4222
	old_data_grads_norm = 7.2011
	sim_grads_norm_tr = -0.0291
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9111
	data_grads_norm = 4.1179
	new_data_grads_norm = 6.4374
	old_data_grads_norm = 4.9190
	sim_grads_norm_tr = 0.0537
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2860
	data_grads_norm = 4.4607
	new_data_grads_norm = 6.4183
	old_data_grads_norm = 6.0273
	sim_grads_norm_tr = -0.0526
-- Starting training on experience 159 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9641
	data_grads_norm = 4.7588
	new_data_grads_norm = 6.5827
	old_data_grads_norm = 7.8368
	sim_grads_norm_tr = -0.0522
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8689
	data_grads_norm = 4.2142
	new_data_grads_norm = 7.4460
	old_data_grads_norm = 4.0167
	sim_grads_norm_tr = 0.0575
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9171
	data_grads_norm = 4.9539
	new_data_grads_norm = 7.0528
	old_data_grads_norm = 6.2374
	sim_grads_norm_tr = -0.0151
-- Starting training on experience 160 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6407
	data_grads_norm = 4.7996
	new_data_grads_norm = 7.3700
	old_data_grads_norm = 6.1393
	sim_grads_norm_tr = 0.0177
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3315
	data_grads_norm = 4.5844
	new_data_grads_norm = 7.1044
	old_data_grads_norm = 5.4765
	sim_grads_norm_tr = 0.0352
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5912
	data_grads_norm = 5.3494
	new_data_grads_norm = 7.0824
	old_data_grads_norm = 7.7236
	sim_grads_norm_tr = -0.0615
-- Starting training on experience 161 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2803
	data_grads_norm = 4.8865
	new_data_grads_norm = 6.5782
	old_data_grads_norm = 7.4432
	sim_grads_norm_tr = -0.0006
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2198
	data_grads_norm = 4.7790
	new_data_grads_norm = 6.7861
	old_data_grads_norm = 6.7587
	sim_grads_norm_tr = -0.0049
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5497
	data_grads_norm = 4.7218
	new_data_grads_norm = 5.9764
	old_data_grads_norm = 6.2787
	sim_grads_norm_tr = 0.0926
-- Starting training on experience 162 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0672
	data_grads_norm = 4.5562
	new_data_grads_norm = 6.6294
	old_data_grads_norm = 7.1663
	sim_grads_norm_tr = -0.0438
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1107
	data_grads_norm = 4.3952
	new_data_grads_norm = 6.8065
	old_data_grads_norm = 6.0770
	sim_grads_norm_tr = 0.0232
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1028
	data_grads_norm = 4.3201
	new_data_grads_norm = 7.0494
	old_data_grads_norm = 5.5583
	sim_grads_norm_tr = -0.0377
-- Starting training on experience 163 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5481
	data_grads_norm = 5.0008
	new_data_grads_norm = 7.0449
	old_data_grads_norm = 6.7327
	sim_grads_norm_tr = 0.0535
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4945
	data_grads_norm = 5.7338
	new_data_grads_norm = 7.5047
	old_data_grads_norm = 7.3290
	sim_grads_norm_tr = 0.0605
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4432
	data_grads_norm = 4.5533
	new_data_grads_norm = 6.7406
	old_data_grads_norm = 5.0952
	sim_grads_norm_tr = 0.1365
-- Starting training on experience 164 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1066
	data_grads_norm = 5.0615
	new_data_grads_norm = 6.6226
	old_data_grads_norm = 7.2218
	sim_grads_norm_tr = -0.0112
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0162
	data_grads_norm = 4.2526
	new_data_grads_norm = 6.1903
	old_data_grads_norm = 6.1473
	sim_grads_norm_tr = 0.0138
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7780
	data_grads_norm = 4.1108
	new_data_grads_norm = 6.4772
	old_data_grads_norm = 6.3205
	sim_grads_norm_tr = -0.0473
-- Starting training on experience 165 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1666
	data_grads_norm = 4.9646
	new_data_grads_norm = 5.8739
	old_data_grads_norm = 6.8763
	sim_grads_norm_tr = -0.0264
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7048
	data_grads_norm = 4.3793
	new_data_grads_norm = 7.0717
	old_data_grads_norm = 6.1450
	sim_grads_norm_tr = 0.0280
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5974
	data_grads_norm = 5.9951
	new_data_grads_norm = 7.0056
	old_data_grads_norm = 8.8930
	sim_grads_norm_tr = 0.0605
-- Starting training on experience 166 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9104
	data_grads_norm = 4.2756
	new_data_grads_norm = 6.2965
	old_data_grads_norm = 6.0025
	sim_grads_norm_tr = 0.0153
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2541
	data_grads_norm = 4.8264
	new_data_grads_norm = 6.2900
	old_data_grads_norm = 6.7921
	sim_grads_norm_tr = -0.0257
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1152
	data_grads_norm = 4.5171
	new_data_grads_norm = 6.5574
	old_data_grads_norm = 6.7008
	sim_grads_norm_tr = -0.0498
-- Starting training on experience 167 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9774
	data_grads_norm = 4.2257
	new_data_grads_norm = 6.0403
	old_data_grads_norm = 6.1728
	sim_grads_norm_tr = 0.0377
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3927
	data_grads_norm = 4.5599
	new_data_grads_norm = 6.1050
	old_data_grads_norm = 6.3121
	sim_grads_norm_tr = 0.0289
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8335
	data_grads_norm = 4.3501
	new_data_grads_norm = 6.2005
	old_data_grads_norm = 6.2036
	sim_grads_norm_tr = -0.0070
-- Starting training on experience 168 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0026
	data_grads_norm = 4.6655
	new_data_grads_norm = 6.3752
	old_data_grads_norm = 7.6565
	sim_grads_norm_tr = 0.0057
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1217
	data_grads_norm = 4.3078
	new_data_grads_norm = 6.6396
	old_data_grads_norm = 5.9754
	sim_grads_norm_tr = -0.0363
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5727
	data_grads_norm = 4.9190
	new_data_grads_norm = 6.5918
	old_data_grads_norm = 6.6155
	sim_grads_norm_tr = -0.0091
-- Starting training on experience 169 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9205
	data_grads_norm = 4.2886
	new_data_grads_norm = 6.8637
	old_data_grads_norm = 4.8105
	sim_grads_norm_tr = -0.0230
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4365
	data_grads_norm = 4.6399
	new_data_grads_norm = 6.3779
	old_data_grads_norm = 5.5771
	sim_grads_norm_tr = 0.0874
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4674
	data_grads_norm = 4.8764
	new_data_grads_norm = 6.3464
	old_data_grads_norm = 6.8461
	sim_grads_norm_tr = 0.0698
-- Starting training on experience 170 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1293
	data_grads_norm = 4.9309
	new_data_grads_norm = 8.2011
	old_data_grads_norm = 4.7663
	sim_grads_norm_tr = 0.0409
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5067
	data_grads_norm = 5.0151
	new_data_grads_norm = 7.2388
	old_data_grads_norm = 7.0280
	sim_grads_norm_tr = -0.0175
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7030
	data_grads_norm = 5.8867
	new_data_grads_norm = 8.5557
	old_data_grads_norm = 5.7350
	sim_grads_norm_tr = 0.0179
-- Starting training on experience 171 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5604
	data_grads_norm = 3.7449
	new_data_grads_norm = 7.0011
	old_data_grads_norm = 4.5009
	sim_grads_norm_tr = -0.0399
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1834
	data_grads_norm = 5.5684
	new_data_grads_norm = 6.2904
	old_data_grads_norm = 8.0635
	sim_grads_norm_tr = 0.0339
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9269
	data_grads_norm = 4.5372
	new_data_grads_norm = 6.4632
	old_data_grads_norm = 6.4905
	sim_grads_norm_tr = 0.0157
-- Starting training on experience 172 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0195
	data_grads_norm = 4.3749
	new_data_grads_norm = 5.9333
	old_data_grads_norm = 6.2940
	sim_grads_norm_tr = -0.0088
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2718
	data_grads_norm = 5.3404
	new_data_grads_norm = 5.9221
	old_data_grads_norm = 7.2628
	sim_grads_norm_tr = 0.1016
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6521
	data_grads_norm = 3.7838
	new_data_grads_norm = 5.2569
	old_data_grads_norm = 4.8997
	sim_grads_norm_tr = -0.0364
-- Starting training on experience 173 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9115
	data_grads_norm = 3.8062
	new_data_grads_norm = 5.9832
	old_data_grads_norm = 5.8445
	sim_grads_norm_tr = -0.0091
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1887
	data_grads_norm = 4.4639
	new_data_grads_norm = 6.0749
	old_data_grads_norm = 6.3625
	sim_grads_norm_tr = -0.0182
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0825
	data_grads_norm = 4.4048
	new_data_grads_norm = 5.6291
	old_data_grads_norm = 6.2660
	sim_grads_norm_tr = -0.0132
-- Starting training on experience 174 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3006
	data_grads_norm = 4.9037
	new_data_grads_norm = 7.1714
	old_data_grads_norm = 5.7184
	sim_grads_norm_tr = -0.0007
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6488
	data_grads_norm = 4.9812
	new_data_grads_norm = 7.7495
	old_data_grads_norm = 6.0734
	sim_grads_norm_tr = -0.0078
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6073
	data_grads_norm = 5.7325
	new_data_grads_norm = 7.4454
	old_data_grads_norm = 7.9470
	sim_grads_norm_tr = 0.0574
-- Starting training on experience 175 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2721
	data_grads_norm = 4.7124
	new_data_grads_norm = 5.9384
	old_data_grads_norm = 7.7074
	sim_grads_norm_tr = -0.0439
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2458
	data_grads_norm = 5.0176
	new_data_grads_norm = 6.4732
	old_data_grads_norm = 6.7633
	sim_grads_norm_tr = 0.0009
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2989
	data_grads_norm = 4.1673
	new_data_grads_norm = 6.0684
	old_data_grads_norm = 5.2645
	sim_grads_norm_tr = 0.0520
-- Starting training on experience 176 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8694
	data_grads_norm = 4.0974
	new_data_grads_norm = 7.0658
	old_data_grads_norm = 4.0068
	sim_grads_norm_tr = -0.0238
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1951
	data_grads_norm = 4.8855
	new_data_grads_norm = 6.6744
	old_data_grads_norm = 6.9580
	sim_grads_norm_tr = 0.0569
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5252
	data_grads_norm = 5.0144
	new_data_grads_norm = 6.4119
	old_data_grads_norm = 6.6073
	sim_grads_norm_tr = 0.0063
-- Starting training on experience 177 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5588
	data_grads_norm = 5.5365
	new_data_grads_norm = 5.6513
	old_data_grads_norm = 7.9227
	sim_grads_norm_tr = 0.1055
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2041
	data_grads_norm = 4.0641
	new_data_grads_norm = 5.1922
	old_data_grads_norm = 5.8886
	sim_grads_norm_tr = 0.0685
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9121
	data_grads_norm = 4.0114
	new_data_grads_norm = 5.1533
	old_data_grads_norm = 5.8527
	sim_grads_norm_tr = 0.0052
-- Starting training on experience 178 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8326
	data_grads_norm = 3.8201
	new_data_grads_norm = 5.6857
	old_data_grads_norm = 4.7682
	sim_grads_norm_tr = 0.0111
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9519
	data_grads_norm = 4.4418
	new_data_grads_norm = 5.9906
	old_data_grads_norm = 6.4440
	sim_grads_norm_tr = -0.0445
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6174
	data_grads_norm = 4.5227
	new_data_grads_norm = 6.5961
	old_data_grads_norm = 6.2112
	sim_grads_norm_tr = 0.0100
-- Starting training on experience 179 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0741
	data_grads_norm = 4.9014
	new_data_grads_norm = 6.5388
	old_data_grads_norm = 7.6897
	sim_grads_norm_tr = -0.0169
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8895
	data_grads_norm = 4.7795
	new_data_grads_norm = 7.1045
	old_data_grads_norm = 5.2509
	sim_grads_norm_tr = 0.0367
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2096
	data_grads_norm = 5.1468
	new_data_grads_norm = 6.7848
	old_data_grads_norm = 6.7488
	sim_grads_norm_tr = -0.0140
-- Starting training on experience 180 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9261
	data_grads_norm = 3.9498
	new_data_grads_norm = 5.5040
	old_data_grads_norm = 6.0368
	sim_grads_norm_tr = -0.0327
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1010
	data_grads_norm = 4.4622
	new_data_grads_norm = 5.2685
	old_data_grads_norm = 6.6551
	sim_grads_norm_tr = 0.0269
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7058
	data_grads_norm = 3.8150
	new_data_grads_norm = 5.4646
	old_data_grads_norm = 5.1360
	sim_grads_norm_tr = 0.1020
-- Starting training on experience 181 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1027
	data_grads_norm = 3.9778
	new_data_grads_norm = 6.2660
	old_data_grads_norm = 5.5237
	sim_grads_norm_tr = -0.0405
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1250
	data_grads_norm = 4.8205
	new_data_grads_norm = 6.6227
	old_data_grads_norm = 6.9112
	sim_grads_norm_tr = -0.0379
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9051
	data_grads_norm = 5.5570
	new_data_grads_norm = 6.6414
	old_data_grads_norm = 8.0498
	sim_grads_norm_tr = 0.0104
-- Starting training on experience 182 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1061
	data_grads_norm = 4.7566
	new_data_grads_norm = 7.6934
	old_data_grads_norm = 6.5819
	sim_grads_norm_tr = -0.0030
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7186
	data_grads_norm = 5.0233
	new_data_grads_norm = 7.0658
	old_data_grads_norm = 6.1690
	sim_grads_norm_tr = 0.0686
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0788
	data_grads_norm = 4.4557
	new_data_grads_norm = 7.2160
	old_data_grads_norm = 5.7701
	sim_grads_norm_tr = 0.0568
-- Starting training on experience 183 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7056
	data_grads_norm = 3.8773
	new_data_grads_norm = 5.9356
	old_data_grads_norm = 5.7976
	sim_grads_norm_tr = -0.0106
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0696
	data_grads_norm = 4.4410
	new_data_grads_norm = 6.9695
	old_data_grads_norm = 5.5840
	sim_grads_norm_tr = 0.0161
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8979
	data_grads_norm = 4.3884
	new_data_grads_norm = 6.8980
	old_data_grads_norm = 4.1558
	sim_grads_norm_tr = 0.1611
-- Starting training on experience 184 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8762
	data_grads_norm = 3.9456
	new_data_grads_norm = 5.5080
	old_data_grads_norm = 6.1302
	sim_grads_norm_tr = -0.0114
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9083
	data_grads_norm = 4.6299
	new_data_grads_norm = 5.6470
	old_data_grads_norm = 7.9656
	sim_grads_norm_tr = 0.0499
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2122
	data_grads_norm = 4.7396
	new_data_grads_norm = 5.7267
	old_data_grads_norm = 7.3893
	sim_grads_norm_tr = 0.0218
-- Starting training on experience 185 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1436
	data_grads_norm = 4.4528
	new_data_grads_norm = 6.6454
	old_data_grads_norm = 6.0164
	sim_grads_norm_tr = 0.0560
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1787
	data_grads_norm = 4.2755
	new_data_grads_norm = 6.9584
	old_data_grads_norm = 4.0975
	sim_grads_norm_tr = 0.0389
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0516
	data_grads_norm = 4.2912
	new_data_grads_norm = 6.7733
	old_data_grads_norm = 6.0352
	sim_grads_norm_tr = 0.0221
-- Starting training on experience 186 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6091
	data_grads_norm = 4.5756
	new_data_grads_norm = 6.1530
	old_data_grads_norm = 5.8771
	sim_grads_norm_tr = -0.0054
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0253
	data_grads_norm = 4.2567
	new_data_grads_norm = 6.0791
	old_data_grads_norm = 7.0092
	sim_grads_norm_tr = -0.0343
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8162
	data_grads_norm = 4.3452
	new_data_grads_norm = 5.3435
	old_data_grads_norm = 6.1100
	sim_grads_norm_tr = 0.1208
-- Starting training on experience 187 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9850
	data_grads_norm = 4.3353
	new_data_grads_norm = 7.1754
	old_data_grads_norm = 4.7172
	sim_grads_norm_tr = -0.0003
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9115
	data_grads_norm = 4.7726
	new_data_grads_norm = 7.6120
	old_data_grads_norm = 5.1367
	sim_grads_norm_tr = 0.1661
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2285
	data_grads_norm = 4.6666
	new_data_grads_norm = 5.8325
	old_data_grads_norm = 6.9478
	sim_grads_norm_tr = -0.0520
-- Starting training on experience 188 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9412
	data_grads_norm = 4.2009
	new_data_grads_norm = 6.4831
	old_data_grads_norm = 5.3138
	sim_grads_norm_tr = -0.0069
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1369
	data_grads_norm = 4.5117
	new_data_grads_norm = 6.5173
	old_data_grads_norm = 6.0694
	sim_grads_norm_tr = 0.0265
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8433
	data_grads_norm = 3.9006
	new_data_grads_norm = 6.4092
	old_data_grads_norm = 4.6452
	sim_grads_norm_tr = -0.0266
-- Starting training on experience 189 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6491
	data_grads_norm = 3.9571
	new_data_grads_norm = 5.6435
	old_data_grads_norm = 6.7431
	sim_grads_norm_tr = -0.0065
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6902
	data_grads_norm = 4.5560
	new_data_grads_norm = 5.8331
	old_data_grads_norm = 7.1460
	sim_grads_norm_tr = -0.0121
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7410
	data_grads_norm = 4.1927
	new_data_grads_norm = 5.9593
	old_data_grads_norm = 6.9144
	sim_grads_norm_tr = -0.0133
-- Starting training on experience 190 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3434
	data_grads_norm = 5.0632
	new_data_grads_norm = 7.2907
	old_data_grads_norm = 6.5695
	sim_grads_norm_tr = -0.0262
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5328
	data_grads_norm = 4.7521
	new_data_grads_norm = 7.3246
	old_data_grads_norm = 5.7066
	sim_grads_norm_tr = 0.0219
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1751
	data_grads_norm = 4.5290
	new_data_grads_norm = 6.8843
	old_data_grads_norm = 5.3514
	sim_grads_norm_tr = 0.0077
-- Starting training on experience 191 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0277
	data_grads_norm = 4.9307
	new_data_grads_norm = 6.9694
	old_data_grads_norm = 6.6995
	sim_grads_norm_tr = 0.0137
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8660
	data_grads_norm = 5.0654
	new_data_grads_norm = 7.4930
	old_data_grads_norm = 5.5830
	sim_grads_norm_tr = 0.0043
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9240
	data_grads_norm = 4.2284
	new_data_grads_norm = 6.8656
	old_data_grads_norm = 5.3670
	sim_grads_norm_tr = -0.0316
-- Starting training on experience 192 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3633
	data_grads_norm = 5.0012
	new_data_grads_norm = 5.9094
	old_data_grads_norm = 8.6204
	sim_grads_norm_tr = 0.0061
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1447
	data_grads_norm = 4.3259
	new_data_grads_norm = 6.0260
	old_data_grads_norm = 5.2401
	sim_grads_norm_tr = 0.0863
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7001
	data_grads_norm = 5.2660
	new_data_grads_norm = 5.5952
	old_data_grads_norm = 8.9192
	sim_grads_norm_tr = 0.0135
-- Starting training on experience 193 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6235
	data_grads_norm = 3.8218
	new_data_grads_norm = 5.5713
	old_data_grads_norm = 5.5304
	sim_grads_norm_tr = -0.1220
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9249
	data_grads_norm = 4.3725
	new_data_grads_norm = 5.7297
	old_data_grads_norm = 6.3030
	sim_grads_norm_tr = -0.0969
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4119
	data_grads_norm = 4.8883
	new_data_grads_norm = 6.4647
	old_data_grads_norm = 7.1954
	sim_grads_norm_tr = 0.0091
-- Starting training on experience 194 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2642
	data_grads_norm = 4.9092
	new_data_grads_norm = 7.5353
	old_data_grads_norm = 5.6832
	sim_grads_norm_tr = 0.0889
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1476
	data_grads_norm = 4.4288
	new_data_grads_norm = 6.5536
	old_data_grads_norm = 6.1249
	sim_grads_norm_tr = -0.0022
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5613
	data_grads_norm = 5.2638
	new_data_grads_norm = 6.2727
	old_data_grads_norm = 7.6969
	sim_grads_norm_tr = 0.0672
-- Starting training on experience 195 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9857
	data_grads_norm = 4.4304
	new_data_grads_norm = 6.4426
	old_data_grads_norm = 4.9338
	sim_grads_norm_tr = -0.0187
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6586
	data_grads_norm = 4.0893
	new_data_grads_norm = 6.7304
	old_data_grads_norm = 5.1138
	sim_grads_norm_tr = -0.0430
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8123
	data_grads_norm = 4.5951
	new_data_grads_norm = 6.6425
	old_data_grads_norm = 6.9814
	sim_grads_norm_tr = -0.0127
-- Starting training on experience 196 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0593
	data_grads_norm = 4.5848
	new_data_grads_norm = 6.9720
	old_data_grads_norm = 5.9158
	sim_grads_norm_tr = -0.0323
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3529
	data_grads_norm = 4.6745
	new_data_grads_norm = 6.6114
	old_data_grads_norm = 7.6338
	sim_grads_norm_tr = -0.0190
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1329
	data_grads_norm = 4.1627
	new_data_grads_norm = 6.5598
	old_data_grads_norm = 5.6522
	sim_grads_norm_tr = 0.0013
-- Starting training on experience 197 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3474
	data_grads_norm = 4.3882
	new_data_grads_norm = 7.3051
	old_data_grads_norm = 5.3138
	sim_grads_norm_tr = -0.0627
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3822
	data_grads_norm = 5.1823
	new_data_grads_norm = 7.9753
	old_data_grads_norm = 7.6597
	sim_grads_norm_tr = -0.0641
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5083
	data_grads_norm = 5.4307
	new_data_grads_norm = 7.9283
	old_data_grads_norm = 7.4730
	sim_grads_norm_tr = 0.0907
-- Starting training on experience 198 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2078
	data_grads_norm = 4.7291
	new_data_grads_norm = 7.4085
	old_data_grads_norm = 5.4716
	sim_grads_norm_tr = 0.0280
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7510
	data_grads_norm = 4.6438
	new_data_grads_norm = 7.0001
	old_data_grads_norm = 5.1475
	sim_grads_norm_tr = 0.0423
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0979
	data_grads_norm = 5.0072
	new_data_grads_norm = 6.7133
	old_data_grads_norm = 6.7557
	sim_grads_norm_tr = -0.0399
-- Starting training on experience 199 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6074
	data_grads_norm = 5.3730
	new_data_grads_norm = 7.2543
	old_data_grads_norm = 7.5725
	sim_grads_norm_tr = 0.0310
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2096
	data_grads_norm = 4.9361
	new_data_grads_norm = 7.2937
	old_data_grads_norm = 6.3468
	sim_grads_norm_tr = 0.0240
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4845
	data_grads_norm = 4.2973
	new_data_grads_norm = 7.6623
	old_data_grads_norm = 5.1991
	sim_grads_norm_tr = 0.0167
-- Starting training on experience 200 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1567
	data_grads_norm = 4.5284
	new_data_grads_norm = 6.6889
	old_data_grads_norm = 5.6541
	sim_grads_norm_tr = 0.0662
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0440
	data_grads_norm = 4.4361
	new_data_grads_norm = 7.0846
	old_data_grads_norm = 4.7131
	sim_grads_norm_tr = -0.0347
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9296
	data_grads_norm = 4.1145
	new_data_grads_norm = 7.1000
	old_data_grads_norm = 6.0176
	sim_grads_norm_tr = -0.0311
-- Starting training on experience 201 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8432
	data_grads_norm = 3.8412
	new_data_grads_norm = 5.8673
	old_data_grads_norm = 4.9454
	sim_grads_norm_tr = 0.1262
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0276
	data_grads_norm = 4.3724
	new_data_grads_norm = 6.1761
	old_data_grads_norm = 5.5799
	sim_grads_norm_tr = 0.0496
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8282
	data_grads_norm = 4.3092
	new_data_grads_norm = 6.0605
	old_data_grads_norm = 5.9888
	sim_grads_norm_tr = 0.0194
-- Starting training on experience 202 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1375
	data_grads_norm = 5.0258
	new_data_grads_norm = 6.7275
	old_data_grads_norm = 8.2015
	sim_grads_norm_tr = -0.0473
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7912
	data_grads_norm = 4.4361
	new_data_grads_norm = 5.5003
	old_data_grads_norm = 6.2739
	sim_grads_norm_tr = -0.0351
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5646
	data_grads_norm = 3.7810
	new_data_grads_norm = 5.3068
	old_data_grads_norm = 5.6551
	sim_grads_norm_tr = 0.0103
-- Starting training on experience 203 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2535
	data_grads_norm = 4.8270
	new_data_grads_norm = 6.6260
	old_data_grads_norm = 5.5005
	sim_grads_norm_tr = 0.0704
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0679
	data_grads_norm = 4.9600
	new_data_grads_norm = 7.7843
	old_data_grads_norm = 5.2818
	sim_grads_norm_tr = 0.0501
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1159
	data_grads_norm = 4.7416
	new_data_grads_norm = 6.8654
	old_data_grads_norm = 6.5009
	sim_grads_norm_tr = 0.0132
-- Starting training on experience 204 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2976
	data_grads_norm = 4.6771
	new_data_grads_norm = 7.3071
	old_data_grads_norm = 5.5451
	sim_grads_norm_tr = -0.0085
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0587
	data_grads_norm = 4.8011
	new_data_grads_norm = 7.0462
	old_data_grads_norm = 6.4441
	sim_grads_norm_tr = -0.0770
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0085
	data_grads_norm = 5.9504
	new_data_grads_norm = 8.0963
	old_data_grads_norm = 8.4160
	sim_grads_norm_tr = 0.0195
-- Starting training on experience 205 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2589
	data_grads_norm = 4.9453
	new_data_grads_norm = 7.3109
	old_data_grads_norm = 6.5261
	sim_grads_norm_tr = -0.0472
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1824
	data_grads_norm = 5.1408
	new_data_grads_norm = 7.4687
	old_data_grads_norm = 6.2952
	sim_grads_norm_tr = 0.0020
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4506
	data_grads_norm = 5.4654
	new_data_grads_norm = 7.9826
	old_data_grads_norm = 6.8507
	sim_grads_norm_tr = 0.0164
-- Starting training on experience 206 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2842
	data_grads_norm = 4.7741
	new_data_grads_norm = 6.7950
	old_data_grads_norm = 5.4462
	sim_grads_norm_tr = 0.1229
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8489
	data_grads_norm = 4.0745
	new_data_grads_norm = 6.3487
	old_data_grads_norm = 5.0156
	sim_grads_norm_tr = 0.0674
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2759
	data_grads_norm = 5.1683
	new_data_grads_norm = 7.0139
	old_data_grads_norm = 7.3911
	sim_grads_norm_tr = -0.0048
-- Starting training on experience 207 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3398
	data_grads_norm = 4.7316
	new_data_grads_norm = 7.3309
	old_data_grads_norm = 6.3775
	sim_grads_norm_tr = 0.0368
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2622
	data_grads_norm = 5.0837
	new_data_grads_norm = 5.4044
	old_data_grads_norm = 6.6878
	sim_grads_norm_tr = 0.0007
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1179
	data_grads_norm = 4.4542
	new_data_grads_norm = 6.3075
	old_data_grads_norm = 5.9006
	sim_grads_norm_tr = 0.0373
-- Starting training on experience 208 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8818
	data_grads_norm = 4.2366
	new_data_grads_norm = 6.3005
	old_data_grads_norm = 5.2490
	sim_grads_norm_tr = -0.0315
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4018
	data_grads_norm = 5.0100
	new_data_grads_norm = 7.6396
	old_data_grads_norm = 5.2378
	sim_grads_norm_tr = 0.1698
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4835
	data_grads_norm = 5.2877
	new_data_grads_norm = 6.6897
	old_data_grads_norm = 7.9677
	sim_grads_norm_tr = -0.0237
-- Starting training on experience 209 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2059
	data_grads_norm = 4.3132
	new_data_grads_norm = 6.0263
	old_data_grads_norm = 6.2148
	sim_grads_norm_tr = -0.0682
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6307
	data_grads_norm = 5.1793
	new_data_grads_norm = 6.6395
	old_data_grads_norm = 7.1198
	sim_grads_norm_tr = 0.0787
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9419
	data_grads_norm = 4.6110
	new_data_grads_norm = 6.7914
	old_data_grads_norm = 6.1423
	sim_grads_norm_tr = 0.0429
-- Starting training on experience 210 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6708
	data_grads_norm = 5.8636
	new_data_grads_norm = 7.7059
	old_data_grads_norm = 8.3708
	sim_grads_norm_tr = 0.0598
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4989
	data_grads_norm = 5.0715
	new_data_grads_norm = 7.1714
	old_data_grads_norm = 7.2760
	sim_grads_norm_tr = -0.0492
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4210
	data_grads_norm = 4.7666
	new_data_grads_norm = 7.2848
	old_data_grads_norm = 5.9149
	sim_grads_norm_tr = -0.0143
-- Starting training on experience 211 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9244
	data_grads_norm = 4.5846
	new_data_grads_norm = 6.8492
	old_data_grads_norm = 5.2020
	sim_grads_norm_tr = 0.1257
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6258
	data_grads_norm = 4.6316
	new_data_grads_norm = 6.8958
	old_data_grads_norm = 6.1129
	sim_grads_norm_tr = 0.0229
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4173
	data_grads_norm = 5.4728
	new_data_grads_norm = 7.4236
	old_data_grads_norm = 8.7626
	sim_grads_norm_tr = 0.0239
-- Starting training on experience 212 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8293
	data_grads_norm = 4.1799
	new_data_grads_norm = 7.3056
	old_data_grads_norm = 4.7978
	sim_grads_norm_tr = 0.0650
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0037
	data_grads_norm = 4.9484
	new_data_grads_norm = 6.3826
	old_data_grads_norm = 7.3928
	sim_grads_norm_tr = 0.0289
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4555
	data_grads_norm = 3.8925
	new_data_grads_norm = 7.0770
	old_data_grads_norm = 5.7166
	sim_grads_norm_tr = -0.0294
-- Starting training on experience 213 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8788
	data_grads_norm = 4.3898
	new_data_grads_norm = 5.6480
	old_data_grads_norm = 5.6942
	sim_grads_norm_tr = -0.0053
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2061
	data_grads_norm = 4.7547
	new_data_grads_norm = 5.7213
	old_data_grads_norm = 6.9926
	sim_grads_norm_tr = 0.0278
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1758
	data_grads_norm = 4.3353
	new_data_grads_norm = 5.3105
	old_data_grads_norm = 6.9289
	sim_grads_norm_tr = -0.0598
-- Starting training on experience 214 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0794
	data_grads_norm = 4.5631
	new_data_grads_norm = 6.4917
	old_data_grads_norm = 6.1356
	sim_grads_norm_tr = -0.0388
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4652
	data_grads_norm = 5.8400
	new_data_grads_norm = 6.9721
	old_data_grads_norm = 9.2759
	sim_grads_norm_tr = 0.0242
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2652
	data_grads_norm = 5.1594
	new_data_grads_norm = 7.2553
	old_data_grads_norm = 6.5568
	sim_grads_norm_tr = -0.0115
-- Starting training on experience 215 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4571
	data_grads_norm = 4.3533
	new_data_grads_norm = 5.7760
	old_data_grads_norm = 6.4472
	sim_grads_norm_tr = 0.0488
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1871
	data_grads_norm = 4.3526
	new_data_grads_norm = 6.1034
	old_data_grads_norm = 5.6527
	sim_grads_norm_tr = 0.0685
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0864
	data_grads_norm = 4.1557
	new_data_grads_norm = 5.9150
	old_data_grads_norm = 6.2893
	sim_grads_norm_tr = -0.0298
-- Starting training on experience 216 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0750
	data_grads_norm = 4.4086
	new_data_grads_norm = 6.8861
	old_data_grads_norm = 4.9699
	sim_grads_norm_tr = -0.0370
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4684
	data_grads_norm = 4.9001
	new_data_grads_norm = 7.3905
	old_data_grads_norm = 5.5728
	sim_grads_norm_tr = 0.0129
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2875
	data_grads_norm = 5.1865
	new_data_grads_norm = 7.8185
	old_data_grads_norm = 6.3501
	sim_grads_norm_tr = -0.0309
-- Starting training on experience 217 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4165
	data_grads_norm = 5.0517
	new_data_grads_norm = 7.1127
	old_data_grads_norm = 7.1266
	sim_grads_norm_tr = -0.0019
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8501
	data_grads_norm = 5.7358
	new_data_grads_norm = 7.4360
	old_data_grads_norm = 8.3159
	sim_grads_norm_tr = 0.0005
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3086
	data_grads_norm = 4.5936
	new_data_grads_norm = 7.0929
	old_data_grads_norm = 5.4753
	sim_grads_norm_tr = -0.0164
-- Starting training on experience 218 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9441
	data_grads_norm = 5.7902
	new_data_grads_norm = 7.6219
	old_data_grads_norm = 6.9301
	sim_grads_norm_tr = 0.0562
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6090
	data_grads_norm = 5.6001
	new_data_grads_norm = 7.5901
	old_data_grads_norm = 6.5909
	sim_grads_norm_tr = 0.1491
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1053
	data_grads_norm = 4.5696
	new_data_grads_norm = 7.1369
	old_data_grads_norm = 5.9011
	sim_grads_norm_tr = -0.0433
-- Starting training on experience 219 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1096
	data_grads_norm = 4.4345
	new_data_grads_norm = 6.7930
	old_data_grads_norm = 5.9392
	sim_grads_norm_tr = 0.0018
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3504
	data_grads_norm = 4.5889
	new_data_grads_norm = 6.9619
	old_data_grads_norm = 6.1141
	sim_grads_norm_tr = -0.0398
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0775
	data_grads_norm = 4.4032
	new_data_grads_norm = 7.4282
	old_data_grads_norm = 6.7350
	sim_grads_norm_tr = 0.0528
-- Starting training on experience 220 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3387
	data_grads_norm = 4.6487
	new_data_grads_norm = 6.5141
	old_data_grads_norm = 6.7786
	sim_grads_norm_tr = 0.0063
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9056
	data_grads_norm = 4.1404
	new_data_grads_norm = 6.2195
	old_data_grads_norm = 6.0874
	sim_grads_norm_tr = -0.0050
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3427
	data_grads_norm = 5.6872
	new_data_grads_norm = 6.0635
	old_data_grads_norm = 7.2299
	sim_grads_norm_tr = 0.0858
-- Starting training on experience 221 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0252
	data_grads_norm = 4.4037
	new_data_grads_norm = 6.7830
	old_data_grads_norm = 5.3360
	sim_grads_norm_tr = 0.0791
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2078
	data_grads_norm = 4.4035
	new_data_grads_norm = 6.4920
	old_data_grads_norm = 6.8677
	sim_grads_norm_tr = -0.0874
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0623
	data_grads_norm = 4.4391
	new_data_grads_norm = 6.7676
	old_data_grads_norm = 5.7527
	sim_grads_norm_tr = 0.1007
-- Starting training on experience 222 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5845
	data_grads_norm = 4.9832
	new_data_grads_norm = 7.5949
	old_data_grads_norm = 6.6922
	sim_grads_norm_tr = 0.0465
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9843
	data_grads_norm = 4.2090
	new_data_grads_norm = 7.0675
	old_data_grads_norm = 5.4354
	sim_grads_norm_tr = -0.0721
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8918
	data_grads_norm = 5.3290
	new_data_grads_norm = 7.7029
	old_data_grads_norm = 6.9886
	sim_grads_norm_tr = 0.0405
-- Starting training on experience 223 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9224
	data_grads_norm = 4.3983
	new_data_grads_norm = 7.1378
	old_data_grads_norm = 4.7373
	sim_grads_norm_tr = -0.0205
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3970
	data_grads_norm = 5.0923
	new_data_grads_norm = 7.0094
	old_data_grads_norm = 6.3897
	sim_grads_norm_tr = 0.0781
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5866
	data_grads_norm = 4.7046
	new_data_grads_norm = 6.8273
	old_data_grads_norm = 5.8491
	sim_grads_norm_tr = 0.0409
-- Starting training on experience 224 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2024
	data_grads_norm = 4.9564
	new_data_grads_norm = 6.8763
	old_data_grads_norm = 6.5576
	sim_grads_norm_tr = -0.0096
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0638
	data_grads_norm = 4.8883
	new_data_grads_norm = 6.2448
	old_data_grads_norm = 6.2845
	sim_grads_norm_tr = 0.0319
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0694
	data_grads_norm = 4.5341
	new_data_grads_norm = 6.2500
	old_data_grads_norm = 6.0441
	sim_grads_norm_tr = 0.0093
-- Starting training on experience 225 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3469
	data_grads_norm = 5.5678
	new_data_grads_norm = 7.3948
	old_data_grads_norm = 7.9279
	sim_grads_norm_tr = -0.0326
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8722
	data_grads_norm = 5.1319
	new_data_grads_norm = 7.5149
	old_data_grads_norm = 7.2409
	sim_grads_norm_tr = -0.0063
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1971
	data_grads_norm = 4.8169
	new_data_grads_norm = 7.0348
	old_data_grads_norm = 5.4533
	sim_grads_norm_tr = 0.0652
-- Starting training on experience 226 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0114
	data_grads_norm = 4.5310
	new_data_grads_norm = 5.9859
	old_data_grads_norm = 6.0874
	sim_grads_norm_tr = 0.0557
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2957
	data_grads_norm = 5.4551
	new_data_grads_norm = 7.3464
	old_data_grads_norm = 7.6572
	sim_grads_norm_tr = 0.0537
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8370
	data_grads_norm = 4.1360
	new_data_grads_norm = 6.0151
	old_data_grads_norm = 5.6523
	sim_grads_norm_tr = 0.0064
-- Starting training on experience 227 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3770
	data_grads_norm = 4.2328
	new_data_grads_norm = 5.8181
	old_data_grads_norm = 7.0807
	sim_grads_norm_tr = -0.0170
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9145
	data_grads_norm = 4.4250
	new_data_grads_norm = 5.7549
	old_data_grads_norm = 5.8999
	sim_grads_norm_tr = 0.0649
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8262
	data_grads_norm = 4.4380
	new_data_grads_norm = 6.1066
	old_data_grads_norm = 7.1018
	sim_grads_norm_tr = 0.0743
-- Starting training on experience 228 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1542
	data_grads_norm = 5.4151
	new_data_grads_norm = 6.5023
	old_data_grads_norm = 7.8115
	sim_grads_norm_tr = -0.0579
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0386
	data_grads_norm = 5.5453
	new_data_grads_norm = 7.1530
	old_data_grads_norm = 8.4267
	sim_grads_norm_tr = -0.0371
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2404
	data_grads_norm = 5.2069
	new_data_grads_norm = 7.1766
	old_data_grads_norm = 7.9931
	sim_grads_norm_tr = 0.0274
-- Starting training on experience 229 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0235
	data_grads_norm = 4.4382
	new_data_grads_norm = 6.0044
	old_data_grads_norm = 5.8052
	sim_grads_norm_tr = 0.0239
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4210
	data_grads_norm = 4.6635
	new_data_grads_norm = 6.1622
	old_data_grads_norm = 6.8787
	sim_grads_norm_tr = -0.0543
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7436
	data_grads_norm = 4.4033
	new_data_grads_norm = 6.6558
	old_data_grads_norm = 5.6293
	sim_grads_norm_tr = -0.0278
-- Starting training on experience 230 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2627
	data_grads_norm = 5.5367
	new_data_grads_norm = 7.5346
	old_data_grads_norm = 6.1969
	sim_grads_norm_tr = 0.1309
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3620
	data_grads_norm = 5.1939
	new_data_grads_norm = 6.5923
	old_data_grads_norm = 7.9364
	sim_grads_norm_tr = -0.0456
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1515
	data_grads_norm = 5.1514
	new_data_grads_norm = 6.9630
	old_data_grads_norm = 7.1242
	sim_grads_norm_tr = -0.0099
-- Starting training on experience 231 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2267
	data_grads_norm = 5.3934
	new_data_grads_norm = 6.8428
	old_data_grads_norm = 8.1927
	sim_grads_norm_tr = 0.0648
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0929
	data_grads_norm = 4.2936
	new_data_grads_norm = 6.1532
	old_data_grads_norm = 7.1292
	sim_grads_norm_tr = 0.0048
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8132
	data_grads_norm = 4.4908
	new_data_grads_norm = 5.5677
	old_data_grads_norm = 7.0718
	sim_grads_norm_tr = -0.0022
-- Starting training on experience 232 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9008
	data_grads_norm = 4.4667
	new_data_grads_norm = 6.6902
	old_data_grads_norm = 5.5935
	sim_grads_norm_tr = -0.0534
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8011
	data_grads_norm = 4.1873
	new_data_grads_norm = 6.8328
	old_data_grads_norm = 5.0747
	sim_grads_norm_tr = 0.0144
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7841
	data_grads_norm = 4.2130
	new_data_grads_norm = 6.4038
	old_data_grads_norm = 5.5305
	sim_grads_norm_tr = -0.0515
-- Starting training on experience 233 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8654
	data_grads_norm = 4.7628
	new_data_grads_norm = 6.9681
	old_data_grads_norm = 6.9515
	sim_grads_norm_tr = 0.0008
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0420
	data_grads_norm = 4.5694
	new_data_grads_norm = 6.3397
	old_data_grads_norm = 7.0436
	sim_grads_norm_tr = -0.0188
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7753
	data_grads_norm = 4.2169
	new_data_grads_norm = 6.7998
	old_data_grads_norm = 5.2136
	sim_grads_norm_tr = -0.0119
-- Starting training on experience 234 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3548
	data_grads_norm = 4.7833
	new_data_grads_norm = 8.4175
	old_data_grads_norm = 5.9106
	sim_grads_norm_tr = 0.0154
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9575
	data_grads_norm = 4.6802
	new_data_grads_norm = 7.2256
	old_data_grads_norm = 5.6676
	sim_grads_norm_tr = -0.0009
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2217
	data_grads_norm = 5.4262
	new_data_grads_norm = 7.1635
	old_data_grads_norm = 7.7186
	sim_grads_norm_tr = 0.0101
-- Starting training on experience 235 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8987
	data_grads_norm = 5.0433
	new_data_grads_norm = 8.2307
	old_data_grads_norm = 6.4758
	sim_grads_norm_tr = -0.0035
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5234
	data_grads_norm = 4.7498
	new_data_grads_norm = 7.5116
	old_data_grads_norm = 6.1177
	sim_grads_norm_tr = -0.0353
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6248
	data_grads_norm = 4.8988
	new_data_grads_norm = 7.8558
	old_data_grads_norm = 5.8950
	sim_grads_norm_tr = 0.0433
-- Starting training on experience 236 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4488
	data_grads_norm = 4.8563
	new_data_grads_norm = 6.7648
	old_data_grads_norm = 8.4735
	sim_grads_norm_tr = 0.0029
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8359
	data_grads_norm = 5.5958
	new_data_grads_norm = 7.3165
	old_data_grads_norm = 5.5282
	sim_grads_norm_tr = 0.0730
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5878
	data_grads_norm = 4.2958
	new_data_grads_norm = 6.8200
	old_data_grads_norm = 6.2597
	sim_grads_norm_tr = 0.0105
-- Starting training on experience 237 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
-- >> End of training phase << --
-- >> Start of eval phase << --
-- Starting eval on experience 0 (Task 0) from test stream --
> Eval on experience 0 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp000 = 2.5839
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.3420
	mb_index = 2380
	time = 702.0982
-- Starting eval on experience 1 (Task 0) from test stream --
> Eval on experience 1 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp001 = 2.1027
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.5120
-- Starting eval on experience 2 (Task 0) from test stream --
> Eval on experience 2 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp002 = 3.2149
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.2420
-- Starting eval on experience 3 (Task 0) from test stream --
> Eval on experience 3 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp003 = 2.5793
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.4080
-- Starting eval on experience 4 (Task 0) from test stream --
> Eval on experience 4 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp004 = 2.9226
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.2920
-- Starting eval on experience 5 (Task 0) from test stream --
> Eval on experience 5 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp005 = 2.6778
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.3680
-- Starting eval on experience 6 (Task 0) from test stream --
> Eval on experience 6 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp006 = 2.6637
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp006 = 0.2900
-- Starting eval on experience 7 (Task 0) from test stream --
> Eval on experience 7 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp007 = 2.4904
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp007 = 0.3980
-- Starting eval on experience 8 (Task 0) from test stream --
> Eval on experience 8 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp008 = 2.7184
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp008 = 0.2620
-- Starting eval on experience 9 (Task 0) from test stream --
> Eval on experience 9 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp009 = 2.7684
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp009 = 0.2500
-- >> End of eval phase << --
	CumulativeAccuracy/eval_phase/test_stream/Exp000 = 0.7320
	CumulativeAccuracy/eval_phase/test_stream/Exp001 = 0.6750
	CumulativeAccuracy/eval_phase/test_stream/Exp002 = 0.5433
	CumulativeAccuracy/eval_phase/test_stream/Exp003 = 0.5245
	CumulativeAccuracy/eval_phase/test_stream/Exp004 = 0.4708
	CumulativeAccuracy/eval_phase/test_stream/Exp005 = 0.4273
	CumulativeAccuracy/eval_phase/test_stream/Exp006 = 0.3911
	CumulativeAccuracy/eval_phase/test_stream/Exp007 = 0.3723
	CumulativeAccuracy/eval_phase/test_stream/Exp008 = 0.3520
	CumulativeAccuracy/eval_phase/test_stream/Exp009 = 0.3364
	Loss_Stream/eval_phase/test_stream/Task000 = 2.6722
	Top1_Acc_Stream/eval_phase/test_stream/Task000 = 0.3364
-- >> Start of training phase << --
-- Starting training on experience 0 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4888
	data_grads_norm = 5.0670
	new_data_grads_norm = 6.2075
	old_data_grads_norm = 7.2129
	sim_grads_norm_tr = -0.0257
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2431
	data_grads_norm = 5.3273
	new_data_grads_norm = 6.5848
	old_data_grads_norm = 7.1385
	sim_grads_norm_tr = 0.0177
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0703
	data_grads_norm = 4.9244
	new_data_grads_norm = 6.5626
	old_data_grads_norm = 6.1792
	sim_grads_norm_tr = 0.0251
-- Starting training on experience 1 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0460
	data_grads_norm = 5.1286
	new_data_grads_norm = 6.2515
	old_data_grads_norm = 7.4757
	sim_grads_norm_tr = 0.0009
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9360
	data_grads_norm = 4.8122
	new_data_grads_norm = 6.1418
	old_data_grads_norm = 6.4832
	sim_grads_norm_tr = 0.0363
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5452
	data_grads_norm = 4.3151
	new_data_grads_norm = 6.1719
	old_data_grads_norm = 4.8029
	sim_grads_norm_tr = -0.0006
-- Starting training on experience 2 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1477
	data_grads_norm = 5.2082
	new_data_grads_norm = 6.6554
	old_data_grads_norm = 7.9516
	sim_grads_norm_tr = 0.0669
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8491
	data_grads_norm = 4.6018
	new_data_grads_norm = 7.0112
	old_data_grads_norm = 5.5882
	sim_grads_norm_tr = -0.0281
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2485
	data_grads_norm = 4.9797
	new_data_grads_norm = 7.1796
	old_data_grads_norm = 5.7483
	sim_grads_norm_tr = -0.0160
-- Starting training on experience 3 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8634
	data_grads_norm = 4.3646
	new_data_grads_norm = 6.4152
	old_data_grads_norm = 6.5564
	sim_grads_norm_tr = 0.0176
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8856
	data_grads_norm = 4.4288
	new_data_grads_norm = 6.5423
	old_data_grads_norm = 5.6166
	sim_grads_norm_tr = -0.0121
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5383
	data_grads_norm = 5.1045
	new_data_grads_norm = 6.5898
	old_data_grads_norm = 7.5233
	sim_grads_norm_tr = 0.0070
-- Starting training on experience 4 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1202
	data_grads_norm = 4.8508
	new_data_grads_norm = 6.4797
	old_data_grads_norm = 6.3940
	sim_grads_norm_tr = 0.0022
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9233
	data_grads_norm = 5.2486
	new_data_grads_norm = 6.7255
	old_data_grads_norm = 7.6336
	sim_grads_norm_tr = 0.0580
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5601
	data_grads_norm = 4.2407
	new_data_grads_norm = 6.7592
	old_data_grads_norm = 4.6884
	sim_grads_norm_tr = 0.0141
-- Starting training on experience 5 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0279
	data_grads_norm = 4.8634
	new_data_grads_norm = 7.2892
	old_data_grads_norm = 5.8728
	sim_grads_norm_tr = -0.0040
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0642
	data_grads_norm = 4.7729
	new_data_grads_norm = 7.5632
	old_data_grads_norm = 4.9206
	sim_grads_norm_tr = 0.0275
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2645
	data_grads_norm = 5.1303
	new_data_grads_norm = 7.1241
	old_data_grads_norm = 6.2396
	sim_grads_norm_tr = 0.0903
-- Starting training on experience 6 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8668
	data_grads_norm = 4.3182
	new_data_grads_norm = 6.6998
	old_data_grads_norm = 5.1028
	sim_grads_norm_tr = 0.0780
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6482
	data_grads_norm = 5.3735
	new_data_grads_norm = 6.6087
	old_data_grads_norm = 7.1762
	sim_grads_norm_tr = 0.1154
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3806
	data_grads_norm = 4.0173
	new_data_grads_norm = 7.0054
	old_data_grads_norm = 5.2398
	sim_grads_norm_tr = 0.0082
-- Starting training on experience 7 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5021
	data_grads_norm = 5.7993
	new_data_grads_norm = 6.3755
	old_data_grads_norm = 8.3674
	sim_grads_norm_tr = 0.0628
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5764
	data_grads_norm = 3.8191
	new_data_grads_norm = 6.7848
	old_data_grads_norm = 4.8267
	sim_grads_norm_tr = 0.0085
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0375
	data_grads_norm = 4.4733
	new_data_grads_norm = 6.2300
	old_data_grads_norm = 5.8417
	sim_grads_norm_tr = -0.0166
-- Starting training on experience 8 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0067
	data_grads_norm = 4.5344
	new_data_grads_norm = 5.8942
	old_data_grads_norm = 6.6590
	sim_grads_norm_tr = 0.0697
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0111
	data_grads_norm = 5.1287
	new_data_grads_norm = 6.3633
	old_data_grads_norm = 8.2446
	sim_grads_norm_tr = 0.0144
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6636
	data_grads_norm = 5.0468
	new_data_grads_norm = 6.1698
	old_data_grads_norm = 7.6621
	sim_grads_norm_tr = 0.0147
-- Starting training on experience 9 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8241
	data_grads_norm = 4.3579
	new_data_grads_norm = 6.8986
	old_data_grads_norm = 5.6821
	sim_grads_norm_tr = 0.0329
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7900
	data_grads_norm = 4.5768
	new_data_grads_norm = 6.4128
	old_data_grads_norm = 5.9552
	sim_grads_norm_tr = 0.0174
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7198
	data_grads_norm = 4.3535
	new_data_grads_norm = 6.7523
	old_data_grads_norm = 5.5950
	sim_grads_norm_tr = 0.0498
-- Starting training on experience 10 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0117
	data_grads_norm = 4.8743
	new_data_grads_norm = 6.8941
	old_data_grads_norm = 6.1178
	sim_grads_norm_tr = 0.1177
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9674
	data_grads_norm = 5.8817
	new_data_grads_norm = 6.7525
	old_data_grads_norm = 7.2002
	sim_grads_norm_tr = -0.0160
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9505
	data_grads_norm = 4.7950
	new_data_grads_norm = 6.5290
	old_data_grads_norm = 6.8814
	sim_grads_norm_tr = 0.0688
-- Starting training on experience 11 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8607
	data_grads_norm = 5.0162
	new_data_grads_norm = 6.0691
	old_data_grads_norm = 6.8440
	sim_grads_norm_tr = 0.0357
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6677
	data_grads_norm = 5.0567
	new_data_grads_norm = 6.2762
	old_data_grads_norm = 7.1550
	sim_grads_norm_tr = -0.0173
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1974
	data_grads_norm = 4.0009
	new_data_grads_norm = 6.9261
	old_data_grads_norm = 4.6159
	sim_grads_norm_tr = 0.0125
-- Starting training on experience 12 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7572
	data_grads_norm = 4.6045
	new_data_grads_norm = 6.1525
	old_data_grads_norm = 6.0382
	sim_grads_norm_tr = 0.0204
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9286
	data_grads_norm = 5.0177
	new_data_grads_norm = 6.2326
	old_data_grads_norm = 6.5995
	sim_grads_norm_tr = 0.0970
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9646
	data_grads_norm = 4.7992
	new_data_grads_norm = 6.5069
	old_data_grads_norm = 6.3838
	sim_grads_norm_tr = 0.0292
-- Starting training on experience 13 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4743
	data_grads_norm = 4.5638
	new_data_grads_norm = 6.4881
	old_data_grads_norm = 6.4030
	sim_grads_norm_tr = -0.0300
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9280
	data_grads_norm = 4.4020
	new_data_grads_norm = 6.1822
	old_data_grads_norm = 5.9042
	sim_grads_norm_tr = 0.0130
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5367
	data_grads_norm = 4.5754
	new_data_grads_norm = 6.4412
	old_data_grads_norm = 5.0512
	sim_grads_norm_tr = 0.0125
-- Starting training on experience 14 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8895
	data_grads_norm = 4.5322
	new_data_grads_norm = 7.1696
	old_data_grads_norm = 5.8407
	sim_grads_norm_tr = 0.0314
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3876
	data_grads_norm = 4.5725
	new_data_grads_norm = 7.2508
	old_data_grads_norm = 5.0522
	sim_grads_norm_tr = 0.0216
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8349
	data_grads_norm = 4.9057
	new_data_grads_norm = 7.4270
	old_data_grads_norm = 5.8161
	sim_grads_norm_tr = -0.0106
-- Starting training on experience 15 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4376
	data_grads_norm = 5.2560
	new_data_grads_norm = 7.2354
	old_data_grads_norm = 6.7373
	sim_grads_norm_tr = 0.0356
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9129
	data_grads_norm = 5.3197
	new_data_grads_norm = 6.8389
	old_data_grads_norm = 7.7163
	sim_grads_norm_tr = 0.0321
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3717
	data_grads_norm = 4.3211
	new_data_grads_norm = 6.0388
	old_data_grads_norm = 6.3392
	sim_grads_norm_tr = -0.0178
-- Starting training on experience 16 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2424
	data_grads_norm = 6.0066
	new_data_grads_norm = 5.8567
	old_data_grads_norm = 7.6962
	sim_grads_norm_tr = 0.0171
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3818
	data_grads_norm = 4.2901
	new_data_grads_norm = 5.7086
	old_data_grads_norm = 5.3356
	sim_grads_norm_tr = 0.0140
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2834
	data_grads_norm = 3.6356
	new_data_grads_norm = 5.7102
	old_data_grads_norm = 4.9417
	sim_grads_norm_tr = -0.0492
-- Starting training on experience 17 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9831
	data_grads_norm = 4.2377
	new_data_grads_norm = 6.4757
	old_data_grads_norm = 4.9356
	sim_grads_norm_tr = -0.0167
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3978
	data_grads_norm = 4.8432
	new_data_grads_norm = 6.7222
	old_data_grads_norm = 6.3150
	sim_grads_norm_tr = 0.0376
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3191
	data_grads_norm = 4.5120
	new_data_grads_norm = 6.6854
	old_data_grads_norm = 5.0782
	sim_grads_norm_tr = 0.0270
-- Starting training on experience 18 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1088
	data_grads_norm = 3.9705
	new_data_grads_norm = 6.0081
	old_data_grads_norm = 6.1863
	sim_grads_norm_tr = -0.0330
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5215
	data_grads_norm = 4.6214
	new_data_grads_norm = 6.3598
	old_data_grads_norm = 6.3559
	sim_grads_norm_tr = -0.0408
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2691
	data_grads_norm = 4.2521
	new_data_grads_norm = 6.1069
	old_data_grads_norm = 6.0605
	sim_grads_norm_tr = 0.0322
-- Starting training on experience 19 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3783
	data_grads_norm = 5.2425
	new_data_grads_norm = 7.0162
	old_data_grads_norm = 5.7275
	sim_grads_norm_tr = 0.1382
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0391
	data_grads_norm = 4.1147
	new_data_grads_norm = 6.1770
	old_data_grads_norm = 5.4472
	sim_grads_norm_tr = -0.0482
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5659
	data_grads_norm = 4.4394
	new_data_grads_norm = 6.3018
	old_data_grads_norm = 5.4523
	sim_grads_norm_tr = -0.0284
-- Starting training on experience 20 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2341
	data_grads_norm = 4.2153
	new_data_grads_norm = 6.3720
	old_data_grads_norm = 4.4193
	sim_grads_norm_tr = 0.0289
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3534
	data_grads_norm = 3.7936
	new_data_grads_norm = 6.2978
	old_data_grads_norm = 4.4015
	sim_grads_norm_tr = -0.0020
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4121
	data_grads_norm = 4.3931
	new_data_grads_norm = 6.2401
	old_data_grads_norm = 6.5672
	sim_grads_norm_tr = 0.0170
-- Starting training on experience 21 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9985
	data_grads_norm = 3.9380
	new_data_grads_norm = 5.7402
	old_data_grads_norm = 6.0450
	sim_grads_norm_tr = -0.0016
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4052
	data_grads_norm = 4.2967
	new_data_grads_norm = 5.4537
	old_data_grads_norm = 5.7966
	sim_grads_norm_tr = 0.0791
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9929
	data_grads_norm = 3.8764
	new_data_grads_norm = 5.8214
	old_data_grads_norm = 4.9429
	sim_grads_norm_tr = 0.0224
-- Starting training on experience 22 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1869
	data_grads_norm = 4.1862
	new_data_grads_norm = 6.7710
	old_data_grads_norm = 5.2975
	sim_grads_norm_tr = 0.0108
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8842
	data_grads_norm = 4.6402
	new_data_grads_norm = 6.2430
	old_data_grads_norm = 5.9976
	sim_grads_norm_tr = 0.0733
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2347
	data_grads_norm = 4.5527
	new_data_grads_norm = 6.9351
	old_data_grads_norm = 5.8702
	sim_grads_norm_tr = 0.0386
-- Starting training on experience 23 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6990
	data_grads_norm = 4.8805
	new_data_grads_norm = 6.9615
	old_data_grads_norm = 5.0209
	sim_grads_norm_tr = 0.0321
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4803
	data_grads_norm = 4.9687
	new_data_grads_norm = 7.2226
	old_data_grads_norm = 6.3479
	sim_grads_norm_tr = 0.0264
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1309
	data_grads_norm = 4.3490
	new_data_grads_norm = 6.9265
	old_data_grads_norm = 6.0403
	sim_grads_norm_tr = -0.0025
-- Starting training on experience 24 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4142
	data_grads_norm = 4.3879
	new_data_grads_norm = 6.0587
	old_data_grads_norm = 6.0701
	sim_grads_norm_tr = 0.0488
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2374
	data_grads_norm = 4.2035
	new_data_grads_norm = 6.1521
	old_data_grads_norm = 4.2246
	sim_grads_norm_tr = 0.1798
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0225
	data_grads_norm = 4.2431
	new_data_grads_norm = 6.3226
	old_data_grads_norm = 6.0731
	sim_grads_norm_tr = -0.0388
-- Starting training on experience 25 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5011
	data_grads_norm = 4.3496
	new_data_grads_norm = 6.7348
	old_data_grads_norm = 5.1480
	sim_grads_norm_tr = 0.0393
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4337
	data_grads_norm = 5.9223
	new_data_grads_norm = 6.7235
	old_data_grads_norm = 8.5135
	sim_grads_norm_tr = 0.0087
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6060
	data_grads_norm = 5.0950
	new_data_grads_norm = 6.6500
	old_data_grads_norm = 6.8708
	sim_grads_norm_tr = 0.1504
-- Starting training on experience 26 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7461
	data_grads_norm = 5.0640
	new_data_grads_norm = 6.4206
	old_data_grads_norm = 6.4698
	sim_grads_norm_tr = 0.1035
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2741
	data_grads_norm = 4.9379
	new_data_grads_norm = 6.2990
	old_data_grads_norm = 7.0618
	sim_grads_norm_tr = -0.0034
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9100
	data_grads_norm = 3.8942
	new_data_grads_norm = 6.3475
	old_data_grads_norm = 3.8617
	sim_grads_norm_tr = -0.0246
-- Starting training on experience 27 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6899
	data_grads_norm = 4.3129
	new_data_grads_norm = 5.3093
	old_data_grads_norm = 6.5148
	sim_grads_norm_tr = -0.0243
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9645
	data_grads_norm = 4.0367
	new_data_grads_norm = 5.3352
	old_data_grads_norm = 5.6061
	sim_grads_norm_tr = -0.0240
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3574
	data_grads_norm = 4.9522
	new_data_grads_norm = 5.6305
	old_data_grads_norm = 7.1603
	sim_grads_norm_tr = 0.0198
-- Starting training on experience 28 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2446
	data_grads_norm = 4.3722
	new_data_grads_norm = 7.3770
	old_data_grads_norm = 5.6822
	sim_grads_norm_tr = 0.0111
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2350
	data_grads_norm = 4.5030
	new_data_grads_norm = 6.8970
	old_data_grads_norm = 7.1149
	sim_grads_norm_tr = 0.0554
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2459
	data_grads_norm = 4.9876
	new_data_grads_norm = 7.3224
	old_data_grads_norm = 7.2066
	sim_grads_norm_tr = -0.0209
-- Starting training on experience 29 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1672
	data_grads_norm = 4.6189
	new_data_grads_norm = 6.4992
	old_data_grads_norm = 5.0355
	sim_grads_norm_tr = 0.0610
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9795
	data_grads_norm = 4.9278
	new_data_grads_norm = 6.4431
	old_data_grads_norm = 5.7445
	sim_grads_norm_tr = 0.0534
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1449
	data_grads_norm = 5.0513
	new_data_grads_norm = 6.3412
	old_data_grads_norm = 7.9117
	sim_grads_norm_tr = 0.0095
-- Starting training on experience 30 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0881
	data_grads_norm = 4.4029
	new_data_grads_norm = 5.7928
	old_data_grads_norm = 6.2945
	sim_grads_norm_tr = 0.0154
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8097
	data_grads_norm = 4.2228
	new_data_grads_norm = 6.3956
	old_data_grads_norm = 4.8415
	sim_grads_norm_tr = 0.0067
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3897
	data_grads_norm = 5.3118
	new_data_grads_norm = 6.2642
	old_data_grads_norm = 7.0987
	sim_grads_norm_tr = 0.0327
-- Starting training on experience 31 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5798
	data_grads_norm = 3.7683
	new_data_grads_norm = 5.9868
	old_data_grads_norm = 4.4940
	sim_grads_norm_tr = -0.0110
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2369
	data_grads_norm = 5.3425
	new_data_grads_norm = 5.9866
	old_data_grads_norm = 7.8079
	sim_grads_norm_tr = 0.0131
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9985
	data_grads_norm = 4.3472
	new_data_grads_norm = 6.2751
	old_data_grads_norm = 5.8774
	sim_grads_norm_tr = 0.0035
-- Starting training on experience 32 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9316
	data_grads_norm = 4.6465
	new_data_grads_norm = 6.5209
	old_data_grads_norm = 6.1862
	sim_grads_norm_tr = -0.0075
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0890
	data_grads_norm = 4.7834
	new_data_grads_norm = 6.4202
	old_data_grads_norm = 6.5800
	sim_grads_norm_tr = -0.0287
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2208
	data_grads_norm = 4.8582
	new_data_grads_norm = 6.4974
	old_data_grads_norm = 6.3292
	sim_grads_norm_tr = 0.0518
-- Starting training on experience 33 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7496
	data_grads_norm = 4.2653
	new_data_grads_norm = 6.9598
	old_data_grads_norm = 5.4366
	sim_grads_norm_tr = -0.0145
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1949
	data_grads_norm = 4.8104
	new_data_grads_norm = 6.0146
	old_data_grads_norm = 8.5184
	sim_grads_norm_tr = 0.0355
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6577
	data_grads_norm = 4.5349
	new_data_grads_norm = 6.5489
	old_data_grads_norm = 6.4189
	sim_grads_norm_tr = -0.0384
-- Starting training on experience 34 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0080
	data_grads_norm = 5.8079
	new_data_grads_norm = 6.1185
	old_data_grads_norm = 9.5172
	sim_grads_norm_tr = -0.0158
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9144
	data_grads_norm = 4.7957
	new_data_grads_norm = 6.2418
	old_data_grads_norm = 6.3915
	sim_grads_norm_tr = 0.0001
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8271
	data_grads_norm = 4.3885
	new_data_grads_norm = 6.2143
	old_data_grads_norm = 5.3628
	sim_grads_norm_tr = -0.0175
-- Starting training on experience 35 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7013
	data_grads_norm = 4.7667
	new_data_grads_norm = 5.7587
	old_data_grads_norm = 7.1733
	sim_grads_norm_tr = 0.0636
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7831
	data_grads_norm = 4.3287
	new_data_grads_norm = 6.2566
	old_data_grads_norm = 5.6288
	sim_grads_norm_tr = 0.0365
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3496
	data_grads_norm = 5.1833
	new_data_grads_norm = 5.8536
	old_data_grads_norm = 8.4305
	sim_grads_norm_tr = -0.0100
-- Starting training on experience 36 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6970
	data_grads_norm = 4.2389
	new_data_grads_norm = 6.0842
	old_data_grads_norm = 5.4066
	sim_grads_norm_tr = 0.0068
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1511
	data_grads_norm = 4.8406
	new_data_grads_norm = 6.2229
	old_data_grads_norm = 6.1156
	sim_grads_norm_tr = 0.0525
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9311
	data_grads_norm = 4.5613
	new_data_grads_norm = 5.7709
	old_data_grads_norm = 7.0377
	sim_grads_norm_tr = 0.0054
-- Starting training on experience 37 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7735
	data_grads_norm = 4.9253
	new_data_grads_norm = 5.6469
	old_data_grads_norm = 6.9860
	sim_grads_norm_tr = -0.0376
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9776
	data_grads_norm = 4.0799
	new_data_grads_norm = 5.8324
	old_data_grads_norm = 5.4080
	sim_grads_norm_tr = 0.0143
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2479
	data_grads_norm = 4.5919
	new_data_grads_norm = 6.1444
	old_data_grads_norm = 5.3176
	sim_grads_norm_tr = 0.0621
-- Starting training on experience 38 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4798
	data_grads_norm = 5.3730
	new_data_grads_norm = 6.9745
	old_data_grads_norm = 6.4221
	sim_grads_norm_tr = 0.2254
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3377
	data_grads_norm = 5.2856
	new_data_grads_norm = 6.2708
	old_data_grads_norm = 7.4504
	sim_grads_norm_tr = 0.0616
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5070
	data_grads_norm = 3.9733
	new_data_grads_norm = 6.2317
	old_data_grads_norm = 4.7106
	sim_grads_norm_tr = 0.0280
-- Starting training on experience 39 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7209
	data_grads_norm = 4.4719
	new_data_grads_norm = 5.3848
	old_data_grads_norm = 6.5244
	sim_grads_norm_tr = -0.0370
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7838
	data_grads_norm = 5.3479
	new_data_grads_norm = 5.4146
	old_data_grads_norm = 7.4790
	sim_grads_norm_tr = 0.0034
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1286
	data_grads_norm = 4.1580
	new_data_grads_norm = 6.1320
	old_data_grads_norm = 5.5635
	sim_grads_norm_tr = -0.0217
-- Starting training on experience 40 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0918
	data_grads_norm = 4.9322
	new_data_grads_norm = 5.9581
	old_data_grads_norm = 7.9984
	sim_grads_norm_tr = -0.0628
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5826
	data_grads_norm = 4.3274
	new_data_grads_norm = 5.5827
	old_data_grads_norm = 6.8621
	sim_grads_norm_tr = -0.0010
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6242
	data_grads_norm = 4.1852
	new_data_grads_norm = 6.0745
	old_data_grads_norm = 5.3651
	sim_grads_norm_tr = 0.0445
-- Starting training on experience 41 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6005
	data_grads_norm = 4.2741
	new_data_grads_norm = 7.0772
	old_data_grads_norm = 4.4798
	sim_grads_norm_tr = -0.0228
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7916
	data_grads_norm = 5.7587
	new_data_grads_norm = 6.8962
	old_data_grads_norm = 8.7836
	sim_grads_norm_tr = -0.0034
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0272
	data_grads_norm = 5.0181
	new_data_grads_norm = 6.8250
	old_data_grads_norm = 6.1255
	sim_grads_norm_tr = -0.0124
-- Starting training on experience 42 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1942
	data_grads_norm = 4.8013
	new_data_grads_norm = 6.7729
	old_data_grads_norm = 6.2032
	sim_grads_norm_tr = 0.0220
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8060
	data_grads_norm = 4.7357
	new_data_grads_norm = 6.6517
	old_data_grads_norm = 6.5083
	sim_grads_norm_tr = 0.0357
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4370
	data_grads_norm = 3.8253
	new_data_grads_norm = 5.8217
	old_data_grads_norm = 4.4518
	sim_grads_norm_tr = -0.0306
-- Starting training on experience 43 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7832
	data_grads_norm = 4.3182
	new_data_grads_norm = 5.8576
	old_data_grads_norm = 5.6787
	sim_grads_norm_tr = 0.0547
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0907
	data_grads_norm = 3.4597
	new_data_grads_norm = 5.2250
	old_data_grads_norm = 5.4404
	sim_grads_norm_tr = 0.0116
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2894
	data_grads_norm = 4.1072
	new_data_grads_norm = 5.9732
	old_data_grads_norm = 5.0515
	sim_grads_norm_tr = 0.0789
-- Starting training on experience 44 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9241
	data_grads_norm = 4.5505
	new_data_grads_norm = 6.3354
	old_data_grads_norm = 6.2084
	sim_grads_norm_tr = 0.0148
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9677
	data_grads_norm = 5.0214
	new_data_grads_norm = 6.2014
	old_data_grads_norm = 8.0718
	sim_grads_norm_tr = 0.0269
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0593
	data_grads_norm = 4.8911
	new_data_grads_norm = 6.2701
	old_data_grads_norm = 7.0511
	sim_grads_norm_tr = -0.0081
-- Starting training on experience 45 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4470
	data_grads_norm = 3.8406
	new_data_grads_norm = 5.8176
	old_data_grads_norm = 5.3326
	sim_grads_norm_tr = -0.0508
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8498
	data_grads_norm = 4.6502
	new_data_grads_norm = 6.0079
	old_data_grads_norm = 6.4416
	sim_grads_norm_tr = -0.0216
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7978
	data_grads_norm = 4.3305
	new_data_grads_norm = 6.4436
	old_data_grads_norm = 5.9403
	sim_grads_norm_tr = 0.0335
-- Starting training on experience 46 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7577
	data_grads_norm = 4.5984
	new_data_grads_norm = 6.8504
	old_data_grads_norm = 6.1180
	sim_grads_norm_tr = 0.0436
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4310
	data_grads_norm = 4.7016
	new_data_grads_norm = 6.5615
	old_data_grads_norm = 5.5323
	sim_grads_norm_tr = 0.0135
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5087
	data_grads_norm = 4.1514
	new_data_grads_norm = 6.4590
	old_data_grads_norm = 5.2843
	sim_grads_norm_tr = -0.0384
-- Starting training on experience 47 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3427
	data_grads_norm = 4.1309
	new_data_grads_norm = 5.8224
	old_data_grads_norm = 6.7195
	sim_grads_norm_tr = 0.0111
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4143
	data_grads_norm = 4.7096
	new_data_grads_norm = 6.1846
	old_data_grads_norm = 7.2977
	sim_grads_norm_tr = -0.0223
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6003
	data_grads_norm = 4.0186
	new_data_grads_norm = 6.1017
	old_data_grads_norm = 5.9153
	sim_grads_norm_tr = -0.0082
-- Starting training on experience 48 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0340
	data_grads_norm = 4.8672
	new_data_grads_norm = 5.8350
	old_data_grads_norm = 6.9160
	sim_grads_norm_tr = 0.0027
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8034
	data_grads_norm = 4.4184
	new_data_grads_norm = 6.3862
	old_data_grads_norm = 6.3069
	sim_grads_norm_tr = 0.0808
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8211
	data_grads_norm = 4.7640
	new_data_grads_norm = 5.8230
	old_data_grads_norm = 6.0128
	sim_grads_norm_tr = 0.1204
-- Starting training on experience 49 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4379
	data_grads_norm = 4.3228
	new_data_grads_norm = 7.2225
	old_data_grads_norm = 5.3319
	sim_grads_norm_tr = -0.0433
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5932
	data_grads_norm = 4.5173
	new_data_grads_norm = 7.0810
	old_data_grads_norm = 6.1907
	sim_grads_norm_tr = 0.0348
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5744
	data_grads_norm = 4.1589
	new_data_grads_norm = 6.4211
	old_data_grads_norm = 5.1992
	sim_grads_norm_tr = 0.1814
-- Starting training on experience 50 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6832
	data_grads_norm = 5.2896
	new_data_grads_norm = 7.5652
	old_data_grads_norm = 7.3971
	sim_grads_norm_tr = -0.0835
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6123
	data_grads_norm = 5.0821
	new_data_grads_norm = 7.2121
	old_data_grads_norm = 6.6527
	sim_grads_norm_tr = -0.0014
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8676
	data_grads_norm = 5.5386
	new_data_grads_norm = 7.2507
	old_data_grads_norm = 7.1540
	sim_grads_norm_tr = 0.0237
-- Starting training on experience 51 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7195
	data_grads_norm = 4.1336
	new_data_grads_norm = 5.7689
	old_data_grads_norm = 6.1981
	sim_grads_norm_tr = 0.0477
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2315
	data_grads_norm = 4.3501
	new_data_grads_norm = 4.8033
	old_data_grads_norm = 7.7108
	sim_grads_norm_tr = 0.0489
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0625
	data_grads_norm = 3.5897
	new_data_grads_norm = 5.2881
	old_data_grads_norm = 4.8341
	sim_grads_norm_tr = -0.0346
-- Starting training on experience 52 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2897
	data_grads_norm = 3.7144
	new_data_grads_norm = 6.0530
	old_data_grads_norm = 4.9111
	sim_grads_norm_tr = 0.0113
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5462
	data_grads_norm = 4.7776
	new_data_grads_norm = 6.0513
	old_data_grads_norm = 7.6684
	sim_grads_norm_tr = 0.0387
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3974
	data_grads_norm = 4.5576
	new_data_grads_norm = 5.6735
	old_data_grads_norm = 6.5452
	sim_grads_norm_tr = -0.0278
-- Starting training on experience 53 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8510
	data_grads_norm = 5.6202
	new_data_grads_norm = 6.1636
	old_data_grads_norm = 7.1666
	sim_grads_norm_tr = 0.0544
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6044
	data_grads_norm = 4.5494
	new_data_grads_norm = 6.7163
	old_data_grads_norm = 5.4808
	sim_grads_norm_tr = -0.0197
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1983
	data_grads_norm = 3.6863
	new_data_grads_norm = 6.4955
	old_data_grads_norm = 4.2366
	sim_grads_norm_tr = 0.0097
-- Starting training on experience 54 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5888
	data_grads_norm = 4.5043
	new_data_grads_norm = 6.8646
	old_data_grads_norm = 6.6191
	sim_grads_norm_tr = 0.0392
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6199
	data_grads_norm = 4.5449
	new_data_grads_norm = 6.3131
	old_data_grads_norm = 6.4209
	sim_grads_norm_tr = 0.0230
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0431
	data_grads_norm = 4.8123
	new_data_grads_norm = 4.9954
	old_data_grads_norm = 6.9424
	sim_grads_norm_tr = 0.0939
-- Starting training on experience 55 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8001
	data_grads_norm = 5.1473
	new_data_grads_norm = 5.6148
	old_data_grads_norm = 6.4964
	sim_grads_norm_tr = 0.0582
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6889
	data_grads_norm = 4.5658
	new_data_grads_norm = 6.8191
	old_data_grads_norm = 6.0412
	sim_grads_norm_tr = -0.0249
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9018
	data_grads_norm = 4.5265
	new_data_grads_norm = 6.2944
	old_data_grads_norm = 5.8388
	sim_grads_norm_tr = -0.0121
-- Starting training on experience 56 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7113
	data_grads_norm = 4.3091
	new_data_grads_norm = 6.9108
	old_data_grads_norm = 6.6643
	sim_grads_norm_tr = 0.0445
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9622
	data_grads_norm = 4.6055
	new_data_grads_norm = 6.3801
	old_data_grads_norm = 7.4334
	sim_grads_norm_tr = -0.0076
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2409
	data_grads_norm = 3.9967
	new_data_grads_norm = 7.9436
	old_data_grads_norm = 4.5142
	sim_grads_norm_tr = -0.1220
-- Starting training on experience 57 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3599
	data_grads_norm = 4.4319
	new_data_grads_norm = 6.6073
	old_data_grads_norm = 5.9640
	sim_grads_norm_tr = -0.0444
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9026
	data_grads_norm = 4.5244
	new_data_grads_norm = 6.6701
	old_data_grads_norm = 6.7481
	sim_grads_norm_tr = 0.0130
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3687
	data_grads_norm = 4.1805
	new_data_grads_norm = 6.0779
	old_data_grads_norm = 5.5661
	sim_grads_norm_tr = 0.0483
-- Starting training on experience 58 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8227
	data_grads_norm = 5.4669
	new_data_grads_norm = 6.9372
	old_data_grads_norm = 5.4108
	sim_grads_norm_tr = 0.0712
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2296
	data_grads_norm = 5.6152
	new_data_grads_norm = 7.4529
	old_data_grads_norm = 5.8592
	sim_grads_norm_tr = 0.0186
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5798
	data_grads_norm = 4.9555
	new_data_grads_norm = 7.0982
	old_data_grads_norm = 6.5717
	sim_grads_norm_tr = -0.0387
-- Starting training on experience 59 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6449
	data_grads_norm = 4.5633
	new_data_grads_norm = 5.7822
	old_data_grads_norm = 6.5907
	sim_grads_norm_tr = -0.0497
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8613
	data_grads_norm = 5.1159
	new_data_grads_norm = 6.1870
	old_data_grads_norm = 7.1665
	sim_grads_norm_tr = 0.1086
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0903
	data_grads_norm = 3.9507
	new_data_grads_norm = 5.6285
	old_data_grads_norm = 5.2674
	sim_grads_norm_tr = -0.0400
-- Starting training on experience 60 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9083
	data_grads_norm = 5.0422
	new_data_grads_norm = 6.7678
	old_data_grads_norm = 6.8906
	sim_grads_norm_tr = -0.0273
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5702
	data_grads_norm = 4.2728
	new_data_grads_norm = 6.4540
	old_data_grads_norm = 4.7106
	sim_grads_norm_tr = 0.0829
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7212
	data_grads_norm = 4.6872
	new_data_grads_norm = 6.6190
	old_data_grads_norm = 6.0492
	sim_grads_norm_tr = 0.0417
-- Starting training on experience 61 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5212
	data_grads_norm = 4.3409
	new_data_grads_norm = 5.7312
	old_data_grads_norm = 5.6378
	sim_grads_norm_tr = -0.0373
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7198
	data_grads_norm = 5.1652
	new_data_grads_norm = 5.7397
	old_data_grads_norm = 8.8334
	sim_grads_norm_tr = 0.0051
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5443
	data_grads_norm = 4.6087
	new_data_grads_norm = 6.5762
	old_data_grads_norm = 5.1378
	sim_grads_norm_tr = 0.0698
-- Starting training on experience 62 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4942
	data_grads_norm = 4.3052
	new_data_grads_norm = 6.8049
	old_data_grads_norm = 5.6707
	sim_grads_norm_tr = 0.0012
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5963
	data_grads_norm = 4.4311
	new_data_grads_norm = 6.4762
	old_data_grads_norm = 7.0200
	sim_grads_norm_tr = 0.0390
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4108
	data_grads_norm = 4.4531
	new_data_grads_norm = 6.0278
	old_data_grads_norm = 5.9791
	sim_grads_norm_tr = 0.0256
-- Starting training on experience 63 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6129
	data_grads_norm = 3.9432
	new_data_grads_norm = 6.0026
	old_data_grads_norm = 4.8719
	sim_grads_norm_tr = -0.0352
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8997
	data_grads_norm = 4.4629
	new_data_grads_norm = 6.2112
	old_data_grads_norm = 6.8339
	sim_grads_norm_tr = 0.1162
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7067
	data_grads_norm = 4.6567
	new_data_grads_norm = 6.5061
	old_data_grads_norm = 6.7574
	sim_grads_norm_tr = -0.0376
-- Starting training on experience 64 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1519
	data_grads_norm = 3.8292
	new_data_grads_norm = 5.7522
	old_data_grads_norm = 4.8761
	sim_grads_norm_tr = 0.0559
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7810
	data_grads_norm = 3.6434
	new_data_grads_norm = 5.7369
	old_data_grads_norm = 6.4056
	sim_grads_norm_tr = -0.0570
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1228
	data_grads_norm = 4.3912
	new_data_grads_norm = 6.1619
	old_data_grads_norm = 6.1566
	sim_grads_norm_tr = -0.0047
-- Starting training on experience 65 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3601
	data_grads_norm = 4.2819
	new_data_grads_norm = 5.5715
	old_data_grads_norm = 5.8960
	sim_grads_norm_tr = -0.0586
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3097
	data_grads_norm = 4.3602
	new_data_grads_norm = 6.4475
	old_data_grads_norm = 7.3498
	sim_grads_norm_tr = -0.0011
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3489
	data_grads_norm = 4.8792
	new_data_grads_norm = 6.3572
	old_data_grads_norm = 7.2503
	sim_grads_norm_tr = 0.0663
-- Starting training on experience 66 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6603
	data_grads_norm = 4.9837
	new_data_grads_norm = 7.1421
	old_data_grads_norm = 6.2617
	sim_grads_norm_tr = 0.0127
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8099
	data_grads_norm = 5.0960
	new_data_grads_norm = 7.0192
	old_data_grads_norm = 7.9595
	sim_grads_norm_tr = 0.0440
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4690
	data_grads_norm = 4.7270
	new_data_grads_norm = 6.8589
	old_data_grads_norm = 6.7396
	sim_grads_norm_tr = 0.0106
-- Starting training on experience 67 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0076
	data_grads_norm = 4.6662
	new_data_grads_norm = 6.3000
	old_data_grads_norm = 5.7536
	sim_grads_norm_tr = 0.0104
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5548
	data_grads_norm = 4.8215
	new_data_grads_norm = 6.7283
	old_data_grads_norm = 6.7222
	sim_grads_norm_tr = -0.0161
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5361
	data_grads_norm = 5.0970
	new_data_grads_norm = 6.6995
	old_data_grads_norm = 6.8226
	sim_grads_norm_tr = 0.0187
-- Starting training on experience 68 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2424
	data_grads_norm = 3.9197
	new_data_grads_norm = 5.8031
	old_data_grads_norm = 5.9994
	sim_grads_norm_tr = -0.0410
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4094
	data_grads_norm = 4.2559
	new_data_grads_norm = 6.1163
	old_data_grads_norm = 6.4831
	sim_grads_norm_tr = -0.0183
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3148
	data_grads_norm = 4.0274
	new_data_grads_norm = 6.1242
	old_data_grads_norm = 5.8972
	sim_grads_norm_tr = -0.0048
-- Starting training on experience 69 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7417
	data_grads_norm = 5.3696
	new_data_grads_norm = 6.1855
	old_data_grads_norm = 7.6517
	sim_grads_norm_tr = -0.0486
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4196
	data_grads_norm = 4.3847
	new_data_grads_norm = 6.6156
	old_data_grads_norm = 6.0242
	sim_grads_norm_tr = -0.0403
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0034
	data_grads_norm = 5.5223
	new_data_grads_norm = 7.3902
	old_data_grads_norm = 8.1283
	sim_grads_norm_tr = 0.0511
-- Starting training on experience 70 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3309
	data_grads_norm = 4.6240
	new_data_grads_norm = 7.1811
	old_data_grads_norm = 5.2493
	sim_grads_norm_tr = 0.0072
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4344
	data_grads_norm = 4.5801
	new_data_grads_norm = 7.3679
	old_data_grads_norm = 4.9324
	sim_grads_norm_tr = -0.0143
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6738
	data_grads_norm = 4.9298
	new_data_grads_norm = 7.2860
	old_data_grads_norm = 6.5198
	sim_grads_norm_tr = 0.0311
-- Starting training on experience 71 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5386
	data_grads_norm = 4.6271
	new_data_grads_norm = 5.4659
	old_data_grads_norm = 7.2235
	sim_grads_norm_tr = 0.0250
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6942
	data_grads_norm = 4.5291
	new_data_grads_norm = 6.5720
	old_data_grads_norm = 5.6330
	sim_grads_norm_tr = -0.0144
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7662
	data_grads_norm = 4.4638
	new_data_grads_norm = 5.9545
	old_data_grads_norm = 6.2999
	sim_grads_norm_tr = 0.0010
-- Starting training on experience 72 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4055
	data_grads_norm = 4.6188
	new_data_grads_norm = 7.3145
	old_data_grads_norm = 5.9362
	sim_grads_norm_tr = -0.0365
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5281
	data_grads_norm = 4.7750
	new_data_grads_norm = 6.9341
	old_data_grads_norm = 6.2469
	sim_grads_norm_tr = 0.0430
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9199
	data_grads_norm = 5.3181
	new_data_grads_norm = 8.4089
	old_data_grads_norm = 6.4876
	sim_grads_norm_tr = 0.0084
-- Starting training on experience 73 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8929
	data_grads_norm = 4.7623
	new_data_grads_norm = 7.0458
	old_data_grads_norm = 5.6450
	sim_grads_norm_tr = -0.0075
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9149
	data_grads_norm = 4.5669
	new_data_grads_norm = 6.7008
	old_data_grads_norm = 6.7040
	sim_grads_norm_tr = -0.0006
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9517
	data_grads_norm = 4.9105
	new_data_grads_norm = 6.9245
	old_data_grads_norm = 6.7322
	sim_grads_norm_tr = 0.0493
-- Starting training on experience 74 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4267
	data_grads_norm = 5.2726
	new_data_grads_norm = 7.4349
	old_data_grads_norm = 7.2358
	sim_grads_norm_tr = 0.0587
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7409
	data_grads_norm = 5.0340
	new_data_grads_norm = 7.2904
	old_data_grads_norm = 7.3778
	sim_grads_norm_tr = 0.0482
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9000
	data_grads_norm = 5.1073
	new_data_grads_norm = 6.7605
	old_data_grads_norm = 6.7983
	sim_grads_norm_tr = -0.0175
-- Starting training on experience 75 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8964
	data_grads_norm = 4.7402
	new_data_grads_norm = 6.6534
	old_data_grads_norm = 5.2286
	sim_grads_norm_tr = 0.0660
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5873
	data_grads_norm = 5.7355
	new_data_grads_norm = 7.0166
	old_data_grads_norm = 8.3741
	sim_grads_norm_tr = -0.0240
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3354
	data_grads_norm = 3.9673
	new_data_grads_norm = 6.4847
	old_data_grads_norm = 5.3955
	sim_grads_norm_tr = -0.0352
-- Starting training on experience 76 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7829
	data_grads_norm = 5.5981
	new_data_grads_norm = 7.9727
	old_data_grads_norm = 8.3410
	sim_grads_norm_tr = 0.0040
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5970
	data_grads_norm = 4.8090
	new_data_grads_norm = 6.7715
	old_data_grads_norm = 6.8655
	sim_grads_norm_tr = 0.0778
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5556
	data_grads_norm = 4.5672
	new_data_grads_norm = 7.6152
	old_data_grads_norm = 6.1093
	sim_grads_norm_tr = -0.0116
-- Starting training on experience 77 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4158
	data_grads_norm = 4.2455
	new_data_grads_norm = 6.4698
	old_data_grads_norm = 6.3236
	sim_grads_norm_tr = -0.0439
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6420
	data_grads_norm = 4.3663
	new_data_grads_norm = 6.6012
	old_data_grads_norm = 6.0360
	sim_grads_norm_tr = 0.0094
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9185
	data_grads_norm = 5.2012
	new_data_grads_norm = 5.9235
	old_data_grads_norm = 8.2563
	sim_grads_norm_tr = 0.0258
-- Starting training on experience 78 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8236
	data_grads_norm = 5.2587
	new_data_grads_norm = 6.5607
	old_data_grads_norm = 8.6398
	sim_grads_norm_tr = -0.0006
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2779
	data_grads_norm = 3.8310
	new_data_grads_norm = 5.7190
	old_data_grads_norm = 4.9636
	sim_grads_norm_tr = -0.0449
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1596
	data_grads_norm = 3.9482
	new_data_grads_norm = 5.8265
	old_data_grads_norm = 6.1410
	sim_grads_norm_tr = -0.0021
-- Starting training on experience 79 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3193
	data_grads_norm = 4.6582
	new_data_grads_norm = 7.0937
	old_data_grads_norm = 6.5299
	sim_grads_norm_tr = -0.0187
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9417
	data_grads_norm = 4.8107
	new_data_grads_norm = 6.6656
	old_data_grads_norm = 5.6055
	sim_grads_norm_tr = 0.0761
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4474
	data_grads_norm = 4.2248
	new_data_grads_norm = 6.2332
	old_data_grads_norm = 4.2883
	sim_grads_norm_tr = 0.0987
-- Starting training on experience 80 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0433
	data_grads_norm = 5.3111
	new_data_grads_norm = 7.9401
	old_data_grads_norm = 6.2234
	sim_grads_norm_tr = 0.0481
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5481
	data_grads_norm = 4.7315
	new_data_grads_norm = 7.2728
	old_data_grads_norm = 5.5260
	sim_grads_norm_tr = -0.0033
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5545
	data_grads_norm = 4.8640
	new_data_grads_norm = 7.6464
	old_data_grads_norm = 5.6016
	sim_grads_norm_tr = -0.0135
-- Starting training on experience 81 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1050
	data_grads_norm = 3.7524
	new_data_grads_norm = 6.4190
	old_data_grads_norm = 4.8713
	sim_grads_norm_tr = 0.0046
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7386
	data_grads_norm = 4.7487
	new_data_grads_norm = 6.1103
	old_data_grads_norm = 6.9066
	sim_grads_norm_tr = -0.0187
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4420
	data_grads_norm = 4.4306
	new_data_grads_norm = 6.2856
	old_data_grads_norm = 5.7756
	sim_grads_norm_tr = 0.0256
-- Starting training on experience 82 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1044
	data_grads_norm = 3.6599
	new_data_grads_norm = 6.3580
	old_data_grads_norm = 4.6208
	sim_grads_norm_tr = 0.0189
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2316
	data_grads_norm = 4.1605
	new_data_grads_norm = 6.8872
	old_data_grads_norm = 5.0449
	sim_grads_norm_tr = 0.0741
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5008
	data_grads_norm = 4.4713
	new_data_grads_norm = 6.5841
	old_data_grads_norm = 7.3601
	sim_grads_norm_tr = -0.0382
-- Starting training on experience 83 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8536
	data_grads_norm = 3.5168
	new_data_grads_norm = 6.5338
	old_data_grads_norm = 3.2558
	sim_grads_norm_tr = -0.0065
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0395
	data_grads_norm = 3.8611
	new_data_grads_norm = 6.2142
	old_data_grads_norm = 4.4702
	sim_grads_norm_tr = -0.0290
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4361
	data_grads_norm = 4.6206
	new_data_grads_norm = 6.7967
	old_data_grads_norm = 6.7401
	sim_grads_norm_tr = -0.0165
-- Starting training on experience 84 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2246
	data_grads_norm = 5.1841
	new_data_grads_norm = 6.5197
	old_data_grads_norm = 7.0168
	sim_grads_norm_tr = 0.0212
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8208
	data_grads_norm = 5.4812
	new_data_grads_norm = 6.3542
	old_data_grads_norm = 8.2584
	sim_grads_norm_tr = 0.1398
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9343
	data_grads_norm = 4.7806
	new_data_grads_norm = 6.5069
	old_data_grads_norm = 6.8050
	sim_grads_norm_tr = 0.0172
-- Starting training on experience 85 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4486
	data_grads_norm = 4.2296
	new_data_grads_norm = 6.5258
	old_data_grads_norm = 6.4484
	sim_grads_norm_tr = 0.0015
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9480
	data_grads_norm = 5.3109
	new_data_grads_norm = 6.5137
	old_data_grads_norm = 7.5183
	sim_grads_norm_tr = -0.0044
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7576
	data_grads_norm = 4.4597
	new_data_grads_norm = 6.1818
	old_data_grads_norm = 7.3356
	sim_grads_norm_tr = -0.0026
-- Starting training on experience 86 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1884
	data_grads_norm = 5.4675
	new_data_grads_norm = 7.2941
	old_data_grads_norm = 6.9420
	sim_grads_norm_tr = 0.0390
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8954
	data_grads_norm = 4.5385
	new_data_grads_norm = 6.9084
	old_data_grads_norm = 4.6512
	sim_grads_norm_tr = 0.0745
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2348
	data_grads_norm = 4.6621
	new_data_grads_norm = 7.0473
	old_data_grads_norm = 6.0650
	sim_grads_norm_tr = -0.0534
-- Starting training on experience 87 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3921
	data_grads_norm = 4.8192
	new_data_grads_norm = 6.5065
	old_data_grads_norm = 6.7158
	sim_grads_norm_tr = -0.0305
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4368
	data_grads_norm = 4.1466
	new_data_grads_norm = 6.3009
	old_data_grads_norm = 5.3518
	sim_grads_norm_tr = 0.0970
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2848
	data_grads_norm = 3.8890
	new_data_grads_norm = 5.9211
	old_data_grads_norm = 5.1388
	sim_grads_norm_tr = -0.0027
-- Starting training on experience 88 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0040
	data_grads_norm = 4.3063
	new_data_grads_norm = 6.4252
	old_data_grads_norm = 6.5819
	sim_grads_norm_tr = -0.0523
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7272
	data_grads_norm = 5.1323
	new_data_grads_norm = 6.1093
	old_data_grads_norm = 7.6485
	sim_grads_norm_tr = 0.0493
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8062
	data_grads_norm = 4.7658
	new_data_grads_norm = 6.2642
	old_data_grads_norm = 7.3786
	sim_grads_norm_tr = -0.0072
-- Starting training on experience 89 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5295
	data_grads_norm = 5.0388
	new_data_grads_norm = 7.0563
	old_data_grads_norm = 6.2730
	sim_grads_norm_tr = 0.0646
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1010
	data_grads_norm = 5.1170
	new_data_grads_norm = 6.8323
	old_data_grads_norm = 7.9508
	sim_grads_norm_tr = 0.0290
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4950
	data_grads_norm = 4.4344
	new_data_grads_norm = 6.7244
	old_data_grads_norm = 5.5567
	sim_grads_norm_tr = 0.0117
-- Starting training on experience 90 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7641
	data_grads_norm = 5.8234
	new_data_grads_norm = 7.4689
	old_data_grads_norm = 7.2792
	sim_grads_norm_tr = 0.0459
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1019
	data_grads_norm = 4.1929
	new_data_grads_norm = 7.7532
	old_data_grads_norm = 4.1065
	sim_grads_norm_tr = -0.0154
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4600
	data_grads_norm = 5.4795
	new_data_grads_norm = 7.9212
	old_data_grads_norm = 7.0518
	sim_grads_norm_tr = 0.0090
-- Starting training on experience 91 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4901
	data_grads_norm = 4.5374
	new_data_grads_norm = 6.6184
	old_data_grads_norm = 5.8492
	sim_grads_norm_tr = 0.0552
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2064
	data_grads_norm = 4.8709
	new_data_grads_norm = 6.0042
	old_data_grads_norm = 8.0580
	sim_grads_norm_tr = 0.0294
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4951
	data_grads_norm = 4.5222
	new_data_grads_norm = 6.2154
	old_data_grads_norm = 6.4201
	sim_grads_norm_tr = -0.0611
-- Starting training on experience 92 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4907
	data_grads_norm = 4.4150
	new_data_grads_norm = 6.5204
	old_data_grads_norm = 6.1191
	sim_grads_norm_tr = 0.0063
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2577
	data_grads_norm = 4.0978
	new_data_grads_norm = 6.8180
	old_data_grads_norm = 4.5272
	sim_grads_norm_tr = -0.0137
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8422
	data_grads_norm = 4.9687
	new_data_grads_norm = 6.4140
	old_data_grads_norm = 7.9146
	sim_grads_norm_tr = -0.0075
-- Starting training on experience 93 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8166
	data_grads_norm = 4.9052
	new_data_grads_norm = 7.6245
	old_data_grads_norm = 5.4083
	sim_grads_norm_tr = 0.0302
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6680
	data_grads_norm = 4.4946
	new_data_grads_norm = 6.7325
	old_data_grads_norm = 5.9553
	sim_grads_norm_tr = 0.0602
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5968
	data_grads_norm = 4.7853
	new_data_grads_norm = 6.8832
	old_data_grads_norm = 5.1330
	sim_grads_norm_tr = -0.0176
-- Starting training on experience 94 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5524
	data_grads_norm = 4.3615
	new_data_grads_norm = 6.3527
	old_data_grads_norm = 5.9850
	sim_grads_norm_tr = -0.0445
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7417
	data_grads_norm = 5.3057
	new_data_grads_norm = 6.6265
	old_data_grads_norm = 7.7223
	sim_grads_norm_tr = 0.0243
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7583
	data_grads_norm = 4.9774
	new_data_grads_norm = 6.9876
	old_data_grads_norm = 7.1421
	sim_grads_norm_tr = 0.0695
-- Starting training on experience 95 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0373
	data_grads_norm = 5.1911
	new_data_grads_norm = 6.4823
	old_data_grads_norm = 6.5090
	sim_grads_norm_tr = 0.0251
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6230
	data_grads_norm = 3.9933
	new_data_grads_norm = 5.4676
	old_data_grads_norm = 5.9772
	sim_grads_norm_tr = -0.0140
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7776
	data_grads_norm = 3.9046
	new_data_grads_norm = 6.2799
	old_data_grads_norm = 5.6026
	sim_grads_norm_tr = -0.0175
-- Starting training on experience 96 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2428
	data_grads_norm = 3.7164
	new_data_grads_norm = 6.7140
	old_data_grads_norm = 4.7517
	sim_grads_norm_tr = -0.0650
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2304
	data_grads_norm = 5.3221
	new_data_grads_norm = 7.7022
	old_data_grads_norm = 7.1774
	sim_grads_norm_tr = 0.1435
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2702
	data_grads_norm = 4.0141
	new_data_grads_norm = 6.4032
	old_data_grads_norm = 4.9836
	sim_grads_norm_tr = -0.0327
-- Starting training on experience 97 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3365
	data_grads_norm = 4.9042
	new_data_grads_norm = 6.4503
	old_data_grads_norm = 7.3623
	sim_grads_norm_tr = -0.0117
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4826
	data_grads_norm = 4.6772
	new_data_grads_norm = 6.1011
	old_data_grads_norm = 6.3538
	sim_grads_norm_tr = 0.0889
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1991
	data_grads_norm = 4.3899
	new_data_grads_norm = 6.5542
	old_data_grads_norm = 4.8711
	sim_grads_norm_tr = 0.0768
-- Starting training on experience 98 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7376
	data_grads_norm = 4.8700
	new_data_grads_norm = 5.7886
	old_data_grads_norm = 7.7963
	sim_grads_norm_tr = -0.0494
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1968
	data_grads_norm = 3.6333
	new_data_grads_norm = 5.7043
	old_data_grads_norm = 4.8807
	sim_grads_norm_tr = -0.0134
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8592
	data_grads_norm = 4.6444
	new_data_grads_norm = 6.0425
	old_data_grads_norm = 6.5730
	sim_grads_norm_tr = 0.0711
-- Starting training on experience 99 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2106
	data_grads_norm = 4.1365
	new_data_grads_norm = 7.0439
	old_data_grads_norm = 5.4358
	sim_grads_norm_tr = 0.0176
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0095
	data_grads_norm = 4.8480
	new_data_grads_norm = 6.9226
	old_data_grads_norm = 7.1585
	sim_grads_norm_tr = 0.0905
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4650
	data_grads_norm = 4.2671
	new_data_grads_norm = 7.1427
	old_data_grads_norm = 5.3382
	sim_grads_norm_tr = -0.0408
-- Starting training on experience 100 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6413
	data_grads_norm = 4.9829
	new_data_grads_norm = 6.3922
	old_data_grads_norm = 6.9850
	sim_grads_norm_tr = 0.0221
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9633
	data_grads_norm = 4.1025
	new_data_grads_norm = 5.7482
	old_data_grads_norm = 6.3897
	sim_grads_norm_tr = 0.0060
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6758
	data_grads_norm = 4.6897
	new_data_grads_norm = 7.4969
	old_data_grads_norm = 6.4659
	sim_grads_norm_tr = -0.0191
-- Starting training on experience 101 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4875
	data_grads_norm = 4.5263
	new_data_grads_norm = 7.0605
	old_data_grads_norm = 4.2692
	sim_grads_norm_tr = 0.1577
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6600
	data_grads_norm = 5.2647
	new_data_grads_norm = 6.5349
	old_data_grads_norm = 8.7508
	sim_grads_norm_tr = 0.0149
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2009
	data_grads_norm = 4.8541
	new_data_grads_norm = 6.7573
	old_data_grads_norm = 6.7708
	sim_grads_norm_tr = 0.0504
-- Starting training on experience 102 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2572
	data_grads_norm = 4.1177
	new_data_grads_norm = 5.5179
	old_data_grads_norm = 5.6385
	sim_grads_norm_tr = -0.0149
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0317
	data_grads_norm = 3.9536
	new_data_grads_norm = 6.0409
	old_data_grads_norm = 5.4532
	sim_grads_norm_tr = -0.0163
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4152
	data_grads_norm = 4.3249
	new_data_grads_norm = 5.9105
	old_data_grads_norm = 5.5903
	sim_grads_norm_tr = 0.0460
-- Starting training on experience 103 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3838
	data_grads_norm = 4.1057
	new_data_grads_norm = 5.3058
	old_data_grads_norm = 5.9202
	sim_grads_norm_tr = -0.0441
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7313
	data_grads_norm = 3.3818
	new_data_grads_norm = 5.1766
	old_data_grads_norm = 4.6709
	sim_grads_norm_tr = -0.0290
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3189
	data_grads_norm = 4.5849
	new_data_grads_norm = 5.2116
	old_data_grads_norm = 8.3767
	sim_grads_norm_tr = -0.0267
-- Starting training on experience 104 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9955
	data_grads_norm = 4.2971
	new_data_grads_norm = 6.4901
	old_data_grads_norm = 5.3766
	sim_grads_norm_tr = -0.0109
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0822
	data_grads_norm = 4.7291
	new_data_grads_norm = 6.5847
	old_data_grads_norm = 6.4672
	sim_grads_norm_tr = -0.0371
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5477
	data_grads_norm = 5.1406
	new_data_grads_norm = 6.2680
	old_data_grads_norm = 7.8023
	sim_grads_norm_tr = -0.0597
-- Starting training on experience 105 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5535
	data_grads_norm = 4.7558
	new_data_grads_norm = 6.2388
	old_data_grads_norm = 6.1072
	sim_grads_norm_tr = 0.0804
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9991
	data_grads_norm = 3.6047
	new_data_grads_norm = 5.7977
	old_data_grads_norm = 3.9394
	sim_grads_norm_tr = 0.0993
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0467
	data_grads_norm = 4.2461
	new_data_grads_norm = 6.4156
	old_data_grads_norm = 6.4764
	sim_grads_norm_tr = 0.0343
-- Starting training on experience 106 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4628
	data_grads_norm = 4.3814
	new_data_grads_norm = 5.4149
	old_data_grads_norm = 6.8315
	sim_grads_norm_tr = -0.0073
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6275
	data_grads_norm = 4.2855
	new_data_grads_norm = 5.8042
	old_data_grads_norm = 6.6693
	sim_grads_norm_tr = 0.0449
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2904
	data_grads_norm = 4.7347
	new_data_grads_norm = 5.6640
	old_data_grads_norm = 6.4420
	sim_grads_norm_tr = -0.0464
-- Starting training on experience 107 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1131
	data_grads_norm = 4.0762
	new_data_grads_norm = 5.5791
	old_data_grads_norm = 5.2823
	sim_grads_norm_tr = 0.0210
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4723
	data_grads_norm = 4.5568
	new_data_grads_norm = 5.9601
	old_data_grads_norm = 7.0868
	sim_grads_norm_tr = -0.0628
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4295
	data_grads_norm = 4.9292
	new_data_grads_norm = 5.5742
	old_data_grads_norm = 6.8564
	sim_grads_norm_tr = -0.0002
-- Starting training on experience 108 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5544
	data_grads_norm = 4.6898
	new_data_grads_norm = 6.1072
	old_data_grads_norm = 7.3508
	sim_grads_norm_tr = 0.0364
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1000
	data_grads_norm = 6.3099
	new_data_grads_norm = 6.8884
	old_data_grads_norm = 9.4296
	sim_grads_norm_tr = 0.0424
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1990
	data_grads_norm = 4.3249
	new_data_grads_norm = 5.6829
	old_data_grads_norm = 8.0292
	sim_grads_norm_tr = -0.0171
-- Starting training on experience 109 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0867
	data_grads_norm = 4.0100
	new_data_grads_norm = 6.0805
	old_data_grads_norm = 5.9715
	sim_grads_norm_tr = -0.0475
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1914
	data_grads_norm = 4.0945
	new_data_grads_norm = 6.9617
	old_data_grads_norm = 5.0034
	sim_grads_norm_tr = 0.0411
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3310
	data_grads_norm = 4.8769
	new_data_grads_norm = 6.6266
	old_data_grads_norm = 6.5279
	sim_grads_norm_tr = 0.0255
-- Starting training on experience 110 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2565
	data_grads_norm = 4.1953
	new_data_grads_norm = 6.0968
	old_data_grads_norm = 5.8051
	sim_grads_norm_tr = 0.0694
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3583
	data_grads_norm = 4.9551
	new_data_grads_norm = 6.7483
	old_data_grads_norm = 6.8771
	sim_grads_norm_tr = 0.0465
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6813
	data_grads_norm = 3.4218
	new_data_grads_norm = 5.9707
	old_data_grads_norm = 4.8640
	sim_grads_norm_tr = -0.0251
-- Starting training on experience 111 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9710
	data_grads_norm = 5.8844
	new_data_grads_norm = 7.8654
	old_data_grads_norm = 6.7118
	sim_grads_norm_tr = 0.0058
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6237
	data_grads_norm = 5.0510
	new_data_grads_norm = 7.8921
	old_data_grads_norm = 6.7222
	sim_grads_norm_tr = 0.0094
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6438
	data_grads_norm = 5.1596
	new_data_grads_norm = 6.8594
	old_data_grads_norm = 6.7684
	sim_grads_norm_tr = 0.0232
-- Starting training on experience 112 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1363
	data_grads_norm = 4.1134
	new_data_grads_norm = 5.8734
	old_data_grads_norm = 5.1677
	sim_grads_norm_tr = 0.0393
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4792
	data_grads_norm = 4.7490
	new_data_grads_norm = 6.1553
	old_data_grads_norm = 6.9406
	sim_grads_norm_tr = -0.0273
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0281
	data_grads_norm = 4.0531
	new_data_grads_norm = 6.6479
	old_data_grads_norm = 4.8682
	sim_grads_norm_tr = -0.0577
-- Starting training on experience 113 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3319
	data_grads_norm = 4.4781
	new_data_grads_norm = 5.8515
	old_data_grads_norm = 6.5720
	sim_grads_norm_tr = 0.0084
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6813
	data_grads_norm = 4.1824
	new_data_grads_norm = 5.6217
	old_data_grads_norm = 5.5957
	sim_grads_norm_tr = 0.1067
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4357
	data_grads_norm = 4.2765
	new_data_grads_norm = 5.9381
	old_data_grads_norm = 7.5612
	sim_grads_norm_tr = 0.0132
-- Starting training on experience 114 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3307
	data_grads_norm = 4.5907
	new_data_grads_norm = 6.3201
	old_data_grads_norm = 6.4501
	sim_grads_norm_tr = -0.0547
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2564
	data_grads_norm = 3.9024
	new_data_grads_norm = 6.5228
	old_data_grads_norm = 5.0692
	sim_grads_norm_tr = -0.0176
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3095
	data_grads_norm = 4.6134
	new_data_grads_norm = 6.5887
	old_data_grads_norm = 6.1890
	sim_grads_norm_tr = 0.0775
-- Starting training on experience 115 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6967
	data_grads_norm = 5.6107
	new_data_grads_norm = 7.6976
	old_data_grads_norm = 8.4267
	sim_grads_norm_tr = 0.0201
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6783
	data_grads_norm = 5.2123
	new_data_grads_norm = 7.2615
	old_data_grads_norm = 6.2999
	sim_grads_norm_tr = -0.0087
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2407
	data_grads_norm = 4.8837
	new_data_grads_norm = 7.3787
	old_data_grads_norm = 5.5346
	sim_grads_norm_tr = 0.0902
-- Starting training on experience 116 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2914
	data_grads_norm = 4.3427
	new_data_grads_norm = 6.5549
	old_data_grads_norm = 4.5001
	sim_grads_norm_tr = 0.0047
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4114
	data_grads_norm = 4.8497
	new_data_grads_norm = 6.6426
	old_data_grads_norm = 5.5871
	sim_grads_norm_tr = 0.1583
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5142
	data_grads_norm = 4.7147
	new_data_grads_norm = 6.6742
	old_data_grads_norm = 5.8943
	sim_grads_norm_tr = 0.0178
-- Starting training on experience 117 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8989
	data_grads_norm = 4.8654
	new_data_grads_norm = 6.0328
	old_data_grads_norm = 6.8292
	sim_grads_norm_tr = 0.0286
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5475
	data_grads_norm = 4.2427
	new_data_grads_norm = 5.7225
	old_data_grads_norm = 6.4171
	sim_grads_norm_tr = -0.0131
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1279
	data_grads_norm = 4.4161
	new_data_grads_norm = 6.5533
	old_data_grads_norm = 5.7383
	sim_grads_norm_tr = -0.0282
-- Starting training on experience 118 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0673
	data_grads_norm = 4.0727
	new_data_grads_norm = 5.8158
	old_data_grads_norm = 5.9768
	sim_grads_norm_tr = 0.0731
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4264
	data_grads_norm = 5.4651
	new_data_grads_norm = 7.0020
	old_data_grads_norm = 6.1125
	sim_grads_norm_tr = -0.0066
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0261
	data_grads_norm = 4.6438
	new_data_grads_norm = 7.3543
	old_data_grads_norm = 5.8895
	sim_grads_norm_tr = -0.0073
-- Starting training on experience 119 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8681
	data_grads_norm = 4.8169
	new_data_grads_norm = 6.2794
	old_data_grads_norm = 6.4116
	sim_grads_norm_tr = 0.0531
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7501
	data_grads_norm = 5.2329
	new_data_grads_norm = 6.9022
	old_data_grads_norm = 7.7912
	sim_grads_norm_tr = 0.0158
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0499
	data_grads_norm = 5.2367
	new_data_grads_norm = 6.5438
	old_data_grads_norm = 6.6765
	sim_grads_norm_tr = 0.0904
-- Starting training on experience 120 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8650
	data_grads_norm = 3.7722
	new_data_grads_norm = 6.4525
	old_data_grads_norm = 4.4260
	sim_grads_norm_tr = -0.0218
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6437
	data_grads_norm = 4.4969
	new_data_grads_norm = 6.7009
	old_data_grads_norm = 6.2216
	sim_grads_norm_tr = 0.0056
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3799
	data_grads_norm = 5.0539
	new_data_grads_norm = 6.6706
	old_data_grads_norm = 6.9167
	sim_grads_norm_tr = -0.0514
-- Starting training on experience 121 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8417
	data_grads_norm = 4.9589
	new_data_grads_norm = 7.7798
	old_data_grads_norm = 7.3048
	sim_grads_norm_tr = -0.0393
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8184
	data_grads_norm = 5.0284
	new_data_grads_norm = 7.6874
	old_data_grads_norm = 6.0244
	sim_grads_norm_tr = -0.0010
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6746
	data_grads_norm = 4.5649
	new_data_grads_norm = 7.9952
	old_data_grads_norm = 6.6538
	sim_grads_norm_tr = -0.0997
-- Starting training on experience 122 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3199
	data_grads_norm = 4.4189
	new_data_grads_norm = 5.4218
	old_data_grads_norm = 9.3051
	sim_grads_norm_tr = 0.0695
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3944
	data_grads_norm = 4.5264
	new_data_grads_norm = 5.8307
	old_data_grads_norm = 5.5960
	sim_grads_norm_tr = 0.0617
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3660
	data_grads_norm = 4.3386
	new_data_grads_norm = 5.3635
	old_data_grads_norm = 6.7976
	sim_grads_norm_tr = 0.0001
-- Starting training on experience 123 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6609
	data_grads_norm = 4.2903
	new_data_grads_norm = 6.6500
	old_data_grads_norm = 4.9598
	sim_grads_norm_tr = -0.0157
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7617
	data_grads_norm = 4.7896
	new_data_grads_norm = 6.8607
	old_data_grads_norm = 5.3721
	sim_grads_norm_tr = 0.1308
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8984
	data_grads_norm = 4.8531
	new_data_grads_norm = 7.0869
	old_data_grads_norm = 6.6277
	sim_grads_norm_tr = 0.0003
-- Starting training on experience 124 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6592
	data_grads_norm = 5.0749
	new_data_grads_norm = 6.2774
	old_data_grads_norm = 7.1320
	sim_grads_norm_tr = 0.1120
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7533
	data_grads_norm = 4.9017
	new_data_grads_norm = 6.0973
	old_data_grads_norm = 6.6023
	sim_grads_norm_tr = -0.0205
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7321
	data_grads_norm = 5.2409
	new_data_grads_norm = 6.2493
	old_data_grads_norm = 6.9930
	sim_grads_norm_tr = 0.0000
-- Starting training on experience 125 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3875
	data_grads_norm = 4.0960
	new_data_grads_norm = 5.8809
	old_data_grads_norm = 5.3400
	sim_grads_norm_tr = -0.0033
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6256
	data_grads_norm = 5.2841
	new_data_grads_norm = 6.5339
	old_data_grads_norm = 8.7017
	sim_grads_norm_tr = 0.0231
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0903
	data_grads_norm = 5.3974
	new_data_grads_norm = 6.1107
	old_data_grads_norm = 8.6157
	sim_grads_norm_tr = -0.0048
-- Starting training on experience 126 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6096
	data_grads_norm = 4.1901
	new_data_grads_norm = 6.6886
	old_data_grads_norm = 4.7824
	sim_grads_norm_tr = 0.1748
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6987
	data_grads_norm = 4.6546
	new_data_grads_norm = 6.0470
	old_data_grads_norm = 6.1990
	sim_grads_norm_tr = 0.0100
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7698
	data_grads_norm = 5.2542
	new_data_grads_norm = 6.4081
	old_data_grads_norm = 8.1491
	sim_grads_norm_tr = 0.0010
-- Starting training on experience 127 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2281
	data_grads_norm = 5.2347
	new_data_grads_norm = 6.0006
	old_data_grads_norm = 7.8931
	sim_grads_norm_tr = 0.0200
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7453
	data_grads_norm = 5.3053
	new_data_grads_norm = 6.0798
	old_data_grads_norm = 8.5465
	sim_grads_norm_tr = 0.0242
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9847
	data_grads_norm = 4.1602
	new_data_grads_norm = 6.0972
	old_data_grads_norm = 5.2206
	sim_grads_norm_tr = 0.1135
-- Starting training on experience 128 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4442
	data_grads_norm = 4.8042
	new_data_grads_norm = 6.8590
	old_data_grads_norm = 6.3127
	sim_grads_norm_tr = 0.1698
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0498
	data_grads_norm = 3.8502
	new_data_grads_norm = 6.8866
	old_data_grads_norm = 6.5857
	sim_grads_norm_tr = -0.0313
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1141
	data_grads_norm = 4.4565
	new_data_grads_norm = 6.9931
	old_data_grads_norm = 5.5340
	sim_grads_norm_tr = -0.0136
-- Starting training on experience 129 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2040
	data_grads_norm = 4.5138
	new_data_grads_norm = 6.6592
	old_data_grads_norm = 5.6964
	sim_grads_norm_tr = -0.0260
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3525
	data_grads_norm = 4.6381
	new_data_grads_norm = 6.4488
	old_data_grads_norm = 6.5597
	sim_grads_norm_tr = -0.0571
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5333
	data_grads_norm = 4.6827
	new_data_grads_norm = 7.4544
	old_data_grads_norm = 4.7184
	sim_grads_norm_tr = 0.0051
-- Starting training on experience 130 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0634
	data_grads_norm = 3.7694
	new_data_grads_norm = 5.9060
	old_data_grads_norm = 4.5274
	sim_grads_norm_tr = 0.0452
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3601
	data_grads_norm = 4.2983
	new_data_grads_norm = 6.1467
	old_data_grads_norm = 6.5366
	sim_grads_norm_tr = 0.0434
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9663
	data_grads_norm = 3.7744
	new_data_grads_norm = 6.2459
	old_data_grads_norm = 4.7603
	sim_grads_norm_tr = 0.0376
-- Starting training on experience 131 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9510
	data_grads_norm = 3.9567
	new_data_grads_norm = 6.6884
	old_data_grads_norm = 4.4889
	sim_grads_norm_tr = -0.0354
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0768
	data_grads_norm = 4.1772
	new_data_grads_norm = 7.0972
	old_data_grads_norm = 6.3052
	sim_grads_norm_tr = 0.0197
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5758
	data_grads_norm = 4.6259
	new_data_grads_norm = 6.2606
	old_data_grads_norm = 6.3799
	sim_grads_norm_tr = 0.0816
-- Starting training on experience 132 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7725
	data_grads_norm = 4.5177
	new_data_grads_norm = 7.0056
	old_data_grads_norm = 7.0753
	sim_grads_norm_tr = 0.0102
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6073
	data_grads_norm = 5.0103
	new_data_grads_norm = 6.5120
	old_data_grads_norm = 7.1248
	sim_grads_norm_tr = -0.0277
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9415
	data_grads_norm = 5.3102
	new_data_grads_norm = 7.1317
	old_data_grads_norm = 7.2510
	sim_grads_norm_tr = -0.0133
-- Starting training on experience 133 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6442
	data_grads_norm = 4.3169
	new_data_grads_norm = 6.3175
	old_data_grads_norm = 6.4424
	sim_grads_norm_tr = 0.0070
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5837
	data_grads_norm = 5.2465
	new_data_grads_norm = 6.0248
	old_data_grads_norm = 8.9070
	sim_grads_norm_tr = -0.0235
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2795
	data_grads_norm = 4.1566
	new_data_grads_norm = 5.9416
	old_data_grads_norm = 6.0074
	sim_grads_norm_tr = 0.0068
-- Starting training on experience 134 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2623
	data_grads_norm = 4.2030
	new_data_grads_norm = 6.3057
	old_data_grads_norm = 5.2299
	sim_grads_norm_tr = 0.0201
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4532
	data_grads_norm = 4.4265
	new_data_grads_norm = 6.4856
	old_data_grads_norm = 6.5243
	sim_grads_norm_tr = -0.0303
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9507
	data_grads_norm = 4.9595
	new_data_grads_norm = 6.4487
	old_data_grads_norm = 7.7950
	sim_grads_norm_tr = -0.0206
-- Starting training on experience 135 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4776
	data_grads_norm = 5.2259
	new_data_grads_norm = 6.5635
	old_data_grads_norm = 7.2943
	sim_grads_norm_tr = 0.0530
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6982
	data_grads_norm = 5.1888
	new_data_grads_norm = 6.9224
	old_data_grads_norm = 7.5022
	sim_grads_norm_tr = 0.0642
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2315
	data_grads_norm = 4.9129
	new_data_grads_norm = 6.0234
	old_data_grads_norm = 7.5615
	sim_grads_norm_tr = 0.0053
-- Starting training on experience 136 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3122
	data_grads_norm = 5.1135
	new_data_grads_norm = 6.3702
	old_data_grads_norm = 6.1842
	sim_grads_norm_tr = 0.0691
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8823
	data_grads_norm = 5.6971
	new_data_grads_norm = 6.0427
	old_data_grads_norm = 8.7552
	sim_grads_norm_tr = 0.0009
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5069
	data_grads_norm = 4.5116
	new_data_grads_norm = 6.1069
	old_data_grads_norm = 6.6475
	sim_grads_norm_tr = -0.0095
-- Starting training on experience 137 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4517
	data_grads_norm = 4.7989
	new_data_grads_norm = 7.4580
	old_data_grads_norm = 5.6859
	sim_grads_norm_tr = -0.1147
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6099
	data_grads_norm = 5.0872
	new_data_grads_norm = 7.4983
	old_data_grads_norm = 6.0968
	sim_grads_norm_tr = 0.0083
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6353
	data_grads_norm = 5.7843
	new_data_grads_norm = 7.7389
	old_data_grads_norm = 7.5651
	sim_grads_norm_tr = 0.0245
-- Starting training on experience 138 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2832
	data_grads_norm = 4.4703
	new_data_grads_norm = 6.8653
	old_data_grads_norm = 4.8157
	sim_grads_norm_tr = 0.0902
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8853
	data_grads_norm = 3.9255
	new_data_grads_norm = 6.5210
	old_data_grads_norm = 4.8970
	sim_grads_norm_tr = -0.0043
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0156
	data_grads_norm = 4.4694
	new_data_grads_norm = 7.2693
	old_data_grads_norm = 6.2984
	sim_grads_norm_tr = -0.0311
-- Starting training on experience 139 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5998
	data_grads_norm = 4.7841
	new_data_grads_norm = 7.2767
	old_data_grads_norm = 5.5507
	sim_grads_norm_tr = 0.0573
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1481
	data_grads_norm = 5.2239
	new_data_grads_norm = 6.4691
	old_data_grads_norm = 6.0579
	sim_grads_norm_tr = 0.0135
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7799
	data_grads_norm = 5.0249
	new_data_grads_norm = 7.3576
	old_data_grads_norm = 6.2876
	sim_grads_norm_tr = 0.0317
-- Starting training on experience 140 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1375
	data_grads_norm = 4.3052
	new_data_grads_norm = 7.9182
	old_data_grads_norm = 4.1438
	sim_grads_norm_tr = 0.0322
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3945
	data_grads_norm = 4.8256
	new_data_grads_norm = 7.5496
	old_data_grads_norm = 6.3632
	sim_grads_norm_tr = 0.0764
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5771
	data_grads_norm = 5.2307
	new_data_grads_norm = 6.3339
	old_data_grads_norm = 7.3410
	sim_grads_norm_tr = -0.0144
-- Starting training on experience 141 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1930
	data_grads_norm = 5.3909
	new_data_grads_norm = 7.4412
	old_data_grads_norm = 5.3802
	sim_grads_norm_tr = -0.0340
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6241
	data_grads_norm = 5.8796
	new_data_grads_norm = 7.2932
	old_data_grads_norm = 6.0315
	sim_grads_norm_tr = 0.0039
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5059
	data_grads_norm = 5.6426
	new_data_grads_norm = 8.0872
	old_data_grads_norm = 5.5786
	sim_grads_norm_tr = -0.0180
-- Starting training on experience 142 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5208
	data_grads_norm = 5.3714
	new_data_grads_norm = 7.4758
	old_data_grads_norm = 7.4351
	sim_grads_norm_tr = 0.0596
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3657
	data_grads_norm = 4.9084
	new_data_grads_norm = 8.1589
	old_data_grads_norm = 6.0933
	sim_grads_norm_tr = -0.0469
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0630
	data_grads_norm = 6.5605
	new_data_grads_norm = 8.4511
	old_data_grads_norm = 9.0575
	sim_grads_norm_tr = 0.1158
-- Starting training on experience 143 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2446
	data_grads_norm = 4.4266
	new_data_grads_norm = 5.4938
	old_data_grads_norm = 6.3126
	sim_grads_norm_tr = -0.0200
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4072
	data_grads_norm = 4.1591
	new_data_grads_norm = 6.0743
	old_data_grads_norm = 6.6189
	sim_grads_norm_tr = -0.0115
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2506
	data_grads_norm = 4.3789
	new_data_grads_norm = 6.4151
	old_data_grads_norm = 5.9980
	sim_grads_norm_tr = -0.0414
-- Starting training on experience 144 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9227
	data_grads_norm = 5.0116
	new_data_grads_norm = 7.7854
	old_data_grads_norm = 6.5017
	sim_grads_norm_tr = -0.0038
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9800
	data_grads_norm = 5.5844
	new_data_grads_norm = 7.5531
	old_data_grads_norm = 7.3680
	sim_grads_norm_tr = 0.0094
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3149
	data_grads_norm = 4.5662
	new_data_grads_norm = 7.1474
	old_data_grads_norm = 5.6514
	sim_grads_norm_tr = -0.0176
-- Starting training on experience 145 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9417
	data_grads_norm = 4.6404
	new_data_grads_norm = 6.5719
	old_data_grads_norm = 5.5131
	sim_grads_norm_tr = -0.0265
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7278
	data_grads_norm = 5.7390
	new_data_grads_norm = 7.6069
	old_data_grads_norm = 7.5820
	sim_grads_norm_tr = -0.0088
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4467
	data_grads_norm = 5.0646
	new_data_grads_norm = 7.4192
	old_data_grads_norm = 7.1759
	sim_grads_norm_tr = -0.0276
-- Starting training on experience 146 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5136
	data_grads_norm = 5.0639
	new_data_grads_norm = 6.7190
	old_data_grads_norm = 7.1144
	sim_grads_norm_tr = -0.0674
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3232
	data_grads_norm = 4.3529
	new_data_grads_norm = 6.9789
	old_data_grads_norm = 4.4097
	sim_grads_norm_tr = 0.0046
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5901
	data_grads_norm = 4.8578
	new_data_grads_norm = 7.0026
	old_data_grads_norm = 7.1087
	sim_grads_norm_tr = 0.0195
-- Starting training on experience 147 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9741
	data_grads_norm = 4.8821
	new_data_grads_norm = 6.5651
	old_data_grads_norm = 6.4917
	sim_grads_norm_tr = 0.0103
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5612
	data_grads_norm = 4.3278
	new_data_grads_norm = 6.3839
	old_data_grads_norm = 5.0297
	sim_grads_norm_tr = 0.0258
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6622
	data_grads_norm = 4.7113
	new_data_grads_norm = 6.6645
	old_data_grads_norm = 5.3416
	sim_grads_norm_tr = 0.0716
-- Starting training on experience 148 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7159
	data_grads_norm = 4.7129
	new_data_grads_norm = 6.8165
	old_data_grads_norm = 5.5160
	sim_grads_norm_tr = -0.0182
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7290
	data_grads_norm = 4.7632
	new_data_grads_norm = 7.0970
	old_data_grads_norm = 5.8533
	sim_grads_norm_tr = -0.0394
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9356
	data_grads_norm = 5.2630
	new_data_grads_norm = 7.9439
	old_data_grads_norm = 6.4166
	sim_grads_norm_tr = -0.0178
-- Starting training on experience 149 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7875
	data_grads_norm = 4.6579
	new_data_grads_norm = 6.8480
	old_data_grads_norm = 5.9645
	sim_grads_norm_tr = -0.0061
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4320
	data_grads_norm = 4.9995
	new_data_grads_norm = 7.2605
	old_data_grads_norm = 6.3442
	sim_grads_norm_tr = -0.0159
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6209
	data_grads_norm = 4.3674
	new_data_grads_norm = 6.9449
	old_data_grads_norm = 5.6433
	sim_grads_norm_tr = 0.0159
-- Starting training on experience 150 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1886
	data_grads_norm = 4.8004
	new_data_grads_norm = 6.6646
	old_data_grads_norm = 7.4642
	sim_grads_norm_tr = 0.0161
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9589
	data_grads_norm = 4.6801
	new_data_grads_norm = 6.7156
	old_data_grads_norm = 6.7479
	sim_grads_norm_tr = -0.0127
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9712
	data_grads_norm = 4.8815
	new_data_grads_norm = 6.6022
	old_data_grads_norm = 6.4621
	sim_grads_norm_tr = 0.0087
-- Starting training on experience 151 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4759
	data_grads_norm = 4.7369
	new_data_grads_norm = 6.2451
	old_data_grads_norm = 6.6062
	sim_grads_norm_tr = -0.0270
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5245
	data_grads_norm = 4.1706
	new_data_grads_norm = 6.8634
	old_data_grads_norm = 4.2724
	sim_grads_norm_tr = -0.0248
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5909
	data_grads_norm = 4.0943
	new_data_grads_norm = 5.9139
	old_data_grads_norm = 5.4171
	sim_grads_norm_tr = -0.0078
-- Starting training on experience 152 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4467
	data_grads_norm = 4.7261
	new_data_grads_norm = 6.8382
	old_data_grads_norm = 5.9788
	sim_grads_norm_tr = -0.0011
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4532
	data_grads_norm = 4.4440
	new_data_grads_norm = 6.5321
	old_data_grads_norm = 5.8048
	sim_grads_norm_tr = 0.0430
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5657
	data_grads_norm = 4.8267
	new_data_grads_norm = 6.8081
	old_data_grads_norm = 7.3170
	sim_grads_norm_tr = 0.0062
-- Starting training on experience 153 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9749
	data_grads_norm = 5.4922
	new_data_grads_norm = 7.9340
	old_data_grads_norm = 7.1466
	sim_grads_norm_tr = 0.0005
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7491
	data_grads_norm = 5.1249
	new_data_grads_norm = 7.3040
	old_data_grads_norm = 6.9776
	sim_grads_norm_tr = -0.0192
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6703
	data_grads_norm = 5.0455
	new_data_grads_norm = 8.2327
	old_data_grads_norm = 4.3575
	sim_grads_norm_tr = 0.0411
-- Starting training on experience 154 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6452
	data_grads_norm = 4.7466
	new_data_grads_norm = 6.6810
	old_data_grads_norm = 5.5807
	sim_grads_norm_tr = 0.0624
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7240
	data_grads_norm = 5.0076
	new_data_grads_norm = 6.7919
	old_data_grads_norm = 6.7802
	sim_grads_norm_tr = -0.0391
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9395
	data_grads_norm = 4.8461
	new_data_grads_norm = 6.7691
	old_data_grads_norm = 6.8557
	sim_grads_norm_tr = -0.0201
-- Starting training on experience 155 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7239
	data_grads_norm = 4.7315
	new_data_grads_norm = 7.2029
	old_data_grads_norm = 6.0356
	sim_grads_norm_tr = 0.1172
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5764
	data_grads_norm = 4.6594
	new_data_grads_norm = 6.2440
	old_data_grads_norm = 6.3601
	sim_grads_norm_tr = 0.0543
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5096
	data_grads_norm = 5.1394
	new_data_grads_norm = 7.2302
	old_data_grads_norm = 7.0363
	sim_grads_norm_tr = 0.0141
-- Starting training on experience 156 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6116
	data_grads_norm = 4.8022
	new_data_grads_norm = 7.0200
	old_data_grads_norm = 6.8789
	sim_grads_norm_tr = -0.0105
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5641
	data_grads_norm = 4.7111
	new_data_grads_norm = 6.9743
	old_data_grads_norm = 6.3505
	sim_grads_norm_tr = -0.0301
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4768
	data_grads_norm = 4.5578
	new_data_grads_norm = 7.6725
	old_data_grads_norm = 8.7331
	sim_grads_norm_tr = 0.0159
-- Starting training on experience 157 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8133
	data_grads_norm = 4.9332
	new_data_grads_norm = 7.6700
	old_data_grads_norm = 5.8592
	sim_grads_norm_tr = 0.0970
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9098
	data_grads_norm = 3.9431
	new_data_grads_norm = 7.2140
	old_data_grads_norm = 5.6516
	sim_grads_norm_tr = -0.0374
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7543
	data_grads_norm = 5.5041
	new_data_grads_norm = 6.7776
	old_data_grads_norm = 8.7011
	sim_grads_norm_tr = 0.0097
-- Starting training on experience 158 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1145
	data_grads_norm = 4.0469
	new_data_grads_norm = 6.7469
	old_data_grads_norm = 4.0945
	sim_grads_norm_tr = 0.0682
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3065
	data_grads_norm = 4.1066
	new_data_grads_norm = 6.1566
	old_data_grads_norm = 5.7750
	sim_grads_norm_tr = 0.0138
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6153
	data_grads_norm = 5.3429
	new_data_grads_norm = 7.5095
	old_data_grads_norm = 6.5581
	sim_grads_norm_tr = 0.0651
-- Starting training on experience 159 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3170
	data_grads_norm = 4.1674
	new_data_grads_norm = 5.8750
	old_data_grads_norm = 5.0997
	sim_grads_norm_tr = 0.1019
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1836
	data_grads_norm = 4.6969
	new_data_grads_norm = 5.9170
	old_data_grads_norm = 6.4981
	sim_grads_norm_tr = -0.0028
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9588
	data_grads_norm = 4.2320
	new_data_grads_norm = 5.7037
	old_data_grads_norm = 6.4884
	sim_grads_norm_tr = 0.0353
-- Starting training on experience 160 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0934
	data_grads_norm = 4.1929
	new_data_grads_norm = 6.8879
	old_data_grads_norm = 4.4906
	sim_grads_norm_tr = 0.0765
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4114
	data_grads_norm = 4.7209
	new_data_grads_norm = 7.0122
	old_data_grads_norm = 6.5581
	sim_grads_norm_tr = -0.0077
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8306
	data_grads_norm = 4.0617
	new_data_grads_norm = 6.6681
	old_data_grads_norm = 3.7415
	sim_grads_norm_tr = 0.0232
-- Starting training on experience 161 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4727
	data_grads_norm = 5.2394
	new_data_grads_norm = 8.1509
	old_data_grads_norm = 5.6969
	sim_grads_norm_tr = 0.0700
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6429
	data_grads_norm = 5.2089
	new_data_grads_norm = 7.4264
	old_data_grads_norm = 6.6846
	sim_grads_norm_tr = -0.0080
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6010
	data_grads_norm = 5.2345
	new_data_grads_norm = 6.9436
	old_data_grads_norm = 8.5872
	sim_grads_norm_tr = 0.0100
-- Starting training on experience 162 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3478
	data_grads_norm = 5.4120
	new_data_grads_norm = 7.4588
	old_data_grads_norm = 8.1900
	sim_grads_norm_tr = 0.0365
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8941
	data_grads_norm = 4.5521
	new_data_grads_norm = 6.1864
	old_data_grads_norm = 5.8879
	sim_grads_norm_tr = 0.1269
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5428
	data_grads_norm = 4.8330
	new_data_grads_norm = 6.4591
	old_data_grads_norm = 6.3913
	sim_grads_norm_tr = 0.0522
-- Starting training on experience 163 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2016
	data_grads_norm = 5.0577
	new_data_grads_norm = 7.0553
	old_data_grads_norm = 7.5805
	sim_grads_norm_tr = -0.0221
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9314
	data_grads_norm = 5.5535
	new_data_grads_norm = 8.2179
	old_data_grads_norm = 6.6210
	sim_grads_norm_tr = 0.0005
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7000
	data_grads_norm = 5.2066
	new_data_grads_norm = 7.6041
	old_data_grads_norm = 6.1884
	sim_grads_norm_tr = 0.1220
-- Starting training on experience 164 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1320
	data_grads_norm = 4.0927
	new_data_grads_norm = 6.3787
	old_data_grads_norm = 5.9588
	sim_grads_norm_tr = -0.0705
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4915
	data_grads_norm = 4.7686
	new_data_grads_norm = 6.9848
	old_data_grads_norm = 6.2644
	sim_grads_norm_tr = -0.0028
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5489
	data_grads_norm = 4.3648
	new_data_grads_norm = 6.7455
	old_data_grads_norm = 5.0338
	sim_grads_norm_tr = -0.0016
-- Starting training on experience 165 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3944
	data_grads_norm = 4.3759
	new_data_grads_norm = 6.4474
	old_data_grads_norm = 5.9651
	sim_grads_norm_tr = -0.0172
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2114
	data_grads_norm = 4.3605
	new_data_grads_norm = 6.2712
	old_data_grads_norm = 7.2105
	sim_grads_norm_tr = 0.0192
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7708
	data_grads_norm = 4.6965
	new_data_grads_norm = 6.1377
	old_data_grads_norm = 5.8038
	sim_grads_norm_tr = 0.0443
-- Starting training on experience 166 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6240
	data_grads_norm = 5.2568
	new_data_grads_norm = 6.6899
	old_data_grads_norm = 7.6257
	sim_grads_norm_tr = 0.0095
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2411
	data_grads_norm = 4.5588
	new_data_grads_norm = 6.3198
	old_data_grads_norm = 6.6756
	sim_grads_norm_tr = -0.0343
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3074
	data_grads_norm = 4.5616
	new_data_grads_norm = 7.0703
	old_data_grads_norm = 5.5313
	sim_grads_norm_tr = -0.0166
-- Starting training on experience 167 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0666
	data_grads_norm = 5.4863
	new_data_grads_norm = 7.8800
	old_data_grads_norm = 7.8335
	sim_grads_norm_tr = -0.0324
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4390
	data_grads_norm = 5.4194
	new_data_grads_norm = 8.0890
	old_data_grads_norm = 5.5318
	sim_grads_norm_tr = 0.0034
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3006
	data_grads_norm = 4.9201
	new_data_grads_norm = 7.9408
	old_data_grads_norm = 5.3981
	sim_grads_norm_tr = 0.0165
-- Starting training on experience 168 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5011
	data_grads_norm = 4.9858
	new_data_grads_norm = 6.1630
	old_data_grads_norm = 6.3750
	sim_grads_norm_tr = 0.0790
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1669
	data_grads_norm = 4.3066
	new_data_grads_norm = 5.8843
	old_data_grads_norm = 6.1357
	sim_grads_norm_tr = 0.0014
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8771
	data_grads_norm = 3.8848
	new_data_grads_norm = 5.5217
	old_data_grads_norm = 5.8813
	sim_grads_norm_tr = -0.0030
-- Starting training on experience 169 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6653
	data_grads_norm = 5.5858
	new_data_grads_norm = 8.0674
	old_data_grads_norm = 5.9239
	sim_grads_norm_tr = 0.0676
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3387
	data_grads_norm = 5.1164
	new_data_grads_norm = 7.6421
	old_data_grads_norm = 6.9186
	sim_grads_norm_tr = -0.0030
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6474
	data_grads_norm = 5.2552
	new_data_grads_norm = 6.7152
	old_data_grads_norm = 6.5186
	sim_grads_norm_tr = -0.0030
-- Starting training on experience 170 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3562
	data_grads_norm = 5.6557
	new_data_grads_norm = 7.9759
	old_data_grads_norm = 6.8442
	sim_grads_norm_tr = -0.0498
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9188
	data_grads_norm = 5.5120
	new_data_grads_norm = 8.8429
	old_data_grads_norm = 3.8081
	sim_grads_norm_tr = 0.1010
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9791
	data_grads_norm = 5.1896
	new_data_grads_norm = 8.0759
	old_data_grads_norm = 4.7620
	sim_grads_norm_tr = -0.0197
-- Starting training on experience 171 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1014
	data_grads_norm = 3.8936
	new_data_grads_norm = 6.4269
	old_data_grads_norm = 5.1383
	sim_grads_norm_tr = -0.0163
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4704
	data_grads_norm = 4.7965
	new_data_grads_norm = 6.8355
	old_data_grads_norm = 5.9075
	sim_grads_norm_tr = -0.0295
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5113
	data_grads_norm = 4.6791
	new_data_grads_norm = 6.6711
	old_data_grads_norm = 6.8395
	sim_grads_norm_tr = -0.0503
-- Starting training on experience 172 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7449
	data_grads_norm = 5.4699
	new_data_grads_norm = 6.7631
	old_data_grads_norm = 7.2234
	sim_grads_norm_tr = 0.0354
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1903
	data_grads_norm = 4.6237
	new_data_grads_norm = 6.6775
	old_data_grads_norm = 5.9649
	sim_grads_norm_tr = -0.0023
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2303
	data_grads_norm = 4.7583
	new_data_grads_norm = 6.4769
	old_data_grads_norm = 7.2982
	sim_grads_norm_tr = 0.0274
-- Starting training on experience 173 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6345
	data_grads_norm = 5.1608
	new_data_grads_norm = 7.8656
	old_data_grads_norm = 5.9645
	sim_grads_norm_tr = 0.0848
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3759
	data_grads_norm = 4.5973
	new_data_grads_norm = 6.8641
	old_data_grads_norm = 6.3952
	sim_grads_norm_tr = -0.0446
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5453
	data_grads_norm = 5.0535
	new_data_grads_norm = 7.9960
	old_data_grads_norm = 6.1802
	sim_grads_norm_tr = -0.0221
-- Starting training on experience 174 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6266
	data_grads_norm = 4.6911
	new_data_grads_norm = 6.4187
	old_data_grads_norm = 7.0040
	sim_grads_norm_tr = -0.0118
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2187
	data_grads_norm = 4.0579
	new_data_grads_norm = 6.7114
	old_data_grads_norm = 4.8987
	sim_grads_norm_tr = -0.0237
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5666
	data_grads_norm = 4.6917
	new_data_grads_norm = 6.4419
	old_data_grads_norm = 7.0519
	sim_grads_norm_tr = 0.0551
-- Starting training on experience 175 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6557
	data_grads_norm = 5.8064
	new_data_grads_norm = 7.3523
	old_data_grads_norm = 8.9976
	sim_grads_norm_tr = -0.0252
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8880
	data_grads_norm = 5.7588
	new_data_grads_norm = 7.1744
	old_data_grads_norm = 6.5852
	sim_grads_norm_tr = 0.1034
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1707
	data_grads_norm = 4.2266
	new_data_grads_norm = 7.1022
	old_data_grads_norm = 4.1043
	sim_grads_norm_tr = 0.0128
-- Starting training on experience 176 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0289
	data_grads_norm = 3.4294
	new_data_grads_norm = 5.6781
	old_data_grads_norm = 3.7940
	sim_grads_norm_tr = 0.0327
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9459
	data_grads_norm = 3.7382
	new_data_grads_norm = 5.7525
	old_data_grads_norm = 5.4903
	sim_grads_norm_tr = -0.0254
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3136
	data_grads_norm = 4.9676
	new_data_grads_norm = 6.8105
	old_data_grads_norm = 6.7130
	sim_grads_norm_tr = 0.1137
-- Starting training on experience 177 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4302
	data_grads_norm = 5.1800
	new_data_grads_norm = 5.6300
	old_data_grads_norm = 7.1537
	sim_grads_norm_tr = -0.0111
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5614
	data_grads_norm = 5.6430
	new_data_grads_norm = 5.7327
	old_data_grads_norm = 9.3148
	sim_grads_norm_tr = 0.0352
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8466
	data_grads_norm = 3.8806
	new_data_grads_norm = 5.8026
	old_data_grads_norm = 6.6869
	sim_grads_norm_tr = 0.0456
-- Starting training on experience 178 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3370
	data_grads_norm = 4.7138
	new_data_grads_norm = 8.2646
	old_data_grads_norm = 4.8396
	sim_grads_norm_tr = -0.0543
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8876
	data_grads_norm = 6.2124
	new_data_grads_norm = 8.7236
	old_data_grads_norm = 8.2532
	sim_grads_norm_tr = 0.0156
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2885
	data_grads_norm = 5.4776
	new_data_grads_norm = 8.2165
	old_data_grads_norm = 7.2061
	sim_grads_norm_tr = 0.0065
-- Starting training on experience 179 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9140
	data_grads_norm = 3.9314
	new_data_grads_norm = 8.1055
	old_data_grads_norm = 5.2519
	sim_grads_norm_tr = -0.0233
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7473
	data_grads_norm = 3.4293
	new_data_grads_norm = 6.6626
	old_data_grads_norm = 4.2933
	sim_grads_norm_tr = -0.0070
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2004
	data_grads_norm = 4.8179
	new_data_grads_norm = 7.2851
	old_data_grads_norm = 6.2789
	sim_grads_norm_tr = 0.0120
-- Starting training on experience 180 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1760
	data_grads_norm = 4.7905
	new_data_grads_norm = 6.5093
	old_data_grads_norm = 6.2440
	sim_grads_norm_tr = -0.0269
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3936
	data_grads_norm = 4.4868
	new_data_grads_norm = 6.2901
	old_data_grads_norm = 5.3796
	sim_grads_norm_tr = 0.0398
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3690
	data_grads_norm = 4.4892
	new_data_grads_norm = 6.9478
	old_data_grads_norm = 6.0983
	sim_grads_norm_tr = -0.0484
-- Starting training on experience 181 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0059
	data_grads_norm = 4.8167
	new_data_grads_norm = 6.5786
	old_data_grads_norm = 7.1128
	sim_grads_norm_tr = 0.0302
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2499
	data_grads_norm = 4.7872
	new_data_grads_norm = 6.3567
	old_data_grads_norm = 6.8928
	sim_grads_norm_tr = 0.1254
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5345
	data_grads_norm = 5.1247
	new_data_grads_norm = 6.0910
	old_data_grads_norm = 8.2107
	sim_grads_norm_tr = 0.0504
-- Starting training on experience 182 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2042
	data_grads_norm = 5.3211
	new_data_grads_norm = 7.4114
	old_data_grads_norm = 5.7571
	sim_grads_norm_tr = -0.0128
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2676
	data_grads_norm = 5.2234
	new_data_grads_norm = 7.7958
	old_data_grads_norm = 6.7507
	sim_grads_norm_tr = -0.0001
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0662
	data_grads_norm = 4.6969
	new_data_grads_norm = 7.2174
	old_data_grads_norm = 5.5928
	sim_grads_norm_tr = -0.0319
-- Starting training on experience 183 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8260
	data_grads_norm = 5.2968
	new_data_grads_norm = 7.8327
	old_data_grads_norm = 6.9174
	sim_grads_norm_tr = -0.0197
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8230
	data_grads_norm = 4.8192
	new_data_grads_norm = 7.9182
	old_data_grads_norm = 6.0107
	sim_grads_norm_tr = 0.0685
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4710
	data_grads_norm = 5.7933
	new_data_grads_norm = 7.7720
	old_data_grads_norm = 7.8670
	sim_grads_norm_tr = -0.0180
-- Starting training on experience 184 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1860
	data_grads_norm = 4.6768
	new_data_grads_norm = 7.6209
	old_data_grads_norm = 6.2420
	sim_grads_norm_tr = -0.0316
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8557
	data_grads_norm = 5.2514
	new_data_grads_norm = 8.7408
	old_data_grads_norm = 6.0792
	sim_grads_norm_tr = 0.0532
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8456
	data_grads_norm = 5.8616
	new_data_grads_norm = 8.3126
	old_data_grads_norm = 8.1131
	sim_grads_norm_tr = 0.0869
-- Starting training on experience 185 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5595
	data_grads_norm = 5.6032
	new_data_grads_norm = 8.5085
	old_data_grads_norm = 6.2413
	sim_grads_norm_tr = 0.0164
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0717
	data_grads_norm = 5.4134
	new_data_grads_norm = 8.8491
	old_data_grads_norm = 5.4015
	sim_grads_norm_tr = -0.0394
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0636
	data_grads_norm = 5.3723
	new_data_grads_norm = 8.8562
	old_data_grads_norm = 6.3056
	sim_grads_norm_tr = 0.1220
-- Starting training on experience 186 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5805
	data_grads_norm = 5.4071
	new_data_grads_norm = 8.3361
	old_data_grads_norm = 4.3260
	sim_grads_norm_tr = 0.0392
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0770
	data_grads_norm = 5.7293
	new_data_grads_norm = 8.6024
	old_data_grads_norm = 5.8097
	sim_grads_norm_tr = -0.0133
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7530
	data_grads_norm = 5.4219
	new_data_grads_norm = 8.2268
	old_data_grads_norm = 6.9621
	sim_grads_norm_tr = -0.0513
-- Starting training on experience 187 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7515
	data_grads_norm = 4.1543
	new_data_grads_norm = 5.8874
	old_data_grads_norm = 6.0789
	sim_grads_norm_tr = -0.0823
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7670
	data_grads_norm = 4.3358
	new_data_grads_norm = 6.2526
	old_data_grads_norm = 6.2563
	sim_grads_norm_tr = -0.0484
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9630
	data_grads_norm = 4.5342
	new_data_grads_norm = 6.2380
	old_data_grads_norm = 5.4107
	sim_grads_norm_tr = 0.1189
-- Starting training on experience 188 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7579
	data_grads_norm = 4.6251
	new_data_grads_norm = 6.8758
	old_data_grads_norm = 4.8752
	sim_grads_norm_tr = -0.0018
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0750
	data_grads_norm = 5.0261
	new_data_grads_norm = 7.0640
	old_data_grads_norm = 6.8914
	sim_grads_norm_tr = 0.0657
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2021
	data_grads_norm = 5.4701
	new_data_grads_norm = 7.7131
	old_data_grads_norm = 7.2782
	sim_grads_norm_tr = 0.0099
-- Starting training on experience 189 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7812
	data_grads_norm = 4.6004
	new_data_grads_norm = 7.8224
	old_data_grads_norm = 4.9485
	sim_grads_norm_tr = 0.0060
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1740
	data_grads_norm = 5.4409
	new_data_grads_norm = 6.8521
	old_data_grads_norm = 8.3177
	sim_grads_norm_tr = -0.0332
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8147
	data_grads_norm = 4.5350
	new_data_grads_norm = 6.6915
	old_data_grads_norm = 5.9230
	sim_grads_norm_tr = -0.0433
-- Starting training on experience 190 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1601
	data_grads_norm = 4.7391
	new_data_grads_norm = 6.7549
	old_data_grads_norm = 7.4179
	sim_grads_norm_tr = -0.0517
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3598
	data_grads_norm = 4.2413
	new_data_grads_norm = 7.0425
	old_data_grads_norm = 5.5505
	sim_grads_norm_tr = -0.0511
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4988
	data_grads_norm = 4.0636
	new_data_grads_norm = 7.7261
	old_data_grads_norm = 4.4644
	sim_grads_norm_tr = 0.0036
-- Starting training on experience 191 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7731
	data_grads_norm = 3.9362
	new_data_grads_norm = 6.2504
	old_data_grads_norm = 4.7219
	sim_grads_norm_tr = -0.0077
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5852
	data_grads_norm = 3.9756
	new_data_grads_norm = 6.8378
	old_data_grads_norm = 4.1950
	sim_grads_norm_tr = 0.1023
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7702
	data_grads_norm = 4.2695
	new_data_grads_norm = 6.5223
	old_data_grads_norm = 6.8471
	sim_grads_norm_tr = 0.0422
-- Starting training on experience 192 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3842
	data_grads_norm = 4.5689
	new_data_grads_norm = 5.7457
	old_data_grads_norm = 5.6979
	sim_grads_norm_tr = 0.0118
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3589
	data_grads_norm = 5.0387
	new_data_grads_norm = 7.0495
	old_data_grads_norm = 7.5815
	sim_grads_norm_tr = -0.0507
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9244
	data_grads_norm = 4.1957
	new_data_grads_norm = 6.8648
	old_data_grads_norm = 4.8961
	sim_grads_norm_tr = -0.0385
-- Starting training on experience 193 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9713
	data_grads_norm = 5.0836
	new_data_grads_norm = 8.1365
	old_data_grads_norm = 6.9003
	sim_grads_norm_tr = -0.0578
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8838
	data_grads_norm = 5.4835
	new_data_grads_norm = 7.8714
	old_data_grads_norm = 6.6607
	sim_grads_norm_tr = 0.0327
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3797
	data_grads_norm = 5.3889
	new_data_grads_norm = 8.0968
	old_data_grads_norm = 6.9322
	sim_grads_norm_tr = 0.0369
-- Starting training on experience 194 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1320
	data_grads_norm = 4.9344
	new_data_grads_norm = 5.8069
	old_data_grads_norm = 6.3871
	sim_grads_norm_tr = 0.0625
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1579
	data_grads_norm = 4.3248
	new_data_grads_norm = 6.2639
	old_data_grads_norm = 5.6576
	sim_grads_norm_tr = 0.0497
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9723
	data_grads_norm = 4.0007
	new_data_grads_norm = 5.9245
	old_data_grads_norm = 6.0795
	sim_grads_norm_tr = -0.0288
-- Starting training on experience 195 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8043
	data_grads_norm = 3.8628
	new_data_grads_norm = 6.0285
	old_data_grads_norm = 5.7504
	sim_grads_norm_tr = -0.0150
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0315
	data_grads_norm = 4.0053
	new_data_grads_norm = 5.8963
	old_data_grads_norm = 4.9281
	sim_grads_norm_tr = -0.0004
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7596
	data_grads_norm = 3.3485
	new_data_grads_norm = 6.1615
	old_data_grads_norm = 4.2573
	sim_grads_norm_tr = -0.0180
-- Starting training on experience 196 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6081
	data_grads_norm = 4.5787
	new_data_grads_norm = 7.2694
	old_data_grads_norm = 6.3790
	sim_grads_norm_tr = 0.0155
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8668
	data_grads_norm = 5.2985
	new_data_grads_norm = 7.9382
	old_data_grads_norm = 6.2554
	sim_grads_norm_tr = -0.0156
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2335
	data_grads_norm = 5.6364
	new_data_grads_norm = 8.2137
	old_data_grads_norm = 7.5331
	sim_grads_norm_tr = 0.0920
-- Starting training on experience 197 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9400
	data_grads_norm = 5.2156
	new_data_grads_norm = 7.4034
	old_data_grads_norm = 6.6441
	sim_grads_norm_tr = 0.0337
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8803
	data_grads_norm = 6.0771
	new_data_grads_norm = 7.6480
	old_data_grads_norm = 7.9127
	sim_grads_norm_tr = 0.0294
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1478
	data_grads_norm = 4.2693
	new_data_grads_norm = 7.0255
	old_data_grads_norm = 4.7874
	sim_grads_norm_tr = -0.0146
-- Starting training on experience 198 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5282
	data_grads_norm = 4.6641
	new_data_grads_norm = 7.8426
	old_data_grads_norm = 4.7988
	sim_grads_norm_tr = 0.1239
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3972
	data_grads_norm = 4.9150
	new_data_grads_norm = 7.3582
	old_data_grads_norm = 6.5989
	sim_grads_norm_tr = 0.0542
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6469
	data_grads_norm = 3.5834
	new_data_grads_norm = 7.2075
	old_data_grads_norm = 4.6278
	sim_grads_norm_tr = 0.0374
-- Starting training on experience 199 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9728
	data_grads_norm = 4.5565
	new_data_grads_norm = 7.4573
	old_data_grads_norm = 5.1607
	sim_grads_norm_tr = 0.1067
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5512
	data_grads_norm = 5.5573
	new_data_grads_norm = 7.8537
	old_data_grads_norm = 6.8821
	sim_grads_norm_tr = -0.0006
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0009
	data_grads_norm = 4.6217
	new_data_grads_norm = 6.8928
	old_data_grads_norm = 5.2411
	sim_grads_norm_tr = 0.0775
-- Starting training on experience 200 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2487
	data_grads_norm = 4.8731
	new_data_grads_norm = 7.2459
	old_data_grads_norm = 6.3372
	sim_grads_norm_tr = -0.0829
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5283
	data_grads_norm = 4.8168
	new_data_grads_norm = 7.0867
	old_data_grads_norm = 4.9614
	sim_grads_norm_tr = 0.1239
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0910
	data_grads_norm = 4.8452
	new_data_grads_norm = 7.6548
	old_data_grads_norm = 4.6906
	sim_grads_norm_tr = -0.0387
-- Starting training on experience 201 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1643
	data_grads_norm = 4.6631
	new_data_grads_norm = 7.5358
	old_data_grads_norm = 6.1766
	sim_grads_norm_tr = -0.0015
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4385
	data_grads_norm = 5.3042
	new_data_grads_norm = 8.3245
	old_data_grads_norm = 7.4033
	sim_grads_norm_tr = -0.0201
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3529
	data_grads_norm = 4.5170
	new_data_grads_norm = 8.0063
	old_data_grads_norm = 5.9331
	sim_grads_norm_tr = -0.0371
-- Starting training on experience 202 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1917
	data_grads_norm = 5.7538
	new_data_grads_norm = 8.3105
	old_data_grads_norm = 7.7212
	sim_grads_norm_tr = 0.0488
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4379
	data_grads_norm = 5.2421
	new_data_grads_norm = 7.9269
	old_data_grads_norm = 6.1929
	sim_grads_norm_tr = 0.0253
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8026
	data_grads_norm = 6.2482
	new_data_grads_norm = 8.5890
	old_data_grads_norm = 7.3588
	sim_grads_norm_tr = 0.1223
-- Starting training on experience 203 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1762
	data_grads_norm = 3.9873
	new_data_grads_norm = 6.8484
	old_data_grads_norm = 4.0082
	sim_grads_norm_tr = -0.0122
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9955
	data_grads_norm = 5.2144
	new_data_grads_norm = 7.7288
	old_data_grads_norm = 6.7681
	sim_grads_norm_tr = 0.0349
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4455
	data_grads_norm = 4.8963
	new_data_grads_norm = 7.3026
	old_data_grads_norm = 6.2841
	sim_grads_norm_tr = 0.0149
-- Starting training on experience 204 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4290
	data_grads_norm = 5.5323
	new_data_grads_norm = 6.2668
	old_data_grads_norm = 6.8629
	sim_grads_norm_tr = 0.0071
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5277
	data_grads_norm = 5.7196
	new_data_grads_norm = 6.7189
	old_data_grads_norm = 8.6375
	sim_grads_norm_tr = -0.0061
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2275
	data_grads_norm = 4.2737
	new_data_grads_norm = 6.5037
	old_data_grads_norm = 5.6190
	sim_grads_norm_tr = 0.0153
-- Starting training on experience 205 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3552
	data_grads_norm = 5.3821
	new_data_grads_norm = 7.4899
	old_data_grads_norm = 7.4561
	sim_grads_norm_tr = 0.0231
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3336
	data_grads_norm = 4.6554
	new_data_grads_norm = 7.4340
	old_data_grads_norm = 4.8225
	sim_grads_norm_tr = 0.0748
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4602
	data_grads_norm = 5.2372
	new_data_grads_norm = 7.7335
	old_data_grads_norm = 7.3067
	sim_grads_norm_tr = -0.0196
-- Starting training on experience 206 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6398
	data_grads_norm = 5.6121
	new_data_grads_norm = 8.0330
	old_data_grads_norm = 6.5411
	sim_grads_norm_tr = -0.0019
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5680
	data_grads_norm = 4.9210
	new_data_grads_norm = 7.7367
	old_data_grads_norm = 6.4099
	sim_grads_norm_tr = -0.0025
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9021
	data_grads_norm = 4.6720
	new_data_grads_norm = 7.0160
	old_data_grads_norm = 5.2384
	sim_grads_norm_tr = 0.0333
-- Starting training on experience 207 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3573
	data_grads_norm = 4.1427
	new_data_grads_norm = 7.2830
	old_data_grads_norm = 4.7426
	sim_grads_norm_tr = 0.0026
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6130
	data_grads_norm = 5.3850
	new_data_grads_norm = 8.6481
	old_data_grads_norm = 6.8390
	sim_grads_norm_tr = -0.0069
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7712
	data_grads_norm = 5.4607
	new_data_grads_norm = 7.9313
	old_data_grads_norm = 6.2439
	sim_grads_norm_tr = 0.0806
-- Starting training on experience 208 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3950
	data_grads_norm = 5.2462
	new_data_grads_norm = 7.4177
	old_data_grads_norm = 7.3158
	sim_grads_norm_tr = -0.0169
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5274
	data_grads_norm = 5.1732
	new_data_grads_norm = 6.8641
	old_data_grads_norm = 7.1001
	sim_grads_norm_tr = 0.0006
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7331
	data_grads_norm = 4.8126
	new_data_grads_norm = 7.2950
	old_data_grads_norm = 5.6944
	sim_grads_norm_tr = 0.1060
-- Starting training on experience 209 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5448
	data_grads_norm = 4.0459
	new_data_grads_norm = 6.1731
	old_data_grads_norm = 6.3830
	sim_grads_norm_tr = -0.0134
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4991
	data_grads_norm = 5.0064
	new_data_grads_norm = 6.3624
	old_data_grads_norm = 6.7511
	sim_grads_norm_tr = 0.1051
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7148
	data_grads_norm = 3.9417
	new_data_grads_norm = 6.4641
	old_data_grads_norm = 5.7025
	sim_grads_norm_tr = 0.0071
-- Starting training on experience 210 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2244
	data_grads_norm = 4.6212
	new_data_grads_norm = 6.2168
	old_data_grads_norm = 6.3451
	sim_grads_norm_tr = -0.0134
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6637
	data_grads_norm = 5.9725
	new_data_grads_norm = 6.8073
	old_data_grads_norm = 8.6586
	sim_grads_norm_tr = -0.0244
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8079
	data_grads_norm = 4.7306
	new_data_grads_norm = 7.3027
	old_data_grads_norm = 5.6435
	sim_grads_norm_tr = 0.0590
-- Starting training on experience 211 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9348
	data_grads_norm = 4.2186
	new_data_grads_norm = 7.3892
	old_data_grads_norm = 4.7111
	sim_grads_norm_tr = -0.0280
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9343
	data_grads_norm = 5.6612
	new_data_grads_norm = 7.8128
	old_data_grads_norm = 6.7239
	sim_grads_norm_tr = 0.0185
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4778
	data_grads_norm = 4.5125
	new_data_grads_norm = 7.5634
	old_data_grads_norm = 5.0931
	sim_grads_norm_tr = 0.0111
-- Starting training on experience 212 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8011
	data_grads_norm = 4.1977
	new_data_grads_norm = 6.4738
	old_data_grads_norm = 5.8186
	sim_grads_norm_tr = -0.0552
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3468
	data_grads_norm = 4.5241
	new_data_grads_norm = 6.5247
	old_data_grads_norm = 7.0983
	sim_grads_norm_tr = -0.0292
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9062
	data_grads_norm = 4.4673
	new_data_grads_norm = 6.8347
	old_data_grads_norm = 5.9631
	sim_grads_norm_tr = 0.0208
-- Starting training on experience 213 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6528
	data_grads_norm = 5.2643
	new_data_grads_norm = 6.3279
	old_data_grads_norm = 8.6002
	sim_grads_norm_tr = -0.0094
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6168
	data_grads_norm = 5.0554
	new_data_grads_norm = 6.8122
	old_data_grads_norm = 7.0563
	sim_grads_norm_tr = 0.0061
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8470
	data_grads_norm = 6.1359
	new_data_grads_norm = 6.6002
	old_data_grads_norm = 6.8648
	sim_grads_norm_tr = 0.0050
-- Starting training on experience 214 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2707
	data_grads_norm = 5.3185
	new_data_grads_norm = 6.7109
	old_data_grads_norm = 8.7204
	sim_grads_norm_tr = 0.0137
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3227
	data_grads_norm = 4.5305
	new_data_grads_norm = 6.7276
	old_data_grads_norm = 6.5408
	sim_grads_norm_tr = -0.0146
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4905
	data_grads_norm = 5.2373
	new_data_grads_norm = 7.4666
	old_data_grads_norm = 6.8787
	sim_grads_norm_tr = 0.0774
-- Starting training on experience 215 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8102
	data_grads_norm = 4.3534
	new_data_grads_norm = 6.8122
	old_data_grads_norm = 5.1028
	sim_grads_norm_tr = -0.0115
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5159
	data_grads_norm = 5.3608
	new_data_grads_norm = 7.2421
	old_data_grads_norm = 6.4480
	sim_grads_norm_tr = 0.0181
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4132
	data_grads_norm = 6.1084
	new_data_grads_norm = 7.1479
	old_data_grads_norm = 8.9388
	sim_grads_norm_tr = -0.0155
-- Starting training on experience 216 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0146
	data_grads_norm = 6.5492
	new_data_grads_norm = 8.9915
	old_data_grads_norm = 7.0752
	sim_grads_norm_tr = 0.0214
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4013
	data_grads_norm = 5.7436
	new_data_grads_norm = 9.1241
	old_data_grads_norm = 4.2941
	sim_grads_norm_tr = 0.0876
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3350
	data_grads_norm = 4.9377
	new_data_grads_norm = 8.9672
	old_data_grads_norm = 4.9943
	sim_grads_norm_tr = -0.0808
-- Starting training on experience 217 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3102
	data_grads_norm = 4.8680
	new_data_grads_norm = 7.1787
	old_data_grads_norm = 6.5291
	sim_grads_norm_tr = -0.0329
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8766
	data_grads_norm = 5.3281
	new_data_grads_norm = 8.4747
	old_data_grads_norm = 7.2963
	sim_grads_norm_tr = -0.0073
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8375
	data_grads_norm = 5.6983
	new_data_grads_norm = 8.0797
	old_data_grads_norm = 7.2634
	sim_grads_norm_tr = 0.0147
-- Starting training on experience 218 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4038
	data_grads_norm = 5.0504
	new_data_grads_norm = 6.6387
	old_data_grads_norm = 6.7772
	sim_grads_norm_tr = 0.0091
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3803
	data_grads_norm = 5.0779
	new_data_grads_norm = 7.3316
	old_data_grads_norm = 5.7600
	sim_grads_norm_tr = -0.0081
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0902
	data_grads_norm = 5.6578
	new_data_grads_norm = 6.4425
	old_data_grads_norm = 6.7001
	sim_grads_norm_tr = -0.0364
-- Starting training on experience 219 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2643
	data_grads_norm = 4.5851
	new_data_grads_norm = 7.7005
	old_data_grads_norm = 5.2925
	sim_grads_norm_tr = 0.0168
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4621
	data_grads_norm = 4.8263
	new_data_grads_norm = 7.8397
	old_data_grads_norm = 4.8729
	sim_grads_norm_tr = 0.0364
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5456
	data_grads_norm = 5.4730
	new_data_grads_norm = 8.0921
	old_data_grads_norm = 7.3475
	sim_grads_norm_tr = -0.0173
-- Starting training on experience 220 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1762
	data_grads_norm = 4.5016
	new_data_grads_norm = 9.1138
	old_data_grads_norm = 5.4108
	sim_grads_norm_tr = -0.0392
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7403
	data_grads_norm = 5.7314
	new_data_grads_norm = 8.8456
	old_data_grads_norm = 6.4999
	sim_grads_norm_tr = -0.0625
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3958
	data_grads_norm = 4.9785
	new_data_grads_norm = 9.4650
	old_data_grads_norm = 3.4910
	sim_grads_norm_tr = -0.0434
-- Starting training on experience 221 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5741
	data_grads_norm = 4.7291
	new_data_grads_norm = 6.3422
	old_data_grads_norm = 5.9426
	sim_grads_norm_tr = -0.0154
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3995
	data_grads_norm = 4.9798
	new_data_grads_norm = 5.5280
	old_data_grads_norm = 7.6929
	sim_grads_norm_tr = 0.0195
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5219
	data_grads_norm = 5.1419
	new_data_grads_norm = 6.4207
	old_data_grads_norm = 6.7330
	sim_grads_norm_tr = 0.1134
-- Starting training on experience 222 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7852
	data_grads_norm = 5.8741
	new_data_grads_norm = 8.5791
	old_data_grads_norm = 6.2112
	sim_grads_norm_tr = 0.0267
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1473
	data_grads_norm = 4.6339
	new_data_grads_norm = 7.1893
	old_data_grads_norm = 5.2002
	sim_grads_norm_tr = -0.0207
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1320
	data_grads_norm = 4.5260
	new_data_grads_norm = 7.2579
	old_data_grads_norm = 5.0223
	sim_grads_norm_tr = 0.0448
-- Starting training on experience 223 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9165
	data_grads_norm = 4.5270
	new_data_grads_norm = 6.7974
	old_data_grads_norm = 6.7539
	sim_grads_norm_tr = -0.0410
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9867
	data_grads_norm = 4.1683
	new_data_grads_norm = 6.5018
	old_data_grads_norm = 5.0610
	sim_grads_norm_tr = 0.0132
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1164
	data_grads_norm = 4.3565
	new_data_grads_norm = 6.7564
	old_data_grads_norm = 6.3463
	sim_grads_norm_tr = 0.0375
-- Starting training on experience 224 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6254
	data_grads_norm = 4.9891
	new_data_grads_norm = 7.3404
	old_data_grads_norm = 6.1720
	sim_grads_norm_tr = 0.1281
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0186
	data_grads_norm = 4.6680
	new_data_grads_norm = 6.8720
	old_data_grads_norm = 5.1430
	sim_grads_norm_tr = 0.0094
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2386
	data_grads_norm = 4.5355
	new_data_grads_norm = 7.3081
	old_data_grads_norm = 4.8371
	sim_grads_norm_tr = -0.0144
-- Starting training on experience 225 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6148
	data_grads_norm = 5.2067
	new_data_grads_norm = 6.2501
	old_data_grads_norm = 7.4999
	sim_grads_norm_tr = -0.0019
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3769
	data_grads_norm = 4.1351
	new_data_grads_norm = 6.2149
	old_data_grads_norm = 4.6342
	sim_grads_norm_tr = -0.0012
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2038
	data_grads_norm = 4.0873
	new_data_grads_norm = 6.3121
	old_data_grads_norm = 4.8736
	sim_grads_norm_tr = 0.0004
-- Starting training on experience 226 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2032
	data_grads_norm = 5.3897
	new_data_grads_norm = 6.9169
	old_data_grads_norm = 7.1916
	sim_grads_norm_tr = 0.1343
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0459
	data_grads_norm = 4.4115
	new_data_grads_norm = 6.2848
	old_data_grads_norm = 6.7879
	sim_grads_norm_tr = -0.0494
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4781
	data_grads_norm = 4.4332
	new_data_grads_norm = 6.1763
	old_data_grads_norm = 6.3009
	sim_grads_norm_tr = -0.0834
-- Starting training on experience 227 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5614
	data_grads_norm = 5.2295
	new_data_grads_norm = 6.6854
	old_data_grads_norm = 6.6168
	sim_grads_norm_tr = 0.0599
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9266
	data_grads_norm = 4.5770
	new_data_grads_norm = 6.3863
	old_data_grads_norm = 5.7507
	sim_grads_norm_tr = 0.0027
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7060
	data_grads_norm = 3.8501
	new_data_grads_norm = 6.3347
	old_data_grads_norm = 4.8067
	sim_grads_norm_tr = -0.0164
-- Starting training on experience 228 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3669
	data_grads_norm = 5.1034
	new_data_grads_norm = 7.6957
	old_data_grads_norm = 6.2741
	sim_grads_norm_tr = -0.0257
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8782
	data_grads_norm = 4.2216
	new_data_grads_norm = 8.1042
	old_data_grads_norm = 4.5399
	sim_grads_norm_tr = -0.0558
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5040
	data_grads_norm = 6.0009
	new_data_grads_norm = 8.2734
	old_data_grads_norm = 8.0971
	sim_grads_norm_tr = -0.0139
-- Starting training on experience 229 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7195
	data_grads_norm = 5.1191
	new_data_grads_norm = 7.5909
	old_data_grads_norm = 6.5087
	sim_grads_norm_tr = 0.0572
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2526
	data_grads_norm = 4.6208
	new_data_grads_norm = 7.0738
	old_data_grads_norm = 5.6231
	sim_grads_norm_tr = -0.0422
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5766
	data_grads_norm = 7.0954
	new_data_grads_norm = 8.1038
	old_data_grads_norm = 9.9462
	sim_grads_norm_tr = 0.0193
-- Starting training on experience 230 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3970
	data_grads_norm = 4.8543
	new_data_grads_norm = 7.3957
	old_data_grads_norm = 5.8380
	sim_grads_norm_tr = -0.0047
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4954
	data_grads_norm = 4.7750
	new_data_grads_norm = 7.6574
	old_data_grads_norm = 5.9111
	sim_grads_norm_tr = 0.0062
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6429
	data_grads_norm = 5.4101
	new_data_grads_norm = 7.0668
	old_data_grads_norm = 8.4799
	sim_grads_norm_tr = -0.0386
-- Starting training on experience 231 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7126
	data_grads_norm = 5.0357
	new_data_grads_norm = 6.7885
	old_data_grads_norm = 6.0087
	sim_grads_norm_tr = -0.0381
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8763
	data_grads_norm = 5.6430
	new_data_grads_norm = 6.9027
	old_data_grads_norm = 5.1865
	sim_grads_norm_tr = 0.1499
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6853
	data_grads_norm = 5.5645
	new_data_grads_norm = 6.7926
	old_data_grads_norm = 6.4397
	sim_grads_norm_tr = 0.0158
-- Starting training on experience 232 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1589
	data_grads_norm = 4.5999
	new_data_grads_norm = 7.1835
	old_data_grads_norm = 6.3550
	sim_grads_norm_tr = 0.0692
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5025
	data_grads_norm = 4.9664
	new_data_grads_norm = 7.1626
	old_data_grads_norm = 5.9992
	sim_grads_norm_tr = 0.1253
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8475
	data_grads_norm = 5.9587
	new_data_grads_norm = 6.5946
	old_data_grads_norm = 8.4612
	sim_grads_norm_tr = -0.0079
-- Starting training on experience 233 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4167
	data_grads_norm = 5.3747
	new_data_grads_norm = 7.4022
	old_data_grads_norm = 7.0703
	sim_grads_norm_tr = 0.0667
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1379
	data_grads_norm = 4.2593
	new_data_grads_norm = 6.2112
	old_data_grads_norm = 4.9440
	sim_grads_norm_tr = 0.0626
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7225
	data_grads_norm = 5.1732
	new_data_grads_norm = 6.4684
	old_data_grads_norm = 8.4304
	sim_grads_norm_tr = 0.0240
-- Starting training on experience 234 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3329
	data_grads_norm = 5.6935
	new_data_grads_norm = 8.4313
	old_data_grads_norm = 5.9477
	sim_grads_norm_tr = -0.0290
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6461
	data_grads_norm = 5.9254
	new_data_grads_norm = 8.3290
	old_data_grads_norm = 6.2443
	sim_grads_norm_tr = -0.0453
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0331
	data_grads_norm = 4.6691
	new_data_grads_norm = 8.0879
	old_data_grads_norm = 5.3830
	sim_grads_norm_tr = -0.0279
-- Starting training on experience 235 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2872
	data_grads_norm = 5.1261
	new_data_grads_norm = 7.7063
	old_data_grads_norm = 6.3717
	sim_grads_norm_tr = 0.0178
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0222
	data_grads_norm = 4.3577
	new_data_grads_norm = 7.4316
	old_data_grads_norm = 4.3330
	sim_grads_norm_tr = -0.1203
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4975
	data_grads_norm = 5.4651
	new_data_grads_norm = 7.5203
	old_data_grads_norm = 6.9634
	sim_grads_norm_tr = 0.0021
-- Starting training on experience 236 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9310
	data_grads_norm = 4.1972
	new_data_grads_norm = 7.0417
	old_data_grads_norm = 4.6038
	sim_grads_norm_tr = -0.0200
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5498
	data_grads_norm = 5.1428
	new_data_grads_norm = 7.3121
	old_data_grads_norm = 5.9589
	sim_grads_norm_tr = 0.1041
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7538
	data_grads_norm = 4.1758
	new_data_grads_norm = 7.6383
	old_data_grads_norm = 3.5519
	sim_grads_norm_tr = -0.0153
-- Starting training on experience 237 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
-- >> End of training phase << --
-- >> Start of eval phase << --
-- Starting eval on experience 0 (Task 0) from test stream --
> Eval on experience 0 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp000 = 2.6948
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.3780
	mb_index = 2618
	time = 812.1254
-- Starting eval on experience 1 (Task 0) from test stream --
> Eval on experience 1 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp001 = 2.4088
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.4840
-- Starting eval on experience 2 (Task 0) from test stream --
> Eval on experience 2 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp002 = 2.9387
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.3580
-- Starting eval on experience 3 (Task 0) from test stream --
> Eval on experience 3 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp003 = 2.1980
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.4940
-- Starting eval on experience 4 (Task 0) from test stream --
> Eval on experience 4 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp004 = 3.3649
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.2760
-- Starting eval on experience 5 (Task 0) from test stream --
> Eval on experience 5 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp005 = 2.4993
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.4260
-- Starting eval on experience 6 (Task 0) from test stream --
> Eval on experience 6 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp006 = 2.6558
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp006 = 0.3560
-- Starting eval on experience 7 (Task 0) from test stream --
> Eval on experience 7 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp007 = 2.7209
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp007 = 0.3840
-- Starting eval on experience 8 (Task 0) from test stream --
> Eval on experience 8 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp008 = 2.9218
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp008 = 0.2620
-- Starting eval on experience 9 (Task 0) from test stream --
> Eval on experience 9 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp009 = 2.8006
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp009 = 0.2960
-- Starting eval on experience 10 (Task 0) from test stream --
> Eval on experience 10 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp010 = 3.7691
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp010 = 0.0540
-- >> End of eval phase << --
	CumulativeAccuracy/eval_phase/test_stream/Exp000 = 0.7620
	CumulativeAccuracy/eval_phase/test_stream/Exp001 = 0.6840
	CumulativeAccuracy/eval_phase/test_stream/Exp002 = 0.5933
	CumulativeAccuracy/eval_phase/test_stream/Exp003 = 0.5715
	CumulativeAccuracy/eval_phase/test_stream/Exp004 = 0.5268
	CumulativeAccuracy/eval_phase/test_stream/Exp005 = 0.4797
	CumulativeAccuracy/eval_phase/test_stream/Exp006 = 0.4414
	CumulativeAccuracy/eval_phase/test_stream/Exp007 = 0.4210
	CumulativeAccuracy/eval_phase/test_stream/Exp008 = 0.3916
	CumulativeAccuracy/eval_phase/test_stream/Exp009 = 0.3738
	CumulativeAccuracy/eval_phase/test_stream/Exp010 = 0.3425
	Loss_Stream/eval_phase/test_stream/Task000 = 2.8157
	Top1_Acc_Stream/eval_phase/test_stream/Task000 = 0.3425
-- >> Start of training phase << --
-- Starting training on experience 0 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0913
	data_grads_norm = 5.0127
	new_data_grads_norm = 7.6959
	old_data_grads_norm = 5.2430
	sim_grads_norm_tr = -0.0110
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1585
	data_grads_norm = 5.3402
	new_data_grads_norm = 8.1419
	old_data_grads_norm = 6.2366
	sim_grads_norm_tr = -0.0030
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3353
	data_grads_norm = 5.7466
	new_data_grads_norm = 7.7586
	old_data_grads_norm = 7.1821
	sim_grads_norm_tr = 0.0464
-- Starting training on experience 1 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1371
	data_grads_norm = 4.6987
	new_data_grads_norm = 7.6212
	old_data_grads_norm = 5.8543
	sim_grads_norm_tr = -0.0117
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2026
	data_grads_norm = 5.2852
	new_data_grads_norm = 7.4732
	old_data_grads_norm = 6.3051
	sim_grads_norm_tr = -0.0009
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4099
	data_grads_norm = 5.0116
	new_data_grads_norm = 7.9967
	old_data_grads_norm = 5.0717
	sim_grads_norm_tr = -0.0151
-- Starting training on experience 2 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6936
	data_grads_norm = 4.8134
	new_data_grads_norm = 7.7901
	old_data_grads_norm = 4.9865
	sim_grads_norm_tr = -0.0105
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2923
	data_grads_norm = 5.5339
	new_data_grads_norm = 8.0817
	old_data_grads_norm = 5.8760
	sim_grads_norm_tr = 0.0059
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2040
	data_grads_norm = 5.0334
	new_data_grads_norm = 7.6736
	old_data_grads_norm = 4.7457
	sim_grads_norm_tr = 0.0355
-- Starting training on experience 3 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3558
	data_grads_norm = 5.7998
	new_data_grads_norm = 9.1375
	old_data_grads_norm = 5.2412
	sim_grads_norm_tr = -0.0209
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1460
	data_grads_norm = 5.9018
	new_data_grads_norm = 8.6223
	old_data_grads_norm = 6.4478
	sim_grads_norm_tr = 0.0297
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1475
	data_grads_norm = 5.2521
	new_data_grads_norm = 8.0977
	old_data_grads_norm = 6.2257
	sim_grads_norm_tr = -0.0132
-- Starting training on experience 4 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2068
	data_grads_norm = 6.5230
	new_data_grads_norm = 8.8076
	old_data_grads_norm = 6.6649
	sim_grads_norm_tr = -0.0122
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0556
	data_grads_norm = 6.5929
	new_data_grads_norm = 7.9103
	old_data_grads_norm = 8.0850
	sim_grads_norm_tr = 0.0551
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0945
	data_grads_norm = 5.6798
	new_data_grads_norm = 8.5362
	old_data_grads_norm = 7.1251
	sim_grads_norm_tr = -0.0323
-- Starting training on experience 5 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5836
	data_grads_norm = 5.7113
	new_data_grads_norm = 7.8743
	old_data_grads_norm = 8.0781
	sim_grads_norm_tr = 0.0439
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2717
	data_grads_norm = 5.0938
	new_data_grads_norm = 6.7641
	old_data_grads_norm = 5.6942
	sim_grads_norm_tr = -0.0071
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0188
	data_grads_norm = 5.5419
	new_data_grads_norm = 7.3229
	old_data_grads_norm = 7.2275
	sim_grads_norm_tr = -0.0405
-- Starting training on experience 6 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3361
	data_grads_norm = 5.1647
	new_data_grads_norm = 7.8463
	old_data_grads_norm = 5.3636
	sim_grads_norm_tr = -0.0160
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5850
	data_grads_norm = 5.6177
	new_data_grads_norm = 8.3950
	old_data_grads_norm = 5.9019
	sim_grads_norm_tr = 0.0226
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.7794
	data_grads_norm = 5.7469
	new_data_grads_norm = 8.3216
	old_data_grads_norm = 7.6761
	sim_grads_norm_tr = 0.0471
-- Starting training on experience 7 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4930
	data_grads_norm = 5.3602
	new_data_grads_norm = 7.0218
	old_data_grads_norm = 7.8613
	sim_grads_norm_tr = 0.0529
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7009
	data_grads_norm = 4.8672
	new_data_grads_norm = 7.5548
	old_data_grads_norm = 6.2685
	sim_grads_norm_tr = -0.0147
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6191
	data_grads_norm = 4.4415
	new_data_grads_norm = 6.9425
	old_data_grads_norm = 5.5686
	sim_grads_norm_tr = 0.0163
-- Starting training on experience 8 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5092
	data_grads_norm = 4.2048
	new_data_grads_norm = 6.5194
	old_data_grads_norm = 5.2131
	sim_grads_norm_tr = -0.0175
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1237
	data_grads_norm = 5.0947
	new_data_grads_norm = 7.5060
	old_data_grads_norm = 7.2004
	sim_grads_norm_tr = 0.0041
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2568
	data_grads_norm = 4.4723
	new_data_grads_norm = 7.3915
	old_data_grads_norm = 4.7821
	sim_grads_norm_tr = -0.0080
-- Starting training on experience 9 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1544
	data_grads_norm = 5.7939
	new_data_grads_norm = 7.7633
	old_data_grads_norm = 6.2075
	sim_grads_norm_tr = -0.0032
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4392
	data_grads_norm = 5.7972
	new_data_grads_norm = 7.8544
	old_data_grads_norm = 7.7246
	sim_grads_norm_tr = -0.0560
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2089
	data_grads_norm = 5.2732
	new_data_grads_norm = 7.5272
	old_data_grads_norm = 5.9655
	sim_grads_norm_tr = 0.0706
-- Starting training on experience 10 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8170
	data_grads_norm = 5.4244
	new_data_grads_norm = 7.1763
	old_data_grads_norm = 5.2469
	sim_grads_norm_tr = 0.0109
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6253
	data_grads_norm = 5.1942
	new_data_grads_norm = 7.2521
	old_data_grads_norm = 4.4442
	sim_grads_norm_tr = -0.0036
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9096
	data_grads_norm = 5.5520
	new_data_grads_norm = 7.4537
	old_data_grads_norm = 6.4111
	sim_grads_norm_tr = -0.0009
-- Starting training on experience 11 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.7584
	data_grads_norm = 5.2671
	new_data_grads_norm = 6.8055
	old_data_grads_norm = 6.6383
	sim_grads_norm_tr = 0.0844
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6888
	data_grads_norm = 5.2891
	new_data_grads_norm = 6.7101
	old_data_grads_norm = 7.2873
	sim_grads_norm_tr = 0.0008
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3494
	data_grads_norm = 5.8011
	new_data_grads_norm = 6.6448
	old_data_grads_norm = 10.1729
	sim_grads_norm_tr = 0.0345
-- Starting training on experience 12 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1644
	data_grads_norm = 4.7725
	new_data_grads_norm = 6.9852
	old_data_grads_norm = 5.7230
	sim_grads_norm_tr = -0.0146
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3005
	data_grads_norm = 5.6735
	new_data_grads_norm = 6.9324
	old_data_grads_norm = 7.9772
	sim_grads_norm_tr = -0.0080
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3704
	data_grads_norm = 5.0883
	new_data_grads_norm = 6.9884
	old_data_grads_norm = 6.9414
	sim_grads_norm_tr = 0.0001
-- Starting training on experience 13 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9254
	data_grads_norm = 5.1181
	new_data_grads_norm = 6.2716
	old_data_grads_norm = 8.7271
	sim_grads_norm_tr = -0.0283
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6300
	data_grads_norm = 4.9184
	new_data_grads_norm = 7.7990
	old_data_grads_norm = 5.5829
	sim_grads_norm_tr = -0.0034
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1544
	data_grads_norm = 5.6788
	new_data_grads_norm = 6.9901
	old_data_grads_norm = 7.4996
	sim_grads_norm_tr = 0.1219
-- Starting training on experience 14 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9546
	data_grads_norm = 6.1761
	new_data_grads_norm = 7.8268
	old_data_grads_norm = 8.7611
	sim_grads_norm_tr = -0.0323
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9670
	data_grads_norm = 5.8801
	new_data_grads_norm = 7.3444
	old_data_grads_norm = 8.2490
	sim_grads_norm_tr = 0.0679
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3127
	data_grads_norm = 4.5409
	new_data_grads_norm = 6.9031
	old_data_grads_norm = 5.4568
	sim_grads_norm_tr = -0.0346
-- Starting training on experience 15 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6006
	data_grads_norm = 6.2717
	new_data_grads_norm = 7.1213
	old_data_grads_norm = 7.9601
	sim_grads_norm_tr = 0.0292
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8631
	data_grads_norm = 4.4497
	new_data_grads_norm = 7.1534
	old_data_grads_norm = 4.9679
	sim_grads_norm_tr = 0.0493
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5720
	data_grads_norm = 6.1549
	new_data_grads_norm = 7.5037
	old_data_grads_norm = 8.8149
	sim_grads_norm_tr = 0.0384
-- Starting training on experience 16 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3131
	data_grads_norm = 4.2126
	new_data_grads_norm = 7.0492
	old_data_grads_norm = 4.5266
	sim_grads_norm_tr = -0.0070
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4884
	data_grads_norm = 5.1849
	new_data_grads_norm = 7.3966
	old_data_grads_norm = 6.0866
	sim_grads_norm_tr = 0.0166
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4282
	data_grads_norm = 4.7388
	new_data_grads_norm = 7.6310
	old_data_grads_norm = 4.6767
	sim_grads_norm_tr = 0.0451
-- Starting training on experience 17 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0939
	data_grads_norm = 5.2228
	new_data_grads_norm = 7.0648
	old_data_grads_norm = 6.8774
	sim_grads_norm_tr = 0.0142
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6944
	data_grads_norm = 4.9796
	new_data_grads_norm = 6.8559
	old_data_grads_norm = 6.0002
	sim_grads_norm_tr = 0.0186
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2418
	data_grads_norm = 5.2042
	new_data_grads_norm = 7.2434
	old_data_grads_norm = 5.4620
	sim_grads_norm_tr = 0.1794
-- Starting training on experience 18 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7117
	data_grads_norm = 4.3553
	new_data_grads_norm = 6.7599
	old_data_grads_norm = 5.4637
	sim_grads_norm_tr = 0.0191
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3983
	data_grads_norm = 5.0795
	new_data_grads_norm = 7.2046
	old_data_grads_norm = 7.8256
	sim_grads_norm_tr = 0.0247
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5232
	data_grads_norm = 5.2195
	new_data_grads_norm = 7.1979
	old_data_grads_norm = 6.0711
	sim_grads_norm_tr = 0.0090
-- Starting training on experience 19 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3029
	data_grads_norm = 5.1292
	new_data_grads_norm = 6.5955
	old_data_grads_norm = 6.6730
	sim_grads_norm_tr = -0.0234
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3833
	data_grads_norm = 5.0387
	new_data_grads_norm = 6.6994
	old_data_grads_norm = 5.9231
	sim_grads_norm_tr = 0.0214
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7967
	data_grads_norm = 5.7839
	new_data_grads_norm = 6.6390
	old_data_grads_norm = 8.0792
	sim_grads_norm_tr = -0.0131
-- Starting training on experience 20 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5091
	data_grads_norm = 4.5965
	new_data_grads_norm = 7.1388
	old_data_grads_norm = 4.9856
	sim_grads_norm_tr = 0.0064
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3919
	data_grads_norm = 4.9590
	new_data_grads_norm = 7.0380
	old_data_grads_norm = 7.2845
	sim_grads_norm_tr = -0.0070
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8186
	data_grads_norm = 5.7196
	new_data_grads_norm = 7.7247
	old_data_grads_norm = 7.3396
	sim_grads_norm_tr = -0.0008
-- Starting training on experience 21 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5270
	data_grads_norm = 5.9698
	new_data_grads_norm = 7.7486
	old_data_grads_norm = 7.5196
	sim_grads_norm_tr = 0.0046
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2382
	data_grads_norm = 4.8248
	new_data_grads_norm = 7.5514
	old_data_grads_norm = 6.3685
	sim_grads_norm_tr = 0.0277
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6727
	data_grads_norm = 5.1327
	new_data_grads_norm = 7.1324
	old_data_grads_norm = 6.1673
	sim_grads_norm_tr = 0.0497
-- Starting training on experience 22 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9796
	data_grads_norm = 5.0022
	new_data_grads_norm = 7.2616
	old_data_grads_norm = 6.3345
	sim_grads_norm_tr = -0.0063
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4172
	data_grads_norm = 5.3040
	new_data_grads_norm = 7.5733
	old_data_grads_norm = 7.3574
	sim_grads_norm_tr = 0.0203
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5417
	data_grads_norm = 5.3549
	new_data_grads_norm = 7.5047
	old_data_grads_norm = 7.0261
	sim_grads_norm_tr = 0.0459
-- Starting training on experience 23 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4260
	data_grads_norm = 5.2855
	new_data_grads_norm = 7.2871
	old_data_grads_norm = 6.9979
	sim_grads_norm_tr = -0.0609
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1627
	data_grads_norm = 5.2680
	new_data_grads_norm = 7.6056
	old_data_grads_norm = 5.9234
	sim_grads_norm_tr = 0.0143
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0624
	data_grads_norm = 4.4050
	new_data_grads_norm = 7.3834
	old_data_grads_norm = 4.3795
	sim_grads_norm_tr = 0.0148
-- Starting training on experience 24 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8134
	data_grads_norm = 5.0881
	new_data_grads_norm = 6.8001
	old_data_grads_norm = 6.0536
	sim_grads_norm_tr = -0.0028
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0149
	data_grads_norm = 5.0497
	new_data_grads_norm = 7.1721
	old_data_grads_norm = 6.0510
	sim_grads_norm_tr = 0.0267
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8883
	data_grads_norm = 4.2839
	new_data_grads_norm = 6.6015
	old_data_grads_norm = 4.7714
	sim_grads_norm_tr = 0.0360
-- Starting training on experience 25 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6368
	data_grads_norm = 4.7442
	new_data_grads_norm = 6.2436
	old_data_grads_norm = 3.7277
	sim_grads_norm_tr = -0.0146
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5496
	data_grads_norm = 5.3426
	new_data_grads_norm = 7.2843
	old_data_grads_norm = 6.1901
	sim_grads_norm_tr = 0.0145
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2233
	data_grads_norm = 4.9550
	new_data_grads_norm = 6.5829
	old_data_grads_norm = 6.3185
	sim_grads_norm_tr = -0.0226
-- Starting training on experience 26 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9075
	data_grads_norm = 5.0791
	new_data_grads_norm = 6.9817
	old_data_grads_norm = 6.9901
	sim_grads_norm_tr = -0.0128
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9607
	data_grads_norm = 4.6154
	new_data_grads_norm = 7.7200
	old_data_grads_norm = 4.7668
	sim_grads_norm_tr = 0.0419
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5750
	data_grads_norm = 4.8879
	new_data_grads_norm = 7.1870
	old_data_grads_norm = 4.7581
	sim_grads_norm_tr = 0.0271
-- Starting training on experience 27 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5872
	data_grads_norm = 4.6449
	new_data_grads_norm = 6.9274
	old_data_grads_norm = 4.8477
	sim_grads_norm_tr = 0.1060
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7274
	data_grads_norm = 3.5965
	new_data_grads_norm = 6.3868
	old_data_grads_norm = 3.7914
	sim_grads_norm_tr = -0.0278
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6657
	data_grads_norm = 5.8180
	new_data_grads_norm = 6.5043
	old_data_grads_norm = 8.9802
	sim_grads_norm_tr = -0.0211
-- Starting training on experience 28 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9101
	data_grads_norm = 4.5058
	new_data_grads_norm = 6.8517
	old_data_grads_norm = 5.8059
	sim_grads_norm_tr = 0.0002
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7045
	data_grads_norm = 3.9909
	new_data_grads_norm = 7.6422
	old_data_grads_norm = 4.1903
	sim_grads_norm_tr = 0.0895
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1811
	data_grads_norm = 4.4236
	new_data_grads_norm = 6.7302
	old_data_grads_norm = 5.0441
	sim_grads_norm_tr = -0.0269
-- Starting training on experience 29 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9099
	data_grads_norm = 4.7808
	new_data_grads_norm = 7.8265
	old_data_grads_norm = 4.9574
	sim_grads_norm_tr = -0.0552
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2546
	data_grads_norm = 4.6981
	new_data_grads_norm = 7.7351
	old_data_grads_norm = 5.3190
	sim_grads_norm_tr = -0.0364
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7023
	data_grads_norm = 5.5750
	new_data_grads_norm = 8.5757
	old_data_grads_norm = 7.3685
	sim_grads_norm_tr = 0.0338
-- Starting training on experience 30 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7738
	data_grads_norm = 4.0922
	new_data_grads_norm = 6.3786
	old_data_grads_norm = 5.0030
	sim_grads_norm_tr = 0.0570
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4126
	data_grads_norm = 4.0242
	new_data_grads_norm = 5.9310
	old_data_grads_norm = 4.7101
	sim_grads_norm_tr = 0.0463
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1899
	data_grads_norm = 5.5529
	new_data_grads_norm = 7.2995
	old_data_grads_norm = 7.5948
	sim_grads_norm_tr = -0.0231
-- Starting training on experience 31 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1770
	data_grads_norm = 5.4906
	new_data_grads_norm = 6.4809
	old_data_grads_norm = 6.7396
	sim_grads_norm_tr = -0.0156
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1465
	data_grads_norm = 4.0720
	new_data_grads_norm = 6.3087
	old_data_grads_norm = 5.5559
	sim_grads_norm_tr = 0.0062
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6251
	data_grads_norm = 5.0337
	new_data_grads_norm = 6.5256
	old_data_grads_norm = 7.1652
	sim_grads_norm_tr = -0.0191
-- Starting training on experience 32 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3000
	data_grads_norm = 6.1071
	new_data_grads_norm = 7.3683
	old_data_grads_norm = 7.6494
	sim_grads_norm_tr = -0.0222
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7940
	data_grads_norm = 4.7353
	new_data_grads_norm = 6.5304
	old_data_grads_norm = 4.9772
	sim_grads_norm_tr = 0.0282
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9264
	data_grads_norm = 4.7027
	new_data_grads_norm = 6.9928
	old_data_grads_norm = 5.8703
	sim_grads_norm_tr = 0.0115
-- Starting training on experience 33 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5222
	data_grads_norm = 3.8631
	new_data_grads_norm = 6.2137
	old_data_grads_norm = 3.6628
	sim_grads_norm_tr = 0.1201
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4865
	data_grads_norm = 4.4096
	new_data_grads_norm = 6.1321
	old_data_grads_norm = 6.0353
	sim_grads_norm_tr = 0.0146
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2562
	data_grads_norm = 3.9345
	new_data_grads_norm = 5.7724
	old_data_grads_norm = 5.2315
	sim_grads_norm_tr = -0.0443
-- Starting training on experience 34 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3814
	data_grads_norm = 5.1535
	new_data_grads_norm = 6.4114
	old_data_grads_norm = 7.5915
	sim_grads_norm_tr = 0.0061
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9760
	data_grads_norm = 4.4365
	new_data_grads_norm = 6.3566
	old_data_grads_norm = 6.3014
	sim_grads_norm_tr = -0.0010
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1284
	data_grads_norm = 4.9376
	new_data_grads_norm = 6.1905
	old_data_grads_norm = 6.7802
	sim_grads_norm_tr = 0.0140
-- Starting training on experience 35 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7119
	data_grads_norm = 4.2905
	new_data_grads_norm = 6.2745
	old_data_grads_norm = 5.0693
	sim_grads_norm_tr = -0.0212
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4202
	data_grads_norm = 3.7786
	new_data_grads_norm = 5.9232
	old_data_grads_norm = 4.5829
	sim_grads_norm_tr = -0.0142
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8827
	data_grads_norm = 4.7715
	new_data_grads_norm = 6.4531
	old_data_grads_norm = 6.8457
	sim_grads_norm_tr = 0.0503
-- Starting training on experience 36 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4108
	data_grads_norm = 5.7645
	new_data_grads_norm = 7.4587
	old_data_grads_norm = 8.3023
	sim_grads_norm_tr = 0.0257
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9516
	data_grads_norm = 5.7775
	new_data_grads_norm = 6.8615
	old_data_grads_norm = 6.9750
	sim_grads_norm_tr = -0.0066
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1272
	data_grads_norm = 5.0264
	new_data_grads_norm = 7.2071
	old_data_grads_norm = 5.9902
	sim_grads_norm_tr = 0.0232
-- Starting training on experience 37 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7202
	data_grads_norm = 4.6210
	new_data_grads_norm = 6.2331
	old_data_grads_norm = 5.9772
	sim_grads_norm_tr = 0.0544
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9806
	data_grads_norm = 5.1932
	new_data_grads_norm = 5.8843
	old_data_grads_norm = 7.2816
	sim_grads_norm_tr = 0.0123
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2610
	data_grads_norm = 3.6455
	new_data_grads_norm = 6.2633
	old_data_grads_norm = 4.2110
	sim_grads_norm_tr = -0.0045
-- Starting training on experience 38 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4245
	data_grads_norm = 5.3135
	new_data_grads_norm = 6.4265
	old_data_grads_norm = 7.7088
	sim_grads_norm_tr = 0.0557
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5859
	data_grads_norm = 4.4372
	new_data_grads_norm = 5.5188
	old_data_grads_norm = 6.4393
	sim_grads_norm_tr = -0.0342
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4007
	data_grads_norm = 4.3121
	new_data_grads_norm = 5.8073
	old_data_grads_norm = 6.6000
	sim_grads_norm_tr = 0.0125
-- Starting training on experience 39 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6492
	data_grads_norm = 5.0848
	new_data_grads_norm = 6.2234
	old_data_grads_norm = 6.7192
	sim_grads_norm_tr = -0.0620
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9524
	data_grads_norm = 5.5802
	new_data_grads_norm = 7.4483
	old_data_grads_norm = 6.5968
	sim_grads_norm_tr = 0.0362
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3820
	data_grads_norm = 3.6759
	new_data_grads_norm = 5.7433
	old_data_grads_norm = 5.1890
	sim_grads_norm_tr = -0.0271
-- Starting training on experience 40 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9738
	data_grads_norm = 4.8920
	new_data_grads_norm = 7.5000
	old_data_grads_norm = 5.6531
	sim_grads_norm_tr = -0.0029
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1909
	data_grads_norm = 4.8680
	new_data_grads_norm = 7.7362
	old_data_grads_norm = 5.8378
	sim_grads_norm_tr = 0.0715
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0281
	data_grads_norm = 4.5929
	new_data_grads_norm = 8.0363
	old_data_grads_norm = 5.7185
	sim_grads_norm_tr = 0.0333
-- Starting training on experience 41 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9933
	data_grads_norm = 4.7199
	new_data_grads_norm = 7.0750
	old_data_grads_norm = 6.0985
	sim_grads_norm_tr = 0.0865
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7470
	data_grads_norm = 4.3668
	new_data_grads_norm = 6.5250
	old_data_grads_norm = 4.8576
	sim_grads_norm_tr = 0.0403
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8559
	data_grads_norm = 4.4919
	new_data_grads_norm = 6.3667
	old_data_grads_norm = 5.5713
	sim_grads_norm_tr = 0.0452
-- Starting training on experience 42 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4862
	data_grads_norm = 4.9872
	new_data_grads_norm = 5.4339
	old_data_grads_norm = 7.3253
	sim_grads_norm_tr = 0.0203
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4080
	data_grads_norm = 4.0896
	new_data_grads_norm = 6.2052
	old_data_grads_norm = 4.5247
	sim_grads_norm_tr = 0.0653
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6374
	data_grads_norm = 4.8354
	new_data_grads_norm = 6.3640
	old_data_grads_norm = 6.4330
	sim_grads_norm_tr = 0.0245
-- Starting training on experience 43 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2249
	data_grads_norm = 4.0721
	new_data_grads_norm = 6.3717
	old_data_grads_norm = 5.1055
	sim_grads_norm_tr = 0.0352
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5344
	data_grads_norm = 4.8729
	new_data_grads_norm = 6.4620
	old_data_grads_norm = 6.3216
	sim_grads_norm_tr = -0.0031
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6833
	data_grads_norm = 4.7329
	new_data_grads_norm = 6.5567
	old_data_grads_norm = 6.6691
	sim_grads_norm_tr = -0.0182
-- Starting training on experience 44 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2294
	data_grads_norm = 3.8812
	new_data_grads_norm = 6.6252
	old_data_grads_norm = 5.0826
	sim_grads_norm_tr = -0.0221
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3208
	data_grads_norm = 3.8884
	new_data_grads_norm = 5.8035
	old_data_grads_norm = 6.4120
	sim_grads_norm_tr = -0.0297
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8880
	data_grads_norm = 4.7457
	new_data_grads_norm = 5.5923
	old_data_grads_norm = 6.6621
	sim_grads_norm_tr = -0.0150
-- Starting training on experience 45 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8208
	data_grads_norm = 4.7644
	new_data_grads_norm = 5.5035
	old_data_grads_norm = 6.4218
	sim_grads_norm_tr = 0.0129
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6990
	data_grads_norm = 4.7470
	new_data_grads_norm = 6.4912
	old_data_grads_norm = 6.8229
	sim_grads_norm_tr = 0.0223
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7620
	data_grads_norm = 4.7479
	new_data_grads_norm = 5.9224
	old_data_grads_norm = 6.5756
	sim_grads_norm_tr = -0.0055
-- Starting training on experience 46 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4396
	data_grads_norm = 5.3191
	new_data_grads_norm = 6.8118
	old_data_grads_norm = 7.5990
	sim_grads_norm_tr = 0.0452
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4222
	data_grads_norm = 4.5462
	new_data_grads_norm = 6.5801
	old_data_grads_norm = 6.9264
	sim_grads_norm_tr = -0.0148
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3221
	data_grads_norm = 4.3783
	new_data_grads_norm = 6.9607
	old_data_grads_norm = 5.4862
	sim_grads_norm_tr = -0.0352
-- Starting training on experience 47 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1203
	data_grads_norm = 4.7582
	new_data_grads_norm = 7.5556
	old_data_grads_norm = 5.8979
	sim_grads_norm_tr = -0.0168
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9381
	data_grads_norm = 5.6338
	new_data_grads_norm = 7.5212
	old_data_grads_norm = 5.4134
	sim_grads_norm_tr = 0.0633
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2139
	data_grads_norm = 4.5853
	new_data_grads_norm = 7.2476
	old_data_grads_norm = 5.8645
	sim_grads_norm_tr = -0.0385
-- Starting training on experience 48 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6002
	data_grads_norm = 4.4928
	new_data_grads_norm = 7.1640
	old_data_grads_norm = 5.7262
	sim_grads_norm_tr = 0.0150
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7845
	data_grads_norm = 5.2584
	new_data_grads_norm = 7.5593
	old_data_grads_norm = 6.0010
	sim_grads_norm_tr = 0.0411
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0431
	data_grads_norm = 4.0903
	new_data_grads_norm = 7.1493
	old_data_grads_norm = 3.5797
	sim_grads_norm_tr = -0.0143
-- Starting training on experience 49 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9425
	data_grads_norm = 5.4319
	new_data_grads_norm = 6.2439
	old_data_grads_norm = 7.8665
	sim_grads_norm_tr = -0.0043
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6983
	data_grads_norm = 4.5590
	new_data_grads_norm = 5.8457
	old_data_grads_norm = 6.3976
	sim_grads_norm_tr = -0.0242
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0505
	data_grads_norm = 5.0525
	new_data_grads_norm = 5.8114
	old_data_grads_norm = 6.0538
	sim_grads_norm_tr = 0.1523
-- Starting training on experience 50 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5694
	data_grads_norm = 4.1513
	new_data_grads_norm = 5.8987
	old_data_grads_norm = 6.4882
	sim_grads_norm_tr = -0.0007
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9965
	data_grads_norm = 5.0137
	new_data_grads_norm = 7.0937
	old_data_grads_norm = 7.3217
	sim_grads_norm_tr = -0.0410
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3411
	data_grads_norm = 4.4266
	new_data_grads_norm = 6.7668
	old_data_grads_norm = 5.0430
	sim_grads_norm_tr = 0.0003
-- Starting training on experience 51 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3606
	data_grads_norm = 4.8163
	new_data_grads_norm = 5.3085
	old_data_grads_norm = 7.2508
	sim_grads_norm_tr = -0.0323
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0472
	data_grads_norm = 4.0359
	new_data_grads_norm = 5.8866
	old_data_grads_norm = 5.3002
	sim_grads_norm_tr = -0.0406
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1872
	data_grads_norm = 4.6005
	new_data_grads_norm = 6.4341
	old_data_grads_norm = 5.2432
	sim_grads_norm_tr = 0.0612
-- Starting training on experience 52 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1007
	data_grads_norm = 4.3111
	new_data_grads_norm = 6.7470
	old_data_grads_norm = 6.1351
	sim_grads_norm_tr = -0.0361
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3321
	data_grads_norm = 4.7842
	new_data_grads_norm = 6.7054
	old_data_grads_norm = 6.4819
	sim_grads_norm_tr = -0.0415
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3649
	data_grads_norm = 5.0853
	new_data_grads_norm = 7.0044
	old_data_grads_norm = 7.1404
	sim_grads_norm_tr = -0.0312
-- Starting training on experience 53 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1429
	data_grads_norm = 4.5828
	new_data_grads_norm = 6.1059
	old_data_grads_norm = 5.2952
	sim_grads_norm_tr = -0.0148
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8640
	data_grads_norm = 5.2247
	new_data_grads_norm = 6.2363
	old_data_grads_norm = 6.4773
	sim_grads_norm_tr = 0.1559
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5351
	data_grads_norm = 5.1351
	new_data_grads_norm = 5.6979
	old_data_grads_norm = 8.5928
	sim_grads_norm_tr = 0.0230
-- Starting training on experience 54 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7989
	data_grads_norm = 5.1956
	new_data_grads_norm = 6.4294
	old_data_grads_norm = 8.2151
	sim_grads_norm_tr = 0.0291
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4246
	data_grads_norm = 4.0642
	new_data_grads_norm = 6.2712
	old_data_grads_norm = 4.6736
	sim_grads_norm_tr = -0.0103
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3808
	data_grads_norm = 4.6705
	new_data_grads_norm = 6.4039
	old_data_grads_norm = 6.5560
	sim_grads_norm_tr = 0.0400
-- Starting training on experience 55 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0449
	data_grads_norm = 4.5712
	new_data_grads_norm = 6.6941
	old_data_grads_norm = 5.4350
	sim_grads_norm_tr = 0.0099
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0548
	data_grads_norm = 5.0896
	new_data_grads_norm = 7.0603
	old_data_grads_norm = 7.3916
	sim_grads_norm_tr = 0.0288
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8799
	data_grads_norm = 4.9294
	new_data_grads_norm = 7.1573
	old_data_grads_norm = 7.8562
	sim_grads_norm_tr = -0.0116
-- Starting training on experience 56 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2953
	data_grads_norm = 4.5683
	new_data_grads_norm = 7.8935
	old_data_grads_norm = 4.5419
	sim_grads_norm_tr = 0.0025
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4894
	data_grads_norm = 4.4873
	new_data_grads_norm = 7.5624
	old_data_grads_norm = 5.4759
	sim_grads_norm_tr = -0.0281
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4143
	data_grads_norm = 4.5504
	new_data_grads_norm = 7.6553
	old_data_grads_norm = 4.9558
	sim_grads_norm_tr = -0.0123
-- Starting training on experience 57 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2850
	data_grads_norm = 4.1032
	new_data_grads_norm = 5.8094
	old_data_grads_norm = 5.1598
	sim_grads_norm_tr = 0.0462
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9131
	data_grads_norm = 4.6356
	new_data_grads_norm = 5.8371
	old_data_grads_norm = 7.0524
	sim_grads_norm_tr = -0.0054
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4788
	data_grads_norm = 4.8433
	new_data_grads_norm = 6.1340
	old_data_grads_norm = 6.7476
	sim_grads_norm_tr = 0.0541
-- Starting training on experience 58 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3320
	data_grads_norm = 4.6616
	new_data_grads_norm = 6.7049
	old_data_grads_norm = 5.7183
	sim_grads_norm_tr = 0.0296
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0299
	data_grads_norm = 3.7440
	new_data_grads_norm = 5.6122
	old_data_grads_norm = 6.7819
	sim_grads_norm_tr = -0.0474
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7767
	data_grads_norm = 3.5083
	new_data_grads_norm = 5.9285
	old_data_grads_norm = 3.8731
	sim_grads_norm_tr = -0.0346
-- Starting training on experience 59 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1811
	data_grads_norm = 5.5069
	new_data_grads_norm = 6.9088
	old_data_grads_norm = 8.0470
	sim_grads_norm_tr = 0.0283
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1492
	data_grads_norm = 4.7316
	new_data_grads_norm = 7.1928
	old_data_grads_norm = 6.0984
	sim_grads_norm_tr = -0.0419
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6640
	data_grads_norm = 4.9534
	new_data_grads_norm = 7.5741
	old_data_grads_norm = 5.0081
	sim_grads_norm_tr = -0.0269
-- Starting training on experience 60 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1266
	data_grads_norm = 5.4764
	new_data_grads_norm = 7.3360
	old_data_grads_norm = 7.2011
	sim_grads_norm_tr = -0.0251
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5228
	data_grads_norm = 4.6084
	new_data_grads_norm = 8.0986
	old_data_grads_norm = 5.3914
	sim_grads_norm_tr = -0.0005
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9872
	data_grads_norm = 5.5827
	new_data_grads_norm = 8.2926
	old_data_grads_norm = 6.5316
	sim_grads_norm_tr = -0.0119
-- Starting training on experience 61 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6759
	data_grads_norm = 4.7336
	new_data_grads_norm = 6.5839
	old_data_grads_norm = 6.1887
	sim_grads_norm_tr = 0.0071
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5305
	data_grads_norm = 4.2447
	new_data_grads_norm = 6.3634
	old_data_grads_norm = 4.8546
	sim_grads_norm_tr = -0.0207
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6570
	data_grads_norm = 4.2347
	new_data_grads_norm = 6.0268
	old_data_grads_norm = 5.2316
	sim_grads_norm_tr = 0.0379
-- Starting training on experience 62 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7780
	data_grads_norm = 4.8137
	new_data_grads_norm = 7.6031
	old_data_grads_norm = 5.1694
	sim_grads_norm_tr = 0.0175
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6960
	data_grads_norm = 5.3019
	new_data_grads_norm = 7.5932
	old_data_grads_norm = 5.1875
	sim_grads_norm_tr = 0.0672
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7317
	data_grads_norm = 4.6449
	new_data_grads_norm = 7.8103
	old_data_grads_norm = 5.6014
	sim_grads_norm_tr = 0.0032
-- Starting training on experience 63 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6565
	data_grads_norm = 4.7450
	new_data_grads_norm = 6.7423
	old_data_grads_norm = 6.5485
	sim_grads_norm_tr = 0.0024
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6461
	data_grads_norm = 4.6257
	new_data_grads_norm = 6.4300
	old_data_grads_norm = 6.5905
	sim_grads_norm_tr = -0.0113
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4703
	data_grads_norm = 4.0092
	new_data_grads_norm = 6.4185
	old_data_grads_norm = 4.4611
	sim_grads_norm_tr = -0.0146
-- Starting training on experience 64 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3775
	data_grads_norm = 4.7815
	new_data_grads_norm = 6.4515
	old_data_grads_norm = 6.3031
	sim_grads_norm_tr = 0.0087
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0765
	data_grads_norm = 4.8788
	new_data_grads_norm = 6.3684
	old_data_grads_norm = 6.4876
	sim_grads_norm_tr = -0.0099
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2256
	data_grads_norm = 4.9464
	new_data_grads_norm = 6.8700
	old_data_grads_norm = 6.8800
	sim_grads_norm_tr = -0.0315
-- Starting training on experience 65 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4729
	data_grads_norm = 4.8110
	new_data_grads_norm = 7.2264
	old_data_grads_norm = 6.3383
	sim_grads_norm_tr = 0.0562
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5423
	data_grads_norm = 4.6822
	new_data_grads_norm = 8.2501
	old_data_grads_norm = 6.0257
	sim_grads_norm_tr = 0.0062
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5162
	data_grads_norm = 5.1167
	new_data_grads_norm = 6.9569
	old_data_grads_norm = 7.2217
	sim_grads_norm_tr = 0.0645
-- Starting training on experience 66 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6637
	data_grads_norm = 4.4112
	new_data_grads_norm = 6.5812
	old_data_grads_norm = 5.8328
	sim_grads_norm_tr = -0.0867
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8068
	data_grads_norm = 5.1998
	new_data_grads_norm = 6.6198
	old_data_grads_norm = 5.9851
	sim_grads_norm_tr = 0.0955
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4891
	data_grads_norm = 4.5663
	new_data_grads_norm = 7.0762
	old_data_grads_norm = 5.4997
	sim_grads_norm_tr = -0.0409
-- Starting training on experience 67 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4496
	data_grads_norm = 4.1934
	new_data_grads_norm = 8.1042
	old_data_grads_norm = 4.6294
	sim_grads_norm_tr = -0.0158
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5037
	data_grads_norm = 4.5690
	new_data_grads_norm = 7.9160
	old_data_grads_norm = 5.7670
	sim_grads_norm_tr = -0.0018
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5887
	data_grads_norm = 4.4664
	new_data_grads_norm = 7.3440
	old_data_grads_norm = 5.4425
	sim_grads_norm_tr = 0.0141
-- Starting training on experience 68 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4638
	data_grads_norm = 4.4660
	new_data_grads_norm = 6.9348
	old_data_grads_norm = 5.6027
	sim_grads_norm_tr = 0.0358
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3259
	data_grads_norm = 5.1909
	new_data_grads_norm = 6.6346
	old_data_grads_norm = 8.0728
	sim_grads_norm_tr = -0.0174
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2381
	data_grads_norm = 4.9650
	new_data_grads_norm = 6.5256
	old_data_grads_norm = 7.4954
	sim_grads_norm_tr = -0.0661
-- Starting training on experience 69 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6410
	data_grads_norm = 4.6134
	new_data_grads_norm = 7.1423
	old_data_grads_norm = 5.5510
	sim_grads_norm_tr = 0.0076
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5930
	data_grads_norm = 4.6161
	new_data_grads_norm = 7.0859
	old_data_grads_norm = 6.1582
	sim_grads_norm_tr = -0.0366
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2221
	data_grads_norm = 5.6047
	new_data_grads_norm = 7.3110
	old_data_grads_norm = 6.9723
	sim_grads_norm_tr = 0.0046
-- Starting training on experience 70 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9302
	data_grads_norm = 5.8837
	new_data_grads_norm = 8.4865
	old_data_grads_norm = 7.2030
	sim_grads_norm_tr = 0.0171
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2789
	data_grads_norm = 5.4991
	new_data_grads_norm = 8.3356
	old_data_grads_norm = 5.6798
	sim_grads_norm_tr = 0.0420
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9011
	data_grads_norm = 5.4630
	new_data_grads_norm = 8.7156
	old_data_grads_norm = 5.0666
	sim_grads_norm_tr = 0.1548
-- Starting training on experience 71 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7288
	data_grads_norm = 4.5785
	new_data_grads_norm = 6.6495
	old_data_grads_norm = 4.6610
	sim_grads_norm_tr = 0.1092
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9306
	data_grads_norm = 5.5391
	new_data_grads_norm = 6.3983
	old_data_grads_norm = 8.2012
	sim_grads_norm_tr = 0.0164
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2621
	data_grads_norm = 5.5847
	new_data_grads_norm = 6.7388
	old_data_grads_norm = 6.8698
	sim_grads_norm_tr = 0.0274
-- Starting training on experience 72 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0456
	data_grads_norm = 3.9172
	new_data_grads_norm = 5.8719
	old_data_grads_norm = 5.7034
	sim_grads_norm_tr = 0.0092
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2405
	data_grads_norm = 4.3677
	new_data_grads_norm = 6.7369
	old_data_grads_norm = 5.1295
	sim_grads_norm_tr = 0.0332
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1222
	data_grads_norm = 3.7845
	new_data_grads_norm = 5.9767
	old_data_grads_norm = 5.0437
	sim_grads_norm_tr = 0.0031
-- Starting training on experience 73 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2528
	data_grads_norm = 5.0320
	new_data_grads_norm = 6.6124
	old_data_grads_norm = 6.2124
	sim_grads_norm_tr = -0.0070
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3054
	data_grads_norm = 5.0826
	new_data_grads_norm = 6.9467
	old_data_grads_norm = 6.8245
	sim_grads_norm_tr = 0.0312
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2179
	data_grads_norm = 4.3969
	new_data_grads_norm = 6.4755
	old_data_grads_norm = 7.3036
	sim_grads_norm_tr = -0.0356
-- Starting training on experience 74 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1185
	data_grads_norm = 3.9482
	new_data_grads_norm = 6.1575
	old_data_grads_norm = 6.0143
	sim_grads_norm_tr = -0.0516
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1153
	data_grads_norm = 4.1846
	new_data_grads_norm = 5.9926
	old_data_grads_norm = 6.6076
	sim_grads_norm_tr = 0.0055
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7197
	data_grads_norm = 4.9653
	new_data_grads_norm = 5.8922
	old_data_grads_norm = 6.5169
	sim_grads_norm_tr = 0.0353
-- Starting training on experience 75 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6125
	data_grads_norm = 4.5380
	new_data_grads_norm = 7.2537
	old_data_grads_norm = 5.0324
	sim_grads_norm_tr = 0.0011
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6604
	data_grads_norm = 4.9525
	new_data_grads_norm = 7.3961
	old_data_grads_norm = 6.1435
	sim_grads_norm_tr = -0.0104
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9443
	data_grads_norm = 4.9166
	new_data_grads_norm = 6.9716
	old_data_grads_norm = 6.1054
	sim_grads_norm_tr = -0.0071
-- Starting training on experience 76 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3740
	data_grads_norm = 4.1288
	new_data_grads_norm = 6.7228
	old_data_grads_norm = 4.4085
	sim_grads_norm_tr = 0.0130
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5699
	data_grads_norm = 4.6073
	new_data_grads_norm = 6.9399
	old_data_grads_norm = 6.1073
	sim_grads_norm_tr = -0.0481
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6390
	data_grads_norm = 4.8349
	new_data_grads_norm = 6.6809
	old_data_grads_norm = 6.9996
	sim_grads_norm_tr = 0.0603
-- Starting training on experience 77 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9959
	data_grads_norm = 5.5679
	new_data_grads_norm = 8.3611
	old_data_grads_norm = 7.0542
	sim_grads_norm_tr = 0.0549
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3319
	data_grads_norm = 6.2141
	new_data_grads_norm = 8.5649
	old_data_grads_norm = 7.3001
	sim_grads_norm_tr = 0.0062
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4287
	data_grads_norm = 4.4922
	new_data_grads_norm = 7.1471
	old_data_grads_norm = 5.9609
	sim_grads_norm_tr = 0.0450
-- Starting training on experience 78 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6116
	data_grads_norm = 5.2748
	new_data_grads_norm = 7.0093
	old_data_grads_norm = 6.5830
	sim_grads_norm_tr = 0.0014
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5030
	data_grads_norm = 5.0043
	new_data_grads_norm = 6.5086
	old_data_grads_norm = 6.5387
	sim_grads_norm_tr = -0.0203
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2271
	data_grads_norm = 4.0958
	new_data_grads_norm = 6.8136
	old_data_grads_norm = 5.1378
	sim_grads_norm_tr = -0.0062
-- Starting training on experience 79 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3505
	data_grads_norm = 4.9320
	new_data_grads_norm = 6.8059
	old_data_grads_norm = 6.1633
	sim_grads_norm_tr = 0.0167
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6816
	data_grads_norm = 4.9779
	new_data_grads_norm = 6.7343
	old_data_grads_norm = 6.4499
	sim_grads_norm_tr = -0.0058
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1717
	data_grads_norm = 5.5631
	new_data_grads_norm = 6.7493
	old_data_grads_norm = 7.1886
	sim_grads_norm_tr = 0.0695
-- Starting training on experience 80 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4647
	data_grads_norm = 4.2007
	new_data_grads_norm = 7.4383
	old_data_grads_norm = 4.5824
	sim_grads_norm_tr = -0.0289
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4407
	data_grads_norm = 4.1576
	new_data_grads_norm = 7.8777
	old_data_grads_norm = 4.1467
	sim_grads_norm_tr = -0.0298
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2803
	data_grads_norm = 3.9189
	new_data_grads_norm = 7.0330
	old_data_grads_norm = 5.3121
	sim_grads_norm_tr = -0.0272
-- Starting training on experience 81 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3091
	data_grads_norm = 4.4989
	new_data_grads_norm = 7.8558
	old_data_grads_norm = 5.3140
	sim_grads_norm_tr = -0.0545
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4405
	data_grads_norm = 4.9273
	new_data_grads_norm = 7.4242
	old_data_grads_norm = 5.1999
	sim_grads_norm_tr = -0.0053
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8971
	data_grads_norm = 5.2823
	new_data_grads_norm = 6.8042
	old_data_grads_norm = 6.9680
	sim_grads_norm_tr = 0.0308
-- Starting training on experience 82 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6798
	data_grads_norm = 4.9221
	new_data_grads_norm = 6.4976
	old_data_grads_norm = 6.7399
	sim_grads_norm_tr = -0.0292
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6926
	data_grads_norm = 4.7079
	new_data_grads_norm = 6.5946
	old_data_grads_norm = 6.3419
	sim_grads_norm_tr = 0.0153
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3137
	data_grads_norm = 4.5165
	new_data_grads_norm = 6.3310
	old_data_grads_norm = 4.9526
	sim_grads_norm_tr = -0.0072
-- Starting training on experience 83 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3737
	data_grads_norm = 5.3568
	new_data_grads_norm = 7.2559
	old_data_grads_norm = 7.6322
	sim_grads_norm_tr = 0.0365
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8139
	data_grads_norm = 5.9353
	new_data_grads_norm = 7.1258
	old_data_grads_norm = 6.8104
	sim_grads_norm_tr = 0.0812
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6939
	data_grads_norm = 5.5417
	new_data_grads_norm = 6.8535
	old_data_grads_norm = 8.2833
	sim_grads_norm_tr = 0.0063
-- Starting training on experience 84 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8800
	data_grads_norm = 4.4972
	new_data_grads_norm = 6.9304
	old_data_grads_norm = 6.0508
	sim_grads_norm_tr = 0.0411
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2903
	data_grads_norm = 4.5913
	new_data_grads_norm = 6.7468
	old_data_grads_norm = 5.6323
	sim_grads_norm_tr = -0.0390
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3165
	data_grads_norm = 4.4838
	new_data_grads_norm = 6.8322
	old_data_grads_norm = 6.7911
	sim_grads_norm_tr = -0.0442
-- Starting training on experience 85 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4024
	data_grads_norm = 4.5770
	new_data_grads_norm = 7.1050
	old_data_grads_norm = 5.5303
	sim_grads_norm_tr = 0.0947
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2301
	data_grads_norm = 4.4665
	new_data_grads_norm = 6.4521
	old_data_grads_norm = 6.5377
	sim_grads_norm_tr = -0.0330
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4204
	data_grads_norm = 4.7378
	new_data_grads_norm = 7.0127
	old_data_grads_norm = 5.8814
	sim_grads_norm_tr = -0.0702
-- Starting training on experience 86 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8514
	data_grads_norm = 3.7144
	new_data_grads_norm = 5.9729
	old_data_grads_norm = 4.3037
	sim_grads_norm_tr = -0.0341
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3148
	data_grads_norm = 5.0414
	new_data_grads_norm = 6.0075
	old_data_grads_norm = 6.5774
	sim_grads_norm_tr = 0.0083
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4210
	data_grads_norm = 4.3690
	new_data_grads_norm = 6.6594
	old_data_grads_norm = 5.2253
	sim_grads_norm_tr = 0.0284
-- Starting training on experience 87 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2854
	data_grads_norm = 4.3619
	new_data_grads_norm = 6.3617
	old_data_grads_norm = 6.4190
	sim_grads_norm_tr = 0.0296
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5934
	data_grads_norm = 4.7084
	new_data_grads_norm = 6.0901
	old_data_grads_norm = 6.6877
	sim_grads_norm_tr = 0.0056
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8257
	data_grads_norm = 5.0800
	new_data_grads_norm = 6.3079
	old_data_grads_norm = 7.4572
	sim_grads_norm_tr = -0.0230
-- Starting training on experience 88 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0393
	data_grads_norm = 5.3805
	new_data_grads_norm = 8.6968
	old_data_grads_norm = 5.9308
	sim_grads_norm_tr = 0.0104
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6454
	data_grads_norm = 4.9602
	new_data_grads_norm = 8.7473
	old_data_grads_norm = 6.2269
	sim_grads_norm_tr = -0.0319
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1554
	data_grads_norm = 5.1268
	new_data_grads_norm = 8.9835
	old_data_grads_norm = 5.6055
	sim_grads_norm_tr = -0.0160
-- Starting training on experience 89 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7583
	data_grads_norm = 5.4841
	new_data_grads_norm = 7.7029
	old_data_grads_norm = 6.3793
	sim_grads_norm_tr = -0.0016
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1897
	data_grads_norm = 4.5136
	new_data_grads_norm = 7.5035
	old_data_grads_norm = 5.9863
	sim_grads_norm_tr = -0.0223
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5560
	data_grads_norm = 5.0510
	new_data_grads_norm = 7.6430
	old_data_grads_norm = 6.5472
	sim_grads_norm_tr = 0.0256
-- Starting training on experience 90 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6709
	data_grads_norm = 5.0715
	new_data_grads_norm = 8.2535
	old_data_grads_norm = 7.0365
	sim_grads_norm_tr = 0.0055
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6934
	data_grads_norm = 5.5926
	new_data_grads_norm = 7.7155
	old_data_grads_norm = 6.6345
	sim_grads_norm_tr = 0.0479
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8162
	data_grads_norm = 5.2753
	new_data_grads_norm = 8.4385
	old_data_grads_norm = 7.3131
	sim_grads_norm_tr = 0.0687
-- Starting training on experience 91 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9043
	data_grads_norm = 5.8608
	new_data_grads_norm = 7.5759
	old_data_grads_norm = 6.7295
	sim_grads_norm_tr = 0.0660
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3676
	data_grads_norm = 5.2899
	new_data_grads_norm = 6.1701
	old_data_grads_norm = 8.6655
	sim_grads_norm_tr = -0.0423
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8815
	data_grads_norm = 5.1398
	new_data_grads_norm = 6.6890
	old_data_grads_norm = 7.1276
	sim_grads_norm_tr = -0.0141
-- Starting training on experience 92 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2785
	data_grads_norm = 4.3250
	new_data_grads_norm = 6.5001
	old_data_grads_norm = 4.9956
	sim_grads_norm_tr = -0.0018
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4147
	data_grads_norm = 3.9794
	new_data_grads_norm = 5.4356
	old_data_grads_norm = 4.7384
	sim_grads_norm_tr = -0.0224
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2971
	data_grads_norm = 4.1168
	new_data_grads_norm = 5.9054
	old_data_grads_norm = 4.2656
	sim_grads_norm_tr = 0.0066
-- Starting training on experience 93 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1109
	data_grads_norm = 4.5765
	new_data_grads_norm = 6.3494
	old_data_grads_norm = 6.3279
	sim_grads_norm_tr = -0.0338
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4783
	data_grads_norm = 4.7974
	new_data_grads_norm = 5.6758
	old_data_grads_norm = 7.2280
	sim_grads_norm_tr = 0.0355
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3902
	data_grads_norm = 4.9403
	new_data_grads_norm = 6.8240
	old_data_grads_norm = 7.2301
	sim_grads_norm_tr = -0.0172
-- Starting training on experience 94 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6981
	data_grads_norm = 5.5143
	new_data_grads_norm = 8.5950
	old_data_grads_norm = 6.4074
	sim_grads_norm_tr = 0.1455
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1896
	data_grads_norm = 5.3908
	new_data_grads_norm = 6.1429
	old_data_grads_norm = 8.6688
	sim_grads_norm_tr = 0.0482
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9550
	data_grads_norm = 4.3801
	new_data_grads_norm = 6.2828
	old_data_grads_norm = 6.1406
	sim_grads_norm_tr = -0.0199
-- Starting training on experience 95 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9515
	data_grads_norm = 4.0362
	new_data_grads_norm = 6.3851
	old_data_grads_norm = 5.3942
	sim_grads_norm_tr = 0.0561
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2320
	data_grads_norm = 4.3497
	new_data_grads_norm = 6.5100
	old_data_grads_norm = 5.7586
	sim_grads_norm_tr = 0.0121
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9169
	data_grads_norm = 4.6192
	new_data_grads_norm = 6.0104
	old_data_grads_norm = 6.3207
	sim_grads_norm_tr = 0.0108
-- Starting training on experience 96 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6043
	data_grads_norm = 4.8415
	new_data_grads_norm = 7.5833
	old_data_grads_norm = 6.8645
	sim_grads_norm_tr = 0.0667
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3568
	data_grads_norm = 5.0714
	new_data_grads_norm = 7.0904
	old_data_grads_norm = 8.4132
	sim_grads_norm_tr = -0.0625
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4747
	data_grads_norm = 5.0279
	new_data_grads_norm = 7.0620
	old_data_grads_norm = 5.7254
	sim_grads_norm_tr = -0.0376
-- Starting training on experience 97 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3559
	data_grads_norm = 4.6619
	new_data_grads_norm = 6.7859
	old_data_grads_norm = 5.1920
	sim_grads_norm_tr = 0.0780
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4966
	data_grads_norm = 5.1656
	new_data_grads_norm = 6.9515
	old_data_grads_norm = 7.2299
	sim_grads_norm_tr = 0.0008
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7086
	data_grads_norm = 5.2347
	new_data_grads_norm = 6.5585
	old_data_grads_norm = 7.2864
	sim_grads_norm_tr = -0.0005
-- Starting training on experience 98 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4241
	data_grads_norm = 4.3846
	new_data_grads_norm = 7.2369
	old_data_grads_norm = 7.5433
	sim_grads_norm_tr = -0.0209
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3658
	data_grads_norm = 4.4735
	new_data_grads_norm = 7.1834
	old_data_grads_norm = 5.4619
	sim_grads_norm_tr = -0.0403
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5522
	data_grads_norm = 5.2546
	new_data_grads_norm = 8.3444
	old_data_grads_norm = 7.2721
	sim_grads_norm_tr = 0.0930
-- Starting training on experience 99 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3744
	data_grads_norm = 5.0558
	new_data_grads_norm = 7.5972
	old_data_grads_norm = 6.4466
	sim_grads_norm_tr = 0.0442
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2922
	data_grads_norm = 3.9673
	new_data_grads_norm = 5.9417
	old_data_grads_norm = 4.2936
	sim_grads_norm_tr = 0.0557
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3669
	data_grads_norm = 4.3918
	new_data_grads_norm = 6.1718
	old_data_grads_norm = 6.5324
	sim_grads_norm_tr = -0.0091
-- Starting training on experience 100 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3438
	data_grads_norm = 4.5653
	new_data_grads_norm = 6.9607
	old_data_grads_norm = 5.7753
	sim_grads_norm_tr = 0.0716
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0952
	data_grads_norm = 4.1014
	new_data_grads_norm = 5.9766
	old_data_grads_norm = 5.9259
	sim_grads_norm_tr = -0.0269
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1710
	data_grads_norm = 4.1497
	new_data_grads_norm = 6.6795
	old_data_grads_norm = 6.3723
	sim_grads_norm_tr = -0.0357
-- Starting training on experience 101 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1901
	data_grads_norm = 4.8142
	new_data_grads_norm = 7.3090
	old_data_grads_norm = 7.8616
	sim_grads_norm_tr = 0.0474
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4624
	data_grads_norm = 4.8479
	new_data_grads_norm = 6.3847
	old_data_grads_norm = 6.4774
	sim_grads_norm_tr = 0.0399
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4519
	data_grads_norm = 4.2096
	new_data_grads_norm = 6.0413
	old_data_grads_norm = 7.1576
	sim_grads_norm_tr = -0.0430
-- Starting training on experience 102 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3945
	data_grads_norm = 4.5255
	new_data_grads_norm = 6.6786
	old_data_grads_norm = 5.1202
	sim_grads_norm_tr = 0.0657
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3980
	data_grads_norm = 4.0763
	new_data_grads_norm = 6.4785
	old_data_grads_norm = 4.8242
	sim_grads_norm_tr = -0.0500
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4395
	data_grads_norm = 4.2794
	new_data_grads_norm = 6.6774
	old_data_grads_norm = 4.7510
	sim_grads_norm_tr = 0.0938
-- Starting training on experience 103 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8834
	data_grads_norm = 5.2221
	new_data_grads_norm = 5.9921
	old_data_grads_norm = 7.4188
	sim_grads_norm_tr = -0.0123
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3429
	data_grads_norm = 4.5509
	new_data_grads_norm = 5.9360
	old_data_grads_norm = 7.0594
	sim_grads_norm_tr = 0.0082
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6969
	data_grads_norm = 5.1008
	new_data_grads_norm = 6.0557
	old_data_grads_norm = 7.7222
	sim_grads_norm_tr = 0.0530
-- Starting training on experience 104 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6218
	data_grads_norm = 4.6517
	new_data_grads_norm = 7.7613
	old_data_grads_norm = 5.2556
	sim_grads_norm_tr = -0.0382
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3841
	data_grads_norm = 5.7371
	new_data_grads_norm = 7.3173
	old_data_grads_norm = 6.8906
	sim_grads_norm_tr = 0.0319
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4248
	data_grads_norm = 4.7359
	new_data_grads_norm = 7.0841
	old_data_grads_norm = 6.8970
	sim_grads_norm_tr = 0.0266
-- Starting training on experience 105 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1452
	data_grads_norm = 5.3365
	new_data_grads_norm = 5.8608
	old_data_grads_norm = 8.1965
	sim_grads_norm_tr = 0.1227
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1206
	data_grads_norm = 4.2437
	new_data_grads_norm = 5.5579
	old_data_grads_norm = 4.9358
	sim_grads_norm_tr = 0.0908
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9914
	data_grads_norm = 3.7849
	new_data_grads_norm = 4.8956
	old_data_grads_norm = 5.5814
	sim_grads_norm_tr = 0.0363
-- Starting training on experience 106 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1115
	data_grads_norm = 4.0886
	new_data_grads_norm = 6.3387
	old_data_grads_norm = 5.7531
	sim_grads_norm_tr = -0.0419
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3484
	data_grads_norm = 5.8858
	new_data_grads_norm = 6.5879
	old_data_grads_norm = 8.3778
	sim_grads_norm_tr = 0.0250
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0668
	data_grads_norm = 4.7207
	new_data_grads_norm = 6.5717
	old_data_grads_norm = 6.2730
	sim_grads_norm_tr = 0.0221
-- Starting training on experience 107 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0775
	data_grads_norm = 4.3149
	new_data_grads_norm = 6.4201
	old_data_grads_norm = 6.7737
	sim_grads_norm_tr = 0.0251
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1266
	data_grads_norm = 4.7469
	new_data_grads_norm = 5.6226
	old_data_grads_norm = 8.0116
	sim_grads_norm_tr = 0.0054
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9575
	data_grads_norm = 4.8160
	new_data_grads_norm = 5.9224
	old_data_grads_norm = 6.5394
	sim_grads_norm_tr = -0.0157
-- Starting training on experience 108 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5179
	data_grads_norm = 5.0945
	new_data_grads_norm = 6.7273
	old_data_grads_norm = 6.6998
	sim_grads_norm_tr = -0.0469
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2960
	data_grads_norm = 4.6041
	new_data_grads_norm = 6.0947
	old_data_grads_norm = 7.4117
	sim_grads_norm_tr = 0.0556
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0761
	data_grads_norm = 4.0449
	new_data_grads_norm = 6.0862
	old_data_grads_norm = 6.2678
	sim_grads_norm_tr = -0.1000
-- Starting training on experience 109 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1890
	data_grads_norm = 5.6613
	new_data_grads_norm = 6.7208
	old_data_grads_norm = 8.8847
	sim_grads_norm_tr = 0.0385
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9918
	data_grads_norm = 4.8679
	new_data_grads_norm = 5.7440
	old_data_grads_norm = 7.5316
	sim_grads_norm_tr = -0.0162
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7653
	data_grads_norm = 4.2357
	new_data_grads_norm = 5.9259
	old_data_grads_norm = 5.6937
	sim_grads_norm_tr = -0.0064
-- Starting training on experience 110 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8971
	data_grads_norm = 5.2302
	new_data_grads_norm = 7.2691
	old_data_grads_norm = 7.0164
	sim_grads_norm_tr = -0.0465
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2555
	data_grads_norm = 4.6819
	new_data_grads_norm = 6.9385
	old_data_grads_norm = 6.0276
	sim_grads_norm_tr = -0.0113
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0661
	data_grads_norm = 3.7385
	new_data_grads_norm = 6.3613
	old_data_grads_norm = 5.0840
	sim_grads_norm_tr = 0.0129
-- Starting training on experience 111 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9814
	data_grads_norm = 5.9514
	new_data_grads_norm = 7.6083
	old_data_grads_norm = 8.4434
	sim_grads_norm_tr = 0.0528
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2024
	data_grads_norm = 4.8827
	new_data_grads_norm = 7.6733
	old_data_grads_norm = 6.6331
	sim_grads_norm_tr = -0.0142
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4743
	data_grads_norm = 5.4288
	new_data_grads_norm = 7.1186
	old_data_grads_norm = 6.9509
	sim_grads_norm_tr = 0.0326
-- Starting training on experience 112 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4080
	data_grads_norm = 4.7972
	new_data_grads_norm = 6.4317
	old_data_grads_norm = 7.4585
	sim_grads_norm_tr = 0.0368
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3923
	data_grads_norm = 4.9851
	new_data_grads_norm = 6.2651
	old_data_grads_norm = 8.2486
	sim_grads_norm_tr = -0.0229
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2883
	data_grads_norm = 4.9956
	new_data_grads_norm = 6.2279
	old_data_grads_norm = 7.3153
	sim_grads_norm_tr = 0.0062
-- Starting training on experience 113 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8440
	data_grads_norm = 4.6576
	new_data_grads_norm = 7.0083
	old_data_grads_norm = 7.3948
	sim_grads_norm_tr = -0.0241
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8622
	data_grads_norm = 4.5133
	new_data_grads_norm = 6.8213
	old_data_grads_norm = 6.5592
	sim_grads_norm_tr = 0.0040
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3857
	data_grads_norm = 5.5230
	new_data_grads_norm = 6.4415
	old_data_grads_norm = 9.0417
	sim_grads_norm_tr = 0.0145
-- Starting training on experience 114 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3647
	data_grads_norm = 4.4158
	new_data_grads_norm = 6.3074
	old_data_grads_norm = 5.5973
	sim_grads_norm_tr = 0.0311
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7946
	data_grads_norm = 4.7500
	new_data_grads_norm = 6.1936
	old_data_grads_norm = 6.3617
	sim_grads_norm_tr = -0.0200
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4400
	data_grads_norm = 4.9278
	new_data_grads_norm = 6.2347
	old_data_grads_norm = 6.8884
	sim_grads_norm_tr = 0.0027
-- Starting training on experience 115 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3565
	data_grads_norm = 4.6111
	new_data_grads_norm = 6.9696
	old_data_grads_norm = 6.3064
	sim_grads_norm_tr = 0.0543
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0319
	data_grads_norm = 4.7183
	new_data_grads_norm = 7.0143
	old_data_grads_norm = 6.0928
	sim_grads_norm_tr = 0.0437
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6251
	data_grads_norm = 4.7370
	new_data_grads_norm = 7.2444
	old_data_grads_norm = 6.9790
	sim_grads_norm_tr = 0.0134
-- Starting training on experience 116 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5112
	data_grads_norm = 4.2735
	new_data_grads_norm = 7.2122
	old_data_grads_norm = 4.4566
	sim_grads_norm_tr = -0.0120
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6421
	data_grads_norm = 5.2689
	new_data_grads_norm = 7.5917
	old_data_grads_norm = 6.5567
	sim_grads_norm_tr = -0.0250
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7911
	data_grads_norm = 5.1454
	new_data_grads_norm = 7.3566
	old_data_grads_norm = 5.8474
	sim_grads_norm_tr = 0.0451
-- Starting training on experience 117 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2656
	data_grads_norm = 5.0455
	new_data_grads_norm = 7.1474
	old_data_grads_norm = 6.5864
	sim_grads_norm_tr = -0.0329
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2745
	data_grads_norm = 5.2629
	new_data_grads_norm = 7.4653
	old_data_grads_norm = 7.2339
	sim_grads_norm_tr = 0.0324
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1909
	data_grads_norm = 5.2188
	new_data_grads_norm = 6.2046
	old_data_grads_norm = 9.3508
	sim_grads_norm_tr = -0.0169
-- Starting training on experience 118 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0392
	data_grads_norm = 5.9605
	new_data_grads_norm = 7.4215
	old_data_grads_norm = 8.8881
	sim_grads_norm_tr = 0.0510
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3420
	data_grads_norm = 4.7476
	new_data_grads_norm = 6.9721
	old_data_grads_norm = 6.0326
	sim_grads_norm_tr = 0.0223
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1063
	data_grads_norm = 4.7878
	new_data_grads_norm = 7.2033
	old_data_grads_norm = 5.2871
	sim_grads_norm_tr = -0.0232
-- Starting training on experience 119 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1204
	data_grads_norm = 4.3273
	new_data_grads_norm = 5.7688
	old_data_grads_norm = 6.4599
	sim_grads_norm_tr = 0.0032
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4498
	data_grads_norm = 4.4435
	new_data_grads_norm = 5.9411
	old_data_grads_norm = 6.2831
	sim_grads_norm_tr = 0.0644
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2861
	data_grads_norm = 4.5743
	new_data_grads_norm = 5.6810
	old_data_grads_norm = 7.4662
	sim_grads_norm_tr = -0.0373
-- Starting training on experience 120 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7161
	data_grads_norm = 5.2576
	new_data_grads_norm = 6.9454
	old_data_grads_norm = 7.0771
	sim_grads_norm_tr = 0.0288
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9828
	data_grads_norm = 5.4993
	new_data_grads_norm = 7.2873
	old_data_grads_norm = 7.5396
	sim_grads_norm_tr = 0.0094
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2506
	data_grads_norm = 4.0704
	new_data_grads_norm = 6.5695
	old_data_grads_norm = 5.9242
	sim_grads_norm_tr = 0.0255
-- Starting training on experience 121 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6660
	data_grads_norm = 5.4186
	new_data_grads_norm = 7.5123
	old_data_grads_norm = 6.0780
	sim_grads_norm_tr = 0.0956
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6674
	data_grads_norm = 5.5259
	new_data_grads_norm = 6.8660
	old_data_grads_norm = 8.4578
	sim_grads_norm_tr = 0.0260
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1217
	data_grads_norm = 5.0889
	new_data_grads_norm = 7.4192
	old_data_grads_norm = 6.1346
	sim_grads_norm_tr = 0.1020
-- Starting training on experience 122 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3795
	data_grads_norm = 5.7616
	new_data_grads_norm = 7.1316
	old_data_grads_norm = 6.8067
	sim_grads_norm_tr = 0.0178
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4741
	data_grads_norm = 5.0312
	new_data_grads_norm = 6.6609
	old_data_grads_norm = 5.5139
	sim_grads_norm_tr = 0.0418
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2242
	data_grads_norm = 4.5140
	new_data_grads_norm = 6.5266
	old_data_grads_norm = 6.9516
	sim_grads_norm_tr = -0.0265
-- Starting training on experience 123 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9243
	data_grads_norm = 5.5844
	new_data_grads_norm = 6.7430
	old_data_grads_norm = 7.6326
	sim_grads_norm_tr = 0.0142
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6519
	data_grads_norm = 5.5231
	new_data_grads_norm = 7.2382
	old_data_grads_norm = 9.4509
	sim_grads_norm_tr = -0.0263
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9486
	data_grads_norm = 5.0181
	new_data_grads_norm = 6.8003
	old_data_grads_norm = 6.4846
	sim_grads_norm_tr = 0.0246
-- Starting training on experience 124 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6072
	data_grads_norm = 6.0931
	new_data_grads_norm = 6.3568
	old_data_grads_norm = 9.4853
	sim_grads_norm_tr = 0.1037
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2226
	data_grads_norm = 4.2397
	new_data_grads_norm = 5.8450
	old_data_grads_norm = 6.4545
	sim_grads_norm_tr = -0.0039
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5582
	data_grads_norm = 4.5084
	new_data_grads_norm = 6.4293
	old_data_grads_norm = 5.6292
	sim_grads_norm_tr = -0.0087
-- Starting training on experience 125 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7298
	data_grads_norm = 5.8515
	new_data_grads_norm = 6.7247
	old_data_grads_norm = 7.7446
	sim_grads_norm_tr = -0.0193
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3879
	data_grads_norm = 4.9369
	new_data_grads_norm = 6.6959
	old_data_grads_norm = 6.7538
	sim_grads_norm_tr = 0.0301
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3349
	data_grads_norm = 4.6013
	new_data_grads_norm = 7.0817
	old_data_grads_norm = 4.7348
	sim_grads_norm_tr = -0.0287
-- Starting training on experience 126 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0384
	data_grads_norm = 4.8743
	new_data_grads_norm = 7.2372
	old_data_grads_norm = 6.4146
	sim_grads_norm_tr = -0.0306
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7769
	data_grads_norm = 4.5101
	new_data_grads_norm = 6.7604
	old_data_grads_norm = 5.6696
	sim_grads_norm_tr = 0.0982
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1477
	data_grads_norm = 4.2295
	new_data_grads_norm = 6.1752
	old_data_grads_norm = 5.5796
	sim_grads_norm_tr = -0.0077
-- Starting training on experience 127 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1958
	data_grads_norm = 4.8990
	new_data_grads_norm = 6.5888
	old_data_grads_norm = 7.7309
	sim_grads_norm_tr = 0.0188
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2708
	data_grads_norm = 4.3350
	new_data_grads_norm = 6.6585
	old_data_grads_norm = 5.2866
	sim_grads_norm_tr = -0.0052
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4944
	data_grads_norm = 5.3434
	new_data_grads_norm = 7.0035
	old_data_grads_norm = 7.3925
	sim_grads_norm_tr = -0.0045
-- Starting training on experience 128 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1613
	data_grads_norm = 4.6407
	new_data_grads_norm = 7.0794
	old_data_grads_norm = 6.6605
	sim_grads_norm_tr = -0.0455
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6678
	data_grads_norm = 4.6376
	new_data_grads_norm = 7.0705
	old_data_grads_norm = 6.8731
	sim_grads_norm_tr = -0.0348
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4323
	data_grads_norm = 4.8857
	new_data_grads_norm = 7.3675
	old_data_grads_norm = 5.8959
	sim_grads_norm_tr = 0.0317
-- Starting training on experience 129 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2073
	data_grads_norm = 4.6042
	new_data_grads_norm = 7.3774
	old_data_grads_norm = 4.6639
	sim_grads_norm_tr = -0.0240
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6331
	data_grads_norm = 5.5699
	new_data_grads_norm = 8.0626
	old_data_grads_norm = 6.2733
	sim_grads_norm_tr = 0.0262
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7074
	data_grads_norm = 5.5270
	new_data_grads_norm = 7.0348
	old_data_grads_norm = 6.6675
	sim_grads_norm_tr = -0.0037
-- Starting training on experience 130 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3379
	data_grads_norm = 4.5656
	new_data_grads_norm = 6.7596
	old_data_grads_norm = 6.3968
	sim_grads_norm_tr = 0.0166
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1990
	data_grads_norm = 4.8634
	new_data_grads_norm = 6.3880
	old_data_grads_norm = 6.7408
	sim_grads_norm_tr = 0.0554
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1773
	data_grads_norm = 5.0245
	new_data_grads_norm = 6.4290
	old_data_grads_norm = 6.4291
	sim_grads_norm_tr = -0.0133
-- Starting training on experience 131 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0021
	data_grads_norm = 3.8838
	new_data_grads_norm = 6.6501
	old_data_grads_norm = 5.3747
	sim_grads_norm_tr = 0.0116
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1803
	data_grads_norm = 4.5760
	new_data_grads_norm = 6.5870
	old_data_grads_norm = 6.9616
	sim_grads_norm_tr = 0.0189
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9396
	data_grads_norm = 4.3035
	new_data_grads_norm = 7.2268
	old_data_grads_norm = 5.7982
	sim_grads_norm_tr = -0.0443
-- Starting training on experience 132 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6740
	data_grads_norm = 3.8564
	new_data_grads_norm = 6.5043
	old_data_grads_norm = 3.1923
	sim_grads_norm_tr = -0.0405
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9878
	data_grads_norm = 3.9907
	new_data_grads_norm = 6.5084
	old_data_grads_norm = 4.2104
	sim_grads_norm_tr = 0.0097
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1746
	data_grads_norm = 4.4065
	new_data_grads_norm = 7.1350
	old_data_grads_norm = 6.3025
	sim_grads_norm_tr = -0.0150
-- Starting training on experience 133 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5367
	data_grads_norm = 5.2797
	new_data_grads_norm = 6.5366
	old_data_grads_norm = 7.1325
	sim_grads_norm_tr = -0.0199
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5073
	data_grads_norm = 4.8131
	new_data_grads_norm = 7.0754
	old_data_grads_norm = 6.4423
	sim_grads_norm_tr = -0.0469
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1434
	data_grads_norm = 4.3198
	new_data_grads_norm = 6.7972
	old_data_grads_norm = 5.7765
	sim_grads_norm_tr = -0.0188
-- Starting training on experience 134 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1541
	data_grads_norm = 4.3422
	new_data_grads_norm = 5.2507
	old_data_grads_norm = 8.1105
	sim_grads_norm_tr = -0.0280
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5244
	data_grads_norm = 4.8960
	new_data_grads_norm = 6.1491
	old_data_grads_norm = 6.7579
	sim_grads_norm_tr = 0.0448
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1610
	data_grads_norm = 4.7747
	new_data_grads_norm = 5.9756
	old_data_grads_norm = 5.7354
	sim_grads_norm_tr = 0.0257
-- Starting training on experience 135 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1978
	data_grads_norm = 4.9523
	new_data_grads_norm = 6.5308
	old_data_grads_norm = 6.9480
	sim_grads_norm_tr = 0.0414
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4808
	data_grads_norm = 5.3021
	new_data_grads_norm = 7.2995
	old_data_grads_norm = 6.0816
	sim_grads_norm_tr = 0.0531
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1774
	data_grads_norm = 4.5779
	new_data_grads_norm = 7.4153
	old_data_grads_norm = 4.4211
	sim_grads_norm_tr = -0.0183
-- Starting training on experience 136 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8251
	data_grads_norm = 3.9118
	new_data_grads_norm = 6.2037
	old_data_grads_norm = 5.0404
	sim_grads_norm_tr = 0.0050
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9637
	data_grads_norm = 4.3577
	new_data_grads_norm = 6.6653
	old_data_grads_norm = 4.8466
	sim_grads_norm_tr = 0.0148
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9486
	data_grads_norm = 4.3036
	new_data_grads_norm = 6.3131
	old_data_grads_norm = 5.4031
	sim_grads_norm_tr = -0.0364
-- Starting training on experience 137 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3184
	data_grads_norm = 4.5693
	new_data_grads_norm = 6.1654
	old_data_grads_norm = 6.8923
	sim_grads_norm_tr = 0.0440
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3094
	data_grads_norm = 5.0760
	new_data_grads_norm = 6.5627
	old_data_grads_norm = 6.7485
	sim_grads_norm_tr = 0.0120
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0849
	data_grads_norm = 4.1658
	new_data_grads_norm = 5.9831
	old_data_grads_norm = 5.1137
	sim_grads_norm_tr = 0.0414
-- Starting training on experience 138 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3167
	data_grads_norm = 4.9014
	new_data_grads_norm = 6.1841
	old_data_grads_norm = 6.5041
	sim_grads_norm_tr = -0.0313
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0098
	data_grads_norm = 4.7313
	new_data_grads_norm = 6.5492
	old_data_grads_norm = 6.6140
	sim_grads_norm_tr = -0.0407
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3065
	data_grads_norm = 4.4579
	new_data_grads_norm = 6.9615
	old_data_grads_norm = 5.5616
	sim_grads_norm_tr = 0.0041
-- Starting training on experience 139 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9517
	data_grads_norm = 5.0863
	new_data_grads_norm = 6.0747
	old_data_grads_norm = 7.4502
	sim_grads_norm_tr = -0.0484
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5315
	data_grads_norm = 5.1314
	new_data_grads_norm = 6.4999
	old_data_grads_norm = 7.5826
	sim_grads_norm_tr = -0.0502
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2627
	data_grads_norm = 4.5214
	new_data_grads_norm = 7.2103
	old_data_grads_norm = 5.2283
	sim_grads_norm_tr = 0.0259
-- Starting training on experience 140 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0302
	data_grads_norm = 4.9283
	new_data_grads_norm = 6.8339
	old_data_grads_norm = 7.6972
	sim_grads_norm_tr = -0.0228
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3919
	data_grads_norm = 5.3821
	new_data_grads_norm = 8.4424
	old_data_grads_norm = 7.2996
	sim_grads_norm_tr = 0.0393
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0600
	data_grads_norm = 4.9814
	new_data_grads_norm = 8.6234
	old_data_grads_norm = 6.1194
	sim_grads_norm_tr = 0.0061
-- Starting training on experience 141 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3385
	data_grads_norm = 5.5684
	new_data_grads_norm = 6.6182
	old_data_grads_norm = 7.6311
	sim_grads_norm_tr = -0.0068
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2605
	data_grads_norm = 4.6512
	new_data_grads_norm = 7.2144
	old_data_grads_norm = 6.5492
	sim_grads_norm_tr = -0.0053
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4795
	data_grads_norm = 5.1972
	new_data_grads_norm = 7.7500
	old_data_grads_norm = 7.2625
	sim_grads_norm_tr = 0.0327
-- Starting training on experience 142 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2025
	data_grads_norm = 5.3444
	new_data_grads_norm = 6.3445
	old_data_grads_norm = 8.0569
	sim_grads_norm_tr = 0.0240
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9904
	data_grads_norm = 4.4321
	new_data_grads_norm = 6.1615
	old_data_grads_norm = 5.7671
	sim_grads_norm_tr = 0.0445
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9920
	data_grads_norm = 4.3760
	new_data_grads_norm = 6.3525
	old_data_grads_norm = 6.3178
	sim_grads_norm_tr = 0.0351
-- Starting training on experience 143 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1864
	data_grads_norm = 5.4906
	new_data_grads_norm = 7.2353
	old_data_grads_norm = 7.7616
	sim_grads_norm_tr = 0.0305
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1411
	data_grads_norm = 5.2463
	new_data_grads_norm = 5.5632
	old_data_grads_norm = 8.3885
	sim_grads_norm_tr = 0.0052
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7421
	data_grads_norm = 4.2256
	new_data_grads_norm = 5.9226
	old_data_grads_norm = 5.6506
	sim_grads_norm_tr = 0.1107
-- Starting training on experience 144 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1406
	data_grads_norm = 4.6273
	new_data_grads_norm = 6.6150
	old_data_grads_norm = 6.5250
	sim_grads_norm_tr = -0.0082
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1203
	data_grads_norm = 5.1462
	new_data_grads_norm = 7.4129
	old_data_grads_norm = 6.6820
	sim_grads_norm_tr = -0.0129
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0303
	data_grads_norm = 4.9255
	new_data_grads_norm = 7.2891
	old_data_grads_norm = 5.6159
	sim_grads_norm_tr = 0.0599
-- Starting training on experience 145 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4747
	data_grads_norm = 4.0582
	new_data_grads_norm = 6.7116
	old_data_grads_norm = 5.1739
	sim_grads_norm_tr = -0.0091
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1442
	data_grads_norm = 4.9873
	new_data_grads_norm = 6.2166
	old_data_grads_norm = 6.5554
	sim_grads_norm_tr = 0.0683
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4279
	data_grads_norm = 5.2720
	new_data_grads_norm = 6.4212
	old_data_grads_norm = 6.8662
	sim_grads_norm_tr = -0.0082
-- Starting training on experience 146 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5555
	data_grads_norm = 5.4989
	new_data_grads_norm = 7.1823
	old_data_grads_norm = 8.4776
	sim_grads_norm_tr = 0.0006
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3061
	data_grads_norm = 4.9724
	new_data_grads_norm = 7.2332
	old_data_grads_norm = 5.3366
	sim_grads_norm_tr = 0.0035
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5152
	data_grads_norm = 5.2213
	new_data_grads_norm = 7.7809
	old_data_grads_norm = 7.0891
	sim_grads_norm_tr = -0.0354
-- Starting training on experience 147 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7505
	data_grads_norm = 4.6546
	new_data_grads_norm = 5.4866
	old_data_grads_norm = 6.7328
	sim_grads_norm_tr = 0.0086
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1074
	data_grads_norm = 4.0234
	new_data_grads_norm = 5.3857
	old_data_grads_norm = 6.2894
	sim_grads_norm_tr = 0.0409
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5845
	data_grads_norm = 5.3561
	new_data_grads_norm = 5.6163
	old_data_grads_norm = 9.0130
	sim_grads_norm_tr = 0.0650
-- Starting training on experience 148 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0195
	data_grads_norm = 4.1542
	new_data_grads_norm = 7.3137
	old_data_grads_norm = 4.8404
	sim_grads_norm_tr = -0.0243
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8335
	data_grads_norm = 3.7810
	new_data_grads_norm = 7.4008
	old_data_grads_norm = 4.4608
	sim_grads_norm_tr = -0.0392
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1744
	data_grads_norm = 4.7126
	new_data_grads_norm = 7.6636
	old_data_grads_norm = 6.5136
	sim_grads_norm_tr = 0.0070
-- Starting training on experience 149 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6395
	data_grads_norm = 6.6394
	new_data_grads_norm = 8.5619
	old_data_grads_norm = 8.6074
	sim_grads_norm_tr = 0.0197
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3213
	data_grads_norm = 5.2059
	new_data_grads_norm = 8.0982
	old_data_grads_norm = 7.3476
	sim_grads_norm_tr = -0.0233
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9745
	data_grads_norm = 4.4762
	new_data_grads_norm = 8.2367
	old_data_grads_norm = 4.1607
	sim_grads_norm_tr = 0.0580
-- Starting training on experience 150 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4531
	data_grads_norm = 5.0212
	new_data_grads_norm = 6.2944
	old_data_grads_norm = 6.5067
	sim_grads_norm_tr = 0.0925
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0475
	data_grads_norm = 4.5951
	new_data_grads_norm = 5.9476
	old_data_grads_norm = 6.5839
	sim_grads_norm_tr = -0.0447
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2900
	data_grads_norm = 5.0233
	new_data_grads_norm = 6.2570
	old_data_grads_norm = 6.5805
	sim_grads_norm_tr = 0.0307
-- Starting training on experience 151 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0603
	data_grads_norm = 4.4852
	new_data_grads_norm = 6.1821
	old_data_grads_norm = 6.9822
	sim_grads_norm_tr = -0.0337
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4203
	data_grads_norm = 4.8599
	new_data_grads_norm = 6.6902
	old_data_grads_norm = 6.6637
	sim_grads_norm_tr = -0.0373
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0179
	data_grads_norm = 3.9458
	new_data_grads_norm = 6.5431
	old_data_grads_norm = 3.5731
	sim_grads_norm_tr = 0.1242
-- Starting training on experience 152 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0025
	data_grads_norm = 4.3967
	new_data_grads_norm = 6.3879
	old_data_grads_norm = 6.2172
	sim_grads_norm_tr = -0.0590
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5568
	data_grads_norm = 4.6325
	new_data_grads_norm = 6.4160
	old_data_grads_norm = 5.9439
	sim_grads_norm_tr = 0.0249
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5859
	data_grads_norm = 5.0919
	new_data_grads_norm = 6.7635
	old_data_grads_norm = 6.4279
	sim_grads_norm_tr = 0.0278
-- Starting training on experience 153 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7462
	data_grads_norm = 3.8721
	new_data_grads_norm = 7.0980
	old_data_grads_norm = 5.0510
	sim_grads_norm_tr = 0.0390
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1131
	data_grads_norm = 4.3588
	new_data_grads_norm = 6.1083
	old_data_grads_norm = 6.3311
	sim_grads_norm_tr = 0.0051
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1597
	data_grads_norm = 4.3141
	new_data_grads_norm = 6.0059
	old_data_grads_norm = 7.9534
	sim_grads_norm_tr = 0.0402
-- Starting training on experience 154 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9500
	data_grads_norm = 4.2067
	new_data_grads_norm = 6.7452
	old_data_grads_norm = 4.4464
	sim_grads_norm_tr = -0.0138
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2383
	data_grads_norm = 4.6223
	new_data_grads_norm = 6.7844
	old_data_grads_norm = 7.6075
	sim_grads_norm_tr = -0.0411
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1267
	data_grads_norm = 4.3110
	new_data_grads_norm = 7.2984
	old_data_grads_norm = 6.5905
	sim_grads_norm_tr = -0.0061
-- Starting training on experience 155 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7786
	data_grads_norm = 4.2346
	new_data_grads_norm = 6.0609
	old_data_grads_norm = 4.3941
	sim_grads_norm_tr = 0.0274
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0010
	data_grads_norm = 4.7904
	new_data_grads_norm = 6.4804
	old_data_grads_norm = 6.4955
	sim_grads_norm_tr = -0.0177
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1502
	data_grads_norm = 5.0259
	new_data_grads_norm = 6.9314
	old_data_grads_norm = 7.4816
	sim_grads_norm_tr = 0.0453
-- Starting training on experience 156 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5418
	data_grads_norm = 5.2891
	new_data_grads_norm = 7.6437
	old_data_grads_norm = 6.4095
	sim_grads_norm_tr = -0.0195
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3083
	data_grads_norm = 5.3087
	new_data_grads_norm = 7.4049
	old_data_grads_norm = 7.5171
	sim_grads_norm_tr = 0.0037
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4788
	data_grads_norm = 5.2919
	new_data_grads_norm = 7.2949
	old_data_grads_norm = 5.7357
	sim_grads_norm_tr = 0.0678
-- Starting training on experience 157 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2880
	data_grads_norm = 5.0820
	new_data_grads_norm = 7.1867
	old_data_grads_norm = 6.2439
	sim_grads_norm_tr = 0.0146
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8312
	data_grads_norm = 4.0254
	new_data_grads_norm = 7.1651
	old_data_grads_norm = 6.4821
	sim_grads_norm_tr = 0.0008
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7744
	data_grads_norm = 4.2275
	new_data_grads_norm = 7.6829
	old_data_grads_norm = 3.3682
	sim_grads_norm_tr = -0.0356
-- Starting training on experience 158 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2185
	data_grads_norm = 4.2042
	new_data_grads_norm = 6.4337
	old_data_grads_norm = 5.2171
	sim_grads_norm_tr = -0.0081
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1149
	data_grads_norm = 4.3057
	new_data_grads_norm = 6.3707
	old_data_grads_norm = 5.8255
	sim_grads_norm_tr = -0.0057
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4785
	data_grads_norm = 5.8206
	new_data_grads_norm = 6.9737
	old_data_grads_norm = 8.6197
	sim_grads_norm_tr = -0.0213
-- Starting training on experience 159 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4320
	data_grads_norm = 4.5446
	new_data_grads_norm = 8.4112
	old_data_grads_norm = 5.4942
	sim_grads_norm_tr = -0.0273
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5724
	data_grads_norm = 5.1950
	new_data_grads_norm = 8.7007
	old_data_grads_norm = 6.0432
	sim_grads_norm_tr = 0.0537
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6587
	data_grads_norm = 5.0195
	new_data_grads_norm = 7.5784
	old_data_grads_norm = 6.1986
	sim_grads_norm_tr = 0.0252
-- Starting training on experience 160 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9630
	data_grads_norm = 4.2887
	new_data_grads_norm = 5.6068
	old_data_grads_norm = 5.9766
	sim_grads_norm_tr = -0.0320
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5544
	data_grads_norm = 5.4567
	new_data_grads_norm = 5.9232
	old_data_grads_norm = 7.9071
	sim_grads_norm_tr = -0.0147
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4211
	data_grads_norm = 4.6294
	new_data_grads_norm = 6.6381
	old_data_grads_norm = 5.9163
	sim_grads_norm_tr = 0.0752
-- Starting training on experience 161 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5967
	data_grads_norm = 4.8254
	new_data_grads_norm = 7.5697
	old_data_grads_norm = 7.3205
	sim_grads_norm_tr = -0.0024
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8085
	data_grads_norm = 5.9649
	new_data_grads_norm = 8.2993
	old_data_grads_norm = 8.1584
	sim_grads_norm_tr = -0.0078
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1381
	data_grads_norm = 4.3721
	new_data_grads_norm = 7.7153
	old_data_grads_norm = 5.2078
	sim_grads_norm_tr = -0.0200
-- Starting training on experience 162 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4739
	data_grads_norm = 4.9251
	new_data_grads_norm = 6.6134
	old_data_grads_norm = 6.8649
	sim_grads_norm_tr = 0.0498
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8875
	data_grads_norm = 4.0052
	new_data_grads_norm = 6.0528
	old_data_grads_norm = 5.5928
	sim_grads_norm_tr = 0.0609
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3495
	data_grads_norm = 4.8958
	new_data_grads_norm = 5.9162
	old_data_grads_norm = 7.4914
	sim_grads_norm_tr = -0.0103
-- Starting training on experience 163 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0877
	data_grads_norm = 5.2731
	new_data_grads_norm = 6.5969
	old_data_grads_norm = 8.1506
	sim_grads_norm_tr = 0.0585
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5530
	data_grads_norm = 4.9812
	new_data_grads_norm = 7.0517
	old_data_grads_norm = 5.8279
	sim_grads_norm_tr = 0.0323
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3333
	data_grads_norm = 5.1781
	new_data_grads_norm = 8.1129
	old_data_grads_norm = 5.8717
	sim_grads_norm_tr = 0.0143
-- Starting training on experience 164 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9538
	data_grads_norm = 4.4698
	new_data_grads_norm = 6.7535
	old_data_grads_norm = 5.3246
	sim_grads_norm_tr = -0.0089
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5652
	data_grads_norm = 4.9428
	new_data_grads_norm = 6.7104
	old_data_grads_norm = 6.1890
	sim_grads_norm_tr = 0.0545
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8169
	data_grads_norm = 4.5126
	new_data_grads_norm = 7.0498
	old_data_grads_norm = 6.5546
	sim_grads_norm_tr = -0.0330
-- Starting training on experience 165 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4000
	data_grads_norm = 4.8017
	new_data_grads_norm = 7.4059
	old_data_grads_norm = 6.1146
	sim_grads_norm_tr = -0.0256
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0742
	data_grads_norm = 5.2602
	new_data_grads_norm = 7.7073
	old_data_grads_norm = 7.3615
	sim_grads_norm_tr = 0.0041
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1553
	data_grads_norm = 4.2708
	new_data_grads_norm = 7.2005
	old_data_grads_norm = 4.0268
	sim_grads_norm_tr = 0.0011
-- Starting training on experience 166 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6117
	data_grads_norm = 4.7761
	new_data_grads_norm = 5.6085
	old_data_grads_norm = 6.8358
	sim_grads_norm_tr = 0.0410
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8829
	data_grads_norm = 3.8408
	new_data_grads_norm = 5.8378
	old_data_grads_norm = 4.1678
	sim_grads_norm_tr = 0.0613
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3736
	data_grads_norm = 4.8856
	new_data_grads_norm = 6.1282
	old_data_grads_norm = 8.0599
	sim_grads_norm_tr = -0.0249
-- Starting training on experience 167 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7680
	data_grads_norm = 5.1734
	new_data_grads_norm = 7.4558
	old_data_grads_norm = 6.4462
	sim_grads_norm_tr = 0.0209
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1523
	data_grads_norm = 4.0203
	new_data_grads_norm = 6.8748
	old_data_grads_norm = 4.9952
	sim_grads_norm_tr = 0.0307
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6771
	data_grads_norm = 5.8021
	new_data_grads_norm = 6.9574
	old_data_grads_norm = 8.9456
	sim_grads_norm_tr = 0.0722
-- Starting training on experience 168 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7799
	data_grads_norm = 5.1832
	new_data_grads_norm = 7.0529
	old_data_grads_norm = 7.2045
	sim_grads_norm_tr = 0.0161
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9980
	data_grads_norm = 5.3659
	new_data_grads_norm = 7.3892
	old_data_grads_norm = 6.6101
	sim_grads_norm_tr = 0.0247
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3129
	data_grads_norm = 4.3487
	new_data_grads_norm = 7.2276
	old_data_grads_norm = 4.8152
	sim_grads_norm_tr = -0.0854
-- Starting training on experience 169 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3126
	data_grads_norm = 4.8699
	new_data_grads_norm = 6.3130
	old_data_grads_norm = 6.6603
	sim_grads_norm_tr = 0.0125
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6979
	data_grads_norm = 5.1112
	new_data_grads_norm = 6.6415
	old_data_grads_norm = 6.5815
	sim_grads_norm_tr = 0.0796
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4038
	data_grads_norm = 5.2828
	new_data_grads_norm = 6.6973
	old_data_grads_norm = 7.7467
	sim_grads_norm_tr = -0.0147
-- Starting training on experience 170 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1773
	data_grads_norm = 5.6533
	new_data_grads_norm = 7.1494
	old_data_grads_norm = 7.0612
	sim_grads_norm_tr = 0.0558
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7728
	data_grads_norm = 5.2165
	new_data_grads_norm = 6.9668
	old_data_grads_norm = 6.8636
	sim_grads_norm_tr = 0.0601
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3947
	data_grads_norm = 4.2440
	new_data_grads_norm = 6.7884
	old_data_grads_norm = 5.5697
	sim_grads_norm_tr = 0.0294
-- Starting training on experience 171 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2459
	data_grads_norm = 4.7272
	new_data_grads_norm = 7.0446
	old_data_grads_norm = 7.2353
	sim_grads_norm_tr = 0.0202
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2631
	data_grads_norm = 4.9309
	new_data_grads_norm = 6.6585
	old_data_grads_norm = 7.3028
	sim_grads_norm_tr = 0.0284
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0890
	data_grads_norm = 4.6408
	new_data_grads_norm = 6.8961
	old_data_grads_norm = 7.9695
	sim_grads_norm_tr = -0.0308
-- Starting training on experience 172 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0949
	data_grads_norm = 5.6413
	new_data_grads_norm = 7.9169
	old_data_grads_norm = 7.2191
	sim_grads_norm_tr = 0.0276
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2739
	data_grads_norm = 4.3092
	new_data_grads_norm = 7.0072
	old_data_grads_norm = 4.1001
	sim_grads_norm_tr = 0.0548
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5820
	data_grads_norm = 5.0406
	new_data_grads_norm = 6.9950
	old_data_grads_norm = 7.2508
	sim_grads_norm_tr = -0.0018
-- Starting training on experience 173 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8783
	data_grads_norm = 4.3276
	new_data_grads_norm = 6.5910
	old_data_grads_norm = 5.3079
	sim_grads_norm_tr = 0.0045
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2100
	data_grads_norm = 4.8516
	new_data_grads_norm = 7.8259
	old_data_grads_norm = 5.5161
	sim_grads_norm_tr = -0.0357
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0733
	data_grads_norm = 4.5610
	new_data_grads_norm = 7.4782
	old_data_grads_norm = 5.1216
	sim_grads_norm_tr = 0.0125
-- Starting training on experience 174 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0308
	data_grads_norm = 5.3194
	new_data_grads_norm = 7.7455
	old_data_grads_norm = 6.4286
	sim_grads_norm_tr = 0.0443
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0786
	data_grads_norm = 5.5297
	new_data_grads_norm = 7.1142
	old_data_grads_norm = 7.5003
	sim_grads_norm_tr = -0.0396
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2120
	data_grads_norm = 6.3649
	new_data_grads_norm = 8.2015
	old_data_grads_norm = 9.3017
	sim_grads_norm_tr = 0.0242
-- Starting training on experience 175 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1622
	data_grads_norm = 4.8890
	new_data_grads_norm = 6.6102
	old_data_grads_norm = 6.4626
	sim_grads_norm_tr = -0.0412
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3397
	data_grads_norm = 5.5923
	new_data_grads_norm = 7.3800
	old_data_grads_norm = 7.8860
	sim_grads_norm_tr = 0.0258
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7848
	data_grads_norm = 5.9438
	new_data_grads_norm = 7.1881
	old_data_grads_norm = 7.6081
	sim_grads_norm_tr = 0.1041
-- Starting training on experience 176 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5329
	data_grads_norm = 4.7052
	new_data_grads_norm = 7.0783
	old_data_grads_norm = 5.8270
	sim_grads_norm_tr = 0.0266
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5792
	data_grads_norm = 4.9645
	new_data_grads_norm = 6.6437
	old_data_grads_norm = 6.2954
	sim_grads_norm_tr = 0.0373
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8182
	data_grads_norm = 3.5522
	new_data_grads_norm = 6.2067
	old_data_grads_norm = 4.6952
	sim_grads_norm_tr = -0.0373
-- Starting training on experience 177 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6194
	data_grads_norm = 5.4980
	new_data_grads_norm = 7.8114
	old_data_grads_norm = 7.2959
	sim_grads_norm_tr = 0.0467
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4003
	data_grads_norm = 5.8919
	new_data_grads_norm = 7.3316
	old_data_grads_norm = 7.0779
	sim_grads_norm_tr = 0.0190
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2268
	data_grads_norm = 5.0905
	new_data_grads_norm = 6.5428
	old_data_grads_norm = 8.8506
	sim_grads_norm_tr = 0.0214
-- Starting training on experience 178 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0527
	data_grads_norm = 4.5362
	new_data_grads_norm = 6.6748
	old_data_grads_norm = 6.1653
	sim_grads_norm_tr = 0.0465
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0064
	data_grads_norm = 4.0949
	new_data_grads_norm = 6.7937
	old_data_grads_norm = 5.5971
	sim_grads_norm_tr = -0.0116
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3193
	data_grads_norm = 6.6538
	new_data_grads_norm = 5.8549
	old_data_grads_norm = 9.0655
	sim_grads_norm_tr = -0.0364
-- Starting training on experience 179 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1938
	data_grads_norm = 4.8519
	new_data_grads_norm = 7.4668
	old_data_grads_norm = 5.5337
	sim_grads_norm_tr = -0.0071
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5373
	data_grads_norm = 5.7030
	new_data_grads_norm = 7.2669
	old_data_grads_norm = 6.5486
	sim_grads_norm_tr = 0.0820
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8468
	data_grads_norm = 5.0774
	new_data_grads_norm = 7.5601
	old_data_grads_norm = 6.0717
	sim_grads_norm_tr = 0.0153
-- Starting training on experience 180 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3263
	data_grads_norm = 4.8243
	new_data_grads_norm = 6.6429
	old_data_grads_norm = 6.5532
	sim_grads_norm_tr = -0.0115
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1032
	data_grads_norm = 4.5690
	new_data_grads_norm = 6.8991
	old_data_grads_norm = 4.7580
	sim_grads_norm_tr = -0.0067
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9201
	data_grads_norm = 3.8624
	new_data_grads_norm = 6.5252
	old_data_grads_norm = 4.3500
	sim_grads_norm_tr = 0.0685
-- Starting training on experience 181 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8105
	data_grads_norm = 5.9725
	new_data_grads_norm = 7.0054
	old_data_grads_norm = 8.8086
	sim_grads_norm_tr = -0.0300
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0015
	data_grads_norm = 4.1162
	new_data_grads_norm = 6.9743
	old_data_grads_norm = 4.1090
	sim_grads_norm_tr = -0.0051
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2238
	data_grads_norm = 5.2165
	new_data_grads_norm = 7.5032
	old_data_grads_norm = 7.3842
	sim_grads_norm_tr = 0.0311
-- Starting training on experience 182 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1538
	data_grads_norm = 5.1243
	new_data_grads_norm = 7.4322
	old_data_grads_norm = 5.6092
	sim_grads_norm_tr = 0.0104
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9458
	data_grads_norm = 4.4227
	new_data_grads_norm = 6.9506
	old_data_grads_norm = 4.0306
	sim_grads_norm_tr = 0.0401
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7103
	data_grads_norm = 4.3972
	new_data_grads_norm = 6.4841
	old_data_grads_norm = 5.7595
	sim_grads_norm_tr = -0.0240
-- Starting training on experience 183 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2711
	data_grads_norm = 4.9359
	new_data_grads_norm = 7.0317
	old_data_grads_norm = 5.6887
	sim_grads_norm_tr = -0.0075
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5535
	data_grads_norm = 5.1252
	new_data_grads_norm = 6.7025
	old_data_grads_norm = 6.9165
	sim_grads_norm_tr = 0.0275
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8209
	data_grads_norm = 5.2787
	new_data_grads_norm = 6.7337
	old_data_grads_norm = 7.1930
	sim_grads_norm_tr = 0.0330
-- Starting training on experience 184 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5872
	data_grads_norm = 4.8193
	new_data_grads_norm = 7.1521
	old_data_grads_norm = 6.2887
	sim_grads_norm_tr = 0.0278
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1930
	data_grads_norm = 4.6480
	new_data_grads_norm = 6.2574
	old_data_grads_norm = 6.8672
	sim_grads_norm_tr = 0.0099
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5917
	data_grads_norm = 4.5537
	new_data_grads_norm = 7.0255
	old_data_grads_norm = 5.2544
	sim_grads_norm_tr = 0.0141
-- Starting training on experience 185 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9779
	data_grads_norm = 4.8236
	new_data_grads_norm = 7.1445
	old_data_grads_norm = 6.9738
	sim_grads_norm_tr = 0.0119
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9532
	data_grads_norm = 4.4287
	new_data_grads_norm = 7.0416
	old_data_grads_norm = 5.4884
	sim_grads_norm_tr = 0.0549
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6987
	data_grads_norm = 4.1344
	new_data_grads_norm = 6.4319
	old_data_grads_norm = 5.0948
	sim_grads_norm_tr = -0.0014
-- Starting training on experience 186 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9861
	data_grads_norm = 4.0755
	new_data_grads_norm = 7.3491
	old_data_grads_norm = 5.5880
	sim_grads_norm_tr = 0.0287
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1206
	data_grads_norm = 4.8835
	new_data_grads_norm = 7.8495
	old_data_grads_norm = 5.9395
	sim_grads_norm_tr = -0.0034
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6422
	data_grads_norm = 5.4365
	new_data_grads_norm = 7.5260
	old_data_grads_norm = 7.5341
	sim_grads_norm_tr = 0.0406
-- Starting training on experience 187 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7743
	data_grads_norm = 4.1852
	new_data_grads_norm = 6.3976
	old_data_grads_norm = 5.7614
	sim_grads_norm_tr = -0.0062
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7621
	data_grads_norm = 4.7035
	new_data_grads_norm = 7.1994
	old_data_grads_norm = 6.2448
	sim_grads_norm_tr = -0.0502
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3717
	data_grads_norm = 5.3020
	new_data_grads_norm = 6.4776
	old_data_grads_norm = 6.9297
	sim_grads_norm_tr = 0.0810
-- Starting training on experience 188 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7220
	data_grads_norm = 4.3704
	new_data_grads_norm = 7.9181
	old_data_grads_norm = 5.3216
	sim_grads_norm_tr = 0.0060
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5104
	data_grads_norm = 5.0006
	new_data_grads_norm = 6.7675
	old_data_grads_norm = 6.5748
	sim_grads_norm_tr = 0.1094
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0660
	data_grads_norm = 5.1695
	new_data_grads_norm = 6.9687
	old_data_grads_norm = 6.8961
	sim_grads_norm_tr = -0.0473
-- Starting training on experience 189 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7262
	data_grads_norm = 5.8302
	new_data_grads_norm = 6.7554
	old_data_grads_norm = 8.5513
	sim_grads_norm_tr = 0.0243
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1784
	data_grads_norm = 4.6453
	new_data_grads_norm = 6.8031
	old_data_grads_norm = 4.7794
	sim_grads_norm_tr = -0.0321
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0471
	data_grads_norm = 4.8633
	new_data_grads_norm = 7.0026
	old_data_grads_norm = 5.0202
	sim_grads_norm_tr = -0.0111
-- Starting training on experience 190 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2066
	data_grads_norm = 5.1891
	new_data_grads_norm = 8.6230
	old_data_grads_norm = 7.5217
	sim_grads_norm_tr = -0.0167
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3827
	data_grads_norm = 5.3188
	new_data_grads_norm = 8.0098
	old_data_grads_norm = 6.0871
	sim_grads_norm_tr = -0.0405
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2017
	data_grads_norm = 6.6631
	new_data_grads_norm = 9.4962
	old_data_grads_norm = 8.0238
	sim_grads_norm_tr = 0.0299
-- Starting training on experience 191 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7395
	data_grads_norm = 4.0448
	new_data_grads_norm = 6.2304
	old_data_grads_norm = 5.8560
	sim_grads_norm_tr = -0.0344
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9560
	data_grads_norm = 4.8141
	new_data_grads_norm = 7.4676
	old_data_grads_norm = 5.4033
	sim_grads_norm_tr = -0.0247
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4387
	data_grads_norm = 5.1762
	new_data_grads_norm = 6.9658
	old_data_grads_norm = 6.5524
	sim_grads_norm_tr = 0.0633
-- Starting training on experience 192 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7462
	data_grads_norm = 3.9068
	new_data_grads_norm = 6.5381
	old_data_grads_norm = 3.8867
	sim_grads_norm_tr = -0.0081
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5147
	data_grads_norm = 5.0221
	new_data_grads_norm = 6.5563
	old_data_grads_norm = 7.6311
	sim_grads_norm_tr = -0.0397
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5437
	data_grads_norm = 5.1324
	new_data_grads_norm = 6.7539
	old_data_grads_norm = 5.8754
	sim_grads_norm_tr = 0.0490
-- Starting training on experience 193 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9042
	data_grads_norm = 6.1996
	new_data_grads_norm = 8.6567
	old_data_grads_norm = 6.1205
	sim_grads_norm_tr = 0.0140
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8134
	data_grads_norm = 6.4924
	new_data_grads_norm = 8.3684
	old_data_grads_norm = 7.1049
	sim_grads_norm_tr = 0.0065
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6923
	data_grads_norm = 6.6951
	new_data_grads_norm = 8.5702
	old_data_grads_norm = 6.9575
	sim_grads_norm_tr = 0.0254
-- Starting training on experience 194 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3172
	data_grads_norm = 5.2371
	new_data_grads_norm = 7.3671
	old_data_grads_norm = 7.3746
	sim_grads_norm_tr = -0.0007
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5388
	data_grads_norm = 5.6234
	new_data_grads_norm = 8.0603
	old_data_grads_norm = 7.3376
	sim_grads_norm_tr = 0.0136
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5391
	data_grads_norm = 5.1483
	new_data_grads_norm = 7.4221
	old_data_grads_norm = 5.3382
	sim_grads_norm_tr = 0.0213
-- Starting training on experience 195 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2993
	data_grads_norm = 5.0491
	new_data_grads_norm = 6.9617
	old_data_grads_norm = 6.1911
	sim_grads_norm_tr = 0.0211
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5629
	data_grads_norm = 5.8192
	new_data_grads_norm = 7.4002
	old_data_grads_norm = 8.2792
	sim_grads_norm_tr = 0.0066
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4983
	data_grads_norm = 6.4549
	new_data_grads_norm = 7.3384
	old_data_grads_norm = 9.3677
	sim_grads_norm_tr = 0.0020
-- Starting training on experience 196 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7094
	data_grads_norm = 3.7526
	new_data_grads_norm = 7.2083
	old_data_grads_norm = 5.3996
	sim_grads_norm_tr = -0.0548
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3727
	data_grads_norm = 5.1437
	new_data_grads_norm = 7.5061
	old_data_grads_norm = 6.1590
	sim_grads_norm_tr = 0.0448
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2589
	data_grads_norm = 5.3976
	new_data_grads_norm = 7.0765
	old_data_grads_norm = 7.1520
	sim_grads_norm_tr = 0.0391
-- Starting training on experience 197 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0334
	data_grads_norm = 5.4040
	new_data_grads_norm = 7.9671
	old_data_grads_norm = 5.4388
	sim_grads_norm_tr = 0.0305
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1090
	data_grads_norm = 4.8835
	new_data_grads_norm = 7.6394
	old_data_grads_norm = 4.8155
	sim_grads_norm_tr = 0.0243
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4939
	data_grads_norm = 5.4192
	new_data_grads_norm = 7.4964
	old_data_grads_norm = 6.5270
	sim_grads_norm_tr = -0.0437
-- Starting training on experience 198 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9118
	data_grads_norm = 5.4439
	new_data_grads_norm = 7.7137
	old_data_grads_norm = 6.7622
	sim_grads_norm_tr = -0.0022
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3836
	data_grads_norm = 4.7845
	new_data_grads_norm = 7.9996
	old_data_grads_norm = 4.0753
	sim_grads_norm_tr = 0.0184
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5583
	data_grads_norm = 5.5405
	new_data_grads_norm = 7.9507
	old_data_grads_norm = 6.7414
	sim_grads_norm_tr = 0.0017
-- Starting training on experience 199 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6233
	data_grads_norm = 5.5350
	new_data_grads_norm = 8.9368
	old_data_grads_norm = 5.4936
	sim_grads_norm_tr = -0.0379
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8622
	data_grads_norm = 5.4713
	new_data_grads_norm = 8.6014
	old_data_grads_norm = 6.2697
	sim_grads_norm_tr = -0.0005
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1440
	data_grads_norm = 5.8223
	new_data_grads_norm = 8.4958
	old_data_grads_norm = 6.1860
	sim_grads_norm_tr = 0.0407
-- Starting training on experience 200 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4682
	data_grads_norm = 5.0468
	new_data_grads_norm = 7.3994
	old_data_grads_norm = 6.6376
	sim_grads_norm_tr = 0.0143
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3137
	data_grads_norm = 4.3199
	new_data_grads_norm = 7.6943
	old_data_grads_norm = 4.9093
	sim_grads_norm_tr = 0.0239
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3530
	data_grads_norm = 4.5566
	new_data_grads_norm = 7.3623
	old_data_grads_norm = 6.1129
	sim_grads_norm_tr = -0.0148
-- Starting training on experience 201 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7448
	data_grads_norm = 5.4860
	new_data_grads_norm = 7.6900
	old_data_grads_norm = 7.0148
	sim_grads_norm_tr = 0.0437
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5215
	data_grads_norm = 5.1337
	new_data_grads_norm = 7.2925
	old_data_grads_norm = 6.2863
	sim_grads_norm_tr = -0.0007
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9759
	data_grads_norm = 4.4716
	new_data_grads_norm = 7.5356
	old_data_grads_norm = 5.1052
	sim_grads_norm_tr = 0.0228
-- Starting training on experience 202 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8334
	data_grads_norm = 5.6822
	new_data_grads_norm = 8.4416
	old_data_grads_norm = 6.5126
	sim_grads_norm_tr = 0.0226
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9133
	data_grads_norm = 6.1929
	new_data_grads_norm = 8.8951
	old_data_grads_norm = 7.8577
	sim_grads_norm_tr = -0.0099
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9533
	data_grads_norm = 5.7395
	new_data_grads_norm = 8.4862
	old_data_grads_norm = 5.6622
	sim_grads_norm_tr = 0.0109
-- Starting training on experience 203 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4981
	data_grads_norm = 5.4839
	new_data_grads_norm = 7.3245
	old_data_grads_norm = 7.5981
	sim_grads_norm_tr = 0.0237
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1404
	data_grads_norm = 4.6836
	new_data_grads_norm = 5.9371
	old_data_grads_norm = 7.2964
	sim_grads_norm_tr = -0.0027
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3884
	data_grads_norm = 5.0326
	new_data_grads_norm = 7.4238
	old_data_grads_norm = 6.5959
	sim_grads_norm_tr = 0.0088
-- Starting training on experience 204 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7789
	data_grads_norm = 4.2096
	new_data_grads_norm = 7.4780
	old_data_grads_norm = 3.9186
	sim_grads_norm_tr = -0.0317
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5552
	data_grads_norm = 5.8029
	new_data_grads_norm = 8.0855
	old_data_grads_norm = 6.5711
	sim_grads_norm_tr = 0.0159
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1350
	data_grads_norm = 5.1307
	new_data_grads_norm = 8.6171
	old_data_grads_norm = 6.3839
	sim_grads_norm_tr = -0.0371
-- Starting training on experience 205 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2856
	data_grads_norm = 5.1964
	new_data_grads_norm = 7.1156
	old_data_grads_norm = 5.6901
	sim_grads_norm_tr = -0.0222
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8927
	data_grads_norm = 4.8090
	new_data_grads_norm = 7.5637
	old_data_grads_norm = 5.6292
	sim_grads_norm_tr = -0.0050
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3105
	data_grads_norm = 5.5811
	new_data_grads_norm = 7.8520
	old_data_grads_norm = 5.9265
	sim_grads_norm_tr = 0.0678
-- Starting training on experience 206 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6767
	data_grads_norm = 5.9718
	new_data_grads_norm = 7.9472
	old_data_grads_norm = 8.1522
	sim_grads_norm_tr = 0.0062
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5014
	data_grads_norm = 4.8380
	new_data_grads_norm = 8.0878
	old_data_grads_norm = 6.0291
	sim_grads_norm_tr = 0.0299
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6114
	data_grads_norm = 5.2426
	new_data_grads_norm = 7.6283
	old_data_grads_norm = 6.3048
	sim_grads_norm_tr = 0.0469
-- Starting training on experience 207 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5899
	data_grads_norm = 5.5765
	new_data_grads_norm = 6.8451
	old_data_grads_norm = 7.8669
	sim_grads_norm_tr = 0.0176
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2455
	data_grads_norm = 5.0385
	new_data_grads_norm = 6.9491
	old_data_grads_norm = 7.2120
	sim_grads_norm_tr = -0.0047
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1758
	data_grads_norm = 4.5573
	new_data_grads_norm = 6.8909
	old_data_grads_norm = 5.7502
	sim_grads_norm_tr = -0.0048
-- Starting training on experience 208 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8944
	data_grads_norm = 4.3598
	new_data_grads_norm = 8.0340
	old_data_grads_norm = 4.7347
	sim_grads_norm_tr = 0.0206
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8365
	data_grads_norm = 4.6272
	new_data_grads_norm = 7.8897
	old_data_grads_norm = 4.5049
	sim_grads_norm_tr = -0.0759
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2409
	data_grads_norm = 4.6803
	new_data_grads_norm = 8.3334
	old_data_grads_norm = 6.4943
	sim_grads_norm_tr = -0.0146
-- Starting training on experience 209 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9478
	data_grads_norm = 5.1188
	new_data_grads_norm = 6.1840
	old_data_grads_norm = 6.8921
	sim_grads_norm_tr = 0.0163
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0124
	data_grads_norm = 4.1537
	new_data_grads_norm = 6.1158
	old_data_grads_norm = 5.3869
	sim_grads_norm_tr = 0.0218
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6743
	data_grads_norm = 4.5288
	new_data_grads_norm = 6.2551
	old_data_grads_norm = 5.5463
	sim_grads_norm_tr = 0.0936
-- Starting training on experience 210 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9524
	data_grads_norm = 4.3352
	new_data_grads_norm = 6.6450
	old_data_grads_norm = 6.3546
	sim_grads_norm_tr = 0.0128
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8711
	data_grads_norm = 4.4126
	new_data_grads_norm = 6.6073
	old_data_grads_norm = 6.4676
	sim_grads_norm_tr = -0.0586
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0290
	data_grads_norm = 4.2346
	new_data_grads_norm = 6.4745
	old_data_grads_norm = 5.6220
	sim_grads_norm_tr = 0.0383
-- Starting training on experience 211 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1220
	data_grads_norm = 4.2491
	new_data_grads_norm = 6.7311
	old_data_grads_norm = 4.2881
	sim_grads_norm_tr = -0.0170
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2681
	data_grads_norm = 4.9336
	new_data_grads_norm = 7.2615
	old_data_grads_norm = 7.6894
	sim_grads_norm_tr = -0.0242
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7805
	data_grads_norm = 5.3856
	new_data_grads_norm = 7.4727
	old_data_grads_norm = 6.6173
	sim_grads_norm_tr = 0.0647
-- Starting training on experience 212 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4971
	data_grads_norm = 6.0650
	new_data_grads_norm = 6.5801
	old_data_grads_norm = 9.5962
	sim_grads_norm_tr = -0.0007
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7438
	data_grads_norm = 5.0205
	new_data_grads_norm = 7.1540
	old_data_grads_norm = 7.7832
	sim_grads_norm_tr = 0.0327
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4454
	data_grads_norm = 5.1136
	new_data_grads_norm = 7.0904
	old_data_grads_norm = 7.5709
	sim_grads_norm_tr = -0.0265
-- Starting training on experience 213 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5861
	data_grads_norm = 5.4333
	new_data_grads_norm = 8.3451
	old_data_grads_norm = 7.0484
	sim_grads_norm_tr = -0.0376
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9998
	data_grads_norm = 4.7710
	new_data_grads_norm = 8.2031
	old_data_grads_norm = 6.3872
	sim_grads_norm_tr = 0.0271
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2695
	data_grads_norm = 5.3850
	new_data_grads_norm = 7.4405
	old_data_grads_norm = 7.6988
	sim_grads_norm_tr = -0.0264
-- Starting training on experience 214 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5576
	data_grads_norm = 6.0509
	new_data_grads_norm = 8.0843
	old_data_grads_norm = 6.2543
	sim_grads_norm_tr = -0.0129
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9687
	data_grads_norm = 4.8146
	new_data_grads_norm = 8.0902
	old_data_grads_norm = 4.2209
	sim_grads_norm_tr = -0.0604
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4293
	data_grads_norm = 4.8779
	new_data_grads_norm = 7.8821
	old_data_grads_norm = 5.9731
	sim_grads_norm_tr = 0.0025
-- Starting training on experience 215 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0015
	data_grads_norm = 3.9143
	new_data_grads_norm = 6.8117
	old_data_grads_norm = 5.1223
	sim_grads_norm_tr = 0.0246
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4748
	data_grads_norm = 5.3130
	new_data_grads_norm = 6.5532
	old_data_grads_norm = 8.1085
	sim_grads_norm_tr = -0.0288
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5363
	data_grads_norm = 5.3479
	new_data_grads_norm = 6.6688
	old_data_grads_norm = 8.3202
	sim_grads_norm_tr = 0.0547
-- Starting training on experience 216 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0795
	data_grads_norm = 4.4147
	new_data_grads_norm = 6.9960
	old_data_grads_norm = 5.2662
	sim_grads_norm_tr = 0.0445
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0379
	data_grads_norm = 4.9316
	new_data_grads_norm = 7.2255
	old_data_grads_norm = 6.7131
	sim_grads_norm_tr = 0.0314
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6616
	data_grads_norm = 6.0099
	new_data_grads_norm = 7.6833
	old_data_grads_norm = 8.0373
	sim_grads_norm_tr = 0.0650
-- Starting training on experience 217 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7878
	data_grads_norm = 5.2128
	new_data_grads_norm = 8.2861
	old_data_grads_norm = 5.7284
	sim_grads_norm_tr = -0.0902
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0212
	data_grads_norm = 5.9549
	new_data_grads_norm = 9.0660
	old_data_grads_norm = 7.5555
	sim_grads_norm_tr = 0.0149
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9193
	data_grads_norm = 4.9650
	new_data_grads_norm = 8.3000
	old_data_grads_norm = 4.9541
	sim_grads_norm_tr = -0.0459
-- Starting training on experience 218 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1058
	data_grads_norm = 5.0210
	new_data_grads_norm = 8.4931
	old_data_grads_norm = 5.6213
	sim_grads_norm_tr = -0.0068
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6527
	data_grads_norm = 5.5648
	new_data_grads_norm = 8.4192
	old_data_grads_norm = 6.4344
	sim_grads_norm_tr = 0.0790
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5358
	data_grads_norm = 6.3889
	new_data_grads_norm = 8.0979
	old_data_grads_norm = 8.9561
	sim_grads_norm_tr = 0.0041
-- Starting training on experience 219 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6909
	data_grads_norm = 5.7973
	new_data_grads_norm = 6.9080
	old_data_grads_norm = 6.3333
	sim_grads_norm_tr = 0.0009
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0286
	data_grads_norm = 5.4692
	new_data_grads_norm = 8.3890
	old_data_grads_norm = 6.3205
	sim_grads_norm_tr = 0.0404
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8251
	data_grads_norm = 5.5777
	new_data_grads_norm = 8.1516
	old_data_grads_norm = 5.9928
	sim_grads_norm_tr = 0.0163
-- Starting training on experience 220 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9280
	data_grads_norm = 4.5658
	new_data_grads_norm = 6.6685
	old_data_grads_norm = 5.1604
	sim_grads_norm_tr = 0.0449
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8777
	data_grads_norm = 4.9999
	new_data_grads_norm = 7.4940
	old_data_grads_norm = 8.5637
	sim_grads_norm_tr = -0.0396
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1030
	data_grads_norm = 4.3599
	new_data_grads_norm = 6.8916
	old_data_grads_norm = 5.0742
	sim_grads_norm_tr = 0.0977
-- Starting training on experience 221 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8161
	data_grads_norm = 4.8531
	new_data_grads_norm = 7.6421
	old_data_grads_norm = 4.9735
	sim_grads_norm_tr = 0.0325
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3198
	data_grads_norm = 5.6461
	new_data_grads_norm = 8.4638
	old_data_grads_norm = 7.1002
	sim_grads_norm_tr = -0.0437
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0005
	data_grads_norm = 5.8822
	new_data_grads_norm = 8.7678
	old_data_grads_norm = 4.9268
	sim_grads_norm_tr = -0.0216
-- Starting training on experience 222 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2121
	data_grads_norm = 4.7647
	new_data_grads_norm = 6.4793
	old_data_grads_norm = 6.8284
	sim_grads_norm_tr = -0.0061
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9616
	data_grads_norm = 4.1931
	new_data_grads_norm = 6.8451
	old_data_grads_norm = 5.3505
	sim_grads_norm_tr = -0.0254
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9356
	data_grads_norm = 4.5534
	new_data_grads_norm = 7.0522
	old_data_grads_norm = 6.1049
	sim_grads_norm_tr = 0.0027
-- Starting training on experience 223 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6243
	data_grads_norm = 5.1678
	new_data_grads_norm = 7.8011
	old_data_grads_norm = 8.2005
	sim_grads_norm_tr = 0.0498
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8658
	data_grads_norm = 4.7310
	new_data_grads_norm = 7.9476
	old_data_grads_norm = 5.9810
	sim_grads_norm_tr = -0.0287
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3936
	data_grads_norm = 6.2508
	new_data_grads_norm = 8.0352
	old_data_grads_norm = 8.7448
	sim_grads_norm_tr = -0.0098
-- Starting training on experience 224 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6808
	data_grads_norm = 5.5081
	new_data_grads_norm = 7.4260
	old_data_grads_norm = 7.4549
	sim_grads_norm_tr = 0.0396
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4192
	data_grads_norm = 5.1503
	new_data_grads_norm = 7.3716
	old_data_grads_norm = 6.7180
	sim_grads_norm_tr = 0.0491
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0410
	data_grads_norm = 5.0175
	new_data_grads_norm = 7.7256
	old_data_grads_norm = 6.5608
	sim_grads_norm_tr = -0.0331
-- Starting training on experience 225 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5599
	data_grads_norm = 5.7865
	new_data_grads_norm = 8.0858
	old_data_grads_norm = 6.9325
	sim_grads_norm_tr = -0.0217
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4798
	data_grads_norm = 5.7630
	new_data_grads_norm = 7.6256
	old_data_grads_norm = 9.0673
	sim_grads_norm_tr = 0.0244
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2988
	data_grads_norm = 4.6216
	new_data_grads_norm = 7.8013
	old_data_grads_norm = 5.3465
	sim_grads_norm_tr = 0.0023
-- Starting training on experience 226 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0649
	data_grads_norm = 4.1088
	new_data_grads_norm = 7.5836
	old_data_grads_norm = 3.9444
	sim_grads_norm_tr = -0.0089
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9365
	data_grads_norm = 5.8607
	new_data_grads_norm = 7.4616
	old_data_grads_norm = 8.0529
	sim_grads_norm_tr = 0.0926
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9391
	data_grads_norm = 4.2371
	new_data_grads_norm = 6.1634
	old_data_grads_norm = 4.9471
	sim_grads_norm_tr = 0.0647
-- Starting training on experience 227 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6296
	data_grads_norm = 5.3976
	new_data_grads_norm = 6.3346
	old_data_grads_norm = 8.5654
	sim_grads_norm_tr = -0.0156
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6166
	data_grads_norm = 5.0940
	new_data_grads_norm = 6.4733
	old_data_grads_norm = 6.9855
	sim_grads_norm_tr = 0.0125
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0489
	data_grads_norm = 6.4462
	new_data_grads_norm = 6.9508
	old_data_grads_norm = 8.6939
	sim_grads_norm_tr = -0.0027
-- Starting training on experience 228 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2788
	data_grads_norm = 4.7993
	new_data_grads_norm = 7.0156
	old_data_grads_norm = 5.0879
	sim_grads_norm_tr = 0.1189
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9440
	data_grads_norm = 4.6816
	new_data_grads_norm = 7.7944
	old_data_grads_norm = 5.0444
	sim_grads_norm_tr = -0.0178
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8369
	data_grads_norm = 5.5631
	new_data_grads_norm = 6.4253
	old_data_grads_norm = 8.1774
	sim_grads_norm_tr = -0.0334
-- Starting training on experience 229 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5636
	data_grads_norm = 5.6631
	new_data_grads_norm = 7.1781
	old_data_grads_norm = 9.3704
	sim_grads_norm_tr = -0.0368
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8507
	data_grads_norm = 6.5902
	new_data_grads_norm = 7.7593
	old_data_grads_norm = 10.1152
	sim_grads_norm_tr = -0.0539
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8420
	data_grads_norm = 4.7236
	new_data_grads_norm = 7.6672
	old_data_grads_norm = 5.2370
	sim_grads_norm_tr = 0.0363
-- Starting training on experience 230 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4520
	data_grads_norm = 5.5752
	new_data_grads_norm = 8.6885
	old_data_grads_norm = 7.0492
	sim_grads_norm_tr = -0.0186
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6497
	data_grads_norm = 5.4081
	new_data_grads_norm = 9.2925
	old_data_grads_norm = 4.9247
	sim_grads_norm_tr = 0.0459
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4065
	data_grads_norm = 5.0310
	new_data_grads_norm = 8.5044
	old_data_grads_norm = 5.4005
	sim_grads_norm_tr = 0.0323
-- Starting training on experience 231 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3924
	data_grads_norm = 5.0212
	new_data_grads_norm = 6.6114
	old_data_grads_norm = 8.2994
	sim_grads_norm_tr = -0.0068
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9437
	data_grads_norm = 4.6004
	new_data_grads_norm = 6.3754
	old_data_grads_norm = 7.8858
	sim_grads_norm_tr = -0.0362
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4405
	data_grads_norm = 5.2188
	new_data_grads_norm = 6.7341
	old_data_grads_norm = 6.1722
	sim_grads_norm_tr = 0.0727
-- Starting training on experience 232 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1487
	data_grads_norm = 4.8136
	new_data_grads_norm = 7.0932
	old_data_grads_norm = 7.4439
	sim_grads_norm_tr = 0.0035
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1820
	data_grads_norm = 5.7313
	new_data_grads_norm = 7.5123
	old_data_grads_norm = 7.4130
	sim_grads_norm_tr = 0.0278
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1162
	data_grads_norm = 5.1125
	new_data_grads_norm = 7.4874
	old_data_grads_norm = 6.1442
	sim_grads_norm_tr = 0.0103
-- Starting training on experience 233 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2926
	data_grads_norm = 5.4645
	new_data_grads_norm = 8.1426
	old_data_grads_norm = 7.6509
	sim_grads_norm_tr = -0.0305
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4495
	data_grads_norm = 5.3191
	new_data_grads_norm = 8.5017
	old_data_grads_norm = 4.2366
	sim_grads_norm_tr = 0.1020
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3639
	data_grads_norm = 6.0196
	new_data_grads_norm = 8.1851
	old_data_grads_norm = 8.5789
	sim_grads_norm_tr = 0.0474
-- Starting training on experience 234 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1923
	data_grads_norm = 5.1903
	new_data_grads_norm = 7.1675
	old_data_grads_norm = 7.8811
	sim_grads_norm_tr = -0.0457
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5375
	data_grads_norm = 5.6988
	new_data_grads_norm = 8.2979
	old_data_grads_norm = 7.6067
	sim_grads_norm_tr = 0.0206
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9170
	data_grads_norm = 4.6169
	new_data_grads_norm = 7.6493
	old_data_grads_norm = 5.5358
	sim_grads_norm_tr = 0.0249
-- Starting training on experience 235 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7217
	data_grads_norm = 5.6881
	new_data_grads_norm = 8.3324
	old_data_grads_norm = 7.4532
	sim_grads_norm_tr = 0.0591
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7400
	data_grads_norm = 5.5846
	new_data_grads_norm = 8.3109
	old_data_grads_norm = 6.4550
	sim_grads_norm_tr = 0.0139
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1931
	data_grads_norm = 4.8494
	new_data_grads_norm = 8.0598
	old_data_grads_norm = 5.7453
	sim_grads_norm_tr = -0.0405
-- Starting training on experience 236 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5699
	data_grads_norm = 5.2469
	new_data_grads_norm = 7.1847
	old_data_grads_norm = 7.8049
	sim_grads_norm_tr = 0.0064
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0963
	data_grads_norm = 4.4274
	new_data_grads_norm = 6.6839
	old_data_grads_norm = 5.3695
	sim_grads_norm_tr = -0.0159
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8960
	data_grads_norm = 5.2636
	new_data_grads_norm = 7.6868
	old_data_grads_norm = 8.4691
	sim_grads_norm_tr = -0.0139
-- Starting training on experience 237 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
-- >> End of training phase << --
-- >> Start of eval phase << --
-- Starting eval on experience 0 (Task 0) from test stream --
> Eval on experience 0 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp000 = 4.6017
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.1180
	mb_index = 2856
	time = 925.8861
-- Starting eval on experience 1 (Task 0) from test stream --
> Eval on experience 1 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp001 = 2.4794
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.4800
-- Starting eval on experience 2 (Task 0) from test stream --
> Eval on experience 2 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp002 = 3.1568
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.2860
-- Starting eval on experience 3 (Task 0) from test stream --
> Eval on experience 3 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp003 = 2.3646
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.5320
-- Starting eval on experience 4 (Task 0) from test stream --
> Eval on experience 4 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp004 = 3.4746
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.2440
-- Starting eval on experience 5 (Task 0) from test stream --
> Eval on experience 5 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp005 = 3.0518
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.3480
-- Starting eval on experience 6 (Task 0) from test stream --
> Eval on experience 6 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp006 = 3.3368
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp006 = 0.2000
-- Starting eval on experience 7 (Task 0) from test stream --
> Eval on experience 7 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp007 = 2.6544
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp007 = 0.4060
-- Starting eval on experience 8 (Task 0) from test stream --
> Eval on experience 8 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp008 = 2.6687
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp008 = 0.4140
-- Starting eval on experience 9 (Task 0) from test stream --
> Eval on experience 9 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp009 = 2.5261
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp009 = 0.3180
-- Starting eval on experience 10 (Task 0) from test stream --
> Eval on experience 10 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp010 = 3.0730
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp010 = 0.2020
-- Starting eval on experience 11 (Task 0) from test stream --
> Eval on experience 11 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp011 = 3.1394
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp011 = 0.2600
-- >> End of eval phase << --
	CumulativeAccuracy/eval_phase/test_stream/Exp000 = 0.7100
	CumulativeAccuracy/eval_phase/test_stream/Exp001 = 0.6530
	CumulativeAccuracy/eval_phase/test_stream/Exp002 = 0.5527
	CumulativeAccuracy/eval_phase/test_stream/Exp003 = 0.5360
	CumulativeAccuracy/eval_phase/test_stream/Exp004 = 0.4796
	CumulativeAccuracy/eval_phase/test_stream/Exp005 = 0.4370
	CumulativeAccuracy/eval_phase/test_stream/Exp006 = 0.4103
	CumulativeAccuracy/eval_phase/test_stream/Exp007 = 0.3835
	CumulativeAccuracy/eval_phase/test_stream/Exp008 = 0.3700
	CumulativeAccuracy/eval_phase/test_stream/Exp009 = 0.3490
	CumulativeAccuracy/eval_phase/test_stream/Exp010 = 0.3265
	CumulativeAccuracy/eval_phase/test_stream/Exp011 = 0.3173
	Loss_Stream/eval_phase/test_stream/Task000 = 3.0439
	Top1_Acc_Stream/eval_phase/test_stream/Task000 = 0.3173
-- >> Start of training phase << --
-- Starting training on experience 0 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8939
	data_grads_norm = 4.4199
	new_data_grads_norm = 6.7884
	old_data_grads_norm = 4.8485
	sim_grads_norm_tr = 0.0167
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0204
	data_grads_norm = 5.0894
	new_data_grads_norm = 6.8571
	old_data_grads_norm = 7.2461
	sim_grads_norm_tr = 0.0256
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1857
	data_grads_norm = 4.5991
	new_data_grads_norm = 6.7629
	old_data_grads_norm = 6.3273
	sim_grads_norm_tr = 0.0300
-- Starting training on experience 1 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6729
	data_grads_norm = 5.6416
	new_data_grads_norm = 8.4904
	old_data_grads_norm = 6.0376
	sim_grads_norm_tr = -0.0295
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6584
	data_grads_norm = 5.4471
	new_data_grads_norm = 8.4154
	old_data_grads_norm = 5.6340
	sim_grads_norm_tr = -0.0052
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.9467
	data_grads_norm = 5.7698
	new_data_grads_norm = 8.3420
	old_data_grads_norm = 6.9403
	sim_grads_norm_tr = 0.0237
-- Starting training on experience 2 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2500
	data_grads_norm = 4.7824
	new_data_grads_norm = 7.3992
	old_data_grads_norm = 6.2416
	sim_grads_norm_tr = 0.0195
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7599
	data_grads_norm = 3.9726
	new_data_grads_norm = 6.5037
	old_data_grads_norm = 4.5369
	sim_grads_norm_tr = 0.0226
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3873
	data_grads_norm = 5.0980
	new_data_grads_norm = 6.8922
	old_data_grads_norm = 5.4607
	sim_grads_norm_tr = -0.0038
-- Starting training on experience 3 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3746
	data_grads_norm = 5.2662
	new_data_grads_norm = 6.7341
	old_data_grads_norm = 7.1588
	sim_grads_norm_tr = 0.0413
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.0782
	data_grads_norm = 5.6641
	new_data_grads_norm = 7.0004
	old_data_grads_norm = 7.5431
	sim_grads_norm_tr = 0.0186
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0899
	data_grads_norm = 4.6927
	new_data_grads_norm = 6.7529
	old_data_grads_norm = 5.6528
	sim_grads_norm_tr = 0.0114
-- Starting training on experience 4 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0060
	data_grads_norm = 4.5218
	new_data_grads_norm = 6.4431
	old_data_grads_norm = 5.3566
	sim_grads_norm_tr = 0.0282
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6841
	data_grads_norm = 4.5869
	new_data_grads_norm = 6.2323
	old_data_grads_norm = 5.5731
	sim_grads_norm_tr = 0.1012
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2824
	data_grads_norm = 4.8469
	new_data_grads_norm = 6.6210
	old_data_grads_norm = 6.9095
	sim_grads_norm_tr = 0.0522
-- Starting training on experience 5 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6055
	data_grads_norm = 5.6773
	new_data_grads_norm = 6.8106
	old_data_grads_norm = 7.8003
	sim_grads_norm_tr = -0.0077
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0470
	data_grads_norm = 4.6668
	new_data_grads_norm = 7.1826
	old_data_grads_norm = 4.8229
	sim_grads_norm_tr = 0.0067
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3402
	data_grads_norm = 5.3472
	new_data_grads_norm = 7.3577
	old_data_grads_norm = 6.9260
	sim_grads_norm_tr = 0.0441
-- Starting training on experience 6 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3323
	data_grads_norm = 5.6212
	new_data_grads_norm = 8.2178
	old_data_grads_norm = 6.1208
	sim_grads_norm_tr = 0.0168
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.9331
	data_grads_norm = 6.1631
	new_data_grads_norm = 8.5061
	old_data_grads_norm = 8.0925
	sim_grads_norm_tr = -0.0062
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2843
	data_grads_norm = 4.9806
	new_data_grads_norm = 8.1824
	old_data_grads_norm = 4.7726
	sim_grads_norm_tr = 0.1131
-- Starting training on experience 7 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9087
	data_grads_norm = 4.6703
	new_data_grads_norm = 6.6668
	old_data_grads_norm = 5.4971
	sim_grads_norm_tr = -0.0087
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8225
	data_grads_norm = 4.7146
	new_data_grads_norm = 7.2368
	old_data_grads_norm = 4.3547
	sim_grads_norm_tr = -0.0493
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1298
	data_grads_norm = 4.8305
	new_data_grads_norm = 7.1498
	old_data_grads_norm = 6.1675
	sim_grads_norm_tr = 0.0716
-- Starting training on experience 8 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0394
	data_grads_norm = 4.8517
	new_data_grads_norm = 7.6178
	old_data_grads_norm = 4.0044
	sim_grads_norm_tr = -0.0009
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1851
	data_grads_norm = 5.0592
	new_data_grads_norm = 7.0908
	old_data_grads_norm = 6.6911
	sim_grads_norm_tr = -0.0073
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.9077
	data_grads_norm = 6.7134
	new_data_grads_norm = 8.3777
	old_data_grads_norm = 8.8873
	sim_grads_norm_tr = 0.0155
-- Starting training on experience 9 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9484
	data_grads_norm = 4.4918
	new_data_grads_norm = 7.4164
	old_data_grads_norm = 6.4540
	sim_grads_norm_tr = -0.0090
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2593
	data_grads_norm = 5.7499
	new_data_grads_norm = 7.6444
	old_data_grads_norm = 8.5173
	sim_grads_norm_tr = -0.0168
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1579
	data_grads_norm = 4.7178
	new_data_grads_norm = 7.4241
	old_data_grads_norm = 5.1926
	sim_grads_norm_tr = 0.0329
-- Starting training on experience 10 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5035
	data_grads_norm = 5.0471
	new_data_grads_norm = 6.8412
	old_data_grads_norm = 6.5821
	sim_grads_norm_tr = 0.0046
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3186
	data_grads_norm = 5.2786
	new_data_grads_norm = 6.7564
	old_data_grads_norm = 6.4091
	sim_grads_norm_tr = 0.0308
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0126
	data_grads_norm = 4.5075
	new_data_grads_norm = 6.5777
	old_data_grads_norm = 4.9544
	sim_grads_norm_tr = -0.0549
-- Starting training on experience 11 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.7235
	data_grads_norm = 5.1603
	new_data_grads_norm = 8.1000
	old_data_grads_norm = 5.0557
	sim_grads_norm_tr = 0.1198
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4063
	data_grads_norm = 5.9681
	new_data_grads_norm = 8.4134
	old_data_grads_norm = 7.1746
	sim_grads_norm_tr = 0.0018
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9791
	data_grads_norm = 4.8991
	new_data_grads_norm = 8.0911
	old_data_grads_norm = 6.5204
	sim_grads_norm_tr = 0.0055
-- Starting training on experience 12 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.7863
	data_grads_norm = 5.8021
	new_data_grads_norm = 7.3589
	old_data_grads_norm = 7.4104
	sim_grads_norm_tr = 0.0307
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9284
	data_grads_norm = 4.5842
	new_data_grads_norm = 7.6612
	old_data_grads_norm = 5.6470
	sim_grads_norm_tr = 0.0382
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8637
	data_grads_norm = 4.3924
	new_data_grads_norm = 7.0198
	old_data_grads_norm = 5.7650
	sim_grads_norm_tr = -0.0111
-- Starting training on experience 13 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8250
	data_grads_norm = 4.3166
	new_data_grads_norm = 6.6743
	old_data_grads_norm = 5.8554
	sim_grads_norm_tr = -0.0035
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8176
	data_grads_norm = 4.5834
	new_data_grads_norm = 6.9324
	old_data_grads_norm = 5.3163
	sim_grads_norm_tr = 0.0614
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9959
	data_grads_norm = 5.3223
	new_data_grads_norm = 6.6006
	old_data_grads_norm = 8.2022
	sim_grads_norm_tr = 0.0595
-- Starting training on experience 14 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0815
	data_grads_norm = 5.6218
	new_data_grads_norm = 7.3892
	old_data_grads_norm = 7.4902
	sim_grads_norm_tr = 0.0174
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.1583
	data_grads_norm = 6.2117
	new_data_grads_norm = 8.3318
	old_data_grads_norm = 7.5666
	sim_grads_norm_tr = 0.0495
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8000
	data_grads_norm = 5.4601
	new_data_grads_norm = 7.2656
	old_data_grads_norm = 7.3160
	sim_grads_norm_tr = -0.0038
-- Starting training on experience 15 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4285
	data_grads_norm = 5.0059
	new_data_grads_norm = 6.4660
	old_data_grads_norm = 5.8774
	sim_grads_norm_tr = 0.0035
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9917
	data_grads_norm = 5.2657
	new_data_grads_norm = 7.2665
	old_data_grads_norm = 6.5628
	sim_grads_norm_tr = 0.0437
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0111
	data_grads_norm = 4.8771
	new_data_grads_norm = 6.7260
	old_data_grads_norm = 6.1052
	sim_grads_norm_tr = 0.0339
-- Starting training on experience 16 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8728
	data_grads_norm = 4.8150
	new_data_grads_norm = 6.5004
	old_data_grads_norm = 6.8922
	sim_grads_norm_tr = 0.0515
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9779
	data_grads_norm = 4.3491
	new_data_grads_norm = 7.3290
	old_data_grads_norm = 4.6068
	sim_grads_norm_tr = 0.0596
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9682
	data_grads_norm = 5.4072
	new_data_grads_norm = 7.1494
	old_data_grads_norm = 7.9859
	sim_grads_norm_tr = -0.0007
-- Starting training on experience 17 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9277
	data_grads_norm = 3.8812
	new_data_grads_norm = 6.9223
	old_data_grads_norm = 3.7868
	sim_grads_norm_tr = -0.0543
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4901
	data_grads_norm = 4.9655
	new_data_grads_norm = 7.1992
	old_data_grads_norm = 6.8841
	sim_grads_norm_tr = 0.0227
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0439
	data_grads_norm = 4.4795
	new_data_grads_norm = 6.9574
	old_data_grads_norm = 6.0425
	sim_grads_norm_tr = -0.0301
-- Starting training on experience 18 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7756
	data_grads_norm = 5.4064
	new_data_grads_norm = 7.3943
	old_data_grads_norm = 7.0449
	sim_grads_norm_tr = 0.0431
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6377
	data_grads_norm = 4.7670
	new_data_grads_norm = 6.5348
	old_data_grads_norm = 6.6714
	sim_grads_norm_tr = 0.0780
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2165
	data_grads_norm = 4.4307
	new_data_grads_norm = 6.6501
	old_data_grads_norm = 5.7042
	sim_grads_norm_tr = -0.0216
-- Starting training on experience 19 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3015
	data_grads_norm = 4.7237
	new_data_grads_norm = 7.1576
	old_data_grads_norm = 5.3928
	sim_grads_norm_tr = -0.0174
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2920
	data_grads_norm = 4.9937
	new_data_grads_norm = 7.4869
	old_data_grads_norm = 6.4841
	sim_grads_norm_tr = 0.0102
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5030
	data_grads_norm = 5.3880
	new_data_grads_norm = 8.0464
	old_data_grads_norm = 7.1629
	sim_grads_norm_tr = 0.0501
-- Starting training on experience 20 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8131
	data_grads_norm = 5.3806
	new_data_grads_norm = 6.2898
	old_data_grads_norm = 8.0995
	sim_grads_norm_tr = 0.0201
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7166
	data_grads_norm = 4.9499
	new_data_grads_norm = 6.3439
	old_data_grads_norm = 5.7504
	sim_grads_norm_tr = 0.0698
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5288
	data_grads_norm = 5.4839
	new_data_grads_norm = 6.6101
	old_data_grads_norm = 8.3883
	sim_grads_norm_tr = 0.0552
-- Starting training on experience 21 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1468
	data_grads_norm = 6.8520
	new_data_grads_norm = 7.1113
	old_data_grads_norm = 10.8289
	sim_grads_norm_tr = -0.0168
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3581
	data_grads_norm = 4.9457
	new_data_grads_norm = 7.1904
	old_data_grads_norm = 6.9910
	sim_grads_norm_tr = 0.0359
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6849
	data_grads_norm = 4.7281
	new_data_grads_norm = 7.0950
	old_data_grads_norm = 5.6446
	sim_grads_norm_tr = 0.0499
-- Starting training on experience 22 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8278
	data_grads_norm = 6.0795
	new_data_grads_norm = 7.0667
	old_data_grads_norm = 9.0517
	sim_grads_norm_tr = 0.0585
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2010
	data_grads_norm = 4.0881
	new_data_grads_norm = 5.9344
	old_data_grads_norm = 5.4920
	sim_grads_norm_tr = -0.0097
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4195
	data_grads_norm = 5.3170
	new_data_grads_norm = 6.5050
	old_data_grads_norm = 6.8382
	sim_grads_norm_tr = 0.0048
-- Starting training on experience 23 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2809
	data_grads_norm = 4.8925
	new_data_grads_norm = 6.2258
	old_data_grads_norm = 6.2196
	sim_grads_norm_tr = 0.0904
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6512
	data_grads_norm = 4.6767
	new_data_grads_norm = 6.2895
	old_data_grads_norm = 6.5320
	sim_grads_norm_tr = 0.1002
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9987
	data_grads_norm = 4.2353
	new_data_grads_norm = 5.8171
	old_data_grads_norm = 6.6335
	sim_grads_norm_tr = -0.0168
-- Starting training on experience 24 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0426
	data_grads_norm = 5.5688
	new_data_grads_norm = 6.6893
	old_data_grads_norm = 8.3430
	sim_grads_norm_tr = 0.0014
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6160
	data_grads_norm = 4.8883
	new_data_grads_norm = 6.6231
	old_data_grads_norm = 6.7252
	sim_grads_norm_tr = -0.0194
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5247
	data_grads_norm = 4.7130
	new_data_grads_norm = 6.6666
	old_data_grads_norm = 6.6819
	sim_grads_norm_tr = 0.0120
-- Starting training on experience 25 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0609
	data_grads_norm = 4.5425
	new_data_grads_norm = 6.0827
	old_data_grads_norm = 6.8241
	sim_grads_norm_tr = 0.0134
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6409
	data_grads_norm = 5.3510
	new_data_grads_norm = 6.0280
	old_data_grads_norm = 7.6375
	sim_grads_norm_tr = 0.0124
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3548
	data_grads_norm = 4.6345
	new_data_grads_norm = 6.3193
	old_data_grads_norm = 6.4627
	sim_grads_norm_tr = -0.0050
-- Starting training on experience 26 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4492
	data_grads_norm = 4.9388
	new_data_grads_norm = 7.0403
	old_data_grads_norm = 6.6201
	sim_grads_norm_tr = 0.0235
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2287
	data_grads_norm = 4.7147
	new_data_grads_norm = 7.2342
	old_data_grads_norm = 5.2424
	sim_grads_norm_tr = -0.0161
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4610
	data_grads_norm = 4.5787
	new_data_grads_norm = 7.6064
	old_data_grads_norm = 5.9778
	sim_grads_norm_tr = 0.0591
-- Starting training on experience 27 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1304
	data_grads_norm = 5.0082
	new_data_grads_norm = 7.2260
	old_data_grads_norm = 6.5301
	sim_grads_norm_tr = -0.0254
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6453
	data_grads_norm = 5.2956
	new_data_grads_norm = 7.1282
	old_data_grads_norm = 7.2578
	sim_grads_norm_tr = 0.0189
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9769
	data_grads_norm = 4.3286
	new_data_grads_norm = 6.8535
	old_data_grads_norm = 5.6642
	sim_grads_norm_tr = 0.0691
-- Starting training on experience 28 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0122
	data_grads_norm = 4.4070
	new_data_grads_norm = 6.7985
	old_data_grads_norm = 5.7087
	sim_grads_norm_tr = -0.0029
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8024
	data_grads_norm = 4.6592
	new_data_grads_norm = 6.7214
	old_data_grads_norm = 6.4505
	sim_grads_norm_tr = -0.0146
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1474
	data_grads_norm = 4.6956
	new_data_grads_norm = 6.2238
	old_data_grads_norm = 6.6858
	sim_grads_norm_tr = 0.0404
-- Starting training on experience 29 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7761
	data_grads_norm = 4.1568
	new_data_grads_norm = 6.6495
	old_data_grads_norm = 5.9796
	sim_grads_norm_tr = -0.0277
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5241
	data_grads_norm = 4.9375
	new_data_grads_norm = 6.9710
	old_data_grads_norm = 6.5294
	sim_grads_norm_tr = 0.0859
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8037
	data_grads_norm = 4.3035
	new_data_grads_norm = 6.7214
	old_data_grads_norm = 6.1403
	sim_grads_norm_tr = 0.0343
-- Starting training on experience 30 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3452
	data_grads_norm = 5.3846
	new_data_grads_norm = 5.5485
	old_data_grads_norm = 7.7116
	sim_grads_norm_tr = 0.0044
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0773
	data_grads_norm = 4.5020
	new_data_grads_norm = 5.5438
	old_data_grads_norm = 5.9298
	sim_grads_norm_tr = 0.0197
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3381
	data_grads_norm = 5.1392
	new_data_grads_norm = 5.8774
	old_data_grads_norm = 9.3814
	sim_grads_norm_tr = 0.0419
-- Starting training on experience 31 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6483
	data_grads_norm = 3.9269
	new_data_grads_norm = 6.3158
	old_data_grads_norm = 4.4021
	sim_grads_norm_tr = -0.0104
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8485
	data_grads_norm = 4.4610
	new_data_grads_norm = 6.5689
	old_data_grads_norm = 5.6218
	sim_grads_norm_tr = 0.0822
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1735
	data_grads_norm = 4.6249
	new_data_grads_norm = 6.6519
	old_data_grads_norm = 6.1696
	sim_grads_norm_tr = 0.0170
-- Starting training on experience 32 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8125
	data_grads_norm = 5.7470
	new_data_grads_norm = 6.6077
	old_data_grads_norm = 8.1182
	sim_grads_norm_tr = 0.0344
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0461
	data_grads_norm = 5.0164
	new_data_grads_norm = 6.9200
	old_data_grads_norm = 6.8818
	sim_grads_norm_tr = -0.0006
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0824
	data_grads_norm = 4.6353
	new_data_grads_norm = 6.8899
	old_data_grads_norm = 5.4909
	sim_grads_norm_tr = 0.0663
-- Starting training on experience 33 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0451
	data_grads_norm = 4.3946
	new_data_grads_norm = 6.6035
	old_data_grads_norm = 5.5236
	sim_grads_norm_tr = 0.0113
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9403
	data_grads_norm = 4.8332
	new_data_grads_norm = 7.3857
	old_data_grads_norm = 5.9008
	sim_grads_norm_tr = -0.0204
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0540
	data_grads_norm = 5.2450
	new_data_grads_norm = 7.3412
	old_data_grads_norm = 6.1381
	sim_grads_norm_tr = -0.0150
-- Starting training on experience 34 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2534
	data_grads_norm = 5.1253
	new_data_grads_norm = 7.4472
	old_data_grads_norm = 6.5990
	sim_grads_norm_tr = -0.0024
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1049
	data_grads_norm = 4.7642
	new_data_grads_norm = 7.1852
	old_data_grads_norm = 6.6937
	sim_grads_norm_tr = -0.0315
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3848
	data_grads_norm = 5.0851
	new_data_grads_norm = 7.5581
	old_data_grads_norm = 6.0698
	sim_grads_norm_tr = 0.0315
-- Starting training on experience 35 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2899
	data_grads_norm = 4.8308
	new_data_grads_norm = 7.5569
	old_data_grads_norm = 5.4894
	sim_grads_norm_tr = -0.0130
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2705
	data_grads_norm = 5.1258
	new_data_grads_norm = 7.8947
	old_data_grads_norm = 6.0112
	sim_grads_norm_tr = 0.0225
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6789
	data_grads_norm = 5.6618
	new_data_grads_norm = 7.9718
	old_data_grads_norm = 6.8813
	sim_grads_norm_tr = 0.0228
-- Starting training on experience 36 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9977
	data_grads_norm = 4.1692
	new_data_grads_norm = 6.7706
	old_data_grads_norm = 5.0328
	sim_grads_norm_tr = 0.0652
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8789
	data_grads_norm = 4.9209
	new_data_grads_norm = 6.4524
	old_data_grads_norm = 6.6328
	sim_grads_norm_tr = 0.0115
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1340
	data_grads_norm = 5.1199
	new_data_grads_norm = 6.2806
	old_data_grads_norm = 5.6863
	sim_grads_norm_tr = 0.1098
-- Starting training on experience 37 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9196
	data_grads_norm = 4.9582
	new_data_grads_norm = 7.2308
	old_data_grads_norm = 6.0456
	sim_grads_norm_tr = -0.0115
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6930
	data_grads_norm = 4.6355
	new_data_grads_norm = 6.0558
	old_data_grads_norm = 6.6136
	sim_grads_norm_tr = -0.0328
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1566
	data_grads_norm = 5.0073
	new_data_grads_norm = 7.0273
	old_data_grads_norm = 5.6970
	sim_grads_norm_tr = -0.0157
-- Starting training on experience 38 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0073
	data_grads_norm = 4.7118
	new_data_grads_norm = 6.8932
	old_data_grads_norm = 5.6433
	sim_grads_norm_tr = -0.0243
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0413
	data_grads_norm = 4.9908
	new_data_grads_norm = 6.6154
	old_data_grads_norm = 6.3503
	sim_grads_norm_tr = -0.0027
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2777
	data_grads_norm = 4.4978
	new_data_grads_norm = 6.6735
	old_data_grads_norm = 5.4190
	sim_grads_norm_tr = 0.0505
-- Starting training on experience 39 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1107
	data_grads_norm = 4.4735
	new_data_grads_norm = 6.7569
	old_data_grads_norm = 6.5571
	sim_grads_norm_tr = 0.0152
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9388
	data_grads_norm = 4.8447
	new_data_grads_norm = 6.9314
	old_data_grads_norm = 6.5544
	sim_grads_norm_tr = 0.0045
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1352
	data_grads_norm = 4.8220
	new_data_grads_norm = 6.2114
	old_data_grads_norm = 6.7246
	sim_grads_norm_tr = 0.0450
-- Starting training on experience 40 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4583
	data_grads_norm = 5.6264
	new_data_grads_norm = 7.4070
	old_data_grads_norm = 7.7590
	sim_grads_norm_tr = -0.0071
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9768
	data_grads_norm = 5.0474
	new_data_grads_norm = 7.1231
	old_data_grads_norm = 5.7668
	sim_grads_norm_tr = 0.0148
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3227
	data_grads_norm = 5.0757
	new_data_grads_norm = 7.4434
	old_data_grads_norm = 5.5050
	sim_grads_norm_tr = -0.0081
-- Starting training on experience 41 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1519
	data_grads_norm = 5.1066
	new_data_grads_norm = 6.8054
	old_data_grads_norm = 7.2273
	sim_grads_norm_tr = -0.0317
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5762
	data_grads_norm = 5.5414
	new_data_grads_norm = 7.3772
	old_data_grads_norm = 8.5107
	sim_grads_norm_tr = 0.0482
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5661
	data_grads_norm = 4.1110
	new_data_grads_norm = 7.1708
	old_data_grads_norm = 4.0024
	sim_grads_norm_tr = -0.0425
-- Starting training on experience 42 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5848
	data_grads_norm = 4.5607
	new_data_grads_norm = 6.6892
	old_data_grads_norm = 5.6647
	sim_grads_norm_tr = -0.0094
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4386
	data_grads_norm = 4.1965
	new_data_grads_norm = 6.3984
	old_data_grads_norm = 5.6892
	sim_grads_norm_tr = -0.0121
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4088
	data_grads_norm = 4.2191
	new_data_grads_norm = 6.0557
	old_data_grads_norm = 4.7165
	sim_grads_norm_tr = -0.0195
-- Starting training on experience 43 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7446
	data_grads_norm = 4.7618
	new_data_grads_norm = 6.5373
	old_data_grads_norm = 6.4340
	sim_grads_norm_tr = -0.0102
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3939
	data_grads_norm = 5.4165
	new_data_grads_norm = 7.4431
	old_data_grads_norm = 6.9254
	sim_grads_norm_tr = 0.0639
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1521
	data_grads_norm = 4.9237
	new_data_grads_norm = 6.5684
	old_data_grads_norm = 6.3335
	sim_grads_norm_tr = 0.0475
-- Starting training on experience 44 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6001
	data_grads_norm = 4.5884
	new_data_grads_norm = 7.3583
	old_data_grads_norm = 5.0539
	sim_grads_norm_tr = -0.0230
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9275
	data_grads_norm = 4.8974
	new_data_grads_norm = 7.9787
	old_data_grads_norm = 6.7834
	sim_grads_norm_tr = 0.0298
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0851
	data_grads_norm = 5.3942
	new_data_grads_norm = 6.7893
	old_data_grads_norm = 8.0270
	sim_grads_norm_tr = -0.0273
-- Starting training on experience 45 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6717
	data_grads_norm = 4.1774
	new_data_grads_norm = 7.0125
	old_data_grads_norm = 4.0600
	sim_grads_norm_tr = -0.0134
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5995
	data_grads_norm = 5.5527
	new_data_grads_norm = 6.8297
	old_data_grads_norm = 7.6868
	sim_grads_norm_tr = 0.0510
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8421
	data_grads_norm = 4.5872
	new_data_grads_norm = 7.4665
	old_data_grads_norm = 4.8457
	sim_grads_norm_tr = -0.0361
-- Starting training on experience 46 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3657
	data_grads_norm = 4.3217
	new_data_grads_norm = 6.6987
	old_data_grads_norm = 4.8718
	sim_grads_norm_tr = -0.0203
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7383
	data_grads_norm = 4.6102
	new_data_grads_norm = 6.5454
	old_data_grads_norm = 7.5241
	sim_grads_norm_tr = 0.0858
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2427
	data_grads_norm = 5.8624
	new_data_grads_norm = 7.0192
	old_data_grads_norm = 7.9339
	sim_grads_norm_tr = 0.0965
-- Starting training on experience 47 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2839
	data_grads_norm = 5.3290
	new_data_grads_norm = 6.4363
	old_data_grads_norm = 7.3523
	sim_grads_norm_tr = 0.0246
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6316
	data_grads_norm = 4.0327
	new_data_grads_norm = 6.3060
	old_data_grads_norm = 5.1214
	sim_grads_norm_tr = -0.0746
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8173
	data_grads_norm = 4.2053
	new_data_grads_norm = 6.6735
	old_data_grads_norm = 5.7612
	sim_grads_norm_tr = 0.0721
-- Starting training on experience 48 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5838
	data_grads_norm = 4.5736
	new_data_grads_norm = 6.2260
	old_data_grads_norm = 6.8797
	sim_grads_norm_tr = -0.0308
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0380
	data_grads_norm = 5.2867
	new_data_grads_norm = 6.9215
	old_data_grads_norm = 8.1793
	sim_grads_norm_tr = -0.0350
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6968
	data_grads_norm = 4.2018
	new_data_grads_norm = 7.8407
	old_data_grads_norm = 5.5154
	sim_grads_norm_tr = -0.0561
-- Starting training on experience 49 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7271
	data_grads_norm = 4.5048
	new_data_grads_norm = 6.5698
	old_data_grads_norm = 6.3762
	sim_grads_norm_tr = 0.0605
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0442
	data_grads_norm = 4.7084
	new_data_grads_norm = 6.9346
	old_data_grads_norm = 5.9001
	sim_grads_norm_tr = 0.0411
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7727
	data_grads_norm = 4.3906
	new_data_grads_norm = 6.6089
	old_data_grads_norm = 5.1346
	sim_grads_norm_tr = -0.0374
-- Starting training on experience 50 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2315
	data_grads_norm = 5.7568
	new_data_grads_norm = 8.8029
	old_data_grads_norm = 4.7538
	sim_grads_norm_tr = 0.0207
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1165
	data_grads_norm = 5.3147
	new_data_grads_norm = 6.9482
	old_data_grads_norm = 7.0290
	sim_grads_norm_tr = 0.0244
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0122
	data_grads_norm = 5.0918
	new_data_grads_norm = 7.7455
	old_data_grads_norm = 5.5939
	sim_grads_norm_tr = 0.0467
-- Starting training on experience 51 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8845
	data_grads_norm = 4.7274
	new_data_grads_norm = 7.2747
	old_data_grads_norm = 5.7261
	sim_grads_norm_tr = -0.0466
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5620
	data_grads_norm = 4.5246
	new_data_grads_norm = 7.5810
	old_data_grads_norm = 4.4449
	sim_grads_norm_tr = 0.0215
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9555
	data_grads_norm = 4.7507
	new_data_grads_norm = 6.7923
	old_data_grads_norm = 6.2158
	sim_grads_norm_tr = -0.0268
-- Starting training on experience 52 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6356
	data_grads_norm = 4.1730
	new_data_grads_norm = 6.1140
	old_data_grads_norm = 4.8681
	sim_grads_norm_tr = -0.0035
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6317
	data_grads_norm = 4.0333
	new_data_grads_norm = 6.3699
	old_data_grads_norm = 3.9725
	sim_grads_norm_tr = -0.0096
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8443
	data_grads_norm = 5.1466
	new_data_grads_norm = 6.0053
	old_data_grads_norm = 7.8403
	sim_grads_norm_tr = -0.0085
-- Starting training on experience 53 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8987
	data_grads_norm = 4.8804
	new_data_grads_norm = 7.7913
	old_data_grads_norm = 6.6705
	sim_grads_norm_tr = -0.0047
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6407
	data_grads_norm = 3.8118
	new_data_grads_norm = 6.8366
	old_data_grads_norm = 4.3279
	sim_grads_norm_tr = 0.0778
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1153
	data_grads_norm = 5.7870
	new_data_grads_norm = 7.9133
	old_data_grads_norm = 6.9799
	sim_grads_norm_tr = 0.0988
-- Starting training on experience 54 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6483
	data_grads_norm = 4.3712
	new_data_grads_norm = 8.1172
	old_data_grads_norm = 4.7555
	sim_grads_norm_tr = 0.0075
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1557
	data_grads_norm = 6.0667
	new_data_grads_norm = 7.9822
	old_data_grads_norm = 7.9849
	sim_grads_norm_tr = -0.0219
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1077
	data_grads_norm = 5.1762
	new_data_grads_norm = 8.0498
	old_data_grads_norm = 5.7546
	sim_grads_norm_tr = -0.0162
-- Starting training on experience 55 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1618
	data_grads_norm = 4.5195
	new_data_grads_norm = 7.2149
	old_data_grads_norm = 6.5722
	sim_grads_norm_tr = 0.0197
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2886
	data_grads_norm = 4.3314
	new_data_grads_norm = 7.4110
	old_data_grads_norm = 4.0336
	sim_grads_norm_tr = -0.0086
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9317
	data_grads_norm = 5.6801
	new_data_grads_norm = 7.2245
	old_data_grads_norm = 7.0363
	sim_grads_norm_tr = 0.0096
-- Starting training on experience 56 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4031
	data_grads_norm = 4.3741
	new_data_grads_norm = 5.6745
	old_data_grads_norm = 6.3519
	sim_grads_norm_tr = 0.0121
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3626
	data_grads_norm = 4.1038
	new_data_grads_norm = 6.0597
	old_data_grads_norm = 4.7813
	sim_grads_norm_tr = -0.0055
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6519
	data_grads_norm = 4.6024
	new_data_grads_norm = 6.2570
	old_data_grads_norm = 5.8340
	sim_grads_norm_tr = 0.0728
-- Starting training on experience 57 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2391
	data_grads_norm = 4.2870
	new_data_grads_norm = 5.5924
	old_data_grads_norm = 5.1063
	sim_grads_norm_tr = -0.0067
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9414
	data_grads_norm = 5.4386
	new_data_grads_norm = 6.6325
	old_data_grads_norm = 7.1126
	sim_grads_norm_tr = 0.0314
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5007
	data_grads_norm = 4.9247
	new_data_grads_norm = 5.5338
	old_data_grads_norm = 6.5199
	sim_grads_norm_tr = -0.0045
-- Starting training on experience 58 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9126
	data_grads_norm = 4.9864
	new_data_grads_norm = 7.2484
	old_data_grads_norm = 6.3206
	sim_grads_norm_tr = -0.0148
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1784
	data_grads_norm = 5.4944
	new_data_grads_norm = 6.8006
	old_data_grads_norm = 8.1199
	sim_grads_norm_tr = -0.0049
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9374
	data_grads_norm = 4.7109
	new_data_grads_norm = 6.9008
	old_data_grads_norm = 6.2886
	sim_grads_norm_tr = -0.0204
-- Starting training on experience 59 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0145
	data_grads_norm = 5.4662
	new_data_grads_norm = 8.3143
	old_data_grads_norm = 6.1759
	sim_grads_norm_tr = 0.0260
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1037
	data_grads_norm = 4.7014
	new_data_grads_norm = 7.5626
	old_data_grads_norm = 5.8789
	sim_grads_norm_tr = -0.0817
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8711
	data_grads_norm = 5.0968
	new_data_grads_norm = 7.6310
	old_data_grads_norm = 5.8267
	sim_grads_norm_tr = 0.1286
-- Starting training on experience 60 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7319
	data_grads_norm = 4.8727
	new_data_grads_norm = 6.4490
	old_data_grads_norm = 6.1719
	sim_grads_norm_tr = 0.0021
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7172
	data_grads_norm = 4.1903
	new_data_grads_norm = 6.6684
	old_data_grads_norm = 5.5183
	sim_grads_norm_tr = 0.0162
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7772
	data_grads_norm = 4.6603
	new_data_grads_norm = 6.7023
	old_data_grads_norm = 6.8736
	sim_grads_norm_tr = -0.0308
-- Starting training on experience 61 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2818
	data_grads_norm = 5.6491
	new_data_grads_norm = 7.9214
	old_data_grads_norm = 7.1076
	sim_grads_norm_tr = 0.0633
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9245
	data_grads_norm = 5.6407
	new_data_grads_norm = 7.7649
	old_data_grads_norm = 8.0138
	sim_grads_norm_tr = -0.0091
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2739
	data_grads_norm = 6.1346
	new_data_grads_norm = 7.5103
	old_data_grads_norm = 9.0418
	sim_grads_norm_tr = 0.0166
-- Starting training on experience 62 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7176
	data_grads_norm = 4.5833
	new_data_grads_norm = 6.4590
	old_data_grads_norm = 7.0675
	sim_grads_norm_tr = -0.0226
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2443
	data_grads_norm = 4.8577
	new_data_grads_norm = 7.2938
	old_data_grads_norm = 6.1823
	sim_grads_norm_tr = 0.0211
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8530
	data_grads_norm = 4.7627
	new_data_grads_norm = 7.2083
	old_data_grads_norm = 5.4422
	sim_grads_norm_tr = 0.0232
-- Starting training on experience 63 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6167
	data_grads_norm = 3.7014
	new_data_grads_norm = 6.3957
	old_data_grads_norm = 4.4364
	sim_grads_norm_tr = 0.1031
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9052
	data_grads_norm = 5.0802
	new_data_grads_norm = 6.8706
	old_data_grads_norm = 7.1173
	sim_grads_norm_tr = -0.0044
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3334
	data_grads_norm = 3.9950
	new_data_grads_norm = 6.8800
	old_data_grads_norm = 3.6852
	sim_grads_norm_tr = 0.0805
-- Starting training on experience 64 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8116
	data_grads_norm = 5.2492
	new_data_grads_norm = 7.4993
	old_data_grads_norm = 7.9242
	sim_grads_norm_tr = -0.0024
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6473
	data_grads_norm = 4.5655
	new_data_grads_norm = 7.4875
	old_data_grads_norm = 4.5073
	sim_grads_norm_tr = -0.0208
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8151
	data_grads_norm = 6.4193
	new_data_grads_norm = 7.5355
	old_data_grads_norm = 7.8431
	sim_grads_norm_tr = 0.0329
-- Starting training on experience 65 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9662
	data_grads_norm = 5.0672
	new_data_grads_norm = 7.6751
	old_data_grads_norm = 5.5189
	sim_grads_norm_tr = -0.0132
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7563
	data_grads_norm = 4.8280
	new_data_grads_norm = 7.5862
	old_data_grads_norm = 5.9977
	sim_grads_norm_tr = 0.0036
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1309
	data_grads_norm = 5.2842
	new_data_grads_norm = 7.4478
	old_data_grads_norm = 6.9297
	sim_grads_norm_tr = 0.0042
-- Starting training on experience 66 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5175
	data_grads_norm = 4.2663
	new_data_grads_norm = 6.0797
	old_data_grads_norm = 6.3264
	sim_grads_norm_tr = -0.0051
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2934
	data_grads_norm = 4.0845
	new_data_grads_norm = 6.1693
	old_data_grads_norm = 4.8683
	sim_grads_norm_tr = -0.0425
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5885
	data_grads_norm = 4.1295
	new_data_grads_norm = 7.6039
	old_data_grads_norm = 6.4453
	sim_grads_norm_tr = 0.0137
-- Starting training on experience 67 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6523
	data_grads_norm = 3.8929
	new_data_grads_norm = 6.3595
	old_data_grads_norm = 4.0807
	sim_grads_norm_tr = 0.0096
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2497
	data_grads_norm = 5.6003
	new_data_grads_norm = 6.5734
	old_data_grads_norm = 8.7678
	sim_grads_norm_tr = 0.0141
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3210
	data_grads_norm = 4.9427
	new_data_grads_norm = 6.3284
	old_data_grads_norm = 6.6554
	sim_grads_norm_tr = 0.0751
-- Starting training on experience 68 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0646
	data_grads_norm = 4.6298
	new_data_grads_norm = 6.1015
	old_data_grads_norm = 6.9875
	sim_grads_norm_tr = -0.0346
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3171
	data_grads_norm = 4.4832
	new_data_grads_norm = 7.0563
	old_data_grads_norm = 5.7270
	sim_grads_norm_tr = 0.0001
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5961
	data_grads_norm = 4.1277
	new_data_grads_norm = 7.0624
	old_data_grads_norm = 4.3117
	sim_grads_norm_tr = -0.0116
-- Starting training on experience 69 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7436
	data_grads_norm = 5.4455
	new_data_grads_norm = 7.0069
	old_data_grads_norm = 5.8560
	sim_grads_norm_tr = 0.0009
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9378
	data_grads_norm = 4.7540
	new_data_grads_norm = 6.4328
	old_data_grads_norm = 5.9081
	sim_grads_norm_tr = -0.0244
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9675
	data_grads_norm = 4.7720
	new_data_grads_norm = 6.5276
	old_data_grads_norm = 6.2245
	sim_grads_norm_tr = 0.0225
-- Starting training on experience 70 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7291
	data_grads_norm = 4.9469
	new_data_grads_norm = 7.0510
	old_data_grads_norm = 7.5746
	sim_grads_norm_tr = -0.0579
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7875
	data_grads_norm = 4.8754
	new_data_grads_norm = 7.0523
	old_data_grads_norm = 6.5076
	sim_grads_norm_tr = -0.0348
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0112
	data_grads_norm = 6.0478
	new_data_grads_norm = 7.3713
	old_data_grads_norm = 8.2800
	sim_grads_norm_tr = 0.0891
-- Starting training on experience 71 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9289
	data_grads_norm = 4.5150
	new_data_grads_norm = 6.9566
	old_data_grads_norm = 6.4209
	sim_grads_norm_tr = 0.0111
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2202
	data_grads_norm = 4.5428
	new_data_grads_norm = 7.2398
	old_data_grads_norm = 5.7244
	sim_grads_norm_tr = -0.0504
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3524
	data_grads_norm = 4.4509
	new_data_grads_norm = 7.8373
	old_data_grads_norm = 5.3140
	sim_grads_norm_tr = 0.0310
-- Starting training on experience 72 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5601
	data_grads_norm = 4.5583
	new_data_grads_norm = 7.5774
	old_data_grads_norm = 5.8444
	sim_grads_norm_tr = -0.0823
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3873
	data_grads_norm = 5.3337
	new_data_grads_norm = 7.5484
	old_data_grads_norm = 6.5989
	sim_grads_norm_tr = 0.0030
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7628
	data_grads_norm = 4.5955
	new_data_grads_norm = 7.3955
	old_data_grads_norm = 5.7965
	sim_grads_norm_tr = -0.0211
-- Starting training on experience 73 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9388
	data_grads_norm = 4.9392
	new_data_grads_norm = 7.9822
	old_data_grads_norm = 6.9439
	sim_grads_norm_tr = 0.0184
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9737
	data_grads_norm = 5.0062
	new_data_grads_norm = 7.6617
	old_data_grads_norm = 6.6114
	sim_grads_norm_tr = 0.0242
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3194
	data_grads_norm = 5.4103
	new_data_grads_norm = 7.9316
	old_data_grads_norm = 7.7529
	sim_grads_norm_tr = 0.0066
-- Starting training on experience 74 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7303
	data_grads_norm = 4.6574
	new_data_grads_norm = 6.1110
	old_data_grads_norm = 6.5608
	sim_grads_norm_tr = 0.0246
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9743
	data_grads_norm = 5.1210
	new_data_grads_norm = 6.6124
	old_data_grads_norm = 8.3627
	sim_grads_norm_tr = -0.0061
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2093
	data_grads_norm = 3.6651
	new_data_grads_norm = 6.8143
	old_data_grads_norm = 3.7851
	sim_grads_norm_tr = 0.0269
-- Starting training on experience 75 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5765
	data_grads_norm = 4.6434
	new_data_grads_norm = 7.0613
	old_data_grads_norm = 4.8410
	sim_grads_norm_tr = 0.1896
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5545
	data_grads_norm = 4.7296
	new_data_grads_norm = 6.1279
	old_data_grads_norm = 6.1705
	sim_grads_norm_tr = 0.0356
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8758
	data_grads_norm = 5.4320
	new_data_grads_norm = 6.4276
	old_data_grads_norm = 7.9142
	sim_grads_norm_tr = -0.0015
-- Starting training on experience 76 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2475
	data_grads_norm = 5.0634
	new_data_grads_norm = 6.8068
	old_data_grads_norm = 7.9450
	sim_grads_norm_tr = -0.0270
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0977
	data_grads_norm = 5.1468
	new_data_grads_norm = 6.5997
	old_data_grads_norm = 7.8083
	sim_grads_norm_tr = 0.0585
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8866
	data_grads_norm = 4.4430
	new_data_grads_norm = 6.4962
	old_data_grads_norm = 4.8425
	sim_grads_norm_tr = 0.0908
-- Starting training on experience 77 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9788
	data_grads_norm = 6.1697
	new_data_grads_norm = 7.6888
	old_data_grads_norm = 8.8668
	sim_grads_norm_tr = 0.0492
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6801
	data_grads_norm = 5.1008
	new_data_grads_norm = 7.3300
	old_data_grads_norm = 6.4804
	sim_grads_norm_tr = -0.0479
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3582
	data_grads_norm = 4.8222
	new_data_grads_norm = 7.0808
	old_data_grads_norm = 6.0203
	sim_grads_norm_tr = 0.0542
-- Starting training on experience 78 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3627
	data_grads_norm = 4.8199
	new_data_grads_norm = 6.9909
	old_data_grads_norm = 7.2572
	sim_grads_norm_tr = 0.0154
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8582
	data_grads_norm = 5.3495
	new_data_grads_norm = 7.4385
	old_data_grads_norm = 7.1953
	sim_grads_norm_tr = 0.0047
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7088
	data_grads_norm = 5.1730
	new_data_grads_norm = 7.5986
	old_data_grads_norm = 6.6997
	sim_grads_norm_tr = 0.0498
-- Starting training on experience 79 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8737
	data_grads_norm = 5.0631
	new_data_grads_norm = 6.5631
	old_data_grads_norm = 8.5474
	sim_grads_norm_tr = -0.0368
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4873
	data_grads_norm = 3.8967
	new_data_grads_norm = 6.2092
	old_data_grads_norm = 5.3151
	sim_grads_norm_tr = 0.0263
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0006
	data_grads_norm = 4.7126
	new_data_grads_norm = 6.4804
	old_data_grads_norm = 7.0588
	sim_grads_norm_tr = -0.0364
-- Starting training on experience 80 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3776
	data_grads_norm = 4.2850
	new_data_grads_norm = 6.2455
	old_data_grads_norm = 6.8477
	sim_grads_norm_tr = 0.0112
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4901
	data_grads_norm = 4.6784
	new_data_grads_norm = 5.9725
	old_data_grads_norm = 8.1954
	sim_grads_norm_tr = -0.0049
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6445
	data_grads_norm = 5.0439
	new_data_grads_norm = 5.9097
	old_data_grads_norm = 8.1071
	sim_grads_norm_tr = 0.0266
-- Starting training on experience 81 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0623
	data_grads_norm = 4.5500
	new_data_grads_norm = 6.7365
	old_data_grads_norm = 5.7956
	sim_grads_norm_tr = -0.0163
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8107
	data_grads_norm = 4.2040
	new_data_grads_norm = 6.3500
	old_data_grads_norm = 4.8757
	sim_grads_norm_tr = 0.0173
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7888
	data_grads_norm = 5.1541
	new_data_grads_norm = 6.2317
	old_data_grads_norm = 7.0296
	sim_grads_norm_tr = 0.0141
-- Starting training on experience 82 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3845
	data_grads_norm = 4.0825
	new_data_grads_norm = 5.9766
	old_data_grads_norm = 5.4659
	sim_grads_norm_tr = 0.0140
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2117
	data_grads_norm = 3.9766
	new_data_grads_norm = 5.7758
	old_data_grads_norm = 5.2444
	sim_grads_norm_tr = -0.0211
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3267
	data_grads_norm = 5.5715
	new_data_grads_norm = 6.3879
	old_data_grads_norm = 8.3684
	sim_grads_norm_tr = 0.0079
-- Starting training on experience 83 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7496
	data_grads_norm = 4.5925
	new_data_grads_norm = 7.6266
	old_data_grads_norm = 4.8087
	sim_grads_norm_tr = 0.0109
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6124
	data_grads_norm = 5.1101
	new_data_grads_norm = 7.4877
	old_data_grads_norm = 7.4604
	sim_grads_norm_tr = -0.0531
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8774
	data_grads_norm = 5.2014
	new_data_grads_norm = 7.8215
	old_data_grads_norm = 7.1597
	sim_grads_norm_tr = 0.0198
-- Starting training on experience 84 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6596
	data_grads_norm = 5.0379
	new_data_grads_norm = 7.1496
	old_data_grads_norm = 7.0207
	sim_grads_norm_tr = -0.0095
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1228
	data_grads_norm = 5.1150
	new_data_grads_norm = 7.0193
	old_data_grads_norm = 6.6975
	sim_grads_norm_tr = -0.0318
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0720
	data_grads_norm = 5.5661
	new_data_grads_norm = 6.8263
	old_data_grads_norm = 7.3462
	sim_grads_norm_tr = 0.0288
-- Starting training on experience 85 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6597
	data_grads_norm = 4.8820
	new_data_grads_norm = 7.4433
	old_data_grads_norm = 7.2663
	sim_grads_norm_tr = 0.0396
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4261
	data_grads_norm = 4.2540
	new_data_grads_norm = 7.6871
	old_data_grads_norm = 6.0690
	sim_grads_norm_tr = 0.0053
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7848
	data_grads_norm = 5.4835
	new_data_grads_norm = 7.1081
	old_data_grads_norm = 6.9487
	sim_grads_norm_tr = 0.1749
-- Starting training on experience 86 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8450
	data_grads_norm = 4.8886
	new_data_grads_norm = 6.8112
	old_data_grads_norm = 6.5971
	sim_grads_norm_tr = -0.0221
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8610
	data_grads_norm = 4.8170
	new_data_grads_norm = 6.8380
	old_data_grads_norm = 7.1019
	sim_grads_norm_tr = 0.0116
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9648
	data_grads_norm = 4.9197
	new_data_grads_norm = 6.5953
	old_data_grads_norm = 7.2758
	sim_grads_norm_tr = 0.0269
-- Starting training on experience 87 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3372
	data_grads_norm = 4.1368
	new_data_grads_norm = 6.5292
	old_data_grads_norm = 5.5184
	sim_grads_norm_tr = -0.0059
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7801
	data_grads_norm = 4.6782
	new_data_grads_norm = 6.3657
	old_data_grads_norm = 6.5791
	sim_grads_norm_tr = -0.0078
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1637
	data_grads_norm = 5.2352
	new_data_grads_norm = 6.7530
	old_data_grads_norm = 7.6878
	sim_grads_norm_tr = 0.0025
-- Starting training on experience 88 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7583
	data_grads_norm = 5.3590
	new_data_grads_norm = 7.4254
	old_data_grads_norm = 7.6714
	sim_grads_norm_tr = -0.0477
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5510
	data_grads_norm = 5.8447
	new_data_grads_norm = 7.8441
	old_data_grads_norm = 7.7562
	sim_grads_norm_tr = 0.0130
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2602
	data_grads_norm = 5.8250
	new_data_grads_norm = 8.9037
	old_data_grads_norm = 7.3399
	sim_grads_norm_tr = -0.0807
-- Starting training on experience 89 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2534
	data_grads_norm = 5.7753
	new_data_grads_norm = 7.4411
	old_data_grads_norm = 8.7575
	sim_grads_norm_tr = -0.0336
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8416
	data_grads_norm = 4.5747
	new_data_grads_norm = 6.8242
	old_data_grads_norm = 6.0257
	sim_grads_norm_tr = 0.0352
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7413
	data_grads_norm = 4.5701
	new_data_grads_norm = 7.1767
	old_data_grads_norm = 6.2002
	sim_grads_norm_tr = 0.0048
-- Starting training on experience 90 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4623
	data_grads_norm = 4.5648
	new_data_grads_norm = 6.7423
	old_data_grads_norm = 5.9591
	sim_grads_norm_tr = -0.0097
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6605
	data_grads_norm = 4.4494
	new_data_grads_norm = 7.0620
	old_data_grads_norm = 6.3842
	sim_grads_norm_tr = -0.0783
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8946
	data_grads_norm = 5.5596
	new_data_grads_norm = 7.6007
	old_data_grads_norm = 7.1697
	sim_grads_norm_tr = 0.0389
-- Starting training on experience 91 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1594
	data_grads_norm = 5.0998
	new_data_grads_norm = 8.5556
	old_data_grads_norm = 5.3412
	sim_grads_norm_tr = 0.0054
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4809
	data_grads_norm = 5.1853
	new_data_grads_norm = 6.8783
	old_data_grads_norm = 6.0270
	sim_grads_norm_tr = 0.0462
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2036
	data_grads_norm = 5.4898
	new_data_grads_norm = 7.6681
	old_data_grads_norm = 7.7261
	sim_grads_norm_tr = -0.0119
-- Starting training on experience 92 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8677
	data_grads_norm = 5.0161
	new_data_grads_norm = 7.3861
	old_data_grads_norm = 6.6189
	sim_grads_norm_tr = -0.0127
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9523
	data_grads_norm = 4.2143
	new_data_grads_norm = 7.9976
	old_data_grads_norm = 4.5104
	sim_grads_norm_tr = 0.0098
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9181
	data_grads_norm = 4.9422
	new_data_grads_norm = 8.8280
	old_data_grads_norm = 4.7126
	sim_grads_norm_tr = -0.0487
-- Starting training on experience 93 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9495
	data_grads_norm = 5.1713
	new_data_grads_norm = 6.9983
	old_data_grads_norm = 7.3481
	sim_grads_norm_tr = 0.0626
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8685
	data_grads_norm = 5.1054
	new_data_grads_norm = 7.0557
	old_data_grads_norm = 6.5666
	sim_grads_norm_tr = 0.0855
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8422
	data_grads_norm = 4.6949
	new_data_grads_norm = 7.1685
	old_data_grads_norm = 6.0708
	sim_grads_norm_tr = -0.0039
-- Starting training on experience 94 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9453
	data_grads_norm = 5.9232
	new_data_grads_norm = 7.5421
	old_data_grads_norm = 7.8825
	sim_grads_norm_tr = 0.0256
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4427
	data_grads_norm = 5.0799
	new_data_grads_norm = 7.2046
	old_data_grads_norm = 7.4131
	sim_grads_norm_tr = 0.0060
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7303
	data_grads_norm = 5.0149
	new_data_grads_norm = 7.6068
	old_data_grads_norm = 5.5570
	sim_grads_norm_tr = 0.0292
-- Starting training on experience 95 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6272
	data_grads_norm = 4.9154
	new_data_grads_norm = 6.6818
	old_data_grads_norm = 6.5852
	sim_grads_norm_tr = 0.0374
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7907
	data_grads_norm = 4.9223
	new_data_grads_norm = 6.0994
	old_data_grads_norm = 7.0775
	sim_grads_norm_tr = -0.0032
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4129
	data_grads_norm = 4.2114
	new_data_grads_norm = 6.5861
	old_data_grads_norm = 4.6990
	sim_grads_norm_tr = 0.0268
-- Starting training on experience 96 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9122
	data_grads_norm = 5.3924
	new_data_grads_norm = 7.1914
	old_data_grads_norm = 5.7266
	sim_grads_norm_tr = -0.0067
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0460
	data_grads_norm = 5.6941
	new_data_grads_norm = 6.3580
	old_data_grads_norm = 6.6718
	sim_grads_norm_tr = 0.0378
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3013
	data_grads_norm = 5.6145
	new_data_grads_norm = 6.2896
	old_data_grads_norm = 7.7737
	sim_grads_norm_tr = 0.0598
-- Starting training on experience 97 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9318
	data_grads_norm = 5.1044
	new_data_grads_norm = 6.8797
	old_data_grads_norm = 7.6084
	sim_grads_norm_tr = 0.0136
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8569
	data_grads_norm = 5.6064
	new_data_grads_norm = 6.3587
	old_data_grads_norm = 7.1911
	sim_grads_norm_tr = -0.0337
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0663
	data_grads_norm = 5.3366
	new_data_grads_norm = 7.2993
	old_data_grads_norm = 7.3236
	sim_grads_norm_tr = 0.0190
-- Starting training on experience 98 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2507
	data_grads_norm = 3.9776
	new_data_grads_norm = 6.6281
	old_data_grads_norm = 5.0342
	sim_grads_norm_tr = 0.0117
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1754
	data_grads_norm = 3.6872
	new_data_grads_norm = 6.8267
	old_data_grads_norm = 5.6399
	sim_grads_norm_tr = -0.0792
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3909
	data_grads_norm = 4.8166
	new_data_grads_norm = 6.5870
	old_data_grads_norm = 6.3119
	sim_grads_norm_tr = 0.0040
-- Starting training on experience 99 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7133
	data_grads_norm = 4.4274
	new_data_grads_norm = 6.3845
	old_data_grads_norm = 6.3251
	sim_grads_norm_tr = -0.0027
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1065
	data_grads_norm = 5.4466
	new_data_grads_norm = 6.5957
	old_data_grads_norm = 7.3134
	sim_grads_norm_tr = 0.0632
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6724
	data_grads_norm = 5.1386
	new_data_grads_norm = 6.1405
	old_data_grads_norm = 6.8872
	sim_grads_norm_tr = 0.0545
-- Starting training on experience 100 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7251
	data_grads_norm = 4.6166
	new_data_grads_norm = 7.7906
	old_data_grads_norm = 5.1233
	sim_grads_norm_tr = 0.0341
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4298
	data_grads_norm = 4.1299
	new_data_grads_norm = 6.3104
	old_data_grads_norm = 5.1258
	sim_grads_norm_tr = 0.0432
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8911
	data_grads_norm = 5.0032
	new_data_grads_norm = 7.3139
	old_data_grads_norm = 6.9268
	sim_grads_norm_tr = -0.0178
-- Starting training on experience 101 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6329
	data_grads_norm = 4.9986
	new_data_grads_norm = 7.9922
	old_data_grads_norm = 6.0984
	sim_grads_norm_tr = -0.0028
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0122
	data_grads_norm = 5.0250
	new_data_grads_norm = 7.7390
	old_data_grads_norm = 6.0017
	sim_grads_norm_tr = 0.0251
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2072
	data_grads_norm = 5.3400
	new_data_grads_norm = 7.9359
	old_data_grads_norm = 5.9634
	sim_grads_norm_tr = 0.0147
-- Starting training on experience 102 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8211
	data_grads_norm = 6.0565
	new_data_grads_norm = 6.7972
	old_data_grads_norm = 8.8625
	sim_grads_norm_tr = -0.0229
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4039
	data_grads_norm = 4.7568
	new_data_grads_norm = 5.8314
	old_data_grads_norm = 7.4544
	sim_grads_norm_tr = 0.0209
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4279
	data_grads_norm = 4.2896
	new_data_grads_norm = 6.9811
	old_data_grads_norm = 4.7346
	sim_grads_norm_tr = 0.0136
-- Starting training on experience 103 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5346
	data_grads_norm = 4.2503
	new_data_grads_norm = 6.4750
	old_data_grads_norm = 4.7862
	sim_grads_norm_tr = 0.0461
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7737
	data_grads_norm = 4.2479
	new_data_grads_norm = 6.4042
	old_data_grads_norm = 4.7401
	sim_grads_norm_tr = -0.0241
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9430
	data_grads_norm = 5.4830
	new_data_grads_norm = 6.5167
	old_data_grads_norm = 7.8598
	sim_grads_norm_tr = 0.0599
-- Starting training on experience 104 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7898
	data_grads_norm = 4.7084
	new_data_grads_norm = 7.1919
	old_data_grads_norm = 6.0889
	sim_grads_norm_tr = 0.0030
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7174
	data_grads_norm = 4.9895
	new_data_grads_norm = 6.8972
	old_data_grads_norm = 7.3511
	sim_grads_norm_tr = 0.0170
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0745
	data_grads_norm = 5.0845
	new_data_grads_norm = 6.5277
	old_data_grads_norm = 7.0931
	sim_grads_norm_tr = 0.0314
-- Starting training on experience 105 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7677
	data_grads_norm = 4.8840
	new_data_grads_norm = 8.1752
	old_data_grads_norm = 5.9409
	sim_grads_norm_tr = -0.0040
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9610
	data_grads_norm = 4.8417
	new_data_grads_norm = 7.2551
	old_data_grads_norm = 4.6224
	sim_grads_norm_tr = 0.0483
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2858
	data_grads_norm = 5.7607
	new_data_grads_norm = 7.4905
	old_data_grads_norm = 8.1712
	sim_grads_norm_tr = 0.0585
-- Starting training on experience 106 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5967
	data_grads_norm = 5.0175
	new_data_grads_norm = 6.9452
	old_data_grads_norm = 7.3722
	sim_grads_norm_tr = -0.0208
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1222
	data_grads_norm = 5.0399
	new_data_grads_norm = 7.2672
	old_data_grads_norm = 5.3543
	sim_grads_norm_tr = 0.0607
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2086
	data_grads_norm = 5.3065
	new_data_grads_norm = 7.0086
	old_data_grads_norm = 6.6425
	sim_grads_norm_tr = -0.0250
-- Starting training on experience 107 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0644
	data_grads_norm = 5.2348
	new_data_grads_norm = 6.6648
	old_data_grads_norm = 7.4083
	sim_grads_norm_tr = 0.0653
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0824
	data_grads_norm = 3.5848
	new_data_grads_norm = 7.0612
	old_data_grads_norm = 3.8116
	sim_grads_norm_tr = -0.0482
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5849
	data_grads_norm = 4.4131
	new_data_grads_norm = 6.5143
	old_data_grads_norm = 6.3421
	sim_grads_norm_tr = 0.0326
-- Starting training on experience 108 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8355
	data_grads_norm = 5.3134
	new_data_grads_norm = 6.2852
	old_data_grads_norm = 7.2826
	sim_grads_norm_tr = -0.0169
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2906
	data_grads_norm = 4.4868
	new_data_grads_norm = 6.2873
	old_data_grads_norm = 6.0118
	sim_grads_norm_tr = -0.0233
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1324
	data_grads_norm = 3.6148
	new_data_grads_norm = 6.4206
	old_data_grads_norm = 4.0694
	sim_grads_norm_tr = 0.0653
-- Starting training on experience 109 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2771
	data_grads_norm = 4.4899
	new_data_grads_norm = 6.2449
	old_data_grads_norm = 7.1539
	sim_grads_norm_tr = 0.0015
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6825
	data_grads_norm = 4.9783
	new_data_grads_norm = 5.7192
	old_data_grads_norm = 7.5504
	sim_grads_norm_tr = -0.0172
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3722
	data_grads_norm = 3.9819
	new_data_grads_norm = 6.0253
	old_data_grads_norm = 4.8246
	sim_grads_norm_tr = -0.0020
-- Starting training on experience 110 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6449
	data_grads_norm = 5.2129
	new_data_grads_norm = 7.5752
	old_data_grads_norm = 6.8814
	sim_grads_norm_tr = -0.0159
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5489
	data_grads_norm = 4.4955
	new_data_grads_norm = 6.3858
	old_data_grads_norm = 6.3465
	sim_grads_norm_tr = 0.0828
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6105
	data_grads_norm = 5.1504
	new_data_grads_norm = 6.9916
	old_data_grads_norm = 7.8599
	sim_grads_norm_tr = 0.0187
-- Starting training on experience 111 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2044
	data_grads_norm = 4.5283
	new_data_grads_norm = 7.0600
	old_data_grads_norm = 6.7604
	sim_grads_norm_tr = -0.0505
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8572
	data_grads_norm = 4.7113
	new_data_grads_norm = 7.1559
	old_data_grads_norm = 5.9766
	sim_grads_norm_tr = 0.0362
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9628
	data_grads_norm = 6.1355
	new_data_grads_norm = 7.2835
	old_data_grads_norm = 9.6585
	sim_grads_norm_tr = 0.0239
-- Starting training on experience 112 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9774
	data_grads_norm = 4.5956
	new_data_grads_norm = 6.6844
	old_data_grads_norm = 5.3545
	sim_grads_norm_tr = 0.0313
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6018
	data_grads_norm = 4.3225
	new_data_grads_norm = 6.8914
	old_data_grads_norm = 5.6262
	sim_grads_norm_tr = 0.0223
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5934
	data_grads_norm = 4.0705
	new_data_grads_norm = 6.4614
	old_data_grads_norm = 4.9741
	sim_grads_norm_tr = 0.0234
-- Starting training on experience 113 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7849
	data_grads_norm = 5.0047
	new_data_grads_norm = 7.2491
	old_data_grads_norm = 5.9100
	sim_grads_norm_tr = 0.1119
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8467
	data_grads_norm = 5.4605
	new_data_grads_norm = 7.0098
	old_data_grads_norm = 7.4869
	sim_grads_norm_tr = -0.0099
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0562
	data_grads_norm = 4.9323
	new_data_grads_norm = 7.0850
	old_data_grads_norm = 6.8302
	sim_grads_norm_tr = 0.0373
-- Starting training on experience 114 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4682
	data_grads_norm = 4.7859
	new_data_grads_norm = 7.3307
	old_data_grads_norm = 6.4652
	sim_grads_norm_tr = -0.0457
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5082
	data_grads_norm = 4.4168
	new_data_grads_norm = 8.0101
	old_data_grads_norm = 8.2936
	sim_grads_norm_tr = -0.0543
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4790
	data_grads_norm = 5.0946
	new_data_grads_norm = 7.8629
	old_data_grads_norm = 6.2651
	sim_grads_norm_tr = 0.0448
-- Starting training on experience 115 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5642
	data_grads_norm = 4.9831
	new_data_grads_norm = 7.0192
	old_data_grads_norm = 5.8332
	sim_grads_norm_tr = 0.0199
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8691
	data_grads_norm = 4.9513
	new_data_grads_norm = 6.7712
	old_data_grads_norm = 5.2075
	sim_grads_norm_tr = 0.1172
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3676
	data_grads_norm = 5.1779
	new_data_grads_norm = 7.6790
	old_data_grads_norm = 8.0582
	sim_grads_norm_tr = -0.0784
-- Starting training on experience 116 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6099
	data_grads_norm = 4.3439
	new_data_grads_norm = 6.8044
	old_data_grads_norm = 5.4350
	sim_grads_norm_tr = -0.0243
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8157
	data_grads_norm = 5.3116
	new_data_grads_norm = 6.6861
	old_data_grads_norm = 7.6808
	sim_grads_norm_tr = 0.0194
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3539
	data_grads_norm = 4.7739
	new_data_grads_norm = 6.7971
	old_data_grads_norm = 6.2752
	sim_grads_norm_tr = 0.0065
-- Starting training on experience 117 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1951
	data_grads_norm = 5.1676
	new_data_grads_norm = 6.8361
	old_data_grads_norm = 9.7649
	sim_grads_norm_tr = 0.0068
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9897
	data_grads_norm = 4.4542
	new_data_grads_norm = 6.0761
	old_data_grads_norm = 6.0647
	sim_grads_norm_tr = -0.0221
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4558
	data_grads_norm = 4.4716
	new_data_grads_norm = 6.1019
	old_data_grads_norm = 6.1761
	sim_grads_norm_tr = -0.0291
-- Starting training on experience 118 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9076
	data_grads_norm = 3.6967
	new_data_grads_norm = 6.3574
	old_data_grads_norm = 4.4431
	sim_grads_norm_tr = -0.0058
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3291
	data_grads_norm = 5.0007
	new_data_grads_norm = 6.2976
	old_data_grads_norm = 7.6877
	sim_grads_norm_tr = 0.0165
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8016
	data_grads_norm = 5.4757
	new_data_grads_norm = 6.4053
	old_data_grads_norm = 7.7493
	sim_grads_norm_tr = -0.0288
-- Starting training on experience 119 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5794
	data_grads_norm = 5.0341
	new_data_grads_norm = 6.6778
	old_data_grads_norm = 5.7617
	sim_grads_norm_tr = 0.0875
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6343
	data_grads_norm = 5.0819
	new_data_grads_norm = 6.2746
	old_data_grads_norm = 6.5049
	sim_grads_norm_tr = 0.0492
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6251
	data_grads_norm = 4.8038
	new_data_grads_norm = 6.7276
	old_data_grads_norm = 7.1886
	sim_grads_norm_tr = -0.0124
-- Starting training on experience 120 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0460
	data_grads_norm = 3.5857
	new_data_grads_norm = 6.5127
	old_data_grads_norm = 4.5522
	sim_grads_norm_tr = 0.0475
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4538
	data_grads_norm = 4.6182
	new_data_grads_norm = 7.5140
	old_data_grads_norm = 5.8026
	sim_grads_norm_tr = 0.0324
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7655
	data_grads_norm = 5.3759
	new_data_grads_norm = 6.5269
	old_data_grads_norm = 7.8614
	sim_grads_norm_tr = 0.0237
-- Starting training on experience 121 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6715
	data_grads_norm = 4.5212
	new_data_grads_norm = 6.3865
	old_data_grads_norm = 6.2770
	sim_grads_norm_tr = -0.0367
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9065
	data_grads_norm = 5.0173
	new_data_grads_norm = 6.4420
	old_data_grads_norm = 7.9949
	sim_grads_norm_tr = -0.0195
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8811
	data_grads_norm = 4.7458
	new_data_grads_norm = 7.1539
	old_data_grads_norm = 6.5580
	sim_grads_norm_tr = 0.0245
-- Starting training on experience 122 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3677
	data_grads_norm = 4.5201
	new_data_grads_norm = 7.1267
	old_data_grads_norm = 5.6234
	sim_grads_norm_tr = -0.0356
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7813
	data_grads_norm = 5.6471
	new_data_grads_norm = 8.1102
	old_data_grads_norm = 7.1589
	sim_grads_norm_tr = -0.0102
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6212
	data_grads_norm = 4.9337
	new_data_grads_norm = 6.9605
	old_data_grads_norm = 6.5166
	sim_grads_norm_tr = -0.0028
-- Starting training on experience 123 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7924
	data_grads_norm = 4.6397
	new_data_grads_norm = 6.3516
	old_data_grads_norm = 6.1482
	sim_grads_norm_tr = 0.0005
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8256
	data_grads_norm = 5.3803
	new_data_grads_norm = 6.7247
	old_data_grads_norm = 7.5824
	sim_grads_norm_tr = 0.0824
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3845
	data_grads_norm = 4.8811
	new_data_grads_norm = 6.1546
	old_data_grads_norm = 7.9879
	sim_grads_norm_tr = -0.0017
-- Starting training on experience 124 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7710
	data_grads_norm = 5.6662
	new_data_grads_norm = 7.1540
	old_data_grads_norm = 7.8825
	sim_grads_norm_tr = -0.0215
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6799
	data_grads_norm = 5.2453
	new_data_grads_norm = 6.7365
	old_data_grads_norm = 7.1319
	sim_grads_norm_tr = 0.0175
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7113
	data_grads_norm = 5.7940
	new_data_grads_norm = 6.5450
	old_data_grads_norm = 9.0350
	sim_grads_norm_tr = 0.0173
-- Starting training on experience 125 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1180
	data_grads_norm = 4.5226
	new_data_grads_norm = 6.1759
	old_data_grads_norm = 5.0199
	sim_grads_norm_tr = 0.0181
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6042
	data_grads_norm = 5.0769
	new_data_grads_norm = 6.6769
	old_data_grads_norm = 6.8836
	sim_grads_norm_tr = -0.0158
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1257
	data_grads_norm = 4.2715
	new_data_grads_norm = 6.5474
	old_data_grads_norm = 6.0749
	sim_grads_norm_tr = 0.0295
-- Starting training on experience 126 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1986
	data_grads_norm = 4.1724
	new_data_grads_norm = 6.1343
	old_data_grads_norm = 5.7826
	sim_grads_norm_tr = -0.0155
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3968
	data_grads_norm = 4.3021
	new_data_grads_norm = 7.0472
	old_data_grads_norm = 5.4778
	sim_grads_norm_tr = -0.0155
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4527
	data_grads_norm = 4.8225
	new_data_grads_norm = 7.3799
	old_data_grads_norm = 6.0756
	sim_grads_norm_tr = -0.0414
-- Starting training on experience 127 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5828
	data_grads_norm = 5.0686
	new_data_grads_norm = 7.0802
	old_data_grads_norm = 6.9586
	sim_grads_norm_tr = -0.0297
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9985
	data_grads_norm = 5.2349
	new_data_grads_norm = 6.7585
	old_data_grads_norm = 6.9781
	sim_grads_norm_tr = 0.0007
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5263
	data_grads_norm = 4.5036
	new_data_grads_norm = 7.2839
	old_data_grads_norm = 5.4296
	sim_grads_norm_tr = 0.0219
-- Starting training on experience 128 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3827
	data_grads_norm = 4.4191
	new_data_grads_norm = 6.2126
	old_data_grads_norm = 7.7598
	sim_grads_norm_tr = -0.0217
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1508
	data_grads_norm = 4.3820
	new_data_grads_norm = 6.5392
	old_data_grads_norm = 5.2995
	sim_grads_norm_tr = -0.0076
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4997
	data_grads_norm = 4.7811
	new_data_grads_norm = 6.4783
	old_data_grads_norm = 7.1990
	sim_grads_norm_tr = 0.0385
-- Starting training on experience 129 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7709
	data_grads_norm = 4.5681
	new_data_grads_norm = 6.5182
	old_data_grads_norm = 5.2867
	sim_grads_norm_tr = -0.0402
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9573
	data_grads_norm = 5.3425
	new_data_grads_norm = 7.3646
	old_data_grads_norm = 7.3561
	sim_grads_norm_tr = 0.0285
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9877
	data_grads_norm = 5.3511
	new_data_grads_norm = 7.7316
	old_data_grads_norm = 7.5896
	sim_grads_norm_tr = -0.0357
-- Starting training on experience 130 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4302
	data_grads_norm = 4.8465
	new_data_grads_norm = 6.8910
	old_data_grads_norm = 5.7948
	sim_grads_norm_tr = 0.0093
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8577
	data_grads_norm = 5.0250
	new_data_grads_norm = 6.0702
	old_data_grads_norm = 6.0406
	sim_grads_norm_tr = -0.0096
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7517
	data_grads_norm = 4.9869
	new_data_grads_norm = 6.5994
	old_data_grads_norm = 8.0499
	sim_grads_norm_tr = -0.0127
-- Starting training on experience 131 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9973
	data_grads_norm = 5.0940
	new_data_grads_norm = 6.9789
	old_data_grads_norm = 6.2932
	sim_grads_norm_tr = 0.1010
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1050
	data_grads_norm = 4.0222
	new_data_grads_norm = 6.3956
	old_data_grads_norm = 5.0433
	sim_grads_norm_tr = 0.0214
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3407
	data_grads_norm = 4.4110
	new_data_grads_norm = 7.0593
	old_data_grads_norm = 5.9458
	sim_grads_norm_tr = -0.0147
-- Starting training on experience 132 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5182
	data_grads_norm = 4.4007
	new_data_grads_norm = 7.3595
	old_data_grads_norm = 5.5186
	sim_grads_norm_tr = -0.0134
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7872
	data_grads_norm = 5.4173
	new_data_grads_norm = 7.5748
	old_data_grads_norm = 6.6943
	sim_grads_norm_tr = 0.0255
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0765
	data_grads_norm = 5.6705
	new_data_grads_norm = 7.2057
	old_data_grads_norm = 9.5687
	sim_grads_norm_tr = 0.0179
-- Starting training on experience 133 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8649
	data_grads_norm = 5.3265
	new_data_grads_norm = 6.6011
	old_data_grads_norm = 8.8914
	sim_grads_norm_tr = -0.0463
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2747
	data_grads_norm = 4.1977
	new_data_grads_norm = 6.2523
	old_data_grads_norm = 5.4356
	sim_grads_norm_tr = -0.0275
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4779
	data_grads_norm = 4.6483
	new_data_grads_norm = 7.3991
	old_data_grads_norm = 5.6283
	sim_grads_norm_tr = -0.0113
-- Starting training on experience 134 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0973
	data_grads_norm = 5.4760
	new_data_grads_norm = 7.2521
	old_data_grads_norm = 7.4250
	sim_grads_norm_tr = -0.0082
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5493
	data_grads_norm = 5.1387
	new_data_grads_norm = 6.4405
	old_data_grads_norm = 7.1995
	sim_grads_norm_tr = -0.0196
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7895
	data_grads_norm = 5.0698
	new_data_grads_norm = 7.0199
	old_data_grads_norm = 6.0679
	sim_grads_norm_tr = 0.0003
-- Starting training on experience 135 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1375
	data_grads_norm = 4.5576
	new_data_grads_norm = 7.2718
	old_data_grads_norm = 5.5504
	sim_grads_norm_tr = -0.0085
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2435
	data_grads_norm = 4.3983
	new_data_grads_norm = 7.5917
	old_data_grads_norm = 5.2196
	sim_grads_norm_tr = -0.0662
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4666
	data_grads_norm = 5.1753
	new_data_grads_norm = 7.4015
	old_data_grads_norm = 6.2520
	sim_grads_norm_tr = -0.0013
-- Starting training on experience 136 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0908
	data_grads_norm = 4.9119
	new_data_grads_norm = 6.8018
	old_data_grads_norm = 6.7619
	sim_grads_norm_tr = 0.0339
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2952
	data_grads_norm = 5.0855
	new_data_grads_norm = 7.3073
	old_data_grads_norm = 5.5498
	sim_grads_norm_tr = 0.0365
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6719
	data_grads_norm = 5.2370
	new_data_grads_norm = 6.9024
	old_data_grads_norm = 7.2592
	sim_grads_norm_tr = 0.0130
-- Starting training on experience 137 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0755
	data_grads_norm = 5.6881
	new_data_grads_norm = 7.1407
	old_data_grads_norm = 7.1057
	sim_grads_norm_tr = 0.0230
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7227
	data_grads_norm = 5.0010
	new_data_grads_norm = 7.5833
	old_data_grads_norm = 6.9852
	sim_grads_norm_tr = 0.0255
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5589
	data_grads_norm = 4.0899
	new_data_grads_norm = 7.0292
	old_data_grads_norm = 4.7149
	sim_grads_norm_tr = 0.0667
-- Starting training on experience 138 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6096
	data_grads_norm = 4.9492
	new_data_grads_norm = 5.9948
	old_data_grads_norm = 6.9205
	sim_grads_norm_tr = 0.0080
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5211
	data_grads_norm = 4.1650
	new_data_grads_norm = 6.0034
	old_data_grads_norm = 5.4367
	sim_grads_norm_tr = -0.0295
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6623
	data_grads_norm = 4.9196
	new_data_grads_norm = 5.9904
	old_data_grads_norm = 6.8802
	sim_grads_norm_tr = -0.0013
-- Starting training on experience 139 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6312
	data_grads_norm = 4.6487
	new_data_grads_norm = 6.2830
	old_data_grads_norm = 6.4681
	sim_grads_norm_tr = 0.0246
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5459
	data_grads_norm = 5.2422
	new_data_grads_norm = 5.8207
	old_data_grads_norm = 7.0600
	sim_grads_norm_tr = -0.0119
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2633
	data_grads_norm = 4.2864
	new_data_grads_norm = 5.7286
	old_data_grads_norm = 6.3695
	sim_grads_norm_tr = 0.0067
-- Starting training on experience 140 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0833
	data_grads_norm = 5.5989
	new_data_grads_norm = 7.9636
	old_data_grads_norm = 8.1196
	sim_grads_norm_tr = 0.0746
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0783
	data_grads_norm = 5.0640
	new_data_grads_norm = 7.9757
	old_data_grads_norm = 5.7302
	sim_grads_norm_tr = 0.0166
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5867
	data_grads_norm = 5.4751
	new_data_grads_norm = 7.8484
	old_data_grads_norm = 7.0523
	sim_grads_norm_tr = -0.0065
-- Starting training on experience 141 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4775
	data_grads_norm = 4.9972
	new_data_grads_norm = 6.4633
	old_data_grads_norm = 6.6928
	sim_grads_norm_tr = 0.0530
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9214
	data_grads_norm = 4.2246
	new_data_grads_norm = 6.9064
	old_data_grads_norm = 5.6844
	sim_grads_norm_tr = -0.0296
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6035
	data_grads_norm = 5.0803
	new_data_grads_norm = 6.3745
	old_data_grads_norm = 7.7019
	sim_grads_norm_tr = -0.0218
-- Starting training on experience 142 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1247
	data_grads_norm = 4.7662
	new_data_grads_norm = 6.5546
	old_data_grads_norm = 6.8641
	sim_grads_norm_tr = -0.0019
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7612
	data_grads_norm = 4.5220
	new_data_grads_norm = 6.5339
	old_data_grads_norm = 5.3092
	sim_grads_norm_tr = 0.0745
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3187
	data_grads_norm = 3.7343
	new_data_grads_norm = 6.2475
	old_data_grads_norm = 5.0952
	sim_grads_norm_tr = -0.0667
-- Starting training on experience 143 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3840
	data_grads_norm = 4.5910
	new_data_grads_norm = 7.3999
	old_data_grads_norm = 5.8584
	sim_grads_norm_tr = -0.0490
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6439
	data_grads_norm = 4.6034
	new_data_grads_norm = 7.4883
	old_data_grads_norm = 6.0356
	sim_grads_norm_tr = -0.0150
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1889
	data_grads_norm = 3.8706
	new_data_grads_norm = 7.1956
	old_data_grads_norm = 5.0299
	sim_grads_norm_tr = -0.0411
-- Starting training on experience 144 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9609
	data_grads_norm = 5.1521
	new_data_grads_norm = 7.5978
	old_data_grads_norm = 7.8313
	sim_grads_norm_tr = 0.0874
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7726
	data_grads_norm = 4.4003
	new_data_grads_norm = 6.6960
	old_data_grads_norm = 5.7738
	sim_grads_norm_tr = -0.0298
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7383
	data_grads_norm = 5.2380
	new_data_grads_norm = 7.5383
	old_data_grads_norm = 8.2449
	sim_grads_norm_tr = 0.0179
-- Starting training on experience 145 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6494
	data_grads_norm = 5.5445
	new_data_grads_norm = 7.2740
	old_data_grads_norm = 7.6450
	sim_grads_norm_tr = -0.0147
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1793
	data_grads_norm = 3.6928
	new_data_grads_norm = 6.6317
	old_data_grads_norm = 4.8057
	sim_grads_norm_tr = -0.0303
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9662
	data_grads_norm = 5.2431
	new_data_grads_norm = 7.4476
	old_data_grads_norm = 8.3778
	sim_grads_norm_tr = 0.0015
-- Starting training on experience 146 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6655
	data_grads_norm = 4.4678
	new_data_grads_norm = 7.2825
	old_data_grads_norm = 5.5477
	sim_grads_norm_tr = -0.0203
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5116
	data_grads_norm = 5.7271
	new_data_grads_norm = 7.6744
	old_data_grads_norm = 7.2807
	sim_grads_norm_tr = 0.0384
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4535
	data_grads_norm = 4.0788
	new_data_grads_norm = 6.9507
	old_data_grads_norm = 4.3340
	sim_grads_norm_tr = -0.0055
-- Starting training on experience 147 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8404
	data_grads_norm = 5.2444
	new_data_grads_norm = 8.1299
	old_data_grads_norm = 6.9980
	sim_grads_norm_tr = -0.0001
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6154
	data_grads_norm = 5.1348
	new_data_grads_norm = 8.3552
	old_data_grads_norm = 5.4850
	sim_grads_norm_tr = 0.0021
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2518
	data_grads_norm = 5.9343
	new_data_grads_norm = 6.7106
	old_data_grads_norm = 8.0790
	sim_grads_norm_tr = 0.0301
-- Starting training on experience 148 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2391
	data_grads_norm = 4.5978
	new_data_grads_norm = 7.4266
	old_data_grads_norm = 4.4603
	sim_grads_norm_tr = 0.0043
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5206
	data_grads_norm = 4.7732
	new_data_grads_norm = 6.7653
	old_data_grads_norm = 6.1459
	sim_grads_norm_tr = 0.0433
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8447
	data_grads_norm = 5.4608
	new_data_grads_norm = 6.8398
	old_data_grads_norm = 7.1224
	sim_grads_norm_tr = 0.0058
-- Starting training on experience 149 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2738
	data_grads_norm = 5.1011
	new_data_grads_norm = 7.4920
	old_data_grads_norm = 6.6627
	sim_grads_norm_tr = 0.0261
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0188
	data_grads_norm = 5.2348
	new_data_grads_norm = 7.0673
	old_data_grads_norm = 8.2913
	sim_grads_norm_tr = 0.0188
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9477
	data_grads_norm = 4.6502
	new_data_grads_norm = 7.4245
	old_data_grads_norm = 5.0213
	sim_grads_norm_tr = -0.0065
-- Starting training on experience 150 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5145
	data_grads_norm = 4.2315
	new_data_grads_norm = 8.0281
	old_data_grads_norm = 5.5786
	sim_grads_norm_tr = -0.0271
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8916
	data_grads_norm = 5.0013
	new_data_grads_norm = 7.6029
	old_data_grads_norm = 6.7970
	sim_grads_norm_tr = 0.0191
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5940
	data_grads_norm = 4.5987
	new_data_grads_norm = 7.3332
	old_data_grads_norm = 5.2051
	sim_grads_norm_tr = 0.0371
-- Starting training on experience 151 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2384
	data_grads_norm = 3.9257
	new_data_grads_norm = 5.6929
	old_data_grads_norm = 5.7683
	sim_grads_norm_tr = -0.0404
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1970
	data_grads_norm = 4.1205
	new_data_grads_norm = 6.3821
	old_data_grads_norm = 5.2494
	sim_grads_norm_tr = 0.0477
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1996
	data_grads_norm = 4.5120
	new_data_grads_norm = 5.7830
	old_data_grads_norm = 6.6948
	sim_grads_norm_tr = 0.0083
-- Starting training on experience 152 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2958
	data_grads_norm = 4.8622
	new_data_grads_norm = 7.5905
	old_data_grads_norm = 5.8901
	sim_grads_norm_tr = 0.0202
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0432
	data_grads_norm = 4.6349
	new_data_grads_norm = 6.5803
	old_data_grads_norm = 6.2324
	sim_grads_norm_tr = 0.0241
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3652
	data_grads_norm = 5.4531
	new_data_grads_norm = 6.6275
	old_data_grads_norm = 8.0514
	sim_grads_norm_tr = -0.0168
-- Starting training on experience 153 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5995
	data_grads_norm = 5.8936
	new_data_grads_norm = 6.9135
	old_data_grads_norm = 7.5303
	sim_grads_norm_tr = -0.0092
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0042
	data_grads_norm = 5.3009
	new_data_grads_norm = 7.1893
	old_data_grads_norm = 6.8484
	sim_grads_norm_tr = 0.0256
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3575
	data_grads_norm = 5.0645
	new_data_grads_norm = 6.7273
	old_data_grads_norm = 7.3035
	sim_grads_norm_tr = -0.0615
-- Starting training on experience 154 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3110
	data_grads_norm = 4.5910
	new_data_grads_norm = 6.4379
	old_data_grads_norm = 6.2231
	sim_grads_norm_tr = 0.0395
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1347
	data_grads_norm = 3.7316
	new_data_grads_norm = 6.3466
	old_data_grads_norm = 3.9235
	sim_grads_norm_tr = -0.0498
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9104
	data_grads_norm = 5.2358
	new_data_grads_norm = 6.0323
	old_data_grads_norm = 8.6639
	sim_grads_norm_tr = 0.0018
-- Starting training on experience 155 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3632
	data_grads_norm = 5.3409
	new_data_grads_norm = 7.9302
	old_data_grads_norm = 7.6041
	sim_grads_norm_tr = -0.0216
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2256
	data_grads_norm = 5.1861
	new_data_grads_norm = 7.2011
	old_data_grads_norm = 8.0175
	sim_grads_norm_tr = -0.0374
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4535
	data_grads_norm = 4.5682
	new_data_grads_norm = 7.9607
	old_data_grads_norm = 6.1207
	sim_grads_norm_tr = -0.0440
-- Starting training on experience 156 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1402
	data_grads_norm = 5.4577
	new_data_grads_norm = 7.7803
	old_data_grads_norm = 6.0930
	sim_grads_norm_tr = 0.0607
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7217
	data_grads_norm = 5.5783
	new_data_grads_norm = 8.0752
	old_data_grads_norm = 6.6452
	sim_grads_norm_tr = 0.1092
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4959
	data_grads_norm = 5.0668
	new_data_grads_norm = 7.1507
	old_data_grads_norm = 5.9960
	sim_grads_norm_tr = -0.0274
-- Starting training on experience 157 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4852
	data_grads_norm = 4.5503
	new_data_grads_norm = 6.5992
	old_data_grads_norm = 5.6100
	sim_grads_norm_tr = -0.0037
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4348
	data_grads_norm = 4.6626
	new_data_grads_norm = 6.2733
	old_data_grads_norm = 7.2450
	sim_grads_norm_tr = -0.0131
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0795
	data_grads_norm = 4.2230
	new_data_grads_norm = 6.2247
	old_data_grads_norm = 6.8510
	sim_grads_norm_tr = -0.0039
-- Starting training on experience 158 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6852
	data_grads_norm = 5.9290
	new_data_grads_norm = 8.0813
	old_data_grads_norm = 6.4367
	sim_grads_norm_tr = -0.0149
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8449
	data_grads_norm = 5.9459
	new_data_grads_norm = 8.8790
	old_data_grads_norm = 5.7963
	sim_grads_norm_tr = 0.0289
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6853
	data_grads_norm = 5.9537
	new_data_grads_norm = 8.4185
	old_data_grads_norm = 6.9437
	sim_grads_norm_tr = 0.0536
-- Starting training on experience 159 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8650
	data_grads_norm = 3.7875
	new_data_grads_norm = 7.3339
	old_data_grads_norm = 4.6543
	sim_grads_norm_tr = 0.0061
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4184
	data_grads_norm = 5.8369
	new_data_grads_norm = 7.0831
	old_data_grads_norm = 7.8539
	sim_grads_norm_tr = -0.0107
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3461
	data_grads_norm = 5.1293
	new_data_grads_norm = 6.5228
	old_data_grads_norm = 5.8212
	sim_grads_norm_tr = -0.0253
-- Starting training on experience 160 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4369
	data_grads_norm = 4.4975
	new_data_grads_norm = 6.5215
	old_data_grads_norm = 6.3233
	sim_grads_norm_tr = -0.0371
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6601
	data_grads_norm = 4.9957
	new_data_grads_norm = 6.6617
	old_data_grads_norm = 6.4306
	sim_grads_norm_tr = 0.0187
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0868
	data_grads_norm = 5.2623
	new_data_grads_norm = 6.6879
	old_data_grads_norm = 7.0618
	sim_grads_norm_tr = 0.0606
-- Starting training on experience 161 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4746
	data_grads_norm = 4.6467
	new_data_grads_norm = 7.1253
	old_data_grads_norm = 6.1814
	sim_grads_norm_tr = -0.0044
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1868
	data_grads_norm = 4.3788
	new_data_grads_norm = 7.1987
	old_data_grads_norm = 6.7089
	sim_grads_norm_tr = -0.0037
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4450
	data_grads_norm = 5.1408
	new_data_grads_norm = 8.3033
	old_data_grads_norm = 6.4846
	sim_grads_norm_tr = -0.0035
-- Starting training on experience 162 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9988
	data_grads_norm = 6.1696
	new_data_grads_norm = 8.2406
	old_data_grads_norm = 8.9769
	sim_grads_norm_tr = -0.0577
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5124
	data_grads_norm = 4.6661
	new_data_grads_norm = 8.1447
	old_data_grads_norm = 4.6986
	sim_grads_norm_tr = -0.0029
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4888
	data_grads_norm = 5.8758
	new_data_grads_norm = 8.4425
	old_data_grads_norm = 6.9918
	sim_grads_norm_tr = 0.1243
-- Starting training on experience 163 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5403
	data_grads_norm = 5.2182
	new_data_grads_norm = 6.6347
	old_data_grads_norm = 7.2814
	sim_grads_norm_tr = 0.0094
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7032
	data_grads_norm = 5.4827
	new_data_grads_norm = 6.7769
	old_data_grads_norm = 7.1354
	sim_grads_norm_tr = 0.0125
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8491
	data_grads_norm = 5.8807
	new_data_grads_norm = 7.1689
	old_data_grads_norm = 8.9400
	sim_grads_norm_tr = -0.0032
-- Starting training on experience 164 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7022
	data_grads_norm = 5.3833
	new_data_grads_norm = 7.5978
	old_data_grads_norm = 6.4369
	sim_grads_norm_tr = 0.0206
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2039
	data_grads_norm = 4.9164
	new_data_grads_norm = 7.2611
	old_data_grads_norm = 6.6039
	sim_grads_norm_tr = 0.0150
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4882
	data_grads_norm = 5.2359
	new_data_grads_norm = 7.1773
	old_data_grads_norm = 6.8953
	sim_grads_norm_tr = 0.0130
-- Starting training on experience 165 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5681
	data_grads_norm = 4.6380
	new_data_grads_norm = 7.1632
	old_data_grads_norm = 5.1478
	sim_grads_norm_tr = 0.0609
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4107
	data_grads_norm = 5.2689
	new_data_grads_norm = 6.7609
	old_data_grads_norm = 7.5927
	sim_grads_norm_tr = 0.0563
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5592
	data_grads_norm = 5.4974
	new_data_grads_norm = 6.7459
	old_data_grads_norm = 7.7742
	sim_grads_norm_tr = 0.0267
-- Starting training on experience 166 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8182
	data_grads_norm = 4.7593
	new_data_grads_norm = 6.9533
	old_data_grads_norm = 6.2650
	sim_grads_norm_tr = 0.0766
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1354
	data_grads_norm = 4.2123
	new_data_grads_norm = 6.4911
	old_data_grads_norm = 6.2188
	sim_grads_norm_tr = -0.0127
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6505
	data_grads_norm = 5.1004
	new_data_grads_norm = 7.0332
	old_data_grads_norm = 7.0071
	sim_grads_norm_tr = -0.0271
-- Starting training on experience 167 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4531
	data_grads_norm = 4.8478
	new_data_grads_norm = 6.3033
	old_data_grads_norm = 6.9348
	sim_grads_norm_tr = -0.0313
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4877
	data_grads_norm = 4.7392
	new_data_grads_norm = 7.5403
	old_data_grads_norm = 5.3534
	sim_grads_norm_tr = 0.0768
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0513
	data_grads_norm = 4.3530
	new_data_grads_norm = 6.6505
	old_data_grads_norm = 5.0789
	sim_grads_norm_tr = -0.0162
-- Starting training on experience 168 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0468
	data_grads_norm = 3.7356
	new_data_grads_norm = 6.7163
	old_data_grads_norm = 4.6071
	sim_grads_norm_tr = -0.0512
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7361
	data_grads_norm = 4.9441
	new_data_grads_norm = 6.2762
	old_data_grads_norm = 6.7313
	sim_grads_norm_tr = -0.0058
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2841
	data_grads_norm = 4.8206
	new_data_grads_norm = 6.9418
	old_data_grads_norm = 5.1924
	sim_grads_norm_tr = -0.0155
-- Starting training on experience 169 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6373
	data_grads_norm = 5.1791
	new_data_grads_norm = 7.0122
	old_data_grads_norm = 6.7569
	sim_grads_norm_tr = 0.0421
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8170
	data_grads_norm = 5.8084
	new_data_grads_norm = 6.8679
	old_data_grads_norm = 7.6729
	sim_grads_norm_tr = 0.0433
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7164
	data_grads_norm = 5.4727
	new_data_grads_norm = 7.0447
	old_data_grads_norm = 7.6069
	sim_grads_norm_tr = 0.0065
-- Starting training on experience 170 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1738
	data_grads_norm = 5.4767
	new_data_grads_norm = 7.0142
	old_data_grads_norm = 8.0129
	sim_grads_norm_tr = 0.0154
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5117
	data_grads_norm = 4.8724
	new_data_grads_norm = 7.5775
	old_data_grads_norm = 5.8045
	sim_grads_norm_tr = -0.0099
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4961
	data_grads_norm = 4.4441
	new_data_grads_norm = 7.0637
	old_data_grads_norm = 5.7805
	sim_grads_norm_tr = 0.0021
-- Starting training on experience 171 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6604
	data_grads_norm = 5.7177
	new_data_grads_norm = 8.1931
	old_data_grads_norm = 5.7513
	sim_grads_norm_tr = 0.0763
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4790
	data_grads_norm = 5.1191
	new_data_grads_norm = 7.4953
	old_data_grads_norm = 6.6913
	sim_grads_norm_tr = -0.0042
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3485
	data_grads_norm = 6.1055
	new_data_grads_norm = 7.9351
	old_data_grads_norm = 7.4636
	sim_grads_norm_tr = 0.0067
-- Starting training on experience 172 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8044
	data_grads_norm = 4.9448
	new_data_grads_norm = 7.2353
	old_data_grads_norm = 6.3310
	sim_grads_norm_tr = -0.0119
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6164
	data_grads_norm = 4.2941
	new_data_grads_norm = 7.1253
	old_data_grads_norm = 5.5909
	sim_grads_norm_tr = 0.0197
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9180
	data_grads_norm = 5.5475
	new_data_grads_norm = 7.5570
	old_data_grads_norm = 7.6612
	sim_grads_norm_tr = 0.0120
-- Starting training on experience 173 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6124
	data_grads_norm = 4.4092
	new_data_grads_norm = 7.4312
	old_data_grads_norm = 4.0996
	sim_grads_norm_tr = -0.0168
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7361
	data_grads_norm = 5.0715
	new_data_grads_norm = 7.5224
	old_data_grads_norm = 7.5645
	sim_grads_norm_tr = -0.0546
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3024
	data_grads_norm = 6.1092
	new_data_grads_norm = 8.2756
	old_data_grads_norm = 9.1317
	sim_grads_norm_tr = -0.0622
-- Starting training on experience 174 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7554
	data_grads_norm = 5.4147
	new_data_grads_norm = 7.2011
	old_data_grads_norm = 6.9324
	sim_grads_norm_tr = 0.0622
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1035
	data_grads_norm = 5.6341
	new_data_grads_norm = 7.1681
	old_data_grads_norm = 7.5159
	sim_grads_norm_tr = 0.0991
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6144
	data_grads_norm = 5.4967
	new_data_grads_norm = 7.3855
	old_data_grads_norm = 7.2962
	sim_grads_norm_tr = 0.0773
-- Starting training on experience 175 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4445
	data_grads_norm = 5.1838
	new_data_grads_norm = 7.1369
	old_data_grads_norm = 7.2265
	sim_grads_norm_tr = 0.0236
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1959
	data_grads_norm = 4.9877
	new_data_grads_norm = 6.4843
	old_data_grads_norm = 6.7378
	sim_grads_norm_tr = 0.0334
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4001
	data_grads_norm = 4.3229
	new_data_grads_norm = 6.7201
	old_data_grads_norm = 5.0569
	sim_grads_norm_tr = 0.0005
-- Starting training on experience 176 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6968
	data_grads_norm = 4.2879
	new_data_grads_norm = 6.0006
	old_data_grads_norm = 7.1394
	sim_grads_norm_tr = -0.0233
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9683
	data_grads_norm = 4.8847
	new_data_grads_norm = 5.3079
	old_data_grads_norm = 6.6380
	sim_grads_norm_tr = -0.0208
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1563
	data_grads_norm = 4.2968
	new_data_grads_norm = 5.6489
	old_data_grads_norm = 5.1760
	sim_grads_norm_tr = 0.0525
-- Starting training on experience 177 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6174
	data_grads_norm = 4.8817
	new_data_grads_norm = 6.5547
	old_data_grads_norm = 7.5032
	sim_grads_norm_tr = 0.0300
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2413
	data_grads_norm = 4.6371
	new_data_grads_norm = 6.4048
	old_data_grads_norm = 5.5886
	sim_grads_norm_tr = -0.0069
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6455
	data_grads_norm = 5.1235
	new_data_grads_norm = 6.5390
	old_data_grads_norm = 6.9791
	sim_grads_norm_tr = 0.0107
-- Starting training on experience 178 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1825
	data_grads_norm = 4.3790
	new_data_grads_norm = 7.7111
	old_data_grads_norm = 7.1787
	sim_grads_norm_tr = 0.0474
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6935
	data_grads_norm = 5.2571
	new_data_grads_norm = 7.1767
	old_data_grads_norm = 6.5814
	sim_grads_norm_tr = 0.0667
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6440
	data_grads_norm = 4.9679
	new_data_grads_norm = 8.3137
	old_data_grads_norm = 5.4339
	sim_grads_norm_tr = 0.0421
-- Starting training on experience 179 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5035
	data_grads_norm = 4.9661
	new_data_grads_norm = 8.1509
	old_data_grads_norm = 5.6007
	sim_grads_norm_tr = 0.0246
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6057
	data_grads_norm = 5.0365
	new_data_grads_norm = 7.7442
	old_data_grads_norm = 6.4047
	sim_grads_norm_tr = 0.0301
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0220
	data_grads_norm = 6.2149
	new_data_grads_norm = 8.9382
	old_data_grads_norm = 8.4213
	sim_grads_norm_tr = 0.0057
-- Starting training on experience 180 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9420
	data_grads_norm = 4.9965
	new_data_grads_norm = 8.3254
	old_data_grads_norm = 5.8129
	sim_grads_norm_tr = 0.0713
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5976
	data_grads_norm = 5.2640
	new_data_grads_norm = 8.0234
	old_data_grads_norm = 6.4060
	sim_grads_norm_tr = 0.0091
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5836
	data_grads_norm = 5.3420
	new_data_grads_norm = 8.4694
	old_data_grads_norm = 9.7125
	sim_grads_norm_tr = -0.0002
-- Starting training on experience 181 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9380
	data_grads_norm = 4.6272
	new_data_grads_norm = 7.1758
	old_data_grads_norm = 6.3203
	sim_grads_norm_tr = 0.0140
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1284
	data_grads_norm = 4.4009
	new_data_grads_norm = 7.3025
	old_data_grads_norm = 5.0183
	sim_grads_norm_tr = -0.0297
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0226
	data_grads_norm = 5.2510
	new_data_grads_norm = 6.9266
	old_data_grads_norm = 7.7640
	sim_grads_norm_tr = -0.0014
-- Starting training on experience 182 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0318
	data_grads_norm = 4.6606
	new_data_grads_norm = 7.6078
	old_data_grads_norm = 6.5465
	sim_grads_norm_tr = -0.0129
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1845
	data_grads_norm = 4.2608
	new_data_grads_norm = 7.5814
	old_data_grads_norm = 4.5573
	sim_grads_norm_tr = 0.0524
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4835
	data_grads_norm = 4.8359
	new_data_grads_norm = 6.7843
	old_data_grads_norm = 6.0905
	sim_grads_norm_tr = 0.0457
-- Starting training on experience 183 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6025
	data_grads_norm = 4.5535
	new_data_grads_norm = 7.3171
	old_data_grads_norm = 6.1211
	sim_grads_norm_tr = 0.0356
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6130
	data_grads_norm = 5.1851
	new_data_grads_norm = 7.7894
	old_data_grads_norm = 5.9307
	sim_grads_norm_tr = 0.0285
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9800
	data_grads_norm = 4.1764
	new_data_grads_norm = 7.2139
	old_data_grads_norm = 4.3619
	sim_grads_norm_tr = 0.0153
-- Starting training on experience 184 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2322
	data_grads_norm = 5.7672
	new_data_grads_norm = 6.7858
	old_data_grads_norm = 7.4118
	sim_grads_norm_tr = -0.0396
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8919
	data_grads_norm = 4.2800
	new_data_grads_norm = 7.0933
	old_data_grads_norm = 4.3590
	sim_grads_norm_tr = -0.0488
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1332
	data_grads_norm = 5.1134
	new_data_grads_norm = 6.4482
	old_data_grads_norm = 7.5796
	sim_grads_norm_tr = -0.0311
-- Starting training on experience 185 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7621
	data_grads_norm = 5.3766
	new_data_grads_norm = 8.4625
	old_data_grads_norm = 5.3839
	sim_grads_norm_tr = 0.0195
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6339
	data_grads_norm = 5.3902
	new_data_grads_norm = 8.0031
	old_data_grads_norm = 5.3308
	sim_grads_norm_tr = 0.0210
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9270
	data_grads_norm = 5.3562
	new_data_grads_norm = 7.7415
	old_data_grads_norm = 6.6114
	sim_grads_norm_tr = 0.0481
-- Starting training on experience 186 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4207
	data_grads_norm = 4.9938
	new_data_grads_norm = 7.3066
	old_data_grads_norm = 6.4137
	sim_grads_norm_tr = 0.0442
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2184
	data_grads_norm = 4.9493
	new_data_grads_norm = 6.9087
	old_data_grads_norm = 6.9014
	sim_grads_norm_tr = 0.0054
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1258
	data_grads_norm = 4.6007
	new_data_grads_norm = 7.1081
	old_data_grads_norm = 6.0655
	sim_grads_norm_tr = -0.0686
-- Starting training on experience 187 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5425
	data_grads_norm = 5.3381
	new_data_grads_norm = 8.1580
	old_data_grads_norm = 6.4828
	sim_grads_norm_tr = 0.0093
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6378
	data_grads_norm = 5.2588
	new_data_grads_norm = 7.6300
	old_data_grads_norm = 6.7095
	sim_grads_norm_tr = 0.0028
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4456
	data_grads_norm = 5.1844
	new_data_grads_norm = 6.8814
	old_data_grads_norm = 7.7137
	sim_grads_norm_tr = -0.0588
-- Starting training on experience 188 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5469
	data_grads_norm = 4.4828
	new_data_grads_norm = 7.1608
	old_data_grads_norm = 6.0845
	sim_grads_norm_tr = -0.0009
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7075
	data_grads_norm = 4.6479
	new_data_grads_norm = 7.3567
	old_data_grads_norm = 4.9576
	sim_grads_norm_tr = 0.0368
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4133
	data_grads_norm = 3.9143
	new_data_grads_norm = 7.2975
	old_data_grads_norm = 4.4608
	sim_grads_norm_tr = 0.0094
-- Starting training on experience 189 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6091
	data_grads_norm = 4.3525
	new_data_grads_norm = 6.8176
	old_data_grads_norm = 6.4424
	sim_grads_norm_tr = 0.0264
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8765
	data_grads_norm = 5.3192
	new_data_grads_norm = 7.2982
	old_data_grads_norm = 6.3023
	sim_grads_norm_tr = 0.0239
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8606
	data_grads_norm = 4.5814
	new_data_grads_norm = 7.0247
	old_data_grads_norm = 6.3848
	sim_grads_norm_tr = 0.0979
-- Starting training on experience 190 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8420
	data_grads_norm = 5.5644
	new_data_grads_norm = 6.2536
	old_data_grads_norm = 8.0663
	sim_grads_norm_tr = 0.0440
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2703
	data_grads_norm = 4.7802
	new_data_grads_norm = 5.7842
	old_data_grads_norm = 7.2984
	sim_grads_norm_tr = 0.0816
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1762
	data_grads_norm = 4.7451
	new_data_grads_norm = 6.0764
	old_data_grads_norm = 6.4800
	sim_grads_norm_tr = 0.0207
-- Starting training on experience 191 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0283
	data_grads_norm = 4.5328
	new_data_grads_norm = 6.0155
	old_data_grads_norm = 7.8159
	sim_grads_norm_tr = -0.0347
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2085
	data_grads_norm = 4.5463
	new_data_grads_norm = 6.5816
	old_data_grads_norm = 5.5281
	sim_grads_norm_tr = -0.0078
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1808
	data_grads_norm = 4.6158
	new_data_grads_norm = 7.0981
	old_data_grads_norm = 6.5556
	sim_grads_norm_tr = 0.0257
-- Starting training on experience 192 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3740
	data_grads_norm = 4.6921
	new_data_grads_norm = 6.9818
	old_data_grads_norm = 6.7928
	sim_grads_norm_tr = -0.0163
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5395
	data_grads_norm = 5.1748
	new_data_grads_norm = 6.9044
	old_data_grads_norm = 7.9718
	sim_grads_norm_tr = -0.0205
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2977
	data_grads_norm = 4.6681
	new_data_grads_norm = 6.9905
	old_data_grads_norm = 5.9465
	sim_grads_norm_tr = -0.0568
-- Starting training on experience 193 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6411
	data_grads_norm = 6.4174
	new_data_grads_norm = 6.7779
	old_data_grads_norm = 10.0738
	sim_grads_norm_tr = -0.0192
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3557
	data_grads_norm = 5.3477
	new_data_grads_norm = 7.4509
	old_data_grads_norm = 6.0344
	sim_grads_norm_tr = 0.1069
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4626
	data_grads_norm = 5.4218
	new_data_grads_norm = 7.9466
	old_data_grads_norm = 7.1281
	sim_grads_norm_tr = 0.0433
-- Starting training on experience 194 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0090
	data_grads_norm = 4.6553
	new_data_grads_norm = 7.5635
	old_data_grads_norm = 5.9585
	sim_grads_norm_tr = 0.0002
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9732
	data_grads_norm = 4.6293
	new_data_grads_norm = 8.1167
	old_data_grads_norm = 6.3616
	sim_grads_norm_tr = -0.0787
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1540
	data_grads_norm = 4.9751
	new_data_grads_norm = 8.2493
	old_data_grads_norm = 6.6914
	sim_grads_norm_tr = 0.0013
-- Starting training on experience 195 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5737
	data_grads_norm = 4.9382
	new_data_grads_norm = 8.5742
	old_data_grads_norm = 6.1248
	sim_grads_norm_tr = 0.0722
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7744
	data_grads_norm = 5.8149
	new_data_grads_norm = 9.0167
	old_data_grads_norm = 7.1017
	sim_grads_norm_tr = 0.0220
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7277
	data_grads_norm = 5.8381
	new_data_grads_norm = 8.8686
	old_data_grads_norm = 7.7339
	sim_grads_norm_tr = -0.0329
-- Starting training on experience 196 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7557
	data_grads_norm = 4.8642
	new_data_grads_norm = 7.2591
	old_data_grads_norm = 5.6419
	sim_grads_norm_tr = 0.0314
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4930
	data_grads_norm = 5.2355
	new_data_grads_norm = 7.0821
	old_data_grads_norm = 7.5655
	sim_grads_norm_tr = -0.0140
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1666
	data_grads_norm = 4.4948
	new_data_grads_norm = 6.9864
	old_data_grads_norm = 5.8561
	sim_grads_norm_tr = 0.0550
-- Starting training on experience 197 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4845
	data_grads_norm = 5.2039
	new_data_grads_norm = 7.3036
	old_data_grads_norm = 7.1850
	sim_grads_norm_tr = 0.0057
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8212
	data_grads_norm = 5.8050
	new_data_grads_norm = 6.9984
	old_data_grads_norm = 8.9479
	sim_grads_norm_tr = 0.0048
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4501
	data_grads_norm = 5.2076
	new_data_grads_norm = 7.0604
	old_data_grads_norm = 6.7528
	sim_grads_norm_tr = 0.0382
-- Starting training on experience 198 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8517
	data_grads_norm = 4.8210
	new_data_grads_norm = 6.8915
	old_data_grads_norm = 7.1775
	sim_grads_norm_tr = 0.0236
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5632
	data_grads_norm = 5.3779
	new_data_grads_norm = 7.0325
	old_data_grads_norm = 7.5014
	sim_grads_norm_tr = -0.0094
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2543
	data_grads_norm = 4.2342
	new_data_grads_norm = 6.6111
	old_data_grads_norm = 5.5309
	sim_grads_norm_tr = 0.0371
-- Starting training on experience 199 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9478
	data_grads_norm = 4.3981
	new_data_grads_norm = 7.3171
	old_data_grads_norm = 5.8325
	sim_grads_norm_tr = -0.0236
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0629
	data_grads_norm = 4.5058
	new_data_grads_norm = 7.5725
	old_data_grads_norm = 4.5326
	sim_grads_norm_tr = 0.0706
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4908
	data_grads_norm = 5.3212
	new_data_grads_norm = 6.9424
	old_data_grads_norm = 8.7397
	sim_grads_norm_tr = -0.0262
-- Starting training on experience 200 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3255
	data_grads_norm = 5.0276
	new_data_grads_norm = 7.9635
	old_data_grads_norm = 6.0195
	sim_grads_norm_tr = 0.0324
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2343
	data_grads_norm = 4.7426
	new_data_grads_norm = 7.3827
	old_data_grads_norm = 6.1849
	sim_grads_norm_tr = -0.0201
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5609
	data_grads_norm = 4.9127
	new_data_grads_norm = 7.9083
	old_data_grads_norm = 5.0810
	sim_grads_norm_tr = 0.0946
-- Starting training on experience 201 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2376
	data_grads_norm = 4.2100
	new_data_grads_norm = 6.6922
	old_data_grads_norm = 4.6694
	sim_grads_norm_tr = -0.0587
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1453
	data_grads_norm = 4.4071
	new_data_grads_norm = 7.2609
	old_data_grads_norm = 6.0530
	sim_grads_norm_tr = -0.0414
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5974
	data_grads_norm = 4.9170
	new_data_grads_norm = 7.4024
	old_data_grads_norm = 6.6483
	sim_grads_norm_tr = -0.0447
-- Starting training on experience 202 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6667
	data_grads_norm = 4.9119
	new_data_grads_norm = 7.4097
	old_data_grads_norm = 7.2642
	sim_grads_norm_tr = -0.0010
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6619
	data_grads_norm = 4.9290
	new_data_grads_norm = 7.2646
	old_data_grads_norm = 5.8420
	sim_grads_norm_tr = 0.0475
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9092
	data_grads_norm = 5.5130
	new_data_grads_norm = 7.6185
	old_data_grads_norm = 7.9404
	sim_grads_norm_tr = 0.0574
-- Starting training on experience 203 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4698
	data_grads_norm = 5.0206
	new_data_grads_norm = 7.4656
	old_data_grads_norm = 6.5484
	sim_grads_norm_tr = 0.0335
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8119
	data_grads_norm = 5.4145
	new_data_grads_norm = 8.0869
	old_data_grads_norm = 6.8646
	sim_grads_norm_tr = 0.0306
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2947
	data_grads_norm = 5.1937
	new_data_grads_norm = 7.6036
	old_data_grads_norm = 6.9942
	sim_grads_norm_tr = -0.0426
-- Starting training on experience 204 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7222
	data_grads_norm = 4.4087
	new_data_grads_norm = 7.1313
	old_data_grads_norm = 5.1945
	sim_grads_norm_tr = 0.0195
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2842
	data_grads_norm = 4.3885
	new_data_grads_norm = 7.8673
	old_data_grads_norm = 6.0688
	sim_grads_norm_tr = -0.0179
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4516
	data_grads_norm = 5.1684
	new_data_grads_norm = 7.5647
	old_data_grads_norm = 6.6336
	sim_grads_norm_tr = -0.0320
-- Starting training on experience 205 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4765
	data_grads_norm = 4.8720
	new_data_grads_norm = 7.6142
	old_data_grads_norm = 6.8849
	sim_grads_norm_tr = -0.0037
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7269
	data_grads_norm = 6.0245
	new_data_grads_norm = 7.2774
	old_data_grads_norm = 7.7457
	sim_grads_norm_tr = 0.0232
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6194
	data_grads_norm = 5.4744
	new_data_grads_norm = 6.8067
	old_data_grads_norm = 9.8273
	sim_grads_norm_tr = -0.0209
-- Starting training on experience 206 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9776
	data_grads_norm = 5.7785
	new_data_grads_norm = 8.2794
	old_data_grads_norm = 7.1547
	sim_grads_norm_tr = 0.0443
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6800
	data_grads_norm = 5.4579
	new_data_grads_norm = 8.4068
	old_data_grads_norm = 6.5545
	sim_grads_norm_tr = 0.0095
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9361
	data_grads_norm = 5.3206
	new_data_grads_norm = 7.9535
	old_data_grads_norm = 6.1066
	sim_grads_norm_tr = 0.0294
-- Starting training on experience 207 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1568
	data_grads_norm = 4.9442
	new_data_grads_norm = 7.4701
	old_data_grads_norm = 6.7432
	sim_grads_norm_tr = 0.0745
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5930
	data_grads_norm = 5.5609
	new_data_grads_norm = 7.4867
	old_data_grads_norm = 8.2373
	sim_grads_norm_tr = 0.0575
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2626
	data_grads_norm = 4.8568
	new_data_grads_norm = 7.2384
	old_data_grads_norm = 7.5949
	sim_grads_norm_tr = -0.0290
-- Starting training on experience 208 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6689
	data_grads_norm = 6.0001
	new_data_grads_norm = 8.7578
	old_data_grads_norm = 7.3453
	sim_grads_norm_tr = -0.0005
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8505
	data_grads_norm = 6.3124
	new_data_grads_norm = 8.9254
	old_data_grads_norm = 7.7170
	sim_grads_norm_tr = 0.0798
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0702
	data_grads_norm = 5.5675
	new_data_grads_norm = 8.5910
	old_data_grads_norm = 5.9881
	sim_grads_norm_tr = 0.0404
-- Starting training on experience 209 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7631
	data_grads_norm = 4.5291
	new_data_grads_norm = 7.9925
	old_data_grads_norm = 5.6838
	sim_grads_norm_tr = 0.0013
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6919
	data_grads_norm = 4.5433
	new_data_grads_norm = 8.4786
	old_data_grads_norm = 4.2342
	sim_grads_norm_tr = 0.0460
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6754
	data_grads_norm = 6.0440
	new_data_grads_norm = 8.5334
	old_data_grads_norm = 8.0605
	sim_grads_norm_tr = 0.0385
-- Starting training on experience 210 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4625
	data_grads_norm = 5.7523
	new_data_grads_norm = 7.3457
	old_data_grads_norm = 8.4811
	sim_grads_norm_tr = -0.0966
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9385
	data_grads_norm = 5.5027
	new_data_grads_norm = 7.7481
	old_data_grads_norm = 7.3151
	sim_grads_norm_tr = 0.0252
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8010
	data_grads_norm = 5.4244
	new_data_grads_norm = 7.4964
	old_data_grads_norm = 8.1559
	sim_grads_norm_tr = -0.0031
-- Starting training on experience 211 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7589
	data_grads_norm = 5.0765
	new_data_grads_norm = 7.8103
	old_data_grads_norm = 6.9800
	sim_grads_norm_tr = 0.0293
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6992
	data_grads_norm = 5.4420
	new_data_grads_norm = 7.0028
	old_data_grads_norm = 7.5759
	sim_grads_norm_tr = 0.0125
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3911
	data_grads_norm = 4.7585
	new_data_grads_norm = 7.4857
	old_data_grads_norm = 6.5543
	sim_grads_norm_tr = 0.0229
-- Starting training on experience 212 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9847
	data_grads_norm = 4.4879
	new_data_grads_norm = 7.6147
	old_data_grads_norm = 6.7269
	sim_grads_norm_tr = 0.0006
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4571
	data_grads_norm = 5.0478
	new_data_grads_norm = 6.7329
	old_data_grads_norm = 8.2856
	sim_grads_norm_tr = -0.0093
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7810
	data_grads_norm = 4.1659
	new_data_grads_norm = 6.8203
	old_data_grads_norm = 5.2846
	sim_grads_norm_tr = 0.0488
-- Starting training on experience 213 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5295
	data_grads_norm = 4.9388
	new_data_grads_norm = 8.6423
	old_data_grads_norm = 6.9664
	sim_grads_norm_tr = -0.0318
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2399
	data_grads_norm = 5.7683
	new_data_grads_norm = 8.6205
	old_data_grads_norm = 7.0486
	sim_grads_norm_tr = -0.0043
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9083
	data_grads_norm = 5.3982
	new_data_grads_norm = 8.8791
	old_data_grads_norm = 7.3275
	sim_grads_norm_tr = 0.0254
-- Starting training on experience 214 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5645
	data_grads_norm = 5.1145
	new_data_grads_norm = 7.9362
	old_data_grads_norm = 6.8386
	sim_grads_norm_tr = -0.0012
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6890
	data_grads_norm = 5.4719
	new_data_grads_norm = 8.0917
	old_data_grads_norm = 6.8474
	sim_grads_norm_tr = 0.0208
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4655
	data_grads_norm = 5.0029
	new_data_grads_norm = 7.8882
	old_data_grads_norm = 6.8475
	sim_grads_norm_tr = -0.0252
-- Starting training on experience 215 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5464
	data_grads_norm = 4.9080
	new_data_grads_norm = 6.4957
	old_data_grads_norm = 6.4320
	sim_grads_norm_tr = -0.0218
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6909
	data_grads_norm = 5.2136
	new_data_grads_norm = 6.4016
	old_data_grads_norm = 7.6075
	sim_grads_norm_tr = -0.0295
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5376
	data_grads_norm = 4.8962
	new_data_grads_norm = 7.1318
	old_data_grads_norm = 6.3483
	sim_grads_norm_tr = 0.0091
-- Starting training on experience 216 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7015
	data_grads_norm = 5.0117
	new_data_grads_norm = 7.5789
	old_data_grads_norm = 6.5290
	sim_grads_norm_tr = 0.0123
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6667
	data_grads_norm = 5.3666
	new_data_grads_norm = 8.3137
	old_data_grads_norm = 5.2882
	sim_grads_norm_tr = 0.0330
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4999
	data_grads_norm = 5.1672
	new_data_grads_norm = 8.1736
	old_data_grads_norm = 4.9972
	sim_grads_norm_tr = -0.0177
-- Starting training on experience 217 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2280
	data_grads_norm = 4.8952
	new_data_grads_norm = 8.5616
	old_data_grads_norm = 6.7220
	sim_grads_norm_tr = 0.0058
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5276
	data_grads_norm = 4.9400
	new_data_grads_norm = 7.5825
	old_data_grads_norm = 6.6230
	sim_grads_norm_tr = 0.0619
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9167
	data_grads_norm = 5.2640
	new_data_grads_norm = 7.9248
	old_data_grads_norm = 6.2349
	sim_grads_norm_tr = 0.0668
-- Starting training on experience 218 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8876
	data_grads_norm = 5.8983
	new_data_grads_norm = 7.7434
	old_data_grads_norm = 7.3177
	sim_grads_norm_tr = -0.0289
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0670
	data_grads_norm = 6.2749
	new_data_grads_norm = 8.0488
	old_data_grads_norm = 9.2038
	sim_grads_norm_tr = -0.0165
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6496
	data_grads_norm = 5.4358
	new_data_grads_norm = 8.0272
	old_data_grads_norm = 7.6159
	sim_grads_norm_tr = -0.0133
-- Starting training on experience 219 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5638
	data_grads_norm = 5.8828
	new_data_grads_norm = 7.3646
	old_data_grads_norm = 7.5890
	sim_grads_norm_tr = 0.0058
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4182
	data_grads_norm = 5.0784
	new_data_grads_norm = 7.1722
	old_data_grads_norm = 6.8277
	sim_grads_norm_tr = -0.0106
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0459
	data_grads_norm = 5.3594
	new_data_grads_norm = 8.0218
	old_data_grads_norm = 8.5587
	sim_grads_norm_tr = -0.0062
-- Starting training on experience 220 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2810
	data_grads_norm = 4.5143
	new_data_grads_norm = 7.7398
	old_data_grads_norm = 5.9248
	sim_grads_norm_tr = 0.0338
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2894
	data_grads_norm = 4.7734
	new_data_grads_norm = 7.2975
	old_data_grads_norm = 6.7581
	sim_grads_norm_tr = 0.0174
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3904
	data_grads_norm = 5.1681
	new_data_grads_norm = 6.4557
	old_data_grads_norm = 7.3689
	sim_grads_norm_tr = -0.0311
-- Starting training on experience 221 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7869
	data_grads_norm = 4.9347
	new_data_grads_norm = 7.8578
	old_data_grads_norm = 5.3859
	sim_grads_norm_tr = 0.0044
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1783
	data_grads_norm = 4.4804
	new_data_grads_norm = 7.4206
	old_data_grads_norm = 5.8588
	sim_grads_norm_tr = -0.0606
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9832
	data_grads_norm = 5.2448
	new_data_grads_norm = 8.1326
	old_data_grads_norm = 5.7942
	sim_grads_norm_tr = 0.0587
-- Starting training on experience 222 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3890
	data_grads_norm = 4.9944
	new_data_grads_norm = 7.5868
	old_data_grads_norm = 5.9340
	sim_grads_norm_tr = 0.0130
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0076
	data_grads_norm = 4.2639
	new_data_grads_norm = 8.3360
	old_data_grads_norm = 4.9964
	sim_grads_norm_tr = -0.0324
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6246
	data_grads_norm = 5.0724
	new_data_grads_norm = 8.2753
	old_data_grads_norm = 6.6055
	sim_grads_norm_tr = 0.0076
-- Starting training on experience 223 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2347
	data_grads_norm = 4.8583
	new_data_grads_norm = 7.2550
	old_data_grads_norm = 6.6564
	sim_grads_norm_tr = -0.0137
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9259
	data_grads_norm = 5.8928
	new_data_grads_norm = 7.3834
	old_data_grads_norm = 9.1984
	sim_grads_norm_tr = 0.0070
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0888
	data_grads_norm = 4.5243
	new_data_grads_norm = 7.2349
	old_data_grads_norm = 5.3318
	sim_grads_norm_tr = -0.0221
-- Starting training on experience 224 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4324
	data_grads_norm = 5.5653
	new_data_grads_norm = 8.0661
	old_data_grads_norm = 8.0711
	sim_grads_norm_tr = -0.0020
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1775
	data_grads_norm = 4.7406
	new_data_grads_norm = 7.5627
	old_data_grads_norm = 6.8566
	sim_grads_norm_tr = -0.0018
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5917
	data_grads_norm = 5.6068
	new_data_grads_norm = 7.2375
	old_data_grads_norm = 7.9143
	sim_grads_norm_tr = 0.0150
-- Starting training on experience 225 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3989
	data_grads_norm = 5.4944
	new_data_grads_norm = 7.3163
	old_data_grads_norm = 7.9553
	sim_grads_norm_tr = 0.0693
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8815
	data_grads_norm = 5.8379
	new_data_grads_norm = 8.5139
	old_data_grads_norm = 7.2758
	sim_grads_norm_tr = 0.1419
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3950
	data_grads_norm = 4.8722
	new_data_grads_norm = 8.3678
	old_data_grads_norm = 5.4138
	sim_grads_norm_tr = -0.0370
-- Starting training on experience 226 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8563
	data_grads_norm = 6.3430
	new_data_grads_norm = 8.5221
	old_data_grads_norm = 8.7092
	sim_grads_norm_tr = 0.0243
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4607
	data_grads_norm = 5.7376
	new_data_grads_norm = 8.0645
	old_data_grads_norm = 7.9514
	sim_grads_norm_tr = -0.0083
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6189
	data_grads_norm = 5.4571
	new_data_grads_norm = 8.7703
	old_data_grads_norm = 6.9111
	sim_grads_norm_tr = 0.0003
-- Starting training on experience 227 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3975
	data_grads_norm = 5.6739
	new_data_grads_norm = 7.5032
	old_data_grads_norm = 7.2207
	sim_grads_norm_tr = 0.0015
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1105
	data_grads_norm = 5.0182
	new_data_grads_norm = 7.6257
	old_data_grads_norm = 5.6434
	sim_grads_norm_tr = 0.0132
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1327
	data_grads_norm = 4.8281
	new_data_grads_norm = 6.7738
	old_data_grads_norm = 6.2227
	sim_grads_norm_tr = -0.0426
-- Starting training on experience 228 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2967
	data_grads_norm = 4.5794
	new_data_grads_norm = 6.3655
	old_data_grads_norm = 6.1758
	sim_grads_norm_tr = 0.0338
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0423
	data_grads_norm = 4.4903
	new_data_grads_norm = 6.3847
	old_data_grads_norm = 6.3191
	sim_grads_norm_tr = -0.0298
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5021
	data_grads_norm = 4.7651
	new_data_grads_norm = 6.1641
	old_data_grads_norm = 6.8689
	sim_grads_norm_tr = 0.0217
-- Starting training on experience 229 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1786
	data_grads_norm = 4.9430
	new_data_grads_norm = 7.1992
	old_data_grads_norm = 6.4439
	sim_grads_norm_tr = -0.0105
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6107
	data_grads_norm = 5.8608
	new_data_grads_norm = 8.2347
	old_data_grads_norm = 8.1568
	sim_grads_norm_tr = 0.0139
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2649
	data_grads_norm = 5.0503
	new_data_grads_norm = 7.5333
	old_data_grads_norm = 7.1109
	sim_grads_norm_tr = -0.0125
-- Starting training on experience 230 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6099
	data_grads_norm = 5.5230
	new_data_grads_norm = 6.7713
	old_data_grads_norm = 7.9068
	sim_grads_norm_tr = -0.0104
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2521
	data_grads_norm = 4.0941
	new_data_grads_norm = 7.3011
	old_data_grads_norm = 5.6421
	sim_grads_norm_tr = -0.0373
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2627
	data_grads_norm = 4.6215
	new_data_grads_norm = 7.0480
	old_data_grads_norm = 6.7488
	sim_grads_norm_tr = -0.0266
-- Starting training on experience 231 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3685
	data_grads_norm = 4.5958
	new_data_grads_norm = 6.9989
	old_data_grads_norm = 6.5447
	sim_grads_norm_tr = -0.0339
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4641
	data_grads_norm = 4.7235
	new_data_grads_norm = 7.7075
	old_data_grads_norm = 5.9676
	sim_grads_norm_tr = -0.0208
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7986
	data_grads_norm = 5.2097
	new_data_grads_norm = 7.9536
	old_data_grads_norm = 5.9448
	sim_grads_norm_tr = 0.0074
-- Starting training on experience 232 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4311
	data_grads_norm = 5.6704
	new_data_grads_norm = 7.4433
	old_data_grads_norm = 8.2506
	sim_grads_norm_tr = -0.0183
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2685
	data_grads_norm = 5.1809
	new_data_grads_norm = 7.6414
	old_data_grads_norm = 4.8763
	sim_grads_norm_tr = 0.0952
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2888
	data_grads_norm = 4.5765
	new_data_grads_norm = 7.0243
	old_data_grads_norm = 6.5833
	sim_grads_norm_tr = 0.0182
-- Starting training on experience 233 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0953
	data_grads_norm = 4.6654
	new_data_grads_norm = 8.3111
	old_data_grads_norm = 4.6561
	sim_grads_norm_tr = 0.0330
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4921
	data_grads_norm = 5.5284
	new_data_grads_norm = 7.4116
	old_data_grads_norm = 7.9135
	sim_grads_norm_tr = -0.0389
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8081
	data_grads_norm = 5.6665
	new_data_grads_norm = 6.9916
	old_data_grads_norm = 8.2170
	sim_grads_norm_tr = 0.0367
-- Starting training on experience 234 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7739
	data_grads_norm = 5.7524
	new_data_grads_norm = 7.6758
	old_data_grads_norm = 6.6374
	sim_grads_norm_tr = 0.0402
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9856
	data_grads_norm = 6.2110
	new_data_grads_norm = 8.4302
	old_data_grads_norm = 7.7403
	sim_grads_norm_tr = -0.0307
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9745
	data_grads_norm = 5.6439
	new_data_grads_norm = 8.3117
	old_data_grads_norm = 5.9287
	sim_grads_norm_tr = 0.0647
-- Starting training on experience 235 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6021
	data_grads_norm = 5.0314
	new_data_grads_norm = 7.2895
	old_data_grads_norm = 6.8163
	sim_grads_norm_tr = 0.0077
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6154
	data_grads_norm = 5.7317
	new_data_grads_norm = 6.7332
	old_data_grads_norm = 8.5150
	sim_grads_norm_tr = 0.0873
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1582
	data_grads_norm = 4.9288
	new_data_grads_norm = 7.5842
	old_data_grads_norm = 5.7739
	sim_grads_norm_tr = -0.0004
-- Starting training on experience 236 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6773
	data_grads_norm = 3.4928
	new_data_grads_norm = 6.2901
	old_data_grads_norm = 4.9876
	sim_grads_norm_tr = -0.0074
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8426
	data_grads_norm = 4.1444
	new_data_grads_norm = 7.4145
	old_data_grads_norm = 6.9165
	sim_grads_norm_tr = -0.0052
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3771
	data_grads_norm = 4.8887
	new_data_grads_norm = 6.7520
	old_data_grads_norm = 6.4309
	sim_grads_norm_tr = 0.0027
-- Starting training on experience 237 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
-- >> End of training phase << --
-- >> Start of eval phase << --
-- Starting eval on experience 0 (Task 0) from test stream --
> Eval on experience 0 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp000 = 3.6103
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.2120
	mb_index = 3094
	time = 1044.6595
-- Starting eval on experience 1 (Task 0) from test stream --
> Eval on experience 1 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp001 = 2.6101
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.4400
-- Starting eval on experience 2 (Task 0) from test stream --
> Eval on experience 2 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp002 = 3.0990
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.3480
-- Starting eval on experience 3 (Task 0) from test stream --
> Eval on experience 3 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp003 = 2.2669
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.5260
-- Starting eval on experience 4 (Task 0) from test stream --
> Eval on experience 4 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp004 = 3.9352
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.2140
-- Starting eval on experience 5 (Task 0) from test stream --
> Eval on experience 5 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp005 = 3.1762
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.3640
-- Starting eval on experience 6 (Task 0) from test stream --
> Eval on experience 6 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp006 = 2.5476
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp006 = 0.3740
-- Starting eval on experience 7 (Task 0) from test stream --
> Eval on experience 7 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp007 = 2.9821
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp007 = 0.3520
-- Starting eval on experience 8 (Task 0) from test stream --
> Eval on experience 8 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp008 = 2.8021
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp008 = 0.3440
-- Starting eval on experience 9 (Task 0) from test stream --
> Eval on experience 9 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp009 = 2.4195
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp009 = 0.4080
-- Starting eval on experience 10 (Task 0) from test stream --
> Eval on experience 10 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp010 = 3.0783
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp010 = 0.2180
-- Starting eval on experience 11 (Task 0) from test stream --
> Eval on experience 11 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp011 = 2.3320
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp011 = 0.3800
-- Starting eval on experience 12 (Task 0) from test stream --
> Eval on experience 12 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp012 = 3.8616
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp012 = 0.0400
-- >> End of eval phase << --
	CumulativeAccuracy/eval_phase/test_stream/Exp000 = 0.7380
	CumulativeAccuracy/eval_phase/test_stream/Exp001 = 0.6980
	CumulativeAccuracy/eval_phase/test_stream/Exp002 = 0.5860
	CumulativeAccuracy/eval_phase/test_stream/Exp003 = 0.5645
	CumulativeAccuracy/eval_phase/test_stream/Exp004 = 0.5064
	CumulativeAccuracy/eval_phase/test_stream/Exp005 = 0.4760
	CumulativeAccuracy/eval_phase/test_stream/Exp006 = 0.4386
	CumulativeAccuracy/eval_phase/test_stream/Exp007 = 0.4170
	CumulativeAccuracy/eval_phase/test_stream/Exp008 = 0.4002
	CumulativeAccuracy/eval_phase/test_stream/Exp009 = 0.3856
	CumulativeAccuracy/eval_phase/test_stream/Exp010 = 0.3624
	CumulativeAccuracy/eval_phase/test_stream/Exp011 = 0.3505
	CumulativeAccuracy/eval_phase/test_stream/Exp012 = 0.3246
	Loss_Stream/eval_phase/test_stream/Task000 = 2.9785
	Top1_Acc_Stream/eval_phase/test_stream/Task000 = 0.3246
-- >> Start of training phase << --
-- Starting training on experience 0 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.7576
	data_grads_norm = 5.6840
	new_data_grads_norm = 8.1280
	old_data_grads_norm = 5.6902
	sim_grads_norm_tr = 0.0123
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.8042
	data_grads_norm = 5.6511
	new_data_grads_norm = 7.7311
	old_data_grads_norm = 5.8454
	sim_grads_norm_tr = -0.0024
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6699
	data_grads_norm = 5.3361
	new_data_grads_norm = 7.8607
	old_data_grads_norm = 5.7429
	sim_grads_norm_tr = 0.0187
-- Starting training on experience 1 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3563
	data_grads_norm = 5.5706
	new_data_grads_norm = 8.5386
	old_data_grads_norm = 6.9870
	sim_grads_norm_tr = 0.0203
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.8871
	data_grads_norm = 5.8689
	new_data_grads_norm = 8.1765
	old_data_grads_norm = 8.2614
	sim_grads_norm_tr = 0.0010
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6784
	data_grads_norm = 6.1327
	new_data_grads_norm = 7.9486
	old_data_grads_norm = 7.5799
	sim_grads_norm_tr = 0.0010
-- Starting training on experience 2 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.7756
	data_grads_norm = 5.9162
	new_data_grads_norm = 8.3354
	old_data_grads_norm = 7.4286
	sim_grads_norm_tr = 0.0111
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.8935
	data_grads_norm = 5.4864
	new_data_grads_norm = 7.4844
	old_data_grads_norm = 6.7063
	sim_grads_norm_tr = 0.0619
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5568
	data_grads_norm = 5.4642
	new_data_grads_norm = 7.7190
	old_data_grads_norm = 6.3831
	sim_grads_norm_tr = 0.0136
-- Starting training on experience 3 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3327
	data_grads_norm = 5.0759
	new_data_grads_norm = 7.5844
	old_data_grads_norm = 5.7601
	sim_grads_norm_tr = 0.0081
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.7260
	data_grads_norm = 5.7460
	new_data_grads_norm = 8.4960
	old_data_grads_norm = 6.9165
	sim_grads_norm_tr = 0.0181
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4629
	data_grads_norm = 5.2808
	new_data_grads_norm = 7.7012
	old_data_grads_norm = 5.4096
	sim_grads_norm_tr = 0.0066
-- Starting training on experience 4 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0407
	data_grads_norm = 4.6330
	new_data_grads_norm = 6.7669
	old_data_grads_norm = 5.8381
	sim_grads_norm_tr = 0.0424
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0577
	data_grads_norm = 4.7139
	new_data_grads_norm = 6.8941
	old_data_grads_norm = 7.5932
	sim_grads_norm_tr = -0.0147
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3310
	data_grads_norm = 5.8293
	new_data_grads_norm = 7.6141
	old_data_grads_norm = 7.4235
	sim_grads_norm_tr = 0.0051
-- Starting training on experience 5 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.4811
	data_grads_norm = 5.5214
	new_data_grads_norm = 7.0793
	old_data_grads_norm = 7.3403
	sim_grads_norm_tr = 0.0475
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6099
	data_grads_norm = 5.1948
	new_data_grads_norm = 7.5202
	old_data_grads_norm = 6.2732
	sim_grads_norm_tr = 0.0190
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9084
	data_grads_norm = 4.5646
	new_data_grads_norm = 6.8743
	old_data_grads_norm = 5.1269
	sim_grads_norm_tr = 0.0145
-- Starting training on experience 6 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7582
	data_grads_norm = 4.7004
	new_data_grads_norm = 7.3944
	old_data_grads_norm = 5.7142
	sim_grads_norm_tr = 0.0210
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0264
	data_grads_norm = 4.9341
	new_data_grads_norm = 7.5060
	old_data_grads_norm = 4.7053
	sim_grads_norm_tr = -0.0075
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2194
	data_grads_norm = 5.1356
	new_data_grads_norm = 7.6840
	old_data_grads_norm = 5.5475
	sim_grads_norm_tr = 0.0017
-- Starting training on experience 7 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8936
	data_grads_norm = 4.6606
	new_data_grads_norm = 7.3431
	old_data_grads_norm = 4.9703
	sim_grads_norm_tr = 0.0124
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9101
	data_grads_norm = 5.3429
	new_data_grads_norm = 7.8900
	old_data_grads_norm = 6.8316
	sim_grads_norm_tr = 0.0077
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1564
	data_grads_norm = 5.5418
	new_data_grads_norm = 7.1958
	old_data_grads_norm = 6.7323
	sim_grads_norm_tr = -0.0091
-- Starting training on experience 8 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5001
	data_grads_norm = 6.1703
	new_data_grads_norm = 8.2314
	old_data_grads_norm = 7.6182
	sim_grads_norm_tr = 0.0186
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5654
	data_grads_norm = 5.9159
	new_data_grads_norm = 8.3785
	old_data_grads_norm = 7.0786
	sim_grads_norm_tr = -0.0039
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.9565
	data_grads_norm = 5.9220
	new_data_grads_norm = 8.6616
	old_data_grads_norm = 7.1220
	sim_grads_norm_tr = 0.0106
-- Starting training on experience 9 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5145
	data_grads_norm = 6.2330
	new_data_grads_norm = 7.9466
	old_data_grads_norm = 8.3878
	sim_grads_norm_tr = 0.0453
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0741
	data_grads_norm = 6.1474
	new_data_grads_norm = 8.3970
	old_data_grads_norm = 6.8465
	sim_grads_norm_tr = 0.0010
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8550
	data_grads_norm = 4.7870
	new_data_grads_norm = 7.8207
	old_data_grads_norm = 5.0157
	sim_grads_norm_tr = 0.1330
-- Starting training on experience 10 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9651
	data_grads_norm = 5.8558
	new_data_grads_norm = 8.0813
	old_data_grads_norm = 7.0531
	sim_grads_norm_tr = 0.0185
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8466
	data_grads_norm = 4.4758
	new_data_grads_norm = 7.3911
	old_data_grads_norm = 6.0794
	sim_grads_norm_tr = 0.0413
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6163
	data_grads_norm = 4.7206
	new_data_grads_norm = 6.7183
	old_data_grads_norm = 5.8369
	sim_grads_norm_tr = -0.0042
-- Starting training on experience 11 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8734
	data_grads_norm = 4.9815
	new_data_grads_norm = 8.3229
	old_data_grads_norm = 6.3081
	sim_grads_norm_tr = -0.0609
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0678
	data_grads_norm = 5.1757
	new_data_grads_norm = 8.2593
	old_data_grads_norm = 6.3248
	sim_grads_norm_tr = 0.0299
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7170
	data_grads_norm = 4.5569
	new_data_grads_norm = 7.9000
	old_data_grads_norm = 3.2217
	sim_grads_norm_tr = 0.0027
-- Starting training on experience 12 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0835
	data_grads_norm = 4.9113
	new_data_grads_norm = 7.2187
	old_data_grads_norm = 5.4329
	sim_grads_norm_tr = 0.0195
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6568
	data_grads_norm = 5.7823
	new_data_grads_norm = 7.3527
	old_data_grads_norm = 8.3204
	sim_grads_norm_tr = 0.0321
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4154
	data_grads_norm = 5.6447
	new_data_grads_norm = 7.3377
	old_data_grads_norm = 8.1305
	sim_grads_norm_tr = -0.0077
-- Starting training on experience 13 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.8929
	data_grads_norm = 5.7526
	new_data_grads_norm = 7.0136
	old_data_grads_norm = 8.4534
	sim_grads_norm_tr = 0.0941
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1871
	data_grads_norm = 5.5355
	new_data_grads_norm = 7.5189
	old_data_grads_norm = 7.2494
	sim_grads_norm_tr = -0.0003
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0084
	data_grads_norm = 4.7335
	new_data_grads_norm = 6.0345
	old_data_grads_norm = 7.0629
	sim_grads_norm_tr = 0.0036
-- Starting training on experience 14 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1199
	data_grads_norm = 5.5166
	new_data_grads_norm = 7.4918
	old_data_grads_norm = 7.8401
	sim_grads_norm_tr = 0.0127
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8454
	data_grads_norm = 4.7412
	new_data_grads_norm = 7.3374
	old_data_grads_norm = 5.2932
	sim_grads_norm_tr = 0.0462
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3526
	data_grads_norm = 5.2998
	new_data_grads_norm = 8.1461
	old_data_grads_norm = 6.2704
	sim_grads_norm_tr = -0.0062
-- Starting training on experience 15 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6087
	data_grads_norm = 4.3509
	new_data_grads_norm = 5.7479
	old_data_grads_norm = 7.0416
	sim_grads_norm_tr = 0.0312
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6178
	data_grads_norm = 5.5462
	new_data_grads_norm = 6.6889
	old_data_grads_norm = 8.8210
	sim_grads_norm_tr = -0.0075
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3671
	data_grads_norm = 3.9267
	new_data_grads_norm = 6.4731
	old_data_grads_norm = 5.4569
	sim_grads_norm_tr = 0.0344
-- Starting training on experience 16 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4184
	data_grads_norm = 5.5557
	new_data_grads_norm = 7.8216
	old_data_grads_norm = 6.2475
	sim_grads_norm_tr = 0.1424
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8646
	data_grads_norm = 5.6043
	new_data_grads_norm = 8.1081
	old_data_grads_norm = 6.7658
	sim_grads_norm_tr = -0.0009
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2309
	data_grads_norm = 6.1189
	new_data_grads_norm = 7.6865
	old_data_grads_norm = 7.8258
	sim_grads_norm_tr = 0.0176
-- Starting training on experience 17 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0538
	data_grads_norm = 5.8432
	new_data_grads_norm = 7.5602
	old_data_grads_norm = 9.6974
	sim_grads_norm_tr = -0.0065
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6651
	data_grads_norm = 5.3986
	new_data_grads_norm = 7.6509
	old_data_grads_norm = 5.6644
	sim_grads_norm_tr = 0.0667
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9659
	data_grads_norm = 6.4032
	new_data_grads_norm = 7.5756
	old_data_grads_norm = 8.7299
	sim_grads_norm_tr = 0.0214
-- Starting training on experience 18 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1916
	data_grads_norm = 5.8297
	new_data_grads_norm = 8.1998
	old_data_grads_norm = 8.9813
	sim_grads_norm_tr = 0.0662
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2543
	data_grads_norm = 5.1028
	new_data_grads_norm = 6.7608
	old_data_grads_norm = 7.7152
	sim_grads_norm_tr = 0.0098
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8345
	data_grads_norm = 3.8732
	new_data_grads_norm = 6.6638
	old_data_grads_norm = 4.5233
	sim_grads_norm_tr = -0.0337
-- Starting training on experience 19 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1980
	data_grads_norm = 4.9223
	new_data_grads_norm = 7.9150
	old_data_grads_norm = 4.6252
	sim_grads_norm_tr = 0.0468
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3223
	data_grads_norm = 5.2494
	new_data_grads_norm = 7.1999
	old_data_grads_norm = 6.2399
	sim_grads_norm_tr = 0.0218
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6094
	data_grads_norm = 4.4586
	new_data_grads_norm = 7.8303
	old_data_grads_norm = 4.9391
	sim_grads_norm_tr = 0.0330
-- Starting training on experience 20 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5594
	data_grads_norm = 4.8540
	new_data_grads_norm = 7.4298
	old_data_grads_norm = 5.6467
	sim_grads_norm_tr = 0.0066
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9643
	data_grads_norm = 5.0092
	new_data_grads_norm = 7.5090
	old_data_grads_norm = 5.9063
	sim_grads_norm_tr = 0.1237
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8776
	data_grads_norm = 5.8417
	new_data_grads_norm = 7.9730
	old_data_grads_norm = 7.9151
	sim_grads_norm_tr = 0.0506
-- Starting training on experience 21 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8488
	data_grads_norm = 4.8490
	new_data_grads_norm = 6.9976
	old_data_grads_norm = 6.3859
	sim_grads_norm_tr = 0.0044
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4088
	data_grads_norm = 6.4032
	new_data_grads_norm = 7.6946
	old_data_grads_norm = 9.0489
	sim_grads_norm_tr = 0.0691
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6573
	data_grads_norm = 5.2232
	new_data_grads_norm = 8.1714
	old_data_grads_norm = 6.3071
	sim_grads_norm_tr = -0.0304
-- Starting training on experience 22 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9777
	data_grads_norm = 4.8246
	new_data_grads_norm = 6.9079
	old_data_grads_norm = 5.6823
	sim_grads_norm_tr = 0.0389
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2818
	data_grads_norm = 5.4390
	new_data_grads_norm = 6.4802
	old_data_grads_norm = 7.1091
	sim_grads_norm_tr = 0.0130
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4277
	data_grads_norm = 5.4193
	new_data_grads_norm = 7.2965
	old_data_grads_norm = 7.9410
	sim_grads_norm_tr = 0.0308
-- Starting training on experience 23 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3422
	data_grads_norm = 4.7506
	new_data_grads_norm = 7.2719
	old_data_grads_norm = 5.3680
	sim_grads_norm_tr = 0.0611
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1244
	data_grads_norm = 4.8177
	new_data_grads_norm = 7.4103
	old_data_grads_norm = 4.5826
	sim_grads_norm_tr = 0.0284
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9521
	data_grads_norm = 5.1011
	new_data_grads_norm = 7.1889
	old_data_grads_norm = 6.2469
	sim_grads_norm_tr = 0.0088
-- Starting training on experience 24 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9726
	data_grads_norm = 4.7554
	new_data_grads_norm = 7.2248
	old_data_grads_norm = 5.3387
	sim_grads_norm_tr = 0.0256
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4027
	data_grads_norm = 4.8543
	new_data_grads_norm = 6.9534
	old_data_grads_norm = 6.3057
	sim_grads_norm_tr = 0.0462
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6997
	data_grads_norm = 4.3659
	new_data_grads_norm = 7.4997
	old_data_grads_norm = 4.3558
	sim_grads_norm_tr = -0.0479
-- Starting training on experience 25 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0150
	data_grads_norm = 4.8407
	new_data_grads_norm = 6.5773
	old_data_grads_norm = 7.0306
	sim_grads_norm_tr = -0.0048
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1133
	data_grads_norm = 4.8976
	new_data_grads_norm = 7.7743
	old_data_grads_norm = 5.2746
	sim_grads_norm_tr = -0.0093
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9510
	data_grads_norm = 4.7895
	new_data_grads_norm = 6.8425
	old_data_grads_norm = 5.3188
	sim_grads_norm_tr = 0.0513
-- Starting training on experience 26 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8835
	data_grads_norm = 4.2546
	new_data_grads_norm = 6.3916
	old_data_grads_norm = 5.3002
	sim_grads_norm_tr = -0.0025
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9534
	data_grads_norm = 4.0037
	new_data_grads_norm = 6.4388
	old_data_grads_norm = 4.0655
	sim_grads_norm_tr = 0.0359
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3354
	data_grads_norm = 4.9851
	new_data_grads_norm = 6.9684
	old_data_grads_norm = 7.1605
	sim_grads_norm_tr = 0.0288
-- Starting training on experience 27 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1200
	data_grads_norm = 4.5043
	new_data_grads_norm = 6.3978
	old_data_grads_norm = 5.7718
	sim_grads_norm_tr = 0.0384
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9644
	data_grads_norm = 4.1557
	new_data_grads_norm = 6.2171
	old_data_grads_norm = 4.9232
	sim_grads_norm_tr = 0.0359
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5200
	data_grads_norm = 3.8434
	new_data_grads_norm = 6.1693
	old_data_grads_norm = 4.5583
	sim_grads_norm_tr = -0.0022
-- Starting training on experience 28 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9878
	data_grads_norm = 4.8343
	new_data_grads_norm = 7.2028
	old_data_grads_norm = 6.6584
	sim_grads_norm_tr = -0.0129
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8495
	data_grads_norm = 4.7858
	new_data_grads_norm = 6.0517
	old_data_grads_norm = 5.6759
	sim_grads_norm_tr = 0.0110
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0071
	data_grads_norm = 4.4703
	new_data_grads_norm = 7.7050
	old_data_grads_norm = 5.1025
	sim_grads_norm_tr = 0.0565
-- Starting training on experience 29 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0460
	data_grads_norm = 5.2020
	new_data_grads_norm = 7.2706
	old_data_grads_norm = 6.6371
	sim_grads_norm_tr = 0.0606
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8004
	data_grads_norm = 4.7741
	new_data_grads_norm = 6.7407
	old_data_grads_norm = 6.4680
	sim_grads_norm_tr = 0.0272
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2753
	data_grads_norm = 4.8490
	new_data_grads_norm = 6.7343
	old_data_grads_norm = 6.0241
	sim_grads_norm_tr = 0.0099
-- Starting training on experience 30 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2208
	data_grads_norm = 5.4463
	new_data_grads_norm = 7.8345
	old_data_grads_norm = 6.8062
	sim_grads_norm_tr = 0.0012
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0476
	data_grads_norm = 5.5848
	new_data_grads_norm = 7.1170
	old_data_grads_norm = 7.8883
	sim_grads_norm_tr = -0.0150
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5718
	data_grads_norm = 5.8888
	new_data_grads_norm = 7.6673
	old_data_grads_norm = 7.0691
	sim_grads_norm_tr = 0.0267
-- Starting training on experience 31 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8052
	data_grads_norm = 4.7874
	new_data_grads_norm = 5.6248
	old_data_grads_norm = 8.8310
	sim_grads_norm_tr = -0.0524
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8279
	data_grads_norm = 4.5151
	new_data_grads_norm = 5.5553
	old_data_grads_norm = 6.7139
	sim_grads_norm_tr = 0.0129
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3642
	data_grads_norm = 4.0696
	new_data_grads_norm = 6.0898
	old_data_grads_norm = 5.8690
	sim_grads_norm_tr = -0.0047
-- Starting training on experience 32 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9546
	data_grads_norm = 4.4780
	new_data_grads_norm = 7.7042
	old_data_grads_norm = 5.0627
	sim_grads_norm_tr = -0.0148
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1878
	data_grads_norm = 5.1487
	new_data_grads_norm = 7.1426
	old_data_grads_norm = 6.1576
	sim_grads_norm_tr = -0.0057
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1110
	data_grads_norm = 5.2574
	new_data_grads_norm = 7.5304
	old_data_grads_norm = 6.9618
	sim_grads_norm_tr = -0.0258
-- Starting training on experience 33 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5038
	data_grads_norm = 4.5198
	new_data_grads_norm = 5.9445
	old_data_grads_norm = 7.2619
	sim_grads_norm_tr = -0.0162
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6183
	data_grads_norm = 4.2963
	new_data_grads_norm = 6.0317
	old_data_grads_norm = 6.4299
	sim_grads_norm_tr = 0.0119
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4796
	data_grads_norm = 4.4369
	new_data_grads_norm = 6.0226
	old_data_grads_norm = 7.0048
	sim_grads_norm_tr = -0.0212
-- Starting training on experience 34 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9597
	data_grads_norm = 4.6259
	new_data_grads_norm = 7.0012
	old_data_grads_norm = 6.1690
	sim_grads_norm_tr = -0.0039
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0614
	data_grads_norm = 5.0674
	new_data_grads_norm = 7.1221
	old_data_grads_norm = 8.0653
	sim_grads_norm_tr = -0.0316
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6588
	data_grads_norm = 4.5943
	new_data_grads_norm = 6.8654
	old_data_grads_norm = 5.0395
	sim_grads_norm_tr = 0.0576
-- Starting training on experience 35 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4609
	data_grads_norm = 5.8404
	new_data_grads_norm = 7.5682
	old_data_grads_norm = 7.5302
	sim_grads_norm_tr = 0.0714
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0684
	data_grads_norm = 4.8293
	new_data_grads_norm = 7.5282
	old_data_grads_norm = 5.4656
	sim_grads_norm_tr = 0.0105
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3717
	data_grads_norm = 5.9838
	new_data_grads_norm = 7.7713
	old_data_grads_norm = 7.7596
	sim_grads_norm_tr = 0.0709
-- Starting training on experience 36 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4700
	data_grads_norm = 4.9501
	new_data_grads_norm = 7.3666
	old_data_grads_norm = 7.0607
	sim_grads_norm_tr = -0.0053
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7640
	data_grads_norm = 5.1508
	new_data_grads_norm = 7.4720
	old_data_grads_norm = 6.3591
	sim_grads_norm_tr = -0.0201
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0719
	data_grads_norm = 5.7136
	new_data_grads_norm = 7.3270
	old_data_grads_norm = 8.5110
	sim_grads_norm_tr = -0.0183
-- Starting training on experience 37 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4114
	data_grads_norm = 3.8867
	new_data_grads_norm = 6.0589
	old_data_grads_norm = 4.9273
	sim_grads_norm_tr = -0.0051
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6376
	data_grads_norm = 4.6259
	new_data_grads_norm = 6.3753
	old_data_grads_norm = 5.4663
	sim_grads_norm_tr = 0.0237
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7097
	data_grads_norm = 4.5395
	new_data_grads_norm = 6.4773
	old_data_grads_norm = 6.4809
	sim_grads_norm_tr = -0.0367
-- Starting training on experience 38 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6345
	data_grads_norm = 5.1366
	new_data_grads_norm = 6.6165
	old_data_grads_norm = 7.2867
	sim_grads_norm_tr = 0.0628
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1884
	data_grads_norm = 5.3637
	new_data_grads_norm = 6.2150
	old_data_grads_norm = 8.1834
	sim_grads_norm_tr = 0.0125
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6499
	data_grads_norm = 4.4753
	new_data_grads_norm = 6.0792
	old_data_grads_norm = 5.6894
	sim_grads_norm_tr = -0.0047
-- Starting training on experience 39 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9331
	data_grads_norm = 5.2072
	new_data_grads_norm = 7.2451
	old_data_grads_norm = 6.7476
	sim_grads_norm_tr = 0.0100
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1022
	data_grads_norm = 4.7625
	new_data_grads_norm = 6.8621
	old_data_grads_norm = 5.8524
	sim_grads_norm_tr = 0.0740
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0486
	data_grads_norm = 5.2827
	new_data_grads_norm = 6.7683
	old_data_grads_norm = 8.2692
	sim_grads_norm_tr = -0.0227
-- Starting training on experience 40 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1841
	data_grads_norm = 5.1378
	new_data_grads_norm = 8.2920
	old_data_grads_norm = 7.3058
	sim_grads_norm_tr = -0.0597
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1969
	data_grads_norm = 5.3837
	new_data_grads_norm = 7.7633
	old_data_grads_norm = 6.1905
	sim_grads_norm_tr = -0.0027
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3176
	data_grads_norm = 5.3121
	new_data_grads_norm = 8.0042
	old_data_grads_norm = 5.9433
	sim_grads_norm_tr = -0.0092
-- Starting training on experience 41 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3156
	data_grads_norm = 5.7791
	new_data_grads_norm = 9.0638
	old_data_grads_norm = 5.8844
	sim_grads_norm_tr = 0.0985
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8510
	data_grads_norm = 5.3431
	new_data_grads_norm = 8.3499
	old_data_grads_norm = 4.5323
	sim_grads_norm_tr = 0.0301
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0327
	data_grads_norm = 6.4086
	new_data_grads_norm = 8.8262
	old_data_grads_norm = 7.1916
	sim_grads_norm_tr = 0.0536
-- Starting training on experience 42 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0130
	data_grads_norm = 5.5372
	new_data_grads_norm = 7.4353
	old_data_grads_norm = 7.2732
	sim_grads_norm_tr = -0.0458
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0662
	data_grads_norm = 5.5463
	new_data_grads_norm = 8.0008
	old_data_grads_norm = 5.8560
	sim_grads_norm_tr = -0.0157
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0848
	data_grads_norm = 5.4844
	new_data_grads_norm = 7.1349
	old_data_grads_norm = 8.2153
	sim_grads_norm_tr = 0.0495
-- Starting training on experience 43 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4753
	data_grads_norm = 4.9792
	new_data_grads_norm = 7.3559
	old_data_grads_norm = 6.6379
	sim_grads_norm_tr = -0.0306
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8899
	data_grads_norm = 5.9134
	new_data_grads_norm = 7.7403
	old_data_grads_norm = 9.1586
	sim_grads_norm_tr = -0.0014
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1117
	data_grads_norm = 5.3610
	new_data_grads_norm = 7.3971
	old_data_grads_norm = 6.5264
	sim_grads_norm_tr = 0.0974
-- Starting training on experience 44 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9905
	data_grads_norm = 5.2303
	new_data_grads_norm = 6.8460
	old_data_grads_norm = 7.6668
	sim_grads_norm_tr = 0.0168
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6019
	data_grads_norm = 4.8260
	new_data_grads_norm = 6.2792
	old_data_grads_norm = 6.6326
	sim_grads_norm_tr = -0.0163
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6229
	data_grads_norm = 4.4450
	new_data_grads_norm = 7.3351
	old_data_grads_norm = 4.9929
	sim_grads_norm_tr = 0.0411
-- Starting training on experience 45 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6941
	data_grads_norm = 5.3221
	new_data_grads_norm = 7.1109
	old_data_grads_norm = 6.2100
	sim_grads_norm_tr = 0.0375
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7793
	data_grads_norm = 4.8918
	new_data_grads_norm = 7.5860
	old_data_grads_norm = 6.0133
	sim_grads_norm_tr = 0.0192
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8463
	data_grads_norm = 4.7793
	new_data_grads_norm = 7.0040
	old_data_grads_norm = 5.8859
	sim_grads_norm_tr = 0.0276
-- Starting training on experience 46 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7913
	data_grads_norm = 4.1918
	new_data_grads_norm = 6.7466
	old_data_grads_norm = 4.0488
	sim_grads_norm_tr = -0.0302
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6196
	data_grads_norm = 4.8670
	new_data_grads_norm = 7.3530
	old_data_grads_norm = 6.5382
	sim_grads_norm_tr = -0.0550
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4664
	data_grads_norm = 5.4888
	new_data_grads_norm = 7.8485
	old_data_grads_norm = 6.7646
	sim_grads_norm_tr = 0.0927
-- Starting training on experience 47 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5228
	data_grads_norm = 4.9992
	new_data_grads_norm = 8.9365
	old_data_grads_norm = 4.3687
	sim_grads_norm_tr = -0.0174
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2240
	data_grads_norm = 6.1795
	new_data_grads_norm = 8.4515
	old_data_grads_norm = 8.0075
	sim_grads_norm_tr = 0.0151
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7459
	data_grads_norm = 5.5587
	new_data_grads_norm = 9.6663
	old_data_grads_norm = 5.9534
	sim_grads_norm_tr = 0.0132
-- Starting training on experience 48 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0057
	data_grads_norm = 4.5646
	new_data_grads_norm = 6.8725
	old_data_grads_norm = 6.3797
	sim_grads_norm_tr = -0.0662
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3521
	data_grads_norm = 5.2388
	new_data_grads_norm = 6.6866
	old_data_grads_norm = 7.2497
	sim_grads_norm_tr = 0.1088
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9138
	data_grads_norm = 5.3314
	new_data_grads_norm = 5.4718
	old_data_grads_norm = 8.1750
	sim_grads_norm_tr = 0.0541
-- Starting training on experience 49 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9616
	data_grads_norm = 5.5414
	new_data_grads_norm = 7.7472
	old_data_grads_norm = 6.4638
	sim_grads_norm_tr = 0.0096
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7924
	data_grads_norm = 4.8866
	new_data_grads_norm = 7.5585
	old_data_grads_norm = 5.5159
	sim_grads_norm_tr = -0.0154
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3124
	data_grads_norm = 6.1225
	new_data_grads_norm = 8.3142
	old_data_grads_norm = 8.0602
	sim_grads_norm_tr = 0.0924
-- Starting training on experience 50 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7530
	data_grads_norm = 4.7047
	new_data_grads_norm = 7.5283
	old_data_grads_norm = 6.1425
	sim_grads_norm_tr = 0.0180
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5551
	data_grads_norm = 4.9003
	new_data_grads_norm = 7.5713
	old_data_grads_norm = 5.4680
	sim_grads_norm_tr = 0.0302
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7354
	data_grads_norm = 5.2031
	new_data_grads_norm = 7.0285
	old_data_grads_norm = 7.2541
	sim_grads_norm_tr = 0.0112
-- Starting training on experience 51 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8547
	data_grads_norm = 5.0044
	new_data_grads_norm = 7.5244
	old_data_grads_norm = 5.8167
	sim_grads_norm_tr = -0.0224
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8980
	data_grads_norm = 5.4413
	new_data_grads_norm = 7.6885
	old_data_grads_norm = 5.9850
	sim_grads_norm_tr = 0.0112
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2236
	data_grads_norm = 5.2968
	new_data_grads_norm = 7.3863
	old_data_grads_norm = 7.0027
	sim_grads_norm_tr = 0.0243
-- Starting training on experience 52 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9953
	data_grads_norm = 5.4128
	new_data_grads_norm = 7.7916
	old_data_grads_norm = 7.2682
	sim_grads_norm_tr = -0.0320
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2222
	data_grads_norm = 5.3002
	new_data_grads_norm = 7.6157
	old_data_grads_norm = 7.6302
	sim_grads_norm_tr = -0.0260
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7760
	data_grads_norm = 4.9079
	new_data_grads_norm = 7.8401
	old_data_grads_norm = 4.6505
	sim_grads_norm_tr = -0.0061
-- Starting training on experience 53 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8700
	data_grads_norm = 4.6465
	new_data_grads_norm = 7.5940
	old_data_grads_norm = 4.9495
	sim_grads_norm_tr = -0.0199
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2355
	data_grads_norm = 5.1466
	new_data_grads_norm = 7.0783
	old_data_grads_norm = 5.9875
	sim_grads_norm_tr = 0.0445
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9365
	data_grads_norm = 4.8578
	new_data_grads_norm = 6.4436
	old_data_grads_norm = 7.4163
	sim_grads_norm_tr = 0.0640
-- Starting training on experience 54 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5416
	data_grads_norm = 4.7919
	new_data_grads_norm = 6.8543
	old_data_grads_norm = 6.4278
	sim_grads_norm_tr = -0.0139
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6226
	data_grads_norm = 4.6725
	new_data_grads_norm = 6.7725
	old_data_grads_norm = 6.0906
	sim_grads_norm_tr = -0.0465
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4616
	data_grads_norm = 4.2089
	new_data_grads_norm = 6.8888
	old_data_grads_norm = 5.5583
	sim_grads_norm_tr = -0.0300
-- Starting training on experience 55 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6147
	data_grads_norm = 5.0064
	new_data_grads_norm = 6.3069
	old_data_grads_norm = 8.0079
	sim_grads_norm_tr = -0.0374
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7338
	data_grads_norm = 4.6674
	new_data_grads_norm = 6.7250
	old_data_grads_norm = 6.3458
	sim_grads_norm_tr = 0.0108
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6455
	data_grads_norm = 4.3789
	new_data_grads_norm = 6.3141
	old_data_grads_norm = 5.7106
	sim_grads_norm_tr = -0.0503
-- Starting training on experience 56 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6588
	data_grads_norm = 5.3325
	new_data_grads_norm = 7.8413
	old_data_grads_norm = 7.8273
	sim_grads_norm_tr = -0.0209
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9748
	data_grads_norm = 5.4747
	new_data_grads_norm = 7.6781
	old_data_grads_norm = 6.3735
	sim_grads_norm_tr = 0.0788
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2555
	data_grads_norm = 5.8632
	new_data_grads_norm = 6.9886
	old_data_grads_norm = 7.4369
	sim_grads_norm_tr = 0.0208
-- Starting training on experience 57 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2124
	data_grads_norm = 4.4411
	new_data_grads_norm = 7.2573
	old_data_grads_norm = 4.2600
	sim_grads_norm_tr = -0.0160
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2664
	data_grads_norm = 5.4445
	new_data_grads_norm = 6.9160
	old_data_grads_norm = 6.6760
	sim_grads_norm_tr = -0.0207
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3297
	data_grads_norm = 3.9144
	new_data_grads_norm = 6.2723
	old_data_grads_norm = 3.9751
	sim_grads_norm_tr = -0.0133
-- Starting training on experience 58 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1290
	data_grads_norm = 5.5840
	new_data_grads_norm = 8.5147
	old_data_grads_norm = 7.1538
	sim_grads_norm_tr = 0.0410
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2383
	data_grads_norm = 5.7523
	new_data_grads_norm = 7.6823
	old_data_grads_norm = 8.8496
	sim_grads_norm_tr = -0.0190
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1238
	data_grads_norm = 5.7383
	new_data_grads_norm = 7.9289
	old_data_grads_norm = 5.7512
	sim_grads_norm_tr = 0.1044
-- Starting training on experience 59 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6330
	data_grads_norm = 5.1988
	new_data_grads_norm = 7.5865
	old_data_grads_norm = 6.4422
	sim_grads_norm_tr = 0.0347
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2692
	data_grads_norm = 4.0777
	new_data_grads_norm = 6.9653
	old_data_grads_norm = 5.0198
	sim_grads_norm_tr = -0.0247
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2640
	data_grads_norm = 5.3593
	new_data_grads_norm = 7.2611
	old_data_grads_norm = 7.0360
	sim_grads_norm_tr = 0.0369
-- Starting training on experience 60 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5547
	data_grads_norm = 4.3693
	new_data_grads_norm = 8.4782
	old_data_grads_norm = 3.6698
	sim_grads_norm_tr = -0.0205
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2270
	data_grads_norm = 6.0408
	new_data_grads_norm = 7.8834
	old_data_grads_norm = 6.0890
	sim_grads_norm_tr = 0.0575
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4092
	data_grads_norm = 5.3191
	new_data_grads_norm = 7.7042
	old_data_grads_norm = 6.5742
	sim_grads_norm_tr = -0.0138
-- Starting training on experience 61 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8488
	data_grads_norm = 5.3771
	new_data_grads_norm = 7.4694
	old_data_grads_norm = 7.0640
	sim_grads_norm_tr = 0.0320
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5495
	data_grads_norm = 4.9768
	new_data_grads_norm = 6.8521
	old_data_grads_norm = 6.9261
	sim_grads_norm_tr = -0.0181
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3770
	data_grads_norm = 4.6822
	new_data_grads_norm = 7.0291
	old_data_grads_norm = 6.4710
	sim_grads_norm_tr = -0.0559
-- Starting training on experience 62 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3808
	data_grads_norm = 4.3215
	new_data_grads_norm = 6.0004
	old_data_grads_norm = 5.9622
	sim_grads_norm_tr = 0.0335
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3801
	data_grads_norm = 5.1435
	new_data_grads_norm = 6.2853
	old_data_grads_norm = 8.1278
	sim_grads_norm_tr = 0.0416
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7258
	data_grads_norm = 4.2181
	new_data_grads_norm = 6.3646
	old_data_grads_norm = 5.9175
	sim_grads_norm_tr = 0.0080
-- Starting training on experience 63 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2336
	data_grads_norm = 4.2095
	new_data_grads_norm = 6.8709
	old_data_grads_norm = 4.5428
	sim_grads_norm_tr = -0.0014
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9809
	data_grads_norm = 5.6711
	new_data_grads_norm = 8.2963
	old_data_grads_norm = 5.9152
	sim_grads_norm_tr = -0.0054
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6398
	data_grads_norm = 5.8412
	new_data_grads_norm = 7.2296
	old_data_grads_norm = 5.7945
	sim_grads_norm_tr = 0.0441
-- Starting training on experience 64 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8506
	data_grads_norm = 4.9755
	new_data_grads_norm = 6.4803
	old_data_grads_norm = 6.4255
	sim_grads_norm_tr = 0.0501
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3732
	data_grads_norm = 5.4226
	new_data_grads_norm = 6.2583
	old_data_grads_norm = 9.0812
	sim_grads_norm_tr = -0.0435
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3099
	data_grads_norm = 5.6153
	new_data_grads_norm = 7.7815
	old_data_grads_norm = 7.4064
	sim_grads_norm_tr = 0.0414
-- Starting training on experience 65 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9550
	data_grads_norm = 4.7370
	new_data_grads_norm = 7.3660
	old_data_grads_norm = 6.1307
	sim_grads_norm_tr = -0.0039
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7587
	data_grads_norm = 4.9546
	new_data_grads_norm = 7.5256
	old_data_grads_norm = 6.7349
	sim_grads_norm_tr = -0.0474
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1256
	data_grads_norm = 4.7943
	new_data_grads_norm = 8.3646
	old_data_grads_norm = 6.0466
	sim_grads_norm_tr = -0.0566
-- Starting training on experience 66 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8732
	data_grads_norm = 4.5127
	new_data_grads_norm = 6.6936
	old_data_grads_norm = 6.3498
	sim_grads_norm_tr = 0.0172
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7993
	data_grads_norm = 4.7849
	new_data_grads_norm = 7.4887
	old_data_grads_norm = 6.3757
	sim_grads_norm_tr = 0.0088
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6391
	data_grads_norm = 4.9095
	new_data_grads_norm = 5.6307
	old_data_grads_norm = 7.1909
	sim_grads_norm_tr = 0.0033
-- Starting training on experience 67 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0688
	data_grads_norm = 4.1200
	new_data_grads_norm = 6.3058
	old_data_grads_norm = 5.2118
	sim_grads_norm_tr = -0.0394
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7734
	data_grads_norm = 6.1092
	new_data_grads_norm = 7.7184
	old_data_grads_norm = 8.4771
	sim_grads_norm_tr = 0.0127
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2841
	data_grads_norm = 5.7266
	new_data_grads_norm = 6.9695
	old_data_grads_norm = 8.7718
	sim_grads_norm_tr = 0.0021
-- Starting training on experience 68 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8681
	data_grads_norm = 4.3341
	new_data_grads_norm = 6.5024
	old_data_grads_norm = 5.4895
	sim_grads_norm_tr = 0.1014
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9162
	data_grads_norm = 4.8383
	new_data_grads_norm = 6.6515
	old_data_grads_norm = 6.6206
	sim_grads_norm_tr = -0.0270
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6802
	data_grads_norm = 4.9269
	new_data_grads_norm = 6.3859
	old_data_grads_norm = 7.1100
	sim_grads_norm_tr = 0.0804
-- Starting training on experience 69 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4893
	data_grads_norm = 5.5969
	new_data_grads_norm = 9.0946
	old_data_grads_norm = 6.5287
	sim_grads_norm_tr = -0.0310
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2536
	data_grads_norm = 4.9554
	new_data_grads_norm = 8.2732
	old_data_grads_norm = 5.3233
	sim_grads_norm_tr = -0.0659
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7740
	data_grads_norm = 5.9680
	new_data_grads_norm = 8.7613
	old_data_grads_norm = 6.1139
	sim_grads_norm_tr = 0.0032
-- Starting training on experience 70 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0132
	data_grads_norm = 5.4846
	new_data_grads_norm = 7.5772
	old_data_grads_norm = 6.7566
	sim_grads_norm_tr = 0.0299
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9493
	data_grads_norm = 5.0905
	new_data_grads_norm = 7.4465
	old_data_grads_norm = 6.6657
	sim_grads_norm_tr = 0.0706
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6940
	data_grads_norm = 4.8988
	new_data_grads_norm = 7.1524
	old_data_grads_norm = 5.9256
	sim_grads_norm_tr = -0.0237
-- Starting training on experience 71 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7354
	data_grads_norm = 5.1190
	new_data_grads_norm = 7.7769
	old_data_grads_norm = 5.9600
	sim_grads_norm_tr = 0.0110
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5473
	data_grads_norm = 4.3350
	new_data_grads_norm = 7.6374
	old_data_grads_norm = 4.9847
	sim_grads_norm_tr = 0.0015
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3501
	data_grads_norm = 3.8637
	new_data_grads_norm = 6.8241
	old_data_grads_norm = 3.7592
	sim_grads_norm_tr = 0.0524
-- Starting training on experience 72 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8347
	data_grads_norm = 5.5296
	new_data_grads_norm = 7.3449
	old_data_grads_norm = 7.5518
	sim_grads_norm_tr = 0.0065
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6015
	data_grads_norm = 4.4684
	new_data_grads_norm = 7.0266
	old_data_grads_norm = 5.2989
	sim_grads_norm_tr = 0.0707
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2129
	data_grads_norm = 4.7326
	new_data_grads_norm = 6.8266
	old_data_grads_norm = 6.9957
	sim_grads_norm_tr = -0.0121
-- Starting training on experience 73 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1638
	data_grads_norm = 5.0556
	new_data_grads_norm = 7.6527
	old_data_grads_norm = 6.7714
	sim_grads_norm_tr = -0.0137
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9010
	data_grads_norm = 5.7888
	new_data_grads_norm = 8.2225
	old_data_grads_norm = 7.6345
	sim_grads_norm_tr = 0.0225
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1875
	data_grads_norm = 4.6297
	new_data_grads_norm = 7.7047
	old_data_grads_norm = 5.7775
	sim_grads_norm_tr = 0.0048
-- Starting training on experience 74 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9576
	data_grads_norm = 4.5573
	new_data_grads_norm = 6.5527
	old_data_grads_norm = 5.8564
	sim_grads_norm_tr = 0.0140
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9223
	data_grads_norm = 4.8085
	new_data_grads_norm = 7.5973
	old_data_grads_norm = 7.9773
	sim_grads_norm_tr = -0.0116
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9441
	data_grads_norm = 4.7021
	new_data_grads_norm = 6.9675
	old_data_grads_norm = 5.2276
	sim_grads_norm_tr = 0.1158
-- Starting training on experience 75 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9460
	data_grads_norm = 5.4915
	new_data_grads_norm = 6.7519
	old_data_grads_norm = 8.8465
	sim_grads_norm_tr = -0.0022
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8061
	data_grads_norm = 5.5813
	new_data_grads_norm = 7.4661
	old_data_grads_norm = 7.2918
	sim_grads_norm_tr = 0.0066
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5039
	data_grads_norm = 5.0012
	new_data_grads_norm = 7.5196
	old_data_grads_norm = 6.9018
	sim_grads_norm_tr = -0.0335
-- Starting training on experience 76 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8499
	data_grads_norm = 5.2799
	new_data_grads_norm = 7.1662
	old_data_grads_norm = 7.0530
	sim_grads_norm_tr = -0.0010
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2766
	data_grads_norm = 5.5068
	new_data_grads_norm = 8.1141
	old_data_grads_norm = 6.8184
	sim_grads_norm_tr = 0.0444
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7415
	data_grads_norm = 4.7668
	new_data_grads_norm = 6.9768
	old_data_grads_norm = 5.9928
	sim_grads_norm_tr = 0.0076
-- Starting training on experience 77 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4063
	data_grads_norm = 4.4379
	new_data_grads_norm = 6.4445
	old_data_grads_norm = 4.8900
	sim_grads_norm_tr = 0.0239
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1679
	data_grads_norm = 5.5341
	new_data_grads_norm = 7.0383
	old_data_grads_norm = 8.4546
	sim_grads_norm_tr = 0.0018
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7475
	data_grads_norm = 4.8191
	new_data_grads_norm = 7.4513
	old_data_grads_norm = 4.7549
	sim_grads_norm_tr = 0.0222
-- Starting training on experience 78 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7249
	data_grads_norm = 5.4333
	new_data_grads_norm = 7.0224
	old_data_grads_norm = 6.8291
	sim_grads_norm_tr = 0.0226
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0567
	data_grads_norm = 5.6340
	new_data_grads_norm = 7.1864
	old_data_grads_norm = 7.5323
	sim_grads_norm_tr = -0.0694
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9648
	data_grads_norm = 5.4344
	new_data_grads_norm = 7.7466
	old_data_grads_norm = 7.2798
	sim_grads_norm_tr = 0.0226
-- Starting training on experience 79 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6940
	data_grads_norm = 4.5972
	new_data_grads_norm = 6.6577
	old_data_grads_norm = 6.0465
	sim_grads_norm_tr = 0.0031
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9382
	data_grads_norm = 4.9365
	new_data_grads_norm = 6.3005
	old_data_grads_norm = 8.2346
	sim_grads_norm_tr = -0.0099
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8154
	data_grads_norm = 4.7925
	new_data_grads_norm = 6.2758
	old_data_grads_norm = 5.1865
	sim_grads_norm_tr = 0.0174
-- Starting training on experience 80 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0743
	data_grads_norm = 5.8279
	new_data_grads_norm = 8.4199
	old_data_grads_norm = 6.0576
	sim_grads_norm_tr = 0.0021
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6888
	data_grads_norm = 5.8366
	new_data_grads_norm = 8.5485
	old_data_grads_norm = 8.1157
	sim_grads_norm_tr = 0.0375
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7575
	data_grads_norm = 5.6698
	new_data_grads_norm = 8.0870
	old_data_grads_norm = 6.8234
	sim_grads_norm_tr = 0.0538
-- Starting training on experience 81 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0571
	data_grads_norm = 5.8215
	new_data_grads_norm = 8.4850
	old_data_grads_norm = 7.1075
	sim_grads_norm_tr = 0.0443
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6974
	data_grads_norm = 5.4385
	new_data_grads_norm = 6.7880
	old_data_grads_norm = 6.9386
	sim_grads_norm_tr = -0.0074
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3245
	data_grads_norm = 5.6167
	new_data_grads_norm = 8.4614
	old_data_grads_norm = 6.2128
	sim_grads_norm_tr = 0.0376
-- Starting training on experience 82 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9316
	data_grads_norm = 5.1743
	new_data_grads_norm = 7.0594
	old_data_grads_norm = 6.6636
	sim_grads_norm_tr = 0.0709
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9044
	data_grads_norm = 4.9256
	new_data_grads_norm = 7.5155
	old_data_grads_norm = 6.1868
	sim_grads_norm_tr = 0.0347
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8402
	data_grads_norm = 5.0506
	new_data_grads_norm = 7.1594
	old_data_grads_norm = 6.1910
	sim_grads_norm_tr = -0.0047
-- Starting training on experience 83 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9999
	data_grads_norm = 6.1158
	new_data_grads_norm = 7.9500
	old_data_grads_norm = 8.8572
	sim_grads_norm_tr = -0.0067
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8635
	data_grads_norm = 6.1406
	new_data_grads_norm = 7.8076
	old_data_grads_norm = 8.6990
	sim_grads_norm_tr = -0.0063
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3881
	data_grads_norm = 6.0348
	new_data_grads_norm = 7.3252
	old_data_grads_norm = 7.1547
	sim_grads_norm_tr = 0.2209
-- Starting training on experience 84 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6585
	data_grads_norm = 4.7841
	new_data_grads_norm = 7.9567
	old_data_grads_norm = 4.5755
	sim_grads_norm_tr = 0.0634
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6795
	data_grads_norm = 5.7809
	new_data_grads_norm = 8.4475
	old_data_grads_norm = 7.3192
	sim_grads_norm_tr = -0.0517
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3536
	data_grads_norm = 5.1220
	new_data_grads_norm = 8.1085
	old_data_grads_norm = 5.7398
	sim_grads_norm_tr = -0.0191
-- Starting training on experience 85 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1515
	data_grads_norm = 5.2272
	new_data_grads_norm = 7.8492
	old_data_grads_norm = 6.8733
	sim_grads_norm_tr = -0.0132
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3316
	data_grads_norm = 5.6487
	new_data_grads_norm = 7.9791
	old_data_grads_norm = 6.6027
	sim_grads_norm_tr = 0.1095
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5939
	data_grads_norm = 5.1319
	new_data_grads_norm = 8.2239
	old_data_grads_norm = 6.0260
	sim_grads_norm_tr = -0.0205
-- Starting training on experience 86 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6672
	data_grads_norm = 4.9469
	new_data_grads_norm = 7.4853
	old_data_grads_norm = 6.6109
	sim_grads_norm_tr = -0.0133
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9565
	data_grads_norm = 5.3390
	new_data_grads_norm = 7.8878
	old_data_grads_norm = 7.0897
	sim_grads_norm_tr = 0.0906
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4784
	data_grads_norm = 4.3390
	new_data_grads_norm = 8.1683
	old_data_grads_norm = 5.0116
	sim_grads_norm_tr = 0.0043
-- Starting training on experience 87 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6343
	data_grads_norm = 4.4212
	new_data_grads_norm = 7.4574
	old_data_grads_norm = 5.1326
	sim_grads_norm_tr = 0.0479
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5848
	data_grads_norm = 4.3711
	new_data_grads_norm = 7.2975
	old_data_grads_norm = 4.8191
	sim_grads_norm_tr = -0.0305
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2086
	data_grads_norm = 4.1738
	new_data_grads_norm = 7.4463
	old_data_grads_norm = 4.3737
	sim_grads_norm_tr = -0.0383
-- Starting training on experience 88 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5153
	data_grads_norm = 5.3031
	new_data_grads_norm = 7.8064
	old_data_grads_norm = 6.9085
	sim_grads_norm_tr = -0.0299
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5820
	data_grads_norm = 4.8593
	new_data_grads_norm = 6.6831
	old_data_grads_norm = 7.2830
	sim_grads_norm_tr = -0.0271
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5990
	data_grads_norm = 5.1227
	new_data_grads_norm = 7.1379
	old_data_grads_norm = 6.4683
	sim_grads_norm_tr = 0.0298
-- Starting training on experience 89 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5121
	data_grads_norm = 5.3501
	new_data_grads_norm = 8.8476
	old_data_grads_norm = 6.1169
	sim_grads_norm_tr = -0.0593
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1247
	data_grads_norm = 5.6322
	new_data_grads_norm = 8.6256
	old_data_grads_norm = 6.5508
	sim_grads_norm_tr = -0.0544
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6539
	data_grads_norm = 5.7366
	new_data_grads_norm = 8.6046
	old_data_grads_norm = 6.1389
	sim_grads_norm_tr = -0.0158
-- Starting training on experience 90 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8096
	data_grads_norm = 5.6358
	new_data_grads_norm = 6.9863
	old_data_grads_norm = 7.1183
	sim_grads_norm_tr = 0.0286
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4192
	data_grads_norm = 4.6193
	new_data_grads_norm = 7.1980
	old_data_grads_norm = 6.4540
	sim_grads_norm_tr = -0.0315
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4950
	data_grads_norm = 4.3911
	new_data_grads_norm = 7.8926
	old_data_grads_norm = 3.9221
	sim_grads_norm_tr = 0.0709
-- Starting training on experience 91 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4438
	data_grads_norm = 4.4705
	new_data_grads_norm = 7.8076
	old_data_grads_norm = 4.3936
	sim_grads_norm_tr = -0.0550
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4850
	data_grads_norm = 4.7296
	new_data_grads_norm = 7.2557
	old_data_grads_norm = 5.8692
	sim_grads_norm_tr = -0.0105
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5582
	data_grads_norm = 5.5508
	new_data_grads_norm = 8.0725
	old_data_grads_norm = 6.3266
	sim_grads_norm_tr = -0.0246
-- Starting training on experience 92 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5659
	data_grads_norm = 5.3978
	new_data_grads_norm = 8.1167
	old_data_grads_norm = 7.7544
	sim_grads_norm_tr = -0.0507
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0412
	data_grads_norm = 5.4472
	new_data_grads_norm = 8.6583
	old_data_grads_norm = 6.6908
	sim_grads_norm_tr = 0.0247
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4423
	data_grads_norm = 4.7705
	new_data_grads_norm = 7.7512
	old_data_grads_norm = 5.5087
	sim_grads_norm_tr = -0.0240
-- Starting training on experience 93 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6059
	data_grads_norm = 4.8884
	new_data_grads_norm = 6.8482
	old_data_grads_norm = 6.3073
	sim_grads_norm_tr = 0.0826
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0406
	data_grads_norm = 5.4941
	new_data_grads_norm = 6.4038
	old_data_grads_norm = 8.0610
	sim_grads_norm_tr = 0.0228
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4077
	data_grads_norm = 4.0275
	new_data_grads_norm = 5.8784
	old_data_grads_norm = 5.5663
	sim_grads_norm_tr = -0.0317
-- Starting training on experience 94 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1684
	data_grads_norm = 3.9903
	new_data_grads_norm = 6.1356
	old_data_grads_norm = 5.8399
	sim_grads_norm_tr = 0.0074
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0275
	data_grads_norm = 4.7547
	new_data_grads_norm = 5.9996
	old_data_grads_norm = 6.5201
	sim_grads_norm_tr = 0.0053
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2039
	data_grads_norm = 4.5380
	new_data_grads_norm = 6.3696
	old_data_grads_norm = 7.2230
	sim_grads_norm_tr = -0.0114
-- Starting training on experience 95 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5975
	data_grads_norm = 5.1677
	new_data_grads_norm = 7.4577
	old_data_grads_norm = 6.5767
	sim_grads_norm_tr = -0.0288
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4560
	data_grads_norm = 5.1122
	new_data_grads_norm = 6.9185
	old_data_grads_norm = 6.0296
	sim_grads_norm_tr = -0.0290
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8661
	data_grads_norm = 6.1314
	new_data_grads_norm = 8.2396
	old_data_grads_norm = 8.4796
	sim_grads_norm_tr = 0.0879
-- Starting training on experience 96 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7178
	data_grads_norm = 5.4235
	new_data_grads_norm = 6.3315
	old_data_grads_norm = 9.5372
	sim_grads_norm_tr = -0.0066
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5045
	data_grads_norm = 4.5643
	new_data_grads_norm = 6.5458
	old_data_grads_norm = 6.6425
	sim_grads_norm_tr = 0.0947
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4934
	data_grads_norm = 4.7375
	new_data_grads_norm = 6.6043
	old_data_grads_norm = 5.9287
	sim_grads_norm_tr = 0.0596
-- Starting training on experience 97 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4177
	data_grads_norm = 4.4593
	new_data_grads_norm = 7.2445
	old_data_grads_norm = 5.5254
	sim_grads_norm_tr = -0.0460
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4188
	data_grads_norm = 4.9581
	new_data_grads_norm = 7.0969
	old_data_grads_norm = 7.5360
	sim_grads_norm_tr = -0.0207
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5428
	data_grads_norm = 4.6727
	new_data_grads_norm = 7.5025
	old_data_grads_norm = 5.5976
	sim_grads_norm_tr = -0.0187
-- Starting training on experience 98 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9125
	data_grads_norm = 3.6074
	new_data_grads_norm = 6.4213
	old_data_grads_norm = 3.4807
	sim_grads_norm_tr = -0.0368
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1580
	data_grads_norm = 4.5839
	new_data_grads_norm = 6.2792
	old_data_grads_norm = 6.3082
	sim_grads_norm_tr = -0.0120
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3594
	data_grads_norm = 4.5381
	new_data_grads_norm = 6.7261
	old_data_grads_norm = 6.9258
	sim_grads_norm_tr = 0.0028
-- Starting training on experience 99 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4488
	data_grads_norm = 4.9443
	new_data_grads_norm = 5.9785
	old_data_grads_norm = 7.9742
	sim_grads_norm_tr = -0.0094
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3216
	data_grads_norm = 4.7072
	new_data_grads_norm = 6.4510
	old_data_grads_norm = 6.5265
	sim_grads_norm_tr = -0.0104
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5717
	data_grads_norm = 5.0876
	new_data_grads_norm = 6.2568
	old_data_grads_norm = 6.4740
	sim_grads_norm_tr = 0.0584
-- Starting training on experience 100 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6948
	data_grads_norm = 4.9511
	new_data_grads_norm = 6.3418
	old_data_grads_norm = 6.5915
	sim_grads_norm_tr = -0.0378
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6237
	data_grads_norm = 5.0053
	new_data_grads_norm = 6.8134
	old_data_grads_norm = 5.9250
	sim_grads_norm_tr = 0.0783
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3253
	data_grads_norm = 4.6517
	new_data_grads_norm = 6.2212
	old_data_grads_norm = 7.5091
	sim_grads_norm_tr = 0.0091
-- Starting training on experience 101 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0853
	data_grads_norm = 4.6064
	new_data_grads_norm = 7.1922
	old_data_grads_norm = 5.3703
	sim_grads_norm_tr = 0.0560
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3946
	data_grads_norm = 5.1863
	new_data_grads_norm = 6.7314
	old_data_grads_norm = 6.8683
	sim_grads_norm_tr = -0.0455
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0033
	data_grads_norm = 4.3330
	new_data_grads_norm = 6.8626
	old_data_grads_norm = 4.7333
	sim_grads_norm_tr = -0.0278
-- Starting training on experience 102 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5047
	data_grads_norm = 5.3031
	new_data_grads_norm = 6.5787
	old_data_grads_norm = 7.2786
	sim_grads_norm_tr = -0.0037
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4444
	data_grads_norm = 4.8037
	new_data_grads_norm = 7.3549
	old_data_grads_norm = 6.3151
	sim_grads_norm_tr = -0.0339
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5397
	data_grads_norm = 5.1710
	new_data_grads_norm = 7.1192
	old_data_grads_norm = 6.8169
	sim_grads_norm_tr = -0.0067
-- Starting training on experience 103 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5419
	data_grads_norm = 5.0712
	new_data_grads_norm = 7.2318
	old_data_grads_norm = 7.3898
	sim_grads_norm_tr = -0.0384
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5728
	data_grads_norm = 4.6518
	new_data_grads_norm = 6.4425
	old_data_grads_norm = 5.7017
	sim_grads_norm_tr = 0.0497
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3571
	data_grads_norm = 4.9123
	new_data_grads_norm = 6.5288
	old_data_grads_norm = 6.7200
	sim_grads_norm_tr = 0.0182
-- Starting training on experience 104 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5678
	data_grads_norm = 5.1176
	new_data_grads_norm = 6.1312
	old_data_grads_norm = 7.6620
	sim_grads_norm_tr = 0.0017
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5297
	data_grads_norm = 5.1506
	new_data_grads_norm = 6.0115
	old_data_grads_norm = 7.6144
	sim_grads_norm_tr = -0.0581
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0671
	data_grads_norm = 4.3355
	new_data_grads_norm = 7.2610
	old_data_grads_norm = 5.0815
	sim_grads_norm_tr = -0.0153
-- Starting training on experience 105 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4995
	data_grads_norm = 4.8549
	new_data_grads_norm = 6.0947
	old_data_grads_norm = 7.5035
	sim_grads_norm_tr = 0.0051
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5148
	data_grads_norm = 5.0601
	new_data_grads_norm = 6.7179
	old_data_grads_norm = 5.8495
	sim_grads_norm_tr = 0.0123
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2075
	data_grads_norm = 4.3780
	new_data_grads_norm = 6.2400
	old_data_grads_norm = 6.5523
	sim_grads_norm_tr = -0.0222
-- Starting training on experience 106 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1854
	data_grads_norm = 5.1988
	new_data_grads_norm = 8.3909
	old_data_grads_norm = 8.8907
	sim_grads_norm_tr = -0.0276
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6394
	data_grads_norm = 5.1228
	new_data_grads_norm = 8.8834
	old_data_grads_norm = 5.8723
	sim_grads_norm_tr = -0.0555
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5591
	data_grads_norm = 5.5766
	new_data_grads_norm = 8.7028
	old_data_grads_norm = 6.6129
	sim_grads_norm_tr = -0.0298
-- Starting training on experience 107 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5572
	data_grads_norm = 5.0036
	new_data_grads_norm = 7.3962
	old_data_grads_norm = 8.1122
	sim_grads_norm_tr = 0.0260
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4021
	data_grads_norm = 6.5462
	new_data_grads_norm = 9.2224
	old_data_grads_norm = 8.1687
	sim_grads_norm_tr = 0.0081
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0459
	data_grads_norm = 6.0243
	new_data_grads_norm = 8.1803
	old_data_grads_norm = 8.6521
	sim_grads_norm_tr = 0.0371
-- Starting training on experience 108 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2370
	data_grads_norm = 4.7710
	new_data_grads_norm = 7.1433
	old_data_grads_norm = 6.3878
	sim_grads_norm_tr = -0.0104
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1399
	data_grads_norm = 6.3971
	new_data_grads_norm = 7.9167
	old_data_grads_norm = 9.4156
	sim_grads_norm_tr = 0.0501
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5250
	data_grads_norm = 4.8115
	new_data_grads_norm = 7.1699
	old_data_grads_norm = 5.5563
	sim_grads_norm_tr = 0.1146
-- Starting training on experience 109 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0593
	data_grads_norm = 4.0647
	new_data_grads_norm = 6.8779
	old_data_grads_norm = 5.6866
	sim_grads_norm_tr = 0.0399
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6290
	data_grads_norm = 5.0792
	new_data_grads_norm = 7.0647
	old_data_grads_norm = 7.4638
	sim_grads_norm_tr = 0.0371
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5011
	data_grads_norm = 4.6499
	new_data_grads_norm = 6.7658
	old_data_grads_norm = 7.1654
	sim_grads_norm_tr = 0.0609
-- Starting training on experience 110 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3882
	data_grads_norm = 5.4271
	new_data_grads_norm = 6.9138
	old_data_grads_norm = 9.2447
	sim_grads_norm_tr = 0.0053
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7976
	data_grads_norm = 5.9797
	new_data_grads_norm = 6.4857
	old_data_grads_norm = 7.6866
	sim_grads_norm_tr = 0.0764
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2732
	data_grads_norm = 4.7469
	new_data_grads_norm = 6.2887
	old_data_grads_norm = 6.6083
	sim_grads_norm_tr = 0.0045
-- Starting training on experience 111 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2945
	data_grads_norm = 5.5003
	new_data_grads_norm = 8.5744
	old_data_grads_norm = 8.3296
	sim_grads_norm_tr = -0.0308
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6673
	data_grads_norm = 5.4861
	new_data_grads_norm = 7.3127
	old_data_grads_norm = 7.3761
	sim_grads_norm_tr = -0.0071
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2188
	data_grads_norm = 4.9424
	new_data_grads_norm = 8.1618
	old_data_grads_norm = 5.1441
	sim_grads_norm_tr = -0.0260
-- Starting training on experience 112 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4102
	data_grads_norm = 5.4057
	new_data_grads_norm = 8.2934
	old_data_grads_norm = 6.5966
	sim_grads_norm_tr = -0.0132
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3843
	data_grads_norm = 5.4558
	new_data_grads_norm = 8.3155
	old_data_grads_norm = 6.8464
	sim_grads_norm_tr = -0.0233
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4800
	data_grads_norm = 5.2855
	new_data_grads_norm = 8.4664
	old_data_grads_norm = 5.9649
	sim_grads_norm_tr = -0.0117
-- Starting training on experience 113 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2222
	data_grads_norm = 5.1030
	new_data_grads_norm = 7.1402
	old_data_grads_norm = 7.7391
	sim_grads_norm_tr = 0.0419
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4887
	data_grads_norm = 5.3548
	new_data_grads_norm = 8.7002
	old_data_grads_norm = 6.9500
	sim_grads_norm_tr = -0.0263
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9003
	data_grads_norm = 6.3425
	new_data_grads_norm = 8.9947
	old_data_grads_norm = 8.3287
	sim_grads_norm_tr = -0.0080
-- Starting training on experience 114 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1440
	data_grads_norm = 4.6959
	new_data_grads_norm = 7.2775
	old_data_grads_norm = 4.3299
	sim_grads_norm_tr = 0.0120
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2745
	data_grads_norm = 5.1801
	new_data_grads_norm = 7.9955
	old_data_grads_norm = 6.3126
	sim_grads_norm_tr = -0.0243
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2704
	data_grads_norm = 4.7115
	new_data_grads_norm = 8.5562
	old_data_grads_norm = 5.8632
	sim_grads_norm_tr = -0.0070
-- Starting training on experience 115 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7025
	data_grads_norm = 5.3855
	new_data_grads_norm = 7.1651
	old_data_grads_norm = 8.0559
	sim_grads_norm_tr = 0.0432
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4556
	data_grads_norm = 4.5783
	new_data_grads_norm = 6.5687
	old_data_grads_norm = 6.5905
	sim_grads_norm_tr = -0.0153
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5164
	data_grads_norm = 4.8964
	new_data_grads_norm = 7.1239
	old_data_grads_norm = 6.9552
	sim_grads_norm_tr = 0.0410
-- Starting training on experience 116 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4722
	data_grads_norm = 4.9711
	new_data_grads_norm = 7.6348
	old_data_grads_norm = 5.4453
	sim_grads_norm_tr = 0.1288
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1373
	data_grads_norm = 4.3352
	new_data_grads_norm = 6.5178
	old_data_grads_norm = 6.0368
	sim_grads_norm_tr = -0.0105
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4377
	data_grads_norm = 5.7068
	new_data_grads_norm = 6.8252
	old_data_grads_norm = 8.8763
	sim_grads_norm_tr = -0.0097
-- Starting training on experience 117 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7074
	data_grads_norm = 5.6106
	new_data_grads_norm = 8.1561
	old_data_grads_norm = 7.0809
	sim_grads_norm_tr = -0.0235
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3625
	data_grads_norm = 5.2020
	new_data_grads_norm = 8.3370
	old_data_grads_norm = 5.2799
	sim_grads_norm_tr = 0.0452
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2368
	data_grads_norm = 4.4964
	new_data_grads_norm = 7.8503
	old_data_grads_norm = 4.4869
	sim_grads_norm_tr = -0.0316
-- Starting training on experience 118 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5771
	data_grads_norm = 5.2408
	new_data_grads_norm = 7.5883
	old_data_grads_norm = 6.3860
	sim_grads_norm_tr = 0.0282
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5673
	data_grads_norm = 6.1820
	new_data_grads_norm = 8.0332
	old_data_grads_norm = 9.3133
	sim_grads_norm_tr = 0.0868
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9315
	data_grads_norm = 4.4955
	new_data_grads_norm = 7.2259
	old_data_grads_norm = 5.6510
	sim_grads_norm_tr = -0.0272
-- Starting training on experience 119 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5993
	data_grads_norm = 5.2209
	new_data_grads_norm = 7.6144
	old_data_grads_norm = 6.7529
	sim_grads_norm_tr = -0.0288
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6186
	data_grads_norm = 5.5690
	new_data_grads_norm = 7.4145
	old_data_grads_norm = 7.8172
	sim_grads_norm_tr = 0.0371
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0751
	data_grads_norm = 5.4664
	new_data_grads_norm = 7.2056
	old_data_grads_norm = 8.2472
	sim_grads_norm_tr = 0.0360
-- Starting training on experience 120 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7817
	data_grads_norm = 4.4315
	new_data_grads_norm = 6.8950
	old_data_grads_norm = 6.4983
	sim_grads_norm_tr = -0.0077
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1907
	data_grads_norm = 4.6397
	new_data_grads_norm = 6.9495
	old_data_grads_norm = 5.4227
	sim_grads_norm_tr = 0.0340
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2548
	data_grads_norm = 4.8083
	new_data_grads_norm = 6.8913
	old_data_grads_norm = 6.2270
	sim_grads_norm_tr = -0.0054
-- Starting training on experience 121 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1323
	data_grads_norm = 4.8401
	new_data_grads_norm = 6.1220
	old_data_grads_norm = 6.8271
	sim_grads_norm_tr = -0.0085
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2053
	data_grads_norm = 4.1640
	new_data_grads_norm = 6.6078
	old_data_grads_norm = 5.0915
	sim_grads_norm_tr = 0.0153
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7121
	data_grads_norm = 5.2289
	new_data_grads_norm = 6.4240
	old_data_grads_norm = 6.6250
	sim_grads_norm_tr = 0.0615
-- Starting training on experience 122 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2702
	data_grads_norm = 5.0802
	new_data_grads_norm = 8.0206
	old_data_grads_norm = 6.2350
	sim_grads_norm_tr = 0.0062
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5014
	data_grads_norm = 4.6986
	new_data_grads_norm = 6.7427
	old_data_grads_norm = 6.8066
	sim_grads_norm_tr = 0.0711
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5082
	data_grads_norm = 5.1325
	new_data_grads_norm = 7.6041
	old_data_grads_norm = 7.0931
	sim_grads_norm_tr = -0.0267
-- Starting training on experience 123 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5612
	data_grads_norm = 5.3195
	new_data_grads_norm = 7.0953
	old_data_grads_norm = 7.8351
	sim_grads_norm_tr = 0.0710
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1404
	data_grads_norm = 4.4943
	new_data_grads_norm = 6.7380
	old_data_grads_norm = 6.5882
	sim_grads_norm_tr = 0.0522
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9509
	data_grads_norm = 4.7633
	new_data_grads_norm = 7.5843
	old_data_grads_norm = 6.7906
	sim_grads_norm_tr = -0.0839
-- Starting training on experience 124 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3245
	data_grads_norm = 5.4902
	new_data_grads_norm = 7.1829
	old_data_grads_norm = 9.4043
	sim_grads_norm_tr = -0.0103
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5469
	data_grads_norm = 5.6074
	new_data_grads_norm = 8.3464
	old_data_grads_norm = 7.5978
	sim_grads_norm_tr = 0.0241
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0808
	data_grads_norm = 5.0160
	new_data_grads_norm = 7.4642
	old_data_grads_norm = 5.7996
	sim_grads_norm_tr = -0.0090
-- Starting training on experience 125 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6208
	data_grads_norm = 5.3311
	new_data_grads_norm = 7.2730
	old_data_grads_norm = 8.2882
	sim_grads_norm_tr = -0.0241
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6868
	data_grads_norm = 5.3633
	new_data_grads_norm = 6.9993
	old_data_grads_norm = 6.2986
	sim_grads_norm_tr = 0.0673
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4240
	data_grads_norm = 4.9885
	new_data_grads_norm = 6.9930
	old_data_grads_norm = 6.5096
	sim_grads_norm_tr = 0.0183
-- Starting training on experience 126 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5211
	data_grads_norm = 4.7643
	new_data_grads_norm = 7.0405
	old_data_grads_norm = 7.1343
	sim_grads_norm_tr = -0.0526
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5056
	data_grads_norm = 4.8350
	new_data_grads_norm = 7.5116
	old_data_grads_norm = 5.5035
	sim_grads_norm_tr = -0.0095
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1821
	data_grads_norm = 4.9452
	new_data_grads_norm = 7.7029
	old_data_grads_norm = 5.1272
	sim_grads_norm_tr = 0.0123
-- Starting training on experience 127 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8322
	data_grads_norm = 5.4975
	new_data_grads_norm = 7.3154
	old_data_grads_norm = 7.1028
	sim_grads_norm_tr = 0.0289
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3417
	data_grads_norm = 5.2015
	new_data_grads_norm = 7.5824
	old_data_grads_norm = 7.8715
	sim_grads_norm_tr = 0.0144
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5649
	data_grads_norm = 5.1988
	new_data_grads_norm = 6.8905
	old_data_grads_norm = 7.4832
	sim_grads_norm_tr = 0.0076
-- Starting training on experience 128 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7563
	data_grads_norm = 5.3822
	new_data_grads_norm = 8.1157
	old_data_grads_norm = 6.3079
	sim_grads_norm_tr = 0.0236
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4673
	data_grads_norm = 4.8543
	new_data_grads_norm = 7.6463
	old_data_grads_norm = 5.3842
	sim_grads_norm_tr = 0.0152
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7088
	data_grads_norm = 4.6796
	new_data_grads_norm = 7.5188
	old_data_grads_norm = 5.1697
	sim_grads_norm_tr = 0.0962
-- Starting training on experience 129 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4525
	data_grads_norm = 4.8208
	new_data_grads_norm = 5.9934
	old_data_grads_norm = 8.0613
	sim_grads_norm_tr = -0.0115
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6681
	data_grads_norm = 5.0612
	new_data_grads_norm = 6.0542
	old_data_grads_norm = 8.2247
	sim_grads_norm_tr = 0.0030
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9439
	data_grads_norm = 5.3005
	new_data_grads_norm = 6.5490
	old_data_grads_norm = 7.3057
	sim_grads_norm_tr = 0.0219
-- Starting training on experience 130 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4858
	data_grads_norm = 5.2630
	new_data_grads_norm = 6.7342
	old_data_grads_norm = 7.5671
	sim_grads_norm_tr = 0.0107
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3988
	data_grads_norm = 4.9192
	new_data_grads_norm = 6.7060
	old_data_grads_norm = 7.8920
	sim_grads_norm_tr = 0.0074
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3137
	data_grads_norm = 4.6148
	new_data_grads_norm = 6.6574
	old_data_grads_norm = 6.8539
	sim_grads_norm_tr = 0.0091
-- Starting training on experience 131 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6040
	data_grads_norm = 5.1895
	new_data_grads_norm = 7.7850
	old_data_grads_norm = 7.3984
	sim_grads_norm_tr = -0.0298
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5977
	data_grads_norm = 5.7281
	new_data_grads_norm = 8.0901
	old_data_grads_norm = 8.0441
	sim_grads_norm_tr = -0.0200
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1909
	data_grads_norm = 5.3421
	new_data_grads_norm = 8.0688
	old_data_grads_norm = 7.8350
	sim_grads_norm_tr = 0.0098
-- Starting training on experience 132 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4575
	data_grads_norm = 4.7273
	new_data_grads_norm = 7.1484
	old_data_grads_norm = 6.0130
	sim_grads_norm_tr = 0.0413
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4640
	data_grads_norm = 4.7209
	new_data_grads_norm = 6.8947
	old_data_grads_norm = 6.0922
	sim_grads_norm_tr = 0.0311
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3083
	data_grads_norm = 5.4261
	new_data_grads_norm = 7.2402
	old_data_grads_norm = 7.9242
	sim_grads_norm_tr = -0.0079
-- Starting training on experience 133 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3480
	data_grads_norm = 4.5929
	new_data_grads_norm = 6.9911
	old_data_grads_norm = 6.0432
	sim_grads_norm_tr = 0.0330
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3429
	data_grads_norm = 5.1473
	new_data_grads_norm = 7.0585
	old_data_grads_norm = 6.5949
	sim_grads_norm_tr = -0.0066
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3802
	data_grads_norm = 5.3396
	new_data_grads_norm = 7.1644
	old_data_grads_norm = 7.2722
	sim_grads_norm_tr = 0.0521
-- Starting training on experience 134 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6824
	data_grads_norm = 4.8538
	new_data_grads_norm = 7.3170
	old_data_grads_norm = 6.2148
	sim_grads_norm_tr = 0.0450
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4159
	data_grads_norm = 4.5123
	new_data_grads_norm = 6.9315
	old_data_grads_norm = 6.9498
	sim_grads_norm_tr = -0.0634
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7344
	data_grads_norm = 5.0866
	new_data_grads_norm = 6.8066
	old_data_grads_norm = 7.2619
	sim_grads_norm_tr = -0.0023
-- Starting training on experience 135 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6219
	data_grads_norm = 4.8991
	new_data_grads_norm = 7.1252
	old_data_grads_norm = 6.8109
	sim_grads_norm_tr = -0.0015
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6473
	data_grads_norm = 5.4179
	new_data_grads_norm = 7.3523
	old_data_grads_norm = 7.8335
	sim_grads_norm_tr = -0.0772
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6611
	data_grads_norm = 5.2393
	new_data_grads_norm = 7.9423
	old_data_grads_norm = 6.3568
	sim_grads_norm_tr = 0.0017
-- Starting training on experience 136 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0340
	data_grads_norm = 5.6584
	new_data_grads_norm = 7.4666
	old_data_grads_norm = 6.6393
	sim_grads_norm_tr = 0.0393
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5204
	data_grads_norm = 5.2076
	new_data_grads_norm = 7.4063
	old_data_grads_norm = 7.2454
	sim_grads_norm_tr = -0.0198
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2001
	data_grads_norm = 5.9429
	new_data_grads_norm = 8.0340
	old_data_grads_norm = 7.1968
	sim_grads_norm_tr = 0.0406
-- Starting training on experience 137 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7449
	data_grads_norm = 5.1012
	new_data_grads_norm = 7.5540
	old_data_grads_norm = 5.5183
	sim_grads_norm_tr = 0.0321
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9213
	data_grads_norm = 5.0285
	new_data_grads_norm = 7.4296
	old_data_grads_norm = 7.2540
	sim_grads_norm_tr = -0.0434
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5331
	data_grads_norm = 4.2641
	new_data_grads_norm = 6.7523
	old_data_grads_norm = 4.5995
	sim_grads_norm_tr = 0.1115
-- Starting training on experience 138 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8233
	data_grads_norm = 5.3137
	new_data_grads_norm = 7.0211
	old_data_grads_norm = 7.7680
	sim_grads_norm_tr = -0.0052
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5784
	data_grads_norm = 4.7726
	new_data_grads_norm = 6.7154
	old_data_grads_norm = 6.7746
	sim_grads_norm_tr = -0.0115
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3023
	data_grads_norm = 5.7387
	new_data_grads_norm = 7.0223
	old_data_grads_norm = 8.8404
	sim_grads_norm_tr = -0.0009
-- Starting training on experience 139 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3961
	data_grads_norm = 4.4248
	new_data_grads_norm = 6.7860
	old_data_grads_norm = 5.9237
	sim_grads_norm_tr = 0.0012
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8489
	data_grads_norm = 5.9018
	new_data_grads_norm = 6.7850
	old_data_grads_norm = 9.6957
	sim_grads_norm_tr = -0.0006
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7863
	data_grads_norm = 5.1845
	new_data_grads_norm = 6.9065
	old_data_grads_norm = 7.2120
	sim_grads_norm_tr = -0.0132
-- Starting training on experience 140 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6144
	data_grads_norm = 5.1509
	new_data_grads_norm = 6.3846
	old_data_grads_norm = 7.1160
	sim_grads_norm_tr = 0.0815
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0160
	data_grads_norm = 3.9758
	new_data_grads_norm = 6.2114
	old_data_grads_norm = 6.2367
	sim_grads_norm_tr = -0.0209
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2556
	data_grads_norm = 4.1119
	new_data_grads_norm = 7.0311
	old_data_grads_norm = 5.0001
	sim_grads_norm_tr = 0.0334
-- Starting training on experience 141 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2776
	data_grads_norm = 4.6839
	new_data_grads_norm = 7.5099
	old_data_grads_norm = 6.7248
	sim_grads_norm_tr = -0.0423
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8876
	data_grads_norm = 5.7263
	new_data_grads_norm = 7.2216
	old_data_grads_norm = 7.1311
	sim_grads_norm_tr = -0.0189
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6764
	data_grads_norm = 4.8098
	new_data_grads_norm = 7.9485
	old_data_grads_norm = 6.2789
	sim_grads_norm_tr = 0.0586
-- Starting training on experience 142 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2495
	data_grads_norm = 4.9314
	new_data_grads_norm = 7.4841
	old_data_grads_norm = 7.9670
	sim_grads_norm_tr = 0.0260
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0177
	data_grads_norm = 5.8472
	new_data_grads_norm = 6.7766
	old_data_grads_norm = 7.7654
	sim_grads_norm_tr = 0.0329
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2335
	data_grads_norm = 4.3841
	new_data_grads_norm = 6.7336
	old_data_grads_norm = 5.8677
	sim_grads_norm_tr = -0.0076
-- Starting training on experience 143 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2539
	data_grads_norm = 4.1865
	new_data_grads_norm = 6.3321
	old_data_grads_norm = 5.9149
	sim_grads_norm_tr = 0.0072
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6737
	data_grads_norm = 5.1471
	new_data_grads_norm = 6.9481
	old_data_grads_norm = 7.2166
	sim_grads_norm_tr = 0.0183
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5870
	data_grads_norm = 4.5273
	new_data_grads_norm = 6.5530
	old_data_grads_norm = 5.7391
	sim_grads_norm_tr = 0.0458
-- Starting training on experience 144 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2171
	data_grads_norm = 4.8404
	new_data_grads_norm = 6.0762
	old_data_grads_norm = 6.3911
	sim_grads_norm_tr = 0.0170
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8958
	data_grads_norm = 4.7323
	new_data_grads_norm = 7.0119
	old_data_grads_norm = 6.1562
	sim_grads_norm_tr = -0.0532
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0957
	data_grads_norm = 4.7615
	new_data_grads_norm = 6.3987
	old_data_grads_norm = 6.0189
	sim_grads_norm_tr = -0.0178
-- Starting training on experience 145 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3878
	data_grads_norm = 4.7275
	new_data_grads_norm = 8.3376
	old_data_grads_norm = 4.8794
	sim_grads_norm_tr = -0.0160
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7724
	data_grads_norm = 5.0200
	new_data_grads_norm = 7.5634
	old_data_grads_norm = 6.0308
	sim_grads_norm_tr = 0.0384
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6255
	data_grads_norm = 5.2577
	new_data_grads_norm = 7.1038
	old_data_grads_norm = 7.2091
	sim_grads_norm_tr = 0.0211
-- Starting training on experience 146 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1922
	data_grads_norm = 5.9423
	new_data_grads_norm = 6.2002
	old_data_grads_norm = 9.4467
	sim_grads_norm_tr = 0.0219
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2607
	data_grads_norm = 5.1649
	new_data_grads_norm = 6.0376
	old_data_grads_norm = 7.6158
	sim_grads_norm_tr = 0.0169
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6249
	data_grads_norm = 4.6640
	new_data_grads_norm = 6.2230
	old_data_grads_norm = 6.0977
	sim_grads_norm_tr = 0.0034
-- Starting training on experience 147 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2991
	data_grads_norm = 4.4364
	new_data_grads_norm = 7.3720
	old_data_grads_norm = 5.3760
	sim_grads_norm_tr = -0.0639
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4961
	data_grads_norm = 4.9922
	new_data_grads_norm = 7.4936
	old_data_grads_norm = 6.3103
	sim_grads_norm_tr = 0.0763
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5958
	data_grads_norm = 5.2290
	new_data_grads_norm = 7.4554
	old_data_grads_norm = 7.5486
	sim_grads_norm_tr = 0.0101
-- Starting training on experience 148 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0998
	data_grads_norm = 4.3718
	new_data_grads_norm = 7.1089
	old_data_grads_norm = 5.1629
	sim_grads_norm_tr = -0.0465
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3306
	data_grads_norm = 6.1170
	new_data_grads_norm = 7.9926
	old_data_grads_norm = 7.6762
	sim_grads_norm_tr = 0.0635
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7249
	data_grads_norm = 5.3751
	new_data_grads_norm = 7.5846
	old_data_grads_norm = 6.8883
	sim_grads_norm_tr = 0.0949
-- Starting training on experience 149 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9769
	data_grads_norm = 4.3272
	new_data_grads_norm = 6.7597
	old_data_grads_norm = 5.4969
	sim_grads_norm_tr = 0.0032
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0694
	data_grads_norm = 4.8113
	new_data_grads_norm = 7.3284
	old_data_grads_norm = 6.9517
	sim_grads_norm_tr = -0.0414
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3197
	data_grads_norm = 5.1665
	new_data_grads_norm = 7.0212
	old_data_grads_norm = 6.4881
	sim_grads_norm_tr = 0.0134
-- Starting training on experience 150 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2747
	data_grads_norm = 4.8236
	new_data_grads_norm = 6.8030
	old_data_grads_norm = 6.5551
	sim_grads_norm_tr = -0.0067
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3352
	data_grads_norm = 5.3588
	new_data_grads_norm = 8.1360
	old_data_grads_norm = 6.9200
	sim_grads_norm_tr = -0.0164
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7214
	data_grads_norm = 5.9000
	new_data_grads_norm = 7.9202
	old_data_grads_norm = 8.0577
	sim_grads_norm_tr = 0.0146
-- Starting training on experience 151 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6908
	data_grads_norm = 5.8286
	new_data_grads_norm = 7.7374
	old_data_grads_norm = 7.4819
	sim_grads_norm_tr = 0.0377
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6651
	data_grads_norm = 5.8728
	new_data_grads_norm = 7.8518
	old_data_grads_norm = 7.3468
	sim_grads_norm_tr = 0.0005
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6863
	data_grads_norm = 5.9489
	new_data_grads_norm = 8.7968
	old_data_grads_norm = 7.9688
	sim_grads_norm_tr = -0.0261
-- Starting training on experience 152 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7971
	data_grads_norm = 5.4430
	new_data_grads_norm = 7.8482
	old_data_grads_norm = 6.7845
	sim_grads_norm_tr = 0.0237
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5764
	data_grads_norm = 4.7805
	new_data_grads_norm = 7.8367
	old_data_grads_norm = 6.6083
	sim_grads_norm_tr = -0.0369
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8032
	data_grads_norm = 5.0901
	new_data_grads_norm = 7.8026
	old_data_grads_norm = 6.5090
	sim_grads_norm_tr = -0.0328
-- Starting training on experience 153 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3080
	data_grads_norm = 4.4893
	new_data_grads_norm = 7.2320
	old_data_grads_norm = 5.3866
	sim_grads_norm_tr = 0.0299
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3904
	data_grads_norm = 4.8441
	new_data_grads_norm = 7.1080
	old_data_grads_norm = 5.4496
	sim_grads_norm_tr = -0.0130
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5131
	data_grads_norm = 5.4574
	new_data_grads_norm = 8.0789
	old_data_grads_norm = 7.2549
	sim_grads_norm_tr = 0.0584
-- Starting training on experience 154 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3157
	data_grads_norm = 4.1296
	new_data_grads_norm = 6.0467
	old_data_grads_norm = 5.5256
	sim_grads_norm_tr = 0.0126
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1208
	data_grads_norm = 4.8083
	new_data_grads_norm = 6.3671
	old_data_grads_norm = 6.9149
	sim_grads_norm_tr = -0.0036
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7394
	data_grads_norm = 5.3005
	new_data_grads_norm = 5.9735
	old_data_grads_norm = 8.0992
	sim_grads_norm_tr = 0.0082
-- Starting training on experience 155 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6748
	data_grads_norm = 4.6223
	new_data_grads_norm = 7.3584
	old_data_grads_norm = 6.3164
	sim_grads_norm_tr = 0.0281
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3905
	data_grads_norm = 5.0209
	new_data_grads_norm = 7.9305
	old_data_grads_norm = 6.1263
	sim_grads_norm_tr = 0.0651
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1354
	data_grads_norm = 4.2789
	new_data_grads_norm = 7.4115
	old_data_grads_norm = 3.9797
	sim_grads_norm_tr = 0.0008
-- Starting training on experience 156 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7724
	data_grads_norm = 5.3580
	new_data_grads_norm = 8.0585
	old_data_grads_norm = 7.3580
	sim_grads_norm_tr = -0.0415
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3505
	data_grads_norm = 5.0008
	new_data_grads_norm = 7.4517
	old_data_grads_norm = 5.5415
	sim_grads_norm_tr = 0.0198
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6576
	data_grads_norm = 5.1211
	new_data_grads_norm = 6.8504
	old_data_grads_norm = 6.5639
	sim_grads_norm_tr = 0.0162
-- Starting training on experience 157 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6221
	data_grads_norm = 5.0020
	new_data_grads_norm = 7.7873
	old_data_grads_norm = 4.5404
	sim_grads_norm_tr = 0.0740
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3363
	data_grads_norm = 4.7862
	new_data_grads_norm = 7.8005
	old_data_grads_norm = 5.6329
	sim_grads_norm_tr = -0.0202
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8736
	data_grads_norm = 5.6219
	new_data_grads_norm = 7.4482
	old_data_grads_norm = 7.5639
	sim_grads_norm_tr = 0.0351
-- Starting training on experience 158 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5290
	data_grads_norm = 4.7574
	new_data_grads_norm = 7.3809
	old_data_grads_norm = 4.5874
	sim_grads_norm_tr = 0.0092
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9379
	data_grads_norm = 5.6731
	new_data_grads_norm = 7.8901
	old_data_grads_norm = 6.8592
	sim_grads_norm_tr = 0.0476
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6519
	data_grads_norm = 4.9339
	new_data_grads_norm = 6.8451
	old_data_grads_norm = 6.6693
	sim_grads_norm_tr = -0.0498
-- Starting training on experience 159 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5277
	data_grads_norm = 4.8945
	new_data_grads_norm = 6.6672
	old_data_grads_norm = 6.4464
	sim_grads_norm_tr = 0.0134
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7998
	data_grads_norm = 5.3954
	new_data_grads_norm = 6.3268
	old_data_grads_norm = 7.8190
	sim_grads_norm_tr = 0.0644
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3460
	data_grads_norm = 4.6254
	new_data_grads_norm = 6.3064
	old_data_grads_norm = 5.9430
	sim_grads_norm_tr = 0.0549
-- Starting training on experience 160 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8451
	data_grads_norm = 5.5340
	new_data_grads_norm = 7.4448
	old_data_grads_norm = 8.2609
	sim_grads_norm_tr = 0.0265
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5771
	data_grads_norm = 5.2821
	new_data_grads_norm = 7.8473
	old_data_grads_norm = 7.0366
	sim_grads_norm_tr = -0.0196
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4705
	data_grads_norm = 5.0286
	new_data_grads_norm = 7.7052
	old_data_grads_norm = 6.6472
	sim_grads_norm_tr = -0.0341
-- Starting training on experience 161 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5836
	data_grads_norm = 5.2767
	new_data_grads_norm = 6.7187
	old_data_grads_norm = 7.5313
	sim_grads_norm_tr = 0.0568
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3675
	data_grads_norm = 4.6098
	new_data_grads_norm = 6.8788
	old_data_grads_norm = 5.5285
	sim_grads_norm_tr = 0.0087
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8884
	data_grads_norm = 6.2298
	new_data_grads_norm = 6.5727
	old_data_grads_norm = 7.7320
	sim_grads_norm_tr = -0.0039
-- Starting training on experience 162 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1941
	data_grads_norm = 5.0734
	new_data_grads_norm = 8.8157
	old_data_grads_norm = 5.5326
	sim_grads_norm_tr = -0.0464
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5357
	data_grads_norm = 5.1254
	new_data_grads_norm = 8.6459
	old_data_grads_norm = 6.1192
	sim_grads_norm_tr = 0.0078
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7003
	data_grads_norm = 5.4000
	new_data_grads_norm = 7.9622
	old_data_grads_norm = 6.6219
	sim_grads_norm_tr = 0.0194
-- Starting training on experience 163 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4861
	data_grads_norm = 5.0452
	new_data_grads_norm = 7.7500
	old_data_grads_norm = 5.7748
	sim_grads_norm_tr = 0.0242
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4824
	data_grads_norm = 5.4746
	new_data_grads_norm = 8.6306
	old_data_grads_norm = 5.6482
	sim_grads_norm_tr = 0.0042
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5847
	data_grads_norm = 5.5329
	new_data_grads_norm = 8.0552
	old_data_grads_norm = 6.9591
	sim_grads_norm_tr = 0.0644
-- Starting training on experience 164 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0763
	data_grads_norm = 4.5332
	new_data_grads_norm = 6.4848
	old_data_grads_norm = 4.7841
	sim_grads_norm_tr = -0.0304
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2834
	data_grads_norm = 4.7325
	new_data_grads_norm = 6.8804
	old_data_grads_norm = 5.8317
	sim_grads_norm_tr = 0.0304
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3834
	data_grads_norm = 5.9498
	new_data_grads_norm = 7.2931
	old_data_grads_norm = 7.8979
	sim_grads_norm_tr = 0.0462
-- Starting training on experience 165 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3513
	data_grads_norm = 4.6350
	new_data_grads_norm = 6.6967
	old_data_grads_norm = 4.7632
	sim_grads_norm_tr = 0.0151
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0973
	data_grads_norm = 4.6568
	new_data_grads_norm = 6.4634
	old_data_grads_norm = 5.5694
	sim_grads_norm_tr = 0.1407
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5366
	data_grads_norm = 4.9466
	new_data_grads_norm = 6.5138
	old_data_grads_norm = 7.7947
	sim_grads_norm_tr = 0.0180
-- Starting training on experience 166 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3316
	data_grads_norm = 4.3219
	new_data_grads_norm = 7.3663
	old_data_grads_norm = 5.4703
	sim_grads_norm_tr = 0.0307
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7058
	data_grads_norm = 5.1364
	new_data_grads_norm = 7.2072
	old_data_grads_norm = 6.8404
	sim_grads_norm_tr = -0.0040
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6027
	data_grads_norm = 5.1501
	new_data_grads_norm = 7.5354
	old_data_grads_norm = 6.7440
	sim_grads_norm_tr = -0.0110
-- Starting training on experience 167 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2299
	data_grads_norm = 4.5113
	new_data_grads_norm = 6.8367
	old_data_grads_norm = 5.1284
	sim_grads_norm_tr = 0.0611
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3323
	data_grads_norm = 5.0570
	new_data_grads_norm = 6.9495
	old_data_grads_norm = 7.5604
	sim_grads_norm_tr = -0.0015
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3078
	data_grads_norm = 5.4070
	new_data_grads_norm = 7.4806
	old_data_grads_norm = 7.1308
	sim_grads_norm_tr = 0.0456
-- Starting training on experience 168 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0044
	data_grads_norm = 5.0608
	new_data_grads_norm = 7.5833
	old_data_grads_norm = 6.4573
	sim_grads_norm_tr = -0.0121
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8970
	data_grads_norm = 5.0472
	new_data_grads_norm = 7.1353
	old_data_grads_norm = 6.8913
	sim_grads_norm_tr = -0.0238
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4851
	data_grads_norm = 5.4048
	new_data_grads_norm = 7.8165
	old_data_grads_norm = 7.0623
	sim_grads_norm_tr = -0.0180
-- Starting training on experience 169 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6263
	data_grads_norm = 5.5027
	new_data_grads_norm = 7.0415
	old_data_grads_norm = 7.5091
	sim_grads_norm_tr = 0.0647
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0580
	data_grads_norm = 5.5751
	new_data_grads_norm = 8.3768
	old_data_grads_norm = 5.0166
	sim_grads_norm_tr = -0.0255
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3656
	data_grads_norm = 5.2030
	new_data_grads_norm = 8.3637
	old_data_grads_norm = 6.2917
	sim_grads_norm_tr = 0.0128
-- Starting training on experience 170 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2429
	data_grads_norm = 4.5869
	new_data_grads_norm = 7.3147
	old_data_grads_norm = 5.7050
	sim_grads_norm_tr = -0.0477
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5384
	data_grads_norm = 5.1258
	new_data_grads_norm = 7.0921
	old_data_grads_norm = 7.3668
	sim_grads_norm_tr = -0.0482
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3081
	data_grads_norm = 5.4011
	new_data_grads_norm = 7.3159
	old_data_grads_norm = 6.7248
	sim_grads_norm_tr = -0.0163
-- Starting training on experience 171 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0081
	data_grads_norm = 5.5735
	new_data_grads_norm = 7.8599
	old_data_grads_norm = 6.9173
	sim_grads_norm_tr = 0.0212
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4950
	data_grads_norm = 5.1049
	new_data_grads_norm = 7.7044
	old_data_grads_norm = 5.9526
	sim_grads_norm_tr = 0.0501
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4488
	data_grads_norm = 4.9399
	new_data_grads_norm = 7.7883
	old_data_grads_norm = 5.5218
	sim_grads_norm_tr = 0.0316
-- Starting training on experience 172 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5726
	data_grads_norm = 5.6719
	new_data_grads_norm = 8.0272
	old_data_grads_norm = 7.6387
	sim_grads_norm_tr = -0.0224
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5242
	data_grads_norm = 5.3801
	new_data_grads_norm = 8.2479
	old_data_grads_norm = 5.6970
	sim_grads_norm_tr = 0.0185
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3808
	data_grads_norm = 5.2342
	new_data_grads_norm = 7.9073
	old_data_grads_norm = 6.7716
	sim_grads_norm_tr = 0.0417
-- Starting training on experience 173 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2671
	data_grads_norm = 4.9960
	new_data_grads_norm = 6.7534
	old_data_grads_norm = 7.2808
	sim_grads_norm_tr = 0.0844
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2327
	data_grads_norm = 5.3102
	new_data_grads_norm = 6.7561
	old_data_grads_norm = 8.2929
	sim_grads_norm_tr = -0.0158
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0815
	data_grads_norm = 4.1415
	new_data_grads_norm = 7.0788
	old_data_grads_norm = 4.8384
	sim_grads_norm_tr = -0.0095
-- Starting training on experience 174 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5271
	data_grads_norm = 5.4016
	new_data_grads_norm = 7.4034
	old_data_grads_norm = 7.6935
	sim_grads_norm_tr = -0.0051
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2476
	data_grads_norm = 4.5517
	new_data_grads_norm = 7.2773
	old_data_grads_norm = 5.7447
	sim_grads_norm_tr = -0.0158
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9030
	data_grads_norm = 5.5095
	new_data_grads_norm = 7.1281
	old_data_grads_norm = 7.5716
	sim_grads_norm_tr = -0.0116
-- Starting training on experience 175 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2606
	data_grads_norm = 4.9916
	new_data_grads_norm = 6.9363
	old_data_grads_norm = 7.4375
	sim_grads_norm_tr = -0.0351
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5241
	data_grads_norm = 4.7755
	new_data_grads_norm = 7.6841
	old_data_grads_norm = 5.1043
	sim_grads_norm_tr = 0.0107
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2322
	data_grads_norm = 4.5618
	new_data_grads_norm = 7.1701
	old_data_grads_norm = 5.8445
	sim_grads_norm_tr = 0.0239
-- Starting training on experience 176 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1896
	data_grads_norm = 4.6715
	new_data_grads_norm = 6.8209
	old_data_grads_norm = 6.5134
	sim_grads_norm_tr = -0.0302
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1212
	data_grads_norm = 4.3056
	new_data_grads_norm = 6.5876
	old_data_grads_norm = 4.6519
	sim_grads_norm_tr = 0.0055
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5250
	data_grads_norm = 4.9328
	new_data_grads_norm = 6.2005
	old_data_grads_norm = 6.7264
	sim_grads_norm_tr = 0.0022
-- Starting training on experience 177 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9168
	data_grads_norm = 5.6022
	new_data_grads_norm = 8.0998
	old_data_grads_norm = 7.0423
	sim_grads_norm_tr = 0.0182
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0754
	data_grads_norm = 4.3258
	new_data_grads_norm = 6.6637
	old_data_grads_norm = 4.8101
	sim_grads_norm_tr = 0.0021
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2063
	data_grads_norm = 6.4083
	new_data_grads_norm = 7.0713
	old_data_grads_norm = 9.7976
	sim_grads_norm_tr = 0.0561
-- Starting training on experience 178 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0324
	data_grads_norm = 4.2474
	new_data_grads_norm = 6.8172
	old_data_grads_norm = 5.3908
	sim_grads_norm_tr = 0.0064
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5062
	data_grads_norm = 4.8625
	new_data_grads_norm = 7.0268
	old_data_grads_norm = 5.8070
	sim_grads_norm_tr = -0.0483
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1138
	data_grads_norm = 4.3626
	new_data_grads_norm = 6.6339
	old_data_grads_norm = 5.7877
	sim_grads_norm_tr = -0.0500
-- Starting training on experience 179 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9414
	data_grads_norm = 5.0058
	new_data_grads_norm = 7.0457
	old_data_grads_norm = 7.3845
	sim_grads_norm_tr = -0.0193
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7948
	data_grads_norm = 4.9481
	new_data_grads_norm = 7.0458
	old_data_grads_norm = 5.9319
	sim_grads_norm_tr = 0.0887
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4068
	data_grads_norm = 5.5361
	new_data_grads_norm = 6.7497
	old_data_grads_norm = 7.6645
	sim_grads_norm_tr = 0.0221
-- Starting training on experience 180 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7884
	data_grads_norm = 5.1040
	new_data_grads_norm = 6.5572
	old_data_grads_norm = 7.4979
	sim_grads_norm_tr = 0.0030
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0082
	data_grads_norm = 4.6840
	new_data_grads_norm = 5.9929
	old_data_grads_norm = 6.4183
	sim_grads_norm_tr = 0.0402
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1708
	data_grads_norm = 4.7319
	new_data_grads_norm = 6.4496
	old_data_grads_norm = 6.8420
	sim_grads_norm_tr = 0.0261
-- Starting training on experience 181 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1503
	data_grads_norm = 4.2558
	new_data_grads_norm = 6.3545
	old_data_grads_norm = 4.6163
	sim_grads_norm_tr = 0.0946
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4323
	data_grads_norm = 5.1187
	new_data_grads_norm = 6.7939
	old_data_grads_norm = 7.7733
	sim_grads_norm_tr = -0.0532
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6796
	data_grads_norm = 5.8635
	new_data_grads_norm = 7.5893
	old_data_grads_norm = 7.4786
	sim_grads_norm_tr = 0.0020
-- Starting training on experience 182 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1243
	data_grads_norm = 4.9316
	new_data_grads_norm = 6.2519
	old_data_grads_norm = 7.8532
	sim_grads_norm_tr = -0.0173
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9956
	data_grads_norm = 4.4029
	new_data_grads_norm = 6.0318
	old_data_grads_norm = 5.6292
	sim_grads_norm_tr = -0.0299
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6891
	data_grads_norm = 6.2746
	new_data_grads_norm = 6.7535
	old_data_grads_norm = 9.1485
	sim_grads_norm_tr = 0.0085
-- Starting training on experience 183 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7846
	data_grads_norm = 6.2862
	new_data_grads_norm = 7.0149
	old_data_grads_norm = 9.5647
	sim_grads_norm_tr = -0.0141
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3735
	data_grads_norm = 5.1943
	new_data_grads_norm = 7.2815
	old_data_grads_norm = 7.0502
	sim_grads_norm_tr = -0.0336
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2665
	data_grads_norm = 4.9583
	new_data_grads_norm = 6.7821
	old_data_grads_norm = 8.6418
	sim_grads_norm_tr = 0.0214
-- Starting training on experience 184 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2044
	data_grads_norm = 4.7316
	new_data_grads_norm = 7.0210
	old_data_grads_norm = 6.0070
	sim_grads_norm_tr = -0.0126
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6210
	data_grads_norm = 5.5912
	new_data_grads_norm = 7.0912
	old_data_grads_norm = 7.8784
	sim_grads_norm_tr = -0.0264
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2488
	data_grads_norm = 4.5733
	new_data_grads_norm = 6.2893
	old_data_grads_norm = 5.8997
	sim_grads_norm_tr = 0.0007
-- Starting training on experience 185 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3962
	data_grads_norm = 4.8363
	new_data_grads_norm = 6.9120
	old_data_grads_norm = 6.6037
	sim_grads_norm_tr = 0.0606
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4002
	data_grads_norm = 4.8789
	new_data_grads_norm = 6.8465
	old_data_grads_norm = 7.8303
	sim_grads_norm_tr = -0.0040
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5149
	data_grads_norm = 5.1835
	new_data_grads_norm = 7.0180
	old_data_grads_norm = 7.4318
	sim_grads_norm_tr = 0.0308
-- Starting training on experience 186 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4220
	data_grads_norm = 4.8801
	new_data_grads_norm = 8.4935
	old_data_grads_norm = 4.7338
	sim_grads_norm_tr = -0.0189
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4518
	data_grads_norm = 5.4384
	new_data_grads_norm = 8.3679
	old_data_grads_norm = 6.2589
	sim_grads_norm_tr = 0.0023
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4423
	data_grads_norm = 4.7342
	new_data_grads_norm = 8.6003
	old_data_grads_norm = 4.2267
	sim_grads_norm_tr = -0.0141
-- Starting training on experience 187 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0787
	data_grads_norm = 5.2818
	new_data_grads_norm = 7.2459
	old_data_grads_norm = 6.8757
	sim_grads_norm_tr = 0.0252
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4396
	data_grads_norm = 5.7623
	new_data_grads_norm = 7.9184
	old_data_grads_norm = 9.0606
	sim_grads_norm_tr = -0.0330
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5590
	data_grads_norm = 4.8656
	new_data_grads_norm = 6.9621
	old_data_grads_norm = 6.0444
	sim_grads_norm_tr = 0.0060
-- Starting training on experience 188 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4714
	data_grads_norm = 4.9855
	new_data_grads_norm = 6.3048
	old_data_grads_norm = 7.2782
	sim_grads_norm_tr = 0.0382
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1734
	data_grads_norm = 4.5763
	new_data_grads_norm = 6.1335
	old_data_grads_norm = 6.0972
	sim_grads_norm_tr = 0.0497
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0427
	data_grads_norm = 4.4583
	new_data_grads_norm = 6.8992
	old_data_grads_norm = 5.2526
	sim_grads_norm_tr = -0.0313
-- Starting training on experience 189 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2123
	data_grads_norm = 4.6722
	new_data_grads_norm = 7.2160
	old_data_grads_norm = 6.0047
	sim_grads_norm_tr = -0.0211
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2506
	data_grads_norm = 4.8374
	new_data_grads_norm = 7.2703
	old_data_grads_norm = 6.0130
	sim_grads_norm_tr = -0.0609
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8730
	data_grads_norm = 5.2630
	new_data_grads_norm = 7.4934
	old_data_grads_norm = 5.9106
	sim_grads_norm_tr = 0.0518
-- Starting training on experience 190 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5150
	data_grads_norm = 5.5287
	new_data_grads_norm = 8.3342
	old_data_grads_norm = 7.2390
	sim_grads_norm_tr = -0.0052
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4469
	data_grads_norm = 5.6694
	new_data_grads_norm = 8.7193
	old_data_grads_norm = 6.2388
	sim_grads_norm_tr = 0.0639
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0482
	data_grads_norm = 5.1603
	new_data_grads_norm = 9.0151
	old_data_grads_norm = 6.2516
	sim_grads_norm_tr = -0.0443
-- Starting training on experience 191 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1783
	data_grads_norm = 5.0506
	new_data_grads_norm = 8.1343
	old_data_grads_norm = 6.5077
	sim_grads_norm_tr = -0.0099
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2114
	data_grads_norm = 5.2944
	new_data_grads_norm = 8.0228
	old_data_grads_norm = 5.0005
	sim_grads_norm_tr = -0.0097
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5112
	data_grads_norm = 5.4989
	new_data_grads_norm = 7.8761
	old_data_grads_norm = 6.3006
	sim_grads_norm_tr = 0.0366
-- Starting training on experience 192 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7427
	data_grads_norm = 4.1684
	new_data_grads_norm = 7.3039
	old_data_grads_norm = 4.1944
	sim_grads_norm_tr = -0.0084
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3315
	data_grads_norm = 5.7333
	new_data_grads_norm = 6.8550
	old_data_grads_norm = 9.3946
	sim_grads_norm_tr = 0.0264
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5382
	data_grads_norm = 5.8919
	new_data_grads_norm = 7.0241
	old_data_grads_norm = 8.5731
	sim_grads_norm_tr = -0.0011
-- Starting training on experience 193 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9704
	data_grads_norm = 4.9898
	new_data_grads_norm = 6.5640
	old_data_grads_norm = 7.2726
	sim_grads_norm_tr = 0.0189
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1713
	data_grads_norm = 5.1922
	new_data_grads_norm = 7.1605
	old_data_grads_norm = 8.1714
	sim_grads_norm_tr = 0.0008
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3182
	data_grads_norm = 4.5800
	new_data_grads_norm = 6.5061
	old_data_grads_norm = 6.1939
	sim_grads_norm_tr = 0.0295
-- Starting training on experience 194 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6466
	data_grads_norm = 5.1027
	new_data_grads_norm = 7.0338
	old_data_grads_norm = 6.7543
	sim_grads_norm_tr = -0.0135
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4982
	data_grads_norm = 5.0416
	new_data_grads_norm = 7.1530
	old_data_grads_norm = 6.1596
	sim_grads_norm_tr = 0.0000
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4807
	data_grads_norm = 5.0866
	new_data_grads_norm = 7.1735
	old_data_grads_norm = 6.7612
	sim_grads_norm_tr = -0.0200
-- Starting training on experience 195 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8973
	data_grads_norm = 5.2657
	new_data_grads_norm = 6.7934
	old_data_grads_norm = 7.9952
	sim_grads_norm_tr = 0.0343
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4031
	data_grads_norm = 4.8319
	new_data_grads_norm = 6.3216
	old_data_grads_norm = 6.8466
	sim_grads_norm_tr = 0.0708
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6537
	data_grads_norm = 5.7375
	new_data_grads_norm = 7.1755
	old_data_grads_norm = 9.2502
	sim_grads_norm_tr = -0.0185
-- Starting training on experience 196 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2833
	data_grads_norm = 5.1631
	new_data_grads_norm = 6.9210
	old_data_grads_norm = 8.7681
	sim_grads_norm_tr = -0.0351
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2040
	data_grads_norm = 5.3603
	new_data_grads_norm = 6.9129
	old_data_grads_norm = 7.5493
	sim_grads_norm_tr = 0.1117
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0559
	data_grads_norm = 4.9224
	new_data_grads_norm = 6.7086
	old_data_grads_norm = 5.7959
	sim_grads_norm_tr = 0.0696
-- Starting training on experience 197 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2348
	data_grads_norm = 5.4133
	new_data_grads_norm = 7.0917
	old_data_grads_norm = 7.8030
	sim_grads_norm_tr = 0.0025
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8984
	data_grads_norm = 4.4401
	new_data_grads_norm = 6.2989
	old_data_grads_norm = 5.5963
	sim_grads_norm_tr = 0.0101
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5136
	data_grads_norm = 5.2653
	new_data_grads_norm = 6.5814
	old_data_grads_norm = 7.6345
	sim_grads_norm_tr = 0.0589
-- Starting training on experience 198 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1414
	data_grads_norm = 4.3503
	new_data_grads_norm = 7.2069
	old_data_grads_norm = 5.4381
	sim_grads_norm_tr = -0.0072
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1633
	data_grads_norm = 4.4182
	new_data_grads_norm = 7.1522
	old_data_grads_norm = 6.5344
	sim_grads_norm_tr = -0.0217
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1406
	data_grads_norm = 4.6789
	new_data_grads_norm = 7.0441
	old_data_grads_norm = 6.6802
	sim_grads_norm_tr = -0.0149
-- Starting training on experience 199 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0713
	data_grads_norm = 5.6020
	new_data_grads_norm = 7.7732
	old_data_grads_norm = 7.5950
	sim_grads_norm_tr = 0.0671
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5736
	data_grads_norm = 4.9699
	new_data_grads_norm = 8.5591
	old_data_grads_norm = 6.9291
	sim_grads_norm_tr = -0.0057
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8285
	data_grads_norm = 5.2938
	new_data_grads_norm = 8.1803
	old_data_grads_norm = 5.8595
	sim_grads_norm_tr = -0.0117
-- Starting training on experience 200 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1940
	data_grads_norm = 5.2610
	new_data_grads_norm = 7.7370
	old_data_grads_norm = 7.2965
	sim_grads_norm_tr = -0.0200
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3879
	data_grads_norm = 4.9428
	new_data_grads_norm = 7.3260
	old_data_grads_norm = 7.4463
	sim_grads_norm_tr = -0.0208
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3239
	data_grads_norm = 5.3241
	new_data_grads_norm = 7.0639
	old_data_grads_norm = 7.5674
	sim_grads_norm_tr = 0.0327
-- Starting training on experience 201 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4593
	data_grads_norm = 5.4002
	new_data_grads_norm = 7.0460
	old_data_grads_norm = 6.9112
	sim_grads_norm_tr = -0.0310
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1224
	data_grads_norm = 5.1240
	new_data_grads_norm = 6.6663
	old_data_grads_norm = 6.6481
	sim_grads_norm_tr = 0.0309
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5045
	data_grads_norm = 5.7038
	new_data_grads_norm = 7.1926
	old_data_grads_norm = 7.6857
	sim_grads_norm_tr = 0.0104
-- Starting training on experience 202 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5842
	data_grads_norm = 5.7340
	new_data_grads_norm = 8.7706
	old_data_grads_norm = 7.4223
	sim_grads_norm_tr = -0.0054
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4409
	data_grads_norm = 5.5375
	new_data_grads_norm = 8.1922
	old_data_grads_norm = 6.8611
	sim_grads_norm_tr = -0.0087
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2492
	data_grads_norm = 5.6256
	new_data_grads_norm = 8.7496
	old_data_grads_norm = 6.0512
	sim_grads_norm_tr = 0.0119
-- Starting training on experience 203 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1314
	data_grads_norm = 5.0057
	new_data_grads_norm = 7.4909
	old_data_grads_norm = 5.9129
	sim_grads_norm_tr = 0.0585
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1709
	data_grads_norm = 4.9426
	new_data_grads_norm = 7.5286
	old_data_grads_norm = 6.3173
	sim_grads_norm_tr = -0.0043
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8445
	data_grads_norm = 4.3186
	new_data_grads_norm = 7.3414
	old_data_grads_norm = 6.0814
	sim_grads_norm_tr = -0.0644
-- Starting training on experience 204 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6019
	data_grads_norm = 5.2327
	new_data_grads_norm = 6.8050
	old_data_grads_norm = 6.5645
	sim_grads_norm_tr = 0.0963
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4778
	data_grads_norm = 6.5139
	new_data_grads_norm = 7.5858
	old_data_grads_norm = 9.0794
	sim_grads_norm_tr = 0.0230
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5405
	data_grads_norm = 4.6719
	new_data_grads_norm = 6.6275
	old_data_grads_norm = 5.7252
	sim_grads_norm_tr = 0.0804
-- Starting training on experience 205 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3609
	data_grads_norm = 5.9511
	new_data_grads_norm = 8.2479
	old_data_grads_norm = 7.7866
	sim_grads_norm_tr = -0.0034
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9198
	data_grads_norm = 4.8132
	new_data_grads_norm = 7.5000
	old_data_grads_norm = 4.2963
	sim_grads_norm_tr = -0.0320
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4516
	data_grads_norm = 5.3659
	new_data_grads_norm = 7.5141
	old_data_grads_norm = 7.2410
	sim_grads_norm_tr = -0.0212
-- Starting training on experience 206 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9321
	data_grads_norm = 5.1448
	new_data_grads_norm = 6.6525
	old_data_grads_norm = 7.2342
	sim_grads_norm_tr = -0.0109
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9583
	data_grads_norm = 4.7259
	new_data_grads_norm = 7.1768
	old_data_grads_norm = 5.8827
	sim_grads_norm_tr = -0.0117
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2045
	data_grads_norm = 4.8716
	new_data_grads_norm = 6.8456
	old_data_grads_norm = 6.3450
	sim_grads_norm_tr = 0.0137
-- Starting training on experience 207 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9605
	data_grads_norm = 6.4533
	new_data_grads_norm = 8.6368
	old_data_grads_norm = 8.0621
	sim_grads_norm_tr = 0.0038
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0340
	data_grads_norm = 5.5445
	new_data_grads_norm = 8.7650
	old_data_grads_norm = 6.2079
	sim_grads_norm_tr = 0.0257
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3125
	data_grads_norm = 5.3687
	new_data_grads_norm = 7.5546
	old_data_grads_norm = 5.3394
	sim_grads_norm_tr = -0.0357
-- Starting training on experience 208 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3649
	data_grads_norm = 5.0048
	new_data_grads_norm = 7.5254
	old_data_grads_norm = 6.2422
	sim_grads_norm_tr = 0.0126
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5368
	data_grads_norm = 4.6807
	new_data_grads_norm = 6.9717
	old_data_grads_norm = 6.5574
	sim_grads_norm_tr = 0.1065
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2027
	data_grads_norm = 4.5179
	new_data_grads_norm = 7.1549
	old_data_grads_norm = 5.5415
	sim_grads_norm_tr = 0.0581
-- Starting training on experience 209 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3105
	data_grads_norm = 4.9643
	new_data_grads_norm = 7.8418
	old_data_grads_norm = 7.0233
	sim_grads_norm_tr = 0.0114
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2107
	data_grads_norm = 5.2697
	new_data_grads_norm = 8.6636
	old_data_grads_norm = 6.2063
	sim_grads_norm_tr = -0.0307
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1572
	data_grads_norm = 4.8830
	new_data_grads_norm = 7.8674
	old_data_grads_norm = 5.5781
	sim_grads_norm_tr = -0.0230
-- Starting training on experience 210 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5004
	data_grads_norm = 5.8829
	new_data_grads_norm = 8.2098
	old_data_grads_norm = 8.3922
	sim_grads_norm_tr = -0.0140
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1661
	data_grads_norm = 4.9959
	new_data_grads_norm = 8.1582
	old_data_grads_norm = 6.3191
	sim_grads_norm_tr = 0.0110
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1168
	data_grads_norm = 5.2408
	new_data_grads_norm = 7.1855
	old_data_grads_norm = 6.9901
	sim_grads_norm_tr = -0.0026
-- Starting training on experience 211 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4376
	data_grads_norm = 5.5063
	new_data_grads_norm = 8.5202
	old_data_grads_norm = 6.1106
	sim_grads_norm_tr = 0.0165
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8704
	data_grads_norm = 6.0127
	new_data_grads_norm = 8.5414
	old_data_grads_norm = 6.3297
	sim_grads_norm_tr = 0.1167
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4583
	data_grads_norm = 5.9056
	new_data_grads_norm = 7.9247
	old_data_grads_norm = 8.4195
	sim_grads_norm_tr = 0.0319
-- Starting training on experience 212 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6425
	data_grads_norm = 5.9225
	new_data_grads_norm = 6.6946
	old_data_grads_norm = 9.1400
	sim_grads_norm_tr = -0.0268
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4454
	data_grads_norm = 5.3096
	new_data_grads_norm = 7.3180
	old_data_grads_norm = 5.8705
	sim_grads_norm_tr = 0.0183
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3839
	data_grads_norm = 5.4986
	new_data_grads_norm = 7.2810
	old_data_grads_norm = 9.0088
	sim_grads_norm_tr = -0.0189
-- Starting training on experience 213 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1275
	data_grads_norm = 4.4106
	new_data_grads_norm = 7.3789
	old_data_grads_norm = 4.4373
	sim_grads_norm_tr = 0.0021
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6364
	data_grads_norm = 5.3791
	new_data_grads_norm = 7.2215
	old_data_grads_norm = 8.0247
	sim_grads_norm_tr = -0.0080
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4470
	data_grads_norm = 5.3642
	new_data_grads_norm = 8.1272
	old_data_grads_norm = 7.1594
	sim_grads_norm_tr = 0.0321
-- Starting training on experience 214 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2403
	data_grads_norm = 4.9232
	new_data_grads_norm = 8.7285
	old_data_grads_norm = 5.6361
	sim_grads_norm_tr = 0.0193
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2283
	data_grads_norm = 4.8994
	new_data_grads_norm = 8.2108
	old_data_grads_norm = 5.5490
	sim_grads_norm_tr = 0.0051
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4878
	data_grads_norm = 5.7338
	new_data_grads_norm = 8.1173
	old_data_grads_norm = 7.3684
	sim_grads_norm_tr = -0.0266
-- Starting training on experience 215 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2568
	data_grads_norm = 5.4449
	new_data_grads_norm = 8.4307
	old_data_grads_norm = 6.1323
	sim_grads_norm_tr = 0.0132
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1492
	data_grads_norm = 6.0293
	new_data_grads_norm = 7.7699
	old_data_grads_norm = 8.3588
	sim_grads_norm_tr = 0.0509
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5065
	data_grads_norm = 5.5590
	new_data_grads_norm = 8.0564
	old_data_grads_norm = 7.9452
	sim_grads_norm_tr = -0.0010
-- Starting training on experience 216 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9277
	data_grads_norm = 4.5654
	new_data_grads_norm = 7.7373
	old_data_grads_norm = 5.0155
	sim_grads_norm_tr = -0.0165
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1628
	data_grads_norm = 5.1869
	new_data_grads_norm = 7.3386
	old_data_grads_norm = 6.3727
	sim_grads_norm_tr = 0.0356
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9297
	data_grads_norm = 6.1300
	new_data_grads_norm = 7.4269
	old_data_grads_norm = 7.9013
	sim_grads_norm_tr = 0.0490
-- Starting training on experience 217 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2988
	data_grads_norm = 4.8833
	new_data_grads_norm = 6.1487
	old_data_grads_norm = 5.7656
	sim_grads_norm_tr = 0.0435
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0614
	data_grads_norm = 4.3032
	new_data_grads_norm = 6.0074
	old_data_grads_norm = 7.3956
	sim_grads_norm_tr = -0.0046
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2979
	data_grads_norm = 4.6836
	new_data_grads_norm = 6.0127
	old_data_grads_norm = 6.8713
	sim_grads_norm_tr = -0.0267
-- Starting training on experience 218 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1418
	data_grads_norm = 4.6751
	new_data_grads_norm = 7.6491
	old_data_grads_norm = 5.1672
	sim_grads_norm_tr = -0.0019
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0489
	data_grads_norm = 4.7858
	new_data_grads_norm = 6.9663
	old_data_grads_norm = 6.4931
	sim_grads_norm_tr = -0.0454
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0540
	data_grads_norm = 5.9402
	new_data_grads_norm = 8.6906
	old_data_grads_norm = 6.5781
	sim_grads_norm_tr = 0.0265
-- Starting training on experience 219 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6005
	data_grads_norm = 5.3922
	new_data_grads_norm = 7.4616
	old_data_grads_norm = 7.5380
	sim_grads_norm_tr = -0.0040
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8343
	data_grads_norm = 4.2547
	new_data_grads_norm = 6.6719
	old_data_grads_norm = 5.4158
	sim_grads_norm_tr = -0.0239
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7022
	data_grads_norm = 5.5606
	new_data_grads_norm = 7.4923
	old_data_grads_norm = 8.5642
	sim_grads_norm_tr = -0.0191
-- Starting training on experience 220 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8464
	data_grads_norm = 4.4666
	new_data_grads_norm = 7.5117
	old_data_grads_norm = 5.8766
	sim_grads_norm_tr = -0.0367
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1328
	data_grads_norm = 5.5056
	new_data_grads_norm = 8.0757
	old_data_grads_norm = 7.5618
	sim_grads_norm_tr = 0.0109
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1527
	data_grads_norm = 5.0395
	new_data_grads_norm = 7.4112
	old_data_grads_norm = 6.9276
	sim_grads_norm_tr = -0.0383
-- Starting training on experience 221 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1939
	data_grads_norm = 4.5968
	new_data_grads_norm = 7.8697
	old_data_grads_norm = 4.6698
	sim_grads_norm_tr = -0.0511
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2602
	data_grads_norm = 4.7769
	new_data_grads_norm = 7.4353
	old_data_grads_norm = 6.0514
	sim_grads_norm_tr = -0.0204
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7533
	data_grads_norm = 6.0427
	new_data_grads_norm = 8.1201
	old_data_grads_norm = 5.9088
	sim_grads_norm_tr = -0.0060
-- Starting training on experience 222 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4181
	data_grads_norm = 5.2884
	new_data_grads_norm = 9.4223
	old_data_grads_norm = 5.2166
	sim_grads_norm_tr = 0.0698
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5226
	data_grads_norm = 4.9335
	new_data_grads_norm = 7.9038
	old_data_grads_norm = 7.3448
	sim_grads_norm_tr = -0.0287
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1864
	data_grads_norm = 4.7963
	new_data_grads_norm = 7.9627
	old_data_grads_norm = 5.9707
	sim_grads_norm_tr = -0.0018
-- Starting training on experience 223 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4703
	data_grads_norm = 4.6878
	new_data_grads_norm = 7.4122
	old_data_grads_norm = 4.9498
	sim_grads_norm_tr = 0.0096
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6868
	data_grads_norm = 4.8434
	new_data_grads_norm = 7.9143
	old_data_grads_norm = 6.1235
	sim_grads_norm_tr = 0.0040
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4175
	data_grads_norm = 5.3976
	new_data_grads_norm = 7.2256
	old_data_grads_norm = 6.8806
	sim_grads_norm_tr = -0.0555
-- Starting training on experience 224 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2916
	data_grads_norm = 5.0404
	new_data_grads_norm = 8.3107
	old_data_grads_norm = 5.2798
	sim_grads_norm_tr = -0.0031
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4158
	data_grads_norm = 5.3094
	new_data_grads_norm = 7.5411
	old_data_grads_norm = 6.2032
	sim_grads_norm_tr = 0.0102
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9171
	data_grads_norm = 4.3911
	new_data_grads_norm = 7.3417
	old_data_grads_norm = 4.4212
	sim_grads_norm_tr = -0.0279
-- Starting training on experience 225 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4408
	data_grads_norm = 5.2468
	new_data_grads_norm = 7.9080
	old_data_grads_norm = 6.1404
	sim_grads_norm_tr = 0.0689
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4690
	data_grads_norm = 5.1854
	new_data_grads_norm = 7.0977
	old_data_grads_norm = 6.6257
	sim_grads_norm_tr = 0.0150
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1291
	data_grads_norm = 4.9391
	new_data_grads_norm = 7.2624
	old_data_grads_norm = 7.5092
	sim_grads_norm_tr = -0.0040
-- Starting training on experience 226 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6151
	data_grads_norm = 5.1656
	new_data_grads_norm = 7.3746
	old_data_grads_norm = 7.2271
	sim_grads_norm_tr = -0.0110
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1115
	data_grads_norm = 4.5282
	new_data_grads_norm = 7.3824
	old_data_grads_norm = 5.7060
	sim_grads_norm_tr = 0.0394
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8386
	data_grads_norm = 4.0831
	new_data_grads_norm = 6.7724
	old_data_grads_norm = 6.7784
	sim_grads_norm_tr = -0.0122
-- Starting training on experience 227 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4500
	data_grads_norm = 5.4378
	new_data_grads_norm = 7.3706
	old_data_grads_norm = 7.2482
	sim_grads_norm_tr = 0.0198
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0968
	data_grads_norm = 4.4767
	new_data_grads_norm = 7.1527
	old_data_grads_norm = 5.4292
	sim_grads_norm_tr = -0.0145
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0427
	data_grads_norm = 4.4710
	new_data_grads_norm = 6.6230
	old_data_grads_norm = 4.5663
	sim_grads_norm_tr = 0.0900
-- Starting training on experience 228 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5230
	data_grads_norm = 4.7477
	new_data_grads_norm = 6.8295
	old_data_grads_norm = 5.0538
	sim_grads_norm_tr = 0.0204
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4875
	data_grads_norm = 5.4961
	new_data_grads_norm = 7.6103
	old_data_grads_norm = 7.0769
	sim_grads_norm_tr = -0.0038
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5850
	data_grads_norm = 4.7502
	new_data_grads_norm = 6.9876
	old_data_grads_norm = 6.1840
	sim_grads_norm_tr = -0.0017
-- Starting training on experience 229 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4700
	data_grads_norm = 5.7123
	new_data_grads_norm = 7.3872
	old_data_grads_norm = 9.3489
	sim_grads_norm_tr = -0.0204
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1528
	data_grads_norm = 4.6815
	new_data_grads_norm = 7.6019
	old_data_grads_norm = 4.9844
	sim_grads_norm_tr = -0.0084
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4627
	data_grads_norm = 5.6693
	new_data_grads_norm = 7.6720
	old_data_grads_norm = 7.9059
	sim_grads_norm_tr = -0.0257
-- Starting training on experience 230 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8312
	data_grads_norm = 4.6848
	new_data_grads_norm = 7.6547
	old_data_grads_norm = 7.7744
	sim_grads_norm_tr = -0.0119
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6567
	data_grads_norm = 5.1291
	new_data_grads_norm = 7.5075
	old_data_grads_norm = 6.4307
	sim_grads_norm_tr = -0.0444
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1322
	data_grads_norm = 5.0221
	new_data_grads_norm = 7.9090
	old_data_grads_norm = 5.1814
	sim_grads_norm_tr = 0.0349
-- Starting training on experience 231 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6414
	data_grads_norm = 4.0435
	new_data_grads_norm = 6.9438
	old_data_grads_norm = 4.5406
	sim_grads_norm_tr = -0.0356
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7758
	data_grads_norm = 6.3820
	new_data_grads_norm = 7.9950
	old_data_grads_norm = 9.0907
	sim_grads_norm_tr = -0.0009
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6062
	data_grads_norm = 6.0949
	new_data_grads_norm = 8.0440
	old_data_grads_norm = 7.2131
	sim_grads_norm_tr = -0.0478
-- Starting training on experience 232 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1871
	data_grads_norm = 4.8478
	new_data_grads_norm = 8.2022
	old_data_grads_norm = 6.3587
	sim_grads_norm_tr = -0.0557
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2678
	data_grads_norm = 5.4516
	new_data_grads_norm = 8.6326
	old_data_grads_norm = 5.9349
	sim_grads_norm_tr = 0.0047
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8261
	data_grads_norm = 5.0522
	new_data_grads_norm = 8.0787
	old_data_grads_norm = 6.7228
	sim_grads_norm_tr = 0.0461
-- Starting training on experience 233 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6019
	data_grads_norm = 6.3476
	new_data_grads_norm = 8.3881
	old_data_grads_norm = 7.9275
	sim_grads_norm_tr = 0.0002
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4023
	data_grads_norm = 5.3497
	new_data_grads_norm = 7.7043
	old_data_grads_norm = 7.0054
	sim_grads_norm_tr = 0.0721
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0468
	data_grads_norm = 4.8601
	new_data_grads_norm = 7.6710
	old_data_grads_norm = 7.1944
	sim_grads_norm_tr = -0.0080
-- Starting training on experience 234 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4850
	data_grads_norm = 5.2048
	new_data_grads_norm = 8.4523
	old_data_grads_norm = 6.3515
	sim_grads_norm_tr = 0.0342
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2120
	data_grads_norm = 5.0849
	new_data_grads_norm = 8.3438
	old_data_grads_norm = 5.3916
	sim_grads_norm_tr = 0.0339
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4920
	data_grads_norm = 5.8925
	new_data_grads_norm = 8.5901
	old_data_grads_norm = 6.5494
	sim_grads_norm_tr = -0.0282
-- Starting training on experience 235 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7128
	data_grads_norm = 4.7177
	new_data_grads_norm = 8.0868
	old_data_grads_norm = 5.1991
	sim_grads_norm_tr = -0.0091
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5588
	data_grads_norm = 5.7420
	new_data_grads_norm = 8.7923
	old_data_grads_norm = 7.9213
	sim_grads_norm_tr = 0.0142
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4682
	data_grads_norm = 5.8730
	new_data_grads_norm = 8.1800
	old_data_grads_norm = 8.2834
	sim_grads_norm_tr = 0.0111
-- Starting training on experience 236 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4231
	data_grads_norm = 5.3093
	new_data_grads_norm = 8.0112
	old_data_grads_norm = 5.6797
	sim_grads_norm_tr = 0.0173
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0338
	data_grads_norm = 4.5518
	new_data_grads_norm = 7.7000
	old_data_grads_norm = 6.8589
	sim_grads_norm_tr = -0.0154
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4668
	data_grads_norm = 5.4811
	new_data_grads_norm = 7.4755
	old_data_grads_norm = 8.4642
	sim_grads_norm_tr = 0.0239
-- Starting training on experience 237 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
-- >> End of training phase << --
-- >> Start of eval phase << --
-- Starting eval on experience 0 (Task 0) from test stream --
> Eval on experience 0 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp000 = 2.9383
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.3520
	mb_index = 3332
	time = 1176.2962
-- Starting eval on experience 1 (Task 0) from test stream --
> Eval on experience 1 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp001 = 2.6302
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.4420
-- Starting eval on experience 2 (Task 0) from test stream --
> Eval on experience 2 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp002 = 3.8656
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.2560
-- Starting eval on experience 3 (Task 0) from test stream --
> Eval on experience 3 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp003 = 2.3818
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.4900
-- Starting eval on experience 4 (Task 0) from test stream --
> Eval on experience 4 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp004 = 3.9145
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.2560
-- Starting eval on experience 5 (Task 0) from test stream --
> Eval on experience 5 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp005 = 2.8513
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.3960
-- Starting eval on experience 6 (Task 0) from test stream --
> Eval on experience 6 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp006 = 3.1632
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp006 = 0.2760
-- Starting eval on experience 7 (Task 0) from test stream --
> Eval on experience 7 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp007 = 3.0115
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp007 = 0.4200
-- Starting eval on experience 8 (Task 0) from test stream --
> Eval on experience 8 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp008 = 3.3877
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp008 = 0.3140
-- Starting eval on experience 9 (Task 0) from test stream --
> Eval on experience 9 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp009 = 3.0230
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp009 = 0.3520
-- Starting eval on experience 10 (Task 0) from test stream --
> Eval on experience 10 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp010 = 2.9636
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp010 = 0.2820
-- Starting eval on experience 11 (Task 0) from test stream --
> Eval on experience 11 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp011 = 2.8287
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp011 = 0.3180
-- Starting eval on experience 12 (Task 0) from test stream --
> Eval on experience 12 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp012 = 4.0577
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp012 = 0.1040
-- Starting eval on experience 13 (Task 0) from test stream --
> Eval on experience 13 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp013 = 3.8235
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp013 = 0.0640
-- >> End of eval phase << --
	CumulativeAccuracy/eval_phase/test_stream/Exp000 = 0.7220
	CumulativeAccuracy/eval_phase/test_stream/Exp001 = 0.6750
	CumulativeAccuracy/eval_phase/test_stream/Exp002 = 0.5520
	CumulativeAccuracy/eval_phase/test_stream/Exp003 = 0.5440
	CumulativeAccuracy/eval_phase/test_stream/Exp004 = 0.5044
	CumulativeAccuracy/eval_phase/test_stream/Exp005 = 0.4743
	CumulativeAccuracy/eval_phase/test_stream/Exp006 = 0.4434
	CumulativeAccuracy/eval_phase/test_stream/Exp007 = 0.4103
	CumulativeAccuracy/eval_phase/test_stream/Exp008 = 0.3898
	CumulativeAccuracy/eval_phase/test_stream/Exp009 = 0.3804
	CumulativeAccuracy/eval_phase/test_stream/Exp010 = 0.3602
	CumulativeAccuracy/eval_phase/test_stream/Exp011 = 0.3507
	CumulativeAccuracy/eval_phase/test_stream/Exp012 = 0.3286
	CumulativeAccuracy/eval_phase/test_stream/Exp013 = 0.3087
	Loss_Stream/eval_phase/test_stream/Task000 = 3.2029
	Top1_Acc_Stream/eval_phase/test_stream/Task000 = 0.3087
-- >> Start of training phase << --
-- Starting training on experience 0 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0488
	data_grads_norm = 5.2981
	new_data_grads_norm = 8.4503
	old_data_grads_norm = 5.0388
	sim_grads_norm_tr = 0.0045
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.9677
	data_grads_norm = 6.3247
	new_data_grads_norm = 8.4130
	old_data_grads_norm = 5.7519
	sim_grads_norm_tr = -0.0033
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2331
	data_grads_norm = 5.9083
	new_data_grads_norm = 8.7415
	old_data_grads_norm = 7.2083
	sim_grads_norm_tr = 0.0175
-- Starting training on experience 1 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0784
	data_grads_norm = 5.9208
	new_data_grads_norm = 8.2259
	old_data_grads_norm = 7.7778
	sim_grads_norm_tr = 0.0383
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7487
	data_grads_norm = 4.6619
	new_data_grads_norm = 7.9397
	old_data_grads_norm = 7.8431
	sim_grads_norm_tr = -0.0282
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4550
	data_grads_norm = 5.6301
	new_data_grads_norm = 7.6498
	old_data_grads_norm = 7.7539
	sim_grads_norm_tr = 0.0066
-- Starting training on experience 2 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1601
	data_grads_norm = 5.1326
	new_data_grads_norm = 7.9374
	old_data_grads_norm = 5.8590
	sim_grads_norm_tr = -0.0536
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3760
	data_grads_norm = 5.4563
	new_data_grads_norm = 8.1148
	old_data_grads_norm = 7.0214
	sim_grads_norm_tr = 0.0087
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2529
	data_grads_norm = 5.6550
	new_data_grads_norm = 8.4880
	old_data_grads_norm = 6.9332
	sim_grads_norm_tr = 0.0233
-- Starting training on experience 3 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.7591
	data_grads_norm = 5.9538
	new_data_grads_norm = 10.0753
	old_data_grads_norm = 7.8128
	sim_grads_norm_tr = -0.0171
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.7962
	data_grads_norm = 5.1537
	new_data_grads_norm = 9.6444
	old_data_grads_norm = 4.5240
	sim_grads_norm_tr = 0.0381
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6191
	data_grads_norm = 5.2614
	new_data_grads_norm = 9.6909
	old_data_grads_norm = 5.8500
	sim_grads_norm_tr = 0.0287
-- Starting training on experience 4 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0907
	data_grads_norm = 4.8970
	new_data_grads_norm = 7.2681
	old_data_grads_norm = 6.0911
	sim_grads_norm_tr = -0.0079
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5708
	data_grads_norm = 5.7844
	new_data_grads_norm = 7.8104
	old_data_grads_norm = 6.7458
	sim_grads_norm_tr = 0.1162
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0924
	data_grads_norm = 5.2488
	new_data_grads_norm = 7.8031
	old_data_grads_norm = 4.8655
	sim_grads_norm_tr = -0.0053
-- Starting training on experience 5 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.8025
	data_grads_norm = 6.1633
	new_data_grads_norm = 7.2746
	old_data_grads_norm = 9.5233
	sim_grads_norm_tr = 0.0876
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1178
	data_grads_norm = 5.5366
	new_data_grads_norm = 7.4686
	old_data_grads_norm = 6.6159
	sim_grads_norm_tr = 0.0231
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3366
	data_grads_norm = 5.7933
	new_data_grads_norm = 8.1226
	old_data_grads_norm = 7.4959
	sim_grads_norm_tr = 0.0307
-- Starting training on experience 6 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4402
	data_grads_norm = 5.0404
	new_data_grads_norm = 7.9501
	old_data_grads_norm = 5.4183
	sim_grads_norm_tr = -0.0063
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4552
	data_grads_norm = 6.0535
	new_data_grads_norm = 7.8864
	old_data_grads_norm = 9.4624
	sim_grads_norm_tr = 0.0285
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9165
	data_grads_norm = 5.0668
	new_data_grads_norm = 7.8549
	old_data_grads_norm = 6.3706
	sim_grads_norm_tr = 0.0251
-- Starting training on experience 7 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1839
	data_grads_norm = 5.1847
	new_data_grads_norm = 7.5778
	old_data_grads_norm = 6.3771
	sim_grads_norm_tr = 0.0062
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2604
	data_grads_norm = 4.7177
	new_data_grads_norm = 7.8371
	old_data_grads_norm = 5.1615
	sim_grads_norm_tr = -0.0041
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4480
	data_grads_norm = 5.1126
	new_data_grads_norm = 7.4907
	old_data_grads_norm = 5.9914
	sim_grads_norm_tr = 0.0164
-- Starting training on experience 8 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7522
	data_grads_norm = 4.3466
	new_data_grads_norm = 6.5069
	old_data_grads_norm = 5.1224
	sim_grads_norm_tr = 0.0003
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2579
	data_grads_norm = 5.0523
	new_data_grads_norm = 8.0578
	old_data_grads_norm = 5.9799
	sim_grads_norm_tr = 0.0097
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2394
	data_grads_norm = 5.5347
	new_data_grads_norm = 7.3249
	old_data_grads_norm = 7.2273
	sim_grads_norm_tr = 0.1880
-- Starting training on experience 9 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.7909
	data_grads_norm = 6.8610
	new_data_grads_norm = 8.9462
	old_data_grads_norm = 7.9252
	sim_grads_norm_tr = 0.0144
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.7318
	data_grads_norm = 5.8720
	new_data_grads_norm = 8.3349
	old_data_grads_norm = 6.1956
	sim_grads_norm_tr = 0.0193
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0361
	data_grads_norm = 5.1642
	new_data_grads_norm = 8.3087
	old_data_grads_norm = 8.3882
	sim_grads_norm_tr = 0.0407
-- Starting training on experience 10 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0632
	data_grads_norm = 5.4346
	new_data_grads_norm = 7.7583
	old_data_grads_norm = 7.2000
	sim_grads_norm_tr = -0.0221
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1396
	data_grads_norm = 5.0182
	new_data_grads_norm = 7.7709
	old_data_grads_norm = 6.6589
	sim_grads_norm_tr = -0.0017
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2968
	data_grads_norm = 6.0582
	new_data_grads_norm = 8.1254
	old_data_grads_norm = 7.7490
	sim_grads_norm_tr = 0.0465
-- Starting training on experience 11 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.9362
	data_grads_norm = 5.7318
	new_data_grads_norm = 8.0511
	old_data_grads_norm = 7.3396
	sim_grads_norm_tr = 0.0574
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5657
	data_grads_norm = 5.8150
	new_data_grads_norm = 7.6631
	old_data_grads_norm = 7.6734
	sim_grads_norm_tr = 0.0408
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1641
	data_grads_norm = 5.5056
	new_data_grads_norm = 8.0406
	old_data_grads_norm = 6.6867
	sim_grads_norm_tr = 0.0181
-- Starting training on experience 12 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.8093
	data_grads_norm = 5.9428
	new_data_grads_norm = 9.4094
	old_data_grads_norm = 6.2389
	sim_grads_norm_tr = 0.0087
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.1968
	data_grads_norm = 6.0573
	new_data_grads_norm = 9.0807
	old_data_grads_norm = 7.3421
	sim_grads_norm_tr = 0.0292
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1259
	data_grads_norm = 5.8501
	new_data_grads_norm = 9.5920
	old_data_grads_norm = 5.8046
	sim_grads_norm_tr = 0.0188
-- Starting training on experience 13 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.3551
	data_grads_norm = 5.7934
	new_data_grads_norm = 7.5607
	old_data_grads_norm = 7.6363
	sim_grads_norm_tr = 0.0247
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3505
	data_grads_norm = 5.4096
	new_data_grads_norm = 7.6150
	old_data_grads_norm = 7.7349
	sim_grads_norm_tr = -0.0118
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5553
	data_grads_norm = 5.3188
	new_data_grads_norm = 7.4074
	old_data_grads_norm = 6.7144
	sim_grads_norm_tr = -0.0227
-- Starting training on experience 14 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3441
	data_grads_norm = 5.6968
	new_data_grads_norm = 8.6716
	old_data_grads_norm = 6.4705
	sim_grads_norm_tr = 0.1057
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7669
	data_grads_norm = 5.6229
	new_data_grads_norm = 8.0341
	old_data_grads_norm = 7.4749
	sim_grads_norm_tr = -0.0273
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7224
	data_grads_norm = 5.1532
	new_data_grads_norm = 7.3771
	old_data_grads_norm = 5.3645
	sim_grads_norm_tr = 0.0601
-- Starting training on experience 15 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0087
	data_grads_norm = 5.4165
	new_data_grads_norm = 7.3821
	old_data_grads_norm = 7.4416
	sim_grads_norm_tr = 0.0028
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9165
	data_grads_norm = 5.5922
	new_data_grads_norm = 8.0552
	old_data_grads_norm = 8.0816
	sim_grads_norm_tr = 0.0333
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7681
	data_grads_norm = 5.5156
	new_data_grads_norm = 8.2819
	old_data_grads_norm = 6.6420
	sim_grads_norm_tr = -0.0014
-- Starting training on experience 16 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8651
	data_grads_norm = 5.2186
	new_data_grads_norm = 6.7345
	old_data_grads_norm = 5.9731
	sim_grads_norm_tr = 0.0238
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0729
	data_grads_norm = 5.9900
	new_data_grads_norm = 7.4300
	old_data_grads_norm = 9.1082
	sim_grads_norm_tr = -0.0521
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8083
	data_grads_norm = 5.8484
	new_data_grads_norm = 8.0707
	old_data_grads_norm = 7.6338
	sim_grads_norm_tr = -0.0032
-- Starting training on experience 17 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8175
	data_grads_norm = 6.0384
	new_data_grads_norm = 7.9766
	old_data_grads_norm = 7.5507
	sim_grads_norm_tr = 0.0389
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0983
	data_grads_norm = 5.1609
	new_data_grads_norm = 8.2018
	old_data_grads_norm = 5.7046
	sim_grads_norm_tr = 0.0131
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3046
	data_grads_norm = 5.0588
	new_data_grads_norm = 7.2691
	old_data_grads_norm = 6.1707
	sim_grads_norm_tr = 0.0741
-- Starting training on experience 18 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5822
	data_grads_norm = 5.0695
	new_data_grads_norm = 6.5144
	old_data_grads_norm = 7.0281
	sim_grads_norm_tr = -0.0312
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9834
	data_grads_norm = 5.7508
	new_data_grads_norm = 6.6164
	old_data_grads_norm = 8.7390
	sim_grads_norm_tr = 0.0020
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9660
	data_grads_norm = 5.3702
	new_data_grads_norm = 6.5583
	old_data_grads_norm = 7.5660
	sim_grads_norm_tr = 0.0165
-- Starting training on experience 19 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4748
	data_grads_norm = 4.9061
	new_data_grads_norm = 6.9840
	old_data_grads_norm = 6.3101
	sim_grads_norm_tr = -0.0030
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5999
	data_grads_norm = 5.3733
	new_data_grads_norm = 7.2750
	old_data_grads_norm = 6.8127
	sim_grads_norm_tr = -0.0078
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7014
	data_grads_norm = 5.0977
	new_data_grads_norm = 7.0312
	old_data_grads_norm = 6.4618
	sim_grads_norm_tr = -0.0136
-- Starting training on experience 20 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0181
	data_grads_norm = 5.4609
	new_data_grads_norm = 7.4997
	old_data_grads_norm = 6.8776
	sim_grads_norm_tr = 0.0240
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4484
	data_grads_norm = 5.4499
	new_data_grads_norm = 8.1636
	old_data_grads_norm = 8.0362
	sim_grads_norm_tr = -0.0195
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8026
	data_grads_norm = 5.6525
	new_data_grads_norm = 7.3937
	old_data_grads_norm = 7.8658
	sim_grads_norm_tr = -0.0454
-- Starting training on experience 21 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2868
	data_grads_norm = 5.2322
	new_data_grads_norm = 7.4456
	old_data_grads_norm = 6.8796
	sim_grads_norm_tr = -0.0081
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5867
	data_grads_norm = 5.8487
	new_data_grads_norm = 8.1066
	old_data_grads_norm = 6.7825
	sim_grads_norm_tr = 0.0545
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1391
	data_grads_norm = 4.9336
	new_data_grads_norm = 7.9128
	old_data_grads_norm = 4.5180
	sim_grads_norm_tr = 0.0149
-- Starting training on experience 22 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7505
	data_grads_norm = 4.5301
	new_data_grads_norm = 7.0625
	old_data_grads_norm = 6.0669
	sim_grads_norm_tr = -0.0059
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8998
	data_grads_norm = 3.9963
	new_data_grads_norm = 6.9288
	old_data_grads_norm = 4.5394
	sim_grads_norm_tr = 0.0280
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5064
	data_grads_norm = 4.3690
	new_data_grads_norm = 7.6009
	old_data_grads_norm = 6.5753
	sim_grads_norm_tr = 0.0017
-- Starting training on experience 23 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6173
	data_grads_norm = 4.5767
	new_data_grads_norm = 7.4566
	old_data_grads_norm = 4.5125
	sim_grads_norm_tr = -0.0602
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7046
	data_grads_norm = 5.3163
	new_data_grads_norm = 7.3905
	old_data_grads_norm = 8.1425
	sim_grads_norm_tr = -0.0071
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8307
	data_grads_norm = 5.2461
	new_data_grads_norm = 7.5957
	old_data_grads_norm = 5.8276
	sim_grads_norm_tr = 0.0237
-- Starting training on experience 24 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0588
	data_grads_norm = 4.0517
	new_data_grads_norm = 7.0333
	old_data_grads_norm = 3.4706
	sim_grads_norm_tr = -0.0332
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3213
	data_grads_norm = 5.5042
	new_data_grads_norm = 7.8011
	old_data_grads_norm = 7.8706
	sim_grads_norm_tr = 0.0170
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5007
	data_grads_norm = 5.3837
	new_data_grads_norm = 7.8502
	old_data_grads_norm = 5.7005
	sim_grads_norm_tr = -0.0219
-- Starting training on experience 25 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1506
	data_grads_norm = 4.8415
	new_data_grads_norm = 8.4030
	old_data_grads_norm = 4.8775
	sim_grads_norm_tr = 0.0287
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1577
	data_grads_norm = 5.7556
	new_data_grads_norm = 7.7551
	old_data_grads_norm = 7.1588
	sim_grads_norm_tr = 0.0129
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0029
	data_grads_norm = 5.8273
	new_data_grads_norm = 8.5434
	old_data_grads_norm = 6.6191
	sim_grads_norm_tr = 0.0075
-- Starting training on experience 26 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1829
	data_grads_norm = 5.1576
	new_data_grads_norm = 6.8511
	old_data_grads_norm = 7.6033
	sim_grads_norm_tr = -0.0060
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4906
	data_grads_norm = 6.2190
	new_data_grads_norm = 6.3841
	old_data_grads_norm = 9.9922
	sim_grads_norm_tr = 0.0605
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0182
	data_grads_norm = 4.8138
	new_data_grads_norm = 6.9755
	old_data_grads_norm = 6.9226
	sim_grads_norm_tr = 0.0049
-- Starting training on experience 27 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2287
	data_grads_norm = 5.6074
	new_data_grads_norm = 8.5105
	old_data_grads_norm = 7.6341
	sim_grads_norm_tr = -0.0295
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8413
	data_grads_norm = 5.8162
	new_data_grads_norm = 8.7964
	old_data_grads_norm = 7.5798
	sim_grads_norm_tr = 0.0234
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4783
	data_grads_norm = 5.5984
	new_data_grads_norm = 8.1794
	old_data_grads_norm = 7.7585
	sim_grads_norm_tr = 0.0092
-- Starting training on experience 28 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6660
	data_grads_norm = 5.2968
	new_data_grads_norm = 7.8684
	old_data_grads_norm = 4.9274
	sim_grads_norm_tr = 0.0171
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9902
	data_grads_norm = 5.4825
	new_data_grads_norm = 8.5412
	old_data_grads_norm = 6.2948
	sim_grads_norm_tr = 0.0363
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7312
	data_grads_norm = 5.6304
	new_data_grads_norm = 8.1768
	old_data_grads_norm = 6.9878
	sim_grads_norm_tr = 0.0103
-- Starting training on experience 29 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1830
	data_grads_norm = 5.7787
	new_data_grads_norm = 7.2042
	old_data_grads_norm = 9.0130
	sim_grads_norm_tr = 0.0206
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5133
	data_grads_norm = 5.8321
	new_data_grads_norm = 8.1919
	old_data_grads_norm = 6.3475
	sim_grads_norm_tr = 0.0729
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7263
	data_grads_norm = 4.8125
	new_data_grads_norm = 7.9230
	old_data_grads_norm = 6.0979
	sim_grads_norm_tr = -0.0365
-- Starting training on experience 30 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6935
	data_grads_norm = 5.2533
	new_data_grads_norm = 7.9993
	old_data_grads_norm = 6.0028
	sim_grads_norm_tr = -0.0279
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5026
	data_grads_norm = 4.7847
	new_data_grads_norm = 7.5447
	old_data_grads_norm = 6.0794
	sim_grads_norm_tr = 0.0610
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9076
	data_grads_norm = 5.6131
	new_data_grads_norm = 7.3388
	old_data_grads_norm = 7.6965
	sim_grads_norm_tr = 0.0168
-- Starting training on experience 31 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2247
	data_grads_norm = 5.1495
	new_data_grads_norm = 7.4438
	old_data_grads_norm = 7.0233
	sim_grads_norm_tr = -0.0482
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2954
	data_grads_norm = 5.2479
	new_data_grads_norm = 7.8899
	old_data_grads_norm = 5.8483
	sim_grads_norm_tr = 0.0130
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3638
	data_grads_norm = 5.6829
	new_data_grads_norm = 7.6820
	old_data_grads_norm = 6.7865
	sim_grads_norm_tr = -0.0059
-- Starting training on experience 32 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5848
	data_grads_norm = 4.8802
	new_data_grads_norm = 6.5861
	old_data_grads_norm = 5.7934
	sim_grads_norm_tr = 0.0833
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1467
	data_grads_norm = 5.2852
	new_data_grads_norm = 6.1357
	old_data_grads_norm = 7.3976
	sim_grads_norm_tr = 0.0066
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2139
	data_grads_norm = 4.7000
	new_data_grads_norm = 6.1923
	old_data_grads_norm = 6.3381
	sim_grads_norm_tr = -0.0357
-- Starting training on experience 33 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2241
	data_grads_norm = 5.1602
	new_data_grads_norm = 7.1822
	old_data_grads_norm = 7.1592
	sim_grads_norm_tr = 0.0434
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7920
	data_grads_norm = 4.7112
	new_data_grads_norm = 7.8846
	old_data_grads_norm = 6.5191
	sim_grads_norm_tr = -0.0442
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2081
	data_grads_norm = 4.7041
	new_data_grads_norm = 6.3807
	old_data_grads_norm = 7.1097
	sim_grads_norm_tr = -0.0079
-- Starting training on experience 34 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8849
	data_grads_norm = 4.4923
	new_data_grads_norm = 7.1527
	old_data_grads_norm = 4.5180
	sim_grads_norm_tr = -0.0516
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5694
	data_grads_norm = 5.9775
	new_data_grads_norm = 8.2497
	old_data_grads_norm = 7.4066
	sim_grads_norm_tr = 0.0346
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2858
	data_grads_norm = 6.0461
	new_data_grads_norm = 7.8949
	old_data_grads_norm = 6.7644
	sim_grads_norm_tr = 0.0221
-- Starting training on experience 35 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2577
	data_grads_norm = 5.8729
	new_data_grads_norm = 8.0438
	old_data_grads_norm = 6.6608
	sim_grads_norm_tr = 0.0117
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0121
	data_grads_norm = 5.3666
	new_data_grads_norm = 8.2387
	old_data_grads_norm = 5.4443
	sim_grads_norm_tr = 0.0340
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1095
	data_grads_norm = 5.1834
	new_data_grads_norm = 8.3287
	old_data_grads_norm = 6.3211
	sim_grads_norm_tr = -0.0552
-- Starting training on experience 36 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0971
	data_grads_norm = 5.0651
	new_data_grads_norm = 6.9766
	old_data_grads_norm = 7.5190
	sim_grads_norm_tr = -0.0074
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3381
	data_grads_norm = 5.5469
	new_data_grads_norm = 7.5543
	old_data_grads_norm = 8.1300
	sim_grads_norm_tr = -0.0065
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7929
	data_grads_norm = 4.2958
	new_data_grads_norm = 7.8198
	old_data_grads_norm = 3.8808
	sim_grads_norm_tr = -0.0343
-- Starting training on experience 37 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2372
	data_grads_norm = 5.4530
	new_data_grads_norm = 8.7272
	old_data_grads_norm = 5.4555
	sim_grads_norm_tr = 0.0488
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4375
	data_grads_norm = 5.9994
	new_data_grads_norm = 8.5762
	old_data_grads_norm = 8.4353
	sim_grads_norm_tr = -0.0183
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0996
	data_grads_norm = 5.0139
	new_data_grads_norm = 7.9333
	old_data_grads_norm = 7.7313
	sim_grads_norm_tr = 0.0303
-- Starting training on experience 38 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0846
	data_grads_norm = 5.4584
	new_data_grads_norm = 6.9359
	old_data_grads_norm = 7.1880
	sim_grads_norm_tr = 0.0123
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3657
	data_grads_norm = 5.9217
	new_data_grads_norm = 7.1268
	old_data_grads_norm = 7.9780
	sim_grads_norm_tr = 0.0300
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1596
	data_grads_norm = 5.7423
	new_data_grads_norm = 7.1978
	old_data_grads_norm = 9.1475
	sim_grads_norm_tr = -0.0024
-- Starting training on experience 39 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9661
	data_grads_norm = 5.3840
	new_data_grads_norm = 7.7477
	old_data_grads_norm = 6.7757
	sim_grads_norm_tr = 0.0096
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9238
	data_grads_norm = 5.2349
	new_data_grads_norm = 7.9111
	old_data_grads_norm = 6.5110
	sim_grads_norm_tr = -0.0077
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1922
	data_grads_norm = 5.4740
	new_data_grads_norm = 8.2245
	old_data_grads_norm = 6.3409
	sim_grads_norm_tr = -0.0091
-- Starting training on experience 40 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7792
	data_grads_norm = 5.5578
	new_data_grads_norm = 6.2065
	old_data_grads_norm = 9.0767
	sim_grads_norm_tr = -0.0061
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7236
	data_grads_norm = 5.4757
	new_data_grads_norm = 6.3269
	old_data_grads_norm = 8.2527
	sim_grads_norm_tr = -0.0234
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5542
	data_grads_norm = 4.6134
	new_data_grads_norm = 6.5807
	old_data_grads_norm = 6.1337
	sim_grads_norm_tr = -0.0084
-- Starting training on experience 41 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6840
	data_grads_norm = 4.7390
	new_data_grads_norm = 7.2786
	old_data_grads_norm = 6.6061
	sim_grads_norm_tr = -0.0137
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3394
	data_grads_norm = 5.5448
	new_data_grads_norm = 6.9725
	old_data_grads_norm = 7.0954
	sim_grads_norm_tr = 0.0171
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7092
	data_grads_norm = 4.6495
	new_data_grads_norm = 7.0798
	old_data_grads_norm = 4.8367
	sim_grads_norm_tr = 0.1314
-- Starting training on experience 42 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3477
	data_grads_norm = 4.7070
	new_data_grads_norm = 7.2741
	old_data_grads_norm = 5.6901
	sim_grads_norm_tr = -0.0280
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7508
	data_grads_norm = 5.2061
	new_data_grads_norm = 7.6551
	old_data_grads_norm = 7.0300
	sim_grads_norm_tr = -0.0068
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2463
	data_grads_norm = 4.8227
	new_data_grads_norm = 7.5086
	old_data_grads_norm = 5.1135
	sim_grads_norm_tr = -0.0291
-- Starting training on experience 43 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8608
	data_grads_norm = 5.2811
	new_data_grads_norm = 7.8396
	old_data_grads_norm = 7.1651
	sim_grads_norm_tr = 0.0436
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2484
	data_grads_norm = 4.6040
	new_data_grads_norm = 7.3011
	old_data_grads_norm = 5.6025
	sim_grads_norm_tr = -0.0298
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7901
	data_grads_norm = 5.5011
	new_data_grads_norm = 8.2352
	old_data_grads_norm = 7.4670
	sim_grads_norm_tr = 0.0817
-- Starting training on experience 44 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2745
	data_grads_norm = 4.7127
	new_data_grads_norm = 7.8587
	old_data_grads_norm = 4.8792
	sim_grads_norm_tr = 0.0189
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0752
	data_grads_norm = 4.5965
	new_data_grads_norm = 8.2788
	old_data_grads_norm = 4.9992
	sim_grads_norm_tr = -0.0196
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4013
	data_grads_norm = 6.0413
	new_data_grads_norm = 8.0154
	old_data_grads_norm = 7.7346
	sim_grads_norm_tr = 0.0177
-- Starting training on experience 45 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6850
	data_grads_norm = 5.2316
	new_data_grads_norm = 8.3770
	old_data_grads_norm = 4.6143
	sim_grads_norm_tr = 0.0173
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7275
	data_grads_norm = 5.0578
	new_data_grads_norm = 7.9549
	old_data_grads_norm = 5.3476
	sim_grads_norm_tr = -0.0149
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0353
	data_grads_norm = 5.1993
	new_data_grads_norm = 8.4842
	old_data_grads_norm = 5.2079
	sim_grads_norm_tr = 0.0146
-- Starting training on experience 46 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8252
	data_grads_norm = 5.0164
	new_data_grads_norm = 7.1446
	old_data_grads_norm = 6.5540
	sim_grads_norm_tr = 0.0101
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7285
	data_grads_norm = 4.6960
	new_data_grads_norm = 7.0876
	old_data_grads_norm = 6.3912
	sim_grads_norm_tr = -0.0442
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5067
	data_grads_norm = 4.3638
	new_data_grads_norm = 7.5941
	old_data_grads_norm = 5.5755
	sim_grads_norm_tr = -0.0226
-- Starting training on experience 47 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9640
	data_grads_norm = 5.3108
	new_data_grads_norm = 7.4464
	old_data_grads_norm = 7.7868
	sim_grads_norm_tr = 0.0110
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6196
	data_grads_norm = 6.1265
	new_data_grads_norm = 8.0291
	old_data_grads_norm = 8.0920
	sim_grads_norm_tr = 0.1247
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1710
	data_grads_norm = 5.5790
	new_data_grads_norm = 7.1227
	old_data_grads_norm = 8.0453
	sim_grads_norm_tr = 0.0131
-- Starting training on experience 48 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8759
	data_grads_norm = 5.5681
	new_data_grads_norm = 7.7130
	old_data_grads_norm = 6.3719
	sim_grads_norm_tr = 0.0880
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0092
	data_grads_norm = 4.9775
	new_data_grads_norm = 7.2571
	old_data_grads_norm = 6.5841
	sim_grads_norm_tr = -0.0183
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8821
	data_grads_norm = 5.5058
	new_data_grads_norm = 7.5742
	old_data_grads_norm = 6.5030
	sim_grads_norm_tr = -0.0412
-- Starting training on experience 49 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1135
	data_grads_norm = 5.4620
	new_data_grads_norm = 8.1833
	old_data_grads_norm = 6.3309
	sim_grads_norm_tr = 0.0105
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0100
	data_grads_norm = 5.0385
	new_data_grads_norm = 8.1078
	old_data_grads_norm = 5.5287
	sim_grads_norm_tr = 0.0953
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6738
	data_grads_norm = 6.5893
	new_data_grads_norm = 7.5249
	old_data_grads_norm = 9.9884
	sim_grads_norm_tr = 0.0021
-- Starting training on experience 50 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2301
	data_grads_norm = 6.8150
	new_data_grads_norm = 7.6666
	old_data_grads_norm = 9.8763
	sim_grads_norm_tr = 0.0742
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0655
	data_grads_norm = 5.0069
	new_data_grads_norm = 7.7290
	old_data_grads_norm = 5.3094
	sim_grads_norm_tr = -0.0165
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3551
	data_grads_norm = 5.1160
	new_data_grads_norm = 7.5704
	old_data_grads_norm = 6.5658
	sim_grads_norm_tr = -0.0598
-- Starting training on experience 51 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9299
	data_grads_norm = 5.3248
	new_data_grads_norm = 7.6902
	old_data_grads_norm = 6.3879
	sim_grads_norm_tr = 0.0181
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7033
	data_grads_norm = 5.3131
	new_data_grads_norm = 7.5031
	old_data_grads_norm = 8.0070
	sim_grads_norm_tr = 0.0062
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6731
	data_grads_norm = 5.2512
	new_data_grads_norm = 7.6141
	old_data_grads_norm = 6.1364
	sim_grads_norm_tr = 0.0421
-- Starting training on experience 52 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5936
	data_grads_norm = 5.2682
	new_data_grads_norm = 8.2380
	old_data_grads_norm = 5.7439
	sim_grads_norm_tr = -0.0154
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8757
	data_grads_norm = 5.4310
	new_data_grads_norm = 8.4591
	old_data_grads_norm = 5.8283
	sim_grads_norm_tr = -0.0502
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9769
	data_grads_norm = 5.6138
	new_data_grads_norm = 8.1650
	old_data_grads_norm = 7.1668
	sim_grads_norm_tr = 0.0018
-- Starting training on experience 53 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4854
	data_grads_norm = 5.0311
	new_data_grads_norm = 7.6925
	old_data_grads_norm = 6.2260
	sim_grads_norm_tr = 0.0294
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7861
	data_grads_norm = 5.6650
	new_data_grads_norm = 8.4826
	old_data_grads_norm = 8.1692
	sim_grads_norm_tr = 0.0297
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4885
	data_grads_norm = 4.6166
	new_data_grads_norm = 8.5300
	old_data_grads_norm = 5.4406
	sim_grads_norm_tr = -0.0401
-- Starting training on experience 54 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6374
	data_grads_norm = 4.7333
	new_data_grads_norm = 8.1359
	old_data_grads_norm = 4.7298
	sim_grads_norm_tr = -0.0225
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7929
	data_grads_norm = 5.7681
	new_data_grads_norm = 9.0903
	old_data_grads_norm = 8.5386
	sim_grads_norm_tr = -0.0034
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8655
	data_grads_norm = 5.6432
	new_data_grads_norm = 7.9414
	old_data_grads_norm = 7.6666
	sim_grads_norm_tr = -0.0067
-- Starting training on experience 55 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8726
	data_grads_norm = 5.1785
	new_data_grads_norm = 8.0778
	old_data_grads_norm = 6.1479
	sim_grads_norm_tr = 0.0076
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7363
	data_grads_norm = 4.9646
	new_data_grads_norm = 8.3831
	old_data_grads_norm = 4.9433
	sim_grads_norm_tr = 0.1011
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6801
	data_grads_norm = 5.5923
	new_data_grads_norm = 7.9200
	old_data_grads_norm = 8.1957
	sim_grads_norm_tr = 0.0023
-- Starting training on experience 56 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2148
	data_grads_norm = 5.0403
	new_data_grads_norm = 7.6799
	old_data_grads_norm = 6.6298
	sim_grads_norm_tr = 0.0941
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4145
	data_grads_norm = 4.1849
	new_data_grads_norm = 6.9592
	old_data_grads_norm = 4.7979
	sim_grads_norm_tr = -0.0142
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7486
	data_grads_norm = 5.6302
	new_data_grads_norm = 7.7407
	old_data_grads_norm = 8.8851
	sim_grads_norm_tr = -0.0299
-- Starting training on experience 57 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6328
	data_grads_norm = 5.2533
	new_data_grads_norm = 8.2488
	old_data_grads_norm = 6.3408
	sim_grads_norm_tr = -0.0269
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9853
	data_grads_norm = 5.4686
	new_data_grads_norm = 8.0988
	old_data_grads_norm = 7.6608
	sim_grads_norm_tr = 0.0332
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3401
	data_grads_norm = 5.5521
	new_data_grads_norm = 8.9371
	old_data_grads_norm = 5.7373
	sim_grads_norm_tr = 0.0193
-- Starting training on experience 58 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7447
	data_grads_norm = 5.4292
	new_data_grads_norm = 7.5616
	old_data_grads_norm = 7.6639
	sim_grads_norm_tr = 0.0551
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1229
	data_grads_norm = 5.9684
	new_data_grads_norm = 8.1988
	old_data_grads_norm = 7.5827
	sim_grads_norm_tr = 0.0507
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4920
	data_grads_norm = 5.6280
	new_data_grads_norm = 7.2505
	old_data_grads_norm = 7.8127
	sim_grads_norm_tr = -0.0345
-- Starting training on experience 59 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3924
	data_grads_norm = 5.3597
	new_data_grads_norm = 8.1817
	old_data_grads_norm = 6.3770
	sim_grads_norm_tr = -0.0017
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1371
	data_grads_norm = 4.8913
	new_data_grads_norm = 8.0210
	old_data_grads_norm = 4.1173
	sim_grads_norm_tr = 0.1317
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5324
	data_grads_norm = 5.9824
	new_data_grads_norm = 8.4439
	old_data_grads_norm = 7.1335
	sim_grads_norm_tr = 0.0071
-- Starting training on experience 60 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0093
	data_grads_norm = 5.6863
	new_data_grads_norm = 7.3669
	old_data_grads_norm = 8.2159
	sim_grads_norm_tr = -0.0321
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7660
	data_grads_norm = 5.1742
	new_data_grads_norm = 7.8767
	old_data_grads_norm = 6.0101
	sim_grads_norm_tr = -0.0369
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6053
	data_grads_norm = 5.1320
	new_data_grads_norm = 7.6433
	old_data_grads_norm = 6.1114
	sim_grads_norm_tr = -0.0008
-- Starting training on experience 61 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0411
	data_grads_norm = 5.1353
	new_data_grads_norm = 7.2116
	old_data_grads_norm = 6.6317
	sim_grads_norm_tr = 0.0447
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7107
	data_grads_norm = 4.9816
	new_data_grads_norm = 7.2134
	old_data_grads_norm = 5.2645
	sim_grads_norm_tr = 0.0829
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9316
	data_grads_norm = 5.0075
	new_data_grads_norm = 7.6381
	old_data_grads_norm = 5.8862
	sim_grads_norm_tr = -0.0501
-- Starting training on experience 62 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3986
	data_grads_norm = 4.1946
	new_data_grads_norm = 7.2227
	old_data_grads_norm = 4.9685
	sim_grads_norm_tr = -0.0183
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5538
	data_grads_norm = 4.5615
	new_data_grads_norm = 7.6363
	old_data_grads_norm = 5.6203
	sim_grads_norm_tr = -0.0067
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5319
	data_grads_norm = 4.5027
	new_data_grads_norm = 6.9379
	old_data_grads_norm = 4.8346
	sim_grads_norm_tr = -0.0323
-- Starting training on experience 63 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6961
	data_grads_norm = 5.0635
	new_data_grads_norm = 6.9081
	old_data_grads_norm = 6.9461
	sim_grads_norm_tr = 0.0852
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4627
	data_grads_norm = 4.7544
	new_data_grads_norm = 7.4599
	old_data_grads_norm = 5.2468
	sim_grads_norm_tr = -0.0331
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9358
	data_grads_norm = 5.3828
	new_data_grads_norm = 7.2886
	old_data_grads_norm = 7.6928
	sim_grads_norm_tr = 0.0632
-- Starting training on experience 64 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5565
	data_grads_norm = 5.8800
	new_data_grads_norm = 7.7574
	old_data_grads_norm = 8.2571
	sim_grads_norm_tr = 0.0997
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3055
	data_grads_norm = 4.3476
	new_data_grads_norm = 7.6729
	old_data_grads_norm = 4.8977
	sim_grads_norm_tr = -0.0233
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6052
	data_grads_norm = 4.9313
	new_data_grads_norm = 7.7242
	old_data_grads_norm = 6.9174
	sim_grads_norm_tr = -0.0388
-- Starting training on experience 65 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6686
	data_grads_norm = 4.9567
	new_data_grads_norm = 6.9345
	old_data_grads_norm = 6.4699
	sim_grads_norm_tr = 0.0021
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2314
	data_grads_norm = 5.8069
	new_data_grads_norm = 7.9425
	old_data_grads_norm = 7.9061
	sim_grads_norm_tr = 0.0934
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2045
	data_grads_norm = 4.0943
	new_data_grads_norm = 6.9932
	old_data_grads_norm = 5.3698
	sim_grads_norm_tr = -0.0358
-- Starting training on experience 66 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7645
	data_grads_norm = 5.7629
	new_data_grads_norm = 7.8028
	old_data_grads_norm = 8.0988
	sim_grads_norm_tr = 0.0072
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5025
	data_grads_norm = 4.2813
	new_data_grads_norm = 6.7740
	old_data_grads_norm = 4.6151
	sim_grads_norm_tr = -0.0303
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3284
	data_grads_norm = 4.4748
	new_data_grads_norm = 7.9014
	old_data_grads_norm = 5.0423
	sim_grads_norm_tr = -0.0127
-- Starting training on experience 67 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3311
	data_grads_norm = 4.3995
	new_data_grads_norm = 6.5010
	old_data_grads_norm = 5.8991
	sim_grads_norm_tr = -0.0392
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6195
	data_grads_norm = 4.8127
	new_data_grads_norm = 7.2271
	old_data_grads_norm = 5.2626
	sim_grads_norm_tr = -0.0252
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9674
	data_grads_norm = 4.8823
	new_data_grads_norm = 7.1021
	old_data_grads_norm = 5.4307
	sim_grads_norm_tr = 0.0600
-- Starting training on experience 68 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4688
	data_grads_norm = 5.2298
	new_data_grads_norm = 6.4710
	old_data_grads_norm = 7.9301
	sim_grads_norm_tr = -0.0133
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5913
	data_grads_norm = 4.6384
	new_data_grads_norm = 6.7693
	old_data_grads_norm = 5.5270
	sim_grads_norm_tr = -0.0148
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4240
	data_grads_norm = 5.0863
	new_data_grads_norm = 6.7451
	old_data_grads_norm = 7.0101
	sim_grads_norm_tr = -0.0482
-- Starting training on experience 69 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6572
	data_grads_norm = 5.1264
	new_data_grads_norm = 7.2776
	old_data_grads_norm = 7.3596
	sim_grads_norm_tr = -0.0270
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2265
	data_grads_norm = 5.9769
	new_data_grads_norm = 7.6512
	old_data_grads_norm = 7.5874
	sim_grads_norm_tr = 0.1119
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8172
	data_grads_norm = 5.5564
	new_data_grads_norm = 7.5672
	old_data_grads_norm = 7.3659
	sim_grads_norm_tr = 0.0083
-- Starting training on experience 70 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7571
	data_grads_norm = 5.9496
	new_data_grads_norm = 7.4742
	old_data_grads_norm = 8.4391
	sim_grads_norm_tr = 0.0385
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3187
	data_grads_norm = 4.4409
	new_data_grads_norm = 7.4948
	old_data_grads_norm = 4.7688
	sim_grads_norm_tr = -0.0216
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3447
	data_grads_norm = 4.8913
	new_data_grads_norm = 6.8152
	old_data_grads_norm = 6.2271
	sim_grads_norm_tr = 0.0161
-- Starting training on experience 71 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4165
	data_grads_norm = 4.6531
	new_data_grads_norm = 7.2305
	old_data_grads_norm = 6.3569
	sim_grads_norm_tr = -0.0257
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8082
	data_grads_norm = 5.0314
	new_data_grads_norm = 6.8025
	old_data_grads_norm = 6.4091
	sim_grads_norm_tr = 0.0918
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6346
	data_grads_norm = 4.8956
	new_data_grads_norm = 6.6900
	old_data_grads_norm = 6.7322
	sim_grads_norm_tr = -0.0165
-- Starting training on experience 72 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7560
	data_grads_norm = 5.6087
	new_data_grads_norm = 7.3287
	old_data_grads_norm = 7.9512
	sim_grads_norm_tr = 0.0155
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2972
	data_grads_norm = 4.6736
	new_data_grads_norm = 7.8681
	old_data_grads_norm = 4.5990
	sim_grads_norm_tr = 0.0065
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4093
	data_grads_norm = 4.5417
	new_data_grads_norm = 7.9844
	old_data_grads_norm = 4.8918
	sim_grads_norm_tr = 0.0002
-- Starting training on experience 73 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5908
	data_grads_norm = 5.2823
	new_data_grads_norm = 7.2858
	old_data_grads_norm = 6.5360
	sim_grads_norm_tr = 0.0148
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4911
	data_grads_norm = 5.4349
	new_data_grads_norm = 8.1260
	old_data_grads_norm = 6.5565
	sim_grads_norm_tr = 0.0558
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1398
	data_grads_norm = 5.3232
	new_data_grads_norm = 7.2621
	old_data_grads_norm = 6.7773
	sim_grads_norm_tr = -0.0627
-- Starting training on experience 74 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5818
	data_grads_norm = 5.6817
	new_data_grads_norm = 8.0113
	old_data_grads_norm = 7.1027
	sim_grads_norm_tr = 0.0080
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5927
	data_grads_norm = 4.5780
	new_data_grads_norm = 6.6905
	old_data_grads_norm = 6.0125
	sim_grads_norm_tr = 0.0277
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7925
	data_grads_norm = 5.4601
	new_data_grads_norm = 7.8630
	old_data_grads_norm = 7.7869
	sim_grads_norm_tr = 0.0028
-- Starting training on experience 75 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3800
	data_grads_norm = 5.7716
	new_data_grads_norm = 7.8334
	old_data_grads_norm = 7.0923
	sim_grads_norm_tr = 0.0916
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2417
	data_grads_norm = 4.7885
	new_data_grads_norm = 7.2545
	old_data_grads_norm = 7.0338
	sim_grads_norm_tr = -0.0224
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7261
	data_grads_norm = 5.1276
	new_data_grads_norm = 7.4935
	old_data_grads_norm = 6.5550
	sim_grads_norm_tr = -0.0132
-- Starting training on experience 76 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6570
	data_grads_norm = 6.2317
	new_data_grads_norm = 8.3066
	old_data_grads_norm = 8.6867
	sim_grads_norm_tr = -0.0267
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6281
	data_grads_norm = 5.3526
	new_data_grads_norm = 7.8888
	old_data_grads_norm = 9.0309
	sim_grads_norm_tr = -0.0079
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8926
	data_grads_norm = 5.7548
	new_data_grads_norm = 7.5082
	old_data_grads_norm = 8.0516
	sim_grads_norm_tr = 0.0314
-- Starting training on experience 77 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9868
	data_grads_norm = 5.2016
	new_data_grads_norm = 6.8508
	old_data_grads_norm = 7.1640
	sim_grads_norm_tr = 0.0024
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0361
	data_grads_norm = 5.2802
	new_data_grads_norm = 7.0559
	old_data_grads_norm = 7.6179
	sim_grads_norm_tr = 0.0372
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5539
	data_grads_norm = 5.0422
	new_data_grads_norm = 7.0566
	old_data_grads_norm = 7.2551
	sim_grads_norm_tr = 0.0036
-- Starting training on experience 78 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8998
	data_grads_norm = 5.8877
	new_data_grads_norm = 7.4153
	old_data_grads_norm = 7.8225
	sim_grads_norm_tr = -0.0029
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9809
	data_grads_norm = 5.1061
	new_data_grads_norm = 6.5884
	old_data_grads_norm = 7.4754
	sim_grads_norm_tr = 0.0229
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3500
	data_grads_norm = 4.3132
	new_data_grads_norm = 6.8717
	old_data_grads_norm = 4.3245
	sim_grads_norm_tr = 0.0391
-- Starting training on experience 79 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6595
	data_grads_norm = 4.9083
	new_data_grads_norm = 7.1112
	old_data_grads_norm = 6.6077
	sim_grads_norm_tr = 0.0504
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3533
	data_grads_norm = 4.9592
	new_data_grads_norm = 7.5335
	old_data_grads_norm = 6.3661
	sim_grads_norm_tr = -0.0346
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6881
	data_grads_norm = 5.1037
	new_data_grads_norm = 7.9706
	old_data_grads_norm = 6.8837
	sim_grads_norm_tr = 0.0003
-- Starting training on experience 80 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5314
	data_grads_norm = 5.5335
	new_data_grads_norm = 7.8550
	old_data_grads_norm = 6.6605
	sim_grads_norm_tr = 0.0241
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5569
	data_grads_norm = 5.6095
	new_data_grads_norm = 7.1053
	old_data_grads_norm = 6.4665
	sim_grads_norm_tr = 0.0129
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4040
	data_grads_norm = 5.0862
	new_data_grads_norm = 7.3700
	old_data_grads_norm = 4.9631
	sim_grads_norm_tr = 0.0122
-- Starting training on experience 81 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9616
	data_grads_norm = 5.2245
	new_data_grads_norm = 7.2723
	old_data_grads_norm = 5.7263
	sim_grads_norm_tr = 0.0774
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2892
	data_grads_norm = 4.8797
	new_data_grads_norm = 7.3692
	old_data_grads_norm = 6.7129
	sim_grads_norm_tr = -0.0328
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6031
	data_grads_norm = 5.8677
	new_data_grads_norm = 8.5349
	old_data_grads_norm = 6.1251
	sim_grads_norm_tr = 0.0380
-- Starting training on experience 82 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3693
	data_grads_norm = 4.5281
	new_data_grads_norm = 6.2434
	old_data_grads_norm = 5.4482
	sim_grads_norm_tr = 0.0592
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6469
	data_grads_norm = 4.0230
	new_data_grads_norm = 5.6774
	old_data_grads_norm = 5.2452
	sim_grads_norm_tr = -0.0078
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0628
	data_grads_norm = 5.1929
	new_data_grads_norm = 5.9039
	old_data_grads_norm = 8.2611
	sim_grads_norm_tr = -0.0062
-- Starting training on experience 83 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2400
	data_grads_norm = 4.9052
	new_data_grads_norm = 6.9509
	old_data_grads_norm = 5.0256
	sim_grads_norm_tr = -0.0007
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1665
	data_grads_norm = 4.5103
	new_data_grads_norm = 7.3826
	old_data_grads_norm = 3.6744
	sim_grads_norm_tr = 0.0522
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0185
	data_grads_norm = 4.7983
	new_data_grads_norm = 7.7317
	old_data_grads_norm = 6.7505
	sim_grads_norm_tr = -0.0097
-- Starting training on experience 84 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9726
	data_grads_norm = 4.4548
	new_data_grads_norm = 7.0863
	old_data_grads_norm = 5.3766
	sim_grads_norm_tr = -0.0227
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0334
	data_grads_norm = 5.5259
	new_data_grads_norm = 8.0560
	old_data_grads_norm = 6.8840
	sim_grads_norm_tr = 0.0359
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9692
	data_grads_norm = 4.5697
	new_data_grads_norm = 7.4953
	old_data_grads_norm = 5.4042
	sim_grads_norm_tr = -0.0500
-- Starting training on experience 85 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0924
	data_grads_norm = 4.8001
	new_data_grads_norm = 7.5122
	old_data_grads_norm = 3.9611
	sim_grads_norm_tr = -0.0074
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1431
	data_grads_norm = 4.7508
	new_data_grads_norm = 7.6151
	old_data_grads_norm = 5.2324
	sim_grads_norm_tr = 0.0209
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1468
	data_grads_norm = 4.9079
	new_data_grads_norm = 7.1568
	old_data_grads_norm = 6.2144
	sim_grads_norm_tr = -0.0433
-- Starting training on experience 86 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8044
	data_grads_norm = 6.0011
	new_data_grads_norm = 7.6092
	old_data_grads_norm = 8.3295
	sim_grads_norm_tr = -0.0048
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0728
	data_grads_norm = 4.9459
	new_data_grads_norm = 7.7045
	old_data_grads_norm = 6.0374
	sim_grads_norm_tr = 0.0298
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2942
	data_grads_norm = 5.0423
	new_data_grads_norm = 6.9870
	old_data_grads_norm = 7.2847
	sim_grads_norm_tr = 0.0263
-- Starting training on experience 87 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2747
	data_grads_norm = 5.5421
	new_data_grads_norm = 7.8432
	old_data_grads_norm = 7.4054
	sim_grads_norm_tr = -0.0272
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0456
	data_grads_norm = 5.3987
	new_data_grads_norm = 8.2224
	old_data_grads_norm = 4.9379
	sim_grads_norm_tr = 0.0010
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1490
	data_grads_norm = 4.7394
	new_data_grads_norm = 7.8826
	old_data_grads_norm = 5.5855
	sim_grads_norm_tr = -0.0222
-- Starting training on experience 88 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3397
	data_grads_norm = 4.7914
	new_data_grads_norm = 7.9759
	old_data_grads_norm = 6.4993
	sim_grads_norm_tr = -0.0014
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4716
	data_grads_norm = 5.2924
	new_data_grads_norm = 8.0641
	old_data_grads_norm = 5.8463
	sim_grads_norm_tr = 0.0048
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4592
	data_grads_norm = 5.2078
	new_data_grads_norm = 8.0106
	old_data_grads_norm = 6.8892
	sim_grads_norm_tr = 0.0023
-- Starting training on experience 89 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7780
	data_grads_norm = 4.3058
	new_data_grads_norm = 6.6400
	old_data_grads_norm = 6.0744
	sim_grads_norm_tr = 0.0010
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6525
	data_grads_norm = 4.8663
	new_data_grads_norm = 6.3651
	old_data_grads_norm = 7.3467
	sim_grads_norm_tr = 0.0209
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2396
	data_grads_norm = 5.4553
	new_data_grads_norm = 6.0531
	old_data_grads_norm = 9.3467
	sim_grads_norm_tr = 0.0560
-- Starting training on experience 90 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8246
	data_grads_norm = 4.9463
	new_data_grads_norm = 7.1788
	old_data_grads_norm = 6.3926
	sim_grads_norm_tr = 0.0365
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7014
	data_grads_norm = 5.5234
	new_data_grads_norm = 7.4440
	old_data_grads_norm = 8.1400
	sim_grads_norm_tr = 0.0538
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5289
	data_grads_norm = 4.9949
	new_data_grads_norm = 7.8231
	old_data_grads_norm = 5.4209
	sim_grads_norm_tr = 0.1183
-- Starting training on experience 91 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5309
	data_grads_norm = 5.7883
	new_data_grads_norm = 7.5479
	old_data_grads_norm = 7.3336
	sim_grads_norm_tr = 0.0241
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2604
	data_grads_norm = 4.3835
	new_data_grads_norm = 7.0005
	old_data_grads_norm = 5.9394
	sim_grads_norm_tr = 0.0034
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2545
	data_grads_norm = 4.8314
	new_data_grads_norm = 6.9168
	old_data_grads_norm = 6.8879
	sim_grads_norm_tr = -0.0265
-- Starting training on experience 92 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8994
	data_grads_norm = 5.8250
	new_data_grads_norm = 9.3238
	old_data_grads_norm = 7.4002
	sim_grads_norm_tr = -0.0640
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6929
	data_grads_norm = 5.8341
	new_data_grads_norm = 9.7880
	old_data_grads_norm = 6.2476
	sim_grads_norm_tr = -0.0139
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8883
	data_grads_norm = 5.7771
	new_data_grads_norm = 9.9470
	old_data_grads_norm = 7.3101
	sim_grads_norm_tr = -0.0351
-- Starting training on experience 93 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1973
	data_grads_norm = 4.2717
	new_data_grads_norm = 6.6754
	old_data_grads_norm = 5.3854
	sim_grads_norm_tr = 0.1388
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2344
	data_grads_norm = 5.6137
	new_data_grads_norm = 6.5338
	old_data_grads_norm = 10.0422
	sim_grads_norm_tr = 0.0543
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8573
	data_grads_norm = 4.3033
	new_data_grads_norm = 6.8207
	old_data_grads_norm = 4.7896
	sim_grads_norm_tr = -0.0334
-- Starting training on experience 94 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6060
	data_grads_norm = 5.5059
	new_data_grads_norm = 6.9095
	old_data_grads_norm = 7.6010
	sim_grads_norm_tr = -0.0255
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0983
	data_grads_norm = 4.4135
	new_data_grads_norm = 7.2990
	old_data_grads_norm = 5.3817
	sim_grads_norm_tr = -0.0115
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1326
	data_grads_norm = 4.9244
	new_data_grads_norm = 7.5259
	old_data_grads_norm = 5.5716
	sim_grads_norm_tr = -0.0285
-- Starting training on experience 95 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4898
	data_grads_norm = 5.5121
	new_data_grads_norm = 7.0270
	old_data_grads_norm = 8.1054
	sim_grads_norm_tr = 0.0554
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1474
	data_grads_norm = 6.5108
	new_data_grads_norm = 8.0632
	old_data_grads_norm = 9.2154
	sim_grads_norm_tr = 0.1079
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0867
	data_grads_norm = 4.9197
	new_data_grads_norm = 6.5620
	old_data_grads_norm = 6.4244
	sim_grads_norm_tr = 0.0478
-- Starting training on experience 96 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7544
	data_grads_norm = 5.7935
	new_data_grads_norm = 7.5206
	old_data_grads_norm = 6.7964
	sim_grads_norm_tr = -0.0114
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3465
	data_grads_norm = 4.9250
	new_data_grads_norm = 7.5077
	old_data_grads_norm = 6.1684
	sim_grads_norm_tr = -0.0379
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8561
	data_grads_norm = 5.2807
	new_data_grads_norm = 7.5943
	old_data_grads_norm = 8.0757
	sim_grads_norm_tr = 0.0241
-- Starting training on experience 97 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1722
	data_grads_norm = 4.7787
	new_data_grads_norm = 7.0324
	old_data_grads_norm = 6.1258
	sim_grads_norm_tr = -0.0008
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2398
	data_grads_norm = 4.6229
	new_data_grads_norm = 6.8925
	old_data_grads_norm = 6.4113
	sim_grads_norm_tr = -0.0109
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3885
	data_grads_norm = 5.3908
	new_data_grads_norm = 6.9924
	old_data_grads_norm = 7.5014
	sim_grads_norm_tr = 0.0631
-- Starting training on experience 98 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9890
	data_grads_norm = 5.8037
	new_data_grads_norm = 7.6494
	old_data_grads_norm = 7.9365
	sim_grads_norm_tr = 0.0181
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7016
	data_grads_norm = 4.9657
	new_data_grads_norm = 7.0577
	old_data_grads_norm = 5.8003
	sim_grads_norm_tr = 0.0305
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0557
	data_grads_norm = 5.8497
	new_data_grads_norm = 7.4372
	old_data_grads_norm = 7.8448
	sim_grads_norm_tr = -0.0030
-- Starting training on experience 99 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2374
	data_grads_norm = 4.8319
	new_data_grads_norm = 7.4204
	old_data_grads_norm = 5.7743
	sim_grads_norm_tr = -0.0301
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0942
	data_grads_norm = 4.7683
	new_data_grads_norm = 8.0800
	old_data_grads_norm = 5.7554
	sim_grads_norm_tr = -0.0675
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4043
	data_grads_norm = 5.1351
	new_data_grads_norm = 7.8999
	old_data_grads_norm = 7.6957
	sim_grads_norm_tr = -0.0068
-- Starting training on experience 100 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0586
	data_grads_norm = 4.3075
	new_data_grads_norm = 5.9955
	old_data_grads_norm = 5.8641
	sim_grads_norm_tr = 0.0235
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3554
	data_grads_norm = 5.0658
	new_data_grads_norm = 6.2364
	old_data_grads_norm = 7.4704
	sim_grads_norm_tr = -0.0440
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1335
	data_grads_norm = 4.9237
	new_data_grads_norm = 6.3365
	old_data_grads_norm = 6.8274
	sim_grads_norm_tr = -0.0106
-- Starting training on experience 101 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0326
	data_grads_norm = 6.0642
	new_data_grads_norm = 7.7091
	old_data_grads_norm = 8.2314
	sim_grads_norm_tr = 0.0637
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3849
	data_grads_norm = 5.8154
	new_data_grads_norm = 7.2618
	old_data_grads_norm = 9.8951
	sim_grads_norm_tr = 0.0002
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1603
	data_grads_norm = 4.9699
	new_data_grads_norm = 7.4760
	old_data_grads_norm = 6.7150
	sim_grads_norm_tr = -0.0007
-- Starting training on experience 102 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3875
	data_grads_norm = 5.9650
	new_data_grads_norm = 9.2881
	old_data_grads_norm = 7.1920
	sim_grads_norm_tr = -0.0249
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0219
	data_grads_norm = 7.1590
	new_data_grads_norm = 7.8510
	old_data_grads_norm = 9.2534
	sim_grads_norm_tr = 0.0292
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2986
	data_grads_norm = 5.2755
	new_data_grads_norm = 7.7532
	old_data_grads_norm = 7.6545
	sim_grads_norm_tr = 0.0464
-- Starting training on experience 103 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3853
	data_grads_norm = 6.1506
	new_data_grads_norm = 8.0533
	old_data_grads_norm = 7.1051
	sim_grads_norm_tr = 0.0129
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1903
	data_grads_norm = 4.8880
	new_data_grads_norm = 7.3618
	old_data_grads_norm = 5.8801
	sim_grads_norm_tr = -0.0174
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3401
	data_grads_norm = 5.1770
	new_data_grads_norm = 8.2372
	old_data_grads_norm = 5.6114
	sim_grads_norm_tr = 0.0711
-- Starting training on experience 104 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6516
	data_grads_norm = 6.0185
	new_data_grads_norm = 8.3928
	old_data_grads_norm = 8.7688
	sim_grads_norm_tr = -0.0088
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1292
	data_grads_norm = 4.5850
	new_data_grads_norm = 7.2481
	old_data_grads_norm = 6.4174
	sim_grads_norm_tr = -0.0328
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4391
	data_grads_norm = 5.6324
	new_data_grads_norm = 7.8172
	old_data_grads_norm = 9.2920
	sim_grads_norm_tr = 0.0169
-- Starting training on experience 105 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9410
	data_grads_norm = 4.4779
	new_data_grads_norm = 7.6650
	old_data_grads_norm = 5.3142
	sim_grads_norm_tr = -0.0179
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5536
	data_grads_norm = 3.8642
	new_data_grads_norm = 6.8619
	old_data_grads_norm = 2.5417
	sim_grads_norm_tr = -0.0347
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2254
	data_grads_norm = 5.4296
	new_data_grads_norm = 7.3442
	old_data_grads_norm = 8.6044
	sim_grads_norm_tr = -0.0272
-- Starting training on experience 106 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7567
	data_grads_norm = 5.4290
	new_data_grads_norm = 7.6261
	old_data_grads_norm = 6.5476
	sim_grads_norm_tr = -0.0223
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5478
	data_grads_norm = 5.2909
	new_data_grads_norm = 8.1892
	old_data_grads_norm = 6.1756
	sim_grads_norm_tr = 0.0090
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9298
	data_grads_norm = 5.8830
	new_data_grads_norm = 8.5122
	old_data_grads_norm = 7.5960
	sim_grads_norm_tr = -0.0278
-- Starting training on experience 107 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5900
	data_grads_norm = 5.8069
	new_data_grads_norm = 7.1239
	old_data_grads_norm = 8.3703
	sim_grads_norm_tr = -0.0187
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3561
	data_grads_norm = 5.3137
	new_data_grads_norm = 6.7981
	old_data_grads_norm = 7.5712
	sim_grads_norm_tr = -0.0290
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7626
	data_grads_norm = 5.7766
	new_data_grads_norm = 6.9851
	old_data_grads_norm = 8.4036
	sim_grads_norm_tr = 0.0141
-- Starting training on experience 108 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0421
	data_grads_norm = 5.4622
	new_data_grads_norm = 8.6003
	old_data_grads_norm = 6.2979
	sim_grads_norm_tr = 0.0142
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9614
	data_grads_norm = 5.3997
	new_data_grads_norm = 8.9357
	old_data_grads_norm = 5.7443
	sim_grads_norm_tr = -0.0016
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5957
	data_grads_norm = 5.6370
	new_data_grads_norm = 8.9708
	old_data_grads_norm = 6.4922
	sim_grads_norm_tr = -0.0093
-- Starting training on experience 109 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4752
	data_grads_norm = 5.6838
	new_data_grads_norm = 8.3720
	old_data_grads_norm = 8.1929
	sim_grads_norm_tr = -0.0118
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1540
	data_grads_norm = 4.5944
	new_data_grads_norm = 8.0260
	old_data_grads_norm = 4.3690
	sim_grads_norm_tr = -0.0450
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1589
	data_grads_norm = 6.1486
	new_data_grads_norm = 8.5300
	old_data_grads_norm = 8.0744
	sim_grads_norm_tr = 0.0160
-- Starting training on experience 110 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2837
	data_grads_norm = 4.3416
	new_data_grads_norm = 7.1138
	old_data_grads_norm = 5.9743
	sim_grads_norm_tr = -0.0345
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6700
	data_grads_norm = 4.9580
	new_data_grads_norm = 7.5115
	old_data_grads_norm = 6.1977
	sim_grads_norm_tr = 0.0169
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3753
	data_grads_norm = 4.9076
	new_data_grads_norm = 7.2234
	old_data_grads_norm = 6.5316
	sim_grads_norm_tr = -0.0125
-- Starting training on experience 111 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8170
	data_grads_norm = 5.5588
	new_data_grads_norm = 9.2100
	old_data_grads_norm = 6.5914
	sim_grads_norm_tr = -0.0031
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3034
	data_grads_norm = 6.8830
	new_data_grads_norm = 8.7593
	old_data_grads_norm = 10.1168
	sim_grads_norm_tr = 0.0879
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3458
	data_grads_norm = 4.7555
	new_data_grads_norm = 6.9087
	old_data_grads_norm = 6.1016
	sim_grads_norm_tr = -0.0484
-- Starting training on experience 112 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6323
	data_grads_norm = 5.0930
	new_data_grads_norm = 7.6480
	old_data_grads_norm = 5.9063
	sim_grads_norm_tr = -0.0074
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7659
	data_grads_norm = 5.1829
	new_data_grads_norm = 7.0917
	old_data_grads_norm = 6.9290
	sim_grads_norm_tr = -0.0042
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5378
	data_grads_norm = 4.7533
	new_data_grads_norm = 7.5573
	old_data_grads_norm = 6.1118
	sim_grads_norm_tr = -0.0592
-- Starting training on experience 113 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2037
	data_grads_norm = 5.6068
	new_data_grads_norm = 8.4453
	old_data_grads_norm = 7.9309
	sim_grads_norm_tr = -0.0240
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4571
	data_grads_norm = 4.5403
	new_data_grads_norm = 8.1568
	old_data_grads_norm = 4.8142
	sim_grads_norm_tr = 0.0293
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2316
	data_grads_norm = 6.0845
	new_data_grads_norm = 8.3770
	old_data_grads_norm = 6.9800
	sim_grads_norm_tr = 0.0478
-- Starting training on experience 114 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5259
	data_grads_norm = 4.8941
	new_data_grads_norm = 7.1105
	old_data_grads_norm = 6.2093
	sim_grads_norm_tr = -0.0071
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4887
	data_grads_norm = 4.9601
	new_data_grads_norm = 7.0395
	old_data_grads_norm = 6.1554
	sim_grads_norm_tr = 0.0068
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2963
	data_grads_norm = 4.7448
	new_data_grads_norm = 7.7772
	old_data_grads_norm = 5.3388
	sim_grads_norm_tr = -0.0006
-- Starting training on experience 115 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9142
	data_grads_norm = 5.4039
	new_data_grads_norm = 8.0969
	old_data_grads_norm = 5.9249
	sim_grads_norm_tr = -0.0140
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4969
	data_grads_norm = 4.7780
	new_data_grads_norm = 8.1406
	old_data_grads_norm = 3.9932
	sim_grads_norm_tr = 0.0709
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8649
	data_grads_norm = 5.7022
	new_data_grads_norm = 7.2667
	old_data_grads_norm = 8.2630
	sim_grads_norm_tr = -0.0421
-- Starting training on experience 116 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5994
	data_grads_norm = 4.9500
	new_data_grads_norm = 7.2095
	old_data_grads_norm = 7.8768
	sim_grads_norm_tr = -0.0117
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6536
	data_grads_norm = 5.7822
	new_data_grads_norm = 7.3602
	old_data_grads_norm = 8.3151
	sim_grads_norm_tr = 0.0583
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2274
	data_grads_norm = 5.3862
	new_data_grads_norm = 7.1371
	old_data_grads_norm = 6.2251
	sim_grads_norm_tr = 0.0219
-- Starting training on experience 117 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2074
	data_grads_norm = 5.4804
	new_data_grads_norm = 7.9878
	old_data_grads_norm = 6.2877
	sim_grads_norm_tr = 0.0053
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1111
	data_grads_norm = 5.8268
	new_data_grads_norm = 8.0569
	old_data_grads_norm = 6.4343
	sim_grads_norm_tr = 0.0124
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3627
	data_grads_norm = 5.8078
	new_data_grads_norm = 8.4068
	old_data_grads_norm = 6.4811
	sim_grads_norm_tr = -0.0190
-- Starting training on experience 118 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4637
	data_grads_norm = 4.8488
	new_data_grads_norm = 8.2704
	old_data_grads_norm = 5.3698
	sim_grads_norm_tr = 0.0130
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2464
	data_grads_norm = 4.1147
	new_data_grads_norm = 7.6664
	old_data_grads_norm = 4.5952
	sim_grads_norm_tr = 0.0014
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9680
	data_grads_norm = 5.4538
	new_data_grads_norm = 7.0633
	old_data_grads_norm = 7.5031
	sim_grads_norm_tr = 0.0176
-- Starting training on experience 119 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4666
	data_grads_norm = 5.0708
	new_data_grads_norm = 7.3680
	old_data_grads_norm = 6.3175
	sim_grads_norm_tr = 0.0576
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2788
	data_grads_norm = 4.7537
	new_data_grads_norm = 7.1918
	old_data_grads_norm = 6.9617
	sim_grads_norm_tr = 0.0878
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2189
	data_grads_norm = 5.5448
	new_data_grads_norm = 7.6289
	old_data_grads_norm = 7.8379
	sim_grads_norm_tr = 0.0045
-- Starting training on experience 120 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6185
	data_grads_norm = 5.6891
	new_data_grads_norm = 7.0899
	old_data_grads_norm = 7.7097
	sim_grads_norm_tr = -0.0011
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6373
	data_grads_norm = 5.1396
	new_data_grads_norm = 8.3164
	old_data_grads_norm = 6.4715
	sim_grads_norm_tr = -0.0160
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6009
	data_grads_norm = 5.2621
	new_data_grads_norm = 7.7364
	old_data_grads_norm = 6.2790
	sim_grads_norm_tr = 0.0181
-- Starting training on experience 121 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5490
	data_grads_norm = 5.2137
	new_data_grads_norm = 7.4290
	old_data_grads_norm = 6.6878
	sim_grads_norm_tr = 0.0390
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6726
	data_grads_norm = 5.7392
	new_data_grads_norm = 7.6735
	old_data_grads_norm = 7.3856
	sim_grads_norm_tr = -0.0388
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6662
	data_grads_norm = 5.4563
	new_data_grads_norm = 8.1026
	old_data_grads_norm = 5.6308
	sim_grads_norm_tr = -0.0151
-- Starting training on experience 122 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6987
	data_grads_norm = 5.2991
	new_data_grads_norm = 7.6582
	old_data_grads_norm = 6.2358
	sim_grads_norm_tr = 0.0332
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0655
	data_grads_norm = 6.0662
	new_data_grads_norm = 8.3620
	old_data_grads_norm = 8.4694
	sim_grads_norm_tr = 0.0595
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6829
	data_grads_norm = 5.0912
	new_data_grads_norm = 6.9221
	old_data_grads_norm = 6.6044
	sim_grads_norm_tr = 0.0113
-- Starting training on experience 123 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0538
	data_grads_norm = 4.7970
	new_data_grads_norm = 7.1199
	old_data_grads_norm = 6.2519
	sim_grads_norm_tr = 0.0124
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2754
	data_grads_norm = 4.9897
	new_data_grads_norm = 6.7946
	old_data_grads_norm = 7.0951
	sim_grads_norm_tr = -0.0187
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2521
	data_grads_norm = 5.3550
	new_data_grads_norm = 7.7111
	old_data_grads_norm = 7.5110
	sim_grads_norm_tr = -0.0221
-- Starting training on experience 124 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0192
	data_grads_norm = 4.5680
	new_data_grads_norm = 7.0803
	old_data_grads_norm = 6.4186
	sim_grads_norm_tr = -0.0161
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1060
	data_grads_norm = 5.0977
	new_data_grads_norm = 8.5905
	old_data_grads_norm = 5.3148
	sim_grads_norm_tr = -0.0426
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7209
	data_grads_norm = 5.9853
	new_data_grads_norm = 7.4203
	old_data_grads_norm = 7.8976
	sim_grads_norm_tr = 0.0638
-- Starting training on experience 125 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8662
	data_grads_norm = 4.7935
	new_data_grads_norm = 7.1594
	old_data_grads_norm = 5.2804
	sim_grads_norm_tr = 0.0198
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1186
	data_grads_norm = 5.1760
	new_data_grads_norm = 7.8720
	old_data_grads_norm = 6.1223
	sim_grads_norm_tr = 0.0603
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1177
	data_grads_norm = 4.2297
	new_data_grads_norm = 6.7552
	old_data_grads_norm = 4.8826
	sim_grads_norm_tr = -0.0221
-- Starting training on experience 126 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6376
	data_grads_norm = 5.4196
	new_data_grads_norm = 8.0599
	old_data_grads_norm = 5.8191
	sim_grads_norm_tr = 0.0797
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3016
	data_grads_norm = 5.0325
	new_data_grads_norm = 7.5391
	old_data_grads_norm = 6.5293
	sim_grads_norm_tr = 0.0188
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5333
	data_grads_norm = 4.6694
	new_data_grads_norm = 6.9938
	old_data_grads_norm = 5.5579
	sim_grads_norm_tr = 0.0435
-- Starting training on experience 127 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8969
	data_grads_norm = 4.6918
	new_data_grads_norm = 7.5626
	old_data_grads_norm = 4.3838
	sim_grads_norm_tr = 0.0186
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6271
	data_grads_norm = 4.0019
	new_data_grads_norm = 6.1722
	old_data_grads_norm = 5.0216
	sim_grads_norm_tr = -0.0024
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7372
	data_grads_norm = 4.3178
	new_data_grads_norm = 7.4798
	old_data_grads_norm = 5.0811
	sim_grads_norm_tr = -0.0403
-- Starting training on experience 128 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1638
	data_grads_norm = 6.0172
	new_data_grads_norm = 8.8026
	old_data_grads_norm = 8.2203
	sim_grads_norm_tr = -0.0118
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0554
	data_grads_norm = 5.6253
	new_data_grads_norm = 9.1787
	old_data_grads_norm = 6.5621
	sim_grads_norm_tr = -0.0251
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9522
	data_grads_norm = 5.7212
	new_data_grads_norm = 7.8556
	old_data_grads_norm = 7.6967
	sim_grads_norm_tr = 0.0271
-- Starting training on experience 129 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0270
	data_grads_norm = 4.5220
	new_data_grads_norm = 7.6718
	old_data_grads_norm = 3.6833
	sim_grads_norm_tr = -0.0146
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9048
	data_grads_norm = 4.6610
	new_data_grads_norm = 7.9130
	old_data_grads_norm = 6.0696
	sim_grads_norm_tr = 0.0298
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4025
	data_grads_norm = 5.1820
	new_data_grads_norm = 7.3027
	old_data_grads_norm = 6.3143
	sim_grads_norm_tr = -0.0476
-- Starting training on experience 130 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9069
	data_grads_norm = 5.5273
	new_data_grads_norm = 6.9346
	old_data_grads_norm = 8.3495
	sim_grads_norm_tr = 0.0179
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4125
	data_grads_norm = 5.1718
	new_data_grads_norm = 7.0361
	old_data_grads_norm = 7.3085
	sim_grads_norm_tr = -0.0179
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7287
	data_grads_norm = 4.8769
	new_data_grads_norm = 7.6280
	old_data_grads_norm = 7.4830
	sim_grads_norm_tr = 0.0144
-- Starting training on experience 131 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1582
	data_grads_norm = 5.2501
	new_data_grads_norm = 8.4438
	old_data_grads_norm = 5.3886
	sim_grads_norm_tr = -0.0221
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2324
	data_grads_norm = 4.6727
	new_data_grads_norm = 7.6117
	old_data_grads_norm = 5.0339
	sim_grads_norm_tr = 0.0570
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5088
	data_grads_norm = 5.2953
	new_data_grads_norm = 8.4606
	old_data_grads_norm = 6.0028
	sim_grads_norm_tr = 0.0667
-- Starting training on experience 132 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7828
	data_grads_norm = 5.6613
	new_data_grads_norm = 6.9938
	old_data_grads_norm = 7.1039
	sim_grads_norm_tr = 0.0427
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3833
	data_grads_norm = 4.7056
	new_data_grads_norm = 6.3545
	old_data_grads_norm = 5.8602
	sim_grads_norm_tr = -0.0173
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2605
	data_grads_norm = 4.5866
	new_data_grads_norm = 6.8087
	old_data_grads_norm = 6.0849
	sim_grads_norm_tr = -0.0230
-- Starting training on experience 133 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4215
	data_grads_norm = 5.5334
	new_data_grads_norm = 8.5594
	old_data_grads_norm = 5.6112
	sim_grads_norm_tr = 0.0020
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7222
	data_grads_norm = 5.2919
	new_data_grads_norm = 7.4054
	old_data_grads_norm = 6.8243
	sim_grads_norm_tr = 0.0260
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5927
	data_grads_norm = 5.4553
	new_data_grads_norm = 7.7080
	old_data_grads_norm = 7.7244
	sim_grads_norm_tr = -0.0405
-- Starting training on experience 134 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4510
	data_grads_norm = 5.1467
	new_data_grads_norm = 8.0816
	old_data_grads_norm = 5.7479
	sim_grads_norm_tr = 0.0312
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8789
	data_grads_norm = 5.8157
	new_data_grads_norm = 8.5272
	old_data_grads_norm = 7.1050
	sim_grads_norm_tr = 0.0494
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9176
	data_grads_norm = 6.2159
	new_data_grads_norm = 9.0475
	old_data_grads_norm = 8.4559
	sim_grads_norm_tr = -0.0371
-- Starting training on experience 135 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2988
	data_grads_norm = 4.7060
	new_data_grads_norm = 7.0746
	old_data_grads_norm = 6.0698
	sim_grads_norm_tr = -0.0298
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0621
	data_grads_norm = 4.6143
	new_data_grads_norm = 7.1185
	old_data_grads_norm = 6.0285
	sim_grads_norm_tr = -0.0189
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4537
	data_grads_norm = 5.2928
	new_data_grads_norm = 6.8349
	old_data_grads_norm = 6.6299
	sim_grads_norm_tr = 0.0521
-- Starting training on experience 136 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3814
	data_grads_norm = 5.6497
	new_data_grads_norm = 7.6794
	old_data_grads_norm = 8.0198
	sim_grads_norm_tr = -0.0099
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3947
	data_grads_norm = 5.5869
	new_data_grads_norm = 7.9459
	old_data_grads_norm = 7.1545
	sim_grads_norm_tr = 0.0084
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5065
	data_grads_norm = 5.9421
	new_data_grads_norm = 7.4303
	old_data_grads_norm = 8.3125
	sim_grads_norm_tr = 0.0273
-- Starting training on experience 137 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1541
	data_grads_norm = 4.6526
	new_data_grads_norm = 7.2882
	old_data_grads_norm = 5.0157
	sim_grads_norm_tr = -0.0120
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8048
	data_grads_norm = 5.1845
	new_data_grads_norm = 7.1348
	old_data_grads_norm = 7.0808
	sim_grads_norm_tr = 0.0012
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1189
	data_grads_norm = 6.3296
	new_data_grads_norm = 7.3175
	old_data_grads_norm = 9.0466
	sim_grads_norm_tr = 0.0936
-- Starting training on experience 138 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4790
	data_grads_norm = 4.4865
	new_data_grads_norm = 7.4262
	old_data_grads_norm = 4.9841
	sim_grads_norm_tr = 0.0741
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9096
	data_grads_norm = 5.4516
	new_data_grads_norm = 8.3198
	old_data_grads_norm = 7.7535
	sim_grads_norm_tr = -0.0399
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1732
	data_grads_norm = 5.2719
	new_data_grads_norm = 8.1955
	old_data_grads_norm = 6.2243
	sim_grads_norm_tr = 0.0442
-- Starting training on experience 139 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2037
	data_grads_norm = 4.4069
	new_data_grads_norm = 6.2176
	old_data_grads_norm = 6.3011
	sim_grads_norm_tr = 0.0119
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0505
	data_grads_norm = 4.2523
	new_data_grads_norm = 6.7139
	old_data_grads_norm = 5.1928
	sim_grads_norm_tr = -0.0217
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4361
	data_grads_norm = 4.7491
	new_data_grads_norm = 6.9924
	old_data_grads_norm = 6.2219
	sim_grads_norm_tr = 0.0471
-- Starting training on experience 140 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6508
	data_grads_norm = 5.4275
	new_data_grads_norm = 7.9875
	old_data_grads_norm = 7.7200
	sim_grads_norm_tr = -0.0163
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8194
	data_grads_norm = 5.6699
	new_data_grads_norm = 8.6156
	old_data_grads_norm = 7.6443
	sim_grads_norm_tr = -0.0309
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8961
	data_grads_norm = 6.1241
	new_data_grads_norm = 8.3825
	old_data_grads_norm = 7.4581
	sim_grads_norm_tr = 0.0067
-- Starting training on experience 141 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9254
	data_grads_norm = 4.2394
	new_data_grads_norm = 7.0681
	old_data_grads_norm = 4.3262
	sim_grads_norm_tr = -0.0335
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3805
	data_grads_norm = 5.3886
	new_data_grads_norm = 7.8218
	old_data_grads_norm = 7.1947
	sim_grads_norm_tr = -0.0275
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3651
	data_grads_norm = 5.0425
	new_data_grads_norm = 7.9539
	old_data_grads_norm = 6.2620
	sim_grads_norm_tr = -0.0309
-- Starting training on experience 142 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4163
	data_grads_norm = 5.5646
	new_data_grads_norm = 8.7893
	old_data_grads_norm = 6.3547
	sim_grads_norm_tr = 0.1074
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9333
	data_grads_norm = 4.3464
	new_data_grads_norm = 6.3587
	old_data_grads_norm = 5.9336
	sim_grads_norm_tr = 0.0008
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0563
	data_grads_norm = 6.1933
	new_data_grads_norm = 6.7784
	old_data_grads_norm = 9.6771
	sim_grads_norm_tr = 0.0529
-- Starting training on experience 143 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4066
	data_grads_norm = 4.6993
	new_data_grads_norm = 7.0097
	old_data_grads_norm = 5.6982
	sim_grads_norm_tr = -0.0389
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6311
	data_grads_norm = 6.2539
	new_data_grads_norm = 7.5997
	old_data_grads_norm = 8.8725
	sim_grads_norm_tr = -0.0079
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8855
	data_grads_norm = 5.5720
	new_data_grads_norm = 7.8320
	old_data_grads_norm = 7.9110
	sim_grads_norm_tr = 0.0229
-- Starting training on experience 144 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1085
	data_grads_norm = 4.9691
	new_data_grads_norm = 7.1396
	old_data_grads_norm = 7.0037
	sim_grads_norm_tr = 0.0257
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5957
	data_grads_norm = 5.1365
	new_data_grads_norm = 7.2530
	old_data_grads_norm = 5.6884
	sim_grads_norm_tr = 0.0478
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3643
	data_grads_norm = 4.9194
	new_data_grads_norm = 7.3761
	old_data_grads_norm = 5.4193
	sim_grads_norm_tr = -0.0166
-- Starting training on experience 145 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1532
	data_grads_norm = 5.1049
	new_data_grads_norm = 7.4898
	old_data_grads_norm = 5.9918
	sim_grads_norm_tr = 0.0285
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5905
	data_grads_norm = 6.0037
	new_data_grads_norm = 7.8248
	old_data_grads_norm = 8.7907
	sim_grads_norm_tr = 0.0011
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5942
	data_grads_norm = 6.1314
	new_data_grads_norm = 8.3704
	old_data_grads_norm = 8.2870
	sim_grads_norm_tr = -0.0148
-- Starting training on experience 146 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3270
	data_grads_norm = 5.1631
	new_data_grads_norm = 8.4816
	old_data_grads_norm = 8.1371
	sim_grads_norm_tr = -0.0345
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7143
	data_grads_norm = 6.3555
	new_data_grads_norm = 9.0882
	old_data_grads_norm = 8.2802
	sim_grads_norm_tr = -0.0255
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4784
	data_grads_norm = 6.2212
	new_data_grads_norm = 9.4492
	old_data_grads_norm = 6.2097
	sim_grads_norm_tr = 0.0293
-- Starting training on experience 147 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6011
	data_grads_norm = 5.9536
	new_data_grads_norm = 7.9594
	old_data_grads_norm = 8.0184
	sim_grads_norm_tr = -0.0235
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8775
	data_grads_norm = 4.7078
	new_data_grads_norm = 7.6453
	old_data_grads_norm = 4.7343
	sim_grads_norm_tr = -0.0193
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1991
	data_grads_norm = 5.1918
	new_data_grads_norm = 9.0522
	old_data_grads_norm = 6.0092
	sim_grads_norm_tr = 0.0055
-- Starting training on experience 148 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2238
	data_grads_norm = 5.2413
	new_data_grads_norm = 6.9328
	old_data_grads_norm = 5.1350
	sim_grads_norm_tr = -0.0226
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0408
	data_grads_norm = 5.5202
	new_data_grads_norm = 7.1731
	old_data_grads_norm = 6.2720
	sim_grads_norm_tr = 0.0067
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4590
	data_grads_norm = 5.5906
	new_data_grads_norm = 7.6115
	old_data_grads_norm = 7.3511
	sim_grads_norm_tr = 0.0491
-- Starting training on experience 149 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0880
	data_grads_norm = 4.6914
	new_data_grads_norm = 8.0584
	old_data_grads_norm = 5.2469
	sim_grads_norm_tr = -0.0179
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7347
	data_grads_norm = 6.2349
	new_data_grads_norm = 7.3404
	old_data_grads_norm = 8.7580
	sim_grads_norm_tr = 0.0873
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2891
	data_grads_norm = 5.5873
	new_data_grads_norm = 7.2679
	old_data_grads_norm = 8.2700
	sim_grads_norm_tr = 0.1059
-- Starting training on experience 150 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0228
	data_grads_norm = 4.6234
	new_data_grads_norm = 6.8903
	old_data_grads_norm = 5.6105
	sim_grads_norm_tr = 0.0045
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2594
	data_grads_norm = 4.9702
	new_data_grads_norm = 6.7226
	old_data_grads_norm = 7.4838
	sim_grads_norm_tr = 0.0081
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1511
	data_grads_norm = 5.3660
	new_data_grads_norm = 7.5381
	old_data_grads_norm = 6.7282
	sim_grads_norm_tr = 0.0078
-- Starting training on experience 151 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7561
	data_grads_norm = 4.5824
	new_data_grads_norm = 8.0378
	old_data_grads_norm = 5.2313
	sim_grads_norm_tr = -0.0006
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6749
	data_grads_norm = 5.6757
	new_data_grads_norm = 7.0378
	old_data_grads_norm = 9.1066
	sim_grads_norm_tr = 0.0438
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6282
	data_grads_norm = 5.2804
	new_data_grads_norm = 7.5001
	old_data_grads_norm = 7.4778
	sim_grads_norm_tr = 0.0666
-- Starting training on experience 152 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3922
	data_grads_norm = 5.0920
	new_data_grads_norm = 6.5574
	old_data_grads_norm = 7.4948
	sim_grads_norm_tr = -0.0050
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8777
	data_grads_norm = 4.5425
	new_data_grads_norm = 6.5378
	old_data_grads_norm = 6.7823
	sim_grads_norm_tr = -0.0065
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0785
	data_grads_norm = 4.8009
	new_data_grads_norm = 7.2380
	old_data_grads_norm = 6.7559
	sim_grads_norm_tr = -0.0352
-- Starting training on experience 153 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2874
	data_grads_norm = 5.9146
	new_data_grads_norm = 8.1242
	old_data_grads_norm = 7.2187
	sim_grads_norm_tr = 0.0173
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8425
	data_grads_norm = 4.6900
	new_data_grads_norm = 7.6944
	old_data_grads_norm = 6.6010
	sim_grads_norm_tr = -0.0048
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6381
	data_grads_norm = 5.9455
	new_data_grads_norm = 8.2834
	old_data_grads_norm = 7.2226
	sim_grads_norm_tr = 0.0440
-- Starting training on experience 154 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6381
	data_grads_norm = 5.8143
	new_data_grads_norm = 8.3678
	old_data_grads_norm = 7.5289
	sim_grads_norm_tr = 0.0514
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1940
	data_grads_norm = 5.8089
	new_data_grads_norm = 8.5270
	old_data_grads_norm = 7.4345
	sim_grads_norm_tr = 0.0185
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0483
	data_grads_norm = 5.4793
	new_data_grads_norm = 7.9428
	old_data_grads_norm = 6.9892
	sim_grads_norm_tr = 0.0350
-- Starting training on experience 155 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4691
	data_grads_norm = 5.3023
	new_data_grads_norm = 7.4833
	old_data_grads_norm = 7.3088
	sim_grads_norm_tr = -0.0390
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2880
	data_grads_norm = 5.4699
	new_data_grads_norm = 6.8596
	old_data_grads_norm = 7.4411
	sim_grads_norm_tr = 0.0323
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2097
	data_grads_norm = 5.0373
	new_data_grads_norm = 7.5653
	old_data_grads_norm = 6.1032
	sim_grads_norm_tr = 0.0290
-- Starting training on experience 156 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0282
	data_grads_norm = 5.4259
	new_data_grads_norm = 8.1547
	old_data_grads_norm = 6.7245
	sim_grads_norm_tr = -0.0453
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8247
	data_grads_norm = 5.1909
	new_data_grads_norm = 7.6733
	old_data_grads_norm = 7.9898
	sim_grads_norm_tr = 0.0336
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8908
	data_grads_norm = 4.6412
	new_data_grads_norm = 8.3576
	old_data_grads_norm = 7.1484
	sim_grads_norm_tr = -0.0456
-- Starting training on experience 157 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0081
	data_grads_norm = 4.9447
	new_data_grads_norm = 7.9621
	old_data_grads_norm = 5.7670
	sim_grads_norm_tr = 0.0443
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5439
	data_grads_norm = 5.4669
	new_data_grads_norm = 8.1827
	old_data_grads_norm = 6.7460
	sim_grads_norm_tr = 0.0792
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2297
	data_grads_norm = 5.6882
	new_data_grads_norm = 9.0728
	old_data_grads_norm = 5.8775
	sim_grads_norm_tr = 0.0139
-- Starting training on experience 158 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1373
	data_grads_norm = 5.1442
	new_data_grads_norm = 8.0952
	old_data_grads_norm = 6.3439
	sim_grads_norm_tr = -0.0250
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4030
	data_grads_norm = 5.4494
	new_data_grads_norm = 7.2452
	old_data_grads_norm = 8.0429
	sim_grads_norm_tr = 0.0128
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5052
	data_grads_norm = 5.4300
	new_data_grads_norm = 7.0024
	old_data_grads_norm = 7.8619
	sim_grads_norm_tr = 0.0101
-- Starting training on experience 159 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6168
	data_grads_norm = 5.4438
	new_data_grads_norm = 8.4350
	old_data_grads_norm = 6.1886
	sim_grads_norm_tr = -0.0280
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3915
	data_grads_norm = 4.8468
	new_data_grads_norm = 7.0376
	old_data_grads_norm = 5.7976
	sim_grads_norm_tr = -0.0261
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0951
	data_grads_norm = 4.2454
	new_data_grads_norm = 6.9666
	old_data_grads_norm = 5.3539
	sim_grads_norm_tr = 0.0051
-- Starting training on experience 160 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4209
	data_grads_norm = 5.7509
	new_data_grads_norm = 8.7707
	old_data_grads_norm = 7.4806
	sim_grads_norm_tr = 0.0053
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6472
	data_grads_norm = 5.6409
	new_data_grads_norm = 8.1348
	old_data_grads_norm = 6.4532
	sim_grads_norm_tr = 0.0135
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0404
	data_grads_norm = 4.6857
	new_data_grads_norm = 7.4447
	old_data_grads_norm = 6.6893
	sim_grads_norm_tr = 0.0307
-- Starting training on experience 161 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1574
	data_grads_norm = 6.0764
	new_data_grads_norm = 9.5343
	old_data_grads_norm = 7.1556
	sim_grads_norm_tr = -0.0316
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2980
	data_grads_norm = 6.0613
	new_data_grads_norm = 9.5010
	old_data_grads_norm = 8.5936
	sim_grads_norm_tr = -0.0371
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1285
	data_grads_norm = 5.9101
	new_data_grads_norm = 9.5760
	old_data_grads_norm = 8.8452
	sim_grads_norm_tr = -0.0207
-- Starting training on experience 162 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8895
	data_grads_norm = 6.0084
	new_data_grads_norm = 8.1888
	old_data_grads_norm = 6.9767
	sim_grads_norm_tr = 0.0094
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3477
	data_grads_norm = 5.1943
	new_data_grads_norm = 7.8069
	old_data_grads_norm = 7.8321
	sim_grads_norm_tr = -0.0035
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6416
	data_grads_norm = 5.3853
	new_data_grads_norm = 8.4397
	old_data_grads_norm = 6.5595
	sim_grads_norm_tr = 0.0241
-- Starting training on experience 163 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4557
	data_grads_norm = 5.6156
	new_data_grads_norm = 8.1489
	old_data_grads_norm = 7.0505
	sim_grads_norm_tr = 0.0380
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7411
	data_grads_norm = 5.9230
	new_data_grads_norm = 8.3351
	old_data_grads_norm = 5.6793
	sim_grads_norm_tr = -0.0031
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9468
	data_grads_norm = 6.0843
	new_data_grads_norm = 8.3647
	old_data_grads_norm = 7.3453
	sim_grads_norm_tr = 0.0471
-- Starting training on experience 164 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0068
	data_grads_norm = 6.0046
	new_data_grads_norm = 8.7052
	old_data_grads_norm = 8.5090
	sim_grads_norm_tr = 0.0021
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4473
	data_grads_norm = 5.2879
	new_data_grads_norm = 7.5866
	old_data_grads_norm = 6.6433
	sim_grads_norm_tr = 0.1008
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8896
	data_grads_norm = 4.3542
	new_data_grads_norm = 7.5145
	old_data_grads_norm = 5.8293
	sim_grads_norm_tr = 0.0344
-- Starting training on experience 165 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1608
	data_grads_norm = 5.5231
	new_data_grads_norm = 7.4480
	old_data_grads_norm = 6.8316
	sim_grads_norm_tr = 0.0442
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2981
	data_grads_norm = 5.7288
	new_data_grads_norm = 7.5670
	old_data_grads_norm = 8.1426
	sim_grads_norm_tr = 0.0277
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1304
	data_grads_norm = 4.9027
	new_data_grads_norm = 7.3142
	old_data_grads_norm = 5.7557
	sim_grads_norm_tr = 0.1058
-- Starting training on experience 166 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1459
	data_grads_norm = 5.2695
	new_data_grads_norm = 6.8853
	old_data_grads_norm = 8.0393
	sim_grads_norm_tr = -0.0353
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0412
	data_grads_norm = 4.8906
	new_data_grads_norm = 8.1942
	old_data_grads_norm = 5.4766
	sim_grads_norm_tr = 0.0389
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1733
	data_grads_norm = 5.0047
	new_data_grads_norm = 7.4093
	old_data_grads_norm = 5.6737
	sim_grads_norm_tr = 0.0253
-- Starting training on experience 167 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9720
	data_grads_norm = 5.3177
	new_data_grads_norm = 8.1319
	old_data_grads_norm = 7.5731
	sim_grads_norm_tr = -0.0122
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8341
	data_grads_norm = 4.5968
	new_data_grads_norm = 8.2478
	old_data_grads_norm = 8.3636
	sim_grads_norm_tr = -0.0294
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8072
	data_grads_norm = 4.6109
	new_data_grads_norm = 7.7403
	old_data_grads_norm = 4.8601
	sim_grads_norm_tr = -0.0104
-- Starting training on experience 168 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1323
	data_grads_norm = 4.2114
	new_data_grads_norm = 7.2161
	old_data_grads_norm = 5.3398
	sim_grads_norm_tr = 0.0010
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6139
	data_grads_norm = 5.5119
	new_data_grads_norm = 7.0342
	old_data_grads_norm = 5.1490
	sim_grads_norm_tr = 0.0279
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5515
	data_grads_norm = 5.3919
	new_data_grads_norm = 7.8132
	old_data_grads_norm = 7.2134
	sim_grads_norm_tr = -0.0395
-- Starting training on experience 169 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4598
	data_grads_norm = 5.4121
	new_data_grads_norm = 7.7349
	old_data_grads_norm = 7.0899
	sim_grads_norm_tr = -0.0163
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1595
	data_grads_norm = 5.4707
	new_data_grads_norm = 7.7041
	old_data_grads_norm = 6.6565
	sim_grads_norm_tr = -0.0007
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5405
	data_grads_norm = 4.6180
	new_data_grads_norm = 7.7536
	old_data_grads_norm = 4.0989
	sim_grads_norm_tr = -0.0161
-- Starting training on experience 170 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0807
	data_grads_norm = 4.7358
	new_data_grads_norm = 7.6510
	old_data_grads_norm = 5.0975
	sim_grads_norm_tr = -0.0048
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7367
	data_grads_norm = 5.4931
	new_data_grads_norm = 8.7266
	old_data_grads_norm = 5.9380
	sim_grads_norm_tr = 0.0737
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3341
	data_grads_norm = 4.6834
	new_data_grads_norm = 6.4898
	old_data_grads_norm = 5.2836
	sim_grads_norm_tr = 0.0418
-- Starting training on experience 171 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0840
	data_grads_norm = 4.5436
	new_data_grads_norm = 7.1750
	old_data_grads_norm = 4.9885
	sim_grads_norm_tr = 0.0239
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2453
	data_grads_norm = 4.0403
	new_data_grads_norm = 6.4545
	old_data_grads_norm = 5.8327
	sim_grads_norm_tr = -0.0008
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0531
	data_grads_norm = 4.9254
	new_data_grads_norm = 6.6100
	old_data_grads_norm = 6.4515
	sim_grads_norm_tr = 0.0477
-- Starting training on experience 172 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8786
	data_grads_norm = 5.1876
	new_data_grads_norm = 7.6089
	old_data_grads_norm = 6.5681
	sim_grads_norm_tr = 0.0397
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2621
	data_grads_norm = 4.3962
	new_data_grads_norm = 7.2834
	old_data_grads_norm = 5.4385
	sim_grads_norm_tr = -0.0314
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6612
	data_grads_norm = 5.4519
	new_data_grads_norm = 7.1801
	old_data_grads_norm = 8.4587
	sim_grads_norm_tr = 0.0520
-- Starting training on experience 173 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9686
	data_grads_norm = 5.4307
	new_data_grads_norm = 7.6773
	old_data_grads_norm = 7.9975
	sim_grads_norm_tr = 0.0246
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4061
	data_grads_norm = 5.4647
	new_data_grads_norm = 6.9758
	old_data_grads_norm = 8.4135
	sim_grads_norm_tr = -0.0129
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0688
	data_grads_norm = 5.6711
	new_data_grads_norm = 6.6792
	old_data_grads_norm = 8.4075
	sim_grads_norm_tr = -0.0314
-- Starting training on experience 174 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2148
	data_grads_norm = 4.7549
	new_data_grads_norm = 8.0542
	old_data_grads_norm = 5.2477
	sim_grads_norm_tr = 0.0635
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3009
	data_grads_norm = 4.8856
	new_data_grads_norm = 6.9870
	old_data_grads_norm = 6.7602
	sim_grads_norm_tr = 0.0029
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2802
	data_grads_norm = 4.8615
	new_data_grads_norm = 7.8402
	old_data_grads_norm = 5.4565
	sim_grads_norm_tr = 0.0838
-- Starting training on experience 175 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2321
	data_grads_norm = 5.1235
	new_data_grads_norm = 7.3253
	old_data_grads_norm = 6.8502
	sim_grads_norm_tr = -0.0105
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1370
	data_grads_norm = 4.7857
	new_data_grads_norm = 7.1931
	old_data_grads_norm = 5.4380
	sim_grads_norm_tr = -0.0058
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0527
	data_grads_norm = 4.6026
	new_data_grads_norm = 6.7400
	old_data_grads_norm = 6.7937
	sim_grads_norm_tr = 0.0052
-- Starting training on experience 176 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5766
	data_grads_norm = 4.4653
	new_data_grads_norm = 6.6047
	old_data_grads_norm = 5.9063
	sim_grads_norm_tr = 0.0238
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9842
	data_grads_norm = 6.0680
	new_data_grads_norm = 6.4666
	old_data_grads_norm = 7.9125
	sim_grads_norm_tr = 0.0346
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7168
	data_grads_norm = 4.3125
	new_data_grads_norm = 6.8375
	old_data_grads_norm = 5.9216
	sim_grads_norm_tr = -0.0219
-- Starting training on experience 177 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1051
	data_grads_norm = 5.0786
	new_data_grads_norm = 7.7467
	old_data_grads_norm = 6.6265
	sim_grads_norm_tr = 0.0253
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6247
	data_grads_norm = 4.9492
	new_data_grads_norm = 7.5655
	old_data_grads_norm = 6.2173
	sim_grads_norm_tr = 0.0250
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7243
	data_grads_norm = 4.7428
	new_data_grads_norm = 7.5297
	old_data_grads_norm = 6.9855
	sim_grads_norm_tr = -0.0040
-- Starting training on experience 178 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2630
	data_grads_norm = 5.2589
	new_data_grads_norm = 7.1444
	old_data_grads_norm = 7.3966
	sim_grads_norm_tr = 0.0042
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4962
	data_grads_norm = 3.6979
	new_data_grads_norm = 6.8167
	old_data_grads_norm = 4.7214
	sim_grads_norm_tr = -0.0226
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6693
	data_grads_norm = 4.8276
	new_data_grads_norm = 6.6333
	old_data_grads_norm = 6.9875
	sim_grads_norm_tr = -0.0383
-- Starting training on experience 179 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3141
	data_grads_norm = 5.6638
	new_data_grads_norm = 8.4097
	old_data_grads_norm = 7.0601
	sim_grads_norm_tr = -0.0364
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5457
	data_grads_norm = 5.4996
	new_data_grads_norm = 8.7377
	old_data_grads_norm = 7.9138
	sim_grads_norm_tr = -0.0063
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2703
	data_grads_norm = 5.6064
	new_data_grads_norm = 8.9185
	old_data_grads_norm = 6.8553
	sim_grads_norm_tr = 0.0039
-- Starting training on experience 180 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8361
	data_grads_norm = 4.9360
	new_data_grads_norm = 7.4289
	old_data_grads_norm = 4.8125
	sim_grads_norm_tr = -0.0009
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1343
	data_grads_norm = 5.5977
	new_data_grads_norm = 7.7224
	old_data_grads_norm = 7.7466
	sim_grads_norm_tr = -0.0318
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2656
	data_grads_norm = 5.7764
	new_data_grads_norm = 8.3029
	old_data_grads_norm = 6.8380
	sim_grads_norm_tr = -0.0514
-- Starting training on experience 181 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5603
	data_grads_norm = 5.6162
	new_data_grads_norm = 8.3500
	old_data_grads_norm = 6.4202
	sim_grads_norm_tr = 0.0198
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5237
	data_grads_norm = 5.2827
	new_data_grads_norm = 8.1208
	old_data_grads_norm = 6.7415
	sim_grads_norm_tr = 0.0032
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8057
	data_grads_norm = 5.6698
	new_data_grads_norm = 7.7480
	old_data_grads_norm = 7.6865
	sim_grads_norm_tr = 0.0201
-- Starting training on experience 182 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6739
	data_grads_norm = 5.4407
	new_data_grads_norm = 9.1832
	old_data_grads_norm = 5.7558
	sim_grads_norm_tr = -0.0192
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4309
	data_grads_norm = 5.0216
	new_data_grads_norm = 8.8345
	old_data_grads_norm = 4.6795
	sim_grads_norm_tr = 0.0240
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3579
	data_grads_norm = 4.8153
	new_data_grads_norm = 8.7011
	old_data_grads_norm = 4.6501
	sim_grads_norm_tr = -0.0205
-- Starting training on experience 183 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8294
	data_grads_norm = 6.6392
	new_data_grads_norm = 9.9848
	old_data_grads_norm = 7.7342
	sim_grads_norm_tr = -0.0348
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8019
	data_grads_norm = 6.2212
	new_data_grads_norm = 10.6202
	old_data_grads_norm = 6.5972
	sim_grads_norm_tr = 0.0435
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7471
	data_grads_norm = 6.5474
	new_data_grads_norm = 10.2258
	old_data_grads_norm = 6.8249
	sim_grads_norm_tr = -0.0079
-- Starting training on experience 184 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2609
	data_grads_norm = 5.3490
	new_data_grads_norm = 7.4964
	old_data_grads_norm = 5.8634
	sim_grads_norm_tr = -0.0202
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4286
	data_grads_norm = 6.0203
	new_data_grads_norm = 7.4188
	old_data_grads_norm = 7.4174
	sim_grads_norm_tr = 0.1305
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7711
	data_grads_norm = 4.3741
	new_data_grads_norm = 6.2321
	old_data_grads_norm = 5.6935
	sim_grads_norm_tr = -0.0197
-- Starting training on experience 185 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4849
	data_grads_norm = 5.9033
	new_data_grads_norm = 9.8120
	old_data_grads_norm = 6.3295
	sim_grads_norm_tr = -0.0080
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4150
	data_grads_norm = 5.3981
	new_data_grads_norm = 10.0129
	old_data_grads_norm = 7.2447
	sim_grads_norm_tr = -0.0262
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7602
	data_grads_norm = 5.8735
	new_data_grads_norm = 9.6168
	old_data_grads_norm = 6.7736
	sim_grads_norm_tr = 0.0079
-- Starting training on experience 186 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5381
	data_grads_norm = 5.4273
	new_data_grads_norm = 7.8549
	old_data_grads_norm = 6.6648
	sim_grads_norm_tr = 0.0760
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0652
	data_grads_norm = 5.4783
	new_data_grads_norm = 7.8733
	old_data_grads_norm = 5.6071
	sim_grads_norm_tr = -0.0210
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0847
	data_grads_norm = 5.4921
	new_data_grads_norm = 8.4579
	old_data_grads_norm = 7.5128
	sim_grads_norm_tr = 0.0162
-- Starting training on experience 187 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4789
	data_grads_norm = 6.9165
	new_data_grads_norm = 9.9296
	old_data_grads_norm = 8.5298
	sim_grads_norm_tr = -0.0019
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8299
	data_grads_norm = 5.6711
	new_data_grads_norm = 8.8717
	old_data_grads_norm = 6.1423
	sim_grads_norm_tr = -0.0035
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0453
	data_grads_norm = 5.9626
	new_data_grads_norm = 9.1009
	old_data_grads_norm = 6.2307
	sim_grads_norm_tr = 0.0983
-- Starting training on experience 188 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2922
	data_grads_norm = 5.7038
	new_data_grads_norm = 6.5258
	old_data_grads_norm = 7.6048
	sim_grads_norm_tr = 0.0724
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7171
	data_grads_norm = 3.8089
	new_data_grads_norm = 6.4419
	old_data_grads_norm = 4.8083
	sim_grads_norm_tr = -0.0636
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1930
	data_grads_norm = 5.3547
	new_data_grads_norm = 7.9946
	old_data_grads_norm = 6.2513
	sim_grads_norm_tr = 0.0705
-- Starting training on experience 189 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1076
	data_grads_norm = 4.3439
	new_data_grads_norm = 6.5524
	old_data_grads_norm = 4.3563
	sim_grads_norm_tr = 0.0051
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2538
	data_grads_norm = 5.2423
	new_data_grads_norm = 6.8018
	old_data_grads_norm = 6.8345
	sim_grads_norm_tr = -0.0346
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3611
	data_grads_norm = 4.9798
	new_data_grads_norm = 7.2620
	old_data_grads_norm = 5.8898
	sim_grads_norm_tr = 0.0007
-- Starting training on experience 190 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1904
	data_grads_norm = 5.0610
	new_data_grads_norm = 6.7108
	old_data_grads_norm = 7.6211
	sim_grads_norm_tr = 0.0240
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0307
	data_grads_norm = 4.7357
	new_data_grads_norm = 6.0366
	old_data_grads_norm = 6.7061
	sim_grads_norm_tr = -0.0139
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2183
	data_grads_norm = 5.2637
	new_data_grads_norm = 6.8068
	old_data_grads_norm = 6.7084
	sim_grads_norm_tr = 0.0169
-- Starting training on experience 191 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8712
	data_grads_norm = 4.6942
	new_data_grads_norm = 6.9559
	old_data_grads_norm = 5.4851
	sim_grads_norm_tr = 0.0319
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3245
	data_grads_norm = 5.5501
	new_data_grads_norm = 6.1954
	old_data_grads_norm = 7.7903
	sim_grads_norm_tr = 0.0836
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7690
	data_grads_norm = 4.3790
	new_data_grads_norm = 6.2733
	old_data_grads_norm = 5.8172
	sim_grads_norm_tr = 0.0083
-- Starting training on experience 192 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4278
	data_grads_norm = 5.3213
	new_data_grads_norm = 8.0211
	old_data_grads_norm = 7.2603
	sim_grads_norm_tr = -0.0143
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4660
	data_grads_norm = 5.2548
	new_data_grads_norm = 9.3038
	old_data_grads_norm = 6.4639
	sim_grads_norm_tr = 0.0122
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1820
	data_grads_norm = 5.6073
	new_data_grads_norm = 8.8458
	old_data_grads_norm = 8.4508
	sim_grads_norm_tr = 0.0124
-- Starting training on experience 193 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0142
	data_grads_norm = 5.3389
	new_data_grads_norm = 7.2509
	old_data_grads_norm = 8.5246
	sim_grads_norm_tr = -0.0230
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6219
	data_grads_norm = 6.5483
	new_data_grads_norm = 8.3364
	old_data_grads_norm = 10.1421
	sim_grads_norm_tr = 0.0430
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5656
	data_grads_norm = 4.0139
	new_data_grads_norm = 6.8435
	old_data_grads_norm = 5.7851
	sim_grads_norm_tr = -0.0172
-- Starting training on experience 194 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9024
	data_grads_norm = 6.2538
	new_data_grads_norm = 7.8576
	old_data_grads_norm = 8.2908
	sim_grads_norm_tr = 0.0296
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7732
	data_grads_norm = 4.7498
	new_data_grads_norm = 7.8320
	old_data_grads_norm = 5.7685
	sim_grads_norm_tr = -0.0510
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8618
	data_grads_norm = 4.9266
	new_data_grads_norm = 8.2244
	old_data_grads_norm = 6.3940
	sim_grads_norm_tr = -0.0041
-- Starting training on experience 195 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1455
	data_grads_norm = 4.9234
	new_data_grads_norm = 8.7299
	old_data_grads_norm = 4.3354
	sim_grads_norm_tr = 0.0502
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1543
	data_grads_norm = 4.9735
	new_data_grads_norm = 7.0526
	old_data_grads_norm = 6.3999
	sim_grads_norm_tr = -0.0204
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3047
	data_grads_norm = 5.7594
	new_data_grads_norm = 7.7907
	old_data_grads_norm = 7.6484
	sim_grads_norm_tr = 0.0014
-- Starting training on experience 196 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3321
	data_grads_norm = 6.3454
	new_data_grads_norm = 9.2486
	old_data_grads_norm = 7.6364
	sim_grads_norm_tr = 0.0706
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6071
	data_grads_norm = 5.9483
	new_data_grads_norm = 7.8044
	old_data_grads_norm = 6.5246
	sim_grads_norm_tr = 0.0601
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9248
	data_grads_norm = 5.0454
	new_data_grads_norm = 8.5992
	old_data_grads_norm = 5.1292
	sim_grads_norm_tr = 0.0251
-- Starting training on experience 197 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5507
	data_grads_norm = 5.6708
	new_data_grads_norm = 9.1379
	old_data_grads_norm = 6.6873
	sim_grads_norm_tr = 0.0330
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6395
	data_grads_norm = 6.3269
	new_data_grads_norm = 9.7780
	old_data_grads_norm = 7.9540
	sim_grads_norm_tr = -0.0073
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4305
	data_grads_norm = 6.1290
	new_data_grads_norm = 9.1620
	old_data_grads_norm = 8.0951
	sim_grads_norm_tr = 0.0017
-- Starting training on experience 198 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1648
	data_grads_norm = 6.0049
	new_data_grads_norm = 9.6975
	old_data_grads_norm = 5.9155
	sim_grads_norm_tr = 0.0783
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3846
	data_grads_norm = 6.3728
	new_data_grads_norm = 9.4993
	old_data_grads_norm = 6.9404
	sim_grads_norm_tr = -0.0121
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6529
	data_grads_norm = 4.6624
	new_data_grads_norm = 9.4806
	old_data_grads_norm = 4.6146
	sim_grads_norm_tr = -0.0671
-- Starting training on experience 199 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3371
	data_grads_norm = 5.8875
	new_data_grads_norm = 8.6938
	old_data_grads_norm = 5.2712
	sim_grads_norm_tr = 0.0251
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3707
	data_grads_norm = 5.7835
	new_data_grads_norm = 8.3055
	old_data_grads_norm = 7.0795
	sim_grads_norm_tr = 0.0721
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7661
	data_grads_norm = 5.6441
	new_data_grads_norm = 8.5668
	old_data_grads_norm = 5.1383
	sim_grads_norm_tr = 0.0154
-- Starting training on experience 200 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8021
	data_grads_norm = 5.3025
	new_data_grads_norm = 6.5476
	old_data_grads_norm = 7.1982
	sim_grads_norm_tr = -0.0356
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6576
	data_grads_norm = 4.4187
	new_data_grads_norm = 6.5262
	old_data_grads_norm = 7.0898
	sim_grads_norm_tr = -0.0620
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7596
	data_grads_norm = 4.6330
	new_data_grads_norm = 8.1121
	old_data_grads_norm = 6.5008
	sim_grads_norm_tr = -0.0353
-- Starting training on experience 201 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6409
	data_grads_norm = 6.2710
	new_data_grads_norm = 8.5279
	old_data_grads_norm = 8.6869
	sim_grads_norm_tr = 0.0295
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5288
	data_grads_norm = 6.2790
	new_data_grads_norm = 8.5338
	old_data_grads_norm = 7.4001
	sim_grads_norm_tr = -0.0138
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6336
	data_grads_norm = 4.5579
	new_data_grads_norm = 8.6416
	old_data_grads_norm = 5.1451
	sim_grads_norm_tr = -0.0359
-- Starting training on experience 202 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9042
	data_grads_norm = 4.4787
	new_data_grads_norm = 7.7954
	old_data_grads_norm = 5.0699
	sim_grads_norm_tr = 0.0562
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4573
	data_grads_norm = 5.1723
	new_data_grads_norm = 6.9298
	old_data_grads_norm = 6.7971
	sim_grads_norm_tr = 0.0329
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2601
	data_grads_norm = 4.9123
	new_data_grads_norm = 6.5037
	old_data_grads_norm = 6.5696
	sim_grads_norm_tr = -0.0025
-- Starting training on experience 203 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6570
	data_grads_norm = 6.1863
	new_data_grads_norm = 7.9112
	old_data_grads_norm = 8.3809
	sim_grads_norm_tr = 0.0485
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1183
	data_grads_norm = 5.6668
	new_data_grads_norm = 7.9804
	old_data_grads_norm = 7.5168
	sim_grads_norm_tr = -0.0074
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4056
	data_grads_norm = 5.6135
	new_data_grads_norm = 7.6061
	old_data_grads_norm = 8.1538
	sim_grads_norm_tr = -0.0145
-- Starting training on experience 204 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9332
	data_grads_norm = 5.8754
	new_data_grads_norm = 8.3144
	old_data_grads_norm = 6.8258
	sim_grads_norm_tr = -0.0007
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9923
	data_grads_norm = 5.2543
	new_data_grads_norm = 8.6080
	old_data_grads_norm = 4.6970
	sim_grads_norm_tr = 0.0166
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0869
	data_grads_norm = 5.0506
	new_data_grads_norm = 7.2364
	old_data_grads_norm = 7.4552
	sim_grads_norm_tr = 0.0092
-- Starting training on experience 205 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1379
	data_grads_norm = 6.6286
	new_data_grads_norm = 9.1056
	old_data_grads_norm = 7.3439
	sim_grads_norm_tr = -0.0012
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4899
	data_grads_norm = 5.4641
	new_data_grads_norm = 8.5761
	old_data_grads_norm = 6.0110
	sim_grads_norm_tr = 0.0238
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5544
	data_grads_norm = 6.2861
	new_data_grads_norm = 8.9465
	old_data_grads_norm = 8.3334
	sim_grads_norm_tr = 0.0803
-- Starting training on experience 206 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7566
	data_grads_norm = 4.9172
	new_data_grads_norm = 6.6291
	old_data_grads_norm = 7.8379
	sim_grads_norm_tr = -0.0700
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1473
	data_grads_norm = 4.7458
	new_data_grads_norm = 6.7456
	old_data_grads_norm = 7.4235
	sim_grads_norm_tr = -0.0156
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1366
	data_grads_norm = 5.7136
	new_data_grads_norm = 7.5051
	old_data_grads_norm = 8.3238
	sim_grads_norm_tr = 0.0116
-- Starting training on experience 207 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4554
	data_grads_norm = 5.7083
	new_data_grads_norm = 9.6583
	old_data_grads_norm = 5.0508
	sim_grads_norm_tr = 0.0662
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1290
	data_grads_norm = 5.2847
	new_data_grads_norm = 7.2858
	old_data_grads_norm = 7.2606
	sim_grads_norm_tr = 0.0008
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1482
	data_grads_norm = 5.9856
	new_data_grads_norm = 8.4919
	old_data_grads_norm = 5.8069
	sim_grads_norm_tr = 0.0827
-- Starting training on experience 208 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7221
	data_grads_norm = 4.4588
	new_data_grads_norm = 7.5218
	old_data_grads_norm = 4.8832
	sim_grads_norm_tr = -0.0320
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5649
	data_grads_norm = 4.7984
	new_data_grads_norm = 6.3781
	old_data_grads_norm = 5.2886
	sim_grads_norm_tr = 0.0093
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9841
	data_grads_norm = 5.1007
	new_data_grads_norm = 7.4495
	old_data_grads_norm = 7.1431
	sim_grads_norm_tr = 0.0265
-- Starting training on experience 209 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8028
	data_grads_norm = 5.8382
	new_data_grads_norm = 7.6245
	old_data_grads_norm = 7.2897
	sim_grads_norm_tr = 0.0347
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4245
	data_grads_norm = 4.6076
	new_data_grads_norm = 7.5296
	old_data_grads_norm = 5.5875
	sim_grads_norm_tr = -0.0215
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3065
	data_grads_norm = 4.9885
	new_data_grads_norm = 7.6532
	old_data_grads_norm = 6.2909
	sim_grads_norm_tr = 0.0259
-- Starting training on experience 210 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6902
	data_grads_norm = 6.0990
	new_data_grads_norm = 8.9500
	old_data_grads_norm = 8.0617
	sim_grads_norm_tr = -0.0212
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1499
	data_grads_norm = 5.3778
	new_data_grads_norm = 8.6301
	old_data_grads_norm = 7.2880
	sim_grads_norm_tr = 0.0055
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3591
	data_grads_norm = 6.0576
	new_data_grads_norm = 8.2319
	old_data_grads_norm = 6.1922
	sim_grads_norm_tr = 0.0812
-- Starting training on experience 211 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7509
	data_grads_norm = 4.8466
	new_data_grads_norm = 7.7482
	old_data_grads_norm = 5.8743
	sim_grads_norm_tr = -0.0108
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0375
	data_grads_norm = 5.8051
	new_data_grads_norm = 8.2104
	old_data_grads_norm = 9.3744
	sim_grads_norm_tr = -0.0221
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1002
	data_grads_norm = 5.0842
	new_data_grads_norm = 8.0612
	old_data_grads_norm = 6.2401
	sim_grads_norm_tr = -0.0226
-- Starting training on experience 212 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7413
	data_grads_norm = 5.1065
	new_data_grads_norm = 7.8572
	old_data_grads_norm = 7.1683
	sim_grads_norm_tr = -0.0362
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5824
	data_grads_norm = 4.5472
	new_data_grads_norm = 7.1495
	old_data_grads_norm = 6.9170
	sim_grads_norm_tr = 0.0150
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9083
	data_grads_norm = 5.1346
	new_data_grads_norm = 6.8133
	old_data_grads_norm = 6.3479
	sim_grads_norm_tr = -0.0017
-- Starting training on experience 213 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1244
	data_grads_norm = 5.4942
	new_data_grads_norm = 6.7261
	old_data_grads_norm = 8.0832
	sim_grads_norm_tr = 0.0532
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6411
	data_grads_norm = 6.3583
	new_data_grads_norm = 7.6825
	old_data_grads_norm = 8.5330
	sim_grads_norm_tr = -0.0206
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9014
	data_grads_norm = 6.1695
	new_data_grads_norm = 7.6016
	old_data_grads_norm = 9.9844
	sim_grads_norm_tr = -0.0148
-- Starting training on experience 214 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4567
	data_grads_norm = 4.2246
	new_data_grads_norm = 7.0411
	old_data_grads_norm = 4.3073
	sim_grads_norm_tr = -0.0058
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8038
	data_grads_norm = 4.8069
	new_data_grads_norm = 7.4541
	old_data_grads_norm = 5.4882
	sim_grads_norm_tr = 0.0269
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8742
	data_grads_norm = 5.1117
	new_data_grads_norm = 6.8076
	old_data_grads_norm = 7.5014
	sim_grads_norm_tr = -0.0414
-- Starting training on experience 215 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1880
	data_grads_norm = 5.0835
	new_data_grads_norm = 8.2435
	old_data_grads_norm = 5.1063
	sim_grads_norm_tr = 0.0148
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0136
	data_grads_norm = 5.0194
	new_data_grads_norm = 7.1308
	old_data_grads_norm = 6.7338
	sim_grads_norm_tr = 0.0255
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3385
	data_grads_norm = 5.3237
	new_data_grads_norm = 7.8193
	old_data_grads_norm = 6.0493
	sim_grads_norm_tr = 0.0143
-- Starting training on experience 216 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0313
	data_grads_norm = 6.0094
	new_data_grads_norm = 7.9572
	old_data_grads_norm = 6.8838
	sim_grads_norm_tr = 0.0168
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5512
	data_grads_norm = 5.7364
	new_data_grads_norm = 7.5922
	old_data_grads_norm = 8.5557
	sim_grads_norm_tr = -0.0287
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0980
	data_grads_norm = 6.5607
	new_data_grads_norm = 9.1441
	old_data_grads_norm = 9.1549
	sim_grads_norm_tr = 0.0065
-- Starting training on experience 217 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6426
	data_grads_norm = 5.5187
	new_data_grads_norm = 7.3654
	old_data_grads_norm = 7.3544
	sim_grads_norm_tr = -0.0142
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8201
	data_grads_norm = 4.5864
	new_data_grads_norm = 7.6992
	old_data_grads_norm = 7.2733
	sim_grads_norm_tr = -0.0040
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3235
	data_grads_norm = 5.4426
	new_data_grads_norm = 7.5253
	old_data_grads_norm = 6.5568
	sim_grads_norm_tr = -0.0033
-- Starting training on experience 218 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9678
	data_grads_norm = 5.5483
	new_data_grads_norm = 7.8224
	old_data_grads_norm = 8.0864
	sim_grads_norm_tr = 0.0260
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2087
	data_grads_norm = 4.7821
	new_data_grads_norm = 7.0385
	old_data_grads_norm = 6.0154
	sim_grads_norm_tr = -0.0370
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6634
	data_grads_norm = 5.6425
	new_data_grads_norm = 7.6516
	old_data_grads_norm = 7.9455
	sim_grads_norm_tr = -0.0087
-- Starting training on experience 219 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8934
	data_grads_norm = 6.1247
	new_data_grads_norm = 8.5988
	old_data_grads_norm = 9.3929
	sim_grads_norm_tr = -0.0053
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1232
	data_grads_norm = 4.7820
	new_data_grads_norm = 9.2125
	old_data_grads_norm = 6.0147
	sim_grads_norm_tr = -0.0334
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2471
	data_grads_norm = 5.1796
	new_data_grads_norm = 9.1708
	old_data_grads_norm = 6.0433
	sim_grads_norm_tr = 0.0241
-- Starting training on experience 220 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6374
	data_grads_norm = 3.9276
	new_data_grads_norm = 7.4443
	old_data_grads_norm = 3.3107
	sim_grads_norm_tr = 0.1216
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7490
	data_grads_norm = 4.1732
	new_data_grads_norm = 7.2334
	old_data_grads_norm = 5.5931
	sim_grads_norm_tr = -0.0263
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3310
	data_grads_norm = 5.2408
	new_data_grads_norm = 6.9245
	old_data_grads_norm = 7.0666
	sim_grads_norm_tr = 0.0568
-- Starting training on experience 221 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3799
	data_grads_norm = 5.8202
	new_data_grads_norm = 8.3734
	old_data_grads_norm = 6.7639
	sim_grads_norm_tr = 0.0387
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2574
	data_grads_norm = 4.9490
	new_data_grads_norm = 8.6819
	old_data_grads_norm = 4.8452
	sim_grads_norm_tr = 0.0771
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3540
	data_grads_norm = 6.0380
	new_data_grads_norm = 7.9327
	old_data_grads_norm = 8.1967
	sim_grads_norm_tr = -0.0468
-- Starting training on experience 222 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1621
	data_grads_norm = 5.3570
	new_data_grads_norm = 7.8939
	old_data_grads_norm = 6.7140
	sim_grads_norm_tr = 0.0063
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0386
	data_grads_norm = 5.4717
	new_data_grads_norm = 7.8418
	old_data_grads_norm = 8.5058
	sim_grads_norm_tr = -0.0126
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4739
	data_grads_norm = 5.6281
	new_data_grads_norm = 8.2199
	old_data_grads_norm = 7.4650
	sim_grads_norm_tr = 0.0156
-- Starting training on experience 223 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1129
	data_grads_norm = 5.1749
	new_data_grads_norm = 8.0222
	old_data_grads_norm = 5.9221
	sim_grads_norm_tr = -0.0563
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9857
	data_grads_norm = 4.9561
	new_data_grads_norm = 7.5302
	old_data_grads_norm = 6.9811
	sim_grads_norm_tr = -0.0288
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3022
	data_grads_norm = 5.1853
	new_data_grads_norm = 7.8790
	old_data_grads_norm = 7.0187
	sim_grads_norm_tr = -0.0076
-- Starting training on experience 224 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1808
	data_grads_norm = 5.4851
	new_data_grads_norm = 8.3959
	old_data_grads_norm = 6.0758
	sim_grads_norm_tr = 0.0067
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4012
	data_grads_norm = 6.1747
	new_data_grads_norm = 8.0585
	old_data_grads_norm = 7.9278
	sim_grads_norm_tr = 0.0188
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6227
	data_grads_norm = 5.9914
	new_data_grads_norm = 9.0985
	old_data_grads_norm = 7.1587
	sim_grads_norm_tr = 0.0611
-- Starting training on experience 225 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7005
	data_grads_norm = 6.0925
	new_data_grads_norm = 9.3157
	old_data_grads_norm = 6.4790
	sim_grads_norm_tr = 0.0412
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7928
	data_grads_norm = 5.8256
	new_data_grads_norm = 9.6372
	old_data_grads_norm = 6.7039
	sim_grads_norm_tr = -0.0032
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6446
	data_grads_norm = 5.9178
	new_data_grads_norm = 9.7057
	old_data_grads_norm = 7.3972
	sim_grads_norm_tr = -0.0350
-- Starting training on experience 226 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2059
	data_grads_norm = 5.2045
	new_data_grads_norm = 9.0700
	old_data_grads_norm = 6.4761
	sim_grads_norm_tr = -0.0445
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0303
	data_grads_norm = 5.1546
	new_data_grads_norm = 9.6722
	old_data_grads_norm = 7.0721
	sim_grads_norm_tr = -0.0424
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6702
	data_grads_norm = 7.3299
	new_data_grads_norm = 10.1119
	old_data_grads_norm = 10.0304
	sim_grads_norm_tr = 0.0085
-- Starting training on experience 227 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1995
	data_grads_norm = 5.9802
	new_data_grads_norm = 7.8272
	old_data_grads_norm = 10.7002
	sim_grads_norm_tr = -0.0271
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8451
	data_grads_norm = 5.3997
	new_data_grads_norm = 8.9280
	old_data_grads_norm = 6.0491
	sim_grads_norm_tr = -0.0217
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9356
	data_grads_norm = 4.9826
	new_data_grads_norm = 9.3155
	old_data_grads_norm = 5.7593
	sim_grads_norm_tr = -0.0019
-- Starting training on experience 228 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7763
	data_grads_norm = 4.4550
	new_data_grads_norm = 7.1671
	old_data_grads_norm = 5.5285
	sim_grads_norm_tr = -0.0200
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2652
	data_grads_norm = 5.7077
	new_data_grads_norm = 8.8535
	old_data_grads_norm = 7.4090
	sim_grads_norm_tr = 0.0128
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6202
	data_grads_norm = 5.5146
	new_data_grads_norm = 8.0050
	old_data_grads_norm = 7.9416
	sim_grads_norm_tr = 0.0195
-- Starting training on experience 229 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5485
	data_grads_norm = 5.5222
	new_data_grads_norm = 9.0397
	old_data_grads_norm = 7.1062
	sim_grads_norm_tr = -0.0247
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6199
	data_grads_norm = 6.1474
	new_data_grads_norm = 9.7545
	old_data_grads_norm = 6.8845
	sim_grads_norm_tr = 0.0099
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0461
	data_grads_norm = 4.8172
	new_data_grads_norm = 8.5608
	old_data_grads_norm = 5.5809
	sim_grads_norm_tr = -0.0475
-- Starting training on experience 230 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8370
	data_grads_norm = 5.3497
	new_data_grads_norm = 8.5666
	old_data_grads_norm = 7.3979
	sim_grads_norm_tr = -0.0007
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0945
	data_grads_norm = 5.4678
	new_data_grads_norm = 7.6187
	old_data_grads_norm = 6.3784
	sim_grads_norm_tr = 0.0088
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3573
	data_grads_norm = 5.4514
	new_data_grads_norm = 8.6211
	old_data_grads_norm = 5.6625
	sim_grads_norm_tr = 0.0322
-- Starting training on experience 231 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9544
	data_grads_norm = 5.5611
	new_data_grads_norm = 8.8537
	old_data_grads_norm = 7.3129
	sim_grads_norm_tr = 0.0216
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5074
	data_grads_norm = 6.0467
	new_data_grads_norm = 8.2900
	old_data_grads_norm = 8.3384
	sim_grads_norm_tr = 0.0113
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4960
	data_grads_norm = 5.4195
	new_data_grads_norm = 7.3510
	old_data_grads_norm = 6.0411
	sim_grads_norm_tr = 0.1217
-- Starting training on experience 232 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9872
	data_grads_norm = 4.6716
	new_data_grads_norm = 7.2798
	old_data_grads_norm = 6.4530
	sim_grads_norm_tr = 0.0849
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9531
	data_grads_norm = 4.6202
	new_data_grads_norm = 6.6906
	old_data_grads_norm = 6.3160
	sim_grads_norm_tr = 0.0599
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6072
	data_grads_norm = 4.6084
	new_data_grads_norm = 7.2089
	old_data_grads_norm = 7.4851
	sim_grads_norm_tr = -0.0234
-- Starting training on experience 233 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0964
	data_grads_norm = 4.8581
	new_data_grads_norm = 8.0267
	old_data_grads_norm = 5.6747
	sim_grads_norm_tr = -0.0242
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9472
	data_grads_norm = 4.9256
	new_data_grads_norm = 8.0039
	old_data_grads_norm = 5.5245
	sim_grads_norm_tr = -0.0130
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9275
	data_grads_norm = 4.8767
	new_data_grads_norm = 8.5726
	old_data_grads_norm = 4.6158
	sim_grads_norm_tr = -0.0409
-- Starting training on experience 234 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7532
	data_grads_norm = 6.0330
	new_data_grads_norm = 8.6547
	old_data_grads_norm = 6.2870
	sim_grads_norm_tr = 0.0024
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3723
	data_grads_norm = 5.3526
	new_data_grads_norm = 8.7495
	old_data_grads_norm = 5.5616
	sim_grads_norm_tr = -0.0322
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5713
	data_grads_norm = 6.6036
	new_data_grads_norm = 9.5904
	old_data_grads_norm = 7.5966
	sim_grads_norm_tr = 0.0400
-- Starting training on experience 235 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8947
	data_grads_norm = 5.0608
	new_data_grads_norm = 7.3457
	old_data_grads_norm = 6.3171
	sim_grads_norm_tr = 0.0474
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2728
	data_grads_norm = 5.4804
	new_data_grads_norm = 8.0224
	old_data_grads_norm = 6.2988
	sim_grads_norm_tr = -0.0043
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6433
	data_grads_norm = 4.8877
	new_data_grads_norm = 8.1141
	old_data_grads_norm = 6.9130
	sim_grads_norm_tr = -0.0448
-- Starting training on experience 236 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8398
	data_grads_norm = 6.0156
	new_data_grads_norm = 8.9522
	old_data_grads_norm = 7.7941
	sim_grads_norm_tr = 0.0055
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8855
	data_grads_norm = 5.1035
	new_data_grads_norm = 7.7583
	old_data_grads_norm = 5.7996
	sim_grads_norm_tr = 0.0522
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5860
	data_grads_norm = 6.4175
	new_data_grads_norm = 8.7221
	old_data_grads_norm = 8.3987
	sim_grads_norm_tr = -0.0340
-- Starting training on experience 237 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
-- >> End of training phase << --
-- >> Start of eval phase << --
-- Starting eval on experience 0 (Task 0) from test stream --
> Eval on experience 0 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp000 = 3.5274
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.2680
	mb_index = 3570
	time = 1304.6057
-- Starting eval on experience 1 (Task 0) from test stream --
> Eval on experience 1 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp001 = 3.2789
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.3920
-- Starting eval on experience 2 (Task 0) from test stream --
> Eval on experience 2 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp002 = 3.9172
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.2900
-- Starting eval on experience 3 (Task 0) from test stream --
> Eval on experience 3 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp003 = 2.6087
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.4600
-- Starting eval on experience 4 (Task 0) from test stream --
> Eval on experience 4 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp004 = 4.3522
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.2300
-- Starting eval on experience 5 (Task 0) from test stream --
> Eval on experience 5 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp005 = 3.1952
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.3320
-- Starting eval on experience 6 (Task 0) from test stream --
> Eval on experience 6 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp006 = 3.4131
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp006 = 0.2680
-- Starting eval on experience 7 (Task 0) from test stream --
> Eval on experience 7 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp007 = 3.3450
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp007 = 0.3460
-- Starting eval on experience 8 (Task 0) from test stream --
> Eval on experience 8 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp008 = 3.2107
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp008 = 0.3640
-- Starting eval on experience 9 (Task 0) from test stream --
> Eval on experience 9 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp009 = 3.2854
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp009 = 0.3040
-- Starting eval on experience 10 (Task 0) from test stream --
> Eval on experience 10 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp010 = 3.5265
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp010 = 0.2280
-- Starting eval on experience 11 (Task 0) from test stream --
> Eval on experience 11 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp011 = 3.0228
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp011 = 0.3140
-- Starting eval on experience 12 (Task 0) from test stream --
> Eval on experience 12 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp012 = 4.0998
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp012 = 0.1260
-- Starting eval on experience 13 (Task 0) from test stream --
> Eval on experience 13 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp013 = 2.6802
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp013 = 0.2760
-- Starting eval on experience 14 (Task 0) from test stream --
> Eval on experience 14 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp014 = 2.9924
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp014 = 0.1940
-- >> End of eval phase << --
	CumulativeAccuracy/eval_phase/test_stream/Exp000 = 0.7440
	CumulativeAccuracy/eval_phase/test_stream/Exp001 = 0.6870
	CumulativeAccuracy/eval_phase/test_stream/Exp002 = 0.5653
	CumulativeAccuracy/eval_phase/test_stream/Exp003 = 0.5195
	CumulativeAccuracy/eval_phase/test_stream/Exp004 = 0.4768
	CumulativeAccuracy/eval_phase/test_stream/Exp005 = 0.4387
	CumulativeAccuracy/eval_phase/test_stream/Exp006 = 0.4189
	CumulativeAccuracy/eval_phase/test_stream/Exp007 = 0.3992
	CumulativeAccuracy/eval_phase/test_stream/Exp008 = 0.3853
	CumulativeAccuracy/eval_phase/test_stream/Exp009 = 0.3746
	CumulativeAccuracy/eval_phase/test_stream/Exp010 = 0.3556
	CumulativeAccuracy/eval_phase/test_stream/Exp011 = 0.3465
	CumulativeAccuracy/eval_phase/test_stream/Exp012 = 0.3235
	CumulativeAccuracy/eval_phase/test_stream/Exp013 = 0.3057
	CumulativeAccuracy/eval_phase/test_stream/Exp014 = 0.2928
	Loss_Stream/eval_phase/test_stream/Task000 = 3.3637
	Top1_Acc_Stream/eval_phase/test_stream/Task000 = 0.2928
-- >> Start of training phase << --
-- Starting training on experience 0 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.0742
	data_grads_norm = 6.2916
	new_data_grads_norm = 9.0364
	old_data_grads_norm = 5.4210
	sim_grads_norm_tr = -0.0416
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5614
	data_grads_norm = 5.9883
	new_data_grads_norm = 8.8333
	old_data_grads_norm = 7.3016
	sim_grads_norm_tr = 0.0249
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.5602
	data_grads_norm = 7.6709
	new_data_grads_norm = 9.0552
	old_data_grads_norm = 9.1354
	sim_grads_norm_tr = -0.0069
-- Starting training on experience 1 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5910
	data_grads_norm = 5.5235
	new_data_grads_norm = 7.9782
	old_data_grads_norm = 6.6121
	sim_grads_norm_tr = 0.0317
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6445
	data_grads_norm = 5.8526
	new_data_grads_norm = 7.8786
	old_data_grads_norm = 7.4876
	sim_grads_norm_tr = 0.0058
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.7695
	data_grads_norm = 5.5168
	new_data_grads_norm = 8.1883
	old_data_grads_norm = 6.3132
	sim_grads_norm_tr = -0.0113
-- Starting training on experience 2 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.7892
	data_grads_norm = 5.7408
	new_data_grads_norm = 8.9240
	old_data_grads_norm = 4.7147
	sim_grads_norm_tr = 0.0658
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.7433
	data_grads_norm = 6.0866
	new_data_grads_norm = 8.8885
	old_data_grads_norm = 6.7798
	sim_grads_norm_tr = 0.0031
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6266
	data_grads_norm = 5.9396
	new_data_grads_norm = 9.3563
	old_data_grads_norm = 5.7945
	sim_grads_norm_tr = 0.0211
-- Starting training on experience 3 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.8069
	data_grads_norm = 6.2261
	new_data_grads_norm = 7.2813
	old_data_grads_norm = 8.1081
	sim_grads_norm_tr = 0.0185
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.8406
	data_grads_norm = 5.6703
	new_data_grads_norm = 8.1646
	old_data_grads_norm = 7.5656
	sim_grads_norm_tr = 0.0345
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.2819
	data_grads_norm = 6.8690
	new_data_grads_norm = 8.0174
	old_data_grads_norm = 7.4746
	sim_grads_norm_tr = -0.0172
-- Starting training on experience 4 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.7809
	data_grads_norm = 5.8815
	new_data_grads_norm = 9.1256
	old_data_grads_norm = 6.3451
	sim_grads_norm_tr = 0.0020
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.9420
	data_grads_norm = 6.6642
	new_data_grads_norm = 10.3422
	old_data_grads_norm = 6.6884
	sim_grads_norm_tr = 0.0316
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.7223
	data_grads_norm = 6.7058
	new_data_grads_norm = 9.8623
	old_data_grads_norm = 7.3440
	sim_grads_norm_tr = 0.0049
-- Starting training on experience 5 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5174
	data_grads_norm = 5.5095
	new_data_grads_norm = 8.0904
	old_data_grads_norm = 6.3252
	sim_grads_norm_tr = 0.0067
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.7853
	data_grads_norm = 5.9690
	new_data_grads_norm = 7.9955
	old_data_grads_norm = 7.7166
	sim_grads_norm_tr = 0.0658
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2015
	data_grads_norm = 4.7145
	new_data_grads_norm = 7.4592
	old_data_grads_norm = 5.4018
	sim_grads_norm_tr = -0.0392
-- Starting training on experience 6 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.8412
	data_grads_norm = 6.1902
	new_data_grads_norm = 8.7219
	old_data_grads_norm = 5.6913
	sim_grads_norm_tr = -0.0239
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.0363
	data_grads_norm = 6.3313
	new_data_grads_norm = 8.6091
	old_data_grads_norm = 6.1114
	sim_grads_norm_tr = 0.0546
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.8640
	data_grads_norm = 6.1483
	new_data_grads_norm = 7.7080
	old_data_grads_norm = 8.0519
	sim_grads_norm_tr = 0.0113
-- Starting training on experience 7 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.8868
	data_grads_norm = 5.9728
	new_data_grads_norm = 8.3505
	old_data_grads_norm = 6.9729
	sim_grads_norm_tr = 0.0459
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1404
	data_grads_norm = 5.8638
	new_data_grads_norm = 8.7008
	old_data_grads_norm = 4.8591
	sim_grads_norm_tr = 0.0132
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.1015
	data_grads_norm = 5.9892
	new_data_grads_norm = 8.4508
	old_data_grads_norm = 7.2800
	sim_grads_norm_tr = 0.0194
-- Starting training on experience 8 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5747
	data_grads_norm = 5.8054
	new_data_grads_norm = 9.2643
	old_data_grads_norm = 7.6966
	sim_grads_norm_tr = 0.0221
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.9621
	data_grads_norm = 6.5375
	new_data_grads_norm = 8.2191
	old_data_grads_norm = 8.4803
	sim_grads_norm_tr = 0.0136
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4623
	data_grads_norm = 6.0566
	new_data_grads_norm = 9.9508
	old_data_grads_norm = 7.2401
	sim_grads_norm_tr = -0.0490
-- Starting training on experience 9 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4954
	data_grads_norm = 5.7611
	new_data_grads_norm = 8.3576
	old_data_grads_norm = 7.4597
	sim_grads_norm_tr = 0.0458
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.8694
	data_grads_norm = 6.4968
	new_data_grads_norm = 7.1184
	old_data_grads_norm = 9.2089
	sim_grads_norm_tr = 0.0491
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.7283
	data_grads_norm = 6.3118
	new_data_grads_norm = 8.4928
	old_data_grads_norm = 7.5263
	sim_grads_norm_tr = 0.0782
-- Starting training on experience 10 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.8422
	data_grads_norm = 6.5036
	new_data_grads_norm = 8.4121
	old_data_grads_norm = 9.3188
	sim_grads_norm_tr = 0.0541
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5922
	data_grads_norm = 5.5842
	new_data_grads_norm = 8.5503
	old_data_grads_norm = 7.1077
	sim_grads_norm_tr = 0.0614
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3805
	data_grads_norm = 5.4216
	new_data_grads_norm = 8.4089
	old_data_grads_norm = 6.4456
	sim_grads_norm_tr = 0.0207
-- Starting training on experience 11 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2944
	data_grads_norm = 6.1915
	new_data_grads_norm = 7.6083
	old_data_grads_norm = 5.3697
	sim_grads_norm_tr = 0.0802
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9640
	data_grads_norm = 5.4281
	new_data_grads_norm = 8.0665
	old_data_grads_norm = 5.9344
	sim_grads_norm_tr = 0.0179
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9955
	data_grads_norm = 5.5161
	new_data_grads_norm = 7.7979
	old_data_grads_norm = 6.5466
	sim_grads_norm_tr = 0.0532
-- Starting training on experience 12 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4452
	data_grads_norm = 6.1733
	new_data_grads_norm = 10.7186
	old_data_grads_norm = 5.3809
	sim_grads_norm_tr = 0.0177
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8566
	data_grads_norm = 5.4776
	new_data_grads_norm = 8.8305
	old_data_grads_norm = 5.3325
	sim_grads_norm_tr = -0.0180
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4105
	data_grads_norm = 7.5713
	new_data_grads_norm = 9.5368
	old_data_grads_norm = 10.4826
	sim_grads_norm_tr = 0.0223
-- Starting training on experience 13 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7955
	data_grads_norm = 5.2284
	new_data_grads_norm = 7.0520
	old_data_grads_norm = 5.6587
	sim_grads_norm_tr = 0.0127
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0942
	data_grads_norm = 6.0737
	new_data_grads_norm = 7.9053
	old_data_grads_norm = 7.2495
	sim_grads_norm_tr = 0.0496
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6620
	data_grads_norm = 5.8706
	new_data_grads_norm = 7.6873
	old_data_grads_norm = 8.7686
	sim_grads_norm_tr = -0.0132
-- Starting training on experience 14 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1851
	data_grads_norm = 5.7882
	new_data_grads_norm = 8.2801
	old_data_grads_norm = 8.5564
	sim_grads_norm_tr = 0.0135
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9173
	data_grads_norm = 5.6004
	new_data_grads_norm = 8.5260
	old_data_grads_norm = 6.8920
	sim_grads_norm_tr = -0.0247
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6685
	data_grads_norm = 5.4265
	new_data_grads_norm = 9.1671
	old_data_grads_norm = 4.1134
	sim_grads_norm_tr = -0.0211
-- Starting training on experience 15 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4889
	data_grads_norm = 6.3554
	new_data_grads_norm = 8.5824
	old_data_grads_norm = 8.3143
	sim_grads_norm_tr = 0.0012
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0250
	data_grads_norm = 5.9757
	new_data_grads_norm = 9.4671
	old_data_grads_norm = 6.7383
	sim_grads_norm_tr = 0.0578
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8501
	data_grads_norm = 5.9878
	new_data_grads_norm = 8.4970
	old_data_grads_norm = 6.6765
	sim_grads_norm_tr = 0.0371
-- Starting training on experience 16 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7882
	data_grads_norm = 5.2531
	new_data_grads_norm = 8.1135
	old_data_grads_norm = 6.7349
	sim_grads_norm_tr = -0.0047
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8906
	data_grads_norm = 6.4580
	new_data_grads_norm = 7.8829
	old_data_grads_norm = 7.4804
	sim_grads_norm_tr = 0.0258
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8274
	data_grads_norm = 5.7734
	new_data_grads_norm = 8.5639
	old_data_grads_norm = 6.2875
	sim_grads_norm_tr = -0.0178
-- Starting training on experience 17 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6794
	data_grads_norm = 5.1311
	new_data_grads_norm = 8.4281
	old_data_grads_norm = 7.6041
	sim_grads_norm_tr = 0.0211
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7209
	data_grads_norm = 5.4765
	new_data_grads_norm = 7.9006
	old_data_grads_norm = 6.6250
	sim_grads_norm_tr = 0.0704
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2966
	data_grads_norm = 5.1703
	new_data_grads_norm = 7.9292
	old_data_grads_norm = 6.2929
	sim_grads_norm_tr = -0.0022
-- Starting training on experience 18 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3266
	data_grads_norm = 5.6087
	new_data_grads_norm = 7.7416
	old_data_grads_norm = 7.2818
	sim_grads_norm_tr = 0.0134
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7717
	data_grads_norm = 6.1642
	new_data_grads_norm = 8.0796
	old_data_grads_norm = 7.7939
	sim_grads_norm_tr = 0.0366
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0583
	data_grads_norm = 5.4834
	new_data_grads_norm = 7.2312
	old_data_grads_norm = 7.6937
	sim_grads_norm_tr = -0.0002
-- Starting training on experience 19 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1545
	data_grads_norm = 5.2860
	new_data_grads_norm = 8.7008
	old_data_grads_norm = 3.7569
	sim_grads_norm_tr = 0.0307
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4252
	data_grads_norm = 5.6485
	new_data_grads_norm = 8.3888
	old_data_grads_norm = 5.5084
	sim_grads_norm_tr = 0.0057
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1261
	data_grads_norm = 6.3955
	new_data_grads_norm = 8.8414
	old_data_grads_norm = 6.7918
	sim_grads_norm_tr = 0.0018
-- Starting training on experience 20 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.1698
	data_grads_norm = 6.5801
	new_data_grads_norm = 7.8885
	old_data_grads_norm = 9.9779
	sim_grads_norm_tr = 0.0360
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4754
	data_grads_norm = 5.4400
	new_data_grads_norm = 8.7464
	old_data_grads_norm = 6.1305
	sim_grads_norm_tr = -0.0231
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1731
	data_grads_norm = 5.7453
	new_data_grads_norm = 7.7604
	old_data_grads_norm = 7.6055
	sim_grads_norm_tr = 0.0184
-- Starting training on experience 21 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4023
	data_grads_norm = 5.0092
	new_data_grads_norm = 6.7383
	old_data_grads_norm = 6.3530
	sim_grads_norm_tr = 0.0078
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3984
	data_grads_norm = 5.4229
	new_data_grads_norm = 7.1686
	old_data_grads_norm = 7.9338
	sim_grads_norm_tr = -0.0076
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6123
	data_grads_norm = 5.3185
	new_data_grads_norm = 6.7880
	old_data_grads_norm = 6.3436
	sim_grads_norm_tr = 0.0714
-- Starting training on experience 22 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5274
	data_grads_norm = 5.2122
	new_data_grads_norm = 8.4602
	old_data_grads_norm = 5.1864
	sim_grads_norm_tr = 0.0485
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9035
	data_grads_norm = 6.1355
	new_data_grads_norm = 8.6836
	old_data_grads_norm = 8.5949
	sim_grads_norm_tr = -0.0068
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8121
	data_grads_norm = 6.4592
	new_data_grads_norm = 8.5075
	old_data_grads_norm = 9.5016
	sim_grads_norm_tr = -0.0175
-- Starting training on experience 23 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8630
	data_grads_norm = 6.0600
	new_data_grads_norm = 7.7272
	old_data_grads_norm = 8.2680
	sim_grads_norm_tr = -0.0148
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7977
	data_grads_norm = 5.8321
	new_data_grads_norm = 7.0601
	old_data_grads_norm = 6.9506
	sim_grads_norm_tr = -0.0083
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7696
	data_grads_norm = 5.5149
	new_data_grads_norm = 6.9205
	old_data_grads_norm = 6.8997
	sim_grads_norm_tr = 0.0132
-- Starting training on experience 24 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8241
	data_grads_norm = 5.6393
	new_data_grads_norm = 7.4200
	old_data_grads_norm = 6.5682
	sim_grads_norm_tr = 0.0574
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7170
	data_grads_norm = 5.2728
	new_data_grads_norm = 7.4141
	old_data_grads_norm = 7.0774
	sim_grads_norm_tr = -0.0053
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0476
	data_grads_norm = 6.3128
	new_data_grads_norm = 8.2152
	old_data_grads_norm = 8.4590
	sim_grads_norm_tr = 0.0035
-- Starting training on experience 25 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9984
	data_grads_norm = 6.6044
	new_data_grads_norm = 8.2986
	old_data_grads_norm = 8.4962
	sim_grads_norm_tr = -0.0010
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7342
	data_grads_norm = 5.3025
	new_data_grads_norm = 8.1875
	old_data_grads_norm = 5.5896
	sim_grads_norm_tr = 0.0634
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7598
	data_grads_norm = 5.9813
	new_data_grads_norm = 8.8388
	old_data_grads_norm = 7.8550
	sim_grads_norm_tr = -0.0070
-- Starting training on experience 26 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1961
	data_grads_norm = 6.5702
	new_data_grads_norm = 8.7622
	old_data_grads_norm = 8.4027
	sim_grads_norm_tr = 0.0047
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5247
	data_grads_norm = 5.6036
	new_data_grads_norm = 8.5188
	old_data_grads_norm = 5.8746
	sim_grads_norm_tr = -0.0333
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3000
	data_grads_norm = 6.9925
	new_data_grads_norm = 9.5855
	old_data_grads_norm = 8.3591
	sim_grads_norm_tr = 0.0325
-- Starting training on experience 27 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7035
	data_grads_norm = 5.8690
	new_data_grads_norm = 8.8051
	old_data_grads_norm = 6.2981
	sim_grads_norm_tr = 0.0505
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7185
	data_grads_norm = 4.9769
	new_data_grads_norm = 8.1201
	old_data_grads_norm = 5.5126
	sim_grads_norm_tr = -0.0150
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7456
	data_grads_norm = 5.3855
	new_data_grads_norm = 8.7457
	old_data_grads_norm = 6.1909
	sim_grads_norm_tr = 0.0238
-- Starting training on experience 28 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7957
	data_grads_norm = 4.5513
	new_data_grads_norm = 8.1030
	old_data_grads_norm = 4.5550
	sim_grads_norm_tr = 0.0026
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5406
	data_grads_norm = 5.6745
	new_data_grads_norm = 7.7955
	old_data_grads_norm = 6.8851
	sim_grads_norm_tr = 0.0250
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1097
	data_grads_norm = 4.5860
	new_data_grads_norm = 7.5958
	old_data_grads_norm = 5.8474
	sim_grads_norm_tr = -0.0200
-- Starting training on experience 29 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6530
	data_grads_norm = 6.0313
	new_data_grads_norm = 7.6092
	old_data_grads_norm = 7.4763
	sim_grads_norm_tr = 0.0283
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5294
	data_grads_norm = 5.6224
	new_data_grads_norm = 7.7980
	old_data_grads_norm = 7.4336
	sim_grads_norm_tr = 0.0513
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2558
	data_grads_norm = 5.1247
	new_data_grads_norm = 7.3752
	old_data_grads_norm = 5.4573
	sim_grads_norm_tr = 0.0408
-- Starting training on experience 30 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7770
	data_grads_norm = 5.7747
	new_data_grads_norm = 8.2642
	old_data_grads_norm = 5.3091
	sim_grads_norm_tr = 0.0477
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4248
	data_grads_norm = 4.9709
	new_data_grads_norm = 8.5524
	old_data_grads_norm = 5.3135
	sim_grads_norm_tr = 0.0995
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2654
	data_grads_norm = 5.5392
	new_data_grads_norm = 8.6915
	old_data_grads_norm = 4.9041
	sim_grads_norm_tr = 0.0078
-- Starting training on experience 31 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2430
	data_grads_norm = 5.1621
	new_data_grads_norm = 6.9416
	old_data_grads_norm = 6.9766
	sim_grads_norm_tr = 0.0269
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3471
	data_grads_norm = 5.7168
	new_data_grads_norm = 7.4670
	old_data_grads_norm = 7.6988
	sim_grads_norm_tr = -0.0056
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1244
	data_grads_norm = 5.4494
	new_data_grads_norm = 7.9739
	old_data_grads_norm = 7.1090
	sim_grads_norm_tr = -0.0076
-- Starting training on experience 32 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9182
	data_grads_norm = 4.7181
	new_data_grads_norm = 7.4262
	old_data_grads_norm = 6.2057
	sim_grads_norm_tr = 0.0546
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7903
	data_grads_norm = 4.6996
	new_data_grads_norm = 6.3942
	old_data_grads_norm = 5.6997
	sim_grads_norm_tr = 0.0291
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9523
	data_grads_norm = 4.8708
	new_data_grads_norm = 7.4404
	old_data_grads_norm = 5.1514
	sim_grads_norm_tr = 0.0625
-- Starting training on experience 33 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2491
	data_grads_norm = 4.7847
	new_data_grads_norm = 6.5908
	old_data_grads_norm = 7.1034
	sim_grads_norm_tr = 0.0210
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6003
	data_grads_norm = 4.5593
	new_data_grads_norm = 7.0417
	old_data_grads_norm = 5.4175
	sim_grads_norm_tr = -0.0231
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3529
	data_grads_norm = 5.1636
	new_data_grads_norm = 7.2338
	old_data_grads_norm = 6.6220
	sim_grads_norm_tr = -0.0291
-- Starting training on experience 34 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1704
	data_grads_norm = 5.0418
	new_data_grads_norm = 8.3662
	old_data_grads_norm = 6.5175
	sim_grads_norm_tr = -0.0101
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1099
	data_grads_norm = 5.7933
	new_data_grads_norm = 7.9340
	old_data_grads_norm = 7.6258
	sim_grads_norm_tr = 0.0229
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8904
	data_grads_norm = 5.4735
	new_data_grads_norm = 8.3377
	old_data_grads_norm = 6.1313
	sim_grads_norm_tr = -0.0021
-- Starting training on experience 35 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3772
	data_grads_norm = 5.4675
	new_data_grads_norm = 7.5143
	old_data_grads_norm = 8.6153
	sim_grads_norm_tr = 0.0355
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6387
	data_grads_norm = 4.6227
	new_data_grads_norm = 7.5680
	old_data_grads_norm = 5.8628
	sim_grads_norm_tr = -0.0008
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6376
	data_grads_norm = 5.0105
	new_data_grads_norm = 7.4802
	old_data_grads_norm = 5.6468
	sim_grads_norm_tr = -0.0212
-- Starting training on experience 36 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1777
	data_grads_norm = 5.5627
	new_data_grads_norm = 7.7460
	old_data_grads_norm = 6.6034
	sim_grads_norm_tr = -0.0415
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4770
	data_grads_norm = 6.0237
	new_data_grads_norm = 7.6608
	old_data_grads_norm = 7.1377
	sim_grads_norm_tr = 0.0071
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4799
	data_grads_norm = 6.1317
	new_data_grads_norm = 7.5245
	old_data_grads_norm = 8.2113
	sim_grads_norm_tr = -0.0185
-- Starting training on experience 37 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1075
	data_grads_norm = 5.4951
	new_data_grads_norm = 7.4486
	old_data_grads_norm = 6.7968
	sim_grads_norm_tr = 0.0618
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1047
	data_grads_norm = 5.6110
	new_data_grads_norm = 6.7153
	old_data_grads_norm = 7.7559
	sim_grads_norm_tr = 0.0365
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7307
	data_grads_norm = 4.4233
	new_data_grads_norm = 6.2629
	old_data_grads_norm = 4.9619
	sim_grads_norm_tr = -0.0012
-- Starting training on experience 38 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5439
	data_grads_norm = 4.5428
	new_data_grads_norm = 7.7751
	old_data_grads_norm = 5.6359
	sim_grads_norm_tr = -0.0095
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3814
	data_grads_norm = 5.5205
	new_data_grads_norm = 7.9561
	old_data_grads_norm = 7.1366
	sim_grads_norm_tr = 0.0495
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6061
	data_grads_norm = 4.7587
	new_data_grads_norm = 7.6826
	old_data_grads_norm = 5.6482
	sim_grads_norm_tr = -0.0159
-- Starting training on experience 39 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5474
	data_grads_norm = 4.6542
	new_data_grads_norm = 7.7861
	old_data_grads_norm = 4.9762
	sim_grads_norm_tr = 0.0091
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9305
	data_grads_norm = 5.0524
	new_data_grads_norm = 7.8962
	old_data_grads_norm = 6.1430
	sim_grads_norm_tr = 0.0726
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5811
	data_grads_norm = 5.4210
	new_data_grads_norm = 7.5130
	old_data_grads_norm = 7.5037
	sim_grads_norm_tr = 0.0390
-- Starting training on experience 40 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9580
	data_grads_norm = 5.7627
	new_data_grads_norm = 8.5680
	old_data_grads_norm = 7.1068
	sim_grads_norm_tr = 0.0123
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4924
	data_grads_norm = 6.8208
	new_data_grads_norm = 8.8412
	old_data_grads_norm = 7.8837
	sim_grads_norm_tr = -0.0056
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0448
	data_grads_norm = 5.1141
	new_data_grads_norm = 7.8912
	old_data_grads_norm = 6.4273
	sim_grads_norm_tr = 0.0408
-- Starting training on experience 41 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5342
	data_grads_norm = 5.0930
	new_data_grads_norm = 6.8452
	old_data_grads_norm = 6.6423
	sim_grads_norm_tr = -0.0370
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4868
	data_grads_norm = 4.7832
	new_data_grads_norm = 7.3844
	old_data_grads_norm = 5.1304
	sim_grads_norm_tr = -0.0139
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4026
	data_grads_norm = 4.9444
	new_data_grads_norm = 6.3268
	old_data_grads_norm = 6.8075
	sim_grads_norm_tr = -0.0335
-- Starting training on experience 42 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2650
	data_grads_norm = 5.3046
	new_data_grads_norm = 7.3361
	old_data_grads_norm = 8.0575
	sim_grads_norm_tr = 0.0054
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1740
	data_grads_norm = 5.3508
	new_data_grads_norm = 8.1824
	old_data_grads_norm = 6.9741
	sim_grads_norm_tr = -0.0213
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1583
	data_grads_norm = 5.1641
	new_data_grads_norm = 7.8273
	old_data_grads_norm = 5.3460
	sim_grads_norm_tr = -0.0159
-- Starting training on experience 43 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7331
	data_grads_norm = 4.9201
	new_data_grads_norm = 7.9723
	old_data_grads_norm = 5.7783
	sim_grads_norm_tr = -0.0395
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4874
	data_grads_norm = 5.0624
	new_data_grads_norm = 7.1112
	old_data_grads_norm = 6.2692
	sim_grads_norm_tr = -0.0118
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2719
	data_grads_norm = 5.1751
	new_data_grads_norm = 7.6165
	old_data_grads_norm = 6.9128
	sim_grads_norm_tr = 0.0622
-- Starting training on experience 44 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5174
	data_grads_norm = 5.5829
	new_data_grads_norm = 8.8817
	old_data_grads_norm = 6.6257
	sim_grads_norm_tr = 0.0584
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1617
	data_grads_norm = 5.6573
	new_data_grads_norm = 7.9515
	old_data_grads_norm = 7.8805
	sim_grads_norm_tr = 0.0141
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2182
	data_grads_norm = 6.3853
	new_data_grads_norm = 9.2647
	old_data_grads_norm = 8.6621
	sim_grads_norm_tr = 0.0049
-- Starting training on experience 45 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5073
	data_grads_norm = 4.5733
	new_data_grads_norm = 7.8824
	old_data_grads_norm = 4.4863
	sim_grads_norm_tr = -0.0193
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8867
	data_grads_norm = 5.9379
	new_data_grads_norm = 8.0229
	old_data_grads_norm = 9.2689
	sim_grads_norm_tr = -0.0136
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7264
	data_grads_norm = 5.2370
	new_data_grads_norm = 7.7145
	old_data_grads_norm = 6.6447
	sim_grads_norm_tr = 0.0088
-- Starting training on experience 46 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0540
	data_grads_norm = 5.3843
	new_data_grads_norm = 8.9328
	old_data_grads_norm = 6.4075
	sim_grads_norm_tr = -0.0100
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6320
	data_grads_norm = 6.2212
	new_data_grads_norm = 9.2972
	old_data_grads_norm = 7.9905
	sim_grads_norm_tr = 0.0134
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5326
	data_grads_norm = 5.4110
	new_data_grads_norm = 8.6126
	old_data_grads_norm = 5.8534
	sim_grads_norm_tr = 0.0196
-- Starting training on experience 47 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1524
	data_grads_norm = 5.8483
	new_data_grads_norm = 8.2747
	old_data_grads_norm = 6.4611
	sim_grads_norm_tr = -0.0052
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6894
	data_grads_norm = 4.5449
	new_data_grads_norm = 7.6516
	old_data_grads_norm = 5.1163
	sim_grads_norm_tr = -0.0301
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6291
	data_grads_norm = 4.9332
	new_data_grads_norm = 7.8430
	old_data_grads_norm = 5.4364
	sim_grads_norm_tr = -0.0487
-- Starting training on experience 48 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1704
	data_grads_norm = 5.3159
	new_data_grads_norm = 7.0502
	old_data_grads_norm = 6.4580
	sim_grads_norm_tr = 0.1065
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7129
	data_grads_norm = 4.9712
	new_data_grads_norm = 7.3051
	old_data_grads_norm = 7.6338
	sim_grads_norm_tr = -0.0023
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8282
	data_grads_norm = 5.5738
	new_data_grads_norm = 7.8307
	old_data_grads_norm = 6.0879
	sim_grads_norm_tr = -0.0256
-- Starting training on experience 49 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0316
	data_grads_norm = 6.3116
	new_data_grads_norm = 7.3572
	old_data_grads_norm = 9.1574
	sim_grads_norm_tr = 0.0114
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9381
	data_grads_norm = 5.5039
	new_data_grads_norm = 8.3403
	old_data_grads_norm = 5.9408
	sim_grads_norm_tr = 0.0360
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7173
	data_grads_norm = 5.3278
	new_data_grads_norm = 6.9407
	old_data_grads_norm = 7.3251
	sim_grads_norm_tr = 0.0273
-- Starting training on experience 50 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6229
	data_grads_norm = 5.6607
	new_data_grads_norm = 7.5879
	old_data_grads_norm = 8.2005
	sim_grads_norm_tr = -0.0206
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6527
	data_grads_norm = 4.8366
	new_data_grads_norm = 7.6251
	old_data_grads_norm = 6.3774
	sim_grads_norm_tr = -0.0221
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4489
	data_grads_norm = 5.3816
	new_data_grads_norm = 8.1497
	old_data_grads_norm = 6.6791
	sim_grads_norm_tr = 0.0016
-- Starting training on experience 51 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4307
	data_grads_norm = 4.1805
	new_data_grads_norm = 7.2792
	old_data_grads_norm = 5.5542
	sim_grads_norm_tr = -0.0138
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4075
	data_grads_norm = 4.3573
	new_data_grads_norm = 7.9751
	old_data_grads_norm = 5.3797
	sim_grads_norm_tr = 0.0003
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3318
	data_grads_norm = 6.8782
	new_data_grads_norm = 8.6171
	old_data_grads_norm = 8.3564
	sim_grads_norm_tr = 0.0212
-- Starting training on experience 52 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5686
	data_grads_norm = 6.9187
	new_data_grads_norm = 8.2565
	old_data_grads_norm = 9.8267
	sim_grads_norm_tr = -0.0499
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0742
	data_grads_norm = 5.5126
	new_data_grads_norm = 8.8140
	old_data_grads_norm = 7.5723
	sim_grads_norm_tr = 0.0163
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5128
	data_grads_norm = 5.1959
	new_data_grads_norm = 8.9052
	old_data_grads_norm = 6.1751
	sim_grads_norm_tr = 0.0213
-- Starting training on experience 53 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5215
	data_grads_norm = 6.4821
	new_data_grads_norm = 9.3679
	old_data_grads_norm = 7.0110
	sim_grads_norm_tr = 0.0158
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8846
	data_grads_norm = 5.7448
	new_data_grads_norm = 8.2668
	old_data_grads_norm = 8.1428
	sim_grads_norm_tr = 0.0098
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3540
	data_grads_norm = 5.8619
	new_data_grads_norm = 8.3178
	old_data_grads_norm = 7.0336
	sim_grads_norm_tr = 0.0307
-- Starting training on experience 54 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0498
	data_grads_norm = 5.4345
	new_data_grads_norm = 7.2007
	old_data_grads_norm = 7.7061
	sim_grads_norm_tr = 0.0437
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2042
	data_grads_norm = 5.9016
	new_data_grads_norm = 7.2128
	old_data_grads_norm = 7.4882
	sim_grads_norm_tr = 0.0227
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8219
	data_grads_norm = 5.0416
	new_data_grads_norm = 7.3755
	old_data_grads_norm = 5.3619
	sim_grads_norm_tr = 0.0580
-- Starting training on experience 55 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1735
	data_grads_norm = 5.7452
	new_data_grads_norm = 8.3917
	old_data_grads_norm = 9.5687
	sim_grads_norm_tr = 0.0041
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7221
	data_grads_norm = 6.0053
	new_data_grads_norm = 8.3421
	old_data_grads_norm = 6.4979
	sim_grads_norm_tr = 0.0930
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9299
	data_grads_norm = 5.6043
	new_data_grads_norm = 8.9412
	old_data_grads_norm = 7.1993
	sim_grads_norm_tr = -0.0506
-- Starting training on experience 56 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0889
	data_grads_norm = 5.0989
	new_data_grads_norm = 9.0635
	old_data_grads_norm = 4.7218
	sim_grads_norm_tr = 0.0539
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6929
	data_grads_norm = 5.0571
	new_data_grads_norm = 8.5016
	old_data_grads_norm = 5.3638
	sim_grads_norm_tr = -0.0358
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0003
	data_grads_norm = 6.2285
	new_data_grads_norm = 8.6745
	old_data_grads_norm = 7.2903
	sim_grads_norm_tr = 0.0054
-- Starting training on experience 57 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2480
	data_grads_norm = 5.2452
	new_data_grads_norm = 8.1318
	old_data_grads_norm = 6.4024
	sim_grads_norm_tr = -0.0044
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1665
	data_grads_norm = 5.9549
	new_data_grads_norm = 8.9738
	old_data_grads_norm = 7.4733
	sim_grads_norm_tr = 0.0244
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8974
	data_grads_norm = 6.1953
	new_data_grads_norm = 9.1074
	old_data_grads_norm = 7.1371
	sim_grads_norm_tr = 0.0723
-- Starting training on experience 58 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1498
	data_grads_norm = 4.2252
	new_data_grads_norm = 7.1836
	old_data_grads_norm = 6.1921
	sim_grads_norm_tr = 0.0140
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3021
	data_grads_norm = 5.5346
	new_data_grads_norm = 8.5515
	old_data_grads_norm = 8.1449
	sim_grads_norm_tr = 0.0263
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5647
	data_grads_norm = 4.8789
	new_data_grads_norm = 7.9811
	old_data_grads_norm = 7.6395
	sim_grads_norm_tr = 0.0446
-- Starting training on experience 59 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4348
	data_grads_norm = 4.8298
	new_data_grads_norm = 8.1514
	old_data_grads_norm = 5.4781
	sim_grads_norm_tr = -0.0213
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0062
	data_grads_norm = 4.4576
	new_data_grads_norm = 8.4079
	old_data_grads_norm = 4.9279
	sim_grads_norm_tr = -0.0254
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3689
	data_grads_norm = 5.1761
	new_data_grads_norm = 8.5005
	old_data_grads_norm = 5.0550
	sim_grads_norm_tr = 0.0741
-- Starting training on experience 60 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9641
	data_grads_norm = 6.6966
	new_data_grads_norm = 8.4341
	old_data_grads_norm = 6.3167
	sim_grads_norm_tr = -0.0235
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3981
	data_grads_norm = 5.9724
	new_data_grads_norm = 8.6083
	old_data_grads_norm = 5.9407
	sim_grads_norm_tr = -0.0267
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7438
	data_grads_norm = 6.8379
	new_data_grads_norm = 9.2982
	old_data_grads_norm = 8.4462
	sim_grads_norm_tr = -0.0331
-- Starting training on experience 61 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6616
	data_grads_norm = 4.6195
	new_data_grads_norm = 7.6744
	old_data_grads_norm = 5.1660
	sim_grads_norm_tr = -0.0289
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7634
	data_grads_norm = 5.0014
	new_data_grads_norm = 7.9190
	old_data_grads_norm = 7.5622
	sim_grads_norm_tr = -0.0323
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2812
	data_grads_norm = 6.2708
	new_data_grads_norm = 7.6239
	old_data_grads_norm = 8.1633
	sim_grads_norm_tr = -0.0088
-- Starting training on experience 62 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3682
	data_grads_norm = 4.5836
	new_data_grads_norm = 7.1171
	old_data_grads_norm = 4.1378
	sim_grads_norm_tr = -0.0253
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5592
	data_grads_norm = 4.3977
	new_data_grads_norm = 6.4753
	old_data_grads_norm = 6.1877
	sim_grads_norm_tr = -0.0292
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6675
	data_grads_norm = 4.9442
	new_data_grads_norm = 7.3849
	old_data_grads_norm = 4.8741
	sim_grads_norm_tr = -0.0167
-- Starting training on experience 63 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9097
	data_grads_norm = 6.4692
	new_data_grads_norm = 9.1036
	old_data_grads_norm = 7.1948
	sim_grads_norm_tr = 0.0019
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0229
	data_grads_norm = 6.2086
	new_data_grads_norm = 9.3015
	old_data_grads_norm = 7.7775
	sim_grads_norm_tr = -0.0033
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6097
	data_grads_norm = 5.0267
	new_data_grads_norm = 9.0798
	old_data_grads_norm = 4.8809
	sim_grads_norm_tr = 0.0621
-- Starting training on experience 64 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0647
	data_grads_norm = 5.9318
	new_data_grads_norm = 9.1721
	old_data_grads_norm = 6.5665
	sim_grads_norm_tr = -0.0159
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7726
	data_grads_norm = 5.2398
	new_data_grads_norm = 8.4860
	old_data_grads_norm = 4.8307
	sim_grads_norm_tr = 0.0462
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9675
	data_grads_norm = 6.0711
	new_data_grads_norm = 8.2699
	old_data_grads_norm = 8.6685
	sim_grads_norm_tr = 0.0357
-- Starting training on experience 65 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8502
	data_grads_norm = 5.7504
	new_data_grads_norm = 8.2482
	old_data_grads_norm = 6.9796
	sim_grads_norm_tr = 0.0064
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3399
	data_grads_norm = 5.0316
	new_data_grads_norm = 8.2998
	old_data_grads_norm = 5.8873
	sim_grads_norm_tr = -0.0137
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6747
	data_grads_norm = 5.8114
	new_data_grads_norm = 8.5118
	old_data_grads_norm = 7.4860
	sim_grads_norm_tr = -0.0018
-- Starting training on experience 66 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1735
	data_grads_norm = 5.6539
	new_data_grads_norm = 9.1188
	old_data_grads_norm = 6.6434
	sim_grads_norm_tr = 0.1324
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7103
	data_grads_norm = 5.5740
	new_data_grads_norm = 7.4812
	old_data_grads_norm = 6.6389
	sim_grads_norm_tr = 0.2029
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2264
	data_grads_norm = 5.2373
	new_data_grads_norm = 8.2276
	old_data_grads_norm = 8.2432
	sim_grads_norm_tr = 0.0246
-- Starting training on experience 67 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2670
	data_grads_norm = 4.0800
	new_data_grads_norm = 6.6306
	old_data_grads_norm = 5.9815
	sim_grads_norm_tr = 0.0104
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2261
	data_grads_norm = 4.6078
	new_data_grads_norm = 6.1556
	old_data_grads_norm = 7.7133
	sim_grads_norm_tr = -0.0089
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1307
	data_grads_norm = 5.2426
	new_data_grads_norm = 7.0676
	old_data_grads_norm = 8.2253
	sim_grads_norm_tr = 0.0101
-- Starting training on experience 68 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8115
	data_grads_norm = 4.7467
	new_data_grads_norm = 6.5851
	old_data_grads_norm = 6.0061
	sim_grads_norm_tr = 0.0148
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3019
	data_grads_norm = 4.2192
	new_data_grads_norm = 6.6719
	old_data_grads_norm = 4.8874
	sim_grads_norm_tr = -0.0069
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4833
	data_grads_norm = 4.1806
	new_data_grads_norm = 5.7501
	old_data_grads_norm = 5.5200
	sim_grads_norm_tr = -0.0176
-- Starting training on experience 69 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2586
	data_grads_norm = 4.8122
	new_data_grads_norm = 8.0881
	old_data_grads_norm = 4.5378
	sim_grads_norm_tr = 0.0716
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3576
	data_grads_norm = 5.3723
	new_data_grads_norm = 7.8965
	old_data_grads_norm = 6.6521
	sim_grads_norm_tr = -0.0216
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0160
	data_grads_norm = 5.1104
	new_data_grads_norm = 8.7321
	old_data_grads_norm = 6.1620
	sim_grads_norm_tr = -0.0215
-- Starting training on experience 70 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3235
	data_grads_norm = 5.3482
	new_data_grads_norm = 7.2761
	old_data_grads_norm = 7.0895
	sim_grads_norm_tr = 0.0047
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2514
	data_grads_norm = 4.8975
	new_data_grads_norm = 6.7922
	old_data_grads_norm = 6.6217
	sim_grads_norm_tr = -0.0056
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7683
	data_grads_norm = 5.4705
	new_data_grads_norm = 6.9888
	old_data_grads_norm = 7.2121
	sim_grads_norm_tr = -0.0252
-- Starting training on experience 71 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6161
	data_grads_norm = 5.1234
	new_data_grads_norm = 8.3608
	old_data_grads_norm = 5.8128
	sim_grads_norm_tr = 0.0139
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4933
	data_grads_norm = 6.7140
	new_data_grads_norm = 8.9232
	old_data_grads_norm = 9.0289
	sim_grads_norm_tr = 0.1063
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2620
	data_grads_norm = 4.6942
	new_data_grads_norm = 8.1765
	old_data_grads_norm = 6.5590
	sim_grads_norm_tr = -0.0269
-- Starting training on experience 72 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1155
	data_grads_norm = 5.5726
	new_data_grads_norm = 7.5108
	old_data_grads_norm = 6.9115
	sim_grads_norm_tr = 0.0169
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0859
	data_grads_norm = 4.5279
	new_data_grads_norm = 7.8067
	old_data_grads_norm = 4.6420
	sim_grads_norm_tr = -0.0100
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3130
	data_grads_norm = 4.9601
	new_data_grads_norm = 6.7835
	old_data_grads_norm = 6.2407
	sim_grads_norm_tr = -0.0143
-- Starting training on experience 73 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5491
	data_grads_norm = 5.6355
	new_data_grads_norm = 7.3696
	old_data_grads_norm = 7.4028
	sim_grads_norm_tr = 0.0157
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2097
	data_grads_norm = 4.6252
	new_data_grads_norm = 7.3374
	old_data_grads_norm = 6.9722
	sim_grads_norm_tr = -0.0216
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7250
	data_grads_norm = 6.0340
	new_data_grads_norm = 8.2799
	old_data_grads_norm = 8.9460
	sim_grads_norm_tr = 0.0189
-- Starting training on experience 74 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8102
	data_grads_norm = 5.4584
	new_data_grads_norm = 6.8563
	old_data_grads_norm = 7.5130
	sim_grads_norm_tr = -0.0239
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6324
	data_grads_norm = 5.9264
	new_data_grads_norm = 7.4322
	old_data_grads_norm = 8.9391
	sim_grads_norm_tr = -0.0082
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1950
	data_grads_norm = 4.5826
	new_data_grads_norm = 6.9253
	old_data_grads_norm = 5.1981
	sim_grads_norm_tr = -0.0144
-- Starting training on experience 75 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6700
	data_grads_norm = 5.0187
	new_data_grads_norm = 7.3301
	old_data_grads_norm = 6.1186
	sim_grads_norm_tr = 0.0455
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6053
	data_grads_norm = 4.7094
	new_data_grads_norm = 7.3579
	old_data_grads_norm = 4.8259
	sim_grads_norm_tr = 0.0262
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8789
	data_grads_norm = 5.4919
	new_data_grads_norm = 7.1365
	old_data_grads_norm = 8.6471
	sim_grads_norm_tr = 0.0148
-- Starting training on experience 76 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3947
	data_grads_norm = 5.1852
	new_data_grads_norm = 9.2409
	old_data_grads_norm = 4.9445
	sim_grads_norm_tr = -0.0246
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8853
	data_grads_norm = 6.2030
	new_data_grads_norm = 8.4922
	old_data_grads_norm = 9.0649
	sim_grads_norm_tr = 0.0130
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6779
	data_grads_norm = 5.8875
	new_data_grads_norm = 9.2754
	old_data_grads_norm = 6.2252
	sim_grads_norm_tr = 0.0347
-- Starting training on experience 77 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4928
	data_grads_norm = 5.8896
	new_data_grads_norm = 7.8834
	old_data_grads_norm = 7.3682
	sim_grads_norm_tr = 0.0686
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0468
	data_grads_norm = 6.2185
	new_data_grads_norm = 7.6484
	old_data_grads_norm = 8.0725
	sim_grads_norm_tr = 0.0060
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8938
	data_grads_norm = 4.1486
	new_data_grads_norm = 8.0007
	old_data_grads_norm = 3.7816
	sim_grads_norm_tr = -0.0554
-- Starting training on experience 78 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5005
	data_grads_norm = 5.4826
	new_data_grads_norm = 7.4161
	old_data_grads_norm = 6.6124
	sim_grads_norm_tr = 0.0055
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2020
	data_grads_norm = 5.0807
	new_data_grads_norm = 6.8698
	old_data_grads_norm = 4.6478
	sim_grads_norm_tr = 0.0471
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4599
	data_grads_norm = 5.3924
	new_data_grads_norm = 7.1618
	old_data_grads_norm = 6.4962
	sim_grads_norm_tr = 0.0572
-- Starting training on experience 79 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1779
	data_grads_norm = 4.3795
	new_data_grads_norm = 7.5660
	old_data_grads_norm = 5.6855
	sim_grads_norm_tr = -0.0354
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9603
	data_grads_norm = 6.1874
	new_data_grads_norm = 7.5744
	old_data_grads_norm = 9.2148
	sim_grads_norm_tr = -0.0028
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3756
	data_grads_norm = 5.3190
	new_data_grads_norm = 8.3035
	old_data_grads_norm = 4.9370
	sim_grads_norm_tr = -0.0045
-- Starting training on experience 80 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3377
	data_grads_norm = 5.0238
	new_data_grads_norm = 7.6600
	old_data_grads_norm = 4.9259
	sim_grads_norm_tr = -0.0294
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5262
	data_grads_norm = 5.2570
	new_data_grads_norm = 7.2464
	old_data_grads_norm = 7.3105
	sim_grads_norm_tr = 0.0531
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3457
	data_grads_norm = 5.5198
	new_data_grads_norm = 9.4716
	old_data_grads_norm = 6.4675
	sim_grads_norm_tr = -0.0497
-- Starting training on experience 81 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0309
	data_grads_norm = 4.6717
	new_data_grads_norm = 6.7380
	old_data_grads_norm = 7.1599
	sim_grads_norm_tr = -0.0083
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2471
	data_grads_norm = 4.7401
	new_data_grads_norm = 6.8844
	old_data_grads_norm = 7.3830
	sim_grads_norm_tr = -0.0253
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8249
	data_grads_norm = 5.6365
	new_data_grads_norm = 7.2845
	old_data_grads_norm = 7.4713
	sim_grads_norm_tr = -0.0010
-- Starting training on experience 82 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0030
	data_grads_norm = 6.4970
	new_data_grads_norm = 8.0235
	old_data_grads_norm = 7.9517
	sim_grads_norm_tr = -0.0444
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6895
	data_grads_norm = 5.8808
	new_data_grads_norm = 8.5725
	old_data_grads_norm = 7.5970
	sim_grads_norm_tr = -0.0299
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5689
	data_grads_norm = 6.7993
	new_data_grads_norm = 8.2850
	old_data_grads_norm = 8.4804
	sim_grads_norm_tr = 0.1160
-- Starting training on experience 83 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9613
	data_grads_norm = 5.8331
	new_data_grads_norm = 8.2513
	old_data_grads_norm = 7.5045
	sim_grads_norm_tr = 0.0844
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0940
	data_grads_norm = 5.2054
	new_data_grads_norm = 6.1963
	old_data_grads_norm = 8.2315
	sim_grads_norm_tr = -0.0375
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3048
	data_grads_norm = 5.2122
	new_data_grads_norm = 7.1132
	old_data_grads_norm = 6.5881
	sim_grads_norm_tr = 0.0067
-- Starting training on experience 84 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2478
	data_grads_norm = 4.8639
	new_data_grads_norm = 6.6792
	old_data_grads_norm = 6.5602
	sim_grads_norm_tr = 0.0858
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9828
	data_grads_norm = 5.1252
	new_data_grads_norm = 7.4075
	old_data_grads_norm = 7.0665
	sim_grads_norm_tr = 0.0054
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4426
	data_grads_norm = 5.3802
	new_data_grads_norm = 7.3100
	old_data_grads_norm = 8.9935
	sim_grads_norm_tr = 0.0210
-- Starting training on experience 85 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0829
	data_grads_norm = 4.5160
	new_data_grads_norm = 6.6590
	old_data_grads_norm = 5.6413
	sim_grads_norm_tr = -0.0092
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5143
	data_grads_norm = 4.7885
	new_data_grads_norm = 7.2117
	old_data_grads_norm = 5.8562
	sim_grads_norm_tr = 0.0319
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5752
	data_grads_norm = 5.5939
	new_data_grads_norm = 6.9940
	old_data_grads_norm = 6.7823
	sim_grads_norm_tr = -0.0222
-- Starting training on experience 86 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1016
	data_grads_norm = 4.5147
	new_data_grads_norm = 7.7995
	old_data_grads_norm = 6.7713
	sim_grads_norm_tr = -0.0141
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9287
	data_grads_norm = 5.4898
	new_data_grads_norm = 8.3120
	old_data_grads_norm = 7.3730
	sim_grads_norm_tr = -0.0445
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7545
	data_grads_norm = 5.4246
	new_data_grads_norm = 8.3212
	old_data_grads_norm = 6.2031
	sim_grads_norm_tr = 0.0041
-- Starting training on experience 87 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5898
	data_grads_norm = 5.3656
	new_data_grads_norm = 7.1827
	old_data_grads_norm = 8.5400
	sim_grads_norm_tr = 0.0002
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9763
	data_grads_norm = 3.9699
	new_data_grads_norm = 7.0280
	old_data_grads_norm = 4.6975
	sim_grads_norm_tr = 0.0009
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4426
	data_grads_norm = 5.5060
	new_data_grads_norm = 7.0609
	old_data_grads_norm = 7.1945
	sim_grads_norm_tr = -0.0117
-- Starting training on experience 88 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2637
	data_grads_norm = 4.9250
	new_data_grads_norm = 7.1242
	old_data_grads_norm = 7.0524
	sim_grads_norm_tr = 0.0007
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7159
	data_grads_norm = 5.4371
	new_data_grads_norm = 6.8224
	old_data_grads_norm = 8.9942
	sim_grads_norm_tr = 0.0488
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4163
	data_grads_norm = 5.3120
	new_data_grads_norm = 6.5366
	old_data_grads_norm = 9.0637
	sim_grads_norm_tr = -0.0048
-- Starting training on experience 89 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4002
	data_grads_norm = 5.7007
	new_data_grads_norm = 7.2098
	old_data_grads_norm = 8.6074
	sim_grads_norm_tr = -0.0216
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8263
	data_grads_norm = 5.6129
	new_data_grads_norm = 7.2861
	old_data_grads_norm = 7.6323
	sim_grads_norm_tr = 0.0909
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3274
	data_grads_norm = 5.7189
	new_data_grads_norm = 6.5956
	old_data_grads_norm = 6.7940
	sim_grads_norm_tr = 0.0546
-- Starting training on experience 90 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0235
	data_grads_norm = 4.6100
	new_data_grads_norm = 6.1278
	old_data_grads_norm = 6.7135
	sim_grads_norm_tr = 0.0022
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4917
	data_grads_norm = 4.4636
	new_data_grads_norm = 6.9985
	old_data_grads_norm = 6.3564
	sim_grads_norm_tr = 0.0213
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0773
	data_grads_norm = 4.0565
	new_data_grads_norm = 7.1743
	old_data_grads_norm = 5.6708
	sim_grads_norm_tr = -0.0204
-- Starting training on experience 91 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1411
	data_grads_norm = 6.3815
	new_data_grads_norm = 9.2798
	old_data_grads_norm = 7.5820
	sim_grads_norm_tr = -0.0203
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2390
	data_grads_norm = 5.9052
	new_data_grads_norm = 9.3760
	old_data_grads_norm = 6.0528
	sim_grads_norm_tr = 0.0445
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1396
	data_grads_norm = 5.8450
	new_data_grads_norm = 9.3808
	old_data_grads_norm = 5.3175
	sim_grads_norm_tr = 0.0468
-- Starting training on experience 92 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2034
	data_grads_norm = 5.5176
	new_data_grads_norm = 6.9189
	old_data_grads_norm = 6.6283
	sim_grads_norm_tr = -0.0543
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2608
	data_grads_norm = 4.5212
	new_data_grads_norm = 7.3414
	old_data_grads_norm = 6.1702
	sim_grads_norm_tr = -0.0343
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1641
	data_grads_norm = 5.0180
	new_data_grads_norm = 7.7127
	old_data_grads_norm = 5.7528
	sim_grads_norm_tr = 0.0048
-- Starting training on experience 93 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5891
	data_grads_norm = 5.5307
	new_data_grads_norm = 7.3596
	old_data_grads_norm = 6.8519
	sim_grads_norm_tr = -0.0301
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5082
	data_grads_norm = 5.9153
	new_data_grads_norm = 7.0300
	old_data_grads_norm = 6.3171
	sim_grads_norm_tr = 0.0156
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4926
	data_grads_norm = 5.3824
	new_data_grads_norm = 7.4764
	old_data_grads_norm = 6.5472
	sim_grads_norm_tr = 0.0125
-- Starting training on experience 94 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9905
	data_grads_norm = 4.2707
	new_data_grads_norm = 7.8018
	old_data_grads_norm = 3.4258
	sim_grads_norm_tr = 0.0345
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9875
	data_grads_norm = 4.5769
	new_data_grads_norm = 7.4007
	old_data_grads_norm = 5.5532
	sim_grads_norm_tr = 0.0070
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0487
	data_grads_norm = 4.4666
	new_data_grads_norm = 7.8078
	old_data_grads_norm = 4.1681
	sim_grads_norm_tr = -0.0764
-- Starting training on experience 95 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2141
	data_grads_norm = 4.6386
	new_data_grads_norm = 7.5383
	old_data_grads_norm = 5.9676
	sim_grads_norm_tr = -0.0209
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0639
	data_grads_norm = 4.3505
	new_data_grads_norm = 7.5541
	old_data_grads_norm = 6.5965
	sim_grads_norm_tr = -0.0481
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2613
	data_grads_norm = 6.7843
	new_data_grads_norm = 7.8839
	old_data_grads_norm = 10.3546
	sim_grads_norm_tr = 0.0427
-- Starting training on experience 96 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7322
	data_grads_norm = 5.5897
	new_data_grads_norm = 8.4279
	old_data_grads_norm = 5.1619
	sim_grads_norm_tr = 0.0990
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4612
	data_grads_norm = 5.9442
	new_data_grads_norm = 8.5353
	old_data_grads_norm = 8.7670
	sim_grads_norm_tr = -0.0191
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7066
	data_grads_norm = 5.8918
	new_data_grads_norm = 8.0841
	old_data_grads_norm = 7.1215
	sim_grads_norm_tr = 0.0239
-- Starting training on experience 97 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8173
	data_grads_norm = 5.8559
	new_data_grads_norm = 8.0215
	old_data_grads_norm = 8.4312
	sim_grads_norm_tr = -0.0327
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4595
	data_grads_norm = 5.3109
	new_data_grads_norm = 7.5155
	old_data_grads_norm = 5.7368
	sim_grads_norm_tr = 0.0018
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4292
	data_grads_norm = 5.0408
	new_data_grads_norm = 9.1971
	old_data_grads_norm = 5.1788
	sim_grads_norm_tr = 0.0452
-- Starting training on experience 98 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7738
	data_grads_norm = 5.4699
	new_data_grads_norm = 7.4212
	old_data_grads_norm = 7.0552
	sim_grads_norm_tr = -0.0241
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0991
	data_grads_norm = 4.2559
	new_data_grads_norm = 7.0053
	old_data_grads_norm = 5.5437
	sim_grads_norm_tr = -0.0012
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2716
	data_grads_norm = 4.9368
	new_data_grads_norm = 7.5201
	old_data_grads_norm = 9.5987
	sim_grads_norm_tr = 0.0116
-- Starting training on experience 99 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3943
	data_grads_norm = 5.3577
	new_data_grads_norm = 7.7282
	old_data_grads_norm = 7.2636
	sim_grads_norm_tr = -0.0750
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2234
	data_grads_norm = 4.9638
	new_data_grads_norm = 9.3742
	old_data_grads_norm = 7.5741
	sim_grads_norm_tr = -0.0463
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3652
	data_grads_norm = 5.1641
	new_data_grads_norm = 8.8298
	old_data_grads_norm = 6.5736
	sim_grads_norm_tr = 0.0291
-- Starting training on experience 100 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3393
	data_grads_norm = 6.2334
	new_data_grads_norm = 7.6657
	old_data_grads_norm = 9.0643
	sim_grads_norm_tr = -0.0733
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7492
	data_grads_norm = 5.1600
	new_data_grads_norm = 8.0642
	old_data_grads_norm = 6.4725
	sim_grads_norm_tr = -0.0094
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4142
	data_grads_norm = 5.9960
	new_data_grads_norm = 8.3239
	old_data_grads_norm = 8.0906
	sim_grads_norm_tr = 0.0050
-- Starting training on experience 101 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2002
	data_grads_norm = 4.9456
	new_data_grads_norm = 7.2537
	old_data_grads_norm = 7.5158
	sim_grads_norm_tr = 0.0489
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6765
	data_grads_norm = 5.6741
	new_data_grads_norm = 6.4200
	old_data_grads_norm = 8.7349
	sim_grads_norm_tr = 0.0134
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2800
	data_grads_norm = 6.3321
	new_data_grads_norm = 6.8905
	old_data_grads_norm = 9.6677
	sim_grads_norm_tr = 0.0479
-- Starting training on experience 102 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1771
	data_grads_norm = 5.5902
	new_data_grads_norm = 7.4008
	old_data_grads_norm = 7.0319
	sim_grads_norm_tr = 0.0156
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7399
	data_grads_norm = 6.3950
	new_data_grads_norm = 8.0936
	old_data_grads_norm = 7.5643
	sim_grads_norm_tr = 0.0670
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4082
	data_grads_norm = 6.1114
	new_data_grads_norm = 8.5042
	old_data_grads_norm = 6.7545
	sim_grads_norm_tr = -0.0164
-- Starting training on experience 103 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3226
	data_grads_norm = 5.4028
	new_data_grads_norm = 8.6083
	old_data_grads_norm = 5.2779
	sim_grads_norm_tr = 0.0470
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3646
	data_grads_norm = 4.8890
	new_data_grads_norm = 7.2206
	old_data_grads_norm = 4.7187
	sim_grads_norm_tr = -0.0229
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5646
	data_grads_norm = 5.3159
	new_data_grads_norm = 7.1830
	old_data_grads_norm = 6.5947
	sim_grads_norm_tr = 0.0179
-- Starting training on experience 104 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2055
	data_grads_norm = 5.0471
	new_data_grads_norm = 7.2012
	old_data_grads_norm = 6.9523
	sim_grads_norm_tr = -0.0263
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4584
	data_grads_norm = 5.8128
	new_data_grads_norm = 7.1522
	old_data_grads_norm = 6.9700
	sim_grads_norm_tr = 0.0447
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8033
	data_grads_norm = 4.3200
	new_data_grads_norm = 6.6507
	old_data_grads_norm = 4.3717
	sim_grads_norm_tr = 0.0125
-- Starting training on experience 105 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6327
	data_grads_norm = 5.5910
	new_data_grads_norm = 6.4591
	old_data_grads_norm = 6.7401
	sim_grads_norm_tr = 0.1375
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0244
	data_grads_norm = 4.7377
	new_data_grads_norm = 6.3664
	old_data_grads_norm = 7.4701
	sim_grads_norm_tr = -0.0462
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3903
	data_grads_norm = 4.0449
	new_data_grads_norm = 7.6793
	old_data_grads_norm = 3.7116
	sim_grads_norm_tr = 0.0094
-- Starting training on experience 106 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4090
	data_grads_norm = 5.1942
	new_data_grads_norm = 7.0817
	old_data_grads_norm = 7.3045
	sim_grads_norm_tr = 0.0177
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5851
	data_grads_norm = 5.5696
	new_data_grads_norm = 6.9570
	old_data_grads_norm = 8.4405
	sim_grads_norm_tr = -0.0310
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1657
	data_grads_norm = 5.0776
	new_data_grads_norm = 6.6924
	old_data_grads_norm = 8.4196
	sim_grads_norm_tr = -0.0331
-- Starting training on experience 107 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8893
	data_grads_norm = 5.3619
	new_data_grads_norm = 7.5828
	old_data_grads_norm = 5.9546
	sim_grads_norm_tr = -0.0119
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6298
	data_grads_norm = 4.5933
	new_data_grads_norm = 7.0029
	old_data_grads_norm = 5.6750
	sim_grads_norm_tr = 0.0715
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9758
	data_grads_norm = 5.5661
	new_data_grads_norm = 7.4334
	old_data_grads_norm = 6.7456
	sim_grads_norm_tr = 0.1345
-- Starting training on experience 108 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3151
	data_grads_norm = 5.0823
	new_data_grads_norm = 7.3868
	old_data_grads_norm = 6.6292
	sim_grads_norm_tr = -0.0121
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4995
	data_grads_norm = 5.3613
	new_data_grads_norm = 7.0301
	old_data_grads_norm = 6.3046
	sim_grads_norm_tr = -0.0045
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7810
	data_grads_norm = 5.7210
	new_data_grads_norm = 7.2734
	old_data_grads_norm = 7.1335
	sim_grads_norm_tr = 0.0158
-- Starting training on experience 109 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5672
	data_grads_norm = 3.8788
	new_data_grads_norm = 6.3153
	old_data_grads_norm = 5.2834
	sim_grads_norm_tr = -0.0250
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1042
	data_grads_norm = 5.0777
	new_data_grads_norm = 7.5199
	old_data_grads_norm = 6.4873
	sim_grads_norm_tr = -0.0126
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9839
	data_grads_norm = 5.4179
	new_data_grads_norm = 6.8543
	old_data_grads_norm = 5.3748
	sim_grads_norm_tr = -0.0102
-- Starting training on experience 110 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2521
	data_grads_norm = 5.3281
	new_data_grads_norm = 7.5445
	old_data_grads_norm = 7.2298
	sim_grads_norm_tr = -0.0117
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1916
	data_grads_norm = 4.8868
	new_data_grads_norm = 6.8287
	old_data_grads_norm = 6.4612
	sim_grads_norm_tr = 0.0191
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8459
	data_grads_norm = 3.9820
	new_data_grads_norm = 7.5176
	old_data_grads_norm = 4.7532
	sim_grads_norm_tr = -0.0580
-- Starting training on experience 111 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9104
	data_grads_norm = 6.5511
	new_data_grads_norm = 8.7010
	old_data_grads_norm = 8.4321
	sim_grads_norm_tr = -0.0024
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2553
	data_grads_norm = 5.4936
	new_data_grads_norm = 7.7456
	old_data_grads_norm = 6.6868
	sim_grads_norm_tr = 0.0141
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0569
	data_grads_norm = 4.7145
	new_data_grads_norm = 8.6354
	old_data_grads_norm = 5.7403
	sim_grads_norm_tr = -0.0251
-- Starting training on experience 112 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0770
	data_grads_norm = 6.3880
	new_data_grads_norm = 8.9886
	old_data_grads_norm = 8.5428
	sim_grads_norm_tr = 0.0171
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6880
	data_grads_norm = 5.0366
	new_data_grads_norm = 7.9070
	old_data_grads_norm = 6.5770
	sim_grads_norm_tr = 0.0609
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4511
	data_grads_norm = 5.0984
	new_data_grads_norm = 7.8086
	old_data_grads_norm = 4.9651
	sim_grads_norm_tr = 0.0440
-- Starting training on experience 113 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1249
	data_grads_norm = 6.9891
	new_data_grads_norm = 7.3511
	old_data_grads_norm = 11.0054
	sim_grads_norm_tr = -0.0046
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5427
	data_grads_norm = 5.0429
	new_data_grads_norm = 7.7927
	old_data_grads_norm = 5.6232
	sim_grads_norm_tr = -0.0159
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8600
	data_grads_norm = 5.5858
	new_data_grads_norm = 7.8589
	old_data_grads_norm = 7.0838
	sim_grads_norm_tr = 0.0131
-- Starting training on experience 114 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1247
	data_grads_norm = 5.1480
	new_data_grads_norm = 8.2405
	old_data_grads_norm = 6.1443
	sim_grads_norm_tr = -0.0106
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2868
	data_grads_norm = 5.5753
	new_data_grads_norm = 7.8214
	old_data_grads_norm = 6.6540
	sim_grads_norm_tr = -0.0129
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0693
	data_grads_norm = 6.5789
	new_data_grads_norm = 9.1441
	old_data_grads_norm = 6.9776
	sim_grads_norm_tr = 0.0490
-- Starting training on experience 115 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0230
	data_grads_norm = 5.8771
	new_data_grads_norm = 6.3884
	old_data_grads_norm = 9.1613
	sim_grads_norm_tr = 0.0141
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7762
	data_grads_norm = 5.8325
	new_data_grads_norm = 7.0048
	old_data_grads_norm = 8.2929
	sim_grads_norm_tr = -0.0170
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3244
	data_grads_norm = 5.0597
	new_data_grads_norm = 7.6337
	old_data_grads_norm = 6.3741
	sim_grads_norm_tr = 0.0463
-- Starting training on experience 116 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2102
	data_grads_norm = 5.3743
	new_data_grads_norm = 7.9506
	old_data_grads_norm = 7.3552
	sim_grads_norm_tr = 0.0114
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6129
	data_grads_norm = 5.3603
	new_data_grads_norm = 8.1007
	old_data_grads_norm = 5.8861
	sim_grads_norm_tr = 0.0323
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5315
	data_grads_norm = 6.1830
	new_data_grads_norm = 8.1907
	old_data_grads_norm = 7.5788
	sim_grads_norm_tr = 0.0314
-- Starting training on experience 117 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4788
	data_grads_norm = 5.7557
	new_data_grads_norm = 7.1737
	old_data_grads_norm = 6.8735
	sim_grads_norm_tr = 0.0826
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2067
	data_grads_norm = 5.5336
	new_data_grads_norm = 8.0746
	old_data_grads_norm = 5.7139
	sim_grads_norm_tr = -0.0162
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2477
	data_grads_norm = 4.7485
	new_data_grads_norm = 7.8760
	old_data_grads_norm = 5.4202
	sim_grads_norm_tr = 0.0648
-- Starting training on experience 118 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5295
	data_grads_norm = 5.4094
	new_data_grads_norm = 7.5328
	old_data_grads_norm = 7.8066
	sim_grads_norm_tr = 0.0079
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1148
	data_grads_norm = 4.8283
	new_data_grads_norm = 7.8954
	old_data_grads_norm = 6.7479
	sim_grads_norm_tr = -0.0340
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9410
	data_grads_norm = 6.2308
	new_data_grads_norm = 7.5238
	old_data_grads_norm = 9.6950
	sim_grads_norm_tr = -0.0145
-- Starting training on experience 119 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2618
	data_grads_norm = 4.6491
	new_data_grads_norm = 6.3282
	old_data_grads_norm = 6.2061
	sim_grads_norm_tr = 0.0969
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6397
	data_grads_norm = 5.6247
	new_data_grads_norm = 6.7316
	old_data_grads_norm = 8.1142
	sim_grads_norm_tr = 0.0231
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1084
	data_grads_norm = 4.4967
	new_data_grads_norm = 6.9163
	old_data_grads_norm = 6.0948
	sim_grads_norm_tr = -0.0289
-- Starting training on experience 120 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2040
	data_grads_norm = 5.0045
	new_data_grads_norm = 8.3070
	old_data_grads_norm = 6.2363
	sim_grads_norm_tr = 0.0481
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3454
	data_grads_norm = 5.8601
	new_data_grads_norm = 8.2483
	old_data_grads_norm = 9.2990
	sim_grads_norm_tr = -0.0061
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9035
	data_grads_norm = 5.0244
	new_data_grads_norm = 7.4670
	old_data_grads_norm = 6.3937
	sim_grads_norm_tr = -0.0279
-- Starting training on experience 121 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5037
	data_grads_norm = 5.2074
	new_data_grads_norm = 6.8236
	old_data_grads_norm = 5.4717
	sim_grads_norm_tr = 0.0542
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1697
	data_grads_norm = 4.5733
	new_data_grads_norm = 6.9854
	old_data_grads_norm = 5.1579
	sim_grads_norm_tr = 0.0835
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1093
	data_grads_norm = 4.7942
	new_data_grads_norm = 6.2262
	old_data_grads_norm = 5.6958
	sim_grads_norm_tr = 0.0001
-- Starting training on experience 122 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3491
	data_grads_norm = 5.7447
	new_data_grads_norm = 8.4637
	old_data_grads_norm = 7.1276
	sim_grads_norm_tr = -0.0184
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3695
	data_grads_norm = 5.2161
	new_data_grads_norm = 7.5872
	old_data_grads_norm = 6.5210
	sim_grads_norm_tr = 0.0075
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1066
	data_grads_norm = 5.2096
	new_data_grads_norm = 7.3980
	old_data_grads_norm = 6.0493
	sim_grads_norm_tr = 0.0028
-- Starting training on experience 123 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8579
	data_grads_norm = 4.3306
	new_data_grads_norm = 7.2693
	old_data_grads_norm = 4.5790
	sim_grads_norm_tr = -0.0494
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7789
	data_grads_norm = 3.8607
	new_data_grads_norm = 7.2372
	old_data_grads_norm = 3.3912
	sim_grads_norm_tr = -0.0921
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3946
	data_grads_norm = 5.6173
	new_data_grads_norm = 8.4946
	old_data_grads_norm = 6.0260
	sim_grads_norm_tr = 0.0834
-- Starting training on experience 124 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5453
	data_grads_norm = 5.8468
	new_data_grads_norm = 8.0466
	old_data_grads_norm = 7.3667
	sim_grads_norm_tr = -0.0032
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2685
	data_grads_norm = 5.3227
	new_data_grads_norm = 6.8830
	old_data_grads_norm = 7.0456
	sim_grads_norm_tr = -0.0293
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1927
	data_grads_norm = 5.4154
	new_data_grads_norm = 6.7258
	old_data_grads_norm = 7.7429
	sim_grads_norm_tr = -0.0441
-- Starting training on experience 125 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4133
	data_grads_norm = 5.4669
	new_data_grads_norm = 9.0159
	old_data_grads_norm = 6.3142
	sim_grads_norm_tr = -0.0070
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2954
	data_grads_norm = 6.8941
	new_data_grads_norm = 9.5323
	old_data_grads_norm = 8.2071
	sim_grads_norm_tr = 0.1349
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5871
	data_grads_norm = 5.1179
	new_data_grads_norm = 7.9802
	old_data_grads_norm = 6.3124
	sim_grads_norm_tr = -0.0030
-- Starting training on experience 126 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7379
	data_grads_norm = 4.6990
	new_data_grads_norm = 7.3585
	old_data_grads_norm = 7.0320
	sim_grads_norm_tr = -0.0237
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9446
	data_grads_norm = 5.4191
	new_data_grads_norm = 7.6801
	old_data_grads_norm = 6.6754
	sim_grads_norm_tr = 0.0347
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3053
	data_grads_norm = 5.1350
	new_data_grads_norm = 8.2898
	old_data_grads_norm = 7.4749
	sim_grads_norm_tr = 0.0447
-- Starting training on experience 127 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4365
	data_grads_norm = 6.3234
	new_data_grads_norm = 7.5082
	old_data_grads_norm = 6.9444
	sim_grads_norm_tr = 0.0721
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8286
	data_grads_norm = 5.6847
	new_data_grads_norm = 8.2880
	old_data_grads_norm = 8.3576
	sim_grads_norm_tr = 0.0739
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2653
	data_grads_norm = 5.4715
	new_data_grads_norm = 7.4208
	old_data_grads_norm = 6.8824
	sim_grads_norm_tr = -0.0394
-- Starting training on experience 128 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7816
	data_grads_norm = 5.7570
	new_data_grads_norm = 9.3757
	old_data_grads_norm = 6.2318
	sim_grads_norm_tr = -0.0201
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8945
	data_grads_norm = 6.3601
	new_data_grads_norm = 8.9696
	old_data_grads_norm = 7.5430
	sim_grads_norm_tr = -0.0066
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9461
	data_grads_norm = 6.2393
	new_data_grads_norm = 9.8775
	old_data_grads_norm = 6.2238
	sim_grads_norm_tr = 0.0069
-- Starting training on experience 129 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4249
	data_grads_norm = 5.5227
	new_data_grads_norm = 7.3697
	old_data_grads_norm = 6.7999
	sim_grads_norm_tr = -0.0133
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6713
	data_grads_norm = 5.2488
	new_data_grads_norm = 7.1343
	old_data_grads_norm = 5.9887
	sim_grads_norm_tr = 0.0337
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1914
	data_grads_norm = 5.8764
	new_data_grads_norm = 7.3459
	old_data_grads_norm = 7.9549
	sim_grads_norm_tr = 0.0198
-- Starting training on experience 130 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9359
	data_grads_norm = 4.7429
	new_data_grads_norm = 7.9915
	old_data_grads_norm = 6.3526
	sim_grads_norm_tr = -0.0126
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2518
	data_grads_norm = 5.5065
	new_data_grads_norm = 8.8131
	old_data_grads_norm = 6.8760
	sim_grads_norm_tr = -0.0161
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3027
	data_grads_norm = 4.8450
	new_data_grads_norm = 7.6909
	old_data_grads_norm = 5.8276
	sim_grads_norm_tr = 0.0490
-- Starting training on experience 131 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2535
	data_grads_norm = 4.5743
	new_data_grads_norm = 8.6079
	old_data_grads_norm = 4.9437
	sim_grads_norm_tr = -0.0225
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4255
	data_grads_norm = 5.1746
	new_data_grads_norm = 7.4575
	old_data_grads_norm = 6.3933
	sim_grads_norm_tr = -0.0190
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5744
	data_grads_norm = 5.5024
	new_data_grads_norm = 8.7576
	old_data_grads_norm = 7.0026
	sim_grads_norm_tr = 0.0035
-- Starting training on experience 132 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6144
	data_grads_norm = 5.6599
	new_data_grads_norm = 7.3285
	old_data_grads_norm = 9.0205
	sim_grads_norm_tr = 0.0186
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1044
	data_grads_norm = 5.0661
	new_data_grads_norm = 8.0851
	old_data_grads_norm = 6.7904
	sim_grads_norm_tr = -0.0160
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3228
	data_grads_norm = 4.8775
	new_data_grads_norm = 8.4568
	old_data_grads_norm = 6.7493
	sim_grads_norm_tr = 0.0193
-- Starting training on experience 133 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6181
	data_grads_norm = 5.3534
	new_data_grads_norm = 7.6480
	old_data_grads_norm = 7.0268
	sim_grads_norm_tr = -0.0061
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5251
	data_grads_norm = 5.0401
	new_data_grads_norm = 7.7265
	old_data_grads_norm = 5.6305
	sim_grads_norm_tr = -0.0000
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5240
	data_grads_norm = 6.3012
	new_data_grads_norm = 7.6769
	old_data_grads_norm = 9.6551
	sim_grads_norm_tr = -0.0256
-- Starting training on experience 134 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1779
	data_grads_norm = 5.1968
	new_data_grads_norm = 7.4378
	old_data_grads_norm = 5.7588
	sim_grads_norm_tr = -0.0244
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1114
	data_grads_norm = 5.0624
	new_data_grads_norm = 7.0949
	old_data_grads_norm = 6.8867
	sim_grads_norm_tr = -0.0449
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3665
	data_grads_norm = 5.5597
	new_data_grads_norm = 7.9899
	old_data_grads_norm = 7.1407
	sim_grads_norm_tr = 0.0299
-- Starting training on experience 135 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5157
	data_grads_norm = 5.1023
	new_data_grads_norm = 6.8408
	old_data_grads_norm = 7.0416
	sim_grads_norm_tr = 0.0062
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6332
	data_grads_norm = 5.2236
	new_data_grads_norm = 7.0587
	old_data_grads_norm = 8.5216
	sim_grads_norm_tr = -0.0007
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4864
	data_grads_norm = 5.2532
	new_data_grads_norm = 7.6169
	old_data_grads_norm = 7.0115
	sim_grads_norm_tr = -0.0255
-- Starting training on experience 136 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3076
	data_grads_norm = 5.2175
	new_data_grads_norm = 8.8967
	old_data_grads_norm = 5.1859
	sim_grads_norm_tr = -0.0163
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5602
	data_grads_norm = 5.7268
	new_data_grads_norm = 8.1302
	old_data_grads_norm = 5.4058
	sim_grads_norm_tr = 0.0171
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8689
	data_grads_norm = 5.5729
	new_data_grads_norm = 8.0063
	old_data_grads_norm = 6.2635
	sim_grads_norm_tr = 0.0289
-- Starting training on experience 137 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8278
	data_grads_norm = 4.8472
	new_data_grads_norm = 8.4812
	old_data_grads_norm = 5.2259
	sim_grads_norm_tr = 0.0342
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3090
	data_grads_norm = 4.4318
	new_data_grads_norm = 8.2012
	old_data_grads_norm = 4.4519
	sim_grads_norm_tr = -0.0010
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6691
	data_grads_norm = 5.8547
	new_data_grads_norm = 7.4845
	old_data_grads_norm = 8.3235
	sim_grads_norm_tr = -0.0121
-- Starting training on experience 138 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5081
	data_grads_norm = 5.3852
	new_data_grads_norm = 7.5738
	old_data_grads_norm = 6.7630
	sim_grads_norm_tr = 0.0883
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2107
	data_grads_norm = 5.2956
	new_data_grads_norm = 7.9793
	old_data_grads_norm = 6.6444
	sim_grads_norm_tr = -0.0402
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4502
	data_grads_norm = 6.2568
	new_data_grads_norm = 7.8122
	old_data_grads_norm = 8.0818
	sim_grads_norm_tr = 0.0018
-- Starting training on experience 139 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1548
	data_grads_norm = 4.7942
	new_data_grads_norm = 7.8374
	old_data_grads_norm = 5.0691
	sim_grads_norm_tr = 0.0027
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5073
	data_grads_norm = 5.0372
	new_data_grads_norm = 7.2899
	old_data_grads_norm = 6.4581
	sim_grads_norm_tr = 0.0058
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6759
	data_grads_norm = 5.5986
	new_data_grads_norm = 7.8106
	old_data_grads_norm = 7.4996
	sim_grads_norm_tr = 0.1060
-- Starting training on experience 140 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6397
	data_grads_norm = 5.1872
	new_data_grads_norm = 7.8636
	old_data_grads_norm = 6.1907
	sim_grads_norm_tr = -0.0200
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1798
	data_grads_norm = 5.4321
	new_data_grads_norm = 7.7722
	old_data_grads_norm = 8.8942
	sim_grads_norm_tr = -0.0140
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8654
	data_grads_norm = 6.6393
	new_data_grads_norm = 8.1992
	old_data_grads_norm = 10.3382
	sim_grads_norm_tr = 0.0093
-- Starting training on experience 141 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1974
	data_grads_norm = 4.6620
	new_data_grads_norm = 7.3412
	old_data_grads_norm = 4.9961
	sim_grads_norm_tr = 0.0265
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0816
	data_grads_norm = 4.8067
	new_data_grads_norm = 7.4255
	old_data_grads_norm = 6.8616
	sim_grads_norm_tr = 0.0479
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4519
	data_grads_norm = 6.3745
	new_data_grads_norm = 8.9124
	old_data_grads_norm = 8.5721
	sim_grads_norm_tr = 0.0461
-- Starting training on experience 142 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1785
	data_grads_norm = 5.3219
	new_data_grads_norm = 8.0296
	old_data_grads_norm = 6.1429
	sim_grads_norm_tr = -0.0105
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3217
	data_grads_norm = 4.7654
	new_data_grads_norm = 8.1639
	old_data_grads_norm = 5.5614
	sim_grads_norm_tr = 0.1669
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9242
	data_grads_norm = 5.6735
	new_data_grads_norm = 7.8130
	old_data_grads_norm = 7.9931
	sim_grads_norm_tr = 0.0311
-- Starting training on experience 143 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1175
	data_grads_norm = 6.0726
	new_data_grads_norm = 8.4292
	old_data_grads_norm = 7.4427
	sim_grads_norm_tr = 0.0223
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9762
	data_grads_norm = 5.5514
	new_data_grads_norm = 9.4605
	old_data_grads_norm = 6.5677
	sim_grads_norm_tr = -0.0118
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3339
	data_grads_norm = 6.1838
	new_data_grads_norm = 9.8968
	old_data_grads_norm = 7.5572
	sim_grads_norm_tr = -0.0304
-- Starting training on experience 144 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1473
	data_grads_norm = 4.4468
	new_data_grads_norm = 7.9018
	old_data_grads_norm = 4.5079
	sim_grads_norm_tr = 0.0579
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2032
	data_grads_norm = 5.2980
	new_data_grads_norm = 7.2390
	old_data_grads_norm = 8.5278
	sim_grads_norm_tr = -0.0071
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5763
	data_grads_norm = 3.9109
	new_data_grads_norm = 7.5800
	old_data_grads_norm = 3.7693
	sim_grads_norm_tr = 0.0104
-- Starting training on experience 145 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8933
	data_grads_norm = 5.4297
	new_data_grads_norm = 7.6049
	old_data_grads_norm = 8.4439
	sim_grads_norm_tr = -0.0130
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8658
	data_grads_norm = 5.3239
	new_data_grads_norm = 8.5498
	old_data_grads_norm = 5.0821
	sim_grads_norm_tr = 0.0546
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3593
	data_grads_norm = 5.7268
	new_data_grads_norm = 8.1070
	old_data_grads_norm = 7.3119
	sim_grads_norm_tr = 0.0108
-- Starting training on experience 146 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7589
	data_grads_norm = 4.6514
	new_data_grads_norm = 8.4496
	old_data_grads_norm = 5.2865
	sim_grads_norm_tr = 0.0151
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0962
	data_grads_norm = 5.3723
	new_data_grads_norm = 8.2720
	old_data_grads_norm = 5.8521
	sim_grads_norm_tr = 0.0063
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8958
	data_grads_norm = 5.5541
	new_data_grads_norm = 8.0756
	old_data_grads_norm = 6.2050
	sim_grads_norm_tr = -0.0044
-- Starting training on experience 147 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7728
	data_grads_norm = 5.7261
	new_data_grads_norm = 8.2437
	old_data_grads_norm = 7.7124
	sim_grads_norm_tr = 0.0292
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5746
	data_grads_norm = 5.7758
	new_data_grads_norm = 7.8642
	old_data_grads_norm = 5.8742
	sim_grads_norm_tr = 0.0912
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1440
	data_grads_norm = 6.0825
	new_data_grads_norm = 7.4867
	old_data_grads_norm = 8.9572
	sim_grads_norm_tr = 0.0398
-- Starting training on experience 148 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1463
	data_grads_norm = 5.5663
	new_data_grads_norm = 7.9654
	old_data_grads_norm = 8.1349
	sim_grads_norm_tr = 0.0172
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3952
	data_grads_norm = 5.0931
	new_data_grads_norm = 7.4716
	old_data_grads_norm = 6.8165
	sim_grads_norm_tr = -0.0193
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1467
	data_grads_norm = 5.1952
	new_data_grads_norm = 7.2479
	old_data_grads_norm = 7.3818
	sim_grads_norm_tr = -0.0327
-- Starting training on experience 149 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5676
	data_grads_norm = 5.7076
	new_data_grads_norm = 7.1313
	old_data_grads_norm = 7.1162
	sim_grads_norm_tr = 0.1441
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7105
	data_grads_norm = 4.1774
	new_data_grads_norm = 6.1095
	old_data_grads_norm = 6.0469
	sim_grads_norm_tr = -0.0347
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1473
	data_grads_norm = 4.9350
	new_data_grads_norm = 6.4037
	old_data_grads_norm = 6.8300
	sim_grads_norm_tr = -0.0019
-- Starting training on experience 150 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3218
	data_grads_norm = 5.7166
	new_data_grads_norm = 8.0861
	old_data_grads_norm = 8.0199
	sim_grads_norm_tr = -0.0161
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8160
	data_grads_norm = 6.3105
	new_data_grads_norm = 8.4340
	old_data_grads_norm = 6.9616
	sim_grads_norm_tr = -0.0103
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4168
	data_grads_norm = 5.4380
	new_data_grads_norm = 9.6740
	old_data_grads_norm = 5.4846
	sim_grads_norm_tr = -0.0040
-- Starting training on experience 151 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3394
	data_grads_norm = 5.9413
	new_data_grads_norm = 9.5114
	old_data_grads_norm = 8.3874
	sim_grads_norm_tr = 0.0249
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0401
	data_grads_norm = 5.3956
	new_data_grads_norm = 8.4834
	old_data_grads_norm = 4.2093
	sim_grads_norm_tr = -0.0097
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4311
	data_grads_norm = 5.3873
	new_data_grads_norm = 9.2464
	old_data_grads_norm = 6.8208
	sim_grads_norm_tr = -0.0240
-- Starting training on experience 152 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0939
	data_grads_norm = 5.8920
	new_data_grads_norm = 8.2353
	old_data_grads_norm = 5.6177
	sim_grads_norm_tr = -0.0154
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1205
	data_grads_norm = 5.1271
	new_data_grads_norm = 8.6806
	old_data_grads_norm = 5.2565
	sim_grads_norm_tr = 0.0011
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7062
	data_grads_norm = 6.1205
	new_data_grads_norm = 7.7218
	old_data_grads_norm = 6.8073
	sim_grads_norm_tr = 0.0848
-- Starting training on experience 153 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8879
	data_grads_norm = 4.5856
	new_data_grads_norm = 7.3099
	old_data_grads_norm = 5.2820
	sim_grads_norm_tr = -0.0092
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3253
	data_grads_norm = 5.8237
	new_data_grads_norm = 7.5058
	old_data_grads_norm = 8.2259
	sim_grads_norm_tr = -0.0361
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0142
	data_grads_norm = 4.9093
	new_data_grads_norm = 7.9291
	old_data_grads_norm = 6.7050
	sim_grads_norm_tr = 0.0250
-- Starting training on experience 154 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5298
	data_grads_norm = 5.1473
	new_data_grads_norm = 6.6162
	old_data_grads_norm = 7.1539
	sim_grads_norm_tr = 0.1457
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0374
	data_grads_norm = 4.6504
	new_data_grads_norm = 6.9995
	old_data_grads_norm = 5.6674
	sim_grads_norm_tr = -0.0379
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2175
	data_grads_norm = 5.3068
	new_data_grads_norm = 7.2268
	old_data_grads_norm = 7.6777
	sim_grads_norm_tr = -0.0165
-- Starting training on experience 155 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0014
	data_grads_norm = 5.2640
	new_data_grads_norm = 8.4276
	old_data_grads_norm = 7.1224
	sim_grads_norm_tr = 0.0397
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0503
	data_grads_norm = 5.5275
	new_data_grads_norm = 7.6293
	old_data_grads_norm = 6.7489
	sim_grads_norm_tr = -0.0053
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2183
	data_grads_norm = 5.2830
	new_data_grads_norm = 8.8798
	old_data_grads_norm = 4.9264
	sim_grads_norm_tr = -0.0112
-- Starting training on experience 156 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2404
	data_grads_norm = 5.7910
	new_data_grads_norm = 7.0269
	old_data_grads_norm = 8.3744
	sim_grads_norm_tr = -0.0604
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1050
	data_grads_norm = 4.4911
	new_data_grads_norm = 6.9490
	old_data_grads_norm = 5.6859
	sim_grads_norm_tr = 0.0016
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3864
	data_grads_norm = 5.1156
	new_data_grads_norm = 6.7533
	old_data_grads_norm = 8.1163
	sim_grads_norm_tr = 0.0051
-- Starting training on experience 157 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1281
	data_grads_norm = 4.8412
	new_data_grads_norm = 7.8960
	old_data_grads_norm = 6.4786
	sim_grads_norm_tr = 0.0563
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9186
	data_grads_norm = 4.7014
	new_data_grads_norm = 7.2571
	old_data_grads_norm = 5.6905
	sim_grads_norm_tr = 0.0164
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9090
	data_grads_norm = 4.7749
	new_data_grads_norm = 7.5733
	old_data_grads_norm = 5.7661
	sim_grads_norm_tr = 0.0755
-- Starting training on experience 158 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0824
	data_grads_norm = 5.2811
	new_data_grads_norm = 8.0866
	old_data_grads_norm = 4.9123
	sim_grads_norm_tr = -0.0118
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2703
	data_grads_norm = 5.4136
	new_data_grads_norm = 8.1304
	old_data_grads_norm = 6.2852
	sim_grads_norm_tr = -0.0145
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5393
	data_grads_norm = 5.4947
	new_data_grads_norm = 9.1677
	old_data_grads_norm = 6.8621
	sim_grads_norm_tr = -0.0012
-- Starting training on experience 159 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4335
	data_grads_norm = 5.6249
	new_data_grads_norm = 7.5730
	old_data_grads_norm = 8.2112
	sim_grads_norm_tr = -0.0033
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2093
	data_grads_norm = 4.7652
	new_data_grads_norm = 7.0680
	old_data_grads_norm = 5.6948
	sim_grads_norm_tr = -0.0237
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5227
	data_grads_norm = 5.4171
	new_data_grads_norm = 8.3132
	old_data_grads_norm = 7.3052
	sim_grads_norm_tr = -0.0103
-- Starting training on experience 160 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0905
	data_grads_norm = 4.8495
	new_data_grads_norm = 7.9190
	old_data_grads_norm = 5.5394
	sim_grads_norm_tr = -0.0334
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3383
	data_grads_norm = 5.3900
	new_data_grads_norm = 8.6268
	old_data_grads_norm = 6.0076
	sim_grads_norm_tr = -0.0064
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6108
	data_grads_norm = 5.6491
	new_data_grads_norm = 7.8012
	old_data_grads_norm = 7.4155
	sim_grads_norm_tr = 0.0664
-- Starting training on experience 161 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0812
	data_grads_norm = 5.3624
	new_data_grads_norm = 8.8759
	old_data_grads_norm = 4.3592
	sim_grads_norm_tr = 0.0080
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5057
	data_grads_norm = 5.5294
	new_data_grads_norm = 7.8855
	old_data_grads_norm = 6.3449
	sim_grads_norm_tr = -0.0085
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0012
	data_grads_norm = 6.0034
	new_data_grads_norm = 8.7564
	old_data_grads_norm = 7.8262
	sim_grads_norm_tr = 0.0150
-- Starting training on experience 162 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0281
	data_grads_norm = 6.5943
	new_data_grads_norm = 9.8168
	old_data_grads_norm = 9.1278
	sim_grads_norm_tr = 0.0532
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4075
	data_grads_norm = 5.4688
	new_data_grads_norm = 9.3019
	old_data_grads_norm = 5.7677
	sim_grads_norm_tr = -0.0495
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4301
	data_grads_norm = 5.9480
	new_data_grads_norm = 9.6119
	old_data_grads_norm = 7.0139
	sim_grads_norm_tr = 0.0332
-- Starting training on experience 163 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3361
	data_grads_norm = 5.1252
	new_data_grads_norm = 8.4808
	old_data_grads_norm = 5.2399
	sim_grads_norm_tr = 0.0218
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8943
	data_grads_norm = 4.7756
	new_data_grads_norm = 8.1536
	old_data_grads_norm = 4.7253
	sim_grads_norm_tr = -0.0392
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0141
	data_grads_norm = 5.2349
	new_data_grads_norm = 7.8675
	old_data_grads_norm = 6.2365
	sim_grads_norm_tr = -0.0209
-- Starting training on experience 164 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1837
	data_grads_norm = 6.8067
	new_data_grads_norm = 8.0627
	old_data_grads_norm = 9.3860
	sim_grads_norm_tr = 0.0574
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0851
	data_grads_norm = 5.5596
	new_data_grads_norm = 7.5408
	old_data_grads_norm = 6.8191
	sim_grads_norm_tr = -0.0004
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9651
	data_grads_norm = 5.2989
	new_data_grads_norm = 7.1657
	old_data_grads_norm = 8.3320
	sim_grads_norm_tr = -0.0307
-- Starting training on experience 165 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3818
	data_grads_norm = 5.5268
	new_data_grads_norm = 8.5659
	old_data_grads_norm = 8.9309
	sim_grads_norm_tr = -0.0148
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5437
	data_grads_norm = 6.3530
	new_data_grads_norm = 8.8076
	old_data_grads_norm = 6.4814
	sim_grads_norm_tr = 0.0263
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9511
	data_grads_norm = 5.9687
	new_data_grads_norm = 8.0310
	old_data_grads_norm = 8.0266
	sim_grads_norm_tr = 0.0466
-- Starting training on experience 166 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6333
	data_grads_norm = 5.2821
	new_data_grads_norm = 7.8307
	old_data_grads_norm = 5.5703
	sim_grads_norm_tr = 0.0250
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0987
	data_grads_norm = 4.7489
	new_data_grads_norm = 7.4660
	old_data_grads_norm = 5.9343
	sim_grads_norm_tr = -0.0032
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3555
	data_grads_norm = 5.5425
	new_data_grads_norm = 7.3974
	old_data_grads_norm = 8.4650
	sim_grads_norm_tr = -0.0189
-- Starting training on experience 167 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3876
	data_grads_norm = 5.9197
	new_data_grads_norm = 8.3673
	old_data_grads_norm = 5.6504
	sim_grads_norm_tr = 0.0045
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3553
	data_grads_norm = 5.4936
	new_data_grads_norm = 7.7581
	old_data_grads_norm = 6.0175
	sim_grads_norm_tr = 0.0054
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4968
	data_grads_norm = 5.7241
	new_data_grads_norm = 8.0218
	old_data_grads_norm = 6.6243
	sim_grads_norm_tr = 0.0507
-- Starting training on experience 168 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3815
	data_grads_norm = 5.4599
	new_data_grads_norm = 8.7212
	old_data_grads_norm = 5.2646
	sim_grads_norm_tr = 0.1300
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2654
	data_grads_norm = 5.2333
	new_data_grads_norm = 9.1038
	old_data_grads_norm = 7.2109
	sim_grads_norm_tr = -0.0051
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2209
	data_grads_norm = 4.7856
	new_data_grads_norm = 8.7564
	old_data_grads_norm = 6.2045
	sim_grads_norm_tr = 0.0385
-- Starting training on experience 169 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7601
	data_grads_norm = 3.9470
	new_data_grads_norm = 7.0085
	old_data_grads_norm = 6.8019
	sim_grads_norm_tr = -0.0022
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8613
	data_grads_norm = 5.3435
	new_data_grads_norm = 7.7181
	old_data_grads_norm = 6.6122
	sim_grads_norm_tr = 0.0110
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3654
	data_grads_norm = 5.5354
	new_data_grads_norm = 7.6719
	old_data_grads_norm = 7.8369
	sim_grads_norm_tr = -0.0059
-- Starting training on experience 170 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9071
	data_grads_norm = 5.7108
	new_data_grads_norm = 10.2437
	old_data_grads_norm = 6.1298
	sim_grads_norm_tr = 0.0328
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0884
	data_grads_norm = 5.6105
	new_data_grads_norm = 9.6113
	old_data_grads_norm = 6.3095
	sim_grads_norm_tr = 0.0275
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9353
	data_grads_norm = 4.9989
	new_data_grads_norm = 8.3969
	old_data_grads_norm = 6.5608
	sim_grads_norm_tr = 0.0073
-- Starting training on experience 171 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0364
	data_grads_norm = 4.8982
	new_data_grads_norm = 7.6720
	old_data_grads_norm = 6.0013
	sim_grads_norm_tr = -0.0336
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1229
	data_grads_norm = 5.2403
	new_data_grads_norm = 8.6031
	old_data_grads_norm = 4.1832
	sim_grads_norm_tr = -0.0446
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6340
	data_grads_norm = 5.9027
	new_data_grads_norm = 8.5633
	old_data_grads_norm = 8.3479
	sim_grads_norm_tr = -0.0322
-- Starting training on experience 172 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8956
	data_grads_norm = 6.3768
	new_data_grads_norm = 8.6201
	old_data_grads_norm = 8.6944
	sim_grads_norm_tr = 0.0189
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3901
	data_grads_norm = 5.5917
	new_data_grads_norm = 9.3454
	old_data_grads_norm = 6.6628
	sim_grads_norm_tr = 0.0362
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1268
	data_grads_norm = 5.2145
	new_data_grads_norm = 7.9453
	old_data_grads_norm = 6.0766
	sim_grads_norm_tr = -0.0404
-- Starting training on experience 173 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8608
	data_grads_norm = 5.7492
	new_data_grads_norm = 7.8466
	old_data_grads_norm = 6.9891
	sim_grads_norm_tr = 0.0268
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5415
	data_grads_norm = 5.2845
	new_data_grads_norm = 8.2472
	old_data_grads_norm = 6.2510
	sim_grads_norm_tr = 0.0394
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2432
	data_grads_norm = 4.9522
	new_data_grads_norm = 7.1708
	old_data_grads_norm = 7.2059
	sim_grads_norm_tr = -0.0271
-- Starting training on experience 174 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1854
	data_grads_norm = 4.9874
	new_data_grads_norm = 7.7690
	old_data_grads_norm = 6.3148
	sim_grads_norm_tr = -0.0058
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2542
	data_grads_norm = 5.6760
	new_data_grads_norm = 7.5601
	old_data_grads_norm = 7.6770
	sim_grads_norm_tr = 0.0513
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5560
	data_grads_norm = 5.7615
	new_data_grads_norm = 7.1948
	old_data_grads_norm = 9.1232
	sim_grads_norm_tr = 0.0852
-- Starting training on experience 175 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9147
	data_grads_norm = 5.2770
	new_data_grads_norm = 8.5157
	old_data_grads_norm = 5.0950
	sim_grads_norm_tr = -0.0400
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0617
	data_grads_norm = 6.1676
	new_data_grads_norm = 7.8608
	old_data_grads_norm = 8.2280
	sim_grads_norm_tr = -0.0337
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5836
	data_grads_norm = 5.4587
	new_data_grads_norm = 8.0671
	old_data_grads_norm = 6.9262
	sim_grads_norm_tr = 0.0037
-- Starting training on experience 176 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5116
	data_grads_norm = 5.6620
	new_data_grads_norm = 8.7547
	old_data_grads_norm = 8.6508
	sim_grads_norm_tr = -0.0017
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2976
	data_grads_norm = 5.1321
	new_data_grads_norm = 9.1072
	old_data_grads_norm = 6.1245
	sim_grads_norm_tr = -0.0205
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3787
	data_grads_norm = 5.5643
	new_data_grads_norm = 9.1790
	old_data_grads_norm = 7.3955
	sim_grads_norm_tr = -0.0484
-- Starting training on experience 177 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4852
	data_grads_norm = 4.6528
	new_data_grads_norm = 7.5293
	old_data_grads_norm = 5.4498
	sim_grads_norm_tr = -0.0182
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9214
	data_grads_norm = 5.1860
	new_data_grads_norm = 7.4552
	old_data_grads_norm = 5.2302
	sim_grads_norm_tr = -0.0046
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0166
	data_grads_norm = 5.3190
	new_data_grads_norm = 7.6170
	old_data_grads_norm = 5.7063
	sim_grads_norm_tr = 0.0048
-- Starting training on experience 178 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4056
	data_grads_norm = 4.8494
	new_data_grads_norm = 7.4054
	old_data_grads_norm = 6.0876
	sim_grads_norm_tr = 0.0057
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0492
	data_grads_norm = 4.9776
	new_data_grads_norm = 8.1800
	old_data_grads_norm = 8.2315
	sim_grads_norm_tr = -0.0064
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7692
	data_grads_norm = 4.5178
	new_data_grads_norm = 7.5527
	old_data_grads_norm = 6.3746
	sim_grads_norm_tr = 0.0048
-- Starting training on experience 179 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5683
	data_grads_norm = 5.6009
	new_data_grads_norm = 8.2815
	old_data_grads_norm = 7.8018
	sim_grads_norm_tr = 0.0356
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9494
	data_grads_norm = 6.1021
	new_data_grads_norm = 9.9362
	old_data_grads_norm = 5.6789
	sim_grads_norm_tr = -0.0086
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4389
	data_grads_norm = 5.4065
	new_data_grads_norm = 8.4374
	old_data_grads_norm = 7.0098
	sim_grads_norm_tr = -0.0475
-- Starting training on experience 180 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4692
	data_grads_norm = 4.8892
	new_data_grads_norm = 8.6141
	old_data_grads_norm = 4.5664
	sim_grads_norm_tr = -0.0027
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5907
	data_grads_norm = 5.4603
	new_data_grads_norm = 9.7670
	old_data_grads_norm = 7.5568
	sim_grads_norm_tr = 0.0058
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6141
	data_grads_norm = 6.1440
	new_data_grads_norm = 9.0960
	old_data_grads_norm = 6.3724
	sim_grads_norm_tr = 0.0075
-- Starting training on experience 181 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5379
	data_grads_norm = 5.0993
	new_data_grads_norm = 8.3227
	old_data_grads_norm = 6.3704
	sim_grads_norm_tr = -0.0035
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1364
	data_grads_norm = 5.6797
	new_data_grads_norm = 8.1482
	old_data_grads_norm = 7.9245
	sim_grads_norm_tr = 0.0048
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9851
	data_grads_norm = 5.9288
	new_data_grads_norm = 8.2046
	old_data_grads_norm = 9.1679
	sim_grads_norm_tr = 0.0073
-- Starting training on experience 182 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6408
	data_grads_norm = 6.1573
	new_data_grads_norm = 8.8660
	old_data_grads_norm = 7.0546
	sim_grads_norm_tr = 0.0143
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5002
	data_grads_norm = 5.7572
	new_data_grads_norm = 8.7766
	old_data_grads_norm = 6.5667
	sim_grads_norm_tr = -0.0033
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3452
	data_grads_norm = 5.5383
	new_data_grads_norm = 9.2758
	old_data_grads_norm = 5.6296
	sim_grads_norm_tr = 0.0680
-- Starting training on experience 183 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1318
	data_grads_norm = 4.1700
	new_data_grads_norm = 7.0526
	old_data_grads_norm = 5.7606
	sim_grads_norm_tr = -0.0115
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6528
	data_grads_norm = 5.7979
	new_data_grads_norm = 8.1810
	old_data_grads_norm = 5.9688
	sim_grads_norm_tr = 0.0962
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4013
	data_grads_norm = 5.5495
	new_data_grads_norm = 9.2466
	old_data_grads_norm = 5.1715
	sim_grads_norm_tr = -0.0103
-- Starting training on experience 184 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3039
	data_grads_norm = 6.2075
	new_data_grads_norm = 10.3589
	old_data_grads_norm = 5.9965
	sim_grads_norm_tr = 0.0224
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0409
	data_grads_norm = 6.3342
	new_data_grads_norm = 9.0494
	old_data_grads_norm = 9.8764
	sim_grads_norm_tr = -0.0357
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4368
	data_grads_norm = 6.0378
	new_data_grads_norm = 10.2281
	old_data_grads_norm = 8.1475
	sim_grads_norm_tr = 0.0007
-- Starting training on experience 185 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2580
	data_grads_norm = 5.8743
	new_data_grads_norm = 8.6286
	old_data_grads_norm = 5.8514
	sim_grads_norm_tr = 0.0799
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8722
	data_grads_norm = 4.9463
	new_data_grads_norm = 9.0267
	old_data_grads_norm = 6.0156
	sim_grads_norm_tr = -0.0075
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4467
	data_grads_norm = 6.1886
	new_data_grads_norm = 8.9340
	old_data_grads_norm = 7.2297
	sim_grads_norm_tr = 0.1216
-- Starting training on experience 186 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9211
	data_grads_norm = 6.5692
	new_data_grads_norm = 9.1125
	old_data_grads_norm = 8.0000
	sim_grads_norm_tr = 0.0514
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1038
	data_grads_norm = 5.4395
	new_data_grads_norm = 9.5194
	old_data_grads_norm = 6.7730
	sim_grads_norm_tr = 0.0031
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9851
	data_grads_norm = 5.1721
	new_data_grads_norm = 10.9841
	old_data_grads_norm = 4.8004
	sim_grads_norm_tr = -0.0222
-- Starting training on experience 187 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2979
	data_grads_norm = 5.4520
	new_data_grads_norm = 7.5125
	old_data_grads_norm = 4.7877
	sim_grads_norm_tr = -0.0011
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3073
	data_grads_norm = 6.7867
	new_data_grads_norm = 8.9152
	old_data_grads_norm = 8.3956
	sim_grads_norm_tr = 0.0890
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6984
	data_grads_norm = 5.9024
	new_data_grads_norm = 8.5612
	old_data_grads_norm = 7.2855
	sim_grads_norm_tr = 0.0191
-- Starting training on experience 188 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2411
	data_grads_norm = 6.2465
	new_data_grads_norm = 7.3163
	old_data_grads_norm = 7.2325
	sim_grads_norm_tr = 0.0709
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1495
	data_grads_norm = 5.7476
	new_data_grads_norm = 8.1343
	old_data_grads_norm = 6.8715
	sim_grads_norm_tr = -0.0036
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6125
	data_grads_norm = 4.4891
	new_data_grads_norm = 7.3378
	old_data_grads_norm = 4.4808
	sim_grads_norm_tr = -0.0187
-- Starting training on experience 189 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3220
	data_grads_norm = 4.8889
	new_data_grads_norm = 6.6945
	old_data_grads_norm = 7.1186
	sim_grads_norm_tr = -0.0288
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4009
	data_grads_norm = 4.5573
	new_data_grads_norm = 6.9790
	old_data_grads_norm = 5.9446
	sim_grads_norm_tr = 0.0057
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2421
	data_grads_norm = 4.7018
	new_data_grads_norm = 7.5343
	old_data_grads_norm = 6.6139
	sim_grads_norm_tr = 0.0079
-- Starting training on experience 190 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1520
	data_grads_norm = 5.1733
	new_data_grads_norm = 7.9982
	old_data_grads_norm = 5.4999
	sim_grads_norm_tr = 0.0460
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2233
	data_grads_norm = 5.1487
	new_data_grads_norm = 7.2503
	old_data_grads_norm = 8.0816
	sim_grads_norm_tr = 0.0898
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8141
	data_grads_norm = 4.9748
	new_data_grads_norm = 6.9593
	old_data_grads_norm = 8.1584
	sim_grads_norm_tr = 0.0120
-- Starting training on experience 191 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2851
	data_grads_norm = 5.8244
	new_data_grads_norm = 9.3361
	old_data_grads_norm = 5.2929
	sim_grads_norm_tr = 0.0374
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2389
	data_grads_norm = 5.8707
	new_data_grads_norm = 9.1651
	old_data_grads_norm = 6.4314
	sim_grads_norm_tr = -0.0157
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9594
	data_grads_norm = 5.3870
	new_data_grads_norm = 7.8559
	old_data_grads_norm = 5.3256
	sim_grads_norm_tr = 0.0191
-- Starting training on experience 192 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6284
	data_grads_norm = 6.1559
	new_data_grads_norm = 8.7307
	old_data_grads_norm = 6.7661
	sim_grads_norm_tr = 0.0150
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1436
	data_grads_norm = 4.7594
	new_data_grads_norm = 9.1962
	old_data_grads_norm = 5.1179
	sim_grads_norm_tr = -0.0621
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2540
	data_grads_norm = 5.6864
	new_data_grads_norm = 9.8064
	old_data_grads_norm = 7.4811
	sim_grads_norm_tr = -0.0010
-- Starting training on experience 193 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5835
	data_grads_norm = 5.7926
	new_data_grads_norm = 8.6635
	old_data_grads_norm = 6.2675
	sim_grads_norm_tr = 0.0031
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2412
	data_grads_norm = 4.9731
	new_data_grads_norm = 8.9246
	old_data_grads_norm = 6.1589
	sim_grads_norm_tr = -0.0141
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5399
	data_grads_norm = 5.7387
	new_data_grads_norm = 7.6194
	old_data_grads_norm = 7.1755
	sim_grads_norm_tr = -0.0172
-- Starting training on experience 194 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7868
	data_grads_norm = 6.0401
	new_data_grads_norm = 8.7576
	old_data_grads_norm = 6.8218
	sim_grads_norm_tr = 0.0007
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0437
	data_grads_norm = 6.5076
	new_data_grads_norm = 9.8600
	old_data_grads_norm = 6.5354
	sim_grads_norm_tr = 0.1333
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7033
	data_grads_norm = 6.2524
	new_data_grads_norm = 9.0297
	old_data_grads_norm = 7.2487
	sim_grads_norm_tr = 0.0267
-- Starting training on experience 195 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9997
	data_grads_norm = 5.7527
	new_data_grads_norm = 8.7727
	old_data_grads_norm = 7.1191
	sim_grads_norm_tr = -0.0407
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9890
	data_grads_norm = 5.1112
	new_data_grads_norm = 8.1243
	old_data_grads_norm = 6.0955
	sim_grads_norm_tr = -0.0053
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3755
	data_grads_norm = 5.5565
	new_data_grads_norm = 9.1014
	old_data_grads_norm = 6.7715
	sim_grads_norm_tr = -0.0007
-- Starting training on experience 196 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9888
	data_grads_norm = 6.2428
	new_data_grads_norm = 9.4993
	old_data_grads_norm = 7.4490
	sim_grads_norm_tr = 0.0714
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7382
	data_grads_norm = 6.3439
	new_data_grads_norm = 10.0473
	old_data_grads_norm = 7.4840
	sim_grads_norm_tr = 0.0512
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8929
	data_grads_norm = 6.2375
	new_data_grads_norm = 9.2888
	old_data_grads_norm = 7.7007
	sim_grads_norm_tr = -0.0211
-- Starting training on experience 197 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0387
	data_grads_norm = 5.0649
	new_data_grads_norm = 7.5119
	old_data_grads_norm = 6.1925
	sim_grads_norm_tr = 0.0998
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7160
	data_grads_norm = 4.2719
	new_data_grads_norm = 6.7749
	old_data_grads_norm = 4.1168
	sim_grads_norm_tr = -0.0311
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7170
	data_grads_norm = 5.1367
	new_data_grads_norm = 7.0689
	old_data_grads_norm = 7.1842
	sim_grads_norm_tr = -0.0515
-- Starting training on experience 198 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1962
	data_grads_norm = 5.1989
	new_data_grads_norm = 6.6181
	old_data_grads_norm = 6.9228
	sim_grads_norm_tr = 0.0853
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6759
	data_grads_norm = 4.9564
	new_data_grads_norm = 6.6569
	old_data_grads_norm = 5.4597
	sim_grads_norm_tr = -0.0366
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9874
	data_grads_norm = 5.3242
	new_data_grads_norm = 7.8022
	old_data_grads_norm = 8.4885
	sim_grads_norm_tr = -0.0598
-- Starting training on experience 199 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8887
	data_grads_norm = 4.8324
	new_data_grads_norm = 7.1321
	old_data_grads_norm = 6.1221
	sim_grads_norm_tr = 0.0208
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9308
	data_grads_norm = 4.0172
	new_data_grads_norm = 7.2450
	old_data_grads_norm = 4.0879
	sim_grads_norm_tr = -0.0454
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4589
	data_grads_norm = 5.2359
	new_data_grads_norm = 8.2007
	old_data_grads_norm = 5.7209
	sim_grads_norm_tr = -0.0114
-- Starting training on experience 200 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0276
	data_grads_norm = 4.9530
	new_data_grads_norm = 8.3033
	old_data_grads_norm = 5.3372
	sim_grads_norm_tr = -0.0362
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3483
	data_grads_norm = 5.7977
	new_data_grads_norm = 8.3367
	old_data_grads_norm = 5.2492
	sim_grads_norm_tr = 0.0413
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1904
	data_grads_norm = 5.9588
	new_data_grads_norm = 8.6854
	old_data_grads_norm = 8.0772
	sim_grads_norm_tr = -0.0137
-- Starting training on experience 201 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8209
	data_grads_norm = 5.4167
	new_data_grads_norm = 7.1834
	old_data_grads_norm = 7.4972
	sim_grads_norm_tr = -0.0152
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1974
	data_grads_norm = 5.7633
	new_data_grads_norm = 8.0597
	old_data_grads_norm = 9.8080
	sim_grads_norm_tr = -0.0081
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0365
	data_grads_norm = 5.8149
	new_data_grads_norm = 8.4692
	old_data_grads_norm = 7.3800
	sim_grads_norm_tr = -0.0068
-- Starting training on experience 202 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9539
	data_grads_norm = 6.0973
	new_data_grads_norm = 8.1617
	old_data_grads_norm = 9.9973
	sim_grads_norm_tr = -0.0043
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5650
	data_grads_norm = 5.6095
	new_data_grads_norm = 8.4711
	old_data_grads_norm = 6.8869
	sim_grads_norm_tr = -0.0186
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9969
	data_grads_norm = 6.2545
	new_data_grads_norm = 8.6505
	old_data_grads_norm = 9.3296
	sim_grads_norm_tr = 0.0155
-- Starting training on experience 203 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1633
	data_grads_norm = 5.3163
	new_data_grads_norm = 8.4998
	old_data_grads_norm = 6.5870
	sim_grads_norm_tr = -0.0360
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1900
	data_grads_norm = 6.0296
	new_data_grads_norm = 9.6300
	old_data_grads_norm = 6.4114
	sim_grads_norm_tr = -0.0349
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8556
	data_grads_norm = 6.6072
	new_data_grads_norm = 9.5650
	old_data_grads_norm = 8.6759
	sim_grads_norm_tr = 0.0727
-- Starting training on experience 204 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3955
	data_grads_norm = 4.7191
	new_data_grads_norm = 7.6128
	old_data_grads_norm = 4.3989
	sim_grads_norm_tr = 0.0626
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3912
	data_grads_norm = 5.1240
	new_data_grads_norm = 7.8234
	old_data_grads_norm = 5.9833
	sim_grads_norm_tr = 0.0486
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1243
	data_grads_norm = 4.9948
	new_data_grads_norm = 7.9430
	old_data_grads_norm = 5.6052
	sim_grads_norm_tr = -0.0039
-- Starting training on experience 205 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3222
	data_grads_norm = 5.6748
	new_data_grads_norm = 7.7866
	old_data_grads_norm = 7.3215
	sim_grads_norm_tr = 0.0451
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3201
	data_grads_norm = 4.6600
	new_data_grads_norm = 8.3619
	old_data_grads_norm = 6.1986
	sim_grads_norm_tr = -0.0108
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4853
	data_grads_norm = 5.0874
	new_data_grads_norm = 8.0514
	old_data_grads_norm = 6.5645
	sim_grads_norm_tr = -0.0029
-- Starting training on experience 206 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5972
	data_grads_norm = 5.0925
	new_data_grads_norm = 7.8517
	old_data_grads_norm = 6.7868
	sim_grads_norm_tr = -0.0265
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5584
	data_grads_norm = 5.2144
	new_data_grads_norm = 8.2250
	old_data_grads_norm = 6.2248
	sim_grads_norm_tr = 0.0174
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2137
	data_grads_norm = 4.8550
	new_data_grads_norm = 7.4589
	old_data_grads_norm = 5.7526
	sim_grads_norm_tr = 0.0299
-- Starting training on experience 207 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5253
	data_grads_norm = 5.5542
	new_data_grads_norm = 8.3098
	old_data_grads_norm = 7.5347
	sim_grads_norm_tr = 0.0090
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9338
	data_grads_norm = 4.1203
	new_data_grads_norm = 7.5373
	old_data_grads_norm = 3.0278
	sim_grads_norm_tr = -0.0368
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0600
	data_grads_norm = 4.4586
	new_data_grads_norm = 7.9556
	old_data_grads_norm = 4.8723
	sim_grads_norm_tr = -0.0177
-- Starting training on experience 208 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1224
	data_grads_norm = 6.2668
	new_data_grads_norm = 8.9270
	old_data_grads_norm = 8.0046
	sim_grads_norm_tr = 0.0210
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8230
	data_grads_norm = 6.5159
	new_data_grads_norm = 8.5596
	old_data_grads_norm = 7.4038
	sim_grads_norm_tr = 0.0447
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9727
	data_grads_norm = 5.5121
	new_data_grads_norm = 8.9664
	old_data_grads_norm = 5.2285
	sim_grads_norm_tr = 0.1224
-- Starting training on experience 209 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0294
	data_grads_norm = 4.8660
	new_data_grads_norm = 8.0648
	old_data_grads_norm = 5.9623
	sim_grads_norm_tr = -0.0005
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4054
	data_grads_norm = 5.7847
	new_data_grads_norm = 7.8050
	old_data_grads_norm = 8.5134
	sim_grads_norm_tr = 0.0183
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9285
	data_grads_norm = 4.6814
	new_data_grads_norm = 8.5594
	old_data_grads_norm = 4.5366
	sim_grads_norm_tr = 0.0059
-- Starting training on experience 210 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9608
	data_grads_norm = 5.0525
	new_data_grads_norm = 7.8816
	old_data_grads_norm = 6.4208
	sim_grads_norm_tr = 0.0348
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6740
	data_grads_norm = 4.9679
	new_data_grads_norm = 7.9113
	old_data_grads_norm = 7.5892
	sim_grads_norm_tr = -0.0006
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5792
	data_grads_norm = 4.8362
	new_data_grads_norm = 7.5494
	old_data_grads_norm = 4.7606
	sim_grads_norm_tr = -0.0189
-- Starting training on experience 211 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4992
	data_grads_norm = 5.3071
	new_data_grads_norm = 7.5811
	old_data_grads_norm = 5.9470
	sim_grads_norm_tr = -0.0152
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6616
	data_grads_norm = 4.6601
	new_data_grads_norm = 10.5740
	old_data_grads_norm = 5.8358
	sim_grads_norm_tr = -0.0350
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6686
	data_grads_norm = 4.8215
	new_data_grads_norm = 9.9432
	old_data_grads_norm = 5.2823
	sim_grads_norm_tr = 0.0700
-- Starting training on experience 212 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5175
	data_grads_norm = 4.8948
	new_data_grads_norm = 7.4684
	old_data_grads_norm = 7.0044
	sim_grads_norm_tr = -0.0111
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4830
	data_grads_norm = 6.1139
	new_data_grads_norm = 8.2290
	old_data_grads_norm = 7.3196
	sim_grads_norm_tr = 0.0827
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7449
	data_grads_norm = 4.7321
	new_data_grads_norm = 7.5521
	old_data_grads_norm = 5.9211
	sim_grads_norm_tr = 0.0340
-- Starting training on experience 213 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1983
	data_grads_norm = 4.8741
	new_data_grads_norm = 7.3255
	old_data_grads_norm = 6.2962
	sim_grads_norm_tr = 0.0257
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6094
	data_grads_norm = 4.3464
	new_data_grads_norm = 7.2991
	old_data_grads_norm = 3.5188
	sim_grads_norm_tr = 0.0750
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9425
	data_grads_norm = 4.9657
	new_data_grads_norm = 6.9754
	old_data_grads_norm = 6.9765
	sim_grads_norm_tr = 0.0066
-- Starting training on experience 214 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2008
	data_grads_norm = 5.7922
	new_data_grads_norm = 8.9622
	old_data_grads_norm = 5.5474
	sim_grads_norm_tr = 0.0430
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1418
	data_grads_norm = 5.6556
	new_data_grads_norm = 8.6053
	old_data_grads_norm = 5.9024
	sim_grads_norm_tr = 0.0103
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2458
	data_grads_norm = 6.4932
	new_data_grads_norm = 7.7641
	old_data_grads_norm = 7.2636
	sim_grads_norm_tr = -0.0098
-- Starting training on experience 215 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3191
	data_grads_norm = 6.1738
	new_data_grads_norm = 9.1211
	old_data_grads_norm = 6.6471
	sim_grads_norm_tr = -0.0021
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9787
	data_grads_norm = 5.5483
	new_data_grads_norm = 8.0960
	old_data_grads_norm = 7.8547
	sim_grads_norm_tr = -0.0071
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6644
	data_grads_norm = 5.5730
	new_data_grads_norm = 8.6739
	old_data_grads_norm = 6.8315
	sim_grads_norm_tr = -0.0121
-- Starting training on experience 216 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0786
	data_grads_norm = 4.7730
	new_data_grads_norm = 7.0818
	old_data_grads_norm = 5.0755
	sim_grads_norm_tr = 0.0203
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9902
	data_grads_norm = 4.2155
	new_data_grads_norm = 7.6820
	old_data_grads_norm = 4.4380
	sim_grads_norm_tr = -0.0198
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8801
	data_grads_norm = 4.7587
	new_data_grads_norm = 7.4931
	old_data_grads_norm = 4.8850
	sim_grads_norm_tr = 0.0278
-- Starting training on experience 217 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8549
	data_grads_norm = 6.0341
	new_data_grads_norm = 7.7473
	old_data_grads_norm = 7.6585
	sim_grads_norm_tr = 0.0568
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2606
	data_grads_norm = 5.2968
	new_data_grads_norm = 6.5739
	old_data_grads_norm = 7.4688
	sim_grads_norm_tr = 0.0498
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1790
	data_grads_norm = 5.6485
	new_data_grads_norm = 6.8291
	old_data_grads_norm = 6.9850
	sim_grads_norm_tr = 0.0367
-- Starting training on experience 218 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0506
	data_grads_norm = 5.1181
	new_data_grads_norm = 6.9893
	old_data_grads_norm = 7.1150
	sim_grads_norm_tr = 0.0140
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2796
	data_grads_norm = 5.6658
	new_data_grads_norm = 8.2213
	old_data_grads_norm = 6.8659
	sim_grads_norm_tr = 0.0157
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2070
	data_grads_norm = 4.8794
	new_data_grads_norm = 7.2295
	old_data_grads_norm = 6.2506
	sim_grads_norm_tr = 0.0198
-- Starting training on experience 219 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8494
	data_grads_norm = 4.3347
	new_data_grads_norm = 8.4889
	old_data_grads_norm = 5.3714
	sim_grads_norm_tr = 0.0639
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8229
	data_grads_norm = 4.9918
	new_data_grads_norm = 9.1270
	old_data_grads_norm = 6.5718
	sim_grads_norm_tr = 0.0025
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3726
	data_grads_norm = 5.7392
	new_data_grads_norm = 8.9960
	old_data_grads_norm = 6.7992
	sim_grads_norm_tr = 0.0448
-- Starting training on experience 220 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1293
	data_grads_norm = 5.6365
	new_data_grads_norm = 8.8699
	old_data_grads_norm = 4.2424
	sim_grads_norm_tr = 0.0210
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3971
	data_grads_norm = 5.9845
	new_data_grads_norm = 7.6220
	old_data_grads_norm = 8.1643
	sim_grads_norm_tr = 0.0057
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2082
	data_grads_norm = 5.7278
	new_data_grads_norm = 7.9583
	old_data_grads_norm = 8.2763
	sim_grads_norm_tr = 0.0155
-- Starting training on experience 221 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4497
	data_grads_norm = 4.6113
	new_data_grads_norm = 8.0487
	old_data_grads_norm = 6.0483
	sim_grads_norm_tr = -0.0636
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5312
	data_grads_norm = 4.9533
	new_data_grads_norm = 7.7577
	old_data_grads_norm = 6.2574
	sim_grads_norm_tr = -0.0755
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7471
	data_grads_norm = 5.7997
	new_data_grads_norm = 9.4601
	old_data_grads_norm = 6.7923
	sim_grads_norm_tr = 0.0485
-- Starting training on experience 222 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9095
	data_grads_norm = 5.3896
	new_data_grads_norm = 7.8289
	old_data_grads_norm = 7.9967
	sim_grads_norm_tr = 0.0305
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0341
	data_grads_norm = 6.6887
	new_data_grads_norm = 8.7832
	old_data_grads_norm = 8.8214
	sim_grads_norm_tr = -0.0201
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9508
	data_grads_norm = 6.0610
	new_data_grads_norm = 9.2663
	old_data_grads_norm = 8.8492
	sim_grads_norm_tr = 0.0043
-- Starting training on experience 223 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0028
	data_grads_norm = 5.2430
	new_data_grads_norm = 7.1584
	old_data_grads_norm = 5.8173
	sim_grads_norm_tr = 0.1529
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6969
	data_grads_norm = 4.5758
	new_data_grads_norm = 7.0627
	old_data_grads_norm = 6.3805
	sim_grads_norm_tr = -0.0237
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3605
	data_grads_norm = 4.0298
	new_data_grads_norm = 7.1972
	old_data_grads_norm = 5.1426
	sim_grads_norm_tr = -0.0080
-- Starting training on experience 224 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6689
	data_grads_norm = 4.0753
	new_data_grads_norm = 7.9579
	old_data_grads_norm = 4.5087
	sim_grads_norm_tr = -0.0104
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8638
	data_grads_norm = 5.0039
	new_data_grads_norm = 8.0441
	old_data_grads_norm = 5.4439
	sim_grads_norm_tr = 0.0869
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5508
	data_grads_norm = 4.6444
	new_data_grads_norm = 7.4635
	old_data_grads_norm = 5.9545
	sim_grads_norm_tr = -0.0205
-- Starting training on experience 225 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8388
	data_grads_norm = 4.7164
	new_data_grads_norm = 6.8542
	old_data_grads_norm = 4.5580
	sim_grads_norm_tr = -0.0171
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8929
	data_grads_norm = 5.0681
	new_data_grads_norm = 7.7902
	old_data_grads_norm = 5.7141
	sim_grads_norm_tr = 0.0050
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1013
	data_grads_norm = 5.9115
	new_data_grads_norm = 7.4422
	old_data_grads_norm = 10.0593
	sim_grads_norm_tr = 0.0179
-- Starting training on experience 226 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2836
	data_grads_norm = 5.3849
	new_data_grads_norm = 8.7749
	old_data_grads_norm = 7.7181
	sim_grads_norm_tr = -0.0141
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3434
	data_grads_norm = 6.0613
	new_data_grads_norm = 8.4613
	old_data_grads_norm = 8.4959
	sim_grads_norm_tr = 0.0309
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2062
	data_grads_norm = 5.7735
	new_data_grads_norm = 8.4353
	old_data_grads_norm = 8.0270
	sim_grads_norm_tr = 0.0030
-- Starting training on experience 227 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4790
	data_grads_norm = 4.8385
	new_data_grads_norm = 9.7356
	old_data_grads_norm = 3.9685
	sim_grads_norm_tr = 0.0134
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4319
	data_grads_norm = 5.3216
	new_data_grads_norm = 9.5537
	old_data_grads_norm = 8.5923
	sim_grads_norm_tr = -0.0094
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8150
	data_grads_norm = 5.6188
	new_data_grads_norm = 9.9737
	old_data_grads_norm = 7.6543
	sim_grads_norm_tr = 0.0254
-- Starting training on experience 228 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8155
	data_grads_norm = 6.0582
	new_data_grads_norm = 9.7089
	old_data_grads_norm = 5.9226
	sim_grads_norm_tr = -0.0328
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2475
	data_grads_norm = 6.1325
	new_data_grads_norm = 8.9645
	old_data_grads_norm = 7.1400
	sim_grads_norm_tr = 0.0914
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8060
	data_grads_norm = 5.7372
	new_data_grads_norm = 8.7132
	old_data_grads_norm = 7.1887
	sim_grads_norm_tr = 0.0313
-- Starting training on experience 229 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7660
	data_grads_norm = 5.0494
	new_data_grads_norm = 7.5660
	old_data_grads_norm = 7.9354
	sim_grads_norm_tr = 0.0082
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2498
	data_grads_norm = 6.1054
	new_data_grads_norm = 8.3729
	old_data_grads_norm = 7.3607
	sim_grads_norm_tr = 0.0393
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9626
	data_grads_norm = 5.5844
	new_data_grads_norm = 7.9974
	old_data_grads_norm = 9.5328
	sim_grads_norm_tr = 0.0313
-- Starting training on experience 230 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4237
	data_grads_norm = 4.8258
	new_data_grads_norm = 6.2409
	old_data_grads_norm = 8.8466
	sim_grads_norm_tr = 0.0083
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2647
	data_grads_norm = 3.8353
	new_data_grads_norm = 6.5921
	old_data_grads_norm = 5.8107
	sim_grads_norm_tr = -0.0686
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5904
	data_grads_norm = 4.5705
	new_data_grads_norm = 7.1145
	old_data_grads_norm = 4.9123
	sim_grads_norm_tr = 0.0557
-- Starting training on experience 231 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6298
	data_grads_norm = 4.7057
	new_data_grads_norm = 7.3117
	old_data_grads_norm = 6.3399
	sim_grads_norm_tr = 0.0083
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7346
	data_grads_norm = 5.6696
	new_data_grads_norm = 8.5544
	old_data_grads_norm = 5.4523
	sim_grads_norm_tr = -0.0243
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9622
	data_grads_norm = 5.4625
	new_data_grads_norm = 8.9740
	old_data_grads_norm = 6.3494
	sim_grads_norm_tr = -0.0243
-- Starting training on experience 232 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1167
	data_grads_norm = 5.8140
	new_data_grads_norm = 9.3441
	old_data_grads_norm = 6.2870
	sim_grads_norm_tr = -0.0347
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7220
	data_grads_norm = 4.7344
	new_data_grads_norm = 8.1948
	old_data_grads_norm = 5.1536
	sim_grads_norm_tr = 0.0436
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0595
	data_grads_norm = 6.0408
	new_data_grads_norm = 9.5128
	old_data_grads_norm = 7.1979
	sim_grads_norm_tr = 0.0615
-- Starting training on experience 233 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2907
	data_grads_norm = 3.8795
	new_data_grads_norm = 8.3182
	old_data_grads_norm = 4.4855
	sim_grads_norm_tr = 0.0086
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0777
	data_grads_norm = 6.1505
	new_data_grads_norm = 8.1723
	old_data_grads_norm = 7.4897
	sim_grads_norm_tr = -0.0066
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6926
	data_grads_norm = 4.8318
	new_data_grads_norm = 8.6106
	old_data_grads_norm = 6.4723
	sim_grads_norm_tr = -0.0061
-- Starting training on experience 234 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0443
	data_grads_norm = 4.9696
	new_data_grads_norm = 6.8885
	old_data_grads_norm = 6.2424
	sim_grads_norm_tr = -0.0344
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8856
	data_grads_norm = 5.3549
	new_data_grads_norm = 7.4509
	old_data_grads_norm = 6.5256
	sim_grads_norm_tr = -0.0381
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8941
	data_grads_norm = 5.4152
	new_data_grads_norm = 6.9685
	old_data_grads_norm = 7.0242
	sim_grads_norm_tr = -0.0212
-- Starting training on experience 235 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1926
	data_grads_norm = 5.2148
	new_data_grads_norm = 7.4461
	old_data_grads_norm = 6.4504
	sim_grads_norm_tr = 0.0254
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1502
	data_grads_norm = 5.2570
	new_data_grads_norm = 8.3094
	old_data_grads_norm = 6.3775
	sim_grads_norm_tr = -0.0157
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0499
	data_grads_norm = 5.4191
	new_data_grads_norm = 7.4758
	old_data_grads_norm = 7.2013
	sim_grads_norm_tr = -0.0419
-- Starting training on experience 236 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6264
	data_grads_norm = 6.1804
	new_data_grads_norm = 9.2327
	old_data_grads_norm = 7.8627
	sim_grads_norm_tr = -0.0082
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6671
	data_grads_norm = 6.1073
	new_data_grads_norm = 8.5114
	old_data_grads_norm = 7.6250
	sim_grads_norm_tr = 0.0157
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0516
	data_grads_norm = 5.3544
	new_data_grads_norm = 8.5448
	old_data_grads_norm = 5.5504
	sim_grads_norm_tr = 0.0153
-- Starting training on experience 237 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
-- >> End of training phase << --
-- >> Start of eval phase << --
-- Starting eval on experience 0 (Task 0) from test stream --
> Eval on experience 0 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp000 = 3.7222
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.2780
	mb_index = 3808
	time = 1463.5400
-- Starting eval on experience 1 (Task 0) from test stream --
> Eval on experience 1 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp001 = 2.7573
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.4880
-- Starting eval on experience 2 (Task 0) from test stream --
> Eval on experience 2 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp002 = 4.0431
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.3060
-- Starting eval on experience 3 (Task 0) from test stream --
> Eval on experience 3 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp003 = 3.1243
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.4240
-- Starting eval on experience 4 (Task 0) from test stream --
> Eval on experience 4 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp004 = 4.6824
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.2060
-- Starting eval on experience 5 (Task 0) from test stream --
> Eval on experience 5 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp005 = 3.2901
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.3440
-- Starting eval on experience 6 (Task 0) from test stream --
> Eval on experience 6 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp006 = 3.7433
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp006 = 0.2520
-- Starting eval on experience 7 (Task 0) from test stream --
> Eval on experience 7 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp007 = 3.4133
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp007 = 0.3820
-- Starting eval on experience 8 (Task 0) from test stream --
> Eval on experience 8 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp008 = 3.5907
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp008 = 0.3020
-- Starting eval on experience 9 (Task 0) from test stream --
> Eval on experience 9 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp009 = 3.5168
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp009 = 0.3020
-- Starting eval on experience 10 (Task 0) from test stream --
> Eval on experience 10 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp010 = 4.1306
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp010 = 0.1460
-- Starting eval on experience 11 (Task 0) from test stream --
> Eval on experience 11 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp011 = 2.4110
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp011 = 0.4060
-- Starting eval on experience 12 (Task 0) from test stream --
> Eval on experience 12 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp012 = 4.3097
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp012 = 0.1520
-- Starting eval on experience 13 (Task 0) from test stream --
> Eval on experience 13 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp013 = 3.5656
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp013 = 0.2280
-- Starting eval on experience 14 (Task 0) from test stream --
> Eval on experience 14 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp014 = 3.4762
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp014 = 0.1820
-- Starting eval on experience 15 (Task 0) from test stream --
> Eval on experience 15 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp015 = 3.5618
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp015 = 0.1440
-- >> End of eval phase << --
	CumulativeAccuracy/eval_phase/test_stream/Exp000 = 0.7320
	CumulativeAccuracy/eval_phase/test_stream/Exp001 = 0.6700
	CumulativeAccuracy/eval_phase/test_stream/Exp002 = 0.5680
	CumulativeAccuracy/eval_phase/test_stream/Exp003 = 0.5435
	CumulativeAccuracy/eval_phase/test_stream/Exp004 = 0.4924
	CumulativeAccuracy/eval_phase/test_stream/Exp005 = 0.4690
	CumulativeAccuracy/eval_phase/test_stream/Exp006 = 0.4383
	CumulativeAccuracy/eval_phase/test_stream/Exp007 = 0.4170
	CumulativeAccuracy/eval_phase/test_stream/Exp008 = 0.4000
	CumulativeAccuracy/eval_phase/test_stream/Exp009 = 0.3820
	CumulativeAccuracy/eval_phase/test_stream/Exp010 = 0.3556
	CumulativeAccuracy/eval_phase/test_stream/Exp011 = 0.3432
	CumulativeAccuracy/eval_phase/test_stream/Exp012 = 0.3209
	CumulativeAccuracy/eval_phase/test_stream/Exp013 = 0.3083
	CumulativeAccuracy/eval_phase/test_stream/Exp014 = 0.2969
	CumulativeAccuracy/eval_phase/test_stream/Exp015 = 0.2839
	Loss_Stream/eval_phase/test_stream/Task000 = 3.5836
	Top1_Acc_Stream/eval_phase/test_stream/Task000 = 0.2839
-- >> Start of training phase << --
-- Starting training on experience 0 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6571
	data_grads_norm = 5.9034
	new_data_grads_norm = 7.7947
	old_data_grads_norm = 6.5690
	sim_grads_norm_tr = -0.0048
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2966
	data_grads_norm = 4.8756
	new_data_grads_norm = 7.5256
	old_data_grads_norm = 7.1445
	sim_grads_norm_tr = 0.0080
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3697
	data_grads_norm = 5.2757
	new_data_grads_norm = 6.7915
	old_data_grads_norm = 7.7901
	sim_grads_norm_tr = -0.0191
-- Starting training on experience 1 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.0363
	data_grads_norm = 7.0295
	new_data_grads_norm = 9.8400
	old_data_grads_norm = 8.0507
	sim_grads_norm_tr = 0.0384
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.1732
	data_grads_norm = 6.9502
	new_data_grads_norm = 10.2474
	old_data_grads_norm = 6.5862
	sim_grads_norm_tr = 0.0057
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.1982
	data_grads_norm = 6.5598
	new_data_grads_norm = 9.4884
	old_data_grads_norm = 7.1922
	sim_grads_norm_tr = 0.0144
-- Starting training on experience 2 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3732
	data_grads_norm = 5.3480
	new_data_grads_norm = 9.3937
	old_data_grads_norm = 5.6390
	sim_grads_norm_tr = 0.0181
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.7477
	data_grads_norm = 5.7920
	new_data_grads_norm = 8.6006
	old_data_grads_norm = 7.7857
	sim_grads_norm_tr = 0.0780
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.7800
	data_grads_norm = 5.8506
	new_data_grads_norm = 8.5405
	old_data_grads_norm = 8.2791
	sim_grads_norm_tr = 0.0036
-- Starting training on experience 3 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6213
	data_grads_norm = 5.8517
	new_data_grads_norm = 7.8705
	old_data_grads_norm = 7.2978
	sim_grads_norm_tr = -0.0109
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5717
	data_grads_norm = 5.5143
	new_data_grads_norm = 7.9562
	old_data_grads_norm = 4.5404
	sim_grads_norm_tr = 0.0037
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3952
	data_grads_norm = 5.5391
	new_data_grads_norm = 9.1465
	old_data_grads_norm = 4.9863
	sim_grads_norm_tr = -0.0264
-- Starting training on experience 4 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6711
	data_grads_norm = 6.1316
	new_data_grads_norm = 6.6663
	old_data_grads_norm = 8.9569
	sim_grads_norm_tr = 0.0209
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4623
	data_grads_norm = 4.9983
	new_data_grads_norm = 7.3333
	old_data_grads_norm = 5.9860
	sim_grads_norm_tr = -0.0093
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.9441
	data_grads_norm = 6.1275
	new_data_grads_norm = 7.7079
	old_data_grads_norm = 8.8745
	sim_grads_norm_tr = -0.0004
-- Starting training on experience 5 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3657
	data_grads_norm = 4.9954
	new_data_grads_norm = 7.9811
	old_data_grads_norm = 4.8467
	sim_grads_norm_tr = 0.0079
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4318
	data_grads_norm = 5.7009
	new_data_grads_norm = 7.4876
	old_data_grads_norm = 6.6482
	sim_grads_norm_tr = -0.0211
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.7469
	data_grads_norm = 6.1520
	new_data_grads_norm = 8.3043
	old_data_grads_norm = 7.9178
	sim_grads_norm_tr = 0.0322
-- Starting training on experience 6 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6471
	data_grads_norm = 6.0693
	new_data_grads_norm = 9.3085
	old_data_grads_norm = 5.6513
	sim_grads_norm_tr = -0.0011
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.8269
	data_grads_norm = 6.4569
	new_data_grads_norm = 10.2519
	old_data_grads_norm = 5.4273
	sim_grads_norm_tr = -0.0158
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.9757
	data_grads_norm = 6.2531
	new_data_grads_norm = 9.1443
	old_data_grads_norm = 6.7544
	sim_grads_norm_tr = 0.0184
-- Starting training on experience 7 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.8087
	data_grads_norm = 7.3094
	new_data_grads_norm = 9.5874
	old_data_grads_norm = 8.6522
	sim_grads_norm_tr = 0.0129
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.1365
	data_grads_norm = 6.0977
	new_data_grads_norm = 9.9602
	old_data_grads_norm = 5.7591
	sim_grads_norm_tr = 0.0374
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6083
	data_grads_norm = 6.3353
	new_data_grads_norm = 9.7651
	old_data_grads_norm = 6.7868
	sim_grads_norm_tr = 0.0039
-- Starting training on experience 8 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.0495
	data_grads_norm = 6.1517
	new_data_grads_norm = 8.5096
	old_data_grads_norm = 7.9637
	sim_grads_norm_tr = 0.0498
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.8378
	data_grads_norm = 5.7444
	new_data_grads_norm = 8.1996
	old_data_grads_norm = 7.0730
	sim_grads_norm_tr = 0.0096
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2567
	data_grads_norm = 5.6231
	new_data_grads_norm = 8.4479
	old_data_grads_norm = 5.3329
	sim_grads_norm_tr = 0.0099
-- Starting training on experience 9 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.9708
	data_grads_norm = 6.0366
	new_data_grads_norm = 8.1549
	old_data_grads_norm = 7.5250
	sim_grads_norm_tr = 0.0197
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.6624
	data_grads_norm = 6.7558
	new_data_grads_norm = 9.7734
	old_data_grads_norm = 8.5634
	sim_grads_norm_tr = -0.0074
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.0254
	data_grads_norm = 6.2653
	new_data_grads_norm = 9.8538
	old_data_grads_norm = 5.7274
	sim_grads_norm_tr = 0.0229
-- Starting training on experience 10 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.8780
	data_grads_norm = 6.4817
	new_data_grads_norm = 9.3440
	old_data_grads_norm = 7.5323
	sim_grads_norm_tr = 0.0303
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0839
	data_grads_norm = 6.2771
	new_data_grads_norm = 9.5787
	old_data_grads_norm = 5.5481
	sim_grads_norm_tr = -0.0194
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.7859
	data_grads_norm = 6.5054
	new_data_grads_norm = 8.7032
	old_data_grads_norm = 8.1425
	sim_grads_norm_tr = 0.0909
-- Starting training on experience 11 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6269
	data_grads_norm = 6.7382
	new_data_grads_norm = 8.1469
	old_data_grads_norm = 9.5410
	sim_grads_norm_tr = 0.0374
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1355
	data_grads_norm = 5.0447
	new_data_grads_norm = 6.8969
	old_data_grads_norm = 7.0288
	sim_grads_norm_tr = 0.0604
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5030
	data_grads_norm = 5.1824
	new_data_grads_norm = 7.7909
	old_data_grads_norm = 5.8383
	sim_grads_norm_tr = 0.0081
-- Starting training on experience 12 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.0565
	data_grads_norm = 6.3948
	new_data_grads_norm = 7.7419
	old_data_grads_norm = 9.2210
	sim_grads_norm_tr = 0.0731
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1372
	data_grads_norm = 5.4304
	new_data_grads_norm = 7.4210
	old_data_grads_norm = 6.5825
	sim_grads_norm_tr = 0.0056
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2572
	data_grads_norm = 5.6828
	new_data_grads_norm = 7.3654
	old_data_grads_norm = 7.4895
	sim_grads_norm_tr = 0.0110
-- Starting training on experience 13 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0317
	data_grads_norm = 5.6544
	new_data_grads_norm = 9.4023
	old_data_grads_norm = 7.0511
	sim_grads_norm_tr = -0.0059
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5812
	data_grads_norm = 6.4562
	new_data_grads_norm = 8.9219
	old_data_grads_norm = 8.2913
	sim_grads_norm_tr = -0.0138
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7063
	data_grads_norm = 4.9500
	new_data_grads_norm = 8.0753
	old_data_grads_norm = 6.5390
	sim_grads_norm_tr = -0.0092
-- Starting training on experience 14 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6043
	data_grads_norm = 5.9569
	new_data_grads_norm = 8.7270
	old_data_grads_norm = 6.1555
	sim_grads_norm_tr = -0.0044
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3774
	data_grads_norm = 6.1388
	new_data_grads_norm = 9.0712
	old_data_grads_norm = 7.0048
	sim_grads_norm_tr = 0.0024
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9829
	data_grads_norm = 5.3249
	new_data_grads_norm = 8.1811
	old_data_grads_norm = 6.7501
	sim_grads_norm_tr = -0.0207
-- Starting training on experience 15 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4100
	data_grads_norm = 5.7149
	new_data_grads_norm = 6.7919
	old_data_grads_norm = 8.3989
	sim_grads_norm_tr = 0.0377
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9467
	data_grads_norm = 5.1899
	new_data_grads_norm = 6.4084
	old_data_grads_norm = 5.8806
	sim_grads_norm_tr = 0.0014
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9013
	data_grads_norm = 4.7225
	new_data_grads_norm = 6.5986
	old_data_grads_norm = 7.9385
	sim_grads_norm_tr = 0.0071
-- Starting training on experience 16 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6227
	data_grads_norm = 6.7938
	new_data_grads_norm = 10.3255
	old_data_grads_norm = 7.4364
	sim_grads_norm_tr = -0.0132
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4764
	data_grads_norm = 6.5145
	new_data_grads_norm = 9.3141
	old_data_grads_norm = 6.9377
	sim_grads_norm_tr = 0.0016
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.0374
	data_grads_norm = 7.0135
	new_data_grads_norm = 8.6843
	old_data_grads_norm = 8.4566
	sim_grads_norm_tr = 0.0232
-- Starting training on experience 17 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.7256
	data_grads_norm = 6.6293
	new_data_grads_norm = 9.5620
	old_data_grads_norm = 7.9932
	sim_grads_norm_tr = 0.0429
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.0099
	data_grads_norm = 7.1217
	new_data_grads_norm = 10.5132
	old_data_grads_norm = 7.1086
	sim_grads_norm_tr = 0.1545
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1185
	data_grads_norm = 7.0512
	new_data_grads_norm = 9.5797
	old_data_grads_norm = 8.6458
	sim_grads_norm_tr = 0.0838
-- Starting training on experience 18 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4121
	data_grads_norm = 5.7204
	new_data_grads_norm = 9.1236
	old_data_grads_norm = 5.3952
	sim_grads_norm_tr = 0.1005
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0786
	data_grads_norm = 5.6116
	new_data_grads_norm = 9.0933
	old_data_grads_norm = 6.2909
	sim_grads_norm_tr = -0.0176
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5783
	data_grads_norm = 5.0621
	new_data_grads_norm = 8.7102
	old_data_grads_norm = 5.7568
	sim_grads_norm_tr = 0.0134
-- Starting training on experience 19 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7513
	data_grads_norm = 5.6491
	new_data_grads_norm = 10.4973
	old_data_grads_norm = 6.1581
	sim_grads_norm_tr = 0.0060
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6122
	data_grads_norm = 6.3978
	new_data_grads_norm = 10.5335
	old_data_grads_norm = 7.3086
	sim_grads_norm_tr = 0.0236
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8039
	data_grads_norm = 6.8806
	new_data_grads_norm = 9.7237
	old_data_grads_norm = 8.3311
	sim_grads_norm_tr = -0.0234
-- Starting training on experience 20 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8685
	data_grads_norm = 6.2849
	new_data_grads_norm = 9.1033
	old_data_grads_norm = 5.8759
	sim_grads_norm_tr = 0.0204
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5678
	data_grads_norm = 5.9672
	new_data_grads_norm = 8.8760
	old_data_grads_norm = 7.0723
	sim_grads_norm_tr = 0.0040
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1592
	data_grads_norm = 4.8365
	new_data_grads_norm = 8.1316
	old_data_grads_norm = 5.4118
	sim_grads_norm_tr = 0.0345
-- Starting training on experience 21 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6840
	data_grads_norm = 6.2460
	new_data_grads_norm = 8.9710
	old_data_grads_norm = 7.1418
	sim_grads_norm_tr = -0.0075
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9867
	data_grads_norm = 6.7244
	new_data_grads_norm = 8.9177
	old_data_grads_norm = 8.0148
	sim_grads_norm_tr = 0.0353
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9331
	data_grads_norm = 5.7635
	new_data_grads_norm = 8.5178
	old_data_grads_norm = 6.9737
	sim_grads_norm_tr = 0.0169
-- Starting training on experience 22 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8036
	data_grads_norm = 6.0490
	new_data_grads_norm = 8.3847
	old_data_grads_norm = 7.5989
	sim_grads_norm_tr = 0.0212
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3243
	data_grads_norm = 5.4946
	new_data_grads_norm = 8.5777
	old_data_grads_norm = 5.4787
	sim_grads_norm_tr = -0.0109
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1186
	data_grads_norm = 4.7100
	new_data_grads_norm = 8.0773
	old_data_grads_norm = 3.0483
	sim_grads_norm_tr = -0.0018
-- Starting training on experience 23 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0554
	data_grads_norm = 4.5807
	new_data_grads_norm = 7.8948
	old_data_grads_norm = 4.4819
	sim_grads_norm_tr = 0.0053
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9075
	data_grads_norm = 5.0466
	new_data_grads_norm = 8.0399
	old_data_grads_norm = 4.8926
	sim_grads_norm_tr = 0.0011
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2784
	data_grads_norm = 5.5109
	new_data_grads_norm = 8.2498
	old_data_grads_norm = 7.8035
	sim_grads_norm_tr = 0.0245
-- Starting training on experience 24 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4079
	data_grads_norm = 5.7633
	new_data_grads_norm = 9.1243
	old_data_grads_norm = 5.2360
	sim_grads_norm_tr = 0.0186
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9910
	data_grads_norm = 5.6799
	new_data_grads_norm = 8.7010
	old_data_grads_norm = 6.3327
	sim_grads_norm_tr = -0.0481
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8900
	data_grads_norm = 6.3848
	new_data_grads_norm = 9.3495
	old_data_grads_norm = 6.9776
	sim_grads_norm_tr = 0.0029
-- Starting training on experience 25 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7981
	data_grads_norm = 4.2139
	new_data_grads_norm = 7.9824
	old_data_grads_norm = 3.8197
	sim_grads_norm_tr = -0.0340
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1083
	data_grads_norm = 5.2055
	new_data_grads_norm = 8.7557
	old_data_grads_norm = 5.3379
	sim_grads_norm_tr = -0.0074
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6814
	data_grads_norm = 5.6055
	new_data_grads_norm = 8.6126
	old_data_grads_norm = 6.3466
	sim_grads_norm_tr = 0.1036
-- Starting training on experience 26 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8953
	data_grads_norm = 5.5050
	new_data_grads_norm = 7.9417
	old_data_grads_norm = 7.4217
	sim_grads_norm_tr = -0.0250
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0089
	data_grads_norm = 5.3093
	new_data_grads_norm = 7.6168
	old_data_grads_norm = 7.5140
	sim_grads_norm_tr = -0.0057
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7010
	data_grads_norm = 5.6028
	new_data_grads_norm = 8.1996
	old_data_grads_norm = 6.2337
	sim_grads_norm_tr = 0.0060
-- Starting training on experience 27 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1828
	data_grads_norm = 5.0126
	new_data_grads_norm = 8.3911
	old_data_grads_norm = 4.5055
	sim_grads_norm_tr = 0.0398
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9008
	data_grads_norm = 4.7371
	new_data_grads_norm = 7.2386
	old_data_grads_norm = 5.0704
	sim_grads_norm_tr = -0.0240
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2323
	data_grads_norm = 5.8729
	new_data_grads_norm = 9.0266
	old_data_grads_norm = 8.5250
	sim_grads_norm_tr = 0.0154
-- Starting training on experience 28 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4923
	data_grads_norm = 5.1164
	new_data_grads_norm = 8.2083
	old_data_grads_norm = 5.5658
	sim_grads_norm_tr = 0.0507
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3903
	data_grads_norm = 5.6185
	new_data_grads_norm = 8.5964
	old_data_grads_norm = 6.6158
	sim_grads_norm_tr = 0.0269
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6067
	data_grads_norm = 6.5066
	new_data_grads_norm = 9.0929
	old_data_grads_norm = 8.2731
	sim_grads_norm_tr = 0.0095
-- Starting training on experience 29 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9596
	data_grads_norm = 6.2284
	new_data_grads_norm = 8.4429
	old_data_grads_norm = 7.0698
	sim_grads_norm_tr = 0.1139
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1585
	data_grads_norm = 5.8721
	new_data_grads_norm = 9.0439
	old_data_grads_norm = 6.0489
	sim_grads_norm_tr = -0.0510
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3373
	data_grads_norm = 6.7395
	new_data_grads_norm = 9.0500
	old_data_grads_norm = 8.8557
	sim_grads_norm_tr = -0.0119
-- Starting training on experience 30 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0477
	data_grads_norm = 4.8697
	new_data_grads_norm = 8.1616
	old_data_grads_norm = 3.8718
	sim_grads_norm_tr = -0.0432
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0640
	data_grads_norm = 6.8613
	new_data_grads_norm = 8.6756
	old_data_grads_norm = 9.5865
	sim_grads_norm_tr = 0.0270
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4792
	data_grads_norm = 6.8183
	new_data_grads_norm = 9.1495
	old_data_grads_norm = 9.7034
	sim_grads_norm_tr = 0.0320
-- Starting training on experience 31 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0504
	data_grads_norm = 4.9316
	new_data_grads_norm = 6.9001
	old_data_grads_norm = 7.5856
	sim_grads_norm_tr = 0.0300
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9976
	data_grads_norm = 5.4886
	new_data_grads_norm = 7.0612
	old_data_grads_norm = 7.7508
	sim_grads_norm_tr = 0.0750
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5203
	data_grads_norm = 4.3175
	new_data_grads_norm = 7.3303
	old_data_grads_norm = 4.8055
	sim_grads_norm_tr = -0.0119
-- Starting training on experience 32 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4501
	data_grads_norm = 6.2891
	new_data_grads_norm = 9.6973
	old_data_grads_norm = 6.3360
	sim_grads_norm_tr = 0.0509
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9528
	data_grads_norm = 5.8329
	new_data_grads_norm = 8.9019
	old_data_grads_norm = 5.8433
	sim_grads_norm_tr = 0.0106
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1396
	data_grads_norm = 6.6379
	new_data_grads_norm = 8.4180
	old_data_grads_norm = 8.3893
	sim_grads_norm_tr = 0.0289
-- Starting training on experience 33 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9658
	data_grads_norm = 5.2875
	new_data_grads_norm = 8.3570
	old_data_grads_norm = 6.9941
	sim_grads_norm_tr = -0.0457
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2643
	data_grads_norm = 6.4250
	new_data_grads_norm = 8.0755
	old_data_grads_norm = 10.0150
	sim_grads_norm_tr = 0.0409
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7218
	data_grads_norm = 5.2756
	new_data_grads_norm = 8.9175
	old_data_grads_norm = 3.6824
	sim_grads_norm_tr = -0.0053
-- Starting training on experience 34 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0362
	data_grads_norm = 5.7992
	new_data_grads_norm = 9.2210
	old_data_grads_norm = 5.3605
	sim_grads_norm_tr = 0.0276
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1481
	data_grads_norm = 5.8095
	new_data_grads_norm = 9.7614
	old_data_grads_norm = 6.0704
	sim_grads_norm_tr = -0.0023
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0007
	data_grads_norm = 5.5495
	new_data_grads_norm = 9.5715
	old_data_grads_norm = 5.8016
	sim_grads_norm_tr = 0.0446
-- Starting training on experience 35 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4147
	data_grads_norm = 4.5219
	new_data_grads_norm = 6.9005
	old_data_grads_norm = 6.8948
	sim_grads_norm_tr = 0.0375
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9807
	data_grads_norm = 5.3039
	new_data_grads_norm = 6.9295
	old_data_grads_norm = 7.5544
	sim_grads_norm_tr = -0.0112
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5652
	data_grads_norm = 4.6657
	new_data_grads_norm = 6.8667
	old_data_grads_norm = 5.3747
	sim_grads_norm_tr = -0.0215
-- Starting training on experience 36 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4775
	data_grads_norm = 4.5377
	new_data_grads_norm = 7.5880
	old_data_grads_norm = 4.9117
	sim_grads_norm_tr = -0.0226
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1503
	data_grads_norm = 5.4241
	new_data_grads_norm = 6.8901
	old_data_grads_norm = 6.8386
	sim_grads_norm_tr = 0.0778
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6789
	data_grads_norm = 6.1307
	new_data_grads_norm = 8.6216
	old_data_grads_norm = 7.3633
	sim_grads_norm_tr = 0.0507
-- Starting training on experience 37 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5743
	data_grads_norm = 5.8167
	new_data_grads_norm = 9.1406
	old_data_grads_norm = 7.0475
	sim_grads_norm_tr = -0.0328
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0261
	data_grads_norm = 5.7755
	new_data_grads_norm = 9.9175
	old_data_grads_norm = 5.7651
	sim_grads_norm_tr = 0.0498
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8910
	data_grads_norm = 5.8110
	new_data_grads_norm = 9.4127
	old_data_grads_norm = 5.9312
	sim_grads_norm_tr = 0.0440
-- Starting training on experience 38 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8284
	data_grads_norm = 6.1850
	new_data_grads_norm = 8.2336
	old_data_grads_norm = 8.4795
	sim_grads_norm_tr = 0.0719
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5175
	data_grads_norm = 5.5258
	new_data_grads_norm = 7.0270
	old_data_grads_norm = 8.1851
	sim_grads_norm_tr = -0.0162
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8160
	data_grads_norm = 5.7541
	new_data_grads_norm = 7.5614
	old_data_grads_norm = 6.9405
	sim_grads_norm_tr = -0.0164
-- Starting training on experience 39 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4663
	data_grads_norm = 5.2924
	new_data_grads_norm = 7.4410
	old_data_grads_norm = 4.8295
	sim_grads_norm_tr = 0.0846
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9617
	data_grads_norm = 6.0781
	new_data_grads_norm = 7.5668
	old_data_grads_norm = 6.6730
	sim_grads_norm_tr = -0.0005
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7833
	data_grads_norm = 6.1644
	new_data_grads_norm = 7.4193
	old_data_grads_norm = 9.4048
	sim_grads_norm_tr = -0.0222
-- Starting training on experience 40 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9048
	data_grads_norm = 5.6370
	new_data_grads_norm = 7.4691
	old_data_grads_norm = 8.0572
	sim_grads_norm_tr = -0.0239
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2436
	data_grads_norm = 6.1526
	new_data_grads_norm = 8.0088
	old_data_grads_norm = 6.9064
	sim_grads_norm_tr = 0.0383
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9161
	data_grads_norm = 5.6846
	new_data_grads_norm = 8.0755
	old_data_grads_norm = 6.6969
	sim_grads_norm_tr = 0.0075
-- Starting training on experience 41 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7299
	data_grads_norm = 5.2076
	new_data_grads_norm = 8.4184
	old_data_grads_norm = 5.3881
	sim_grads_norm_tr = 0.0317
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4645
	data_grads_norm = 4.7435
	new_data_grads_norm = 8.1833
	old_data_grads_norm = 5.0253
	sim_grads_norm_tr = 0.0018
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9153
	data_grads_norm = 5.3779
	new_data_grads_norm = 8.0256
	old_data_grads_norm = 7.2564
	sim_grads_norm_tr = -0.0063
-- Starting training on experience 42 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3996
	data_grads_norm = 5.2561
	new_data_grads_norm = 7.2163
	old_data_grads_norm = 5.2796
	sim_grads_norm_tr = 0.0463
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4710
	data_grads_norm = 5.4922
	new_data_grads_norm = 8.0812
	old_data_grads_norm = 5.1436
	sim_grads_norm_tr = -0.0235
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0747
	data_grads_norm = 4.3965
	new_data_grads_norm = 6.4885
	old_data_grads_norm = 5.8261
	sim_grads_norm_tr = -0.0307
-- Starting training on experience 43 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5442
	data_grads_norm = 5.9919
	new_data_grads_norm = 7.8296
	old_data_grads_norm = 6.0623
	sim_grads_norm_tr = -0.0077
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6050
	data_grads_norm = 4.7391
	new_data_grads_norm = 7.0156
	old_data_grads_norm = 7.0621
	sim_grads_norm_tr = 0.0138
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9883
	data_grads_norm = 5.9394
	new_data_grads_norm = 7.2886
	old_data_grads_norm = 7.9104
	sim_grads_norm_tr = -0.0140
-- Starting training on experience 44 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5455
	data_grads_norm = 4.5739
	new_data_grads_norm = 7.3181
	old_data_grads_norm = 5.7516
	sim_grads_norm_tr = 0.0352
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8298
	data_grads_norm = 4.4523
	new_data_grads_norm = 6.4102
	old_data_grads_norm = 5.5171
	sim_grads_norm_tr = -0.0250
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5121
	data_grads_norm = 4.3221
	new_data_grads_norm = 6.5583
	old_data_grads_norm = 5.3489
	sim_grads_norm_tr = 0.0761
-- Starting training on experience 45 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4692
	data_grads_norm = 5.1703
	new_data_grads_norm = 8.4825
	old_data_grads_norm = 6.1434
	sim_grads_norm_tr = -0.0130
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0186
	data_grads_norm = 5.8833
	new_data_grads_norm = 8.6802
	old_data_grads_norm = 6.7870
	sim_grads_norm_tr = 0.0169
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8793
	data_grads_norm = 5.7811
	new_data_grads_norm = 8.0394
	old_data_grads_norm = 7.8530
	sim_grads_norm_tr = -0.0145
-- Starting training on experience 46 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3595
	data_grads_norm = 4.9846
	new_data_grads_norm = 6.5247
	old_data_grads_norm = 7.2251
	sim_grads_norm_tr = -0.0218
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3763
	data_grads_norm = 5.4600
	new_data_grads_norm = 7.3238
	old_data_grads_norm = 9.1762
	sim_grads_norm_tr = 0.0031
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3999
	data_grads_norm = 5.2330
	new_data_grads_norm = 8.1499
	old_data_grads_norm = 5.8722
	sim_grads_norm_tr = 0.0488
-- Starting training on experience 47 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4813
	data_grads_norm = 7.2115
	new_data_grads_norm = 7.7244
	old_data_grads_norm = 11.0031
	sim_grads_norm_tr = 0.0159
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7055
	data_grads_norm = 5.1150
	new_data_grads_norm = 7.5625
	old_data_grads_norm = 7.5712
	sim_grads_norm_tr = -0.0077
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6466
	data_grads_norm = 5.3425
	new_data_grads_norm = 7.8295
	old_data_grads_norm = 5.4890
	sim_grads_norm_tr = -0.0013
-- Starting training on experience 48 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7013
	data_grads_norm = 5.0309
	new_data_grads_norm = 8.5859
	old_data_grads_norm = 6.1596
	sim_grads_norm_tr = -0.0024
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7298
	data_grads_norm = 5.5950
	new_data_grads_norm = 7.9120
	old_data_grads_norm = 9.0297
	sim_grads_norm_tr = 0.0260
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9683
	data_grads_norm = 6.0582
	new_data_grads_norm = 8.9337
	old_data_grads_norm = 8.1288
	sim_grads_norm_tr = 0.0343
-- Starting training on experience 49 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5365
	data_grads_norm = 5.2420
	new_data_grads_norm = 7.5899
	old_data_grads_norm = 7.0616
	sim_grads_norm_tr = 0.0317
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2044
	data_grads_norm = 4.0080
	new_data_grads_norm = 6.7247
	old_data_grads_norm = 6.3210
	sim_grads_norm_tr = -0.0394
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7445
	data_grads_norm = 5.8266
	new_data_grads_norm = 8.7620
	old_data_grads_norm = 9.1051
	sim_grads_norm_tr = -0.0205
-- Starting training on experience 50 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3006
	data_grads_norm = 5.1301
	new_data_grads_norm = 9.0227
	old_data_grads_norm = 5.4193
	sim_grads_norm_tr = -0.0005
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6769
	data_grads_norm = 5.5282
	new_data_grads_norm = 8.1593
	old_data_grads_norm = 6.3631
	sim_grads_norm_tr = 0.0061
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2431
	data_grads_norm = 4.6098
	new_data_grads_norm = 7.5199
	old_data_grads_norm = 6.3044
	sim_grads_norm_tr = -0.0425
-- Starting training on experience 51 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8203
	data_grads_norm = 4.0613
	new_data_grads_norm = 7.0550
	old_data_grads_norm = 6.1635
	sim_grads_norm_tr = -0.0101
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3181
	data_grads_norm = 5.0731
	new_data_grads_norm = 6.9612
	old_data_grads_norm = 6.9874
	sim_grads_norm_tr = -0.0014
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4334
	data_grads_norm = 5.3155
	new_data_grads_norm = 7.3219
	old_data_grads_norm = 6.5701
	sim_grads_norm_tr = -0.0089
-- Starting training on experience 52 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2683
	data_grads_norm = 4.7463
	new_data_grads_norm = 6.5575
	old_data_grads_norm = 5.8994
	sim_grads_norm_tr = -0.0268
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5798
	data_grads_norm = 5.3162
	new_data_grads_norm = 7.5599
	old_data_grads_norm = 5.8821
	sim_grads_norm_tr = 0.0243
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7462
	data_grads_norm = 4.8342
	new_data_grads_norm = 6.7854
	old_data_grads_norm = 5.8042
	sim_grads_norm_tr = 0.0310
-- Starting training on experience 53 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6038
	data_grads_norm = 4.9015
	new_data_grads_norm = 6.5118
	old_data_grads_norm = 6.2478
	sim_grads_norm_tr = 0.0092
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1833
	data_grads_norm = 4.1928
	new_data_grads_norm = 6.9144
	old_data_grads_norm = 5.3666
	sim_grads_norm_tr = -0.0380
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6877
	data_grads_norm = 4.5566
	new_data_grads_norm = 7.0685
	old_data_grads_norm = 5.4409
	sim_grads_norm_tr = -0.0104
-- Starting training on experience 54 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9327
	data_grads_norm = 5.3078
	new_data_grads_norm = 8.4995
	old_data_grads_norm = 6.9187
	sim_grads_norm_tr = -0.0229
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4852
	data_grads_norm = 5.1083
	new_data_grads_norm = 7.0038
	old_data_grads_norm = 5.7982
	sim_grads_norm_tr = -0.0174
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5544
	data_grads_norm = 5.4867
	new_data_grads_norm = 8.0330
	old_data_grads_norm = 6.5547
	sim_grads_norm_tr = -0.0233
-- Starting training on experience 55 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3508
	data_grads_norm = 5.2451
	new_data_grads_norm = 7.4150
	old_data_grads_norm = 8.2069
	sim_grads_norm_tr = -0.0014
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3338
	data_grads_norm = 5.1185
	new_data_grads_norm = 7.2477
	old_data_grads_norm = 6.5696
	sim_grads_norm_tr = -0.0162
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1544
	data_grads_norm = 5.9878
	new_data_grads_norm = 8.3926
	old_data_grads_norm = 6.7223
	sim_grads_norm_tr = 0.0114
-- Starting training on experience 56 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2308
	data_grads_norm = 6.3743
	new_data_grads_norm = 8.7298
	old_data_grads_norm = 8.6253
	sim_grads_norm_tr = -0.0108
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4863
	data_grads_norm = 6.0655
	new_data_grads_norm = 9.6261
	old_data_grads_norm = 5.8161
	sim_grads_norm_tr = 0.0113
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1705
	data_grads_norm = 4.7737
	new_data_grads_norm = 9.1437
	old_data_grads_norm = 4.8105
	sim_grads_norm_tr = -0.0001
-- Starting training on experience 57 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1041
	data_grads_norm = 6.0857
	new_data_grads_norm = 8.3030
	old_data_grads_norm = 8.0550
	sim_grads_norm_tr = 0.0013
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8147
	data_grads_norm = 6.1151
	new_data_grads_norm = 9.5530
	old_data_grads_norm = 6.1345
	sim_grads_norm_tr = 0.0166
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6349
	data_grads_norm = 6.1354
	new_data_grads_norm = 8.9251
	old_data_grads_norm = 5.3817
	sim_grads_norm_tr = -0.0152
-- Starting training on experience 58 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0199
	data_grads_norm = 6.8041
	new_data_grads_norm = 9.1818
	old_data_grads_norm = 8.8873
	sim_grads_norm_tr = 0.0283
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9500
	data_grads_norm = 6.5384
	new_data_grads_norm = 9.1878
	old_data_grads_norm = 9.2161
	sim_grads_norm_tr = -0.0238
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8992
	data_grads_norm = 5.8565
	new_data_grads_norm = 8.6662
	old_data_grads_norm = 7.4599
	sim_grads_norm_tr = 0.0298
-- Starting training on experience 59 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1137
	data_grads_norm = 5.5727
	new_data_grads_norm = 8.6728
	old_data_grads_norm = 5.6135
	sim_grads_norm_tr = 0.0075
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4335
	data_grads_norm = 6.0424
	new_data_grads_norm = 7.9709
	old_data_grads_norm = 8.2998
	sim_grads_norm_tr = 0.0323
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9441
	data_grads_norm = 5.4946
	new_data_grads_norm = 8.6362
	old_data_grads_norm = 5.1614
	sim_grads_norm_tr = 0.0135
-- Starting training on experience 60 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5190
	data_grads_norm = 5.7381
	new_data_grads_norm = 8.4957
	old_data_grads_norm = 7.9697
	sim_grads_norm_tr = 0.0411
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5733
	data_grads_norm = 5.8356
	new_data_grads_norm = 9.0639
	old_data_grads_norm = 7.1639
	sim_grads_norm_tr = -0.0020
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1067
	data_grads_norm = 4.8971
	new_data_grads_norm = 8.6168
	old_data_grads_norm = 5.5355
	sim_grads_norm_tr = -0.0157
-- Starting training on experience 61 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2336
	data_grads_norm = 5.2046
	new_data_grads_norm = 8.4270
	old_data_grads_norm = 5.0950
	sim_grads_norm_tr = -0.0059
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0645
	data_grads_norm = 5.8521
	new_data_grads_norm = 8.3887
	old_data_grads_norm = 8.0239
	sim_grads_norm_tr = -0.0408
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6300
	data_grads_norm = 6.1128
	new_data_grads_norm = 8.9519
	old_data_grads_norm = 6.2846
	sim_grads_norm_tr = -0.0434
-- Starting training on experience 62 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0102
	data_grads_norm = 4.8745
	new_data_grads_norm = 8.4485
	old_data_grads_norm = 4.3968
	sim_grads_norm_tr = -0.0234
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6990
	data_grads_norm = 5.9610
	new_data_grads_norm = 9.0569
	old_data_grads_norm = 6.7080
	sim_grads_norm_tr = 0.0570
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5852
	data_grads_norm = 5.9214
	new_data_grads_norm = 7.4210
	old_data_grads_norm = 8.6304
	sim_grads_norm_tr = 0.0862
-- Starting training on experience 63 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9468
	data_grads_norm = 5.3529
	new_data_grads_norm = 7.0807
	old_data_grads_norm = 7.0289
	sim_grads_norm_tr = 0.0081
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2304
	data_grads_norm = 4.2826
	new_data_grads_norm = 5.9726
	old_data_grads_norm = 5.3712
	sim_grads_norm_tr = 0.0014
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5747
	data_grads_norm = 4.4997
	new_data_grads_norm = 6.9067
	old_data_grads_norm = 6.0917
	sim_grads_norm_tr = -0.0136
-- Starting training on experience 64 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7757
	data_grads_norm = 6.4451
	new_data_grads_norm = 7.2053
	old_data_grads_norm = 8.6824
	sim_grads_norm_tr = -0.0569
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1790
	data_grads_norm = 5.2144
	new_data_grads_norm = 6.9751
	old_data_grads_norm = 5.9228
	sim_grads_norm_tr = 0.1284
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0546
	data_grads_norm = 5.2484
	new_data_grads_norm = 7.5535
	old_data_grads_norm = 7.0507
	sim_grads_norm_tr = -0.0623
-- Starting training on experience 65 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6802
	data_grads_norm = 5.6323
	new_data_grads_norm = 7.6278
	old_data_grads_norm = 7.0359
	sim_grads_norm_tr = -0.0149
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6393
	data_grads_norm = 5.2516
	new_data_grads_norm = 8.5092
	old_data_grads_norm = 5.5907
	sim_grads_norm_tr = -0.0119
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7228
	data_grads_norm = 5.1052
	new_data_grads_norm = 7.8408
	old_data_grads_norm = 7.3947
	sim_grads_norm_tr = -0.0258
-- Starting training on experience 66 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1584
	data_grads_norm = 5.3960
	new_data_grads_norm = 6.2032
	old_data_grads_norm = 7.7758
	sim_grads_norm_tr = 0.0028
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6592
	data_grads_norm = 5.4432
	new_data_grads_norm = 7.4440
	old_data_grads_norm = 8.4088
	sim_grads_norm_tr = -0.0099
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5470
	data_grads_norm = 5.3649
	new_data_grads_norm = 6.3630
	old_data_grads_norm = 6.8254
	sim_grads_norm_tr = 0.0732
-- Starting training on experience 67 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9939
	data_grads_norm = 6.1390
	new_data_grads_norm = 9.2985
	old_data_grads_norm = 7.1540
	sim_grads_norm_tr = 0.0253
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8488
	data_grads_norm = 6.5982
	new_data_grads_norm = 9.7704
	old_data_grads_norm = 10.3355
	sim_grads_norm_tr = 0.0259
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1529
	data_grads_norm = 4.8689
	new_data_grads_norm = 9.2711
	old_data_grads_norm = 4.8542
	sim_grads_norm_tr = -0.0511
-- Starting training on experience 68 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4772
	data_grads_norm = 5.2585
	new_data_grads_norm = 7.6795
	old_data_grads_norm = 5.7655
	sim_grads_norm_tr = -0.0144
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6841
	data_grads_norm = 5.7854
	new_data_grads_norm = 7.9112
	old_data_grads_norm = 8.0411
	sim_grads_norm_tr = -0.0434
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6960
	data_grads_norm = 5.7599
	new_data_grads_norm = 8.3556
	old_data_grads_norm = 8.4326
	sim_grads_norm_tr = -0.0201
-- Starting training on experience 69 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5633
	data_grads_norm = 6.5955
	new_data_grads_norm = 8.2009
	old_data_grads_norm = 9.7791
	sim_grads_norm_tr = 0.0660
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4419
	data_grads_norm = 5.1751
	new_data_grads_norm = 7.7085
	old_data_grads_norm = 6.4673
	sim_grads_norm_tr = -0.0214
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5962
	data_grads_norm = 5.6451
	new_data_grads_norm = 8.2503
	old_data_grads_norm = 8.6011
	sim_grads_norm_tr = 0.0241
-- Starting training on experience 70 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4425
	data_grads_norm = 5.4783
	new_data_grads_norm = 6.8156
	old_data_grads_norm = 7.2796
	sim_grads_norm_tr = -0.0199
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5410
	data_grads_norm = 4.7919
	new_data_grads_norm = 6.7564
	old_data_grads_norm = 6.3202
	sim_grads_norm_tr = 0.0228
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3642
	data_grads_norm = 4.7178
	new_data_grads_norm = 6.1227
	old_data_grads_norm = 7.6631
	sim_grads_norm_tr = 0.0063
-- Starting training on experience 71 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4311
	data_grads_norm = 5.1316
	new_data_grads_norm = 8.2869
	old_data_grads_norm = 5.1746
	sim_grads_norm_tr = -0.0208
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1014
	data_grads_norm = 6.9842
	new_data_grads_norm = 8.9550
	old_data_grads_norm = 10.1219
	sim_grads_norm_tr = 0.0399
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5510
	data_grads_norm = 6.1054
	new_data_grads_norm = 8.2851
	old_data_grads_norm = 8.3193
	sim_grads_norm_tr = -0.0044
-- Starting training on experience 72 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4340
	data_grads_norm = 5.1638
	new_data_grads_norm = 7.4171
	old_data_grads_norm = 6.3593
	sim_grads_norm_tr = -0.0257
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4907
	data_grads_norm = 5.7410
	new_data_grads_norm = 7.5235
	old_data_grads_norm = 9.1245
	sim_grads_norm_tr = -0.0274
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1516
	data_grads_norm = 6.1604
	new_data_grads_norm = 8.4761
	old_data_grads_norm = 8.0715
	sim_grads_norm_tr = 0.0309
-- Starting training on experience 73 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5113
	data_grads_norm = 5.1943
	new_data_grads_norm = 7.2929
	old_data_grads_norm = 6.2816
	sim_grads_norm_tr = 0.0338
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4048
	data_grads_norm = 5.0252
	new_data_grads_norm = 7.0162
	old_data_grads_norm = 6.3270
	sim_grads_norm_tr = -0.0405
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0717
	data_grads_norm = 4.1134
	new_data_grads_norm = 7.4280
	old_data_grads_norm = 3.3811
	sim_grads_norm_tr = 0.0089
-- Starting training on experience 74 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9759
	data_grads_norm = 4.4626
	new_data_grads_norm = 8.7229
	old_data_grads_norm = 4.1444
	sim_grads_norm_tr = -0.0053
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8623
	data_grads_norm = 6.2086
	new_data_grads_norm = 8.1454
	old_data_grads_norm = 7.9021
	sim_grads_norm_tr = -0.0019
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9282
	data_grads_norm = 5.9663
	new_data_grads_norm = 8.8523
	old_data_grads_norm = 8.0153
	sim_grads_norm_tr = 0.0538
-- Starting training on experience 75 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8782
	data_grads_norm = 5.4562
	new_data_grads_norm = 7.4278
	old_data_grads_norm = 7.0806
	sim_grads_norm_tr = -0.0371
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4668
	data_grads_norm = 5.3577
	new_data_grads_norm = 6.9838
	old_data_grads_norm = 7.1022
	sim_grads_norm_tr = -0.0151
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2296
	data_grads_norm = 5.1914
	new_data_grads_norm = 7.4462
	old_data_grads_norm = 6.8030
	sim_grads_norm_tr = 0.0010
-- Starting training on experience 76 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3522
	data_grads_norm = 4.6923
	new_data_grads_norm = 7.0455
	old_data_grads_norm = 5.5689
	sim_grads_norm_tr = 0.0749
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1336
	data_grads_norm = 5.0606
	new_data_grads_norm = 6.6107
	old_data_grads_norm = 7.5842
	sim_grads_norm_tr = -0.0374
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1537
	data_grads_norm = 5.0349
	new_data_grads_norm = 7.6701
	old_data_grads_norm = 5.8140
	sim_grads_norm_tr = 0.0498
-- Starting training on experience 77 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5021
	data_grads_norm = 5.3026
	new_data_grads_norm = 6.8282
	old_data_grads_norm = 7.5731
	sim_grads_norm_tr = -0.0077
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0374
	data_grads_norm = 4.5854
	new_data_grads_norm = 7.7940
	old_data_grads_norm = 5.6769
	sim_grads_norm_tr = -0.0300
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5847
	data_grads_norm = 5.5820
	new_data_grads_norm = 7.6718
	old_data_grads_norm = 6.2246
	sim_grads_norm_tr = 0.1025
-- Starting training on experience 78 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1916
	data_grads_norm = 5.1959
	new_data_grads_norm = 7.4955
	old_data_grads_norm = 6.9806
	sim_grads_norm_tr = 0.0053
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1526
	data_grads_norm = 4.9791
	new_data_grads_norm = 8.1513
	old_data_grads_norm = 5.5681
	sim_grads_norm_tr = 0.0069
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1809
	data_grads_norm = 4.9855
	new_data_grads_norm = 6.6930
	old_data_grads_norm = 7.2969
	sim_grads_norm_tr = -0.0211
-- Starting training on experience 79 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3442
	data_grads_norm = 5.7042
	new_data_grads_norm = 8.0151
	old_data_grads_norm = 8.2290
	sim_grads_norm_tr = 0.0391
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0182
	data_grads_norm = 5.1453
	new_data_grads_norm = 7.3783
	old_data_grads_norm = 5.4683
	sim_grads_norm_tr = 0.0056
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1747
	data_grads_norm = 4.8273
	new_data_grads_norm = 6.2740
	old_data_grads_norm = 6.9336
	sim_grads_norm_tr = -0.0336
-- Starting training on experience 80 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3126
	data_grads_norm = 5.0410
	new_data_grads_norm = 8.0472
	old_data_grads_norm = 3.9944
	sim_grads_norm_tr = 0.0259
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3512
	data_grads_norm = 5.6078
	new_data_grads_norm = 8.6014
	old_data_grads_norm = 7.2187
	sim_grads_norm_tr = -0.0192
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3977
	data_grads_norm = 5.1711
	new_data_grads_norm = 7.4836
	old_data_grads_norm = 7.1732
	sim_grads_norm_tr = -0.0110
-- Starting training on experience 81 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1907
	data_grads_norm = 5.0799
	new_data_grads_norm = 7.6024
	old_data_grads_norm = 4.0950
	sim_grads_norm_tr = -0.0055
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5411
	data_grads_norm = 6.1954
	new_data_grads_norm = 8.1542
	old_data_grads_norm = 7.2105
	sim_grads_norm_tr = 0.0027
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4240
	data_grads_norm = 6.2160
	new_data_grads_norm = 8.4612
	old_data_grads_norm = 6.1651
	sim_grads_norm_tr = 0.0727
-- Starting training on experience 82 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4824
	data_grads_norm = 5.6125
	new_data_grads_norm = 9.0412
	old_data_grads_norm = 7.0240
	sim_grads_norm_tr = 0.0819
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2435
	data_grads_norm = 5.2787
	new_data_grads_norm = 8.3835
	old_data_grads_norm = 6.0741
	sim_grads_norm_tr = 0.0036
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1370
	data_grads_norm = 4.7791
	new_data_grads_norm = 8.1303
	old_data_grads_norm = 6.2603
	sim_grads_norm_tr = -0.0257
-- Starting training on experience 83 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7308
	data_grads_norm = 5.4158
	new_data_grads_norm = 7.3208
	old_data_grads_norm = 7.1857
	sim_grads_norm_tr = 0.0080
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3940
	data_grads_norm = 4.9025
	new_data_grads_norm = 8.2629
	old_data_grads_norm = 5.0719
	sim_grads_norm_tr = -0.0109
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0272
	data_grads_norm = 5.8636
	new_data_grads_norm = 7.6835
	old_data_grads_norm = 7.8875
	sim_grads_norm_tr = 0.0201
-- Starting training on experience 84 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3136
	data_grads_norm = 5.4121
	new_data_grads_norm = 7.2532
	old_data_grads_norm = 6.1218
	sim_grads_norm_tr = -0.0371
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1315
	data_grads_norm = 6.1044
	new_data_grads_norm = 8.2516
	old_data_grads_norm = 7.9192
	sim_grads_norm_tr = -0.0005
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3968
	data_grads_norm = 5.1443
	new_data_grads_norm = 7.3252
	old_data_grads_norm = 7.2096
	sim_grads_norm_tr = 0.0446
-- Starting training on experience 85 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1651
	data_grads_norm = 5.3466
	new_data_grads_norm = 8.0012
	old_data_grads_norm = 6.2157
	sim_grads_norm_tr = -0.0092
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5099
	data_grads_norm = 5.7172
	new_data_grads_norm = 8.0828
	old_data_grads_norm = 9.0527
	sim_grads_norm_tr = -0.0034
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7976
	data_grads_norm = 6.1890
	new_data_grads_norm = 7.7586
	old_data_grads_norm = 9.2993
	sim_grads_norm_tr = 0.0210
-- Starting training on experience 86 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6004
	data_grads_norm = 5.6611
	new_data_grads_norm = 8.6428
	old_data_grads_norm = 6.5239
	sim_grads_norm_tr = -0.0097
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3024
	data_grads_norm = 4.9437
	new_data_grads_norm = 8.3217
	old_data_grads_norm = 5.6098
	sim_grads_norm_tr = 0.0931
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4433
	data_grads_norm = 5.4876
	new_data_grads_norm = 6.9450
	old_data_grads_norm = 8.8767
	sim_grads_norm_tr = -0.0195
-- Starting training on experience 87 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4737
	data_grads_norm = 5.6901
	new_data_grads_norm = 7.4136
	old_data_grads_norm = 6.6570
	sim_grads_norm_tr = -0.0305
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5749
	data_grads_norm = 5.7709
	new_data_grads_norm = 7.6520
	old_data_grads_norm = 8.1446
	sim_grads_norm_tr = 0.0717
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0143
	data_grads_norm = 4.8270
	new_data_grads_norm = 6.8649
	old_data_grads_norm = 6.3081
	sim_grads_norm_tr = 0.0767
-- Starting training on experience 88 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2658
	data_grads_norm = 5.6074
	new_data_grads_norm = 7.4133
	old_data_grads_norm = 7.7377
	sim_grads_norm_tr = -0.0251
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1421
	data_grads_norm = 4.9388
	new_data_grads_norm = 7.2589
	old_data_grads_norm = 6.8251
	sim_grads_norm_tr = 0.0011
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8022
	data_grads_norm = 4.5948
	new_data_grads_norm = 8.4522
	old_data_grads_norm = 5.4847
	sim_grads_norm_tr = -0.0739
-- Starting training on experience 89 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3038
	data_grads_norm = 5.6885
	new_data_grads_norm = 7.9213
	old_data_grads_norm = 6.8970
	sim_grads_norm_tr = 0.0812
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9346
	data_grads_norm = 5.4797
	new_data_grads_norm = 6.6790
	old_data_grads_norm = 7.0496
	sim_grads_norm_tr = -0.0112
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3279
	data_grads_norm = 6.3930
	new_data_grads_norm = 7.5542
	old_data_grads_norm = 9.2395
	sim_grads_norm_tr = -0.0255
-- Starting training on experience 90 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2079
	data_grads_norm = 5.1678
	new_data_grads_norm = 7.7568
	old_data_grads_norm = 6.8578
	sim_grads_norm_tr = 0.0180
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2891
	data_grads_norm = 5.2235
	new_data_grads_norm = 6.7462
	old_data_grads_norm = 6.0166
	sim_grads_norm_tr = -0.0096
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2978
	data_grads_norm = 5.5733
	new_data_grads_norm = 7.3903
	old_data_grads_norm = 7.9688
	sim_grads_norm_tr = -0.0155
-- Starting training on experience 91 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4223
	data_grads_norm = 5.4314
	new_data_grads_norm = 7.3820
	old_data_grads_norm = 7.4233
	sim_grads_norm_tr = 0.0689
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2288
	data_grads_norm = 5.3987
	new_data_grads_norm = 7.8866
	old_data_grads_norm = 5.8270
	sim_grads_norm_tr = 0.0167
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0035
	data_grads_norm = 5.4673
	new_data_grads_norm = 7.4515
	old_data_grads_norm = 8.4724
	sim_grads_norm_tr = -0.0025
-- Starting training on experience 92 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3987
	data_grads_norm = 5.2493
	new_data_grads_norm = 8.0012
	old_data_grads_norm = 6.2809
	sim_grads_norm_tr = 0.0031
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8919
	data_grads_norm = 5.3464
	new_data_grads_norm = 8.5831
	old_data_grads_norm = 7.5147
	sim_grads_norm_tr = 0.0138
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6723
	data_grads_norm = 4.4007
	new_data_grads_norm = 7.3399
	old_data_grads_norm = 5.2778
	sim_grads_norm_tr = -0.0043
-- Starting training on experience 93 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1937
	data_grads_norm = 5.5047
	new_data_grads_norm = 8.4553
	old_data_grads_norm = 7.7097
	sim_grads_norm_tr = -0.0238
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0122
	data_grads_norm = 6.2564
	new_data_grads_norm = 8.7177
	old_data_grads_norm = 7.9144
	sim_grads_norm_tr = 0.0174
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0419
	data_grads_norm = 4.7142
	new_data_grads_norm = 7.8179
	old_data_grads_norm = 5.0804
	sim_grads_norm_tr = -0.0185
-- Starting training on experience 94 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8377
	data_grads_norm = 4.5661
	new_data_grads_norm = 6.9961
	old_data_grads_norm = 5.6553
	sim_grads_norm_tr = -0.0304
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3494
	data_grads_norm = 5.4546
	new_data_grads_norm = 7.0242
	old_data_grads_norm = 7.8356
	sim_grads_norm_tr = -0.0139
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2501
	data_grads_norm = 5.6216
	new_data_grads_norm = 6.9408
	old_data_grads_norm = 7.9844
	sim_grads_norm_tr = 0.0583
-- Starting training on experience 95 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2201
	data_grads_norm = 5.1106
	new_data_grads_norm = 8.6020
	old_data_grads_norm = 5.1885
	sim_grads_norm_tr = -0.0242
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7083
	data_grads_norm = 6.0561
	new_data_grads_norm = 8.1245
	old_data_grads_norm = 7.4928
	sim_grads_norm_tr = 0.0581
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3659
	data_grads_norm = 5.7953
	new_data_grads_norm = 8.5175
	old_data_grads_norm = 8.2364
	sim_grads_norm_tr = -0.0043
-- Starting training on experience 96 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4646
	data_grads_norm = 5.0633
	new_data_grads_norm = 7.0611
	old_data_grads_norm = 6.0530
	sim_grads_norm_tr = 0.0682
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3193
	data_grads_norm = 5.3460
	new_data_grads_norm = 6.8862
	old_data_grads_norm = 6.9912
	sim_grads_norm_tr = -0.0113
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9341
	data_grads_norm = 5.0263
	new_data_grads_norm = 7.5110
	old_data_grads_norm = 5.8501
	sim_grads_norm_tr = 0.0052
-- Starting training on experience 97 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8217
	data_grads_norm = 4.6484
	new_data_grads_norm = 7.2433
	old_data_grads_norm = 5.7850
	sim_grads_norm_tr = -0.0400
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5425
	data_grads_norm = 6.5713
	new_data_grads_norm = 7.9740
	old_data_grads_norm = 8.1276
	sim_grads_norm_tr = 0.0330
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2170
	data_grads_norm = 6.3432
	new_data_grads_norm = 7.7867
	old_data_grads_norm = 9.7308
	sim_grads_norm_tr = 0.0099
-- Starting training on experience 98 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1759
	data_grads_norm = 5.6396
	new_data_grads_norm = 8.5914
	old_data_grads_norm = 7.1123
	sim_grads_norm_tr = -0.0140
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4268
	data_grads_norm = 5.9312
	new_data_grads_norm = 8.3863
	old_data_grads_norm = 8.1171
	sim_grads_norm_tr = 0.0026
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1077
	data_grads_norm = 5.3859
	new_data_grads_norm = 9.2634
	old_data_grads_norm = 5.0971
	sim_grads_norm_tr = 0.0025
-- Starting training on experience 99 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0759
	data_grads_norm = 5.1651
	new_data_grads_norm = 6.9338
	old_data_grads_norm = 9.4035
	sim_grads_norm_tr = -0.0048
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0332
	data_grads_norm = 5.2317
	new_data_grads_norm = 7.5783
	old_data_grads_norm = 6.9341
	sim_grads_norm_tr = 0.0169
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0787
	data_grads_norm = 4.4000
	new_data_grads_norm = 7.5882
	old_data_grads_norm = 5.4087
	sim_grads_norm_tr = 0.0620
-- Starting training on experience 100 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2016
	data_grads_norm = 5.3466
	new_data_grads_norm = 8.4254
	old_data_grads_norm = 6.9953
	sim_grads_norm_tr = -0.0110
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5926
	data_grads_norm = 5.6169
	new_data_grads_norm = 9.2562
	old_data_grads_norm = 6.9344
	sim_grads_norm_tr = 0.0202
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2610
	data_grads_norm = 5.7853
	new_data_grads_norm = 8.8549
	old_data_grads_norm = 5.7687
	sim_grads_norm_tr = -0.0105
-- Starting training on experience 101 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8464
	data_grads_norm = 5.8511
	new_data_grads_norm = 7.8601
	old_data_grads_norm = 7.6517
	sim_grads_norm_tr = 0.0033
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7539
	data_grads_norm = 5.2477
	new_data_grads_norm = 8.3339
	old_data_grads_norm = 6.6528
	sim_grads_norm_tr = 0.0096
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2593
	data_grads_norm = 4.6153
	new_data_grads_norm = 8.1122
	old_data_grads_norm = 5.3399
	sim_grads_norm_tr = -0.0389
-- Starting training on experience 102 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4669
	data_grads_norm = 5.8908
	new_data_grads_norm = 9.1301
	old_data_grads_norm = 7.1709
	sim_grads_norm_tr = 0.0425
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8677
	data_grads_norm = 6.0650
	new_data_grads_norm = 9.3654
	old_data_grads_norm = 5.5301
	sim_grads_norm_tr = 0.0330
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3945
	data_grads_norm = 5.5720
	new_data_grads_norm = 8.3478
	old_data_grads_norm = 8.9276
	sim_grads_norm_tr = -0.0055
-- Starting training on experience 103 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3807
	data_grads_norm = 5.5338
	new_data_grads_norm = 8.5360
	old_data_grads_norm = 5.5543
	sim_grads_norm_tr = -0.0102
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9007
	data_grads_norm = 4.4293
	new_data_grads_norm = 6.6236
	old_data_grads_norm = 5.9304
	sim_grads_norm_tr = 0.0262
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4917
	data_grads_norm = 5.4911
	new_data_grads_norm = 7.1141
	old_data_grads_norm = 7.5376
	sim_grads_norm_tr = 0.0634
-- Starting training on experience 104 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1489
	data_grads_norm = 5.3441
	new_data_grads_norm = 6.1489
	old_data_grads_norm = 8.8987
	sim_grads_norm_tr = 0.0354
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2092
	data_grads_norm = 4.8652
	new_data_grads_norm = 8.0760
	old_data_grads_norm = 6.1228
	sim_grads_norm_tr = -0.0227
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3266
	data_grads_norm = 5.8888
	new_data_grads_norm = 7.1951
	old_data_grads_norm = 8.0608
	sim_grads_norm_tr = 0.0058
-- Starting training on experience 105 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9934
	data_grads_norm = 4.6553
	new_data_grads_norm = 7.9811
	old_data_grads_norm = 5.1136
	sim_grads_norm_tr = 0.0115
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0688
	data_grads_norm = 5.1938
	new_data_grads_norm = 7.2683
	old_data_grads_norm = 8.3421
	sim_grads_norm_tr = -0.0405
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1638
	data_grads_norm = 5.7830
	new_data_grads_norm = 7.5968
	old_data_grads_norm = 7.9148
	sim_grads_norm_tr = 0.0057
-- Starting training on experience 106 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2038
	data_grads_norm = 5.7763
	new_data_grads_norm = 7.1028
	old_data_grads_norm = 9.0825
	sim_grads_norm_tr = -0.0319
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7270
	data_grads_norm = 4.8020
	new_data_grads_norm = 8.1692
	old_data_grads_norm = 5.0188
	sim_grads_norm_tr = -0.0197
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8124
	data_grads_norm = 5.6937
	new_data_grads_norm = 8.3796
	old_data_grads_norm = 5.5582
	sim_grads_norm_tr = 0.0750
-- Starting training on experience 107 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4012
	data_grads_norm = 5.6756
	new_data_grads_norm = 8.2899
	old_data_grads_norm = 6.9105
	sim_grads_norm_tr = 0.0532
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0814
	data_grads_norm = 4.9526
	new_data_grads_norm = 7.5249
	old_data_grads_norm = 7.7543
	sim_grads_norm_tr = 0.0047
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9806
	data_grads_norm = 4.7240
	new_data_grads_norm = 8.0262
	old_data_grads_norm = 5.0311
	sim_grads_norm_tr = 0.0100
-- Starting training on experience 108 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4496
	data_grads_norm = 5.5231
	new_data_grads_norm = 9.3633
	old_data_grads_norm = 4.5472
	sim_grads_norm_tr = 0.1284
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1293
	data_grads_norm = 5.4790
	new_data_grads_norm = 9.1023
	old_data_grads_norm = 7.8372
	sim_grads_norm_tr = -0.0024
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6077
	data_grads_norm = 5.8976
	new_data_grads_norm = 8.4768
	old_data_grads_norm = 7.8155
	sim_grads_norm_tr = 0.0553
-- Starting training on experience 109 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0885
	data_grads_norm = 4.7555
	new_data_grads_norm = 7.7030
	old_data_grads_norm = 5.8598
	sim_grads_norm_tr = 0.0477
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3760
	data_grads_norm = 5.7236
	new_data_grads_norm = 7.5061
	old_data_grads_norm = 8.3621
	sim_grads_norm_tr = 0.0292
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5989
	data_grads_norm = 4.2268
	new_data_grads_norm = 8.0572
	old_data_grads_norm = 4.7167
	sim_grads_norm_tr = -0.0310
-- Starting training on experience 110 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7850
	data_grads_norm = 4.5675
	new_data_grads_norm = 7.0863
	old_data_grads_norm = 5.2396
	sim_grads_norm_tr = 0.0217
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9710
	data_grads_norm = 4.8037
	new_data_grads_norm = 6.3406
	old_data_grads_norm = 7.4166
	sim_grads_norm_tr = -0.0558
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0273
	data_grads_norm = 4.7644
	new_data_grads_norm = 7.8758
	old_data_grads_norm = 5.6954
	sim_grads_norm_tr = 0.0185
-- Starting training on experience 111 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9146
	data_grads_norm = 4.5964
	new_data_grads_norm = 6.7990
	old_data_grads_norm = 4.7708
	sim_grads_norm_tr = 0.0315
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9822
	data_grads_norm = 5.2643
	new_data_grads_norm = 7.1287
	old_data_grads_norm = 7.1181
	sim_grads_norm_tr = 0.0077
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5931
	data_grads_norm = 5.6334
	new_data_grads_norm = 7.2067
	old_data_grads_norm = 6.3713
	sim_grads_norm_tr = -0.0013
-- Starting training on experience 112 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0965
	data_grads_norm = 5.2359
	new_data_grads_norm = 8.0568
	old_data_grads_norm = 6.7518
	sim_grads_norm_tr = 0.0197
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1368
	data_grads_norm = 5.7127
	new_data_grads_norm = 8.5750
	old_data_grads_norm = 8.9061
	sim_grads_norm_tr = -0.0614
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8541
	data_grads_norm = 4.3078
	new_data_grads_norm = 7.9132
	old_data_grads_norm = 4.4317
	sim_grads_norm_tr = -0.0457
-- Starting training on experience 113 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6582
	data_grads_norm = 6.5842
	new_data_grads_norm = 8.9612
	old_data_grads_norm = 8.2262
	sim_grads_norm_tr = -0.0167
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3314
	data_grads_norm = 5.8911
	new_data_grads_norm = 8.3380
	old_data_grads_norm = 7.5498
	sim_grads_norm_tr = 0.0171
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4898
	data_grads_norm = 5.5578
	new_data_grads_norm = 8.6888
	old_data_grads_norm = 4.9410
	sim_grads_norm_tr = 0.0559
-- Starting training on experience 114 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0074
	data_grads_norm = 6.2091
	new_data_grads_norm = 9.2002
	old_data_grads_norm = 7.5987
	sim_grads_norm_tr = -0.0035
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7821
	data_grads_norm = 6.1626
	new_data_grads_norm = 9.1007
	old_data_grads_norm = 7.8749
	sim_grads_norm_tr = -0.0073
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8656
	data_grads_norm = 6.4943
	new_data_grads_norm = 8.4914
	old_data_grads_norm = 8.4767
	sim_grads_norm_tr = 0.0063
-- Starting training on experience 115 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6800
	data_grads_norm = 5.7646
	new_data_grads_norm = 8.1879
	old_data_grads_norm = 7.7015
	sim_grads_norm_tr = 0.0093
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4231
	data_grads_norm = 5.6395
	new_data_grads_norm = 8.7014
	old_data_grads_norm = 4.8181
	sim_grads_norm_tr = -0.0115
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1618
	data_grads_norm = 5.3021
	new_data_grads_norm = 8.3557
	old_data_grads_norm = 6.7590
	sim_grads_norm_tr = 0.0003
-- Starting training on experience 116 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2632
	data_grads_norm = 5.6446
	new_data_grads_norm = 7.3923
	old_data_grads_norm = 6.7470
	sim_grads_norm_tr = -0.0179
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8799
	data_grads_norm = 4.4246
	new_data_grads_norm = 7.1516
	old_data_grads_norm = 4.8762
	sim_grads_norm_tr = -0.0186
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0417
	data_grads_norm = 4.3881
	new_data_grads_norm = 7.3366
	old_data_grads_norm = 5.7491
	sim_grads_norm_tr = -0.0244
-- Starting training on experience 117 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5776
	data_grads_norm = 5.5671
	new_data_grads_norm = 8.4374
	old_data_grads_norm = 7.0955
	sim_grads_norm_tr = -0.0144
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1928
	data_grads_norm = 6.4197
	new_data_grads_norm = 8.2780
	old_data_grads_norm = 8.8406
	sim_grads_norm_tr = 0.0117
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2533
	data_grads_norm = 6.5246
	new_data_grads_norm = 9.8107
	old_data_grads_norm = 7.0688
	sim_grads_norm_tr = -0.0182
-- Starting training on experience 118 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6112
	data_grads_norm = 6.0356
	new_data_grads_norm = 9.4723
	old_data_grads_norm = 7.1661
	sim_grads_norm_tr = -0.0004
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4302
	data_grads_norm = 5.5810
	new_data_grads_norm = 9.3055
	old_data_grads_norm = 4.5854
	sim_grads_norm_tr = 0.0172
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1695
	data_grads_norm = 4.6900
	new_data_grads_norm = 8.3926
	old_data_grads_norm = 3.7353
	sim_grads_norm_tr = -0.0015
-- Starting training on experience 119 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5875
	data_grads_norm = 5.7958
	new_data_grads_norm = 8.2281
	old_data_grads_norm = 6.9458
	sim_grads_norm_tr = 0.0002
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7567
	data_grads_norm = 4.1336
	new_data_grads_norm = 7.4023
	old_data_grads_norm = 2.1053
	sim_grads_norm_tr = -0.0072
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7916
	data_grads_norm = 6.7275
	new_data_grads_norm = 8.5032
	old_data_grads_norm = 8.7375
	sim_grads_norm_tr = -0.0012
-- Starting training on experience 120 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1500
	data_grads_norm = 4.8730
	new_data_grads_norm = 7.9443
	old_data_grads_norm = 4.9914
	sim_grads_norm_tr = 0.0140
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1701
	data_grads_norm = 5.2702
	new_data_grads_norm = 7.8409
	old_data_grads_norm = 6.5933
	sim_grads_norm_tr = 0.0077
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6469
	data_grads_norm = 5.2021
	new_data_grads_norm = 7.9181
	old_data_grads_norm = 6.3664
	sim_grads_norm_tr = -0.0242
-- Starting training on experience 121 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7682
	data_grads_norm = 5.6416
	new_data_grads_norm = 10.1695
	old_data_grads_norm = 5.2648
	sim_grads_norm_tr = 0.0390
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5028
	data_grads_norm = 5.1422
	new_data_grads_norm = 8.4188
	old_data_grads_norm = 4.7617
	sim_grads_norm_tr = 0.0227
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1190
	data_grads_norm = 6.8074
	new_data_grads_norm = 8.9746
	old_data_grads_norm = 7.9055
	sim_grads_norm_tr = 0.0551
-- Starting training on experience 122 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7273
	data_grads_norm = 6.1150
	new_data_grads_norm = 8.1640
	old_data_grads_norm = 8.5303
	sim_grads_norm_tr = 0.0981
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1791
	data_grads_norm = 5.2594
	new_data_grads_norm = 7.9173
	old_data_grads_norm = 5.8198
	sim_grads_norm_tr = -0.0041
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5617
	data_grads_norm = 5.8681
	new_data_grads_norm = 8.5819
	old_data_grads_norm = 7.1398
	sim_grads_norm_tr = -0.0144
-- Starting training on experience 123 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7157
	data_grads_norm = 6.2931
	new_data_grads_norm = 7.6834
	old_data_grads_norm = 9.0981
	sim_grads_norm_tr = 0.0192
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1894
	data_grads_norm = 4.9077
	new_data_grads_norm = 6.9350
	old_data_grads_norm = 5.9297
	sim_grads_norm_tr = 0.0822
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0382
	data_grads_norm = 4.3774
	new_data_grads_norm = 6.9408
	old_data_grads_norm = 6.5226
	sim_grads_norm_tr = -0.0497
-- Starting training on experience 124 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9138
	data_grads_norm = 4.6404
	new_data_grads_norm = 8.7413
	old_data_grads_norm = 4.8843
	sim_grads_norm_tr = -0.0113
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4500
	data_grads_norm = 5.6131
	new_data_grads_norm = 8.9792
	old_data_grads_norm = 6.6135
	sim_grads_norm_tr = -0.0097
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4986
	data_grads_norm = 5.7119
	new_data_grads_norm = 8.7684
	old_data_grads_norm = 6.6688
	sim_grads_norm_tr = 0.0376
-- Starting training on experience 125 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5656
	data_grads_norm = 6.1088
	new_data_grads_norm = 8.4032
	old_data_grads_norm = 7.3369
	sim_grads_norm_tr = 0.0304
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3264
	data_grads_norm = 5.6409
	new_data_grads_norm = 7.4562
	old_data_grads_norm = 7.9049
	sim_grads_norm_tr = -0.0102
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2952
	data_grads_norm = 5.8571
	new_data_grads_norm = 7.5411
	old_data_grads_norm = 8.9801
	sim_grads_norm_tr = 0.0026
-- Starting training on experience 126 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2133
	data_grads_norm = 5.1080
	new_data_grads_norm = 8.4919
	old_data_grads_norm = 4.4683
	sim_grads_norm_tr = 0.0478
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3325
	data_grads_norm = 5.4120
	new_data_grads_norm = 7.7045
	old_data_grads_norm = 6.8524
	sim_grads_norm_tr = 0.0086
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2514
	data_grads_norm = 5.3383
	new_data_grads_norm = 7.2236
	old_data_grads_norm = 5.6155
	sim_grads_norm_tr = -0.0220
-- Starting training on experience 127 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1143
	data_grads_norm = 5.6070
	new_data_grads_norm = 8.5935
	old_data_grads_norm = 6.8635
	sim_grads_norm_tr = 0.0144
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2451
	data_grads_norm = 5.7343
	new_data_grads_norm = 8.3685
	old_data_grads_norm = 7.2646
	sim_grads_norm_tr = 0.0417
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4394
	data_grads_norm = 5.5478
	new_data_grads_norm = 7.5168
	old_data_grads_norm = 8.5809
	sim_grads_norm_tr = 0.0175
-- Starting training on experience 128 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2181
	data_grads_norm = 4.9619
	new_data_grads_norm = 7.6080
	old_data_grads_norm = 6.4437
	sim_grads_norm_tr = 0.0248
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1326
	data_grads_norm = 4.9751
	new_data_grads_norm = 8.2192
	old_data_grads_norm = 5.3759
	sim_grads_norm_tr = -0.0039
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1101
	data_grads_norm = 5.2909
	new_data_grads_norm = 8.0996
	old_data_grads_norm = 6.4559
	sim_grads_norm_tr = -0.0162
-- Starting training on experience 129 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2092
	data_grads_norm = 4.8138
	new_data_grads_norm = 8.3134
	old_data_grads_norm = 4.5039
	sim_grads_norm_tr = -0.0319
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4574
	data_grads_norm = 5.2430
	new_data_grads_norm = 8.4574
	old_data_grads_norm = 6.4205
	sim_grads_norm_tr = 0.0221
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5074
	data_grads_norm = 6.0533
	new_data_grads_norm = 7.8728
	old_data_grads_norm = 7.5701
	sim_grads_norm_tr = 0.0914
-- Starting training on experience 130 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0639
	data_grads_norm = 4.5623
	new_data_grads_norm = 8.3737
	old_data_grads_norm = 6.0516
	sim_grads_norm_tr = -0.0196
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3891
	data_grads_norm = 5.6128
	new_data_grads_norm = 8.1309
	old_data_grads_norm = 7.8464
	sim_grads_norm_tr = -0.0157
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5446
	data_grads_norm = 5.7266
	new_data_grads_norm = 8.8528
	old_data_grads_norm = 7.5296
	sim_grads_norm_tr = 0.0110
-- Starting training on experience 131 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5686
	data_grads_norm = 5.8627
	new_data_grads_norm = 7.9037
	old_data_grads_norm = 7.6081
	sim_grads_norm_tr = 0.0124
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5735
	data_grads_norm = 6.5782
	new_data_grads_norm = 8.7668
	old_data_grads_norm = 8.6071
	sim_grads_norm_tr = 0.0067
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0406
	data_grads_norm = 6.0454
	new_data_grads_norm = 8.1893
	old_data_grads_norm = 6.5235
	sim_grads_norm_tr = 0.0690
-- Starting training on experience 132 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1981
	data_grads_norm = 5.1605
	new_data_grads_norm = 8.9166
	old_data_grads_norm = 5.8244
	sim_grads_norm_tr = 0.0441
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1076
	data_grads_norm = 5.1699
	new_data_grads_norm = 7.6585
	old_data_grads_norm = 6.7622
	sim_grads_norm_tr = 0.0067
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6728
	data_grads_norm = 5.2956
	new_data_grads_norm = 8.0466
	old_data_grads_norm = 6.8420
	sim_grads_norm_tr = 0.0914
-- Starting training on experience 133 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9629
	data_grads_norm = 5.6490
	new_data_grads_norm = 9.4645
	old_data_grads_norm = 7.7528
	sim_grads_norm_tr = -0.0058
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2381
	data_grads_norm = 5.8990
	new_data_grads_norm = 9.3730
	old_data_grads_norm = 5.8148
	sim_grads_norm_tr = 0.0082
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2777
	data_grads_norm = 5.8969
	new_data_grads_norm = 8.6853
	old_data_grads_norm = 6.7485
	sim_grads_norm_tr = 0.0393
-- Starting training on experience 134 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9371
	data_grads_norm = 4.8561
	new_data_grads_norm = 7.1461
	old_data_grads_norm = 5.2719
	sim_grads_norm_tr = -0.0082
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3974
	data_grads_norm = 5.5043
	new_data_grads_norm = 6.9529
	old_data_grads_norm = 7.7704
	sim_grads_norm_tr = -0.0165
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0888
	data_grads_norm = 5.0649
	new_data_grads_norm = 6.9289
	old_data_grads_norm = 7.6037
	sim_grads_norm_tr = -0.0093
-- Starting training on experience 135 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2342
	data_grads_norm = 6.2231
	new_data_grads_norm = 9.9872
	old_data_grads_norm = 7.9235
	sim_grads_norm_tr = 0.0328
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1622
	data_grads_norm = 5.8419
	new_data_grads_norm = 9.1878
	old_data_grads_norm = 4.8437
	sim_grads_norm_tr = 0.0070
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5244
	data_grads_norm = 6.6118
	new_data_grads_norm = 10.3002
	old_data_grads_norm = 8.3556
	sim_grads_norm_tr = 0.0082
-- Starting training on experience 136 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9677
	data_grads_norm = 6.0808
	new_data_grads_norm = 10.5241
	old_data_grads_norm = 7.7498
	sim_grads_norm_tr = -0.0295
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3293
	data_grads_norm = 6.2544
	new_data_grads_norm = 10.1033
	old_data_grads_norm = 7.5003
	sim_grads_norm_tr = 0.0159
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3042
	data_grads_norm = 7.0734
	new_data_grads_norm = 10.6316
	old_data_grads_norm = 8.0950
	sim_grads_norm_tr = 0.0487
-- Starting training on experience 137 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3511
	data_grads_norm = 5.5645
	new_data_grads_norm = 7.9385
	old_data_grads_norm = 6.3263
	sim_grads_norm_tr = -0.0082
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6048
	data_grads_norm = 6.1474
	new_data_grads_norm = 8.6521
	old_data_grads_norm = 5.9433
	sim_grads_norm_tr = -0.0169
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5979
	data_grads_norm = 5.3320
	new_data_grads_norm = 8.8674
	old_data_grads_norm = 5.3514
	sim_grads_norm_tr = -0.0118
-- Starting training on experience 138 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6688
	data_grads_norm = 6.5331
	new_data_grads_norm = 8.7348
	old_data_grads_norm = 7.4115
	sim_grads_norm_tr = 0.0311
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4946
	data_grads_norm = 5.3278
	new_data_grads_norm = 9.3959
	old_data_grads_norm = 6.3243
	sim_grads_norm_tr = 0.0130
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3644
	data_grads_norm = 5.6117
	new_data_grads_norm = 8.7905
	old_data_grads_norm = 7.1592
	sim_grads_norm_tr = -0.0139
-- Starting training on experience 139 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9740
	data_grads_norm = 5.4778
	new_data_grads_norm = 7.5790
	old_data_grads_norm = 4.9866
	sim_grads_norm_tr = 0.0073
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1719
	data_grads_norm = 5.4766
	new_data_grads_norm = 7.7811
	old_data_grads_norm = 7.1225
	sim_grads_norm_tr = 0.0576
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2248
	data_grads_norm = 5.7681
	new_data_grads_norm = 8.4394
	old_data_grads_norm = 6.7478
	sim_grads_norm_tr = -0.0117
-- Starting training on experience 140 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6289
	data_grads_norm = 6.1334
	new_data_grads_norm = 8.8258
	old_data_grads_norm = 7.4152
	sim_grads_norm_tr = 0.0009
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1016
	data_grads_norm = 5.5484
	new_data_grads_norm = 8.2406
	old_data_grads_norm = 7.1070
	sim_grads_norm_tr = 0.0034
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0006
	data_grads_norm = 5.4107
	new_data_grads_norm = 7.7306
	old_data_grads_norm = 6.7106
	sim_grads_norm_tr = 0.0334
-- Starting training on experience 141 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4099
	data_grads_norm = 5.7821
	new_data_grads_norm = 10.6010
	old_data_grads_norm = 3.8863
	sim_grads_norm_tr = 0.0045
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8023
	data_grads_norm = 6.8566
	new_data_grads_norm = 9.8670
	old_data_grads_norm = 8.3163
	sim_grads_norm_tr = 0.0415
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7340
	data_grads_norm = 5.3606
	new_data_grads_norm = 8.5678
	old_data_grads_norm = 7.3637
	sim_grads_norm_tr = -0.0111
-- Starting training on experience 142 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1985
	data_grads_norm = 5.7242
	new_data_grads_norm = 9.0091
	old_data_grads_norm = 7.6793
	sim_grads_norm_tr = 0.0297
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1010
	data_grads_norm = 5.2418
	new_data_grads_norm = 8.6634
	old_data_grads_norm = 7.1890
	sim_grads_norm_tr = 0.0365
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1674
	data_grads_norm = 5.0313
	new_data_grads_norm = 7.9392
	old_data_grads_norm = 7.3761
	sim_grads_norm_tr = -0.0140
-- Starting training on experience 143 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9910
	data_grads_norm = 5.5675
	new_data_grads_norm = 8.9156
	old_data_grads_norm = 6.8613
	sim_grads_norm_tr = 0.0561
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9157
	data_grads_norm = 7.0421
	new_data_grads_norm = 8.4483
	old_data_grads_norm = 9.2633
	sim_grads_norm_tr = 0.0521
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5523
	data_grads_norm = 5.3148
	new_data_grads_norm = 8.4184
	old_data_grads_norm = 7.0295
	sim_grads_norm_tr = -0.0254
-- Starting training on experience 144 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9316
	data_grads_norm = 5.0872
	new_data_grads_norm = 7.5783
	old_data_grads_norm = 6.5662
	sim_grads_norm_tr = -0.0482
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6188
	data_grads_norm = 6.6969
	new_data_grads_norm = 9.4649
	old_data_grads_norm = 8.1332
	sim_grads_norm_tr = -0.0125
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3370
	data_grads_norm = 5.4369
	new_data_grads_norm = 8.9788
	old_data_grads_norm = 7.5070
	sim_grads_norm_tr = -0.0353
-- Starting training on experience 145 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4824
	data_grads_norm = 6.9734
	new_data_grads_norm = 8.6528
	old_data_grads_norm = 8.2930
	sim_grads_norm_tr = 0.0125
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2580
	data_grads_norm = 6.1855
	new_data_grads_norm = 10.3231
	old_data_grads_norm = 6.2180
	sim_grads_norm_tr = -0.0094
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6876
	data_grads_norm = 6.3968
	new_data_grads_norm = 9.6542
	old_data_grads_norm = 7.7264
	sim_grads_norm_tr = 0.0375
-- Starting training on experience 146 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4838
	data_grads_norm = 5.4019
	new_data_grads_norm = 7.4656
	old_data_grads_norm = 6.7827
	sim_grads_norm_tr = -0.0333
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4181
	data_grads_norm = 5.9294
	new_data_grads_norm = 7.6602
	old_data_grads_norm = 6.5264
	sim_grads_norm_tr = -0.0464
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0163
	data_grads_norm = 4.8760
	new_data_grads_norm = 8.1315
	old_data_grads_norm = 4.9364
	sim_grads_norm_tr = -0.0022
-- Starting training on experience 147 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9922
	data_grads_norm = 5.3823
	new_data_grads_norm = 8.7400
	old_data_grads_norm = 6.4072
	sim_grads_norm_tr = 0.0056
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9857
	data_grads_norm = 4.7354
	new_data_grads_norm = 7.9727
	old_data_grads_norm = 4.6879
	sim_grads_norm_tr = 0.0031
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0577
	data_grads_norm = 4.8891
	new_data_grads_norm = 8.1456
	old_data_grads_norm = 5.3518
	sim_grads_norm_tr = -0.0202
-- Starting training on experience 148 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6866
	data_grads_norm = 5.6867
	new_data_grads_norm = 8.7665
	old_data_grads_norm = 7.0750
	sim_grads_norm_tr = 0.0007
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2199
	data_grads_norm = 5.3201
	new_data_grads_norm = 8.9350
	old_data_grads_norm = 5.1150
	sim_grads_norm_tr = -0.0173
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8750
	data_grads_norm = 6.0190
	new_data_grads_norm = 8.9629
	old_data_grads_norm = 6.6866
	sim_grads_norm_tr = 0.0516
-- Starting training on experience 149 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1197
	data_grads_norm = 4.3743
	new_data_grads_norm = 7.0406
	old_data_grads_norm = 3.9354
	sim_grads_norm_tr = 0.0349
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4999
	data_grads_norm = 5.6281
	new_data_grads_norm = 7.8661
	old_data_grads_norm = 6.8250
	sim_grads_norm_tr = 0.0188
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5864
	data_grads_norm = 5.5106
	new_data_grads_norm = 7.9076
	old_data_grads_norm = 6.7284
	sim_grads_norm_tr = 0.0445
-- Starting training on experience 150 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1899
	data_grads_norm = 5.1697
	new_data_grads_norm = 9.5506
	old_data_grads_norm = 5.7292
	sim_grads_norm_tr = 0.0067
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5449
	data_grads_norm = 5.5533
	new_data_grads_norm = 8.8193
	old_data_grads_norm = 6.2301
	sim_grads_norm_tr = 0.0487
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4055
	data_grads_norm = 5.5981
	new_data_grads_norm = 8.9721
	old_data_grads_norm = 6.5464
	sim_grads_norm_tr = 0.0994
-- Starting training on experience 151 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2906
	data_grads_norm = 5.3783
	new_data_grads_norm = 8.1309
	old_data_grads_norm = 6.8159
	sim_grads_norm_tr = -0.0016
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2608
	data_grads_norm = 4.9756
	new_data_grads_norm = 7.9074
	old_data_grads_norm = 6.7753
	sim_grads_norm_tr = -0.0203
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1521
	data_grads_norm = 5.3382
	new_data_grads_norm = 7.6568
	old_data_grads_norm = 6.3953
	sim_grads_norm_tr = 0.0133
-- Starting training on experience 152 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2287
	data_grads_norm = 5.4241
	new_data_grads_norm = 8.4051
	old_data_grads_norm = 5.8554
	sim_grads_norm_tr = 0.0068
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2298
	data_grads_norm = 5.1313
	new_data_grads_norm = 8.4664
	old_data_grads_norm = 5.0504
	sim_grads_norm_tr = -0.0108
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5692
	data_grads_norm = 6.8310
	new_data_grads_norm = 9.1029
	old_data_grads_norm = 8.0746
	sim_grads_norm_tr = 0.0013
-- Starting training on experience 153 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2562
	data_grads_norm = 5.9324
	new_data_grads_norm = 8.6638
	old_data_grads_norm = 5.7037
	sim_grads_norm_tr = 0.0009
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1452
	data_grads_norm = 5.7429
	new_data_grads_norm = 8.6875
	old_data_grads_norm = 7.4400
	sim_grads_norm_tr = 0.0133
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0446
	data_grads_norm = 5.9549
	new_data_grads_norm = 8.2485
	old_data_grads_norm = 9.5406
	sim_grads_norm_tr = 0.0015
-- Starting training on experience 154 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9404
	data_grads_norm = 4.9618
	new_data_grads_norm = 7.6623
	old_data_grads_norm = 5.4083
	sim_grads_norm_tr = -0.0114
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9321
	data_grads_norm = 4.5581
	new_data_grads_norm = 8.3913
	old_data_grads_norm = 4.0030
	sim_grads_norm_tr = 0.0171
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6922
	data_grads_norm = 6.9366
	new_data_grads_norm = 8.7024
	old_data_grads_norm = 9.5976
	sim_grads_norm_tr = 0.0355
-- Starting training on experience 155 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1720
	data_grads_norm = 5.3248
	new_data_grads_norm = 8.2854
	old_data_grads_norm = 6.7488
	sim_grads_norm_tr = -0.0334
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3505
	data_grads_norm = 5.5403
	new_data_grads_norm = 8.0424
	old_data_grads_norm = 6.7526
	sim_grads_norm_tr = 0.0098
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2544
	data_grads_norm = 5.7583
	new_data_grads_norm = 7.9086
	old_data_grads_norm = 8.8029
	sim_grads_norm_tr = -0.0139
-- Starting training on experience 156 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4112
	data_grads_norm = 6.3818
	new_data_grads_norm = 8.7445
	old_data_grads_norm = 4.9658
	sim_grads_norm_tr = 0.0960
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4498
	data_grads_norm = 5.3620
	new_data_grads_norm = 8.2309
	old_data_grads_norm = 5.0324
	sim_grads_norm_tr = -0.0399
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0925
	data_grads_norm = 4.5888
	new_data_grads_norm = 8.0871
	old_data_grads_norm = 3.6491
	sim_grads_norm_tr = 0.1371
-- Starting training on experience 157 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9544
	data_grads_norm = 5.3127
	new_data_grads_norm = 10.2352
	old_data_grads_norm = 5.2579
	sim_grads_norm_tr = 0.0042
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3212
	data_grads_norm = 6.1246
	new_data_grads_norm = 9.0753
	old_data_grads_norm = 7.7445
	sim_grads_norm_tr = 0.0174
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1222
	data_grads_norm = 5.6580
	new_data_grads_norm = 9.3128
	old_data_grads_norm = 8.1166
	sim_grads_norm_tr = -0.0104
-- Starting training on experience 158 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2448
	data_grads_norm = 5.8060
	new_data_grads_norm = 10.4229
	old_data_grads_norm = 4.2763
	sim_grads_norm_tr = 0.0092
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1914
	data_grads_norm = 5.9691
	new_data_grads_norm = 9.7241
	old_data_grads_norm = 6.7153
	sim_grads_norm_tr = 0.0344
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6566
	data_grads_norm = 6.9230
	new_data_grads_norm = 8.8438
	old_data_grads_norm = 10.1509
	sim_grads_norm_tr = 0.0010
-- Starting training on experience 159 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3567
	data_grads_norm = 5.9206
	new_data_grads_norm = 8.6424
	old_data_grads_norm = 8.1954
	sim_grads_norm_tr = 0.0423
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7578
	data_grads_norm = 6.6555
	new_data_grads_norm = 10.0181
	old_data_grads_norm = 8.3731
	sim_grads_norm_tr = 0.0699
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3296
	data_grads_norm = 6.8240
	new_data_grads_norm = 10.2409
	old_data_grads_norm = 6.4755
	sim_grads_norm_tr = 0.0035
-- Starting training on experience 160 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3555
	data_grads_norm = 7.0086
	new_data_grads_norm = 8.5933
	old_data_grads_norm = 9.9628
	sim_grads_norm_tr = -0.0187
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2258
	data_grads_norm = 5.8498
	new_data_grads_norm = 8.3665
	old_data_grads_norm = 9.3995
	sim_grads_norm_tr = 0.0128
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3324
	data_grads_norm = 5.8959
	new_data_grads_norm = 8.1668
	old_data_grads_norm = 6.8902
	sim_grads_norm_tr = 0.0587
-- Starting training on experience 161 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1407
	data_grads_norm = 5.1946
	new_data_grads_norm = 9.0014
	old_data_grads_norm = 5.6038
	sim_grads_norm_tr = 0.0110
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7289
	data_grads_norm = 6.6693
	new_data_grads_norm = 7.7753
	old_data_grads_norm = 8.1072
	sim_grads_norm_tr = 0.0159
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6168
	data_grads_norm = 5.6122
	new_data_grads_norm = 7.8310
	old_data_grads_norm = 6.7337
	sim_grads_norm_tr = 0.0700
-- Starting training on experience 162 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4849
	data_grads_norm = 6.0416
	new_data_grads_norm = 9.6052
	old_data_grads_norm = 8.4907
	sim_grads_norm_tr = 0.0174
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6055
	data_grads_norm = 7.1275
	new_data_grads_norm = 9.6352
	old_data_grads_norm = 6.8196
	sim_grads_norm_tr = 0.0095
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6245
	data_grads_norm = 6.0340
	new_data_grads_norm = 7.8346
	old_data_grads_norm = 7.0221
	sim_grads_norm_tr = -0.0263
-- Starting training on experience 163 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3952
	data_grads_norm = 5.8265
	new_data_grads_norm = 8.7902
	old_data_grads_norm = 6.4626
	sim_grads_norm_tr = 0.0054
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7405
	data_grads_norm = 6.2006
	new_data_grads_norm = 9.4491
	old_data_grads_norm = 6.2573
	sim_grads_norm_tr = 0.0241
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6284
	data_grads_norm = 6.3253
	new_data_grads_norm = 9.9434
	old_data_grads_norm = 7.8934
	sim_grads_norm_tr = -0.0044
-- Starting training on experience 164 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2245
	data_grads_norm = 5.7111
	new_data_grads_norm = 8.6931
	old_data_grads_norm = 7.4618
	sim_grads_norm_tr = 0.0158
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1183
	data_grads_norm = 5.4754
	new_data_grads_norm = 8.4704
	old_data_grads_norm = 7.1514
	sim_grads_norm_tr = 0.0376
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0400
	data_grads_norm = 6.1981
	new_data_grads_norm = 8.2911
	old_data_grads_norm = 9.7643
	sim_grads_norm_tr = 0.0285
-- Starting training on experience 165 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8429
	data_grads_norm = 5.2416
	new_data_grads_norm = 7.2198
	old_data_grads_norm = 8.7092
	sim_grads_norm_tr = 0.0589
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1738
	data_grads_norm = 5.2225
	new_data_grads_norm = 7.5242
	old_data_grads_norm = 6.0931
	sim_grads_norm_tr = 0.0443
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0285
	data_grads_norm = 5.1360
	new_data_grads_norm = 7.7332
	old_data_grads_norm = 6.2570
	sim_grads_norm_tr = -0.0550
-- Starting training on experience 166 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1857
	data_grads_norm = 5.5328
	new_data_grads_norm = 7.3514
	old_data_grads_norm = 7.2031
	sim_grads_norm_tr = -0.0011
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4763
	data_grads_norm = 6.1180
	new_data_grads_norm = 8.0160
	old_data_grads_norm = 8.2620
	sim_grads_norm_tr = -0.0051
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1192
	data_grads_norm = 5.4990
	new_data_grads_norm = 8.0135
	old_data_grads_norm = 6.7535
	sim_grads_norm_tr = 0.0083
-- Starting training on experience 167 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2958
	data_grads_norm = 5.4974
	new_data_grads_norm = 7.9589
	old_data_grads_norm = 6.5359
	sim_grads_norm_tr = 0.0714
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1236
	data_grads_norm = 5.4370
	new_data_grads_norm = 7.4411
	old_data_grads_norm = 6.8367
	sim_grads_norm_tr = -0.0081
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3642
	data_grads_norm = 6.1289
	new_data_grads_norm = 8.1026
	old_data_grads_norm = 9.3361
	sim_grads_norm_tr = 0.0950
-- Starting training on experience 168 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2199
	data_grads_norm = 4.9682
	new_data_grads_norm = 6.6838
	old_data_grads_norm = 5.3408
	sim_grads_norm_tr = 0.1073
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5997
	data_grads_norm = 6.7580
	new_data_grads_norm = 7.8180
	old_data_grads_norm = 9.6055
	sim_grads_norm_tr = -0.0100
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9674
	data_grads_norm = 5.1589
	new_data_grads_norm = 6.8597
	old_data_grads_norm = 5.7891
	sim_grads_norm_tr = 0.0568
-- Starting training on experience 169 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6780
	data_grads_norm = 5.6709
	new_data_grads_norm = 7.7015
	old_data_grads_norm = 8.7368
	sim_grads_norm_tr = 0.0251
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2831
	data_grads_norm = 4.5154
	new_data_grads_norm = 7.9266
	old_data_grads_norm = 3.0328
	sim_grads_norm_tr = 0.0660
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9842
	data_grads_norm = 5.5327
	new_data_grads_norm = 8.2279
	old_data_grads_norm = 7.2139
	sim_grads_norm_tr = -0.0197
-- Starting training on experience 170 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6926
	data_grads_norm = 5.1969
	new_data_grads_norm = 7.2947
	old_data_grads_norm = 7.2643
	sim_grads_norm_tr = -0.0206
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8655
	data_grads_norm = 4.9658
	new_data_grads_norm = 8.2061
	old_data_grads_norm = 6.1105
	sim_grads_norm_tr = -0.0148
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9811
	data_grads_norm = 6.0757
	new_data_grads_norm = 8.5311
	old_data_grads_norm = 6.5096
	sim_grads_norm_tr = 0.0012
-- Starting training on experience 171 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9862
	data_grads_norm = 6.7743
	new_data_grads_norm = 9.3959
	old_data_grads_norm = 9.2765
	sim_grads_norm_tr = -0.0094
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0382
	data_grads_norm = 5.8769
	new_data_grads_norm = 9.5173
	old_data_grads_norm = 7.0800
	sim_grads_norm_tr = 0.0016
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4816
	data_grads_norm = 6.0304
	new_data_grads_norm = 9.6685
	old_data_grads_norm = 6.9239
	sim_grads_norm_tr = -0.0056
-- Starting training on experience 172 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7831
	data_grads_norm = 5.5923
	new_data_grads_norm = 7.1892
	old_data_grads_norm = 6.9361
	sim_grads_norm_tr = -0.0048
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4173
	data_grads_norm = 5.8720
	new_data_grads_norm = 9.7232
	old_data_grads_norm = 7.7629
	sim_grads_norm_tr = 0.0249
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1495
	data_grads_norm = 5.5193
	new_data_grads_norm = 8.0829
	old_data_grads_norm = 6.0917
	sim_grads_norm_tr = 0.1024
-- Starting training on experience 173 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1758
	data_grads_norm = 5.6134
	new_data_grads_norm = 9.0338
	old_data_grads_norm = 6.2719
	sim_grads_norm_tr = 0.0055
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3005
	data_grads_norm = 5.9610
	new_data_grads_norm = 8.5894
	old_data_grads_norm = 6.1548
	sim_grads_norm_tr = 0.1027
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9679
	data_grads_norm = 5.6665
	new_data_grads_norm = 8.9210
	old_data_grads_norm = 7.8444
	sim_grads_norm_tr = 0.0025
-- Starting training on experience 174 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8751
	data_grads_norm = 5.3583
	new_data_grads_norm = 8.0710
	old_data_grads_norm = 6.1975
	sim_grads_norm_tr = 0.0449
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6826
	data_grads_norm = 4.3143
	new_data_grads_norm = 7.5337
	old_data_grads_norm = 6.7460
	sim_grads_norm_tr = -0.0375
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4897
	data_grads_norm = 4.6715
	new_data_grads_norm = 7.1405
	old_data_grads_norm = 5.5566
	sim_grads_norm_tr = -0.0333
-- Starting training on experience 175 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2121
	data_grads_norm = 6.2532
	new_data_grads_norm = 7.7674
	old_data_grads_norm = 8.5873
	sim_grads_norm_tr = 0.0142
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2522
	data_grads_norm = 6.2287
	new_data_grads_norm = 8.4785
	old_data_grads_norm = 9.0011
	sim_grads_norm_tr = -0.0019
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1526
	data_grads_norm = 5.6481
	new_data_grads_norm = 7.8569
	old_data_grads_norm = 8.2055
	sim_grads_norm_tr = 0.0193
-- Starting training on experience 176 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1844
	data_grads_norm = 5.5416
	new_data_grads_norm = 6.6091
	old_data_grads_norm = 8.4036
	sim_grads_norm_tr = -0.0424
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1659
	data_grads_norm = 4.8025
	new_data_grads_norm = 7.2029
	old_data_grads_norm = 8.2599
	sim_grads_norm_tr = -0.0257
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5099
	data_grads_norm = 4.1981
	new_data_grads_norm = 6.9928
	old_data_grads_norm = 4.7244
	sim_grads_norm_tr = -0.0105
-- Starting training on experience 177 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9030
	data_grads_norm = 5.9011
	new_data_grads_norm = 7.7271
	old_data_grads_norm = 8.4242
	sim_grads_norm_tr = 0.0858
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4698
	data_grads_norm = 4.4138
	new_data_grads_norm = 7.0828
	old_data_grads_norm = 6.8986
	sim_grads_norm_tr = -0.0694
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6902
	data_grads_norm = 5.1287
	new_data_grads_norm = 7.2785
	old_data_grads_norm = 8.1220
	sim_grads_norm_tr = -0.0126
-- Starting training on experience 178 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9020
	data_grads_norm = 4.6614
	new_data_grads_norm = 7.2584
	old_data_grads_norm = 6.8913
	sim_grads_norm_tr = -0.0160
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3268
	data_grads_norm = 4.5942
	new_data_grads_norm = 8.0189
	old_data_grads_norm = 7.7445
	sim_grads_norm_tr = -0.0355
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5506
	data_grads_norm = 5.5803
	new_data_grads_norm = 6.7308
	old_data_grads_norm = 8.2370
	sim_grads_norm_tr = -0.0244
-- Starting training on experience 179 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0840
	data_grads_norm = 5.8352
	new_data_grads_norm = 7.5867
	old_data_grads_norm = 6.4842
	sim_grads_norm_tr = 0.0328
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8405
	data_grads_norm = 5.1236
	new_data_grads_norm = 8.1327
	old_data_grads_norm = 7.0435
	sim_grads_norm_tr = -0.0068
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6127
	data_grads_norm = 4.6733
	new_data_grads_norm = 7.0546
	old_data_grads_norm = 4.3702
	sim_grads_norm_tr = 0.0404
-- Starting training on experience 180 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9480
	data_grads_norm = 5.5377
	new_data_grads_norm = 8.6720
	old_data_grads_norm = 6.2676
	sim_grads_norm_tr = -0.0078
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1736
	data_grads_norm = 5.5493
	new_data_grads_norm = 8.5108
	old_data_grads_norm = 6.8114
	sim_grads_norm_tr = 0.0618
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5249
	data_grads_norm = 4.9763
	new_data_grads_norm = 8.6307
	old_data_grads_norm = 8.1771
	sim_grads_norm_tr = -0.0369
-- Starting training on experience 181 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5148
	data_grads_norm = 4.4931
	new_data_grads_norm = 7.6422
	old_data_grads_norm = 5.1255
	sim_grads_norm_tr = -0.0146
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8345
	data_grads_norm = 5.6676
	new_data_grads_norm = 8.2393
	old_data_grads_norm = 6.7428
	sim_grads_norm_tr = 0.0070
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7789
	data_grads_norm = 5.3260
	new_data_grads_norm = 6.9728
	old_data_grads_norm = 6.8247
	sim_grads_norm_tr = 0.0093
-- Starting training on experience 182 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8700
	data_grads_norm = 5.3388
	new_data_grads_norm = 6.8710
	old_data_grads_norm = 7.1881
	sim_grads_norm_tr = -0.0203
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0693
	data_grads_norm = 5.1936
	new_data_grads_norm = 8.4420
	old_data_grads_norm = 6.4408
	sim_grads_norm_tr = 0.0118
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0139
	data_grads_norm = 5.4987
	new_data_grads_norm = 7.9624
	old_data_grads_norm = 6.9003
	sim_grads_norm_tr = -0.0406
-- Starting training on experience 183 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4792
	data_grads_norm = 5.7919
	new_data_grads_norm = 9.4164
	old_data_grads_norm = 6.8783
	sim_grads_norm_tr = -0.0323
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4983
	data_grads_norm = 5.8216
	new_data_grads_norm = 10.0703
	old_data_grads_norm = 5.3512
	sim_grads_norm_tr = 0.0129
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1172
	data_grads_norm = 7.2399
	new_data_grads_norm = 10.1615
	old_data_grads_norm = 8.8679
	sim_grads_norm_tr = 0.0618
-- Starting training on experience 184 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3470
	data_grads_norm = 5.2871
	new_data_grads_norm = 9.1873
	old_data_grads_norm = 6.0684
	sim_grads_norm_tr = -0.0083
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6231
	data_grads_norm = 5.9802
	new_data_grads_norm = 8.5365
	old_data_grads_norm = 6.6218
	sim_grads_norm_tr = 0.0007
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1208
	data_grads_norm = 4.6879
	new_data_grads_norm = 7.8578
	old_data_grads_norm = 5.0412
	sim_grads_norm_tr = 0.0079
-- Starting training on experience 185 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3698
	data_grads_norm = 6.0060
	new_data_grads_norm = 8.2801
	old_data_grads_norm = 9.6734
	sim_grads_norm_tr = 0.0080
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4794
	data_grads_norm = 5.1525
	new_data_grads_norm = 7.3539
	old_data_grads_norm = 7.9944
	sim_grads_norm_tr = -0.0265
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3037
	data_grads_norm = 5.5718
	new_data_grads_norm = 9.2696
	old_data_grads_norm = 8.4928
	sim_grads_norm_tr = 0.0067
-- Starting training on experience 186 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0475
	data_grads_norm = 6.3974
	new_data_grads_norm = 8.0990
	old_data_grads_norm = 7.5480
	sim_grads_norm_tr = 0.0260
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4297
	data_grads_norm = 5.4663
	new_data_grads_norm = 8.3314
	old_data_grads_norm = 7.0167
	sim_grads_norm_tr = -0.0026
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7395
	data_grads_norm = 6.4373
	new_data_grads_norm = 8.7174
	old_data_grads_norm = 7.4642
	sim_grads_norm_tr = -0.0097
-- Starting training on experience 187 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6756
	data_grads_norm = 5.8189
	new_data_grads_norm = 8.6314
	old_data_grads_norm = 9.3221
	sim_grads_norm_tr = -0.0214
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5176
	data_grads_norm = 5.9532
	new_data_grads_norm = 9.0385
	old_data_grads_norm = 7.2255
	sim_grads_norm_tr = 0.0191
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5910
	data_grads_norm = 5.7992
	new_data_grads_norm = 9.5671
	old_data_grads_norm = 6.1705
	sim_grads_norm_tr = 0.0537
-- Starting training on experience 188 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7633
	data_grads_norm = 4.3836
	new_data_grads_norm = 8.5214
	old_data_grads_norm = 5.1465
	sim_grads_norm_tr = 0.0169
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7221
	data_grads_norm = 4.6396
	new_data_grads_norm = 8.3476
	old_data_grads_norm = 6.8000
	sim_grads_norm_tr = -0.0435
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0652
	data_grads_norm = 5.8387
	new_data_grads_norm = 8.8287
	old_data_grads_norm = 8.5482
	sim_grads_norm_tr = -0.0026
-- Starting training on experience 189 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3721
	data_grads_norm = 5.9137
	new_data_grads_norm = 8.2799
	old_data_grads_norm = 5.7577
	sim_grads_norm_tr = 0.1156
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9405
	data_grads_norm = 6.7616
	new_data_grads_norm = 9.0556
	old_data_grads_norm = 9.0096
	sim_grads_norm_tr = 0.0131
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2754
	data_grads_norm = 5.8111
	new_data_grads_norm = 8.2382
	old_data_grads_norm = 6.5575
	sim_grads_norm_tr = 0.0263
-- Starting training on experience 190 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3798
	data_grads_norm = 5.7689
	new_data_grads_norm = 8.0031
	old_data_grads_norm = 7.0744
	sim_grads_norm_tr = 0.0110
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9875
	data_grads_norm = 5.7615
	new_data_grads_norm = 7.8814
	old_data_grads_norm = 8.2249
	sim_grads_norm_tr = -0.0201
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9990
	data_grads_norm = 4.9882
	new_data_grads_norm = 8.0316
	old_data_grads_norm = 6.6207
	sim_grads_norm_tr = -0.0160
-- Starting training on experience 191 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7336
	data_grads_norm = 6.5923
	new_data_grads_norm = 9.2072
	old_data_grads_norm = 6.7014
	sim_grads_norm_tr = 0.0378
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1182
	data_grads_norm = 5.7601
	new_data_grads_norm = 9.0017
	old_data_grads_norm = 7.3099
	sim_grads_norm_tr = 0.0054
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2205
	data_grads_norm = 6.5306
	new_data_grads_norm = 10.4804
	old_data_grads_norm = 6.6961
	sim_grads_norm_tr = 0.0019
-- Starting training on experience 192 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9362
	data_grads_norm = 5.0657
	new_data_grads_norm = 7.9259
	old_data_grads_norm = 4.7108
	sim_grads_norm_tr = 0.0024
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0162
	data_grads_norm = 5.4755
	new_data_grads_norm = 8.2778
	old_data_grads_norm = 8.8181
	sim_grads_norm_tr = 0.0172
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9142
	data_grads_norm = 5.8489
	new_data_grads_norm = 7.8751
	old_data_grads_norm = 7.3457
	sim_grads_norm_tr = 0.0028
-- Starting training on experience 193 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2212
	data_grads_norm = 5.6866
	new_data_grads_norm = 8.1111
	old_data_grads_norm = 6.2825
	sim_grads_norm_tr = 0.0604
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4566
	data_grads_norm = 6.4738
	new_data_grads_norm = 7.9605
	old_data_grads_norm = 8.3722
	sim_grads_norm_tr = 0.0357
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2194
	data_grads_norm = 5.7531
	new_data_grads_norm = 8.0845
	old_data_grads_norm = 7.5540
	sim_grads_norm_tr = 0.0136
-- Starting training on experience 194 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9612
	data_grads_norm = 5.9752
	new_data_grads_norm = 8.3733
	old_data_grads_norm = 8.2322
	sim_grads_norm_tr = -0.0343
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5811
	data_grads_norm = 5.2993
	new_data_grads_norm = 8.5816
	old_data_grads_norm = 5.5267
	sim_grads_norm_tr = -0.0205
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2556
	data_grads_norm = 7.2063
	new_data_grads_norm = 9.6364
	old_data_grads_norm = 8.9351
	sim_grads_norm_tr = 0.0895
-- Starting training on experience 195 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4194
	data_grads_norm = 6.4198
	new_data_grads_norm = 9.6590
	old_data_grads_norm = 7.3389
	sim_grads_norm_tr = 0.0228
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2459
	data_grads_norm = 5.6455
	new_data_grads_norm = 8.2381
	old_data_grads_norm = 6.5592
	sim_grads_norm_tr = 0.0584
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6904
	data_grads_norm = 6.0580
	new_data_grads_norm = 9.3206
	old_data_grads_norm = 7.7267
	sim_grads_norm_tr = 0.0243
-- Starting training on experience 196 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6668
	data_grads_norm = 4.2412
	new_data_grads_norm = 6.4972
	old_data_grads_norm = 5.3192
	sim_grads_norm_tr = 0.0276
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8746
	data_grads_norm = 4.7597
	new_data_grads_norm = 7.3652
	old_data_grads_norm = 5.9185
	sim_grads_norm_tr = -0.0215
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6235
	data_grads_norm = 5.2303
	new_data_grads_norm = 7.6319
	old_data_grads_norm = 7.9229
	sim_grads_norm_tr = -0.0290
-- Starting training on experience 197 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1092
	data_grads_norm = 4.7019
	new_data_grads_norm = 7.9953
	old_data_grads_norm = 4.5460
	sim_grads_norm_tr = -0.0038
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2284
	data_grads_norm = 5.2431
	new_data_grads_norm = 8.2271
	old_data_grads_norm = 5.4148
	sim_grads_norm_tr = 0.0776
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1169
	data_grads_norm = 5.3502
	new_data_grads_norm = 7.1652
	old_data_grads_norm = 7.7587
	sim_grads_norm_tr = 0.0475
-- Starting training on experience 198 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1138
	data_grads_norm = 5.1757
	new_data_grads_norm = 9.7441
	old_data_grads_norm = 3.1311
	sim_grads_norm_tr = 0.0076
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5056
	data_grads_norm = 6.1088
	new_data_grads_norm = 8.9100
	old_data_grads_norm = 7.4213
	sim_grads_norm_tr = 0.0177
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2862
	data_grads_norm = 5.0628
	new_data_grads_norm = 8.0485
	old_data_grads_norm = 4.2965
	sim_grads_norm_tr = 0.0752
-- Starting training on experience 199 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1938
	data_grads_norm = 5.2869
	new_data_grads_norm = 6.8080
	old_data_grads_norm = 7.5235
	sim_grads_norm_tr = -0.0005
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8665
	data_grads_norm = 4.3312
	new_data_grads_norm = 7.4224
	old_data_grads_norm = 4.0356
	sim_grads_norm_tr = 0.0758
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3302
	data_grads_norm = 5.7514
	new_data_grads_norm = 7.3373
	old_data_grads_norm = 7.5208
	sim_grads_norm_tr = 0.0160
-- Starting training on experience 200 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1629
	data_grads_norm = 4.7668
	new_data_grads_norm = 7.7156
	old_data_grads_norm = 4.3422
	sim_grads_norm_tr = -0.0262
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6029
	data_grads_norm = 5.2615
	new_data_grads_norm = 8.1090
	old_data_grads_norm = 6.2220
	sim_grads_norm_tr = 0.0476
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1766
	data_grads_norm = 5.1004
	new_data_grads_norm = 8.1510
	old_data_grads_norm = 5.5624
	sim_grads_norm_tr = -0.0228
-- Starting training on experience 201 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3744
	data_grads_norm = 6.4795
	new_data_grads_norm = 9.1781
	old_data_grads_norm = 7.7940
	sim_grads_norm_tr = 0.0170
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0707
	data_grads_norm = 6.0314
	new_data_grads_norm = 9.4009
	old_data_grads_norm = 6.9905
	sim_grads_norm_tr = 0.0059
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3328
	data_grads_norm = 6.3310
	new_data_grads_norm = 10.1025
	old_data_grads_norm = 10.7775
	sim_grads_norm_tr = -0.0394
-- Starting training on experience 202 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1281
	data_grads_norm = 4.7174
	new_data_grads_norm = 7.3619
	old_data_grads_norm = 5.4883
	sim_grads_norm_tr = -0.0067
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1735
	data_grads_norm = 5.2598
	new_data_grads_norm = 8.3247
	old_data_grads_norm = 5.8226
	sim_grads_norm_tr = -0.0203
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7696
	data_grads_norm = 6.7468
	new_data_grads_norm = 8.8600
	old_data_grads_norm = 7.3951
	sim_grads_norm_tr = 0.0465
-- Starting training on experience 203 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9303
	data_grads_norm = 5.2058
	new_data_grads_norm = 7.8778
	old_data_grads_norm = 6.2589
	sim_grads_norm_tr = -0.0068
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6609
	data_grads_norm = 5.0696
	new_data_grads_norm = 8.0782
	old_data_grads_norm = 6.3361
	sim_grads_norm_tr = -0.0115
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5172
	data_grads_norm = 4.7525
	new_data_grads_norm = 7.4525
	old_data_grads_norm = 5.2372
	sim_grads_norm_tr = 0.0170
-- Starting training on experience 204 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0415
	data_grads_norm = 5.5776
	new_data_grads_norm = 7.2340
	old_data_grads_norm = 7.0599
	sim_grads_norm_tr = -0.0025
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8387
	data_grads_norm = 5.8467
	new_data_grads_norm = 7.6209
	old_data_grads_norm = 6.1558
	sim_grads_norm_tr = 0.0082
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9672
	data_grads_norm = 6.2001
	new_data_grads_norm = 8.6214
	old_data_grads_norm = 6.8605
	sim_grads_norm_tr = 0.0222
-- Starting training on experience 205 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5643
	data_grads_norm = 5.4226
	new_data_grads_norm = 7.5540
	old_data_grads_norm = 6.4209
	sim_grads_norm_tr = -0.0175
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1632
	data_grads_norm = 5.6390
	new_data_grads_norm = 7.6935
	old_data_grads_norm = 8.9533
	sim_grads_norm_tr = -0.0229
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0867
	data_grads_norm = 4.7887
	new_data_grads_norm = 7.6087
	old_data_grads_norm = 6.2536
	sim_grads_norm_tr = -0.0085
-- Starting training on experience 206 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7411
	data_grads_norm = 6.2565
	new_data_grads_norm = 9.6432
	old_data_grads_norm = 7.7648
	sim_grads_norm_tr = -0.0049
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7894
	data_grads_norm = 5.8751
	new_data_grads_norm = 9.2048
	old_data_grads_norm = 7.9812
	sim_grads_norm_tr = -0.0395
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1132
	data_grads_norm = 7.4237
	new_data_grads_norm = 10.8340
	old_data_grads_norm = 8.3690
	sim_grads_norm_tr = 0.0374
-- Starting training on experience 207 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6543
	data_grads_norm = 6.4746
	new_data_grads_norm = 9.4250
	old_data_grads_norm = 7.7936
	sim_grads_norm_tr = 0.0114
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2137
	data_grads_norm = 5.7363
	new_data_grads_norm = 8.7872
	old_data_grads_norm = 5.3601
	sim_grads_norm_tr = 0.0471
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7619
	data_grads_norm = 5.2556
	new_data_grads_norm = 8.9236
	old_data_grads_norm = 7.1259
	sim_grads_norm_tr = 0.0180
-- Starting training on experience 208 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9774
	data_grads_norm = 6.4820
	new_data_grads_norm = 9.0147
	old_data_grads_norm = 9.3265
	sim_grads_norm_tr = 0.0432
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3276
	data_grads_norm = 5.9450
	new_data_grads_norm = 6.8227
	old_data_grads_norm = 7.2667
	sim_grads_norm_tr = 0.0572
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3234
	data_grads_norm = 5.7379
	new_data_grads_norm = 8.5055
	old_data_grads_norm = 6.9197
	sim_grads_norm_tr = -0.0254
-- Starting training on experience 209 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7227
	data_grads_norm = 5.2613
	new_data_grads_norm = 7.8006
	old_data_grads_norm = 8.5671
	sim_grads_norm_tr = 0.0216
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3081
	data_grads_norm = 5.7744
	new_data_grads_norm = 8.9762
	old_data_grads_norm = 7.8051
	sim_grads_norm_tr = -0.0116
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3789
	data_grads_norm = 6.1945
	new_data_grads_norm = 8.9496
	old_data_grads_norm = 9.2385
	sim_grads_norm_tr = -0.0061
-- Starting training on experience 210 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5553
	data_grads_norm = 6.2383
	new_data_grads_norm = 9.5983
	old_data_grads_norm = 8.5794
	sim_grads_norm_tr = -0.0048
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2446
	data_grads_norm = 5.2036
	new_data_grads_norm = 7.9259
	old_data_grads_norm = 5.1824
	sim_grads_norm_tr = 0.0690
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0546
	data_grads_norm = 5.3210
	new_data_grads_norm = 8.4048
	old_data_grads_norm = 7.2345
	sim_grads_norm_tr = -0.0169
-- Starting training on experience 211 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1685
	data_grads_norm = 6.0423
	new_data_grads_norm = 8.0071
	old_data_grads_norm = 8.7299
	sim_grads_norm_tr = -0.0041
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7667
	data_grads_norm = 6.2346
	new_data_grads_norm = 8.8224
	old_data_grads_norm = 8.2136
	sim_grads_norm_tr = 0.0138
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9799
	data_grads_norm = 4.8601
	new_data_grads_norm = 8.4756
	old_data_grads_norm = 4.7424
	sim_grads_norm_tr = -0.0051
-- Starting training on experience 212 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8255
	data_grads_norm = 4.8499
	new_data_grads_norm = 7.8064
	old_data_grads_norm = 4.1592
	sim_grads_norm_tr = -0.0344
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5881
	data_grads_norm = 6.4433
	new_data_grads_norm = 9.0685
	old_data_grads_norm = 8.3537
	sim_grads_norm_tr = 0.0007
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0312
	data_grads_norm = 5.3337
	new_data_grads_norm = 7.5926
	old_data_grads_norm = 6.8725
	sim_grads_norm_tr = 0.0051
-- Starting training on experience 213 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4528
	data_grads_norm = 5.7629
	new_data_grads_norm = 8.8958
	old_data_grads_norm = 5.5440
	sim_grads_norm_tr = 0.0142
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0715
	data_grads_norm = 4.9911
	new_data_grads_norm = 8.1757
	old_data_grads_norm = 5.3788
	sim_grads_norm_tr = 0.0232
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8548
	data_grads_norm = 4.4061
	new_data_grads_norm = 8.2557
	old_data_grads_norm = 4.5654
	sim_grads_norm_tr = 0.0043
-- Starting training on experience 214 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1163
	data_grads_norm = 6.2261
	new_data_grads_norm = 9.2806
	old_data_grads_norm = 8.0890
	sim_grads_norm_tr = -0.0154
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3182
	data_grads_norm = 5.9822
	new_data_grads_norm = 8.2700
	old_data_grads_norm = 5.7758
	sim_grads_norm_tr = -0.0132
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3119
	data_grads_norm = 5.6420
	new_data_grads_norm = 8.7044
	old_data_grads_norm = 7.0587
	sim_grads_norm_tr = 0.0062
-- Starting training on experience 215 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4218
	data_grads_norm = 5.4303
	new_data_grads_norm = 8.3312
	old_data_grads_norm = 5.6399
	sim_grads_norm_tr = -0.0014
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3163
	data_grads_norm = 5.8496
	new_data_grads_norm = 8.3091
	old_data_grads_norm = 7.3917
	sim_grads_norm_tr = -0.0076
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5203
	data_grads_norm = 5.9975
	new_data_grads_norm = 8.2933
	old_data_grads_norm = 7.4996
	sim_grads_norm_tr = 0.0715
-- Starting training on experience 216 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0162
	data_grads_norm = 6.3160
	new_data_grads_norm = 9.8037
	old_data_grads_norm = 6.8050
	sim_grads_norm_tr = 0.0434
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6146
	data_grads_norm = 6.5207
	new_data_grads_norm = 9.7539
	old_data_grads_norm = 7.2751
	sim_grads_norm_tr = 0.0578
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6040
	data_grads_norm = 5.8797
	new_data_grads_norm = 9.4763
	old_data_grads_norm = 6.0754
	sim_grads_norm_tr = 0.0097
-- Starting training on experience 217 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2822
	data_grads_norm = 4.2265
	new_data_grads_norm = 6.8900
	old_data_grads_norm = 6.5139
	sim_grads_norm_tr = 0.0018
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9213
	data_grads_norm = 6.0005
	new_data_grads_norm = 7.9825
	old_data_grads_norm = 8.1069
	sim_grads_norm_tr = -0.0121
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4548
	data_grads_norm = 5.1420
	new_data_grads_norm = 7.7583
	old_data_grads_norm = 6.0335
	sim_grads_norm_tr = 0.0017
-- Starting training on experience 218 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8159
	data_grads_norm = 5.5354
	new_data_grads_norm = 7.9493
	old_data_grads_norm = 6.3904
	sim_grads_norm_tr = 0.0042
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5965
	data_grads_norm = 4.7589
	new_data_grads_norm = 7.9880
	old_data_grads_norm = 5.0718
	sim_grads_norm_tr = -0.0003
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3727
	data_grads_norm = 6.0556
	new_data_grads_norm = 7.8669
	old_data_grads_norm = 9.6471
	sim_grads_norm_tr = 0.0546
-- Starting training on experience 219 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1006
	data_grads_norm = 5.5687
	new_data_grads_norm = 8.9488
	old_data_grads_norm = 7.3377
	sim_grads_norm_tr = 0.0010
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3379
	data_grads_norm = 5.6829
	new_data_grads_norm = 9.1705
	old_data_grads_norm = 6.4524
	sim_grads_norm_tr = 0.0173
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1491
	data_grads_norm = 5.5219
	new_data_grads_norm = 9.0681
	old_data_grads_norm = 5.5452
	sim_grads_norm_tr = -0.0065
-- Starting training on experience 220 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4100
	data_grads_norm = 5.8199
	new_data_grads_norm = 9.0075
	old_data_grads_norm = 7.8326
	sim_grads_norm_tr = 0.0209
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2570
	data_grads_norm = 6.2110
	new_data_grads_norm = 8.8086
	old_data_grads_norm = 9.2490
	sim_grads_norm_tr = -0.0346
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9459
	data_grads_norm = 5.0983
	new_data_grads_norm = 8.6965
	old_data_grads_norm = 6.7815
	sim_grads_norm_tr = 0.0051
-- Starting training on experience 221 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9182
	data_grads_norm = 5.8929
	new_data_grads_norm = 8.3041
	old_data_grads_norm = 7.8294
	sim_grads_norm_tr = 0.0004
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1246
	data_grads_norm = 5.9385
	new_data_grads_norm = 7.7841
	old_data_grads_norm = 10.3456
	sim_grads_norm_tr = -0.0046
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7405
	data_grads_norm = 5.0238
	new_data_grads_norm = 7.6697
	old_data_grads_norm = 6.3806
	sim_grads_norm_tr = -0.0130
-- Starting training on experience 222 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0855
	data_grads_norm = 5.4344
	new_data_grads_norm = 8.3998
	old_data_grads_norm = 7.7802
	sim_grads_norm_tr = -0.0085
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9650
	data_grads_norm = 5.0335
	new_data_grads_norm = 7.7386
	old_data_grads_norm = 6.1916
	sim_grads_norm_tr = 0.0057
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4200
	data_grads_norm = 6.1290
	new_data_grads_norm = 7.6661
	old_data_grads_norm = 8.7124
	sim_grads_norm_tr = 0.0788
-- Starting training on experience 223 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4324
	data_grads_norm = 5.7750
	new_data_grads_norm = 9.1416
	old_data_grads_norm = 7.1629
	sim_grads_norm_tr = -0.0053
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6318
	data_grads_norm = 6.0148
	new_data_grads_norm = 8.4957
	old_data_grads_norm = 8.2399
	sim_grads_norm_tr = 0.0374
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0425
	data_grads_norm = 6.5453
	new_data_grads_norm = 8.9766
	old_data_grads_norm = 8.1209
	sim_grads_norm_tr = -0.0292
-- Starting training on experience 224 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8079
	data_grads_norm = 4.8827
	new_data_grads_norm = 8.3916
	old_data_grads_norm = 5.6805
	sim_grads_norm_tr = 0.0060
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7100
	data_grads_norm = 4.9268
	new_data_grads_norm = 7.5827
	old_data_grads_norm = 7.0608
	sim_grads_norm_tr = -0.0146
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4657
	data_grads_norm = 5.7373
	new_data_grads_norm = 8.2005
	old_data_grads_norm = 6.8459
	sim_grads_norm_tr = 0.1001
-- Starting training on experience 225 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3807
	data_grads_norm = 6.4569
	new_data_grads_norm = 10.4607
	old_data_grads_norm = 6.9927
	sim_grads_norm_tr = -0.0239
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5966
	data_grads_norm = 6.2935
	new_data_grads_norm = 9.7565
	old_data_grads_norm = 5.7175
	sim_grads_norm_tr = -0.0098
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2012
	data_grads_norm = 6.7051
	new_data_grads_norm = 10.6113
	old_data_grads_norm = 7.5037
	sim_grads_norm_tr = -0.0043
-- Starting training on experience 226 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0609
	data_grads_norm = 5.7517
	new_data_grads_norm = 8.6523
	old_data_grads_norm = 6.1848
	sim_grads_norm_tr = -0.0131
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4169
	data_grads_norm = 6.5733
	new_data_grads_norm = 10.0734
	old_data_grads_norm = 6.8183
	sim_grads_norm_tr = 0.0366
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2836
	data_grads_norm = 5.8242
	new_data_grads_norm = 8.5562
	old_data_grads_norm = 7.4368
	sim_grads_norm_tr = 0.0068
-- Starting training on experience 227 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7729
	data_grads_norm = 4.7326
	new_data_grads_norm = 7.7706
	old_data_grads_norm = 4.2093
	sim_grads_norm_tr = -0.0257
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2585
	data_grads_norm = 7.0558
	new_data_grads_norm = 8.2243
	old_data_grads_norm = 10.0174
	sim_grads_norm_tr = -0.0240
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5032
	data_grads_norm = 5.8435
	new_data_grads_norm = 8.9160
	old_data_grads_norm = 7.0296
	sim_grads_norm_tr = 0.0310
-- Starting training on experience 228 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3957
	data_grads_norm = 6.1714
	new_data_grads_norm = 9.2053
	old_data_grads_norm = 7.1094
	sim_grads_norm_tr = 0.0006
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1274
	data_grads_norm = 5.4132
	new_data_grads_norm = 9.6044
	old_data_grads_norm = 3.7709
	sim_grads_norm_tr = -0.0059
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7615
	data_grads_norm = 6.3574
	new_data_grads_norm = 9.6054
	old_data_grads_norm = 7.9576
	sim_grads_norm_tr = 0.0137
-- Starting training on experience 229 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9772
	data_grads_norm = 5.6809
	new_data_grads_norm = 8.7395
	old_data_grads_norm = 6.6875
	sim_grads_norm_tr = -0.0342
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4521
	data_grads_norm = 6.4378
	new_data_grads_norm = 8.1272
	old_data_grads_norm = 7.6610
	sim_grads_norm_tr = 0.0149
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3682
	data_grads_norm = 5.2727
	new_data_grads_norm = 7.0632
	old_data_grads_norm = 7.1250
	sim_grads_norm_tr = 0.0315
-- Starting training on experience 230 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2145
	data_grads_norm = 5.5033
	new_data_grads_norm = 7.7866
	old_data_grads_norm = 5.6675
	sim_grads_norm_tr = 0.0782
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1994
	data_grads_norm = 5.7967
	new_data_grads_norm = 8.0148
	old_data_grads_norm = 8.6541
	sim_grads_norm_tr = 0.0026
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8102
	data_grads_norm = 6.3206
	new_data_grads_norm = 8.4686
	old_data_grads_norm = 8.5455
	sim_grads_norm_tr = 0.0311
-- Starting training on experience 231 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2623
	data_grads_norm = 5.3498
	new_data_grads_norm = 7.8960
	old_data_grads_norm = 6.0848
	sim_grads_norm_tr = 0.0348
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0600
	data_grads_norm = 5.4170
	new_data_grads_norm = 7.4540
	old_data_grads_norm = 6.0848
	sim_grads_norm_tr = -0.0216
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0768
	data_grads_norm = 5.4516
	new_data_grads_norm = 7.7973
	old_data_grads_norm = 4.5171
	sim_grads_norm_tr = 0.0026
-- Starting training on experience 232 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0533
	data_grads_norm = 6.0940
	new_data_grads_norm = 9.2145
	old_data_grads_norm = 6.8083
	sim_grads_norm_tr = -0.0520
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3368
	data_grads_norm = 6.2049
	new_data_grads_norm = 8.6441
	old_data_grads_norm = 8.6506
	sim_grads_norm_tr = 0.0091
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6761
	data_grads_norm = 5.0534
	new_data_grads_norm = 7.9558
	old_data_grads_norm = 6.0974
	sim_grads_norm_tr = -0.0024
-- Starting training on experience 233 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5466
	data_grads_norm = 6.1701
	new_data_grads_norm = 10.1339
	old_data_grads_norm = 7.4912
	sim_grads_norm_tr = 0.0216
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9550
	data_grads_norm = 5.2346
	new_data_grads_norm = 8.2420
	old_data_grads_norm = 6.0377
	sim_grads_norm_tr = -0.0295
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7607
	data_grads_norm = 5.3334
	new_data_grads_norm = 8.9817
	old_data_grads_norm = 7.3661
	sim_grads_norm_tr = -0.0305
-- Starting training on experience 234 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2055
	data_grads_norm = 5.4019
	new_data_grads_norm = 8.3308
	old_data_grads_norm = 6.2274
	sim_grads_norm_tr = 0.0391
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4326
	data_grads_norm = 5.8862
	new_data_grads_norm = 7.8598
	old_data_grads_norm = 9.6146
	sim_grads_norm_tr = 0.0073
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3124
	data_grads_norm = 6.1290
	new_data_grads_norm = 8.6469
	old_data_grads_norm = 8.5326
	sim_grads_norm_tr = -0.0456
-- Starting training on experience 235 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2404
	data_grads_norm = 5.5875
	new_data_grads_norm = 8.3621
	old_data_grads_norm = 6.8714
	sim_grads_norm_tr = -0.0474
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5489
	data_grads_norm = 6.8572
	new_data_grads_norm = 8.7651
	old_data_grads_norm = 8.4617
	sim_grads_norm_tr = 0.0036
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6180
	data_grads_norm = 6.4503
	new_data_grads_norm = 8.5995
	old_data_grads_norm = 7.3265
	sim_grads_norm_tr = -0.0020
-- Starting training on experience 236 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2413
	data_grads_norm = 5.1790
	new_data_grads_norm = 8.1794
	old_data_grads_norm = 5.9045
	sim_grads_norm_tr = 0.0023
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2290
	data_grads_norm = 5.7516
	new_data_grads_norm = 8.3474
	old_data_grads_norm = 7.4422
	sim_grads_norm_tr = 0.0096
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9987
	data_grads_norm = 5.2712
	new_data_grads_norm = 8.1943
	old_data_grads_norm = 6.0706
	sim_grads_norm_tr = 0.0198
-- Starting training on experience 237 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
-- >> End of training phase << --
-- >> Start of eval phase << --
-- Starting eval on experience 0 (Task 0) from test stream --
> Eval on experience 0 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp000 = 3.6362
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.2920
	mb_index = 4046
	time = 1611.0277
-- Starting eval on experience 1 (Task 0) from test stream --
> Eval on experience 1 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp001 = 3.4389
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.3640
-- Starting eval on experience 2 (Task 0) from test stream --
> Eval on experience 2 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp002 = 4.0907
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.2780
-- Starting eval on experience 3 (Task 0) from test stream --
> Eval on experience 3 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp003 = 3.0981
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.4160
-- Starting eval on experience 4 (Task 0) from test stream --
> Eval on experience 4 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp004 = 5.1574
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.1600
-- Starting eval on experience 5 (Task 0) from test stream --
> Eval on experience 5 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp005 = 3.9888
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.2960
-- Starting eval on experience 6 (Task 0) from test stream --
> Eval on experience 6 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp006 = 3.6703
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp006 = 0.2820
-- Starting eval on experience 7 (Task 0) from test stream --
> Eval on experience 7 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp007 = 3.9433
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp007 = 0.3120
-- Starting eval on experience 8 (Task 0) from test stream --
> Eval on experience 8 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp008 = 2.9900
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp008 = 0.4500
-- Starting eval on experience 9 (Task 0) from test stream --
> Eval on experience 9 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp009 = 3.1593
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp009 = 0.3180
-- Starting eval on experience 10 (Task 0) from test stream --
> Eval on experience 10 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp010 = 3.8967
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp010 = 0.1860
-- Starting eval on experience 11 (Task 0) from test stream --
> Eval on experience 11 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp011 = 2.8125
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp011 = 0.3840
-- Starting eval on experience 12 (Task 0) from test stream --
> Eval on experience 12 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp012 = 4.0461
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp012 = 0.1560
-- Starting eval on experience 13 (Task 0) from test stream --
> Eval on experience 13 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp013 = 3.4238
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp013 = 0.1900
-- Starting eval on experience 14 (Task 0) from test stream --
> Eval on experience 14 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp014 = 3.2243
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp014 = 0.2800
-- Starting eval on experience 15 (Task 0) from test stream --
> Eval on experience 15 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp015 = 3.1785
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp015 = 0.2220
-- Starting eval on experience 16 (Task 0) from test stream --
> Eval on experience 16 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp016 = 3.9176
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp016 = 0.0500
-- >> End of eval phase << --
	CumulativeAccuracy/eval_phase/test_stream/Exp000 = 0.7400
	CumulativeAccuracy/eval_phase/test_stream/Exp001 = 0.6640
	CumulativeAccuracy/eval_phase/test_stream/Exp002 = 0.5653
	CumulativeAccuracy/eval_phase/test_stream/Exp003 = 0.5300
	CumulativeAccuracy/eval_phase/test_stream/Exp004 = 0.4840
	CumulativeAccuracy/eval_phase/test_stream/Exp005 = 0.4463
	CumulativeAccuracy/eval_phase/test_stream/Exp006 = 0.4186
	CumulativeAccuracy/eval_phase/test_stream/Exp007 = 0.4022
	CumulativeAccuracy/eval_phase/test_stream/Exp008 = 0.3920
	CumulativeAccuracy/eval_phase/test_stream/Exp009 = 0.3722
	CumulativeAccuracy/eval_phase/test_stream/Exp010 = 0.3522
	CumulativeAccuracy/eval_phase/test_stream/Exp011 = 0.3465
	CumulativeAccuracy/eval_phase/test_stream/Exp012 = 0.3235
	CumulativeAccuracy/eval_phase/test_stream/Exp013 = 0.3111
	CumulativeAccuracy/eval_phase/test_stream/Exp014 = 0.3009
	CumulativeAccuracy/eval_phase/test_stream/Exp015 = 0.2878
	CumulativeAccuracy/eval_phase/test_stream/Exp016 = 0.2727
	Loss_Stream/eval_phase/test_stream/Task000 = 3.6278
	Top1_Acc_Stream/eval_phase/test_stream/Task000 = 0.2727
-- >> Start of training phase << --
-- Starting training on experience 0 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.1737
	data_grads_norm = 6.2209
	new_data_grads_norm = 9.4874
	old_data_grads_norm = 8.0022
	sim_grads_norm_tr = 0.0134
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.3839
	data_grads_norm = 6.3492
	new_data_grads_norm = 8.6813
	old_data_grads_norm = 8.4402
	sim_grads_norm_tr = -0.0082
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.9090
	data_grads_norm = 6.6324
	new_data_grads_norm = 9.7658
	old_data_grads_norm = 8.7299
	sim_grads_norm_tr = -0.0052
-- Starting training on experience 1 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.3229
	data_grads_norm = 6.9855
	new_data_grads_norm = 10.1444
	old_data_grads_norm = 7.9322
	sim_grads_norm_tr = -0.0033
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.7269
	data_grads_norm = 6.7844
	new_data_grads_norm = 8.9489
	old_data_grads_norm = 7.7549
	sim_grads_norm_tr = 0.0189
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.5554
	data_grads_norm = 6.9178
	new_data_grads_norm = 9.9595
	old_data_grads_norm = 7.0669
	sim_grads_norm_tr = 0.0237
-- Starting training on experience 2 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.8422
	data_grads_norm = 5.6335
	new_data_grads_norm = 7.8310
	old_data_grads_norm = 6.3698
	sim_grads_norm_tr = -0.0037
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.9349
	data_grads_norm = 5.6133
	new_data_grads_norm = 7.5068
	old_data_grads_norm = 6.8557
	sim_grads_norm_tr = 0.0265
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4364
	data_grads_norm = 5.4523
	new_data_grads_norm = 7.1578
	old_data_grads_norm = 5.7258
	sim_grads_norm_tr = -0.0184
-- Starting training on experience 3 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.8072
	data_grads_norm = 6.2395
	new_data_grads_norm = 7.9307
	old_data_grads_norm = 9.2371
	sim_grads_norm_tr = 0.0243
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.0607
	data_grads_norm = 5.6177
	new_data_grads_norm = 8.3874
	old_data_grads_norm = 6.5238
	sim_grads_norm_tr = 0.0289
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1599
	data_grads_norm = 4.6776
	new_data_grads_norm = 7.6854
	old_data_grads_norm = 4.4886
	sim_grads_norm_tr = 0.0089
-- Starting training on experience 4 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.9352
	data_grads_norm = 6.0579
	new_data_grads_norm = 8.3548
	old_data_grads_norm = 7.1446
	sim_grads_norm_tr = 0.0197
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6638
	data_grads_norm = 5.5245
	new_data_grads_norm = 7.9181
	old_data_grads_norm = 6.4250
	sim_grads_norm_tr = -0.0164
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.9118
	data_grads_norm = 6.0103
	new_data_grads_norm = 8.4774
	old_data_grads_norm = 6.1033
	sim_grads_norm_tr = 0.0175
-- Starting training on experience 5 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.0275
	data_grads_norm = 6.4184
	new_data_grads_norm = 8.0966
	old_data_grads_norm = 10.2526
	sim_grads_norm_tr = 0.0591
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.9469
	data_grads_norm = 5.6846
	new_data_grads_norm = 7.3511
	old_data_grads_norm = 6.8912
	sim_grads_norm_tr = 0.0662
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0900
	data_grads_norm = 5.0407
	new_data_grads_norm = 7.9555
	old_data_grads_norm = 6.6903
	sim_grads_norm_tr = 0.0078
-- Starting training on experience 6 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3535
	data_grads_norm = 6.0635
	new_data_grads_norm = 7.8385
	old_data_grads_norm = 7.9249
	sim_grads_norm_tr = 0.0294
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2114
	data_grads_norm = 5.2982
	new_data_grads_norm = 7.9347
	old_data_grads_norm = 6.4403
	sim_grads_norm_tr = -0.0155
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5387
	data_grads_norm = 5.2345
	new_data_grads_norm = 7.4431
	old_data_grads_norm = 5.9403
	sim_grads_norm_tr = 0.1245
-- Starting training on experience 7 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2344
	data_grads_norm = 5.9603
	new_data_grads_norm = 9.7386
	old_data_grads_norm = 4.4283
	sim_grads_norm_tr = 0.0337
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8965
	data_grads_norm = 5.0932
	new_data_grads_norm = 8.6248
	old_data_grads_norm = 4.7920
	sim_grads_norm_tr = 0.0005
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3952
	data_grads_norm = 5.8145
	new_data_grads_norm = 9.0879
	old_data_grads_norm = 6.3976
	sim_grads_norm_tr = 0.0604
-- Starting training on experience 8 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8946
	data_grads_norm = 5.4566
	new_data_grads_norm = 9.1731
	old_data_grads_norm = 5.2244
	sim_grads_norm_tr = 0.0071
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9611
	data_grads_norm = 5.4228
	new_data_grads_norm = 8.5142
	old_data_grads_norm = 6.0540
	sim_grads_norm_tr = -0.0113
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1106
	data_grads_norm = 5.4567
	new_data_grads_norm = 8.8197
	old_data_grads_norm = 4.7001
	sim_grads_norm_tr = -0.0013
-- Starting training on experience 9 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6163
	data_grads_norm = 5.6622
	new_data_grads_norm = 8.0971
	old_data_grads_norm = 7.8930
	sim_grads_norm_tr = 0.0018
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1622
	data_grads_norm = 5.0566
	new_data_grads_norm = 8.4976
	old_data_grads_norm = 4.7269
	sim_grads_norm_tr = 0.0129
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5482
	data_grads_norm = 5.5232
	new_data_grads_norm = 8.4209
	old_data_grads_norm = 6.4214
	sim_grads_norm_tr = -0.0090
-- Starting training on experience 10 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.9618
	data_grads_norm = 5.9284
	new_data_grads_norm = 8.9604
	old_data_grads_norm = 7.6783
	sim_grads_norm_tr = -0.0105
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.2384
	data_grads_norm = 6.3315
	new_data_grads_norm = 8.7363
	old_data_grads_norm = 7.6742
	sim_grads_norm_tr = 0.0353
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.1555
	data_grads_norm = 6.5858
	new_data_grads_norm = 9.4011
	old_data_grads_norm = 8.1858
	sim_grads_norm_tr = 0.0498
-- Starting training on experience 11 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1172
	data_grads_norm = 5.3798
	new_data_grads_norm = 9.4112
	old_data_grads_norm = 3.9325
	sim_grads_norm_tr = 0.0288
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6238
	data_grads_norm = 6.0259
	new_data_grads_norm = 9.2817
	old_data_grads_norm = 6.5927
	sim_grads_norm_tr = -0.0432
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.7512
	data_grads_norm = 6.7656
	new_data_grads_norm = 9.2179
	old_data_grads_norm = 8.1256
	sim_grads_norm_tr = -0.0156
-- Starting training on experience 12 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9797
	data_grads_norm = 5.1228
	new_data_grads_norm = 8.4405
	old_data_grads_norm = 6.2345
	sim_grads_norm_tr = -0.0047
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3067
	data_grads_norm = 5.3503
	new_data_grads_norm = 8.5028
	old_data_grads_norm = 5.2365
	sim_grads_norm_tr = 0.0286
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5693
	data_grads_norm = 5.8998
	new_data_grads_norm = 7.9262
	old_data_grads_norm = 7.5343
	sim_grads_norm_tr = 0.0621
-- Starting training on experience 13 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2160
	data_grads_norm = 5.4897
	new_data_grads_norm = 8.0609
	old_data_grads_norm = 7.0777
	sim_grads_norm_tr = 0.0051
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2330
	data_grads_norm = 4.6621
	new_data_grads_norm = 7.8641
	old_data_grads_norm = 4.6590
	sim_grads_norm_tr = 0.0418
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2252
	data_grads_norm = 5.5076
	new_data_grads_norm = 7.7993
	old_data_grads_norm = 6.3859
	sim_grads_norm_tr = 0.0493
-- Starting training on experience 14 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7702
	data_grads_norm = 4.6837
	new_data_grads_norm = 7.6337
	old_data_grads_norm = 4.5122
	sim_grads_norm_tr = 0.0752
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6190
	data_grads_norm = 4.9007
	new_data_grads_norm = 7.7060
	old_data_grads_norm = 5.5454
	sim_grads_norm_tr = 0.0246
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6598
	data_grads_norm = 5.2820
	new_data_grads_norm = 7.5806
	old_data_grads_norm = 6.4980
	sim_grads_norm_tr = -0.0043
-- Starting training on experience 15 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0064
	data_grads_norm = 4.7847
	new_data_grads_norm = 8.0044
	old_data_grads_norm = 4.9379
	sim_grads_norm_tr = 0.0214
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9308
	data_grads_norm = 5.2815
	new_data_grads_norm = 8.2772
	old_data_grads_norm = 6.3925
	sim_grads_norm_tr = 0.0133
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1609
	data_grads_norm = 5.7092
	new_data_grads_norm = 7.5753
	old_data_grads_norm = 8.7014
	sim_grads_norm_tr = 0.0092
-- Starting training on experience 16 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2271
	data_grads_norm = 4.9448
	new_data_grads_norm = 7.9175
	old_data_grads_norm = 5.9259
	sim_grads_norm_tr = 0.0593
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7149
	data_grads_norm = 4.9046
	new_data_grads_norm = 7.5819
	old_data_grads_norm = 8.1527
	sim_grads_norm_tr = 0.0313
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0596
	data_grads_norm = 4.0793
	new_data_grads_norm = 7.0805
	old_data_grads_norm = 6.7141
	sim_grads_norm_tr = -0.0084
-- Starting training on experience 17 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6025
	data_grads_norm = 4.8844
	new_data_grads_norm = 9.4093
	old_data_grads_norm = 4.7361
	sim_grads_norm_tr = 0.0305
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6235
	data_grads_norm = 5.4559
	new_data_grads_norm = 9.3755
	old_data_grads_norm = 8.7231
	sim_grads_norm_tr = -0.0196
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4361
	data_grads_norm = 6.9311
	new_data_grads_norm = 10.3880
	old_data_grads_norm = 8.1933
	sim_grads_norm_tr = 0.0166
-- Starting training on experience 18 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3801
	data_grads_norm = 6.2210
	new_data_grads_norm = 8.8058
	old_data_grads_norm = 8.2263
	sim_grads_norm_tr = 0.0590
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7267
	data_grads_norm = 5.1908
	new_data_grads_norm = 7.8049
	old_data_grads_norm = 7.7530
	sim_grads_norm_tr = 0.0125
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0083
	data_grads_norm = 5.3291
	new_data_grads_norm = 7.8457
	old_data_grads_norm = 6.7438
	sim_grads_norm_tr = 0.0511
-- Starting training on experience 19 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5147
	data_grads_norm = 6.7711
	new_data_grads_norm = 9.8737
	old_data_grads_norm = 7.5218
	sim_grads_norm_tr = 0.0361
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9528
	data_grads_norm = 5.2995
	new_data_grads_norm = 8.7546
	old_data_grads_norm = 5.9835
	sim_grads_norm_tr = 0.0386
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9603
	data_grads_norm = 5.6033
	new_data_grads_norm = 9.0539
	old_data_grads_norm = 5.0668
	sim_grads_norm_tr = 0.0612
-- Starting training on experience 20 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7850
	data_grads_norm = 5.2493
	new_data_grads_norm = 8.1197
	old_data_grads_norm = 6.3446
	sim_grads_norm_tr = 0.0334
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6916
	data_grads_norm = 5.9079
	new_data_grads_norm = 8.7453
	old_data_grads_norm = 6.6996
	sim_grads_norm_tr = -0.0441
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7114
	data_grads_norm = 5.8194
	new_data_grads_norm = 8.3122
	old_data_grads_norm = 7.1468
	sim_grads_norm_tr = 0.0137
-- Starting training on experience 21 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1082
	data_grads_norm = 5.4622
	new_data_grads_norm = 7.0957
	old_data_grads_norm = 6.8412
	sim_grads_norm_tr = -0.0113
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5022
	data_grads_norm = 6.5540
	new_data_grads_norm = 8.8095
	old_data_grads_norm = 8.8910
	sim_grads_norm_tr = 0.0169
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0928
	data_grads_norm = 4.7132
	new_data_grads_norm = 6.9642
	old_data_grads_norm = 5.1364
	sim_grads_norm_tr = -0.0059
-- Starting training on experience 22 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1780
	data_grads_norm = 6.2529
	new_data_grads_norm = 10.0105
	old_data_grads_norm = 6.8353
	sim_grads_norm_tr = 0.0284
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0723
	data_grads_norm = 4.9774
	new_data_grads_norm = 9.3456
	old_data_grads_norm = 4.8200
	sim_grads_norm_tr = 0.0080
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2996
	data_grads_norm = 5.8020
	new_data_grads_norm = 9.5519
	old_data_grads_norm = 8.0076
	sim_grads_norm_tr = 0.0299
-- Starting training on experience 23 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8251
	data_grads_norm = 6.5777
	new_data_grads_norm = 8.9798
	old_data_grads_norm = 7.9962
	sim_grads_norm_tr = 0.0135
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5035
	data_grads_norm = 5.6858
	new_data_grads_norm = 9.2897
	old_data_grads_norm = 5.7818
	sim_grads_norm_tr = 0.0045
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7060
	data_grads_norm = 5.6087
	new_data_grads_norm = 9.0319
	old_data_grads_norm = 5.2606
	sim_grads_norm_tr = 0.0954
-- Starting training on experience 24 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1127
	data_grads_norm = 4.3331
	new_data_grads_norm = 7.4060
	old_data_grads_norm = 6.2838
	sim_grads_norm_tr = 0.0053
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2410
	data_grads_norm = 5.0026
	new_data_grads_norm = 7.8052
	old_data_grads_norm = 6.2965
	sim_grads_norm_tr = 0.0208
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0310
	data_grads_norm = 4.3225
	new_data_grads_norm = 7.4325
	old_data_grads_norm = 5.6428
	sim_grads_norm_tr = -0.0335
-- Starting training on experience 25 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7116
	data_grads_norm = 6.9426
	new_data_grads_norm = 9.3707
	old_data_grads_norm = 8.7078
	sim_grads_norm_tr = 0.0501
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4287
	data_grads_norm = 5.8810
	new_data_grads_norm = 9.4175
	old_data_grads_norm = 7.8102
	sim_grads_norm_tr = -0.0514
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8293
	data_grads_norm = 7.1496
	new_data_grads_norm = 9.4344
	old_data_grads_norm = 10.1124
	sim_grads_norm_tr = 0.0340
-- Starting training on experience 26 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9019
	data_grads_norm = 4.9510
	new_data_grads_norm = 8.2292
	old_data_grads_norm = 5.7407
	sim_grads_norm_tr = -0.0265
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1717
	data_grads_norm = 6.5836
	new_data_grads_norm = 8.6959
	old_data_grads_norm = 7.8966
	sim_grads_norm_tr = 0.1190
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5031
	data_grads_norm = 5.2031
	new_data_grads_norm = 8.4924
	old_data_grads_norm = 7.4281
	sim_grads_norm_tr = -0.0327
-- Starting training on experience 27 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6060
	data_grads_norm = 5.1844
	new_data_grads_norm = 6.8534
	old_data_grads_norm = 4.3322
	sim_grads_norm_tr = 0.0140
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2059
	data_grads_norm = 6.1453
	new_data_grads_norm = 6.9119
	old_data_grads_norm = 8.1979
	sim_grads_norm_tr = -0.0231
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4873
	data_grads_norm = 4.9845
	new_data_grads_norm = 7.2862
	old_data_grads_norm = 6.1811
	sim_grads_norm_tr = 0.0970
-- Starting training on experience 28 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0820
	data_grads_norm = 5.6187
	new_data_grads_norm = 8.0248
	old_data_grads_norm = 6.4647
	sim_grads_norm_tr = 0.0046
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2868
	data_grads_norm = 5.1469
	new_data_grads_norm = 7.4994
	old_data_grads_norm = 6.3584
	sim_grads_norm_tr = -0.0108
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7212
	data_grads_norm = 6.1793
	new_data_grads_norm = 8.3891
	old_data_grads_norm = 7.5235
	sim_grads_norm_tr = 0.0409
-- Starting training on experience 29 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1677
	data_grads_norm = 5.7747
	new_data_grads_norm = 7.3649
	old_data_grads_norm = 9.4737
	sim_grads_norm_tr = 0.0931
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5245
	data_grads_norm = 5.6892
	new_data_grads_norm = 7.0091
	old_data_grads_norm = 9.0258
	sim_grads_norm_tr = 0.0236
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7763
	data_grads_norm = 5.2948
	new_data_grads_norm = 6.9899
	old_data_grads_norm = 7.0907
	sim_grads_norm_tr = -0.0179
-- Starting training on experience 30 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0457
	data_grads_norm = 4.8320
	new_data_grads_norm = 6.3327
	old_data_grads_norm = 6.7588
	sim_grads_norm_tr = 0.0735
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8873
	data_grads_norm = 5.4794
	new_data_grads_norm = 7.1428
	old_data_grads_norm = 7.8475
	sim_grads_norm_tr = 0.0341
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7353
	data_grads_norm = 4.9999
	new_data_grads_norm = 6.9267
	old_data_grads_norm = 6.4401
	sim_grads_norm_tr = 0.0209
-- Starting training on experience 31 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7735
	data_grads_norm = 5.5090
	new_data_grads_norm = 6.9821
	old_data_grads_norm = 7.7807
	sim_grads_norm_tr = 0.0011
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2464
	data_grads_norm = 6.5618
	new_data_grads_norm = 7.6887
	old_data_grads_norm = 9.5161
	sim_grads_norm_tr = -0.0148
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3007
	data_grads_norm = 6.1296
	new_data_grads_norm = 9.5467
	old_data_grads_norm = 8.4275
	sim_grads_norm_tr = -0.0144
-- Starting training on experience 32 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5373
	data_grads_norm = 5.5234
	new_data_grads_norm = 8.9602
	old_data_grads_norm = 7.1825
	sim_grads_norm_tr = 0.0188
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9313
	data_grads_norm = 5.2591
	new_data_grads_norm = 7.5435
	old_data_grads_norm = 6.7801
	sim_grads_norm_tr = -0.0189
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7152
	data_grads_norm = 5.2129
	new_data_grads_norm = 8.3921
	old_data_grads_norm = 5.8341
	sim_grads_norm_tr = -0.0456
-- Starting training on experience 33 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2518
	data_grads_norm = 5.7376
	new_data_grads_norm = 8.2138
	old_data_grads_norm = 6.8913
	sim_grads_norm_tr = 0.0783
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1678
	data_grads_norm = 6.6796
	new_data_grads_norm = 9.4510
	old_data_grads_norm = 8.6672
	sim_grads_norm_tr = -0.0000
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8096
	data_grads_norm = 5.4297
	new_data_grads_norm = 8.3010
	old_data_grads_norm = 6.5139
	sim_grads_norm_tr = 0.0156
-- Starting training on experience 34 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1981
	data_grads_norm = 5.2926
	new_data_grads_norm = 8.2061
	old_data_grads_norm = 4.8482
	sim_grads_norm_tr = 0.0501
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3524
	data_grads_norm = 6.1434
	new_data_grads_norm = 8.6028
	old_data_grads_norm = 6.6880
	sim_grads_norm_tr = -0.0425
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0410
	data_grads_norm = 5.1898
	new_data_grads_norm = 8.4484
	old_data_grads_norm = 7.5073
	sim_grads_norm_tr = -0.0287
-- Starting training on experience 35 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1508
	data_grads_norm = 5.3581
	new_data_grads_norm = 8.4427
	old_data_grads_norm = 5.5729
	sim_grads_norm_tr = 0.0292
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2387
	data_grads_norm = 6.4696
	new_data_grads_norm = 9.3328
	old_data_grads_norm = 7.5309
	sim_grads_norm_tr = -0.0018
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6879
	data_grads_norm = 4.7434
	new_data_grads_norm = 8.2315
	old_data_grads_norm = 4.6722
	sim_grads_norm_tr = 0.0015
-- Starting training on experience 36 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4771
	data_grads_norm = 4.9005
	new_data_grads_norm = 8.1287
	old_data_grads_norm = 4.4102
	sim_grads_norm_tr = 0.0071
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6780
	data_grads_norm = 5.1817
	new_data_grads_norm = 7.7672
	old_data_grads_norm = 6.2613
	sim_grads_norm_tr = -0.0232
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6277
	data_grads_norm = 5.0490
	new_data_grads_norm = 8.1329
	old_data_grads_norm = 3.8561
	sim_grads_norm_tr = -0.0446
-- Starting training on experience 37 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1163
	data_grads_norm = 5.9739
	new_data_grads_norm = 7.0460
	old_data_grads_norm = 7.2835
	sim_grads_norm_tr = 0.0060
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6547
	data_grads_norm = 5.1920
	new_data_grads_norm = 8.1319
	old_data_grads_norm = 6.7587
	sim_grads_norm_tr = -0.0123
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5996
	data_grads_norm = 4.9812
	new_data_grads_norm = 7.5529
	old_data_grads_norm = 7.4713
	sim_grads_norm_tr = 0.0180
-- Starting training on experience 38 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4377
	data_grads_norm = 5.7811
	new_data_grads_norm = 8.7127
	old_data_grads_norm = 6.4041
	sim_grads_norm_tr = 0.1056
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1501
	data_grads_norm = 5.9899
	new_data_grads_norm = 8.6398
	old_data_grads_norm = 7.2070
	sim_grads_norm_tr = 0.0230
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8264
	data_grads_norm = 5.4105
	new_data_grads_norm = 8.1633
	old_data_grads_norm = 6.2658
	sim_grads_norm_tr = -0.0068
-- Starting training on experience 39 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3646
	data_grads_norm = 4.5957
	new_data_grads_norm = 6.5382
	old_data_grads_norm = 7.5317
	sim_grads_norm_tr = -0.0085
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4371
	data_grads_norm = 4.9341
	new_data_grads_norm = 6.3170
	old_data_grads_norm = 7.8888
	sim_grads_norm_tr = 0.0062
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6790
	data_grads_norm = 5.4036
	new_data_grads_norm = 6.2709
	old_data_grads_norm = 8.2795
	sim_grads_norm_tr = -0.0129
-- Starting training on experience 40 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0480
	data_grads_norm = 5.7357
	new_data_grads_norm = 7.6896
	old_data_grads_norm = 8.6488
	sim_grads_norm_tr = -0.0183
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8678
	data_grads_norm = 5.9689
	new_data_grads_norm = 8.4554
	old_data_grads_norm = 8.8128
	sim_grads_norm_tr = -0.0214
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0335
	data_grads_norm = 5.2846
	new_data_grads_norm = 7.7990
	old_data_grads_norm = 6.4141
	sim_grads_norm_tr = 0.0485
-- Starting training on experience 41 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9225
	data_grads_norm = 5.4736
	new_data_grads_norm = 7.8467
	old_data_grads_norm = 7.7824
	sim_grads_norm_tr = 0.0262
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2343
	data_grads_norm = 4.4144
	new_data_grads_norm = 7.4815
	old_data_grads_norm = 5.7345
	sim_grads_norm_tr = -0.0110
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6780
	data_grads_norm = 5.0916
	new_data_grads_norm = 7.6859
	old_data_grads_norm = 6.6321
	sim_grads_norm_tr = 0.0624
-- Starting training on experience 42 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7020
	data_grads_norm = 4.6278
	new_data_grads_norm = 7.0686
	old_data_grads_norm = 5.6202
	sim_grads_norm_tr = 0.0040
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0472
	data_grads_norm = 5.6229
	new_data_grads_norm = 7.2013
	old_data_grads_norm = 7.7471
	sim_grads_norm_tr = 0.0868
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6134
	data_grads_norm = 4.7662
	new_data_grads_norm = 7.1958
	old_data_grads_norm = 6.6791
	sim_grads_norm_tr = -0.0457
-- Starting training on experience 43 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8755
	data_grads_norm = 5.9374
	new_data_grads_norm = 8.8041
	old_data_grads_norm = 7.9064
	sim_grads_norm_tr = -0.0085
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6322
	data_grads_norm = 4.5678
	new_data_grads_norm = 8.2763
	old_data_grads_norm = 5.4564
	sim_grads_norm_tr = 0.0304
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3767
	data_grads_norm = 6.3594
	new_data_grads_norm = 7.4966
	old_data_grads_norm = 7.1440
	sim_grads_norm_tr = -0.0317
-- Starting training on experience 44 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7555
	data_grads_norm = 6.0830
	new_data_grads_norm = 9.3611
	old_data_grads_norm = 6.4729
	sim_grads_norm_tr = -0.0106
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0846
	data_grads_norm = 6.1436
	new_data_grads_norm = 9.4536
	old_data_grads_norm = 7.5062
	sim_grads_norm_tr = 0.0022
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1706
	data_grads_norm = 6.0496
	new_data_grads_norm = 8.7660
	old_data_grads_norm = 7.2723
	sim_grads_norm_tr = 0.0206
-- Starting training on experience 45 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0462
	data_grads_norm = 5.0555
	new_data_grads_norm = 9.4354
	old_data_grads_norm = 3.2925
	sim_grads_norm_tr = 0.0104
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0981
	data_grads_norm = 6.6026
	new_data_grads_norm = 10.1017
	old_data_grads_norm = 6.9352
	sim_grads_norm_tr = 0.0038
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6714
	data_grads_norm = 6.8320
	new_data_grads_norm = 8.0803
	old_data_grads_norm = 7.5526
	sim_grads_norm_tr = -0.0007
-- Starting training on experience 46 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4901
	data_grads_norm = 4.5503
	new_data_grads_norm = 7.5092
	old_data_grads_norm = 7.1743
	sim_grads_norm_tr = -0.0331
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9808
	data_grads_norm = 5.0036
	new_data_grads_norm = 7.1791
	old_data_grads_norm = 6.1556
	sim_grads_norm_tr = 0.0530
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5628
	data_grads_norm = 4.9665
	new_data_grads_norm = 7.3637
	old_data_grads_norm = 5.0188
	sim_grads_norm_tr = 0.0191
-- Starting training on experience 47 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7132
	data_grads_norm = 4.7959
	new_data_grads_norm = 7.4223
	old_data_grads_norm = 5.4093
	sim_grads_norm_tr = -0.0187
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8556
	data_grads_norm = 5.1873
	new_data_grads_norm = 7.4532
	old_data_grads_norm = 6.6923
	sim_grads_norm_tr = -0.0003
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6386
	data_grads_norm = 4.8021
	new_data_grads_norm = 7.6173
	old_data_grads_norm = 4.4816
	sim_grads_norm_tr = -0.0029
-- Starting training on experience 48 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2502
	data_grads_norm = 6.1204
	new_data_grads_norm = 8.9949
	old_data_grads_norm = 7.0371
	sim_grads_norm_tr = 0.0032
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8901
	data_grads_norm = 5.2232
	new_data_grads_norm = 8.4405
	old_data_grads_norm = 6.3033
	sim_grads_norm_tr = 0.0238
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3586
	data_grads_norm = 5.3932
	new_data_grads_norm = 9.2379
	old_data_grads_norm = 5.5749
	sim_grads_norm_tr = 0.0368
-- Starting training on experience 49 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8853
	data_grads_norm = 6.2452
	new_data_grads_norm = 7.8214
	old_data_grads_norm = 7.6913
	sim_grads_norm_tr = 0.0466
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7305
	data_grads_norm = 5.4850
	new_data_grads_norm = 7.3120
	old_data_grads_norm = 7.1170
	sim_grads_norm_tr = -0.0357
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5663
	data_grads_norm = 5.7029
	new_data_grads_norm = 7.4655
	old_data_grads_norm = 5.3290
	sim_grads_norm_tr = 0.0429
-- Starting training on experience 50 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3865
	data_grads_norm = 4.5358
	new_data_grads_norm = 8.1346
	old_data_grads_norm = 7.9588
	sim_grads_norm_tr = 0.0160
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2130
	data_grads_norm = 4.3276
	new_data_grads_norm = 7.0881
	old_data_grads_norm = 7.2599
	sim_grads_norm_tr = -0.0236
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1126
	data_grads_norm = 5.3648
	new_data_grads_norm = 9.1591
	old_data_grads_norm = 6.9724
	sim_grads_norm_tr = 0.0570
-- Starting training on experience 51 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3232
	data_grads_norm = 6.8581
	new_data_grads_norm = 10.8353
	old_data_grads_norm = 7.1541
	sim_grads_norm_tr = 0.0249
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5721
	data_grads_norm = 5.2448
	new_data_grads_norm = 9.8434
	old_data_grads_norm = 4.2759
	sim_grads_norm_tr = -0.0166
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6962
	data_grads_norm = 7.1081
	new_data_grads_norm = 10.2992
	old_data_grads_norm = 8.7753
	sim_grads_norm_tr = 0.0145
-- Starting training on experience 52 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8497
	data_grads_norm = 5.9286
	new_data_grads_norm = 8.6165
	old_data_grads_norm = 7.1401
	sim_grads_norm_tr = -0.0112
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4765
	data_grads_norm = 5.6327
	new_data_grads_norm = 8.0906
	old_data_grads_norm = 6.5759
	sim_grads_norm_tr = 0.0107
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2808
	data_grads_norm = 4.8705
	new_data_grads_norm = 7.4884
	old_data_grads_norm = 6.3524
	sim_grads_norm_tr = -0.0157
-- Starting training on experience 53 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8633
	data_grads_norm = 6.4535
	new_data_grads_norm = 10.6570
	old_data_grads_norm = 7.4551
	sim_grads_norm_tr = 0.0130
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6187
	data_grads_norm = 5.5980
	new_data_grads_norm = 8.8147
	old_data_grads_norm = 5.1596
	sim_grads_norm_tr = -0.0331
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5641
	data_grads_norm = 6.4327
	new_data_grads_norm = 9.9431
	old_data_grads_norm = 8.0863
	sim_grads_norm_tr = 0.0396
-- Starting training on experience 54 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1267
	data_grads_norm = 5.8499
	new_data_grads_norm = 8.3251
	old_data_grads_norm = 7.9301
	sim_grads_norm_tr = 0.0054
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5572
	data_grads_norm = 4.9639
	new_data_grads_norm = 9.1925
	old_data_grads_norm = 5.5137
	sim_grads_norm_tr = 0.0003
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9146
	data_grads_norm = 5.1855
	new_data_grads_norm = 7.6143
	old_data_grads_norm = 7.0149
	sim_grads_norm_tr = -0.0023
-- Starting training on experience 55 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5419
	data_grads_norm = 4.6420
	new_data_grads_norm = 7.9406
	old_data_grads_norm = 5.9751
	sim_grads_norm_tr = 0.0205
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0947
	data_grads_norm = 5.6438
	new_data_grads_norm = 8.4297
	old_data_grads_norm = 5.8078
	sim_grads_norm_tr = 0.0408
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8415
	data_grads_norm = 5.9623
	new_data_grads_norm = 8.2751
	old_data_grads_norm = 6.4421
	sim_grads_norm_tr = 0.0106
-- Starting training on experience 56 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8646
	data_grads_norm = 5.9296
	new_data_grads_norm = 7.3818
	old_data_grads_norm = 8.7166
	sim_grads_norm_tr = 0.0512
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6721
	data_grads_norm = 5.6208
	new_data_grads_norm = 7.7566
	old_data_grads_norm = 7.8975
	sim_grads_norm_tr = 0.0134
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6160
	data_grads_norm = 4.7994
	new_data_grads_norm = 7.4595
	old_data_grads_norm = 6.4740
	sim_grads_norm_tr = -0.0414
-- Starting training on experience 57 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9641
	data_grads_norm = 5.5101
	new_data_grads_norm = 7.8099
	old_data_grads_norm = 9.1296
	sim_grads_norm_tr = 0.0168
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5483
	data_grads_norm = 5.1219
	new_data_grads_norm = 7.7694
	old_data_grads_norm = 7.6708
	sim_grads_norm_tr = -0.0113
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8617
	data_grads_norm = 5.6093
	new_data_grads_norm = 7.8572
	old_data_grads_norm = 7.3922
	sim_grads_norm_tr = 0.0080
-- Starting training on experience 58 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2184
	data_grads_norm = 5.2515
	new_data_grads_norm = 7.2331
	old_data_grads_norm = 7.1564
	sim_grads_norm_tr = 0.0565
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9966
	data_grads_norm = 5.1121
	new_data_grads_norm = 7.9689
	old_data_grads_norm = 5.5141
	sim_grads_norm_tr = 0.0384
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9316
	data_grads_norm = 5.5961
	new_data_grads_norm = 8.2915
	old_data_grads_norm = 8.1242
	sim_grads_norm_tr = 0.0132
-- Starting training on experience 59 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2714
	data_grads_norm = 5.3175
	new_data_grads_norm = 7.6623
	old_data_grads_norm = 6.3857
	sim_grads_norm_tr = -0.0101
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6094
	data_grads_norm = 5.3924
	new_data_grads_norm = 7.5267
	old_data_grads_norm = 6.6635
	sim_grads_norm_tr = -0.0036
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3171
	data_grads_norm = 4.3412
	new_data_grads_norm = 7.1005
	old_data_grads_norm = 4.5994
	sim_grads_norm_tr = -0.0412
-- Starting training on experience 60 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9590
	data_grads_norm = 4.0661
	new_data_grads_norm = 7.4849
	old_data_grads_norm = 3.6354
	sim_grads_norm_tr = 0.0043
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5531
	data_grads_norm = 5.8660
	new_data_grads_norm = 8.4033
	old_data_grads_norm = 6.4799
	sim_grads_norm_tr = 0.0325
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7971
	data_grads_norm = 6.6573
	new_data_grads_norm = 9.1446
	old_data_grads_norm = 7.0987
	sim_grads_norm_tr = 0.0900
-- Starting training on experience 61 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6181
	data_grads_norm = 5.6608
	new_data_grads_norm = 8.5700
	old_data_grads_norm = 7.1877
	sim_grads_norm_tr = 0.0242
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5614
	data_grads_norm = 5.5504
	new_data_grads_norm = 7.9876
	old_data_grads_norm = 8.1285
	sim_grads_norm_tr = 0.0008
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5959
	data_grads_norm = 5.3177
	new_data_grads_norm = 8.0400
	old_data_grads_norm = 6.8107
	sim_grads_norm_tr = 0.0415
-- Starting training on experience 62 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9390
	data_grads_norm = 5.8260
	new_data_grads_norm = 8.4131
	old_data_grads_norm = 5.6234
	sim_grads_norm_tr = 0.1560
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9507
	data_grads_norm = 6.4847
	new_data_grads_norm = 9.3935
	old_data_grads_norm = 6.4653
	sim_grads_norm_tr = 0.0086
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3426
	data_grads_norm = 5.4930
	new_data_grads_norm = 8.6003
	old_data_grads_norm = 6.0735
	sim_grads_norm_tr = -0.0324
-- Starting training on experience 63 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6401
	data_grads_norm = 5.4681
	new_data_grads_norm = 8.4539
	old_data_grads_norm = 6.5030
	sim_grads_norm_tr = -0.0183
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8379
	data_grads_norm = 6.3286
	new_data_grads_norm = 8.8046
	old_data_grads_norm = 7.9425
	sim_grads_norm_tr = -0.0087
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5288
	data_grads_norm = 4.7222
	new_data_grads_norm = 7.9626
	old_data_grads_norm = 4.6134
	sim_grads_norm_tr = -0.0613
-- Starting training on experience 64 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4489
	data_grads_norm = 4.7430
	new_data_grads_norm = 7.8613
	old_data_grads_norm = 5.7378
	sim_grads_norm_tr = -0.0064
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9458
	data_grads_norm = 5.6380
	new_data_grads_norm = 7.6753
	old_data_grads_norm = 6.4952
	sim_grads_norm_tr = 0.0293
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3951
	data_grads_norm = 4.5610
	new_data_grads_norm = 7.5808
	old_data_grads_norm = 4.4245
	sim_grads_norm_tr = -0.0309
-- Starting training on experience 65 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5034
	data_grads_norm = 5.3848
	new_data_grads_norm = 7.1523
	old_data_grads_norm = 7.3422
	sim_grads_norm_tr = 0.0085
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6437
	data_grads_norm = 5.5748
	new_data_grads_norm = 7.6797
	old_data_grads_norm = 7.4879
	sim_grads_norm_tr = -0.0014
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8151
	data_grads_norm = 5.9805
	new_data_grads_norm = 8.0591
	old_data_grads_norm = 8.0130
	sim_grads_norm_tr = 0.0033
-- Starting training on experience 66 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1882
	data_grads_norm = 4.7002
	new_data_grads_norm = 7.9339
	old_data_grads_norm = 5.0260
	sim_grads_norm_tr = -0.0379
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9011
	data_grads_norm = 5.6662
	new_data_grads_norm = 8.4195
	old_data_grads_norm = 7.4249
	sim_grads_norm_tr = 0.0046
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3807
	data_grads_norm = 4.6201
	new_data_grads_norm = 8.0030
	old_data_grads_norm = 5.8914
	sim_grads_norm_tr = -0.0219
-- Starting training on experience 67 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0694
	data_grads_norm = 5.9665
	new_data_grads_norm = 8.9047
	old_data_grads_norm = 9.2263
	sim_grads_norm_tr = 0.0197
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3423
	data_grads_norm = 6.1576
	new_data_grads_norm = 7.7664
	old_data_grads_norm = 8.6254
	sim_grads_norm_tr = 0.0323
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8844
	data_grads_norm = 5.3269
	new_data_grads_norm = 8.7441
	old_data_grads_norm = 7.6152
	sim_grads_norm_tr = -0.0013
-- Starting training on experience 68 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8864
	data_grads_norm = 4.9669
	new_data_grads_norm = 7.0862
	old_data_grads_norm = 6.9786
	sim_grads_norm_tr = -0.0123
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4102
	data_grads_norm = 5.2088
	new_data_grads_norm = 7.5871
	old_data_grads_norm = 7.7536
	sim_grads_norm_tr = -0.0055
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2261
	data_grads_norm = 5.9313
	new_data_grads_norm = 6.6760
	old_data_grads_norm = 9.4069
	sim_grads_norm_tr = 0.0301
-- Starting training on experience 69 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2530
	data_grads_norm = 4.0814
	new_data_grads_norm = 7.5982
	old_data_grads_norm = 6.9195
	sim_grads_norm_tr = -0.0024
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6277
	data_grads_norm = 4.9700
	new_data_grads_norm = 7.0817
	old_data_grads_norm = 5.8081
	sim_grads_norm_tr = -0.0166
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4393
	data_grads_norm = 5.4632
	new_data_grads_norm = 7.0597
	old_data_grads_norm = 8.1300
	sim_grads_norm_tr = -0.0271
-- Starting training on experience 70 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4703
	data_grads_norm = 4.6246
	new_data_grads_norm = 8.6745
	old_data_grads_norm = 5.7853
	sim_grads_norm_tr = 0.0042
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7771
	data_grads_norm = 5.3513
	new_data_grads_norm = 7.4351
	old_data_grads_norm = 8.8614
	sim_grads_norm_tr = -0.0201
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8852
	data_grads_norm = 5.6795
	new_data_grads_norm = 8.6534
	old_data_grads_norm = 5.7180
	sim_grads_norm_tr = -0.0282
-- Starting training on experience 71 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8530
	data_grads_norm = 5.5740
	new_data_grads_norm = 8.3580
	old_data_grads_norm = 6.2413
	sim_grads_norm_tr = 0.0893
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4913
	data_grads_norm = 4.3990
	new_data_grads_norm = 7.3830
	old_data_grads_norm = 5.5739
	sim_grads_norm_tr = 0.0036
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8322
	data_grads_norm = 5.2032
	new_data_grads_norm = 7.3188
	old_data_grads_norm = 7.5382
	sim_grads_norm_tr = -0.0026
-- Starting training on experience 72 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7750
	data_grads_norm = 5.3791
	new_data_grads_norm = 9.0728
	old_data_grads_norm = 4.9647
	sim_grads_norm_tr = 0.0141
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0024
	data_grads_norm = 6.3876
	new_data_grads_norm = 9.9401
	old_data_grads_norm = 8.6623
	sim_grads_norm_tr = -0.0357
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9781
	data_grads_norm = 6.3930
	new_data_grads_norm = 8.8668
	old_data_grads_norm = 8.0099
	sim_grads_norm_tr = 0.0004
-- Starting training on experience 73 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0318
	data_grads_norm = 5.7266
	new_data_grads_norm = 8.8965
	old_data_grads_norm = 5.6905
	sim_grads_norm_tr = 0.0179
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6564
	data_grads_norm = 6.5340
	new_data_grads_norm = 8.7571
	old_data_grads_norm = 7.4968
	sim_grads_norm_tr = 0.0327
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5278
	data_grads_norm = 4.9881
	new_data_grads_norm = 9.3251
	old_data_grads_norm = 5.0842
	sim_grads_norm_tr = -0.0038
-- Starting training on experience 74 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0629
	data_grads_norm = 6.4380
	new_data_grads_norm = 9.8478
	old_data_grads_norm = 6.3330
	sim_grads_norm_tr = -0.0626
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0734
	data_grads_norm = 6.2824
	new_data_grads_norm = 10.4332
	old_data_grads_norm = 7.8761
	sim_grads_norm_tr = 0.0744
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5735
	data_grads_norm = 5.9699
	new_data_grads_norm = 9.0393
	old_data_grads_norm = 5.1642
	sim_grads_norm_tr = -0.0166
-- Starting training on experience 75 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3588
	data_grads_norm = 6.0897
	new_data_grads_norm = 8.2940
	old_data_grads_norm = 7.8270
	sim_grads_norm_tr = 0.0664
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5039
	data_grads_norm = 5.2609
	new_data_grads_norm = 8.6121
	old_data_grads_norm = 6.7292
	sim_grads_norm_tr = 0.0045
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0441
	data_grads_norm = 6.4139
	new_data_grads_norm = 8.8741
	old_data_grads_norm = 7.4797
	sim_grads_norm_tr = 0.0213
-- Starting training on experience 76 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5272
	data_grads_norm = 5.0019
	new_data_grads_norm = 7.1581
	old_data_grads_norm = 6.0931
	sim_grads_norm_tr = 0.0121
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8078
	data_grads_norm = 5.0693
	new_data_grads_norm = 8.1915
	old_data_grads_norm = 9.4599
	sim_grads_norm_tr = 0.0048
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9649
	data_grads_norm = 6.0660
	new_data_grads_norm = 8.2512
	old_data_grads_norm = 7.8112
	sim_grads_norm_tr = 0.0162
-- Starting training on experience 77 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8230
	data_grads_norm = 6.4121
	new_data_grads_norm = 7.4439
	old_data_grads_norm = 8.8412
	sim_grads_norm_tr = 0.0144
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9144
	data_grads_norm = 5.2988
	new_data_grads_norm = 7.8691
	old_data_grads_norm = 6.9877
	sim_grads_norm_tr = 0.0058
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5912
	data_grads_norm = 5.4435
	new_data_grads_norm = 8.4683
	old_data_grads_norm = 5.0453
	sim_grads_norm_tr = 0.0435
-- Starting training on experience 78 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5539
	data_grads_norm = 5.2848
	new_data_grads_norm = 8.1519
	old_data_grads_norm = 6.8747
	sim_grads_norm_tr = -0.0319
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6855
	data_grads_norm = 5.5803
	new_data_grads_norm = 8.6155
	old_data_grads_norm = 6.1004
	sim_grads_norm_tr = -0.0227
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9884
	data_grads_norm = 5.7806
	new_data_grads_norm = 8.2582
	old_data_grads_norm = 6.3241
	sim_grads_norm_tr = 0.0135
-- Starting training on experience 79 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7580
	data_grads_norm = 5.6040
	new_data_grads_norm = 7.4940
	old_data_grads_norm = 7.1192
	sim_grads_norm_tr = -0.0151
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4717
	data_grads_norm = 4.8070
	new_data_grads_norm = 7.3728
	old_data_grads_norm = 6.5516
	sim_grads_norm_tr = 0.0402
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8767
	data_grads_norm = 5.6064
	new_data_grads_norm = 6.9327
	old_data_grads_norm = 11.4488
	sim_grads_norm_tr = 0.0030
-- Starting training on experience 80 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8278
	data_grads_norm = 5.6626
	new_data_grads_norm = 8.5568
	old_data_grads_norm = 6.6662
	sim_grads_norm_tr = 0.1032
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7753
	data_grads_norm = 5.4381
	new_data_grads_norm = 7.7506
	old_data_grads_norm = 6.9042
	sim_grads_norm_tr = -0.0016
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0513
	data_grads_norm = 6.0824
	new_data_grads_norm = 8.4081
	old_data_grads_norm = 10.0930
	sim_grads_norm_tr = -0.0441
-- Starting training on experience 81 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8674
	data_grads_norm = 7.6868
	new_data_grads_norm = 8.7772
	old_data_grads_norm = 10.9841
	sim_grads_norm_tr = 0.0073
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1022
	data_grads_norm = 6.4074
	new_data_grads_norm = 7.8767
	old_data_grads_norm = 7.6234
	sim_grads_norm_tr = 0.0558
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8547
	data_grads_norm = 6.2235
	new_data_grads_norm = 7.1336
	old_data_grads_norm = 6.8634
	sim_grads_norm_tr = 0.0047
-- Starting training on experience 82 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5808
	data_grads_norm = 5.2376
	new_data_grads_norm = 8.4164
	old_data_grads_norm = 6.6956
	sim_grads_norm_tr = -0.0163
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4185
	data_grads_norm = 5.1360
	new_data_grads_norm = 8.2838
	old_data_grads_norm = 5.9312
	sim_grads_norm_tr = -0.0218
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9733
	data_grads_norm = 6.5606
	new_data_grads_norm = 8.5059
	old_data_grads_norm = 8.4478
	sim_grads_norm_tr = -0.0177
-- Starting training on experience 83 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7199
	data_grads_norm = 5.1806
	new_data_grads_norm = 8.1283
	old_data_grads_norm = 7.2095
	sim_grads_norm_tr = 0.0000
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3945
	data_grads_norm = 5.3836
	new_data_grads_norm = 8.6695
	old_data_grads_norm = 8.0920
	sim_grads_norm_tr = 0.0210
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7647
	data_grads_norm = 5.5232
	new_data_grads_norm = 8.0055
	old_data_grads_norm = 7.0273
	sim_grads_norm_tr = 0.0563
-- Starting training on experience 84 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5080
	data_grads_norm = 5.6697
	new_data_grads_norm = 10.1686
	old_data_grads_norm = 6.6704
	sim_grads_norm_tr = 0.0488
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5049
	data_grads_norm = 6.5374
	new_data_grads_norm = 9.1882
	old_data_grads_norm = 7.5619
	sim_grads_norm_tr = 0.0113
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0786
	data_grads_norm = 5.9422
	new_data_grads_norm = 8.6385
	old_data_grads_norm = 6.6098
	sim_grads_norm_tr = -0.0124
-- Starting training on experience 85 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0081
	data_grads_norm = 4.6091
	new_data_grads_norm = 7.6006
	old_data_grads_norm = 5.6031
	sim_grads_norm_tr = -0.0380
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2186
	data_grads_norm = 5.3075
	new_data_grads_norm = 8.9206
	old_data_grads_norm = 7.0712
	sim_grads_norm_tr = -0.0040
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8714
	data_grads_norm = 4.0930
	new_data_grads_norm = 6.9871
	old_data_grads_norm = 5.4345
	sim_grads_norm_tr = -0.0006
-- Starting training on experience 86 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9385
	data_grads_norm = 5.4623
	new_data_grads_norm = 7.8766
	old_data_grads_norm = 6.5443
	sim_grads_norm_tr = 0.0253
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4761
	data_grads_norm = 4.5771
	new_data_grads_norm = 7.5401
	old_data_grads_norm = 6.4635
	sim_grads_norm_tr = -0.0068
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3111
	data_grads_norm = 4.5967
	new_data_grads_norm = 8.6212
	old_data_grads_norm = 6.6861
	sim_grads_norm_tr = 0.0008
-- Starting training on experience 87 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7457
	data_grads_norm = 5.8826
	new_data_grads_norm = 8.1062
	old_data_grads_norm = 7.8414
	sim_grads_norm_tr = -0.0331
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0287
	data_grads_norm = 5.7315
	new_data_grads_norm = 8.0768
	old_data_grads_norm = 8.2781
	sim_grads_norm_tr = 0.0854
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5079
	data_grads_norm = 5.1084
	new_data_grads_norm = 7.5063
	old_data_grads_norm = 4.9346
	sim_grads_norm_tr = 0.0933
-- Starting training on experience 88 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1343
	data_grads_norm = 5.7065
	new_data_grads_norm = 8.9569
	old_data_grads_norm = 6.0222
	sim_grads_norm_tr = -0.0180
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5996
	data_grads_norm = 5.5885
	new_data_grads_norm = 9.1584
	old_data_grads_norm = 4.3154
	sim_grads_norm_tr = -0.0390
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3333
	data_grads_norm = 5.8106
	new_data_grads_norm = 9.1925
	old_data_grads_norm = 7.6359
	sim_grads_norm_tr = 0.0029
-- Starting training on experience 89 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7764
	data_grads_norm = 6.5757
	new_data_grads_norm = 9.4629
	old_data_grads_norm = 9.0806
	sim_grads_norm_tr = -0.0040
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2074
	data_grads_norm = 5.6934
	new_data_grads_norm = 8.1429
	old_data_grads_norm = 7.6255
	sim_grads_norm_tr = 0.0470
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5199
	data_grads_norm = 5.4024
	new_data_grads_norm = 8.5778
	old_data_grads_norm = 8.0956
	sim_grads_norm_tr = -0.0574
-- Starting training on experience 90 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4958
	data_grads_norm = 5.4685
	new_data_grads_norm = 8.0652
	old_data_grads_norm = 8.0754
	sim_grads_norm_tr = -0.0307
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8098
	data_grads_norm = 6.0260
	new_data_grads_norm = 7.7687
	old_data_grads_norm = 7.3244
	sim_grads_norm_tr = -0.0229
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3376
	data_grads_norm = 5.2111
	new_data_grads_norm = 9.4222
	old_data_grads_norm = 5.5697
	sim_grads_norm_tr = 0.0647
-- Starting training on experience 91 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5367
	data_grads_norm = 5.5902
	new_data_grads_norm = 9.3055
	old_data_grads_norm = 8.8604
	sim_grads_norm_tr = 0.0207
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6535
	data_grads_norm = 5.6084
	new_data_grads_norm = 9.6508
	old_data_grads_norm = 6.4099
	sim_grads_norm_tr = -0.0028
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9644
	data_grads_norm = 4.9228
	new_data_grads_norm = 8.3479
	old_data_grads_norm = 6.0262
	sim_grads_norm_tr = -0.0009
-- Starting training on experience 92 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8143
	data_grads_norm = 5.9423
	new_data_grads_norm = 8.2549
	old_data_grads_norm = 8.3448
	sim_grads_norm_tr = 0.0141
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4824
	data_grads_norm = 5.8410
	new_data_grads_norm = 8.3728
	old_data_grads_norm = 7.4609
	sim_grads_norm_tr = 0.0176
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6093
	data_grads_norm = 4.9063
	new_data_grads_norm = 7.3365
	old_data_grads_norm = 5.9156
	sim_grads_norm_tr = 0.0703
-- Starting training on experience 93 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1776
	data_grads_norm = 7.2118
	new_data_grads_norm = 9.4685
	old_data_grads_norm = 8.5752
	sim_grads_norm_tr = -0.0068
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8485
	data_grads_norm = 6.0038
	new_data_grads_norm = 8.8835
	old_data_grads_norm = 8.0262
	sim_grads_norm_tr = 0.0282
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2077
	data_grads_norm = 6.7574
	new_data_grads_norm = 9.1767
	old_data_grads_norm = 7.5805
	sim_grads_norm_tr = 0.1815
-- Starting training on experience 94 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5122
	data_grads_norm = 5.3836
	new_data_grads_norm = 8.5760
	old_data_grads_norm = 6.8389
	sim_grads_norm_tr = -0.0037
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7892
	data_grads_norm = 5.9293
	new_data_grads_norm = 8.6456
	old_data_grads_norm = 6.7324
	sim_grads_norm_tr = -0.0045
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4167
	data_grads_norm = 5.2960
	new_data_grads_norm = 8.3007
	old_data_grads_norm = 6.0080
	sim_grads_norm_tr = -0.0097
-- Starting training on experience 95 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5586
	data_grads_norm = 5.5010
	new_data_grads_norm = 8.2540
	old_data_grads_norm = 6.8417
	sim_grads_norm_tr = -0.0175
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4852
	data_grads_norm = 5.3364
	new_data_grads_norm = 8.4113
	old_data_grads_norm = 6.8223
	sim_grads_norm_tr = -0.0002
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5954
	data_grads_norm = 6.2949
	new_data_grads_norm = 8.6218
	old_data_grads_norm = 7.3378
	sim_grads_norm_tr = 0.0439
-- Starting training on experience 96 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3045
	data_grads_norm = 5.1590
	new_data_grads_norm = 8.1945
	old_data_grads_norm = 5.1414
	sim_grads_norm_tr = -0.0090
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9627
	data_grads_norm = 5.5614
	new_data_grads_norm = 7.7236
	old_data_grads_norm = 6.5671
	sim_grads_norm_tr = -0.0553
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8847
	data_grads_norm = 5.3628
	new_data_grads_norm = 7.5973
	old_data_grads_norm = 5.1720
	sim_grads_norm_tr = 0.0203
-- Starting training on experience 97 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6485
	data_grads_norm = 4.9603
	new_data_grads_norm = 7.7099
	old_data_grads_norm = 5.5613
	sim_grads_norm_tr = -0.0063
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3572
	data_grads_norm = 6.1672
	new_data_grads_norm = 6.9236
	old_data_grads_norm = 7.7965
	sim_grads_norm_tr = 0.0368
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3979
	data_grads_norm = 4.4107
	new_data_grads_norm = 7.2820
	old_data_grads_norm = 4.4505
	sim_grads_norm_tr = 0.0702
-- Starting training on experience 98 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7805
	data_grads_norm = 5.7728
	new_data_grads_norm = 8.1923
	old_data_grads_norm = 6.8282
	sim_grads_norm_tr = 0.0740
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7240
	data_grads_norm = 6.8166
	new_data_grads_norm = 8.9160
	old_data_grads_norm = 9.6689
	sim_grads_norm_tr = 0.0138
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3043
	data_grads_norm = 6.0511
	new_data_grads_norm = 9.1343
	old_data_grads_norm = 7.5541
	sim_grads_norm_tr = -0.0098
-- Starting training on experience 99 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8639
	data_grads_norm = 5.1121
	new_data_grads_norm = 8.2440
	old_data_grads_norm = 6.8965
	sim_grads_norm_tr = 0.0105
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1282
	data_grads_norm = 4.8795
	new_data_grads_norm = 7.7802
	old_data_grads_norm = 4.5003
	sim_grads_norm_tr = -0.0299
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8868
	data_grads_norm = 5.2978
	new_data_grads_norm = 7.8002
	old_data_grads_norm = 7.0851
	sim_grads_norm_tr = -0.0174
-- Starting training on experience 100 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2957
	data_grads_norm = 4.5074
	new_data_grads_norm = 6.5240
	old_data_grads_norm = 5.7382
	sim_grads_norm_tr = -0.0212
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0955
	data_grads_norm = 4.3740
	new_data_grads_norm = 7.0604
	old_data_grads_norm = 5.4385
	sim_grads_norm_tr = -0.0281
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3574
	data_grads_norm = 5.2030
	new_data_grads_norm = 7.3018
	old_data_grads_norm = 6.5787
	sim_grads_norm_tr = 0.0666
-- Starting training on experience 101 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5663
	data_grads_norm = 5.9638
	new_data_grads_norm = 8.9680
	old_data_grads_norm = 5.4458
	sim_grads_norm_tr = -0.0110
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7783
	data_grads_norm = 7.0608
	new_data_grads_norm = 8.7479
	old_data_grads_norm = 8.2146
	sim_grads_norm_tr = 0.0079
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5744
	data_grads_norm = 6.0227
	new_data_grads_norm = 8.8877
	old_data_grads_norm = 7.3473
	sim_grads_norm_tr = -0.0029
-- Starting training on experience 102 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5812
	data_grads_norm = 5.8565
	new_data_grads_norm = 8.8853
	old_data_grads_norm = 5.8480
	sim_grads_norm_tr = -0.0169
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4383
	data_grads_norm = 4.8776
	new_data_grads_norm = 8.2302
	old_data_grads_norm = 4.9502
	sim_grads_norm_tr = -0.0153
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4964
	data_grads_norm = 5.3766
	new_data_grads_norm = 8.2332
	old_data_grads_norm = 7.3652
	sim_grads_norm_tr = 0.0336
-- Starting training on experience 103 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3817
	data_grads_norm = 4.6040
	new_data_grads_norm = 8.1439
	old_data_grads_norm = 4.1678
	sim_grads_norm_tr = 0.0547
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6715
	data_grads_norm = 5.9261
	new_data_grads_norm = 7.4082
	old_data_grads_norm = 7.9383
	sim_grads_norm_tr = 0.0315
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4352
	data_grads_norm = 6.0323
	new_data_grads_norm = 7.3685
	old_data_grads_norm = 9.1232
	sim_grads_norm_tr = -0.0186
-- Starting training on experience 104 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0589
	data_grads_norm = 4.7045
	new_data_grads_norm = 7.7801
	old_data_grads_norm = 4.2260
	sim_grads_norm_tr = -0.0012
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5394
	data_grads_norm = 4.9117
	new_data_grads_norm = 7.9563
	old_data_grads_norm = 5.9902
	sim_grads_norm_tr = -0.0282
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9545
	data_grads_norm = 5.8764
	new_data_grads_norm = 8.0303
	old_data_grads_norm = 7.6510
	sim_grads_norm_tr = 0.0224
-- Starting training on experience 105 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6636
	data_grads_norm = 6.1168
	new_data_grads_norm = 8.9277
	old_data_grads_norm = 8.6822
	sim_grads_norm_tr = 0.0204
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9077
	data_grads_norm = 5.8767
	new_data_grads_norm = 9.3710
	old_data_grads_norm = 7.5740
	sim_grads_norm_tr = 0.0326
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6175
	data_grads_norm = 6.2229
	new_data_grads_norm = 9.1719
	old_data_grads_norm = 7.6005
	sim_grads_norm_tr = 0.0206
-- Starting training on experience 106 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2570
	data_grads_norm = 5.3915
	new_data_grads_norm = 7.2929
	old_data_grads_norm = 7.4723
	sim_grads_norm_tr = -0.0295
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1939
	data_grads_norm = 5.8106
	new_data_grads_norm = 7.2391
	old_data_grads_norm = 8.2787
	sim_grads_norm_tr = -0.0017
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2454
	data_grads_norm = 4.9462
	new_data_grads_norm = 6.6770
	old_data_grads_norm = 6.1441
	sim_grads_norm_tr = 0.0076
-- Starting training on experience 107 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4555
	data_grads_norm = 5.2186
	new_data_grads_norm = 8.9197
	old_data_grads_norm = 5.5889
	sim_grads_norm_tr = -0.0165
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9036
	data_grads_norm = 6.4532
	new_data_grads_norm = 9.7086
	old_data_grads_norm = 9.6651
	sim_grads_norm_tr = -0.0098
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7712
	data_grads_norm = 5.5342
	new_data_grads_norm = 8.8553
	old_data_grads_norm = 5.1017
	sim_grads_norm_tr = 0.0233
-- Starting training on experience 108 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3066
	data_grads_norm = 5.5501
	new_data_grads_norm = 7.5300
	old_data_grads_norm = 7.7134
	sim_grads_norm_tr = -0.0052
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8446
	data_grads_norm = 5.9394
	new_data_grads_norm = 8.2262
	old_data_grads_norm = 8.2356
	sim_grads_norm_tr = 0.0096
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1453
	data_grads_norm = 4.6420
	new_data_grads_norm = 7.2133
	old_data_grads_norm = 5.6372
	sim_grads_norm_tr = -0.0253
-- Starting training on experience 109 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3993
	data_grads_norm = 5.7501
	new_data_grads_norm = 8.7995
	old_data_grads_norm = 7.3291
	sim_grads_norm_tr = -0.0095
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4273
	data_grads_norm = 5.0821
	new_data_grads_norm = 9.4107
	old_data_grads_norm = 4.7577
	sim_grads_norm_tr = -0.0074
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6767
	data_grads_norm = 5.6850
	new_data_grads_norm = 9.7310
	old_data_grads_norm = 6.7598
	sim_grads_norm_tr = -0.0032
-- Starting training on experience 110 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7888
	data_grads_norm = 5.8213
	new_data_grads_norm = 8.6739
	old_data_grads_norm = 8.9269
	sim_grads_norm_tr = -0.0279
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3959
	data_grads_norm = 5.8792
	new_data_grads_norm = 9.5945
	old_data_grads_norm = 5.4810
	sim_grads_norm_tr = -0.0250
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6527
	data_grads_norm = 5.8617
	new_data_grads_norm = 10.2668
	old_data_grads_norm = 5.7041
	sim_grads_norm_tr = -0.0057
-- Starting training on experience 111 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5301
	data_grads_norm = 5.7429
	new_data_grads_norm = 10.1231
	old_data_grads_norm = 5.3639
	sim_grads_norm_tr = -0.0051
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0118
	data_grads_norm = 6.1276
	new_data_grads_norm = 10.1051
	old_data_grads_norm = 6.8076
	sim_grads_norm_tr = 0.0184
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8095
	data_grads_norm = 6.1022
	new_data_grads_norm = 9.7521
	old_data_grads_norm = 6.4323
	sim_grads_norm_tr = -0.0081
-- Starting training on experience 112 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2635
	data_grads_norm = 4.9237
	new_data_grads_norm = 6.9426
	old_data_grads_norm = 6.7124
	sim_grads_norm_tr = 0.0336
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5036
	data_grads_norm = 5.1884
	new_data_grads_norm = 6.6957
	old_data_grads_norm = 8.0996
	sim_grads_norm_tr = -0.0176
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2464
	data_grads_norm = 5.0347
	new_data_grads_norm = 6.6706
	old_data_grads_norm = 8.2920
	sim_grads_norm_tr = -0.0172
-- Starting training on experience 113 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9725
	data_grads_norm = 6.0549
	new_data_grads_norm = 7.5934
	old_data_grads_norm = 8.2924
	sim_grads_norm_tr = 0.0747
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1531
	data_grads_norm = 4.8574
	new_data_grads_norm = 8.5391
	old_data_grads_norm = 4.6767
	sim_grads_norm_tr = 0.0253
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5895
	data_grads_norm = 5.2591
	new_data_grads_norm = 7.7206
	old_data_grads_norm = 6.4730
	sim_grads_norm_tr = 0.0394
-- Starting training on experience 114 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4430
	data_grads_norm = 5.7157
	new_data_grads_norm = 7.4275
	old_data_grads_norm = 6.3957
	sim_grads_norm_tr = -0.0222
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3504
	data_grads_norm = 5.2552
	new_data_grads_norm = 7.7628
	old_data_grads_norm = 8.8755
	sim_grads_norm_tr = 0.0069
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4189
	data_grads_norm = 6.2416
	new_data_grads_norm = 8.5129
	old_data_grads_norm = 8.0636
	sim_grads_norm_tr = 0.0879
-- Starting training on experience 115 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7966
	data_grads_norm = 6.3116
	new_data_grads_norm = 7.1408
	old_data_grads_norm = 8.2368
	sim_grads_norm_tr = -0.0057
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5942
	data_grads_norm = 5.7424
	new_data_grads_norm = 7.4039
	old_data_grads_norm = 6.5877
	sim_grads_norm_tr = 0.0576
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6785
	data_grads_norm = 6.6606
	new_data_grads_norm = 8.7965
	old_data_grads_norm = 6.8349
	sim_grads_norm_tr = 0.0149
-- Starting training on experience 116 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9652
	data_grads_norm = 4.6583
	new_data_grads_norm = 7.4498
	old_data_grads_norm = 5.9752
	sim_grads_norm_tr = -0.0341
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8269
	data_grads_norm = 6.5427
	new_data_grads_norm = 8.9461
	old_data_grads_norm = 9.6409
	sim_grads_norm_tr = 0.0321
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6225
	data_grads_norm = 5.7355
	new_data_grads_norm = 8.4249
	old_data_grads_norm = 7.8921
	sim_grads_norm_tr = 0.0006
-- Starting training on experience 117 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2471
	data_grads_norm = 6.1412
	new_data_grads_norm = 10.0288
	old_data_grads_norm = 8.0205
	sim_grads_norm_tr = -0.0300
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2687
	data_grads_norm = 5.4351
	new_data_grads_norm = 10.2615
	old_data_grads_norm = 5.6783
	sim_grads_norm_tr = -0.0240
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3572
	data_grads_norm = 5.4981
	new_data_grads_norm = 9.7464
	old_data_grads_norm = 5.7750
	sim_grads_norm_tr = 0.0068
-- Starting training on experience 118 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4145
	data_grads_norm = 5.4165
	new_data_grads_norm = 7.2426
	old_data_grads_norm = 7.8420
	sim_grads_norm_tr = -0.0388
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3153
	data_grads_norm = 5.0091
	new_data_grads_norm = 7.9609
	old_data_grads_norm = 5.8785
	sim_grads_norm_tr = 0.0115
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9165
	data_grads_norm = 4.0290
	new_data_grads_norm = 6.9241
	old_data_grads_norm = 4.4132
	sim_grads_norm_tr = 0.0344
-- Starting training on experience 119 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4547
	data_grads_norm = 6.8087
	new_data_grads_norm = 9.5521
	old_data_grads_norm = 8.4057
	sim_grads_norm_tr = -0.0148
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7240
	data_grads_norm = 6.1067
	new_data_grads_norm = 9.6371
	old_data_grads_norm = 7.9321
	sim_grads_norm_tr = 0.0601
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3091
	data_grads_norm = 5.5124
	new_data_grads_norm = 8.6840
	old_data_grads_norm = 6.4139
	sim_grads_norm_tr = 0.0140
-- Starting training on experience 120 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4424
	data_grads_norm = 5.9961
	new_data_grads_norm = 8.4924
	old_data_grads_norm = 8.1027
	sim_grads_norm_tr = -0.0252
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3201
	data_grads_norm = 5.5563
	new_data_grads_norm = 7.7603
	old_data_grads_norm = 7.1337
	sim_grads_norm_tr = -0.0216
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3637
	data_grads_norm = 5.2644
	new_data_grads_norm = 7.7985
	old_data_grads_norm = 6.9704
	sim_grads_norm_tr = 0.0262
-- Starting training on experience 121 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5046
	data_grads_norm = 5.9304
	new_data_grads_norm = 8.4077
	old_data_grads_norm = 7.4798
	sim_grads_norm_tr = 0.0337
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3347
	data_grads_norm = 6.3350
	new_data_grads_norm = 9.0984
	old_data_grads_norm = 6.9592
	sim_grads_norm_tr = -0.0196
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3232
	data_grads_norm = 5.3828
	new_data_grads_norm = 8.0877
	old_data_grads_norm = 6.6027
	sim_grads_norm_tr = -0.0256
-- Starting training on experience 122 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1414
	data_grads_norm = 4.9754
	new_data_grads_norm = 8.8490
	old_data_grads_norm = 4.4029
	sim_grads_norm_tr = -0.0168
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3675
	data_grads_norm = 5.9396
	new_data_grads_norm = 8.9985
	old_data_grads_norm = 7.7341
	sim_grads_norm_tr = -0.0291
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3711
	data_grads_norm = 5.8020
	new_data_grads_norm = 9.0043
	old_data_grads_norm = 6.3240
	sim_grads_norm_tr = -0.0001
-- Starting training on experience 123 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9655
	data_grads_norm = 5.1614
	new_data_grads_norm = 8.4609
	old_data_grads_norm = 5.9167
	sim_grads_norm_tr = 0.0058
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2413
	data_grads_norm = 5.2838
	new_data_grads_norm = 8.7931
	old_data_grads_norm = 6.1499
	sim_grads_norm_tr = -0.0372
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9223
	data_grads_norm = 6.2939
	new_data_grads_norm = 8.4457
	old_data_grads_norm = 6.8739
	sim_grads_norm_tr = 0.0747
-- Starting training on experience 124 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2333
	data_grads_norm = 5.2114
	new_data_grads_norm = 9.5469
	old_data_grads_norm = 4.6717
	sim_grads_norm_tr = -0.0309
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1722
	data_grads_norm = 4.9497
	new_data_grads_norm = 8.2063
	old_data_grads_norm = 5.1641
	sim_grads_norm_tr = -0.0106
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7353
	data_grads_norm = 5.9240
	new_data_grads_norm = 9.1414
	old_data_grads_norm = 7.5179
	sim_grads_norm_tr = 0.0102
-- Starting training on experience 125 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9157
	data_grads_norm = 5.4652
	new_data_grads_norm = 8.7731
	old_data_grads_norm = 6.7224
	sim_grads_norm_tr = -0.0011
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8614
	data_grads_norm = 4.8823
	new_data_grads_norm = 9.2134
	old_data_grads_norm = 4.8821
	sim_grads_norm_tr = -0.0236
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5030
	data_grads_norm = 6.0750
	new_data_grads_norm = 8.3733
	old_data_grads_norm = 8.2128
	sim_grads_norm_tr = 0.0793
-- Starting training on experience 126 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6388
	data_grads_norm = 5.3088
	new_data_grads_norm = 7.6833
	old_data_grads_norm = 7.5621
	sim_grads_norm_tr = 0.0068
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4048
	data_grads_norm = 5.1588
	new_data_grads_norm = 8.4762
	old_data_grads_norm = 5.5943
	sim_grads_norm_tr = -0.0594
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2698
	data_grads_norm = 4.8086
	new_data_grads_norm = 7.0509
	old_data_grads_norm = 6.2404
	sim_grads_norm_tr = -0.0140
-- Starting training on experience 127 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1171
	data_grads_norm = 5.2340
	new_data_grads_norm = 7.4821
	old_data_grads_norm = 6.8465
	sim_grads_norm_tr = -0.0008
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2481
	data_grads_norm = 6.0610
	new_data_grads_norm = 9.3326
	old_data_grads_norm = 6.9727
	sim_grads_norm_tr = -0.0205
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0767
	data_grads_norm = 4.6286
	new_data_grads_norm = 7.2407
	old_data_grads_norm = 5.0307
	sim_grads_norm_tr = -0.0064
-- Starting training on experience 128 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7040
	data_grads_norm = 5.9400
	new_data_grads_norm = 8.7564
	old_data_grads_norm = 7.3192
	sim_grads_norm_tr = -0.0099
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0737
	data_grads_norm = 5.7708
	new_data_grads_norm = 8.5457
	old_data_grads_norm = 6.9655
	sim_grads_norm_tr = -0.0304
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1061
	data_grads_norm = 5.7513
	new_data_grads_norm = 9.2624
	old_data_grads_norm = 5.3662
	sim_grads_norm_tr = 0.0125
-- Starting training on experience 129 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4382
	data_grads_norm = 5.4704
	new_data_grads_norm = 8.1931
	old_data_grads_norm = 6.9984
	sim_grads_norm_tr = 0.0103
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3266
	data_grads_norm = 4.9265
	new_data_grads_norm = 7.3971
	old_data_grads_norm = 5.5407
	sim_grads_norm_tr = 0.0340
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0406
	data_grads_norm = 4.4747
	new_data_grads_norm = 8.5876
	old_data_grads_norm = 5.1815
	sim_grads_norm_tr = -0.0490
-- Starting training on experience 130 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4180
	data_grads_norm = 5.5620
	new_data_grads_norm = 7.8693
	old_data_grads_norm = 6.1727
	sim_grads_norm_tr = 0.0507
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6068
	data_grads_norm = 6.0555
	new_data_grads_norm = 9.0807
	old_data_grads_norm = 7.5299
	sim_grads_norm_tr = 0.0946
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0181
	data_grads_norm = 5.1884
	new_data_grads_norm = 7.6223
	old_data_grads_norm = 5.8483
	sim_grads_norm_tr = 0.0383
-- Starting training on experience 131 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8539
	data_grads_norm = 4.9022
	new_data_grads_norm = 6.8470
	old_data_grads_norm = 6.5127
	sim_grads_norm_tr = -0.0181
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9177
	data_grads_norm = 5.1420
	new_data_grads_norm = 7.4486
	old_data_grads_norm = 5.8492
	sim_grads_norm_tr = 0.0195
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5912
	data_grads_norm = 4.7238
	new_data_grads_norm = 7.6641
	old_data_grads_norm = 6.2988
	sim_grads_norm_tr = 0.0091
-- Starting training on experience 132 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4907
	data_grads_norm = 5.6891
	new_data_grads_norm = 6.8159
	old_data_grads_norm = 8.2142
	sim_grads_norm_tr = 0.0031
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9633
	data_grads_norm = 4.8701
	new_data_grads_norm = 6.1940
	old_data_grads_norm = 7.5271
	sim_grads_norm_tr = -0.0176
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1775
	data_grads_norm = 5.0458
	new_data_grads_norm = 7.8917
	old_data_grads_norm = 6.5416
	sim_grads_norm_tr = -0.0085
-- Starting training on experience 133 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8926
	data_grads_norm = 4.6638
	new_data_grads_norm = 7.7094
	old_data_grads_norm = 6.6487
	sim_grads_norm_tr = -0.0104
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0615
	data_grads_norm = 4.6821
	new_data_grads_norm = 7.8815
	old_data_grads_norm = 6.1671
	sim_grads_norm_tr = 0.0440
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4199
	data_grads_norm = 6.1810
	new_data_grads_norm = 8.5477
	old_data_grads_norm = 7.3395
	sim_grads_norm_tr = 0.0266
-- Starting training on experience 134 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7297
	data_grads_norm = 5.2254
	new_data_grads_norm = 8.6700
	old_data_grads_norm = 5.8740
	sim_grads_norm_tr = -0.0100
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1921
	data_grads_norm = 4.5857
	new_data_grads_norm = 8.6229
	old_data_grads_norm = 4.8646
	sim_grads_norm_tr = 0.0032
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6806
	data_grads_norm = 5.6326
	new_data_grads_norm = 8.4319
	old_data_grads_norm = 5.7672
	sim_grads_norm_tr = 0.0315
-- Starting training on experience 135 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3167
	data_grads_norm = 5.5535
	new_data_grads_norm = 8.4588
	old_data_grads_norm = 6.4839
	sim_grads_norm_tr = 0.0043
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9004
	data_grads_norm = 4.4861
	new_data_grads_norm = 7.6860
	old_data_grads_norm = 6.3291
	sim_grads_norm_tr = 0.0134
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2655
	data_grads_norm = 4.9845
	new_data_grads_norm = 7.7829
	old_data_grads_norm = 6.6613
	sim_grads_norm_tr = -0.0260
-- Starting training on experience 136 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0106
	data_grads_norm = 4.7745
	new_data_grads_norm = 6.8993
	old_data_grads_norm = 5.8664
	sim_grads_norm_tr = 0.0440
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4695
	data_grads_norm = 3.9833
	new_data_grads_norm = 7.2767
	old_data_grads_norm = 7.8457
	sim_grads_norm_tr = 0.0364
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7430
	data_grads_norm = 4.8330
	new_data_grads_norm = 7.0360
	old_data_grads_norm = 6.3802
	sim_grads_norm_tr = -0.0133
-- Starting training on experience 137 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5338
	data_grads_norm = 5.9502
	new_data_grads_norm = 9.5970
	old_data_grads_norm = 7.6981
	sim_grads_norm_tr = 0.0063
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4576
	data_grads_norm = 5.4579
	new_data_grads_norm = 9.7054
	old_data_grads_norm = 4.0880
	sim_grads_norm_tr = -0.0163
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4682
	data_grads_norm = 4.9260
	new_data_grads_norm = 8.8174
	old_data_grads_norm = 5.4092
	sim_grads_norm_tr = -0.0152
-- Starting training on experience 138 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4434
	data_grads_norm = 4.8263
	new_data_grads_norm = 8.3670
	old_data_grads_norm = 5.2989
	sim_grads_norm_tr = -0.0135
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4296
	data_grads_norm = 5.3135
	new_data_grads_norm = 8.8929
	old_data_grads_norm = 5.8744
	sim_grads_norm_tr = -0.0102
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2431
	data_grads_norm = 5.0872
	new_data_grads_norm = 9.0095
	old_data_grads_norm = 5.7174
	sim_grads_norm_tr = -0.0247
-- Starting training on experience 139 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0560
	data_grads_norm = 6.6472
	new_data_grads_norm = 9.1894
	old_data_grads_norm = 7.9534
	sim_grads_norm_tr = 0.0049
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6371
	data_grads_norm = 5.8764
	new_data_grads_norm = 9.9178
	old_data_grads_norm = 7.5349
	sim_grads_norm_tr = -0.0368
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3842
	data_grads_norm = 5.9404
	new_data_grads_norm = 9.2755
	old_data_grads_norm = 6.8599
	sim_grads_norm_tr = 0.1220
-- Starting training on experience 140 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8803
	data_grads_norm = 4.8538
	new_data_grads_norm = 8.4032
	old_data_grads_norm = 7.6026
	sim_grads_norm_tr = -0.0369
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3071
	data_grads_norm = 5.2580
	new_data_grads_norm = 8.4204
	old_data_grads_norm = 5.2430
	sim_grads_norm_tr = 0.0521
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9515
	data_grads_norm = 5.0329
	new_data_grads_norm = 8.0000
	old_data_grads_norm = 7.7957
	sim_grads_norm_tr = -0.0279
-- Starting training on experience 141 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2678
	data_grads_norm = 5.5722
	new_data_grads_norm = 8.0708
	old_data_grads_norm = 7.4576
	sim_grads_norm_tr = -0.0249
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3658
	data_grads_norm = 5.1176
	new_data_grads_norm = 7.9959
	old_data_grads_norm = 5.7781
	sim_grads_norm_tr = 0.0281
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1384
	data_grads_norm = 4.8731
	new_data_grads_norm = 8.3026
	old_data_grads_norm = 3.9866
	sim_grads_norm_tr = 0.0407
-- Starting training on experience 142 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1322
	data_grads_norm = 5.0975
	new_data_grads_norm = 8.0306
	old_data_grads_norm = 6.9072
	sim_grads_norm_tr = -0.0270
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0588
	data_grads_norm = 6.6268
	new_data_grads_norm = 8.2047
	old_data_grads_norm = 10.2474
	sim_grads_norm_tr = 0.0140
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4306
	data_grads_norm = 7.0159
	new_data_grads_norm = 9.6181
	old_data_grads_norm = 11.2693
	sim_grads_norm_tr = 0.0434
-- Starting training on experience 143 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6529
	data_grads_norm = 5.6400
	new_data_grads_norm = 8.8103
	old_data_grads_norm = 8.4043
	sim_grads_norm_tr = -0.0079
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1325
	data_grads_norm = 5.9997
	new_data_grads_norm = 8.0560
	old_data_grads_norm = 8.3746
	sim_grads_norm_tr = 0.0116
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9677
	data_grads_norm = 5.9585
	new_data_grads_norm = 9.1400
	old_data_grads_norm = 7.2420
	sim_grads_norm_tr = -0.0419
-- Starting training on experience 144 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4766
	data_grads_norm = 4.9489
	new_data_grads_norm = 7.9193
	old_data_grads_norm = 6.4550
	sim_grads_norm_tr = -0.0200
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2715
	data_grads_norm = 5.2640
	new_data_grads_norm = 7.5020
	old_data_grads_norm = 7.1744
	sim_grads_norm_tr = -0.0328
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1183
	data_grads_norm = 4.6724
	new_data_grads_norm = 7.9429
	old_data_grads_norm = 4.3703
	sim_grads_norm_tr = -0.0071
-- Starting training on experience 145 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3265
	data_grads_norm = 4.7584
	new_data_grads_norm = 8.4032
	old_data_grads_norm = 6.1533
	sim_grads_norm_tr = -0.0330
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9531
	data_grads_norm = 6.5662
	new_data_grads_norm = 8.0615
	old_data_grads_norm = 9.6570
	sim_grads_norm_tr = 0.0559
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8430
	data_grads_norm = 4.7006
	new_data_grads_norm = 8.1587
	old_data_grads_norm = 7.1732
	sim_grads_norm_tr = -0.0160
-- Starting training on experience 146 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7608
	data_grads_norm = 6.8107
	new_data_grads_norm = 8.5029
	old_data_grads_norm = 8.4928
	sim_grads_norm_tr = 0.0178
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7963
	data_grads_norm = 5.6637
	new_data_grads_norm = 9.7065
	old_data_grads_norm = 5.5454
	sim_grads_norm_tr = 0.0318
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1530
	data_grads_norm = 5.8565
	new_data_grads_norm = 8.8671
	old_data_grads_norm = 8.8306
	sim_grads_norm_tr = 0.0103
-- Starting training on experience 147 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9478
	data_grads_norm = 5.0332
	new_data_grads_norm = 8.5160
	old_data_grads_norm = 6.8150
	sim_grads_norm_tr = 0.0016
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8108
	data_grads_norm = 5.3159
	new_data_grads_norm = 7.6909
	old_data_grads_norm = 6.9837
	sim_grads_norm_tr = -0.0223
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8025
	data_grads_norm = 4.8158
	new_data_grads_norm = 9.2116
	old_data_grads_norm = 4.0628
	sim_grads_norm_tr = -0.0150
-- Starting training on experience 148 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2133
	data_grads_norm = 5.6762
	new_data_grads_norm = 9.7276
	old_data_grads_norm = 6.1112
	sim_grads_norm_tr = 0.0097
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8827
	data_grads_norm = 6.6627
	new_data_grads_norm = 10.1174
	old_data_grads_norm = 5.8670
	sim_grads_norm_tr = -0.0137
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7172
	data_grads_norm = 7.2852
	new_data_grads_norm = 11.4305
	old_data_grads_norm = 9.3262
	sim_grads_norm_tr = 0.0265
-- Starting training on experience 149 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0855
	data_grads_norm = 5.4162
	new_data_grads_norm = 9.2394
	old_data_grads_norm = 6.1222
	sim_grads_norm_tr = -0.0015
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2539
	data_grads_norm = 5.2244
	new_data_grads_norm = 7.6377
	old_data_grads_norm = 7.6252
	sim_grads_norm_tr = -0.0061
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1525
	data_grads_norm = 4.8061
	new_data_grads_norm = 7.4793
	old_data_grads_norm = 6.3381
	sim_grads_norm_tr = 0.0172
-- Starting training on experience 150 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6379
	data_grads_norm = 5.3656
	new_data_grads_norm = 7.3843
	old_data_grads_norm = 7.1242
	sim_grads_norm_tr = -0.0031
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3290
	data_grads_norm = 4.7390
	new_data_grads_norm = 8.6835
	old_data_grads_norm = 5.1794
	sim_grads_norm_tr = 0.0021
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5552
	data_grads_norm = 5.1329
	new_data_grads_norm = 8.0968
	old_data_grads_norm = 6.9790
	sim_grads_norm_tr = 0.0228
-- Starting training on experience 151 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2668
	data_grads_norm = 5.4640
	new_data_grads_norm = 7.3272
	old_data_grads_norm = 9.4655
	sim_grads_norm_tr = -0.0025
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6175
	data_grads_norm = 5.9549
	new_data_grads_norm = 8.0612
	old_data_grads_norm = 8.2442
	sim_grads_norm_tr = -0.0079
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2481
	data_grads_norm = 5.1083
	new_data_grads_norm = 7.1567
	old_data_grads_norm = 7.4945
	sim_grads_norm_tr = 0.0027
-- Starting training on experience 152 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9393
	data_grads_norm = 4.1957
	new_data_grads_norm = 7.4457
	old_data_grads_norm = 4.2102
	sim_grads_norm_tr = 0.0179
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3786
	data_grads_norm = 5.0133
	new_data_grads_norm = 7.1298
	old_data_grads_norm = 6.8900
	sim_grads_norm_tr = 0.0177
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1899
	data_grads_norm = 4.8266
	new_data_grads_norm = 6.7054
	old_data_grads_norm = 6.7994
	sim_grads_norm_tr = 0.0013
-- Starting training on experience 153 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7828
	data_grads_norm = 5.8494
	new_data_grads_norm = 8.3512
	old_data_grads_norm = 7.8410
	sim_grads_norm_tr = -0.0271
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5236
	data_grads_norm = 4.9559
	new_data_grads_norm = 8.6635
	old_data_grads_norm = 4.6380
	sim_grads_norm_tr = 0.0015
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6409
	data_grads_norm = 5.6562
	new_data_grads_norm = 8.2968
	old_data_grads_norm = 7.8541
	sim_grads_norm_tr = -0.0296
-- Starting training on experience 154 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4387
	data_grads_norm = 5.7237
	new_data_grads_norm = 7.7893
	old_data_grads_norm = 7.0067
	sim_grads_norm_tr = 0.0637
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2535
	data_grads_norm = 4.8974
	new_data_grads_norm = 7.6086
	old_data_grads_norm = 5.7050
	sim_grads_norm_tr = -0.0225
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5861
	data_grads_norm = 5.6963
	new_data_grads_norm = 9.2462
	old_data_grads_norm = 5.4593
	sim_grads_norm_tr = 0.0150
-- Starting training on experience 155 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5538
	data_grads_norm = 6.3832
	new_data_grads_norm = 8.2242
	old_data_grads_norm = 9.9005
	sim_grads_norm_tr = -0.0140
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3321
	data_grads_norm = 5.8930
	new_data_grads_norm = 9.1327
	old_data_grads_norm = 6.5322
	sim_grads_norm_tr = 0.0048
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7045
	data_grads_norm = 5.9869
	new_data_grads_norm = 8.8112
	old_data_grads_norm = 8.2940
	sim_grads_norm_tr = 0.0180
-- Starting training on experience 156 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1097
	data_grads_norm = 6.7109
	new_data_grads_norm = 9.7500
	old_data_grads_norm = 7.9495
	sim_grads_norm_tr = 0.0275
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4462
	data_grads_norm = 5.7780
	new_data_grads_norm = 10.0442
	old_data_grads_norm = 5.7741
	sim_grads_norm_tr = -0.0306
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4794
	data_grads_norm = 5.5751
	new_data_grads_norm = 9.3246
	old_data_grads_norm = 6.4433
	sim_grads_norm_tr = 0.0547
-- Starting training on experience 157 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9756
	data_grads_norm = 6.2370
	new_data_grads_norm = 8.0850
	old_data_grads_norm = 7.6824
	sim_grads_norm_tr = 0.0612
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8505
	data_grads_norm = 6.1924
	new_data_grads_norm = 8.1237
	old_data_grads_norm = 7.4722
	sim_grads_norm_tr = 0.0113
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7147
	data_grads_norm = 6.2161
	new_data_grads_norm = 9.0980
	old_data_grads_norm = 6.8602
	sim_grads_norm_tr = 0.0127
-- Starting training on experience 158 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7036
	data_grads_norm = 5.7982
	new_data_grads_norm = 8.0554
	old_data_grads_norm = 8.0095
	sim_grads_norm_tr = 0.0495
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2513
	data_grads_norm = 5.4750
	new_data_grads_norm = 8.3414
	old_data_grads_norm = 6.3744
	sim_grads_norm_tr = 0.1007
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6395
	data_grads_norm = 6.3412
	new_data_grads_norm = 8.2253
	old_data_grads_norm = 9.1992
	sim_grads_norm_tr = 0.0040
-- Starting training on experience 159 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4631
	data_grads_norm = 4.4570
	new_data_grads_norm = 7.8694
	old_data_grads_norm = 5.8303
	sim_grads_norm_tr = -0.0039
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9052
	data_grads_norm = 5.8376
	new_data_grads_norm = 8.5665
	old_data_grads_norm = 7.9176
	sim_grads_norm_tr = -0.0058
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4581
	data_grads_norm = 6.0685
	new_data_grads_norm = 9.3743
	old_data_grads_norm = 6.8633
	sim_grads_norm_tr = 0.0388
-- Starting training on experience 160 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6525
	data_grads_norm = 5.3046
	new_data_grads_norm = 8.5400
	old_data_grads_norm = 5.9544
	sim_grads_norm_tr = -0.0325
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5636
	data_grads_norm = 6.4603
	new_data_grads_norm = 9.8657
	old_data_grads_norm = 10.2299
	sim_grads_norm_tr = -0.0175
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9825
	data_grads_norm = 5.7188
	new_data_grads_norm = 9.1624
	old_data_grads_norm = 7.9389
	sim_grads_norm_tr = -0.0065
-- Starting training on experience 161 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7903
	data_grads_norm = 6.2895
	new_data_grads_norm = 7.9236
	old_data_grads_norm = 9.2354
	sim_grads_norm_tr = 0.0014
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9835
	data_grads_norm = 6.5000
	new_data_grads_norm = 8.0829
	old_data_grads_norm = 8.0842
	sim_grads_norm_tr = 0.0161
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2131
	data_grads_norm = 5.0095
	new_data_grads_norm = 8.2634
	old_data_grads_norm = 5.6687
	sim_grads_norm_tr = -0.0157
-- Starting training on experience 162 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0106
	data_grads_norm = 6.3929
	new_data_grads_norm = 9.5258
	old_data_grads_norm = 8.3750
	sim_grads_norm_tr = 0.0190
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1803
	data_grads_norm = 7.3823
	new_data_grads_norm = 10.5621
	old_data_grads_norm = 8.4227
	sim_grads_norm_tr = 0.0071
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2219
	data_grads_norm = 4.9587
	new_data_grads_norm = 8.7808
	old_data_grads_norm = 3.9665
	sim_grads_norm_tr = -0.0215
-- Starting training on experience 163 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8940
	data_grads_norm = 4.7098
	new_data_grads_norm = 6.7153
	old_data_grads_norm = 6.2417
	sim_grads_norm_tr = -0.0032
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0038
	data_grads_norm = 5.4083
	new_data_grads_norm = 7.8820
	old_data_grads_norm = 6.2829
	sim_grads_norm_tr = 0.0560
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9441
	data_grads_norm = 5.0712
	new_data_grads_norm = 7.1707
	old_data_grads_norm = 7.0593
	sim_grads_norm_tr = -0.0010
-- Starting training on experience 164 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9544
	data_grads_norm = 4.7604
	new_data_grads_norm = 8.5524
	old_data_grads_norm = 4.0655
	sim_grads_norm_tr = -0.0343
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2656
	data_grads_norm = 5.4560
	new_data_grads_norm = 7.7118
	old_data_grads_norm = 9.2836
	sim_grads_norm_tr = 0.0271
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0605
	data_grads_norm = 4.8251
	new_data_grads_norm = 8.6044
	old_data_grads_norm = 7.0585
	sim_grads_norm_tr = -0.0259
-- Starting training on experience 165 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7713
	data_grads_norm = 6.8705
	new_data_grads_norm = 8.9882
	old_data_grads_norm = 7.2689
	sim_grads_norm_tr = 0.0241
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3229
	data_grads_norm = 6.1552
	new_data_grads_norm = 8.6407
	old_data_grads_norm = 6.2811
	sim_grads_norm_tr = 0.0955
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4991
	data_grads_norm = 7.0885
	new_data_grads_norm = 8.9977
	old_data_grads_norm = 8.9221
	sim_grads_norm_tr = 0.0040
-- Starting training on experience 166 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3842
	data_grads_norm = 5.9331
	new_data_grads_norm = 7.8608
	old_data_grads_norm = 8.7770
	sim_grads_norm_tr = 0.0420
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5790
	data_grads_norm = 5.8628
	new_data_grads_norm = 8.8447
	old_data_grads_norm = 7.4861
	sim_grads_norm_tr = 0.0131
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2008
	data_grads_norm = 5.3552
	new_data_grads_norm = 8.6873
	old_data_grads_norm = 5.9949
	sim_grads_norm_tr = -0.0216
-- Starting training on experience 167 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5314
	data_grads_norm = 5.8944
	new_data_grads_norm = 7.5444
	old_data_grads_norm = 8.3634
	sim_grads_norm_tr = -0.0362
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5833
	data_grads_norm = 5.9880
	new_data_grads_norm = 7.9986
	old_data_grads_norm = 7.9771
	sim_grads_norm_tr = 0.0673
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5655
	data_grads_norm = 5.2716
	new_data_grads_norm = 7.1281
	old_data_grads_norm = 8.5363
	sim_grads_norm_tr = -0.0138
-- Starting training on experience 168 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3049
	data_grads_norm = 6.0758
	new_data_grads_norm = 9.4514
	old_data_grads_norm = 7.9343
	sim_grads_norm_tr = -0.0027
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4043
	data_grads_norm = 6.6984
	new_data_grads_norm = 8.7314
	old_data_grads_norm = 7.6600
	sim_grads_norm_tr = -0.0366
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0603
	data_grads_norm = 5.4822
	new_data_grads_norm = 7.8561
	old_data_grads_norm = 5.6822
	sim_grads_norm_tr = -0.0088
-- Starting training on experience 169 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0796
	data_grads_norm = 4.6351
	new_data_grads_norm = 7.5590
	old_data_grads_norm = 5.2768
	sim_grads_norm_tr = 0.0382
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2088
	data_grads_norm = 4.9991
	new_data_grads_norm = 7.4858
	old_data_grads_norm = 5.4887
	sim_grads_norm_tr = 0.0581
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9618
	data_grads_norm = 4.9960
	new_data_grads_norm = 7.1160
	old_data_grads_norm = 7.0835
	sim_grads_norm_tr = -0.0094
-- Starting training on experience 170 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3408
	data_grads_norm = 5.2579
	new_data_grads_norm = 7.6813
	old_data_grads_norm = 6.1995
	sim_grads_norm_tr = 0.0775
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0755
	data_grads_norm = 5.6440
	new_data_grads_norm = 9.3555
	old_data_grads_norm = 7.2078
	sim_grads_norm_tr = -0.0053
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9387
	data_grads_norm = 5.6560
	new_data_grads_norm = 7.7437
	old_data_grads_norm = 6.6422
	sim_grads_norm_tr = 0.0075
-- Starting training on experience 171 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4153
	data_grads_norm = 5.5965
	new_data_grads_norm = 8.0227
	old_data_grads_norm = 6.8090
	sim_grads_norm_tr = -0.0283
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5389
	data_grads_norm = 5.7290
	new_data_grads_norm = 8.0201
	old_data_grads_norm = 8.4040
	sim_grads_norm_tr = 0.0272
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0534
	data_grads_norm = 4.5591
	new_data_grads_norm = 7.7063
	old_data_grads_norm = 5.4585
	sim_grads_norm_tr = 0.0364
-- Starting training on experience 172 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4150
	data_grads_norm = 5.3687
	new_data_grads_norm = 8.3305
	old_data_grads_norm = 5.1762
	sim_grads_norm_tr = 0.0414
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8292
	data_grads_norm = 6.5858
	new_data_grads_norm = 7.3689
	old_data_grads_norm = 9.3351
	sim_grads_norm_tr = 0.0173
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6168
	data_grads_norm = 6.3483
	new_data_grads_norm = 7.2227
	old_data_grads_norm = 9.9034
	sim_grads_norm_tr = 0.0650
-- Starting training on experience 173 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6350
	data_grads_norm = 6.2811
	new_data_grads_norm = 8.6923
	old_data_grads_norm = 8.2187
	sim_grads_norm_tr = -0.0061
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0665
	data_grads_norm = 5.6776
	new_data_grads_norm = 8.9112
	old_data_grads_norm = 5.5850
	sim_grads_norm_tr = -0.0312
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0846
	data_grads_norm = 5.9554
	new_data_grads_norm = 9.4281
	old_data_grads_norm = 6.8446
	sim_grads_norm_tr = 0.0100
-- Starting training on experience 174 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7147
	data_grads_norm = 6.1937
	new_data_grads_norm = 9.3494
	old_data_grads_norm = 6.5945
	sim_grads_norm_tr = 0.0113
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1503
	data_grads_norm = 6.1402
	new_data_grads_norm = 10.3284
	old_data_grads_norm = 6.8232
	sim_grads_norm_tr = 0.0017
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4662
	data_grads_norm = 5.3284
	new_data_grads_norm = 8.1584
	old_data_grads_norm = 5.9270
	sim_grads_norm_tr = 0.1000
-- Starting training on experience 175 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5506
	data_grads_norm = 5.8476
	new_data_grads_norm = 8.3956
	old_data_grads_norm = 8.1614
	sim_grads_norm_tr = -0.0286
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3119
	data_grads_norm = 5.2969
	new_data_grads_norm = 9.3537
	old_data_grads_norm = 6.1423
	sim_grads_norm_tr = -0.0356
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1518
	data_grads_norm = 5.7024
	new_data_grads_norm = 8.2194
	old_data_grads_norm = 7.5059
	sim_grads_norm_tr = -0.0118
-- Starting training on experience 176 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0437
	data_grads_norm = 4.6145
	new_data_grads_norm = 7.8528
	old_data_grads_norm = 6.0863
	sim_grads_norm_tr = -0.0278
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6210
	data_grads_norm = 6.1330
	new_data_grads_norm = 8.7812
	old_data_grads_norm = 7.3747
	sim_grads_norm_tr = 0.1098
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3476
	data_grads_norm = 5.6464
	new_data_grads_norm = 8.7562
	old_data_grads_norm = 7.1873
	sim_grads_norm_tr = -0.0064
-- Starting training on experience 177 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8387
	data_grads_norm = 5.4052
	new_data_grads_norm = 9.3131
	old_data_grads_norm = 5.4323
	sim_grads_norm_tr = 0.0197
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5035
	data_grads_norm = 6.2525
	new_data_grads_norm = 9.1437
	old_data_grads_norm = 8.7646
	sim_grads_norm_tr = -0.0129
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8796
	data_grads_norm = 4.9094
	new_data_grads_norm = 8.3194
	old_data_grads_norm = 6.2137
	sim_grads_norm_tr = -0.0213
-- Starting training on experience 178 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1050
	data_grads_norm = 5.6675
	new_data_grads_norm = 10.6949
	old_data_grads_norm = 3.9850
	sim_grads_norm_tr = -0.0352
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2650
	data_grads_norm = 5.6575
	new_data_grads_norm = 9.3456
	old_data_grads_norm = 6.6090
	sim_grads_norm_tr = 0.0037
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2532
	data_grads_norm = 6.5436
	new_data_grads_norm = 10.1807
	old_data_grads_norm = 4.9074
	sim_grads_norm_tr = 0.1191
-- Starting training on experience 179 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2381
	data_grads_norm = 5.7385
	new_data_grads_norm = 8.8680
	old_data_grads_norm = 8.1093
	sim_grads_norm_tr = -0.0153
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1821
	data_grads_norm = 5.4750
	new_data_grads_norm = 8.1917
	old_data_grads_norm = 8.6545
	sim_grads_norm_tr = 0.0302
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2485
	data_grads_norm = 5.2154
	new_data_grads_norm = 7.0246
	old_data_grads_norm = 5.1249
	sim_grads_norm_tr = 0.2476
-- Starting training on experience 180 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8289
	data_grads_norm = 5.2275
	new_data_grads_norm = 8.3901
	old_data_grads_norm = 5.6136
	sim_grads_norm_tr = 0.0268
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7368
	data_grads_norm = 5.2152
	new_data_grads_norm = 6.9582
	old_data_grads_norm = 8.8120
	sim_grads_norm_tr = 0.0438
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9647
	data_grads_norm = 5.7736
	new_data_grads_norm = 8.1515
	old_data_grads_norm = 7.7597
	sim_grads_norm_tr = 0.0873
-- Starting training on experience 181 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2265
	data_grads_norm = 5.9257
	new_data_grads_norm = 7.9736
	old_data_grads_norm = 9.4169
	sim_grads_norm_tr = 0.0101
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8268
	data_grads_norm = 5.1715
	new_data_grads_norm = 7.5809
	old_data_grads_norm = 5.6401
	sim_grads_norm_tr = -0.0431
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9512
	data_grads_norm = 5.2923
	new_data_grads_norm = 7.8748
	old_data_grads_norm = 8.2397
	sim_grads_norm_tr = -0.0004
-- Starting training on experience 182 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3163
	data_grads_norm = 6.1768
	new_data_grads_norm = 10.0088
	old_data_grads_norm = 8.9469
	sim_grads_norm_tr = 0.0380
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1628
	data_grads_norm = 5.9302
	new_data_grads_norm = 10.0869
	old_data_grads_norm = 5.3894
	sim_grads_norm_tr = 0.0186
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1916
	data_grads_norm = 6.2532
	new_data_grads_norm = 10.1992
	old_data_grads_norm = 8.1216
	sim_grads_norm_tr = -0.0075
-- Starting training on experience 183 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9381
	data_grads_norm = 5.8824
	new_data_grads_norm = 8.3193
	old_data_grads_norm = 6.8606
	sim_grads_norm_tr = 0.0074
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1419
	data_grads_norm = 5.7110
	new_data_grads_norm = 8.1940
	old_data_grads_norm = 7.5825
	sim_grads_norm_tr = 0.0251
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0125
	data_grads_norm = 5.3638
	new_data_grads_norm = 8.1320
	old_data_grads_norm = 8.3447
	sim_grads_norm_tr = -0.0009
-- Starting training on experience 184 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2560
	data_grads_norm = 5.4881
	new_data_grads_norm = 8.0592
	old_data_grads_norm = 5.1617
	sim_grads_norm_tr = -0.0200
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4926
	data_grads_norm = 5.7642
	new_data_grads_norm = 8.5785
	old_data_grads_norm = 7.8898
	sim_grads_norm_tr = 0.0163
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9302
	data_grads_norm = 4.6522
	new_data_grads_norm = 8.7393
	old_data_grads_norm = 4.4896
	sim_grads_norm_tr = 0.0180
-- Starting training on experience 185 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2708
	data_grads_norm = 5.5469
	new_data_grads_norm = 7.7958
	old_data_grads_norm = 7.1183
	sim_grads_norm_tr = -0.0051
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1072
	data_grads_norm = 5.1684
	new_data_grads_norm = 8.7954
	old_data_grads_norm = 6.0973
	sim_grads_norm_tr = -0.0158
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8716
	data_grads_norm = 4.9659
	new_data_grads_norm = 7.4873
	old_data_grads_norm = 7.1024
	sim_grads_norm_tr = 0.0026
-- Starting training on experience 186 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6395
	data_grads_norm = 5.9349
	new_data_grads_norm = 9.6968
	old_data_grads_norm = 6.8419
	sim_grads_norm_tr = 0.0021
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9992
	data_grads_norm = 6.8247
	new_data_grads_norm = 9.8310
	old_data_grads_norm = 8.7444
	sim_grads_norm_tr = 0.0267
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0864
	data_grads_norm = 6.2630
	new_data_grads_norm = 9.2450
	old_data_grads_norm = 6.8795
	sim_grads_norm_tr = 0.0379
-- Starting training on experience 187 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4629
	data_grads_norm = 6.2921
	new_data_grads_norm = 10.1033
	old_data_grads_norm = 8.2437
	sim_grads_norm_tr = 0.0107
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1513
	data_grads_norm = 6.4195
	new_data_grads_norm = 9.2226
	old_data_grads_norm = 8.3855
	sim_grads_norm_tr = 0.0560
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2429
	data_grads_norm = 6.0404
	new_data_grads_norm = 9.9975
	old_data_grads_norm = 6.7889
	sim_grads_norm_tr = -0.0199
-- Starting training on experience 188 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1539
	data_grads_norm = 5.8580
	new_data_grads_norm = 7.8137
	old_data_grads_norm = 9.2905
	sim_grads_norm_tr = -0.0125
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0294
	data_grads_norm = 6.3109
	new_data_grads_norm = 8.9660
	old_data_grads_norm = 10.4583
	sim_grads_norm_tr = 0.0438
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2692
	data_grads_norm = 6.5020
	new_data_grads_norm = 8.0538
	old_data_grads_norm = 7.3180
	sim_grads_norm_tr = -0.0022
-- Starting training on experience 189 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4419
	data_grads_norm = 6.9792
	new_data_grads_norm = 10.3377
	old_data_grads_norm = 7.4989
	sim_grads_norm_tr = 0.0036
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5589
	data_grads_norm = 7.1261
	new_data_grads_norm = 9.7376
	old_data_grads_norm = 6.8522
	sim_grads_norm_tr = 0.0617
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7628
	data_grads_norm = 6.7848
	new_data_grads_norm = 9.9228
	old_data_grads_norm = 9.5051
	sim_grads_norm_tr = -0.0170
-- Starting training on experience 190 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1821
	data_grads_norm = 5.9841
	new_data_grads_norm = 7.0002
	old_data_grads_norm = 9.9351
	sim_grads_norm_tr = 0.0364
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2275
	data_grads_norm = 5.3662
	new_data_grads_norm = 8.5513
	old_data_grads_norm = 6.6479
	sim_grads_norm_tr = -0.0324
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8007
	data_grads_norm = 7.2762
	new_data_grads_norm = 9.1966
	old_data_grads_norm = 9.7704
	sim_grads_norm_tr = -0.0016
-- Starting training on experience 191 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0184
	data_grads_norm = 6.3459
	new_data_grads_norm = 7.8823
	old_data_grads_norm = 9.9863
	sim_grads_norm_tr = 0.0327
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0356
	data_grads_norm = 5.4297
	new_data_grads_norm = 8.0141
	old_data_grads_norm = 7.4488
	sim_grads_norm_tr = 0.0310
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8350
	data_grads_norm = 5.3333
	new_data_grads_norm = 8.1110
	old_data_grads_norm = 5.2653
	sim_grads_norm_tr = 0.0303
-- Starting training on experience 192 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2298
	data_grads_norm = 5.5707
	new_data_grads_norm = 8.3586
	old_data_grads_norm = 7.9892
	sim_grads_norm_tr = 0.0102
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1815
	data_grads_norm = 6.0450
	new_data_grads_norm = 8.0932
	old_data_grads_norm = 7.2897
	sim_grads_norm_tr = -0.0186
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9821
	data_grads_norm = 4.9904
	new_data_grads_norm = 7.5116
	old_data_grads_norm = 6.9432
	sim_grads_norm_tr = -0.0169
-- Starting training on experience 193 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1675
	data_grads_norm = 5.2866
	new_data_grads_norm = 8.4225
	old_data_grads_norm = 5.1960
	sim_grads_norm_tr = 0.0113
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3199
	data_grads_norm = 6.2112
	new_data_grads_norm = 9.8257
	old_data_grads_norm = 7.9991
	sim_grads_norm_tr = -0.0025
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2808
	data_grads_norm = 6.6771
	new_data_grads_norm = 9.3610
	old_data_grads_norm = 8.5729
	sim_grads_norm_tr = 0.0014
-- Starting training on experience 194 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7960
	data_grads_norm = 4.3043
	new_data_grads_norm = 7.7173
	old_data_grads_norm = 4.0933
	sim_grads_norm_tr = -0.0181
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4445
	data_grads_norm = 5.8640
	new_data_grads_norm = 8.1648
	old_data_grads_norm = 8.0955
	sim_grads_norm_tr = 0.0410
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6709
	data_grads_norm = 4.3920
	new_data_grads_norm = 7.4502
	old_data_grads_norm = 5.0550
	sim_grads_norm_tr = 0.0237
-- Starting training on experience 195 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7345
	data_grads_norm = 4.8536
	new_data_grads_norm = 6.6794
	old_data_grads_norm = 6.2351
	sim_grads_norm_tr = 0.0226
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7776
	data_grads_norm = 5.3459
	new_data_grads_norm = 6.9863
	old_data_grads_norm = 6.1364
	sim_grads_norm_tr = -0.0218
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6293
	data_grads_norm = 5.1756
	new_data_grads_norm = 7.0464
	old_data_grads_norm = 7.7401
	sim_grads_norm_tr = 0.0507
-- Starting training on experience 196 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8698
	data_grads_norm = 5.7215
	new_data_grads_norm = 9.7845
	old_data_grads_norm = 4.2900
	sim_grads_norm_tr = 0.0068
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4756
	data_grads_norm = 5.9120
	new_data_grads_norm = 8.2932
	old_data_grads_norm = 8.3392
	sim_grads_norm_tr = -0.0124
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2545
	data_grads_norm = 5.6748
	new_data_grads_norm = 9.3731
	old_data_grads_norm = 5.7459
	sim_grads_norm_tr = 0.0434
-- Starting training on experience 197 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8164
	data_grads_norm = 7.0577
	new_data_grads_norm = 11.2697
	old_data_grads_norm = 5.4600
	sim_grads_norm_tr = 0.0268
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4555
	data_grads_norm = 6.3226
	new_data_grads_norm = 10.2360
	old_data_grads_norm = 5.7259
	sim_grads_norm_tr = 0.0020
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5120
	data_grads_norm = 6.3766
	new_data_grads_norm = 8.9108
	old_data_grads_norm = 7.6435
	sim_grads_norm_tr = 0.0324
-- Starting training on experience 198 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8548
	data_grads_norm = 5.4518
	new_data_grads_norm = 8.7361
	old_data_grads_norm = 7.1464
	sim_grads_norm_tr = 0.0049
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7072
	data_grads_norm = 6.3019
	new_data_grads_norm = 10.3731
	old_data_grads_norm = 5.8995
	sim_grads_norm_tr = 0.0121
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9965
	data_grads_norm = 5.3844
	new_data_grads_norm = 7.8336
	old_data_grads_norm = 5.5979
	sim_grads_norm_tr = 0.0675
-- Starting training on experience 199 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3777
	data_grads_norm = 5.9864
	new_data_grads_norm = 7.8245
	old_data_grads_norm = 9.1325
	sim_grads_norm_tr = 0.0075
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2135
	data_grads_norm = 5.7038
	new_data_grads_norm = 9.5045
	old_data_grads_norm = 6.0589
	sim_grads_norm_tr = 0.0149
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7410
	data_grads_norm = 6.0989
	new_data_grads_norm = 10.1872
	old_data_grads_norm = 8.0576
	sim_grads_norm_tr = 0.0080
-- Starting training on experience 200 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1569
	data_grads_norm = 5.3980
	new_data_grads_norm = 8.2742
	old_data_grads_norm = 8.0701
	sim_grads_norm_tr = -0.0410
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1437
	data_grads_norm = 4.5501
	new_data_grads_norm = 8.5066
	old_data_grads_norm = 5.3776
	sim_grads_norm_tr = -0.0055
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6079
	data_grads_norm = 6.7667
	new_data_grads_norm = 8.4468
	old_data_grads_norm = 6.9310
	sim_grads_norm_tr = 0.0154
-- Starting training on experience 201 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2861
	data_grads_norm = 5.6915
	new_data_grads_norm = 8.4122
	old_data_grads_norm = 5.9200
	sim_grads_norm_tr = 0.0037
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9455
	data_grads_norm = 5.1537
	new_data_grads_norm = 7.6657
	old_data_grads_norm = 6.2048
	sim_grads_norm_tr = 0.0674
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0164
	data_grads_norm = 5.6070
	new_data_grads_norm = 7.9348
	old_data_grads_norm = 7.9498
	sim_grads_norm_tr = -0.0296
-- Starting training on experience 202 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1527
	data_grads_norm = 5.8963
	new_data_grads_norm = 8.0888
	old_data_grads_norm = 7.4428
	sim_grads_norm_tr = -0.0195
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2474
	data_grads_norm = 6.6325
	new_data_grads_norm = 8.2195
	old_data_grads_norm = 9.1416
	sim_grads_norm_tr = -0.0453
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5585
	data_grads_norm = 6.3865
	new_data_grads_norm = 8.1503
	old_data_grads_norm = 8.0309
	sim_grads_norm_tr = 0.0935
-- Starting training on experience 203 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5113
	data_grads_norm = 6.3838
	new_data_grads_norm = 9.4913
	old_data_grads_norm = 8.3464
	sim_grads_norm_tr = 0.0242
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1060
	data_grads_norm = 5.6681
	new_data_grads_norm = 8.1812
	old_data_grads_norm = 9.2129
	sim_grads_norm_tr = -0.0161
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9728
	data_grads_norm = 4.8347
	new_data_grads_norm = 8.8679
	old_data_grads_norm = 5.9119
	sim_grads_norm_tr = -0.0189
-- Starting training on experience 204 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1833
	data_grads_norm = 6.1479
	new_data_grads_norm = 9.2979
	old_data_grads_norm = 6.5162
	sim_grads_norm_tr = -0.0018
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9718
	data_grads_norm = 5.7177
	new_data_grads_norm = 8.4177
	old_data_grads_norm = 7.4954
	sim_grads_norm_tr = 0.0125
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0557
	data_grads_norm = 5.7587
	new_data_grads_norm = 9.7065
	old_data_grads_norm = 4.5506
	sim_grads_norm_tr = 0.0520
-- Starting training on experience 205 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2727
	data_grads_norm = 5.7336
	new_data_grads_norm = 9.2079
	old_data_grads_norm = 7.0173
	sim_grads_norm_tr = 0.0475
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7279
	data_grads_norm = 5.7525
	new_data_grads_norm = 7.8438
	old_data_grads_norm = 6.9999
	sim_grads_norm_tr = 0.1047
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4804
	data_grads_norm = 6.8131
	new_data_grads_norm = 9.3777
	old_data_grads_norm = 7.6359
	sim_grads_norm_tr = -0.0060
-- Starting training on experience 206 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3236
	data_grads_norm = 5.5861
	new_data_grads_norm = 7.9775
	old_data_grads_norm = 8.1648
	sim_grads_norm_tr = 0.0071
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3541
	data_grads_norm = 5.1248
	new_data_grads_norm = 7.7191
	old_data_grads_norm = 6.3632
	sim_grads_norm_tr = 0.0030
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4067
	data_grads_norm = 5.7958
	new_data_grads_norm = 7.4079
	old_data_grads_norm = 7.7962
	sim_grads_norm_tr = 0.0020
-- Starting training on experience 207 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5874
	data_grads_norm = 4.1366
	new_data_grads_norm = 7.1421
	old_data_grads_norm = 2.8927
	sim_grads_norm_tr = 0.1019
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6766
	data_grads_norm = 4.4972
	new_data_grads_norm = 7.2064
	old_data_grads_norm = 7.1891
	sim_grads_norm_tr = -0.0667
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3029
	data_grads_norm = 5.8063
	new_data_grads_norm = 7.8041
	old_data_grads_norm = 7.1036
	sim_grads_norm_tr = -0.0235
-- Starting training on experience 208 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8028
	data_grads_norm = 6.7046
	new_data_grads_norm = 9.5540
	old_data_grads_norm = 8.5911
	sim_grads_norm_tr = 0.0070
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5242
	data_grads_norm = 5.5669
	new_data_grads_norm = 9.0042
	old_data_grads_norm = 6.8531
	sim_grads_norm_tr = 0.0217
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0625
	data_grads_norm = 6.3774
	new_data_grads_norm = 10.0585
	old_data_grads_norm = 7.1866
	sim_grads_norm_tr = 0.0047
-- Starting training on experience 209 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8195
	data_grads_norm = 6.1817
	new_data_grads_norm = 6.7470
	old_data_grads_norm = 9.6056
	sim_grads_norm_tr = 0.0288
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1929
	data_grads_norm = 5.4257
	new_data_grads_norm = 7.2991
	old_data_grads_norm = 6.5056
	sim_grads_norm_tr = 0.0992
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0713
	data_grads_norm = 5.3593
	new_data_grads_norm = 7.0105
	old_data_grads_norm = 6.1608
	sim_grads_norm_tr = 0.0150
-- Starting training on experience 210 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7857
	data_grads_norm = 5.2128
	new_data_grads_norm = 9.0989
	old_data_grads_norm = 5.2449
	sim_grads_norm_tr = 0.0021
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8889
	data_grads_norm = 5.7825
	new_data_grads_norm = 9.3231
	old_data_grads_norm = 6.6638
	sim_grads_norm_tr = -0.0283
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2174
	data_grads_norm = 5.9886
	new_data_grads_norm = 8.0693
	old_data_grads_norm = 7.8272
	sim_grads_norm_tr = -0.0092
-- Starting training on experience 211 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2987
	data_grads_norm = 6.4201
	new_data_grads_norm = 9.0803
	old_data_grads_norm = 7.5041
	sim_grads_norm_tr = -0.0196
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2312
	data_grads_norm = 5.2916
	new_data_grads_norm = 8.0284
	old_data_grads_norm = 8.3178
	sim_grads_norm_tr = 0.0068
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2560
	data_grads_norm = 5.5796
	new_data_grads_norm = 8.9114
	old_data_grads_norm = 7.6198
	sim_grads_norm_tr = -0.0331
-- Starting training on experience 212 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9553
	data_grads_norm = 7.3836
	new_data_grads_norm = 9.5473
	old_data_grads_norm = 9.5814
	sim_grads_norm_tr = 0.0950
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6196
	data_grads_norm = 6.1155
	new_data_grads_norm = 9.6287
	old_data_grads_norm = 7.7424
	sim_grads_norm_tr = 0.0442
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3804
	data_grads_norm = 5.3015
	new_data_grads_norm = 8.5124
	old_data_grads_norm = 7.1140
	sim_grads_norm_tr = -0.0060
-- Starting training on experience 213 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1310
	data_grads_norm = 5.8000
	new_data_grads_norm = 10.7602
	old_data_grads_norm = 4.6420
	sim_grads_norm_tr = -0.0273
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4104
	data_grads_norm = 5.9199
	new_data_grads_norm = 10.5357
	old_data_grads_norm = 6.0999
	sim_grads_norm_tr = 0.0181
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4757
	data_grads_norm = 5.9245
	new_data_grads_norm = 10.4592
	old_data_grads_norm = 6.5117
	sim_grads_norm_tr = 0.0038
-- Starting training on experience 214 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2076
	data_grads_norm = 6.7691
	new_data_grads_norm = 9.2801
	old_data_grads_norm = 8.1314
	sim_grads_norm_tr = 0.0487
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2782
	data_grads_norm = 5.0385
	new_data_grads_norm = 8.7015
	old_data_grads_norm = 5.9815
	sim_grads_norm_tr = 0.0150
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5558
	data_grads_norm = 5.6896
	new_data_grads_norm = 8.3290
	old_data_grads_norm = 7.8014
	sim_grads_norm_tr = -0.0162
-- Starting training on experience 215 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5358
	data_grads_norm = 5.8511
	new_data_grads_norm = 9.6742
	old_data_grads_norm = 6.4056
	sim_grads_norm_tr = 0.1161
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2320
	data_grads_norm = 6.4367
	new_data_grads_norm = 9.7136
	old_data_grads_norm = 9.7377
	sim_grads_norm_tr = -0.0086
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5100
	data_grads_norm = 6.5398
	new_data_grads_norm = 9.2645
	old_data_grads_norm = 7.4034
	sim_grads_norm_tr = 0.0051
-- Starting training on experience 216 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0616
	data_grads_norm = 5.4326
	new_data_grads_norm = 7.3676
	old_data_grads_norm = 7.0773
	sim_grads_norm_tr = -0.0155
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0871
	data_grads_norm = 5.0877
	new_data_grads_norm = 8.1020
	old_data_grads_norm = 6.5554
	sim_grads_norm_tr = 0.0219
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4834
	data_grads_norm = 6.1972
	new_data_grads_norm = 8.3804
	old_data_grads_norm = 7.6252
	sim_grads_norm_tr = -0.0007
-- Starting training on experience 217 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9339
	data_grads_norm = 4.3014
	new_data_grads_norm = 8.0973
	old_data_grads_norm = 4.2263
	sim_grads_norm_tr = -0.0046
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5945
	data_grads_norm = 6.0183
	new_data_grads_norm = 7.8535
	old_data_grads_norm = 8.5382
	sim_grads_norm_tr = 0.0192
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3398
	data_grads_norm = 5.9794
	new_data_grads_norm = 8.1780
	old_data_grads_norm = 8.8386
	sim_grads_norm_tr = -0.0249
-- Starting training on experience 218 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4816
	data_grads_norm = 6.0945
	new_data_grads_norm = 9.5046
	old_data_grads_norm = 6.6713
	sim_grads_norm_tr = -0.0250
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5890
	data_grads_norm = 5.5860
	new_data_grads_norm = 8.7407
	old_data_grads_norm = 5.1928
	sim_grads_norm_tr = 0.0742
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9704
	data_grads_norm = 5.3798
	new_data_grads_norm = 8.8241
	old_data_grads_norm = 4.3875
	sim_grads_norm_tr = 0.0062
-- Starting training on experience 219 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1676
	data_grads_norm = 5.7344
	new_data_grads_norm = 8.6854
	old_data_grads_norm = 7.0241
	sim_grads_norm_tr = -0.0110
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8811
	data_grads_norm = 4.7202
	new_data_grads_norm = 7.9388
	old_data_grads_norm = 4.1015
	sim_grads_norm_tr = 0.0071
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9060
	data_grads_norm = 5.0273
	new_data_grads_norm = 7.9731
	old_data_grads_norm = 7.6289
	sim_grads_norm_tr = -0.0151
-- Starting training on experience 220 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4633
	data_grads_norm = 6.5080
	new_data_grads_norm = 9.5344
	old_data_grads_norm = 8.5811
	sim_grads_norm_tr = 0.0150
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7121
	data_grads_norm = 6.6494
	new_data_grads_norm = 9.5737
	old_data_grads_norm = 6.7169
	sim_grads_norm_tr = 0.0175
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2498
	data_grads_norm = 6.0852
	new_data_grads_norm = 8.8429
	old_data_grads_norm = 9.5116
	sim_grads_norm_tr = 0.0153
-- Starting training on experience 221 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0288
	data_grads_norm = 5.1953
	new_data_grads_norm = 9.0770
	old_data_grads_norm = 4.7943
	sim_grads_norm_tr = -0.0148
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1384
	data_grads_norm = 5.7148
	new_data_grads_norm = 9.2115
	old_data_grads_norm = 5.9745
	sim_grads_norm_tr = 0.0031
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3760
	data_grads_norm = 6.6537
	new_data_grads_norm = 8.4250
	old_data_grads_norm = 10.0939
	sim_grads_norm_tr = 0.0147
-- Starting training on experience 222 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1686
	data_grads_norm = 5.8251
	new_data_grads_norm = 8.6116
	old_data_grads_norm = 10.5412
	sim_grads_norm_tr = -0.0279
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4930
	data_grads_norm = 6.0942
	new_data_grads_norm = 9.4162
	old_data_grads_norm = 7.2366
	sim_grads_norm_tr = 0.0320
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2294
	data_grads_norm = 5.3317
	new_data_grads_norm = 9.5793
	old_data_grads_norm = 4.4395
	sim_grads_norm_tr = 0.0214
-- Starting training on experience 223 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3539
	data_grads_norm = 6.2122
	new_data_grads_norm = 8.9079
	old_data_grads_norm = 7.9067
	sim_grads_norm_tr = -0.0174
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7657
	data_grads_norm = 5.5792
	new_data_grads_norm = 9.6231
	old_data_grads_norm = 4.6263
	sim_grads_norm_tr = -0.0077
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7701
	data_grads_norm = 5.5617
	new_data_grads_norm = 7.5813
	old_data_grads_norm = 6.5699
	sim_grads_norm_tr = 0.0012
-- Starting training on experience 224 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0022
	data_grads_norm = 5.2875
	new_data_grads_norm = 8.5092
	old_data_grads_norm = 7.5631
	sim_grads_norm_tr = -0.0025
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3216
	data_grads_norm = 5.8159
	new_data_grads_norm = 8.8397
	old_data_grads_norm = 6.5273
	sim_grads_norm_tr = -0.0055
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0337
	data_grads_norm = 6.0036
	new_data_grads_norm = 8.9628
	old_data_grads_norm = 7.5054
	sim_grads_norm_tr = 0.0031
-- Starting training on experience 225 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4757
	data_grads_norm = 5.7621
	new_data_grads_norm = 8.9983
	old_data_grads_norm = 5.4933
	sim_grads_norm_tr = -0.0196
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9827
	data_grads_norm = 6.5212
	new_data_grads_norm = 9.1717
	old_data_grads_norm = 8.5701
	sim_grads_norm_tr = 0.0032
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0698
	data_grads_norm = 6.2690
	new_data_grads_norm = 8.5234
	old_data_grads_norm = 7.9457
	sim_grads_norm_tr = 0.0043
-- Starting training on experience 226 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4088
	data_grads_norm = 5.7698
	new_data_grads_norm = 9.3621
	old_data_grads_norm = 5.6855
	sim_grads_norm_tr = 0.0073
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7137
	data_grads_norm = 6.8039
	new_data_grads_norm = 9.2172
	old_data_grads_norm = 9.4248
	sim_grads_norm_tr = 0.0878
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8329
	data_grads_norm = 4.7528
	new_data_grads_norm = 8.2917
	old_data_grads_norm = 5.1807
	sim_grads_norm_tr = 0.0563
-- Starting training on experience 227 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5370
	data_grads_norm = 5.1367
	new_data_grads_norm = 9.6989
	old_data_grads_norm = 5.3561
	sim_grads_norm_tr = -0.0339
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9556
	data_grads_norm = 5.8530
	new_data_grads_norm = 9.8290
	old_data_grads_norm = 7.2866
	sim_grads_norm_tr = 0.0029
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5329
	data_grads_norm = 5.1898
	new_data_grads_norm = 9.7204
	old_data_grads_norm = 3.6686
	sim_grads_norm_tr = -0.0263
-- Starting training on experience 228 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9682
	data_grads_norm = 4.6618
	new_data_grads_norm = 9.9472
	old_data_grads_norm = 5.2432
	sim_grads_norm_tr = -0.0397
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4711
	data_grads_norm = 5.7969
	new_data_grads_norm = 10.9303
	old_data_grads_norm = 5.1871
	sim_grads_norm_tr = 0.0100
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6728
	data_grads_norm = 6.3071
	new_data_grads_norm = 9.2237
	old_data_grads_norm = 6.2971
	sim_grads_norm_tr = -0.0160
-- Starting training on experience 229 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1953
	data_grads_norm = 5.4054
	new_data_grads_norm = 8.6629
	old_data_grads_norm = 6.4813
	sim_grads_norm_tr = -0.0320
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2342
	data_grads_norm = 5.5355
	new_data_grads_norm = 8.9929
	old_data_grads_norm = 6.2791
	sim_grads_norm_tr = 0.0317
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5317
	data_grads_norm = 6.3751
	new_data_grads_norm = 8.1200
	old_data_grads_norm = 7.9840
	sim_grads_norm_tr = 0.0106
-- Starting training on experience 230 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5197
	data_grads_norm = 5.8161
	new_data_grads_norm = 8.0319
	old_data_grads_norm = 6.2274
	sim_grads_norm_tr = 0.0443
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4104
	data_grads_norm = 6.3785
	new_data_grads_norm = 8.7702
	old_data_grads_norm = 6.4828
	sim_grads_norm_tr = -0.0043
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5130
	data_grads_norm = 6.2451
	new_data_grads_norm = 8.9076
	old_data_grads_norm = 8.2539
	sim_grads_norm_tr = 0.0100
-- Starting training on experience 231 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1702
	data_grads_norm = 5.5101
	new_data_grads_norm = 9.9742
	old_data_grads_norm = 6.1765
	sim_grads_norm_tr = -0.0123
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4404
	data_grads_norm = 6.0121
	new_data_grads_norm = 10.5955
	old_data_grads_norm = 6.4988
	sim_grads_norm_tr = -0.0368
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3295
	data_grads_norm = 6.1165
	new_data_grads_norm = 8.8415
	old_data_grads_norm = 5.7500
	sim_grads_norm_tr = 0.0214
-- Starting training on experience 232 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5468
	data_grads_norm = 5.9796
	new_data_grads_norm = 10.1227
	old_data_grads_norm = 5.1733
	sim_grads_norm_tr = -0.0049
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5311
	data_grads_norm = 6.4448
	new_data_grads_norm = 10.9231
	old_data_grads_norm = 6.2644
	sim_grads_norm_tr = -0.0393
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7957
	data_grads_norm = 7.3236
	new_data_grads_norm = 9.8878
	old_data_grads_norm = 9.1293
	sim_grads_norm_tr = 0.0384
-- Starting training on experience 233 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2764
	data_grads_norm = 5.1465
	new_data_grads_norm = 9.2542
	old_data_grads_norm = 4.9138
	sim_grads_norm_tr = -0.0456
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0270
	data_grads_norm = 5.5353
	new_data_grads_norm = 8.4611
	old_data_grads_norm = 5.8085
	sim_grads_norm_tr = -0.0190
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5871
	data_grads_norm = 6.3950
	new_data_grads_norm = 10.2521
	old_data_grads_norm = 9.6166
	sim_grads_norm_tr = 0.0138
-- Starting training on experience 234 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2680
	data_grads_norm = 6.2206
	new_data_grads_norm = 9.1555
	old_data_grads_norm = 7.6162
	sim_grads_norm_tr = 0.0297
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3784
	data_grads_norm = 5.8072
	new_data_grads_norm = 9.7762
	old_data_grads_norm = 4.8603
	sim_grads_norm_tr = 0.0153
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1233
	data_grads_norm = 4.8052
	new_data_grads_norm = 8.4074
	old_data_grads_norm = 3.8800
	sim_grads_norm_tr = 0.1206
-- Starting training on experience 235 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8302
	data_grads_norm = 4.4682
	new_data_grads_norm = 8.6165
	old_data_grads_norm = 5.8402
	sim_grads_norm_tr = -0.0147
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4450
	data_grads_norm = 6.3571
	new_data_grads_norm = 8.9871
	old_data_grads_norm = 8.2027
	sim_grads_norm_tr = -0.0162
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4771
	data_grads_norm = 6.2567
	new_data_grads_norm = 9.6523
	old_data_grads_norm = 9.1038
	sim_grads_norm_tr = -0.0361
-- Starting training on experience 236 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7687
	data_grads_norm = 5.7918
	new_data_grads_norm = 9.6944
	old_data_grads_norm = 7.7956
	sim_grads_norm_tr = -0.0058
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1047
	data_grads_norm = 6.4909
	new_data_grads_norm = 9.1302
	old_data_grads_norm = 8.4631
	sim_grads_norm_tr = 0.0035
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7697
	data_grads_norm = 5.9988
	new_data_grads_norm = 9.3454
	old_data_grads_norm = 6.3432
	sim_grads_norm_tr = 0.0085
-- Starting training on experience 237 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
-- >> End of training phase << --
-- >> Start of eval phase << --
-- Starting eval on experience 0 (Task 0) from test stream --
> Eval on experience 0 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp000 = 4.4316
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.2600
	mb_index = 4284
	time = 1779.9633
-- Starting eval on experience 1 (Task 0) from test stream --
> Eval on experience 1 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp001 = 2.8529
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.4660
-- Starting eval on experience 2 (Task 0) from test stream --
> Eval on experience 2 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp002 = 4.4198
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.2560
-- Starting eval on experience 3 (Task 0) from test stream --
> Eval on experience 3 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp003 = 3.1397
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.4320
-- Starting eval on experience 4 (Task 0) from test stream --
> Eval on experience 4 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp004 = 4.9957
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.1940
-- Starting eval on experience 5 (Task 0) from test stream --
> Eval on experience 5 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp005 = 3.8130
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.3440
-- Starting eval on experience 6 (Task 0) from test stream --
> Eval on experience 6 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp006 = 4.1413
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp006 = 0.2440
-- Starting eval on experience 7 (Task 0) from test stream --
> Eval on experience 7 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp007 = 3.8372
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp007 = 0.3140
-- Starting eval on experience 8 (Task 0) from test stream --
> Eval on experience 8 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp008 = 4.0501
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp008 = 0.3140
-- Starting eval on experience 9 (Task 0) from test stream --
> Eval on experience 9 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp009 = 3.5033
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp009 = 0.2880
-- Starting eval on experience 10 (Task 0) from test stream --
> Eval on experience 10 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp010 = 4.1441
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp010 = 0.1940
-- Starting eval on experience 11 (Task 0) from test stream --
> Eval on experience 11 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp011 = 3.4818
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp011 = 0.3680
-- Starting eval on experience 12 (Task 0) from test stream --
> Eval on experience 12 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp012 = 4.6666
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp012 = 0.1260
-- Starting eval on experience 13 (Task 0) from test stream --
> Eval on experience 13 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp013 = 3.3252
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp013 = 0.2480
-- Starting eval on experience 14 (Task 0) from test stream --
> Eval on experience 14 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp014 = 3.4078
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp014 = 0.2860
-- Starting eval on experience 15 (Task 0) from test stream --
> Eval on experience 15 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp015 = 3.2500
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp015 = 0.2440
-- Starting eval on experience 16 (Task 0) from test stream --
> Eval on experience 16 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp016 = 2.7967
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp016 = 0.2720
-- Starting eval on experience 17 (Task 0) from test stream --
> Eval on experience 17 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp017 = 4.2101
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp017 = 0.0700
-- >> End of eval phase << --
	CumulativeAccuracy/eval_phase/test_stream/Exp000 = 0.7220
	CumulativeAccuracy/eval_phase/test_stream/Exp001 = 0.6880
	CumulativeAccuracy/eval_phase/test_stream/Exp002 = 0.5947
	CumulativeAccuracy/eval_phase/test_stream/Exp003 = 0.5700
	CumulativeAccuracy/eval_phase/test_stream/Exp004 = 0.5076
	CumulativeAccuracy/eval_phase/test_stream/Exp005 = 0.4820
	CumulativeAccuracy/eval_phase/test_stream/Exp006 = 0.4477
	CumulativeAccuracy/eval_phase/test_stream/Exp007 = 0.4188
	CumulativeAccuracy/eval_phase/test_stream/Exp008 = 0.4007
	CumulativeAccuracy/eval_phase/test_stream/Exp009 = 0.3884
	CumulativeAccuracy/eval_phase/test_stream/Exp010 = 0.3613
	CumulativeAccuracy/eval_phase/test_stream/Exp011 = 0.3518
	CumulativeAccuracy/eval_phase/test_stream/Exp012 = 0.3297
	CumulativeAccuracy/eval_phase/test_stream/Exp013 = 0.3176
	CumulativeAccuracy/eval_phase/test_stream/Exp014 = 0.3043
	CumulativeAccuracy/eval_phase/test_stream/Exp015 = 0.2949
	CumulativeAccuracy/eval_phase/test_stream/Exp016 = 0.2859
	CumulativeAccuracy/eval_phase/test_stream/Exp017 = 0.2733
	Loss_Stream/eval_phase/test_stream/Task000 = 3.8037
	Top1_Acc_Stream/eval_phase/test_stream/Task000 = 0.2733
-- >> Start of training phase << --
-- Starting training on experience 0 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.4506
	data_grads_norm = 6.9321
	new_data_grads_norm = 11.0517
	old_data_grads_norm = 6.0577
	sim_grads_norm_tr = 0.0020
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4522
	data_grads_norm = 6.1281
	new_data_grads_norm = 11.1868
	old_data_grads_norm = 5.4944
	sim_grads_norm_tr = 0.0136
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.1160
	data_grads_norm = 6.2731
	new_data_grads_norm = 10.4929
	old_data_grads_norm = 7.6254
	sim_grads_norm_tr = -0.0199
-- Starting training on experience 1 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5442
	data_grads_norm = 5.2402
	new_data_grads_norm = 8.5634
	old_data_grads_norm = 3.9105
	sim_grads_norm_tr = -0.0092
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.2333
	data_grads_norm = 6.2170
	new_data_grads_norm = 8.4805
	old_data_grads_norm = 7.0491
	sim_grads_norm_tr = -0.0105
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.9492
	data_grads_norm = 5.6722
	new_data_grads_norm = 9.0787
	old_data_grads_norm = 6.8697
	sim_grads_norm_tr = 0.0018
-- Starting training on experience 2 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6053
	data_grads_norm = 5.9044
	new_data_grads_norm = 10.0293
	old_data_grads_norm = 4.5030
	sim_grads_norm_tr = -0.0209
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.2385
	data_grads_norm = 6.6930
	new_data_grads_norm = 9.9555
	old_data_grads_norm = 7.9521
	sim_grads_norm_tr = 0.0325
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6425
	data_grads_norm = 5.6771
	new_data_grads_norm = 9.4687
	old_data_grads_norm = 7.7758
	sim_grads_norm_tr = 0.0174
-- Starting training on experience 3 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.2418
	data_grads_norm = 6.3740
	new_data_grads_norm = 8.4684
	old_data_grads_norm = 7.9963
	sim_grads_norm_tr = 0.0071
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.8702
	data_grads_norm = 6.6376
	new_data_grads_norm = 9.5250
	old_data_grads_norm = 6.3677
	sim_grads_norm_tr = 0.0717
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5495
	data_grads_norm = 6.9683
	new_data_grads_norm = 7.9354
	old_data_grads_norm = 9.9394
	sim_grads_norm_tr = 0.0094
-- Starting training on experience 4 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2683
	data_grads_norm = 5.6626
	new_data_grads_norm = 9.5972
	old_data_grads_norm = 5.1550
	sim_grads_norm_tr = 0.0066
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5923
	data_grads_norm = 6.2757
	new_data_grads_norm = 9.5006
	old_data_grads_norm = 8.0542
	sim_grads_norm_tr = -0.0119
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3787
	data_grads_norm = 5.6773
	new_data_grads_norm = 9.2829
	old_data_grads_norm = 6.2228
	sim_grads_norm_tr = -0.0253
-- Starting training on experience 5 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.7061
	data_grads_norm = 5.6600
	new_data_grads_norm = 7.7536
	old_data_grads_norm = 7.0184
	sim_grads_norm_tr = 0.0161
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.8822
	data_grads_norm = 6.2772
	new_data_grads_norm = 9.1358
	old_data_grads_norm = 8.0277
	sim_grads_norm_tr = 0.0197
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6682
	data_grads_norm = 6.0040
	new_data_grads_norm = 9.0964
	old_data_grads_norm = 7.6411
	sim_grads_norm_tr = -0.0069
-- Starting training on experience 6 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.2888
	data_grads_norm = 6.9516
	new_data_grads_norm = 9.7217
	old_data_grads_norm = 6.8076
	sim_grads_norm_tr = 0.0678
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6441
	data_grads_norm = 6.7347
	new_data_grads_norm = 8.3593
	old_data_grads_norm = 10.9061
	sim_grads_norm_tr = -0.0092
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.0921
	data_grads_norm = 6.7989
	new_data_grads_norm = 10.0963
	old_data_grads_norm = 8.5942
	sim_grads_norm_tr = -0.0132
-- Starting training on experience 7 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.7866
	data_grads_norm = 6.2755
	new_data_grads_norm = 10.5144
	old_data_grads_norm = 3.5682
	sim_grads_norm_tr = -0.0040
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3030
	data_grads_norm = 5.8969
	new_data_grads_norm = 8.9071
	old_data_grads_norm = 6.6906
	sim_grads_norm_tr = -0.0045
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.2069
	data_grads_norm = 6.4586
	new_data_grads_norm = 9.5622
	old_data_grads_norm = 6.2597
	sim_grads_norm_tr = -0.0064
-- Starting training on experience 8 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.9329
	data_grads_norm = 6.9420
	new_data_grads_norm = 9.1677
	old_data_grads_norm = 9.2310
	sim_grads_norm_tr = 0.0039
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3534
	data_grads_norm = 5.8823
	new_data_grads_norm = 9.9047
	old_data_grads_norm = 6.1659
	sim_grads_norm_tr = 0.0184
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4082
	data_grads_norm = 5.9019
	new_data_grads_norm = 9.8441
	old_data_grads_norm = 7.1023
	sim_grads_norm_tr = 0.0516
-- Starting training on experience 9 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.6926
	data_grads_norm = 6.9278
	new_data_grads_norm = 9.2039
	old_data_grads_norm = 8.8177
	sim_grads_norm_tr = 0.0267
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.9033
	data_grads_norm = 7.4830
	new_data_grads_norm = 8.8583
	old_data_grads_norm = 9.3315
	sim_grads_norm_tr = 0.0364
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.9940
	data_grads_norm = 6.4105
	new_data_grads_norm = 9.3111
	old_data_grads_norm = 6.1735
	sim_grads_norm_tr = 0.1298
-- Starting training on experience 10 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5984
	data_grads_norm = 6.1830
	new_data_grads_norm = 8.0246
	old_data_grads_norm = 8.1972
	sim_grads_norm_tr = 0.0095
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.7374
	data_grads_norm = 5.6243
	new_data_grads_norm = 8.0306
	old_data_grads_norm = 5.3076
	sim_grads_norm_tr = 0.0909
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1528
	data_grads_norm = 5.2923
	new_data_grads_norm = 8.6739
	old_data_grads_norm = 4.8087
	sim_grads_norm_tr = -0.0043
-- Starting training on experience 11 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4975
	data_grads_norm = 5.8803
	new_data_grads_norm = 8.5495
	old_data_grads_norm = 6.0140
	sim_grads_norm_tr = -0.0141
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.0785
	data_grads_norm = 5.9762
	new_data_grads_norm = 9.3298
	old_data_grads_norm = 7.0237
	sim_grads_norm_tr = 0.0165
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2945
	data_grads_norm = 5.2535
	new_data_grads_norm = 8.7262
	old_data_grads_norm = 7.3541
	sim_grads_norm_tr = 0.0229
-- Starting training on experience 12 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.7143
	data_grads_norm = 5.6904
	new_data_grads_norm = 8.9823
	old_data_grads_norm = 5.8493
	sim_grads_norm_tr = 0.1309
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5529
	data_grads_norm = 5.7110
	new_data_grads_norm = 8.6240
	old_data_grads_norm = 6.5554
	sim_grads_norm_tr = 0.0215
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5301
	data_grads_norm = 6.0965
	new_data_grads_norm = 8.4995
	old_data_grads_norm = 7.9760
	sim_grads_norm_tr = -0.0027
-- Starting training on experience 13 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1922
	data_grads_norm = 6.8325
	new_data_grads_norm = 10.5971
	old_data_grads_norm = 7.3191
	sim_grads_norm_tr = 0.0845
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3459
	data_grads_norm = 6.4828
	new_data_grads_norm = 9.4802
	old_data_grads_norm = 6.6706
	sim_grads_norm_tr = 0.0212
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0150
	data_grads_norm = 5.7816
	new_data_grads_norm = 9.5161
	old_data_grads_norm = 6.5091
	sim_grads_norm_tr = -0.0301
-- Starting training on experience 14 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1071
	data_grads_norm = 5.4226
	new_data_grads_norm = 8.1740
	old_data_grads_norm = 6.8978
	sim_grads_norm_tr = -0.0242
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6265
	data_grads_norm = 6.2493
	new_data_grads_norm = 8.5057
	old_data_grads_norm = 8.3604
	sim_grads_norm_tr = 0.0008
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8380
	data_grads_norm = 5.3112
	new_data_grads_norm = 8.3565
	old_data_grads_norm = 5.1372
	sim_grads_norm_tr = 0.0103
-- Starting training on experience 15 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4344
	data_grads_norm = 5.5406
	new_data_grads_norm = 8.6078
	old_data_grads_norm = 5.5420
	sim_grads_norm_tr = 0.0842
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0436
	data_grads_norm = 5.0732
	new_data_grads_norm = 8.4096
	old_data_grads_norm = 6.3808
	sim_grads_norm_tr = 0.0007
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.2608
	data_grads_norm = 6.4006
	new_data_grads_norm = 8.7728
	old_data_grads_norm = 9.0059
	sim_grads_norm_tr = 0.0570
-- Starting training on experience 16 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0096
	data_grads_norm = 5.9491
	new_data_grads_norm = 8.5700
	old_data_grads_norm = 8.2924
	sim_grads_norm_tr = -0.0151
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7943
	data_grads_norm = 4.9432
	new_data_grads_norm = 9.4048
	old_data_grads_norm = 4.4657
	sim_grads_norm_tr = 0.0178
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2542
	data_grads_norm = 5.3370
	new_data_grads_norm = 8.9325
	old_data_grads_norm = 7.6646
	sim_grads_norm_tr = -0.0014
-- Starting training on experience 17 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1231
	data_grads_norm = 6.1258
	new_data_grads_norm = 9.6601
	old_data_grads_norm = 5.2459
	sim_grads_norm_tr = -0.0052
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.9169
	data_grads_norm = 6.6113
	new_data_grads_norm = 9.2604
	old_data_grads_norm = 9.8218
	sim_grads_norm_tr = 0.0181
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5968
	data_grads_norm = 6.4229
	new_data_grads_norm = 9.0685
	old_data_grads_norm = 8.8183
	sim_grads_norm_tr = 0.0477
-- Starting training on experience 18 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2923
	data_grads_norm = 5.3961
	new_data_grads_norm = 9.2619
	old_data_grads_norm = 7.1832
	sim_grads_norm_tr = 0.0083
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6111
	data_grads_norm = 7.0745
	new_data_grads_norm = 9.4802
	old_data_grads_norm = 8.3106
	sim_grads_norm_tr = 0.1687
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9354
	data_grads_norm = 4.5482
	new_data_grads_norm = 7.7123
	old_data_grads_norm = 5.0243
	sim_grads_norm_tr = 0.0097
-- Starting training on experience 19 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2975
	data_grads_norm = 5.4036
	new_data_grads_norm = 7.9939
	old_data_grads_norm = 6.1408
	sim_grads_norm_tr = 0.1235
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2160
	data_grads_norm = 5.7965
	new_data_grads_norm = 8.4776
	old_data_grads_norm = 6.9307
	sim_grads_norm_tr = -0.0211
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9106
	data_grads_norm = 5.5439
	new_data_grads_norm = 8.0010
	old_data_grads_norm = 7.2806
	sim_grads_norm_tr = -0.0393
-- Starting training on experience 20 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7594
	data_grads_norm = 5.6345
	new_data_grads_norm = 7.4658
	old_data_grads_norm = 9.3226
	sim_grads_norm_tr = 0.0253
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5857
	data_grads_norm = 5.6729
	new_data_grads_norm = 8.6527
	old_data_grads_norm = 6.8807
	sim_grads_norm_tr = 0.0139
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0491
	data_grads_norm = 6.3676
	new_data_grads_norm = 9.0878
	old_data_grads_norm = 8.1244
	sim_grads_norm_tr = 0.0509
-- Starting training on experience 21 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5940
	data_grads_norm = 6.3370
	new_data_grads_norm = 8.8031
	old_data_grads_norm = 10.1741
	sim_grads_norm_tr = 0.0620
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2927
	data_grads_norm = 5.2259
	new_data_grads_norm = 8.4845
	old_data_grads_norm = 4.9371
	sim_grads_norm_tr = -0.0108
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1919
	data_grads_norm = 4.7066
	new_data_grads_norm = 8.1295
	old_data_grads_norm = 5.5326
	sim_grads_norm_tr = 0.0003
-- Starting training on experience 22 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9080
	data_grads_norm = 6.1475
	new_data_grads_norm = 9.6041
	old_data_grads_norm = 5.7412
	sim_grads_norm_tr = -0.0104
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6683
	data_grads_norm = 5.7918
	new_data_grads_norm = 10.2221
	old_data_grads_norm = 7.0310
	sim_grads_norm_tr = 0.0068
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1392
	data_grads_norm = 5.8592
	new_data_grads_norm = 10.3934
	old_data_grads_norm = 7.8469
	sim_grads_norm_tr = -0.0106
-- Starting training on experience 23 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6843
	data_grads_norm = 6.3306
	new_data_grads_norm = 10.2009
	old_data_grads_norm = 8.3099
	sim_grads_norm_tr = 0.0378
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0366
	data_grads_norm = 6.2981
	new_data_grads_norm = 9.7781
	old_data_grads_norm = 4.7777
	sim_grads_norm_tr = -0.0102
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3165
	data_grads_norm = 7.4306
	new_data_grads_norm = 10.3131
	old_data_grads_norm = 7.8659
	sim_grads_norm_tr = -0.0194
-- Starting training on experience 24 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6250
	data_grads_norm = 6.5431
	new_data_grads_norm = 8.5201
	old_data_grads_norm = 9.9928
	sim_grads_norm_tr = -0.0533
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1707
	data_grads_norm = 6.6824
	new_data_grads_norm = 8.8956
	old_data_grads_norm = 7.4159
	sim_grads_norm_tr = 0.0654
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6823
	data_grads_norm = 6.6168
	new_data_grads_norm = 9.4323
	old_data_grads_norm = 8.3689
	sim_grads_norm_tr = -0.0131
-- Starting training on experience 25 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8569
	data_grads_norm = 7.2869
	new_data_grads_norm = 9.6463
	old_data_grads_norm = 10.8213
	sim_grads_norm_tr = -0.0024
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4536
	data_grads_norm = 5.3168
	new_data_grads_norm = 9.5270
	old_data_grads_norm = 5.6949
	sim_grads_norm_tr = -0.0070
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8649
	data_grads_norm = 6.1251
	new_data_grads_norm = 10.3498
	old_data_grads_norm = 5.8898
	sim_grads_norm_tr = 0.0597
-- Starting training on experience 26 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2940
	data_grads_norm = 5.1251
	new_data_grads_norm = 9.2655
	old_data_grads_norm = 4.2355
	sim_grads_norm_tr = -0.0171
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4018
	data_grads_norm = 5.6373
	new_data_grads_norm = 10.3438
	old_data_grads_norm = 4.4868
	sim_grads_norm_tr = 0.0140
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4145
	data_grads_norm = 6.0021
	new_data_grads_norm = 10.2222
	old_data_grads_norm = 5.7569
	sim_grads_norm_tr = 0.0020
-- Starting training on experience 27 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5643
	data_grads_norm = 7.1273
	new_data_grads_norm = 8.8387
	old_data_grads_norm = 9.2864
	sim_grads_norm_tr = 0.0714
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2071
	data_grads_norm = 5.3287
	new_data_grads_norm = 8.4336
	old_data_grads_norm = 5.3084
	sim_grads_norm_tr = -0.0143
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1222
	data_grads_norm = 6.4219
	new_data_grads_norm = 8.0906
	old_data_grads_norm = 6.9193
	sim_grads_norm_tr = 0.1358
-- Starting training on experience 28 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8789
	data_grads_norm = 5.5128
	new_data_grads_norm = 6.5553
	old_data_grads_norm = 8.8054
	sim_grads_norm_tr = 0.0547
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8832
	data_grads_norm = 5.4374
	new_data_grads_norm = 6.9020
	old_data_grads_norm = 7.4156
	sim_grads_norm_tr = 0.0057
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1689
	data_grads_norm = 5.8149
	new_data_grads_norm = 6.9486
	old_data_grads_norm = 7.6059
	sim_grads_norm_tr = -0.0393
-- Starting training on experience 29 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9600
	data_grads_norm = 5.5233
	new_data_grads_norm = 7.6756
	old_data_grads_norm = 6.9250
	sim_grads_norm_tr = 0.0222
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0245
	data_grads_norm = 5.6324
	new_data_grads_norm = 6.2373
	old_data_grads_norm = 9.0871
	sim_grads_norm_tr = -0.0085
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9533
	data_grads_norm = 5.1537
	new_data_grads_norm = 7.2942
	old_data_grads_norm = 5.8959
	sim_grads_norm_tr = 0.0536
-- Starting training on experience 30 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0142
	data_grads_norm = 5.3158
	new_data_grads_norm = 8.1787
	old_data_grads_norm = 7.9594
	sim_grads_norm_tr = -0.0005
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5384
	data_grads_norm = 4.5553
	new_data_grads_norm = 7.8225
	old_data_grads_norm = 4.1851
	sim_grads_norm_tr = 0.0045
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6695
	data_grads_norm = 4.8923
	new_data_grads_norm = 9.4602
	old_data_grads_norm = 4.1183
	sim_grads_norm_tr = 0.0148
-- Starting training on experience 31 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2244
	data_grads_norm = 5.0394
	new_data_grads_norm = 7.8687
	old_data_grads_norm = 5.3326
	sim_grads_norm_tr = -0.0058
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8160
	data_grads_norm = 4.0237
	new_data_grads_norm = 7.1996
	old_data_grads_norm = 4.9921
	sim_grads_norm_tr = -0.0257
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4721
	data_grads_norm = 5.6291
	new_data_grads_norm = 7.3380
	old_data_grads_norm = 8.2612
	sim_grads_norm_tr = 0.0258
-- Starting training on experience 32 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7561
	data_grads_norm = 6.2082
	new_data_grads_norm = 9.8475
	old_data_grads_norm = 7.4403
	sim_grads_norm_tr = 0.0500
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0684
	data_grads_norm = 5.3674
	new_data_grads_norm = 9.1939
	old_data_grads_norm = 6.2024
	sim_grads_norm_tr = 0.0164
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7142
	data_grads_norm = 6.3789
	new_data_grads_norm = 8.9494
	old_data_grads_norm = 8.7519
	sim_grads_norm_tr = 0.0246
-- Starting training on experience 33 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4836
	data_grads_norm = 5.9358
	new_data_grads_norm = 7.9000
	old_data_grads_norm = 8.2177
	sim_grads_norm_tr = -0.0110
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4091
	data_grads_norm = 6.2921
	new_data_grads_norm = 7.9969
	old_data_grads_norm = 9.0402
	sim_grads_norm_tr = -0.0312
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9828
	data_grads_norm = 5.0277
	new_data_grads_norm = 8.3930
	old_data_grads_norm = 6.8847
	sim_grads_norm_tr = -0.0056
-- Starting training on experience 34 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1261
	data_grads_norm = 6.3570
	new_data_grads_norm = 8.0758
	old_data_grads_norm = 7.4193
	sim_grads_norm_tr = 0.0687
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1244
	data_grads_norm = 5.1991
	new_data_grads_norm = 8.0588
	old_data_grads_norm = 5.3740
	sim_grads_norm_tr = 0.0515
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7131
	data_grads_norm = 5.7475
	new_data_grads_norm = 8.5009
	old_data_grads_norm = 7.3471
	sim_grads_norm_tr = 0.0996
-- Starting training on experience 35 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7330
	data_grads_norm = 5.0153
	new_data_grads_norm = 7.0704
	old_data_grads_norm = 5.3513
	sim_grads_norm_tr = 0.0004
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0738
	data_grads_norm = 5.5573
	new_data_grads_norm = 8.2975
	old_data_grads_norm = 7.4900
	sim_grads_norm_tr = 0.0580
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8016
	data_grads_norm = 5.4277
	new_data_grads_norm = 6.9241
	old_data_grads_norm = 7.0218
	sim_grads_norm_tr = -0.0160
-- Starting training on experience 36 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5283
	data_grads_norm = 5.1078
	new_data_grads_norm = 8.8992
	old_data_grads_norm = 6.6842
	sim_grads_norm_tr = -0.0452
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7044
	data_grads_norm = 5.3818
	new_data_grads_norm = 8.4571
	old_data_grads_norm = 7.1098
	sim_grads_norm_tr = 0.0005
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6195
	data_grads_norm = 5.3025
	new_data_grads_norm = 8.6625
	old_data_grads_norm = 6.2850
	sim_grads_norm_tr = -0.0138
-- Starting training on experience 37 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7758
	data_grads_norm = 4.3746
	new_data_grads_norm = 7.5759
	old_data_grads_norm = 4.0798
	sim_grads_norm_tr = 0.0698
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6830
	data_grads_norm = 5.1974
	new_data_grads_norm = 7.3293
	old_data_grads_norm = 7.4243
	sim_grads_norm_tr = 0.0014
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7081
	data_grads_norm = 5.8716
	new_data_grads_norm = 7.3084
	old_data_grads_norm = 10.6081
	sim_grads_norm_tr = -0.0197
-- Starting training on experience 38 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0827
	data_grads_norm = 6.2632
	new_data_grads_norm = 7.5912
	old_data_grads_norm = 10.4733
	sim_grads_norm_tr = 0.0105
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9722
	data_grads_norm = 5.6020
	new_data_grads_norm = 8.0769
	old_data_grads_norm = 6.7330
	sim_grads_norm_tr = 0.0103
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6053
	data_grads_norm = 4.9390
	new_data_grads_norm = 7.5616
	old_data_grads_norm = 5.4702
	sim_grads_norm_tr = 0.0140
-- Starting training on experience 39 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7981
	data_grads_norm = 5.2867
	new_data_grads_norm = 8.1781
	old_data_grads_norm = 5.6837
	sim_grads_norm_tr = 0.0043
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0270
	data_grads_norm = 6.3015
	new_data_grads_norm = 8.2233
	old_data_grads_norm = 9.2769
	sim_grads_norm_tr = -0.0019
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0867
	data_grads_norm = 5.6567
	new_data_grads_norm = 7.6057
	old_data_grads_norm = 7.2679
	sim_grads_norm_tr = 0.0339
-- Starting training on experience 40 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7302
	data_grads_norm = 5.5932
	new_data_grads_norm = 8.1479
	old_data_grads_norm = 9.4347
	sim_grads_norm_tr = 0.0102
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9681
	data_grads_norm = 5.6193
	new_data_grads_norm = 7.4365
	old_data_grads_norm = 7.6670
	sim_grads_norm_tr = 0.0240
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6758
	data_grads_norm = 5.2121
	new_data_grads_norm = 8.1144
	old_data_grads_norm = 5.6000
	sim_grads_norm_tr = -0.0091
-- Starting training on experience 41 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2070
	data_grads_norm = 5.1999
	new_data_grads_norm = 7.5090
	old_data_grads_norm = 6.5348
	sim_grads_norm_tr = 0.0030
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7629
	data_grads_norm = 5.5377
	new_data_grads_norm = 7.7478
	old_data_grads_norm = 6.4940
	sim_grads_norm_tr = -0.0301
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6912
	data_grads_norm = 5.3129
	new_data_grads_norm = 7.9010
	old_data_grads_norm = 5.8694
	sim_grads_norm_tr = 0.0354
-- Starting training on experience 42 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9619
	data_grads_norm = 6.2861
	new_data_grads_norm = 9.1692
	old_data_grads_norm = 7.2645
	sim_grads_norm_tr = 0.0307
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5751
	data_grads_norm = 5.4390
	new_data_grads_norm = 9.3005
	old_data_grads_norm = 5.5779
	sim_grads_norm_tr = 0.0499
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1238
	data_grads_norm = 6.9977
	new_data_grads_norm = 9.1227
	old_data_grads_norm = 11.1083
	sim_grads_norm_tr = 0.0339
-- Starting training on experience 43 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5023
	data_grads_norm = 5.0747
	new_data_grads_norm = 9.4683
	old_data_grads_norm = 4.7480
	sim_grads_norm_tr = -0.0248
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0721
	data_grads_norm = 4.8220
	new_data_grads_norm = 8.4858
	old_data_grads_norm = 5.4666
	sim_grads_norm_tr = -0.0408
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4222
	data_grads_norm = 5.1384
	new_data_grads_norm = 8.9739
	old_data_grads_norm = 5.0805
	sim_grads_norm_tr = -0.0357
-- Starting training on experience 44 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4935
	data_grads_norm = 4.6432
	new_data_grads_norm = 7.8382
	old_data_grads_norm = 4.2768
	sim_grads_norm_tr = -0.0159
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8173
	data_grads_norm = 6.0063
	new_data_grads_norm = 8.5732
	old_data_grads_norm = 8.8116
	sim_grads_norm_tr = -0.0184
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7953
	data_grads_norm = 6.3795
	new_data_grads_norm = 9.0170
	old_data_grads_norm = 8.1852
	sim_grads_norm_tr = 0.0337
-- Starting training on experience 45 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4133
	data_grads_norm = 4.9533
	new_data_grads_norm = 8.3992
	old_data_grads_norm = 6.6775
	sim_grads_norm_tr = 0.0140
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4001
	data_grads_norm = 5.0905
	new_data_grads_norm = 8.4364
	old_data_grads_norm = 5.5893
	sim_grads_norm_tr = -0.0100
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6614
	data_grads_norm = 6.0802
	new_data_grads_norm = 9.8186
	old_data_grads_norm = 7.6565
	sim_grads_norm_tr = 0.0006
-- Starting training on experience 46 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7251
	data_grads_norm = 5.7149
	new_data_grads_norm = 9.0612
	old_data_grads_norm = 5.7919
	sim_grads_norm_tr = 0.0986
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4465
	data_grads_norm = 5.1424
	new_data_grads_norm = 8.4688
	old_data_grads_norm = 4.9774
	sim_grads_norm_tr = -0.0213
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9108
	data_grads_norm = 6.9390
	new_data_grads_norm = 9.0434
	old_data_grads_norm = 11.1963
	sim_grads_norm_tr = -0.0186
-- Starting training on experience 47 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3595
	data_grads_norm = 4.5035
	new_data_grads_norm = 7.4536
	old_data_grads_norm = 4.4354
	sim_grads_norm_tr = -0.0216
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1337
	data_grads_norm = 5.2288
	new_data_grads_norm = 8.2768
	old_data_grads_norm = 5.5046
	sim_grads_norm_tr = -0.0137
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4326
	data_grads_norm = 6.6120
	new_data_grads_norm = 8.0334
	old_data_grads_norm = 8.4522
	sim_grads_norm_tr = 0.0546
-- Starting training on experience 48 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7908
	data_grads_norm = 4.8632
	new_data_grads_norm = 8.3762
	old_data_grads_norm = 6.0078
	sim_grads_norm_tr = 0.0807
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5351
	data_grads_norm = 5.1583
	new_data_grads_norm = 9.9116
	old_data_grads_norm = 3.9665
	sim_grads_norm_tr = -0.0319
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4787
	data_grads_norm = 5.1823
	new_data_grads_norm = 8.5164
	old_data_grads_norm = 7.3757
	sim_grads_norm_tr = -0.0651
-- Starting training on experience 49 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1362
	data_grads_norm = 4.6162
	new_data_grads_norm = 7.3996
	old_data_grads_norm = 4.8503
	sim_grads_norm_tr = 0.0091
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3390
	data_grads_norm = 5.2543
	new_data_grads_norm = 7.5919
	old_data_grads_norm = 6.7279
	sim_grads_norm_tr = 0.0308
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6039
	data_grads_norm = 6.2519
	new_data_grads_norm = 8.3240
	old_data_grads_norm = 9.2055
	sim_grads_norm_tr = 0.0062
-- Starting training on experience 50 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8682
	data_grads_norm = 5.4635
	new_data_grads_norm = 8.2974
	old_data_grads_norm = 6.4421
	sim_grads_norm_tr = -0.0132
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8697
	data_grads_norm = 6.0797
	new_data_grads_norm = 8.9515
	old_data_grads_norm = 7.6080
	sim_grads_norm_tr = 0.0223
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5615
	data_grads_norm = 5.0536
	new_data_grads_norm = 7.3766
	old_data_grads_norm = 5.5570
	sim_grads_norm_tr = -0.0401
-- Starting training on experience 51 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0456
	data_grads_norm = 6.1160
	new_data_grads_norm = 8.2697
	old_data_grads_norm = 8.3367
	sim_grads_norm_tr = -0.0167
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5256
	data_grads_norm = 5.8709
	new_data_grads_norm = 9.4665
	old_data_grads_norm = 6.7254
	sim_grads_norm_tr = 0.0232
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3876
	data_grads_norm = 7.1789
	new_data_grads_norm = 8.3922
	old_data_grads_norm = 9.3547
	sim_grads_norm_tr = 0.0274
-- Starting training on experience 52 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4611
	data_grads_norm = 5.8193
	new_data_grads_norm = 9.5108
	old_data_grads_norm = 8.7567
	sim_grads_norm_tr = -0.0691
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0369
	data_grads_norm = 5.9813
	new_data_grads_norm = 9.3741
	old_data_grads_norm = 9.0847
	sim_grads_norm_tr = 0.0466
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3342
	data_grads_norm = 5.8591
	new_data_grads_norm = 9.2037
	old_data_grads_norm = 8.2597
	sim_grads_norm_tr = 0.0234
-- Starting training on experience 53 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2909
	data_grads_norm = 4.9114
	new_data_grads_norm = 7.9140
	old_data_grads_norm = 6.7017
	sim_grads_norm_tr = -0.0043
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4579
	data_grads_norm = 6.3087
	new_data_grads_norm = 7.8786
	old_data_grads_norm = 8.6383
	sim_grads_norm_tr = -0.0103
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4821
	data_grads_norm = 5.0975
	new_data_grads_norm = 8.5736
	old_data_grads_norm = 5.9827
	sim_grads_norm_tr = 0.0185
-- Starting training on experience 54 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9755
	data_grads_norm = 6.3877
	new_data_grads_norm = 9.9076
	old_data_grads_norm = 7.0395
	sim_grads_norm_tr = 0.0176
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8401
	data_grads_norm = 6.3981
	new_data_grads_norm = 10.0065
	old_data_grads_norm = 7.8476
	sim_grads_norm_tr = -0.0022
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5709
	data_grads_norm = 5.7843
	new_data_grads_norm = 10.2832
	old_data_grads_norm = 3.6440
	sim_grads_norm_tr = 0.0207
-- Starting training on experience 55 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1832
	data_grads_norm = 5.4368
	new_data_grads_norm = 8.3799
	old_data_grads_norm = 6.0385
	sim_grads_norm_tr = -0.0103
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6737
	data_grads_norm = 6.0497
	new_data_grads_norm = 9.1051
	old_data_grads_norm = 5.5352
	sim_grads_norm_tr = -0.0082
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6981
	data_grads_norm = 5.7671
	new_data_grads_norm = 9.2294
	old_data_grads_norm = 7.0420
	sim_grads_norm_tr = 0.0001
-- Starting training on experience 56 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1596
	data_grads_norm = 4.6717
	new_data_grads_norm = 7.9566
	old_data_grads_norm = 7.1245
	sim_grads_norm_tr = -0.0251
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4448
	data_grads_norm = 4.7435
	new_data_grads_norm = 7.2959
	old_data_grads_norm = 7.2764
	sim_grads_norm_tr = -0.0051
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4394
	data_grads_norm = 4.7499
	new_data_grads_norm = 7.6140
	old_data_grads_norm = 5.3727
	sim_grads_norm_tr = 0.0814
-- Starting training on experience 57 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4478
	data_grads_norm = 5.3069
	new_data_grads_norm = 8.5197
	old_data_grads_norm = 4.8044
	sim_grads_norm_tr = -0.0192
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5440
	data_grads_norm = 5.2828
	new_data_grads_norm = 9.0945
	old_data_grads_norm = 6.2585
	sim_grads_norm_tr = -0.0094
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4429
	data_grads_norm = 5.2727
	new_data_grads_norm = 8.6853
	old_data_grads_norm = 5.2947
	sim_grads_norm_tr = 0.0098
-- Starting training on experience 58 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4001
	data_grads_norm = 6.2094
	new_data_grads_norm = 8.3620
	old_data_grads_norm = 9.1639
	sim_grads_norm_tr = 0.0349
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4843
	data_grads_norm = 5.5960
	new_data_grads_norm = 8.8656
	old_data_grads_norm = 7.0695
	sim_grads_norm_tr = 0.0078
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4499
	data_grads_norm = 4.8441
	new_data_grads_norm = 7.4802
	old_data_grads_norm = 5.5334
	sim_grads_norm_tr = 0.0348
-- Starting training on experience 59 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6844
	data_grads_norm = 4.9630
	new_data_grads_norm = 8.1144
	old_data_grads_norm = 7.0434
	sim_grads_norm_tr = -0.0273
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9442
	data_grads_norm = 6.1918
	new_data_grads_norm = 8.3914
	old_data_grads_norm = 6.8566
	sim_grads_norm_tr = 0.0940
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9076
	data_grads_norm = 5.6235
	new_data_grads_norm = 9.0305
	old_data_grads_norm = 6.0050
	sim_grads_norm_tr = 0.0034
-- Starting training on experience 60 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3535
	data_grads_norm = 5.5764
	new_data_grads_norm = 8.3556
	old_data_grads_norm = 9.4769
	sim_grads_norm_tr = 0.0603
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4325
	data_grads_norm = 5.7803
	new_data_grads_norm = 8.4624
	old_data_grads_norm = 8.9815
	sim_grads_norm_tr = -0.0320
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2886
	data_grads_norm = 5.9858
	new_data_grads_norm = 9.5379
	old_data_grads_norm = 5.8607
	sim_grads_norm_tr = 0.0209
-- Starting training on experience 61 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6171
	data_grads_norm = 5.4463
	new_data_grads_norm = 8.2495
	old_data_grads_norm = 6.4292
	sim_grads_norm_tr = 0.0017
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0781
	data_grads_norm = 6.7784
	new_data_grads_norm = 7.3564
	old_data_grads_norm = 9.0829
	sim_grads_norm_tr = 0.0299
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2766
	data_grads_norm = 5.7889
	new_data_grads_norm = 7.4240
	old_data_grads_norm = 6.3470
	sim_grads_norm_tr = 0.0215
-- Starting training on experience 62 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6471
	data_grads_norm = 6.0473
	new_data_grads_norm = 8.2481
	old_data_grads_norm = 9.3113
	sim_grads_norm_tr = 0.0572
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5533
	data_grads_norm = 4.9988
	new_data_grads_norm = 7.8423
	old_data_grads_norm = 5.7297
	sim_grads_norm_tr = 0.0688
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2786
	data_grads_norm = 5.1618
	new_data_grads_norm = 6.9070
	old_data_grads_norm = 6.1377
	sim_grads_norm_tr = 0.0046
-- Starting training on experience 63 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5102
	data_grads_norm = 5.3616
	new_data_grads_norm = 7.9991
	old_data_grads_norm = 7.9656
	sim_grads_norm_tr = 0.0037
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8709
	data_grads_norm = 6.4728
	new_data_grads_norm = 7.7277
	old_data_grads_norm = 8.0652
	sim_grads_norm_tr = -0.0187
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2639
	data_grads_norm = 4.8355
	new_data_grads_norm = 8.3399
	old_data_grads_norm = 6.0112
	sim_grads_norm_tr = 0.0298
-- Starting training on experience 64 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4026
	data_grads_norm = 5.5847
	new_data_grads_norm = 10.8787
	old_data_grads_norm = 4.9046
	sim_grads_norm_tr = -0.0364
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9822
	data_grads_norm = 6.8316
	new_data_grads_norm = 10.5151
	old_data_grads_norm = 7.7175
	sim_grads_norm_tr = 0.0307
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5133
	data_grads_norm = 6.0974
	new_data_grads_norm = 11.6950
	old_data_grads_norm = 5.9888
	sim_grads_norm_tr = -0.0366
-- Starting training on experience 65 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2746
	data_grads_norm = 4.9659
	new_data_grads_norm = 7.7304
	old_data_grads_norm = 4.6147
	sim_grads_norm_tr = 0.0115
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8533
	data_grads_norm = 6.2315
	new_data_grads_norm = 7.3154
	old_data_grads_norm = 9.5629
	sim_grads_norm_tr = 0.0493
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2261
	data_grads_norm = 4.3588
	new_data_grads_norm = 7.9759
	old_data_grads_norm = 5.0376
	sim_grads_norm_tr = -0.0599
-- Starting training on experience 66 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3218
	data_grads_norm = 5.0131
	new_data_grads_norm = 8.3163
	old_data_grads_norm = 6.7157
	sim_grads_norm_tr = 0.0059
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1137
	data_grads_norm = 4.3583
	new_data_grads_norm = 8.3591
	old_data_grads_norm = 5.3429
	sim_grads_norm_tr = -0.0178
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1753
	data_grads_norm = 4.3437
	new_data_grads_norm = 7.4296
	old_data_grads_norm = 4.9427
	sim_grads_norm_tr = -0.0408
-- Starting training on experience 67 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7872
	data_grads_norm = 6.5232
	new_data_grads_norm = 7.6554
	old_data_grads_norm = 8.8452
	sim_grads_norm_tr = -0.0248
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2128
	data_grads_norm = 5.3699
	new_data_grads_norm = 8.4042
	old_data_grads_norm = 7.3411
	sim_grads_norm_tr = 0.0085
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1564
	data_grads_norm = 4.4004
	new_data_grads_norm = 8.1421
	old_data_grads_norm = 3.9349
	sim_grads_norm_tr = 0.1113
-- Starting training on experience 68 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2386
	data_grads_norm = 4.5835
	new_data_grads_norm = 7.5206
	old_data_grads_norm = 4.1283
	sim_grads_norm_tr = -0.0133
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8838
	data_grads_norm = 6.2176
	new_data_grads_norm = 8.4678
	old_data_grads_norm = 7.6699
	sim_grads_norm_tr = 0.0529
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3061
	data_grads_norm = 5.6580
	new_data_grads_norm = 6.9462
	old_data_grads_norm = 6.2117
	sim_grads_norm_tr = 0.0637
-- Starting training on experience 69 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2150
	data_grads_norm = 5.7360
	new_data_grads_norm = 8.0867
	old_data_grads_norm = 7.2502
	sim_grads_norm_tr = 0.0075
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9920
	data_grads_norm = 4.8554
	new_data_grads_norm = 8.2773
	old_data_grads_norm = 4.3367
	sim_grads_norm_tr = 0.0411
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2130
	data_grads_norm = 5.4370
	new_data_grads_norm = 7.0048
	old_data_grads_norm = 7.5268
	sim_grads_norm_tr = -0.0094
-- Starting training on experience 70 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6577
	data_grads_norm = 5.5270
	new_data_grads_norm = 8.6134
	old_data_grads_norm = 6.9603
	sim_grads_norm_tr = 0.0254
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4954
	data_grads_norm = 4.8270
	new_data_grads_norm = 7.4315
	old_data_grads_norm = 6.1510
	sim_grads_norm_tr = -0.0405
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9791
	data_grads_norm = 6.7295
	new_data_grads_norm = 7.1048
	old_data_grads_norm = 10.9237
	sim_grads_norm_tr = -0.0825
-- Starting training on experience 71 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1447
	data_grads_norm = 5.3649
	new_data_grads_norm = 7.6671
	old_data_grads_norm = 7.5147
	sim_grads_norm_tr = 0.0638
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9796
	data_grads_norm = 5.0355
	new_data_grads_norm = 7.6158
	old_data_grads_norm = 7.3364
	sim_grads_norm_tr = -0.0076
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0470
	data_grads_norm = 5.4491
	new_data_grads_norm = 7.1681
	old_data_grads_norm = 7.9657
	sim_grads_norm_tr = 0.0106
-- Starting training on experience 72 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7439
	data_grads_norm = 5.1251
	new_data_grads_norm = 7.9068
	old_data_grads_norm = 8.1023
	sim_grads_norm_tr = -0.0418
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2974
	data_grads_norm = 5.9873
	new_data_grads_norm = 9.1292
	old_data_grads_norm = 7.4465
	sim_grads_norm_tr = -0.0221
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3135
	data_grads_norm = 5.9635
	new_data_grads_norm = 9.5604
	old_data_grads_norm = 6.2908
	sim_grads_norm_tr = -0.0033
-- Starting training on experience 73 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2688
	data_grads_norm = 5.1099
	new_data_grads_norm = 8.0861
	old_data_grads_norm = 6.3397
	sim_grads_norm_tr = -0.0233
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6893
	data_grads_norm = 5.4192
	new_data_grads_norm = 8.1998
	old_data_grads_norm = 5.4515
	sim_grads_norm_tr = 0.0348
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8891
	data_grads_norm = 6.0236
	new_data_grads_norm = 9.0146
	old_data_grads_norm = 7.2223
	sim_grads_norm_tr = -0.0229
-- Starting training on experience 74 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2757
	data_grads_norm = 5.4168
	new_data_grads_norm = 8.9925
	old_data_grads_norm = 5.9360
	sim_grads_norm_tr = -0.0116
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3791
	data_grads_norm = 6.0076
	new_data_grads_norm = 8.5990
	old_data_grads_norm = 5.2837
	sim_grads_norm_tr = -0.0280
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3613
	data_grads_norm = 6.6627
	new_data_grads_norm = 9.6858
	old_data_grads_norm = 8.5061
	sim_grads_norm_tr = -0.0282
-- Starting training on experience 75 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5173
	data_grads_norm = 5.3176
	new_data_grads_norm = 7.8746
	old_data_grads_norm = 8.4538
	sim_grads_norm_tr = -0.0206
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2052
	data_grads_norm = 5.0251
	new_data_grads_norm = 7.7815
	old_data_grads_norm = 4.9289
	sim_grads_norm_tr = -0.0089
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3648
	data_grads_norm = 5.1510
	new_data_grads_norm = 7.2235
	old_data_grads_norm = 6.9091
	sim_grads_norm_tr = 0.0587
-- Starting training on experience 76 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4538
	data_grads_norm = 5.3405
	new_data_grads_norm = 8.5321
	old_data_grads_norm = 6.7027
	sim_grads_norm_tr = 0.0063
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0192
	data_grads_norm = 4.5084
	new_data_grads_norm = 8.3618
	old_data_grads_norm = 4.9366
	sim_grads_norm_tr = -0.0403
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3681
	data_grads_norm = 5.3820
	new_data_grads_norm = 8.1355
	old_data_grads_norm = 4.6329
	sim_grads_norm_tr = -0.0326
-- Starting training on experience 77 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1621
	data_grads_norm = 5.0311
	new_data_grads_norm = 9.5604
	old_data_grads_norm = 4.6488
	sim_grads_norm_tr = 0.0125
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0203
	data_grads_norm = 5.5088
	new_data_grads_norm = 9.5928
	old_data_grads_norm = 5.1646
	sim_grads_norm_tr = -0.0177
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9786
	data_grads_norm = 5.1067
	new_data_grads_norm = 9.4904
	old_data_grads_norm = 5.1565
	sim_grads_norm_tr = -0.0033
-- Starting training on experience 78 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3054
	data_grads_norm = 4.8956
	new_data_grads_norm = 7.2099
	old_data_grads_norm = 5.8469
	sim_grads_norm_tr = 0.0335
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0565
	data_grads_norm = 4.4890
	new_data_grads_norm = 7.0895
	old_data_grads_norm = 6.2058
	sim_grads_norm_tr = 0.0156
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7679
	data_grads_norm = 6.0932
	new_data_grads_norm = 7.1184
	old_data_grads_norm = 10.9509
	sim_grads_norm_tr = -0.0278
-- Starting training on experience 79 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2520
	data_grads_norm = 4.9280
	new_data_grads_norm = 8.1377
	old_data_grads_norm = 5.6820
	sim_grads_norm_tr = -0.0250
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9867
	data_grads_norm = 4.8378
	new_data_grads_norm = 8.0895
	old_data_grads_norm = 7.0849
	sim_grads_norm_tr = -0.0156
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2229
	data_grads_norm = 5.5110
	new_data_grads_norm = 8.7195
	old_data_grads_norm = 6.5943
	sim_grads_norm_tr = -0.0046
-- Starting training on experience 80 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2560
	data_grads_norm = 5.4426
	new_data_grads_norm = 8.9583
	old_data_grads_norm = 5.7863
	sim_grads_norm_tr = 0.0574
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4550
	data_grads_norm = 5.6621
	new_data_grads_norm = 9.4954
	old_data_grads_norm = 5.6952
	sim_grads_norm_tr = 0.0022
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2517
	data_grads_norm = 5.3984
	new_data_grads_norm = 8.7144
	old_data_grads_norm = 6.1979
	sim_grads_norm_tr = -0.0195
-- Starting training on experience 81 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1961
	data_grads_norm = 5.6030
	new_data_grads_norm = 9.8460
	old_data_grads_norm = 4.6756
	sim_grads_norm_tr = 0.0291
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0779
	data_grads_norm = 7.0845
	new_data_grads_norm = 9.9351
	old_data_grads_norm = 8.9954
	sim_grads_norm_tr = 0.0294
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4318
	data_grads_norm = 6.1230
	new_data_grads_norm = 9.2406
	old_data_grads_norm = 7.0975
	sim_grads_norm_tr = 0.0384
-- Starting training on experience 82 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3974
	data_grads_norm = 5.5708
	new_data_grads_norm = 9.5343
	old_data_grads_norm = 5.6656
	sim_grads_norm_tr = -0.0075
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8616
	data_grads_norm = 6.4826
	new_data_grads_norm = 9.0720
	old_data_grads_norm = 5.9679
	sim_grads_norm_tr = 0.0269
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8098
	data_grads_norm = 6.0848
	new_data_grads_norm = 9.2840
	old_data_grads_norm = 7.9375
	sim_grads_norm_tr = 0.0420
-- Starting training on experience 83 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4956
	data_grads_norm = 5.6217
	new_data_grads_norm = 10.4498
	old_data_grads_norm = 6.5714
	sim_grads_norm_tr = 0.0390
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5800
	data_grads_norm = 6.1273
	new_data_grads_norm = 10.4486
	old_data_grads_norm = 7.8815
	sim_grads_norm_tr = 0.0128
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2634
	data_grads_norm = 5.7282
	new_data_grads_norm = 9.6431
	old_data_grads_norm = 6.2222
	sim_grads_norm_tr = 0.0067
-- Starting training on experience 84 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0649
	data_grads_norm = 4.9765
	new_data_grads_norm = 8.1236
	old_data_grads_norm = 5.5716
	sim_grads_norm_tr = -0.0124
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0036
	data_grads_norm = 4.4901
	new_data_grads_norm = 7.3661
	old_data_grads_norm = 5.4964
	sim_grads_norm_tr = -0.0195
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2110
	data_grads_norm = 5.9628
	new_data_grads_norm = 8.7855
	old_data_grads_norm = 7.1939
	sim_grads_norm_tr = 0.0006
-- Starting training on experience 85 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2766
	data_grads_norm = 4.7906
	new_data_grads_norm = 6.7597
	old_data_grads_norm = 7.4108
	sim_grads_norm_tr = 0.0213
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2636
	data_grads_norm = 5.3905
	new_data_grads_norm = 7.0051
	old_data_grads_norm = 7.6925
	sim_grads_norm_tr = 0.0117
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1768
	data_grads_norm = 4.9203
	new_data_grads_norm = 6.8248
	old_data_grads_norm = 7.5571
	sim_grads_norm_tr = 0.0028
-- Starting training on experience 86 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7667
	data_grads_norm = 5.5800
	new_data_grads_norm = 8.8612
	old_data_grads_norm = 8.6399
	sim_grads_norm_tr = -0.0148
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4441
	data_grads_norm = 5.9280
	new_data_grads_norm = 9.2742
	old_data_grads_norm = 7.0474
	sim_grads_norm_tr = -0.0078
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3694
	data_grads_norm = 5.1441
	new_data_grads_norm = 8.8445
	old_data_grads_norm = 7.1982
	sim_grads_norm_tr = 0.0211
-- Starting training on experience 87 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9116
	data_grads_norm = 6.0095
	new_data_grads_norm = 10.0023
	old_data_grads_norm = 7.1334
	sim_grads_norm_tr = -0.0011
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5967
	data_grads_norm = 5.7189
	new_data_grads_norm = 9.8147
	old_data_grads_norm = 7.6859
	sim_grads_norm_tr = 0.0133
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6729
	data_grads_norm = 5.7757
	new_data_grads_norm = 10.4310
	old_data_grads_norm = 6.4977
	sim_grads_norm_tr = -0.0371
-- Starting training on experience 88 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7451
	data_grads_norm = 5.5209
	new_data_grads_norm = 8.0807
	old_data_grads_norm = 7.0474
	sim_grads_norm_tr = -0.0194
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7532
	data_grads_norm = 6.1272
	new_data_grads_norm = 8.8417
	old_data_grads_norm = 7.1522
	sim_grads_norm_tr = -0.0421
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5943
	data_grads_norm = 5.3759
	new_data_grads_norm = 9.6204
	old_data_grads_norm = 7.4568
	sim_grads_norm_tr = 0.0031
-- Starting training on experience 89 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5208
	data_grads_norm = 5.4154
	new_data_grads_norm = 7.9081
	old_data_grads_norm = 5.6534
	sim_grads_norm_tr = 0.0479
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7009
	data_grads_norm = 5.4889
	new_data_grads_norm = 8.3546
	old_data_grads_norm = 7.2442
	sim_grads_norm_tr = 0.0197
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6656
	data_grads_norm = 6.2629
	new_data_grads_norm = 8.3825
	old_data_grads_norm = 7.9006
	sim_grads_norm_tr = 0.0235
-- Starting training on experience 90 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0413
	data_grads_norm = 6.3671
	new_data_grads_norm = 8.3469
	old_data_grads_norm = 8.3815
	sim_grads_norm_tr = 0.0554
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3333
	data_grads_norm = 5.5492
	new_data_grads_norm = 9.2528
	old_data_grads_norm = 7.3363
	sim_grads_norm_tr = -0.0051
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2155
	data_grads_norm = 5.5700
	new_data_grads_norm = 8.9351
	old_data_grads_norm = 5.5554
	sim_grads_norm_tr = -0.0158
-- Starting training on experience 91 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8906
	data_grads_norm = 5.7455
	new_data_grads_norm = 8.1620
	old_data_grads_norm = 7.8577
	sim_grads_norm_tr = 0.0175
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6778
	data_grads_norm = 5.2134
	new_data_grads_norm = 7.9424
	old_data_grads_norm = 6.5061
	sim_grads_norm_tr = -0.0105
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7367
	data_grads_norm = 5.3670
	new_data_grads_norm = 7.2836
	old_data_grads_norm = 8.0918
	sim_grads_norm_tr = -0.0175
-- Starting training on experience 92 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7720
	data_grads_norm = 5.6182
	new_data_grads_norm = 7.6997
	old_data_grads_norm = 7.2330
	sim_grads_norm_tr = 0.0544
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2364
	data_grads_norm = 4.9556
	new_data_grads_norm = 7.7974
	old_data_grads_norm = 4.8473
	sim_grads_norm_tr = 0.0050
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5890
	data_grads_norm = 5.2543
	new_data_grads_norm = 8.2561
	old_data_grads_norm = 4.8926
	sim_grads_norm_tr = -0.0038
-- Starting training on experience 93 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3670
	data_grads_norm = 5.4863
	new_data_grads_norm = 7.7623
	old_data_grads_norm = 8.0751
	sim_grads_norm_tr = -0.0025
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6868
	data_grads_norm = 5.9346
	new_data_grads_norm = 7.4618
	old_data_grads_norm = 7.2024
	sim_grads_norm_tr = -0.0171
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5924
	data_grads_norm = 5.3895
	new_data_grads_norm = 7.4367
	old_data_grads_norm = 8.1717
	sim_grads_norm_tr = -0.0263
-- Starting training on experience 94 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2332
	data_grads_norm = 4.8900
	new_data_grads_norm = 7.7075
	old_data_grads_norm = 4.7729
	sim_grads_norm_tr = -0.0083
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6888
	data_grads_norm = 5.6657
	new_data_grads_norm = 7.8001
	old_data_grads_norm = 8.1347
	sim_grads_norm_tr = 0.0001
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1013
	data_grads_norm = 4.2430
	new_data_grads_norm = 7.1126
	old_data_grads_norm = 5.6422
	sim_grads_norm_tr = 0.0181
-- Starting training on experience 95 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2770
	data_grads_norm = 4.9187
	new_data_grads_norm = 8.4578
	old_data_grads_norm = 7.3854
	sim_grads_norm_tr = 0.0520
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3683
	data_grads_norm = 5.5591
	new_data_grads_norm = 8.6797
	old_data_grads_norm = 5.6989
	sim_grads_norm_tr = -0.0058
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3378
	data_grads_norm = 5.1338
	new_data_grads_norm = 8.3896
	old_data_grads_norm = 7.3356
	sim_grads_norm_tr = -0.0129
-- Starting training on experience 96 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7251
	data_grads_norm = 5.5003
	new_data_grads_norm = 9.8801
	old_data_grads_norm = 6.5794
	sim_grads_norm_tr = -0.0283
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5300
	data_grads_norm = 5.4919
	new_data_grads_norm = 8.4964
	old_data_grads_norm = 5.8548
	sim_grads_norm_tr = 0.0347
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8377
	data_grads_norm = 5.4803
	new_data_grads_norm = 9.1808
	old_data_grads_norm = 7.1063
	sim_grads_norm_tr = 0.0086
-- Starting training on experience 97 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4984
	data_grads_norm = 5.1168
	new_data_grads_norm = 8.5815
	old_data_grads_norm = 6.2486
	sim_grads_norm_tr = -0.0203
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9049
	data_grads_norm = 6.3425
	new_data_grads_norm = 8.0965
	old_data_grads_norm = 8.2960
	sim_grads_norm_tr = 0.0568
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1550
	data_grads_norm = 5.2561
	new_data_grads_norm = 7.8372
	old_data_grads_norm = 5.8958
	sim_grads_norm_tr = -0.0071
-- Starting training on experience 98 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6262
	data_grads_norm = 5.8578
	new_data_grads_norm = 9.2925
	old_data_grads_norm = 7.0318
	sim_grads_norm_tr = 0.0036
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9650
	data_grads_norm = 5.8848
	new_data_grads_norm = 9.2787
	old_data_grads_norm = 7.8837
	sim_grads_norm_tr = -0.0532
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7900
	data_grads_norm = 5.7692
	new_data_grads_norm = 9.4768
	old_data_grads_norm = 8.9301
	sim_grads_norm_tr = 0.0081
-- Starting training on experience 99 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2970
	data_grads_norm = 4.7183
	new_data_grads_norm = 8.1428
	old_data_grads_norm = 8.0510
	sim_grads_norm_tr = 0.0400
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3610
	data_grads_norm = 5.9834
	new_data_grads_norm = 9.2885
	old_data_grads_norm = 8.8142
	sim_grads_norm_tr = 0.0037
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5166
	data_grads_norm = 6.1798
	new_data_grads_norm = 7.5788
	old_data_grads_norm = 9.1567
	sim_grads_norm_tr = 0.0412
-- Starting training on experience 100 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4420
	data_grads_norm = 6.9103
	new_data_grads_norm = 10.4539
	old_data_grads_norm = 8.2536
	sim_grads_norm_tr = -0.0185
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3663
	data_grads_norm = 6.3678
	new_data_grads_norm = 10.0310
	old_data_grads_norm = 7.1723
	sim_grads_norm_tr = 0.0219
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6992
	data_grads_norm = 5.4151
	new_data_grads_norm = 9.6255
	old_data_grads_norm = 6.3828
	sim_grads_norm_tr = -0.0117
-- Starting training on experience 101 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5882
	data_grads_norm = 5.4726
	new_data_grads_norm = 9.6432
	old_data_grads_norm = 4.4491
	sim_grads_norm_tr = 0.0378
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8805
	data_grads_norm = 6.5462
	new_data_grads_norm = 9.5237
	old_data_grads_norm = 8.7038
	sim_grads_norm_tr = 0.0037
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7108
	data_grads_norm = 5.8658
	new_data_grads_norm = 9.7455
	old_data_grads_norm = 7.1516
	sim_grads_norm_tr = 0.0339
-- Starting training on experience 102 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9136
	data_grads_norm = 5.9961
	new_data_grads_norm = 8.9526
	old_data_grads_norm = 8.0681
	sim_grads_norm_tr = -0.0107
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3538
	data_grads_norm = 5.6790
	new_data_grads_norm = 9.9485
	old_data_grads_norm = 5.6034
	sim_grads_norm_tr = -0.0275
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3414
	data_grads_norm = 6.6024
	new_data_grads_norm = 9.3191
	old_data_grads_norm = 8.1531
	sim_grads_norm_tr = 0.0265
-- Starting training on experience 103 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0622
	data_grads_norm = 6.8187
	new_data_grads_norm = 8.1477
	old_data_grads_norm = 9.8836
	sim_grads_norm_tr = 0.0091
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4008
	data_grads_norm = 5.3932
	new_data_grads_norm = 8.1415
	old_data_grads_norm = 4.8606
	sim_grads_norm_tr = -0.0370
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4071
	data_grads_norm = 5.6412
	new_data_grads_norm = 8.2656
	old_data_grads_norm = 7.2729
	sim_grads_norm_tr = -0.0073
-- Starting training on experience 104 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6409
	data_grads_norm = 6.3564
	new_data_grads_norm = 8.4714
	old_data_grads_norm = 9.0369
	sim_grads_norm_tr = 0.0345
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0865
	data_grads_norm = 6.4139
	new_data_grads_norm = 7.5925
	old_data_grads_norm = 9.6810
	sim_grads_norm_tr = 0.0117
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1739
	data_grads_norm = 5.0890
	new_data_grads_norm = 8.3361
	old_data_grads_norm = 4.7546
	sim_grads_norm_tr = 0.0116
-- Starting training on experience 105 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7762
	data_grads_norm = 7.1830
	new_data_grads_norm = 10.5182
	old_data_grads_norm = 9.3287
	sim_grads_norm_tr = 0.0132
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3111
	data_grads_norm = 5.1546
	new_data_grads_norm = 8.9613
	old_data_grads_norm = 6.3368
	sim_grads_norm_tr = -0.0265
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4936
	data_grads_norm = 6.3766
	new_data_grads_norm = 8.7737
	old_data_grads_norm = 7.0353
	sim_grads_norm_tr = 0.0137
-- Starting training on experience 106 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2969
	data_grads_norm = 6.3157
	new_data_grads_norm = 10.6055
	old_data_grads_norm = 6.6637
	sim_grads_norm_tr = -0.0047
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7230
	data_grads_norm = 5.9356
	new_data_grads_norm = 10.0520
	old_data_grads_norm = 6.9195
	sim_grads_norm_tr = -0.0424
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1337
	data_grads_norm = 5.1876
	new_data_grads_norm = 8.9885
	old_data_grads_norm = 6.0783
	sim_grads_norm_tr = 0.0108
-- Starting training on experience 107 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4325
	data_grads_norm = 6.5027
	new_data_grads_norm = 10.0824
	old_data_grads_norm = 6.7484
	sim_grads_norm_tr = 0.0066
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0564
	data_grads_norm = 6.4263
	new_data_grads_norm = 10.5810
	old_data_grads_norm = 5.8422
	sim_grads_norm_tr = 0.0337
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9914
	data_grads_norm = 6.2619
	new_data_grads_norm = 8.3612
	old_data_grads_norm = 10.0577
	sim_grads_norm_tr = 0.0221
-- Starting training on experience 108 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8755
	data_grads_norm = 6.3485
	new_data_grads_norm = 8.7358
	old_data_grads_norm = 9.6169
	sim_grads_norm_tr = 0.0583
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4055
	data_grads_norm = 5.3673
	new_data_grads_norm = 8.7468
	old_data_grads_norm = 7.6612
	sim_grads_norm_tr = 0.0157
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6587
	data_grads_norm = 5.7527
	new_data_grads_norm = 8.3125
	old_data_grads_norm = 7.2994
	sim_grads_norm_tr = 0.0107
-- Starting training on experience 109 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4887
	data_grads_norm = 5.1942
	new_data_grads_norm = 7.5533
	old_data_grads_norm = 7.1776
	sim_grads_norm_tr = -0.0024
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2005
	data_grads_norm = 4.4724
	new_data_grads_norm = 6.9574
	old_data_grads_norm = 5.2636
	sim_grads_norm_tr = -0.0009
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5223
	data_grads_norm = 5.4136
	new_data_grads_norm = 8.0127
	old_data_grads_norm = 5.2154
	sim_grads_norm_tr = 0.0623
-- Starting training on experience 110 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3915
	data_grads_norm = 4.7489
	new_data_grads_norm = 8.2545
	old_data_grads_norm = 5.3392
	sim_grads_norm_tr = -0.0269
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5082
	data_grads_norm = 5.8348
	new_data_grads_norm = 7.9961
	old_data_grads_norm = 7.0794
	sim_grads_norm_tr = -0.0329
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4278
	data_grads_norm = 5.0801
	new_data_grads_norm = 8.5620
	old_data_grads_norm = 6.0043
	sim_grads_norm_tr = -0.0465
-- Starting training on experience 111 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9818
	data_grads_norm = 7.3233
	new_data_grads_norm = 11.0966
	old_data_grads_norm = 8.3096
	sim_grads_norm_tr = 0.0028
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1247
	data_grads_norm = 6.3253
	new_data_grads_norm = 10.3254
	old_data_grads_norm = 6.5586
	sim_grads_norm_tr = 0.0586
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0972
	data_grads_norm = 6.5293
	new_data_grads_norm = 10.8261
	old_data_grads_norm = 6.2400
	sim_grads_norm_tr = -0.0177
-- Starting training on experience 112 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9250
	data_grads_norm = 5.1012
	new_data_grads_norm = 8.7887
	old_data_grads_norm = 3.8127
	sim_grads_norm_tr = -0.0121
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2472
	data_grads_norm = 5.5559
	new_data_grads_norm = 9.9316
	old_data_grads_norm = 5.3766
	sim_grads_norm_tr = -0.0208
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4315
	data_grads_norm = 6.2204
	new_data_grads_norm = 10.2854
	old_data_grads_norm = 7.9765
	sim_grads_norm_tr = 0.0142
-- Starting training on experience 113 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0754
	data_grads_norm = 5.6323
	new_data_grads_norm = 9.0239
	old_data_grads_norm = 6.0834
	sim_grads_norm_tr = -0.0197
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5028
	data_grads_norm = 5.6596
	new_data_grads_norm = 8.7300
	old_data_grads_norm = 6.2328
	sim_grads_norm_tr = -0.0186
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2553
	data_grads_norm = 6.0212
	new_data_grads_norm = 9.1687
	old_data_grads_norm = 8.0689
	sim_grads_norm_tr = 0.0092
-- Starting training on experience 114 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4432
	data_grads_norm = 6.4262
	new_data_grads_norm = 9.9032
	old_data_grads_norm = 6.3089
	sim_grads_norm_tr = 0.0456
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4142
	data_grads_norm = 6.1189
	new_data_grads_norm = 7.8152
	old_data_grads_norm = 8.2441
	sim_grads_norm_tr = 0.0049
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5812
	data_grads_norm = 6.1016
	new_data_grads_norm = 8.2297
	old_data_grads_norm = 8.1968
	sim_grads_norm_tr = -0.0467
-- Starting training on experience 115 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1166
	data_grads_norm = 5.6012
	new_data_grads_norm = 8.2684
	old_data_grads_norm = 5.7831
	sim_grads_norm_tr = 0.0676
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6567
	data_grads_norm = 5.9083
	new_data_grads_norm = 8.6806
	old_data_grads_norm = 8.0952
	sim_grads_norm_tr = -0.0091
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8299
	data_grads_norm = 6.3491
	new_data_grads_norm = 8.9952
	old_data_grads_norm = 8.0213
	sim_grads_norm_tr = 0.0248
-- Starting training on experience 116 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1759
	data_grads_norm = 5.7686
	new_data_grads_norm = 10.7095
	old_data_grads_norm = 4.2295
	sim_grads_norm_tr = -0.0034
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6816
	data_grads_norm = 6.3972
	new_data_grads_norm = 11.1936
	old_data_grads_norm = 6.4372
	sim_grads_norm_tr = -0.0139
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9971
	data_grads_norm = 6.7604
	new_data_grads_norm = 10.6576
	old_data_grads_norm = 7.3266
	sim_grads_norm_tr = 0.0578
-- Starting training on experience 117 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1568
	data_grads_norm = 5.0568
	new_data_grads_norm = 8.1380
	old_data_grads_norm = 5.9811
	sim_grads_norm_tr = -0.0396
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4311
	data_grads_norm = 5.7876
	new_data_grads_norm = 8.7324
	old_data_grads_norm = 7.2894
	sim_grads_norm_tr = -0.0254
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9463
	data_grads_norm = 5.0942
	new_data_grads_norm = 8.4100
	old_data_grads_norm = 7.6955
	sim_grads_norm_tr = -0.0013
-- Starting training on experience 118 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7584
	data_grads_norm = 6.5413
	new_data_grads_norm = 8.7501
	old_data_grads_norm = 9.4049
	sim_grads_norm_tr = -0.0057
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5426
	data_grads_norm = 5.9313
	new_data_grads_norm = 9.5489
	old_data_grads_norm = 7.0256
	sim_grads_norm_tr = 0.0010
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4757
	data_grads_norm = 5.8722
	new_data_grads_norm = 9.2983
	old_data_grads_norm = 5.0517
	sim_grads_norm_tr = -0.0076
-- Starting training on experience 119 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0426
	data_grads_norm = 6.0859
	new_data_grads_norm = 9.3019
	old_data_grads_norm = 8.7206
	sim_grads_norm_tr = 0.0102
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4828
	data_grads_norm = 4.9432
	new_data_grads_norm = 8.0510
	old_data_grads_norm = 5.4548
	sim_grads_norm_tr = -0.0080
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2347
	data_grads_norm = 4.9480
	new_data_grads_norm = 8.8950
	old_data_grads_norm = 6.5642
	sim_grads_norm_tr = 0.0194
-- Starting training on experience 120 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8311
	data_grads_norm = 6.7298
	new_data_grads_norm = 8.7689
	old_data_grads_norm = 7.6333
	sim_grads_norm_tr = 0.0419
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1805
	data_grads_norm = 5.3520
	new_data_grads_norm = 8.6030
	old_data_grads_norm = 5.1857
	sim_grads_norm_tr = 0.0346
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7596
	data_grads_norm = 6.2483
	new_data_grads_norm = 8.0920
	old_data_grads_norm = 8.9989
	sim_grads_norm_tr = 0.0102
-- Starting training on experience 121 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8698
	data_grads_norm = 6.1062
	new_data_grads_norm = 9.2064
	old_data_grads_norm = 8.2960
	sim_grads_norm_tr = -0.0060
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4054
	data_grads_norm = 5.1682
	new_data_grads_norm = 9.4788
	old_data_grads_norm = 7.1853
	sim_grads_norm_tr = 0.0157
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4125
	data_grads_norm = 4.7931
	new_data_grads_norm = 9.2846
	old_data_grads_norm = 5.2839
	sim_grads_norm_tr = -0.0317
-- Starting training on experience 122 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9009
	data_grads_norm = 4.3166
	new_data_grads_norm = 7.4118
	old_data_grads_norm = 6.3148
	sim_grads_norm_tr = -0.0241
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3111
	data_grads_norm = 5.3743
	new_data_grads_norm = 7.9934
	old_data_grads_norm = 6.4667
	sim_grads_norm_tr = -0.0099
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2698
	data_grads_norm = 5.2564
	new_data_grads_norm = 8.3279
	old_data_grads_norm = 5.7610
	sim_grads_norm_tr = -0.0567
-- Starting training on experience 123 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2444
	data_grads_norm = 5.7541
	new_data_grads_norm = 9.3750
	old_data_grads_norm = 5.6312
	sim_grads_norm_tr = -0.0008
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8306
	data_grads_norm = 5.8979
	new_data_grads_norm = 9.0150
	old_data_grads_norm = 6.4727
	sim_grads_norm_tr = 0.1224
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2182
	data_grads_norm = 6.1360
	new_data_grads_norm = 8.6637
	old_data_grads_norm = 8.7740
	sim_grads_norm_tr = -0.0157
-- Starting training on experience 124 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6469
	data_grads_norm = 5.6901
	new_data_grads_norm = 8.5629
	old_data_grads_norm = 6.3158
	sim_grads_norm_tr = -0.0008
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4285
	data_grads_norm = 4.9873
	new_data_grads_norm = 7.6024
	old_data_grads_norm = 5.2342
	sim_grads_norm_tr = -0.0191
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2566
	data_grads_norm = 4.8526
	new_data_grads_norm = 6.7300
	old_data_grads_norm = 5.5047
	sim_grads_norm_tr = -0.0228
-- Starting training on experience 125 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3862
	data_grads_norm = 5.7727
	new_data_grads_norm = 8.6551
	old_data_grads_norm = 7.9641
	sim_grads_norm_tr = -0.0040
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5778
	data_grads_norm = 5.0059
	new_data_grads_norm = 8.2270
	old_data_grads_norm = 6.1133
	sim_grads_norm_tr = -0.0193
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7473
	data_grads_norm = 5.9688
	new_data_grads_norm = 8.1415
	old_data_grads_norm = 6.4359
	sim_grads_norm_tr = 0.0200
-- Starting training on experience 126 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5207
	data_grads_norm = 6.9044
	new_data_grads_norm = 8.9724
	old_data_grads_norm = 9.2133
	sim_grads_norm_tr = 0.0207
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9139
	data_grads_norm = 6.3086
	new_data_grads_norm = 8.5316
	old_data_grads_norm = 7.1323
	sim_grads_norm_tr = 0.2092
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1715
	data_grads_norm = 5.5698
	new_data_grads_norm = 8.7992
	old_data_grads_norm = 6.2004
	sim_grads_norm_tr = -0.0335
-- Starting training on experience 127 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0239
	data_grads_norm = 5.2485
	new_data_grads_norm = 8.7096
	old_data_grads_norm = 5.9874
	sim_grads_norm_tr = -0.0193
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0910
	data_grads_norm = 5.2548
	new_data_grads_norm = 8.0909
	old_data_grads_norm = 5.1420
	sim_grads_norm_tr = 0.1048
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9289
	data_grads_norm = 5.0890
	new_data_grads_norm = 8.3883
	old_data_grads_norm = 7.2320
	sim_grads_norm_tr = 0.0086
-- Starting training on experience 128 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5766
	data_grads_norm = 4.8214
	new_data_grads_norm = 7.6842
	old_data_grads_norm = 5.4252
	sim_grads_norm_tr = 0.0517
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1521
	data_grads_norm = 4.9782
	new_data_grads_norm = 7.8562
	old_data_grads_norm = 6.0149
	sim_grads_norm_tr = -0.0090
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3267
	data_grads_norm = 4.8573
	new_data_grads_norm = 7.9216
	old_data_grads_norm = 5.7036
	sim_grads_norm_tr = -0.0247
-- Starting training on experience 129 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6630
	data_grads_norm = 6.2385
	new_data_grads_norm = 8.4858
	old_data_grads_norm = 8.0840
	sim_grads_norm_tr = -0.0147
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3368
	data_grads_norm = 5.2614
	new_data_grads_norm = 8.7852
	old_data_grads_norm = 6.8250
	sim_grads_norm_tr = 0.0146
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5311
	data_grads_norm = 5.9894
	new_data_grads_norm = 8.8794
	old_data_grads_norm = 8.5485
	sim_grads_norm_tr = -0.0271
-- Starting training on experience 130 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3522
	data_grads_norm = 5.6481
	new_data_grads_norm = 8.4141
	old_data_grads_norm = 7.0285
	sim_grads_norm_tr = 0.0115
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6719
	data_grads_norm = 6.4119
	new_data_grads_norm = 8.3250
	old_data_grads_norm = 7.8396
	sim_grads_norm_tr = -0.0101
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5101
	data_grads_norm = 5.9408
	new_data_grads_norm = 8.9561
	old_data_grads_norm = 5.8326
	sim_grads_norm_tr = -0.0061
-- Starting training on experience 131 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1901
	data_grads_norm = 5.1441
	new_data_grads_norm = 9.0635
	old_data_grads_norm = 5.0583
	sim_grads_norm_tr = -0.0130
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3692
	data_grads_norm = 5.3646
	new_data_grads_norm = 9.6416
	old_data_grads_norm = 4.8721
	sim_grads_norm_tr = -0.0088
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3619
	data_grads_norm = 5.2907
	new_data_grads_norm = 8.0949
	old_data_grads_norm = 5.0617
	sim_grads_norm_tr = 0.0152
-- Starting training on experience 132 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1554
	data_grads_norm = 5.9823
	new_data_grads_norm = 9.0567
	old_data_grads_norm = 7.2452
	sim_grads_norm_tr = 0.0229
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4520
	data_grads_norm = 5.6799
	new_data_grads_norm = 9.2458
	old_data_grads_norm = 7.4955
	sim_grads_norm_tr = -0.0061
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7433
	data_grads_norm = 6.4097
	new_data_grads_norm = 9.6546
	old_data_grads_norm = 7.8800
	sim_grads_norm_tr = 0.1474
-- Starting training on experience 133 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1748
	data_grads_norm = 6.4705
	new_data_grads_norm = 7.4095
	old_data_grads_norm = 10.3410
	sim_grads_norm_tr = 0.0069
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0202
	data_grads_norm = 5.0307
	new_data_grads_norm = 7.6566
	old_data_grads_norm = 6.2084
	sim_grads_norm_tr = -0.0033
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2385
	data_grads_norm = 6.0573
	new_data_grads_norm = 7.8207
	old_data_grads_norm = 8.2297
	sim_grads_norm_tr = -0.0380
-- Starting training on experience 134 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7465
	data_grads_norm = 5.7833
	new_data_grads_norm = 9.7255
	old_data_grads_norm = 5.4684
	sim_grads_norm_tr = -0.0017
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7951
	data_grads_norm = 5.5505
	new_data_grads_norm = 8.6968
	old_data_grads_norm = 9.3527
	sim_grads_norm_tr = -0.0300
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4085
	data_grads_norm = 5.8343
	new_data_grads_norm = 8.8360
	old_data_grads_norm = 7.8369
	sim_grads_norm_tr = 0.0405
-- Starting training on experience 135 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1505
	data_grads_norm = 5.3501
	new_data_grads_norm = 8.9114
	old_data_grads_norm = 5.1303
	sim_grads_norm_tr = -0.0038
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1033
	data_grads_norm = 6.0126
	new_data_grads_norm = 9.0086
	old_data_grads_norm = 7.1735
	sim_grads_norm_tr = -0.0079
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6001
	data_grads_norm = 5.8642
	new_data_grads_norm = 8.3132
	old_data_grads_norm = 7.1757
	sim_grads_norm_tr = 0.0482
-- Starting training on experience 136 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1880
	data_grads_norm = 4.3520
	new_data_grads_norm = 8.8363
	old_data_grads_norm = 5.3298
	sim_grads_norm_tr = -0.0227
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1038
	data_grads_norm = 5.4695
	new_data_grads_norm = 8.6284
	old_data_grads_norm = 6.9747
	sim_grads_norm_tr = -0.0299
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4144
	data_grads_norm = 4.9167
	new_data_grads_norm = 9.4948
	old_data_grads_norm = 4.5545
	sim_grads_norm_tr = 0.0323
-- Starting training on experience 137 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2844
	data_grads_norm = 5.6486
	new_data_grads_norm = 8.6006
	old_data_grads_norm = 7.7506
	sim_grads_norm_tr = 0.0261
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1541
	data_grads_norm = 5.1860
	new_data_grads_norm = 8.8937
	old_data_grads_norm = 7.6936
	sim_grads_norm_tr = -0.0116
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9489
	data_grads_norm = 5.2931
	new_data_grads_norm = 9.3319
	old_data_grads_norm = 7.1017
	sim_grads_norm_tr = -0.0277
-- Starting training on experience 138 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2309
	data_grads_norm = 5.6370
	new_data_grads_norm = 9.5997
	old_data_grads_norm = 5.4847
	sim_grads_norm_tr = -0.0024
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4506
	data_grads_norm = 6.4446
	new_data_grads_norm = 9.6022
	old_data_grads_norm = 6.3237
	sim_grads_norm_tr = 0.0010
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5648
	data_grads_norm = 6.6877
	new_data_grads_norm = 9.4910
	old_data_grads_norm = 5.7848
	sim_grads_norm_tr = 0.0019
-- Starting training on experience 139 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1632
	data_grads_norm = 5.7394
	new_data_grads_norm = 7.8474
	old_data_grads_norm = 9.1584
	sim_grads_norm_tr = 0.0320
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7475
	data_grads_norm = 5.7136
	new_data_grads_norm = 8.5376
	old_data_grads_norm = 6.3231
	sim_grads_norm_tr = 0.0598
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3229
	data_grads_norm = 5.3226
	new_data_grads_norm = 8.0716
	old_data_grads_norm = 7.6179
	sim_grads_norm_tr = 0.0083
-- Starting training on experience 140 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1363
	data_grads_norm = 4.9539
	new_data_grads_norm = 7.7807
	old_data_grads_norm = 6.6744
	sim_grads_norm_tr = 0.0825
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9683
	data_grads_norm = 4.3774
	new_data_grads_norm = 7.1373
	old_data_grads_norm = 6.6922
	sim_grads_norm_tr = 0.0023
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5660
	data_grads_norm = 5.3434
	new_data_grads_norm = 7.9891
	old_data_grads_norm = 6.6373
	sim_grads_norm_tr = 0.0709
-- Starting training on experience 141 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4830
	data_grads_norm = 5.4329
	new_data_grads_norm = 9.8238
	old_data_grads_norm = 6.0723
	sim_grads_norm_tr = 0.0082
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9543
	data_grads_norm = 6.2637
	new_data_grads_norm = 9.2506
	old_data_grads_norm = 8.3747
	sim_grads_norm_tr = 0.0085
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6047
	data_grads_norm = 5.3542
	new_data_grads_norm = 10.1236
	old_data_grads_norm = 6.4235
	sim_grads_norm_tr = 0.0051
-- Starting training on experience 142 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6185
	data_grads_norm = 6.0372
	new_data_grads_norm = 9.1514
	old_data_grads_norm = 7.5921
	sim_grads_norm_tr = 0.0128
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4589
	data_grads_norm = 5.9949
	new_data_grads_norm = 10.1836
	old_data_grads_norm = 6.4756
	sim_grads_norm_tr = 0.0050
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7821
	data_grads_norm = 6.0814
	new_data_grads_norm = 9.4090
	old_data_grads_norm = 6.9599
	sim_grads_norm_tr = 0.0658
-- Starting training on experience 143 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2310
	data_grads_norm = 4.5504
	new_data_grads_norm = 7.7465
	old_data_grads_norm = 4.1886
	sim_grads_norm_tr = -0.0114
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3162
	data_grads_norm = 4.8102
	new_data_grads_norm = 7.6331
	old_data_grads_norm = 6.9974
	sim_grads_norm_tr = 0.0711
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0700
	data_grads_norm = 4.8153
	new_data_grads_norm = 7.5135
	old_data_grads_norm = 4.0365
	sim_grads_norm_tr = -0.0103
-- Starting training on experience 144 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6265
	data_grads_norm = 6.1828
	new_data_grads_norm = 10.0846
	old_data_grads_norm = 5.5392
	sim_grads_norm_tr = 0.0015
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4529
	data_grads_norm = 5.1678
	new_data_grads_norm = 9.1814
	old_data_grads_norm = 6.9587
	sim_grads_norm_tr = 0.0003
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5372
	data_grads_norm = 5.4153
	new_data_grads_norm = 8.7697
	old_data_grads_norm = 5.7927
	sim_grads_norm_tr = 0.0394
-- Starting training on experience 145 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1250
	data_grads_norm = 5.5460
	new_data_grads_norm = 9.7838
	old_data_grads_norm = 5.7723
	sim_grads_norm_tr = -0.0126
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3150
	data_grads_norm = 5.9574
	new_data_grads_norm = 9.3946
	old_data_grads_norm = 7.9421
	sim_grads_norm_tr = 0.0027
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5772
	data_grads_norm = 6.2695
	new_data_grads_norm = 10.1121
	old_data_grads_norm = 7.9861
	sim_grads_norm_tr = -0.0238
-- Starting training on experience 146 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9308
	data_grads_norm = 7.2275
	new_data_grads_norm = 7.4035
	old_data_grads_norm = 11.9780
	sim_grads_norm_tr = 0.0108
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1360
	data_grads_norm = 5.1908
	new_data_grads_norm = 8.0185
	old_data_grads_norm = 7.7855
	sim_grads_norm_tr = -0.0379
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7078
	data_grads_norm = 5.0274
	new_data_grads_norm = 8.0358
	old_data_grads_norm = 6.9226
	sim_grads_norm_tr = 0.0044
-- Starting training on experience 147 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4167
	data_grads_norm = 5.4366
	new_data_grads_norm = 9.0528
	old_data_grads_norm = 4.7406
	sim_grads_norm_tr = 0.0484
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1477
	data_grads_norm = 5.1680
	new_data_grads_norm = 10.0929
	old_data_grads_norm = 7.6336
	sim_grads_norm_tr = -0.0158
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3484
	data_grads_norm = 5.1832
	new_data_grads_norm = 9.0535
	old_data_grads_norm = 5.5186
	sim_grads_norm_tr = 0.0000
-- Starting training on experience 148 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8384
	data_grads_norm = 6.5693
	new_data_grads_norm = 9.6419
	old_data_grads_norm = 8.1429
	sim_grads_norm_tr = 0.0497
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3518
	data_grads_norm = 5.6016
	new_data_grads_norm = 8.4636
	old_data_grads_norm = 5.8767
	sim_grads_norm_tr = 0.0129
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1612
	data_grads_norm = 4.6684
	new_data_grads_norm = 8.0753
	old_data_grads_norm = 5.5932
	sim_grads_norm_tr = 0.0140
-- Starting training on experience 149 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6352
	data_grads_norm = 5.3247
	new_data_grads_norm = 8.2677
	old_data_grads_norm = 5.1415
	sim_grads_norm_tr = -0.0104
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5543
	data_grads_norm = 5.8466
	new_data_grads_norm = 9.0924
	old_data_grads_norm = 6.2087
	sim_grads_norm_tr = -0.0153
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8685
	data_grads_norm = 5.7171
	new_data_grads_norm = 8.3818
	old_data_grads_norm = 8.2908
	sim_grads_norm_tr = 0.0191
-- Starting training on experience 150 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0039
	data_grads_norm = 5.9522
	new_data_grads_norm = 8.5271
	old_data_grads_norm = 5.2107
	sim_grads_norm_tr = -0.0091
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2953
	data_grads_norm = 5.7413
	new_data_grads_norm = 8.3943
	old_data_grads_norm = 6.2743
	sim_grads_norm_tr = -0.0081
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5843
	data_grads_norm = 5.8270
	new_data_grads_norm = 9.1340
	old_data_grads_norm = 6.3287
	sim_grads_norm_tr = 0.0199
-- Starting training on experience 151 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9339
	data_grads_norm = 5.2929
	new_data_grads_norm = 8.2919
	old_data_grads_norm = 6.4343
	sim_grads_norm_tr = -0.0176
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9510
	data_grads_norm = 7.1534
	new_data_grads_norm = 8.0955
	old_data_grads_norm = 9.5432
	sim_grads_norm_tr = 0.0979
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8275
	data_grads_norm = 5.2386
	new_data_grads_norm = 7.1614
	old_data_grads_norm = 4.0697
	sim_grads_norm_tr = 0.0279
-- Starting training on experience 152 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6661
	data_grads_norm = 5.3862
	new_data_grads_norm = 9.7653
	old_data_grads_norm = 5.1445
	sim_grads_norm_tr = 0.0239
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4230
	data_grads_norm = 5.5523
	new_data_grads_norm = 8.9341
	old_data_grads_norm = 7.4828
	sim_grads_norm_tr = 0.0368
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6346
	data_grads_norm = 6.4385
	new_data_grads_norm = 9.6617
	old_data_grads_norm = 8.0334
	sim_grads_norm_tr = 0.0329
-- Starting training on experience 153 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1383
	data_grads_norm = 5.2719
	new_data_grads_norm = 8.8651
	old_data_grads_norm = 5.5425
	sim_grads_norm_tr = 0.0298
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0908
	data_grads_norm = 4.9138
	new_data_grads_norm = 9.6944
	old_data_grads_norm = 4.1800
	sim_grads_norm_tr = -0.0305
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7735
	data_grads_norm = 5.7750
	new_data_grads_norm = 9.3844
	old_data_grads_norm = 6.5424
	sim_grads_norm_tr = 0.0492
-- Starting training on experience 154 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0034
	data_grads_norm = 5.1625
	new_data_grads_norm = 7.4785
	old_data_grads_norm = 7.4566
	sim_grads_norm_tr = -0.0096
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9856
	data_grads_norm = 4.7986
	new_data_grads_norm = 8.3238
	old_data_grads_norm = 5.9524
	sim_grads_norm_tr = -0.0231
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0580
	data_grads_norm = 4.5726
	new_data_grads_norm = 7.4571
	old_data_grads_norm = 5.6871
	sim_grads_norm_tr = -0.0204
-- Starting training on experience 155 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2395
	data_grads_norm = 5.7287
	new_data_grads_norm = 8.2429
	old_data_grads_norm = 7.3484
	sim_grads_norm_tr = 0.0360
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2653
	data_grads_norm = 5.3455
	new_data_grads_norm = 7.4829
	old_data_grads_norm = 6.6797
	sim_grads_norm_tr = -0.0236
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1232
	data_grads_norm = 5.8393
	new_data_grads_norm = 8.1006
	old_data_grads_norm = 7.2831
	sim_grads_norm_tr = 0.0052
-- Starting training on experience 156 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1934
	data_grads_norm = 5.6763
	new_data_grads_norm = 8.8001
	old_data_grads_norm = 10.2283
	sim_grads_norm_tr = 0.0219
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2157
	data_grads_norm = 5.6663
	new_data_grads_norm = 7.6862
	old_data_grads_norm = 8.0560
	sim_grads_norm_tr = 0.0143
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7644
	data_grads_norm = 4.9605
	new_data_grads_norm = 8.5072
	old_data_grads_norm = 7.5897
	sim_grads_norm_tr = 0.0252
-- Starting training on experience 157 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0996
	data_grads_norm = 5.1597
	new_data_grads_norm = 7.3554
	old_data_grads_norm = 7.7780
	sim_grads_norm_tr = -0.0175
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5360
	data_grads_norm = 6.1977
	new_data_grads_norm = 8.0365
	old_data_grads_norm = 8.4266
	sim_grads_norm_tr = 0.0285
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7085
	data_grads_norm = 4.5452
	new_data_grads_norm = 8.1263
	old_data_grads_norm = 5.9683
	sim_grads_norm_tr = -0.0418
-- Starting training on experience 158 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3665
	data_grads_norm = 4.6668
	new_data_grads_norm = 8.6599
	old_data_grads_norm = 4.9828
	sim_grads_norm_tr = -0.0225
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0405
	data_grads_norm = 6.1392
	new_data_grads_norm = 8.7461
	old_data_grads_norm = 10.4209
	sim_grads_norm_tr = -0.0211
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1984
	data_grads_norm = 4.8924
	new_data_grads_norm = 9.1367
	old_data_grads_norm = 6.6881
	sim_grads_norm_tr = -0.0531
-- Starting training on experience 159 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8916
	data_grads_norm = 4.3328
	new_data_grads_norm = 7.8682
	old_data_grads_norm = 6.5712
	sim_grads_norm_tr = -0.0062
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0849
	data_grads_norm = 5.4383
	new_data_grads_norm = 8.6147
	old_data_grads_norm = 7.1725
	sim_grads_norm_tr = -0.0015
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1213
	data_grads_norm = 4.7615
	new_data_grads_norm = 8.2487
	old_data_grads_norm = 4.9392
	sim_grads_norm_tr = 0.0016
-- Starting training on experience 160 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3284
	data_grads_norm = 5.6152
	new_data_grads_norm = 9.3113
	old_data_grads_norm = 8.1677
	sim_grads_norm_tr = 0.0044
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5774
	data_grads_norm = 6.2085
	new_data_grads_norm = 10.3204
	old_data_grads_norm = 7.0916
	sim_grads_norm_tr = 0.0492
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2443
	data_grads_norm = 6.2458
	new_data_grads_norm = 9.2367
	old_data_grads_norm = 7.7832
	sim_grads_norm_tr = -0.0094
-- Starting training on experience 161 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2383
	data_grads_norm = 5.8885
	new_data_grads_norm = 8.7242
	old_data_grads_norm = 8.6036
	sim_grads_norm_tr = -0.0102
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8145
	data_grads_norm = 4.5597
	new_data_grads_norm = 9.1305
	old_data_grads_norm = 5.0309
	sim_grads_norm_tr = -0.0408
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5728
	data_grads_norm = 5.8824
	new_data_grads_norm = 8.9527
	old_data_grads_norm = 7.1304
	sim_grads_norm_tr = -0.0071
-- Starting training on experience 162 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5306
	data_grads_norm = 5.9769
	new_data_grads_norm = 10.1199
	old_data_grads_norm = 4.9410
	sim_grads_norm_tr = -0.0363
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1272
	data_grads_norm = 6.9628
	new_data_grads_norm = 9.3910
	old_data_grads_norm = 8.6739
	sim_grads_norm_tr = 0.0069
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4958
	data_grads_norm = 5.8005
	new_data_grads_norm = 8.9842
	old_data_grads_norm = 4.8372
	sim_grads_norm_tr = 0.0389
-- Starting training on experience 163 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8291
	data_grads_norm = 7.4203
	new_data_grads_norm = 8.4629
	old_data_grads_norm = 9.9045
	sim_grads_norm_tr = -0.0139
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5992
	data_grads_norm = 6.5849
	new_data_grads_norm = 11.6341
	old_data_grads_norm = 7.0995
	sim_grads_norm_tr = -0.0237
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8131
	data_grads_norm = 7.1965
	new_data_grads_norm = 10.7230
	old_data_grads_norm = 7.4010
	sim_grads_norm_tr = 0.0236
-- Starting training on experience 164 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5002
	data_grads_norm = 5.3697
	new_data_grads_norm = 8.4222
	old_data_grads_norm = 6.3532
	sim_grads_norm_tr = 0.0126
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6451
	data_grads_norm = 5.7515
	new_data_grads_norm = 9.9054
	old_data_grads_norm = 4.8954
	sim_grads_norm_tr = 0.0298
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4554
	data_grads_norm = 4.7097
	new_data_grads_norm = 8.2013
	old_data_grads_norm = 3.2147
	sim_grads_norm_tr = 0.0535
-- Starting training on experience 165 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7453
	data_grads_norm = 5.5749
	new_data_grads_norm = 8.9191
	old_data_grads_norm = 6.0682
	sim_grads_norm_tr = 0.0191
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5282
	data_grads_norm = 5.1308
	new_data_grads_norm = 8.5748
	old_data_grads_norm = 5.9267
	sim_grads_norm_tr = -0.0096
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1288
	data_grads_norm = 4.5376
	new_data_grads_norm = 7.6903
	old_data_grads_norm = 6.7301
	sim_grads_norm_tr = -0.0140
-- Starting training on experience 166 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3742
	data_grads_norm = 5.6346
	new_data_grads_norm = 8.8769
	old_data_grads_norm = 8.6154
	sim_grads_norm_tr = 0.0350
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0387
	data_grads_norm = 4.5812
	new_data_grads_norm = 8.0223
	old_data_grads_norm = 5.1740
	sim_grads_norm_tr = -0.0287
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8231
	data_grads_norm = 4.8494
	new_data_grads_norm = 8.2861
	old_data_grads_norm = 5.8032
	sim_grads_norm_tr = 0.0280
-- Starting training on experience 167 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6108
	data_grads_norm = 5.6779
	new_data_grads_norm = 9.8240
	old_data_grads_norm = 4.5456
	sim_grads_norm_tr = 0.0153
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5103
	data_grads_norm = 5.4794
	new_data_grads_norm = 9.3460
	old_data_grads_norm = 4.7151
	sim_grads_norm_tr = -0.0400
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6862
	data_grads_norm = 5.8550
	new_data_grads_norm = 9.2232
	old_data_grads_norm = 7.3687
	sim_grads_norm_tr = -0.0027
-- Starting training on experience 168 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0934
	data_grads_norm = 4.6318
	new_data_grads_norm = 7.9064
	old_data_grads_norm = 5.2131
	sim_grads_norm_tr = 0.0035
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2357
	data_grads_norm = 5.2691
	new_data_grads_norm = 7.5679
	old_data_grads_norm = 6.4529
	sim_grads_norm_tr = -0.0132
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1956
	data_grads_norm = 4.7520
	new_data_grads_norm = 8.0051
	old_data_grads_norm = 4.6191
	sim_grads_norm_tr = -0.0428
-- Starting training on experience 169 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6960
	data_grads_norm = 6.2749
	new_data_grads_norm = 8.3953
	old_data_grads_norm = 8.3581
	sim_grads_norm_tr = 0.0033
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3825
	data_grads_norm = 5.1624
	new_data_grads_norm = 8.2132
	old_data_grads_norm = 6.2672
	sim_grads_norm_tr = 0.0281
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6142
	data_grads_norm = 6.1855
	new_data_grads_norm = 8.3669
	old_data_grads_norm = 7.5340
	sim_grads_norm_tr = 0.0265
-- Starting training on experience 170 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4915
	data_grads_norm = 6.3236
	new_data_grads_norm = 8.1678
	old_data_grads_norm = 8.0378
	sim_grads_norm_tr = -0.0400
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1617
	data_grads_norm = 5.7948
	new_data_grads_norm = 9.1263
	old_data_grads_norm = 5.2887
	sim_grads_norm_tr = 0.0041
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3504
	data_grads_norm = 6.6237
	new_data_grads_norm = 8.7397
	old_data_grads_norm = 8.0332
	sim_grads_norm_tr = -0.0180
-- Starting training on experience 171 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4790
	data_grads_norm = 6.0547
	new_data_grads_norm = 8.5951
	old_data_grads_norm = 11.3382
	sim_grads_norm_tr = 0.0004
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0120
	data_grads_norm = 4.7962
	new_data_grads_norm = 7.8363
	old_data_grads_norm = 5.8089
	sim_grads_norm_tr = -0.0033
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6946
	data_grads_norm = 5.8426
	new_data_grads_norm = 8.3168
	old_data_grads_norm = 8.7708
	sim_grads_norm_tr = 0.0086
-- Starting training on experience 172 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2007
	data_grads_norm = 5.1257
	new_data_grads_norm = 9.0481
	old_data_grads_norm = 6.0995
	sim_grads_norm_tr = -0.0059
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7123
	data_grads_norm = 6.1169
	new_data_grads_norm = 9.0969
	old_data_grads_norm = 7.6875
	sim_grads_norm_tr = 0.0197
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3971
	data_grads_norm = 5.8458
	new_data_grads_norm = 8.7689
	old_data_grads_norm = 8.0607
	sim_grads_norm_tr = 0.0168
-- Starting training on experience 173 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7429
	data_grads_norm = 5.6280
	new_data_grads_norm = 8.9368
	old_data_grads_norm = 6.5133
	sim_grads_norm_tr = -0.0132
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8567
	data_grads_norm = 5.7914
	new_data_grads_norm = 8.2193
	old_data_grads_norm = 7.6785
	sim_grads_norm_tr = 0.0507
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7302
	data_grads_norm = 5.8483
	new_data_grads_norm = 8.4324
	old_data_grads_norm = 7.5719
	sim_grads_norm_tr = 0.0354
-- Starting training on experience 174 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3677
	data_grads_norm = 6.1320
	new_data_grads_norm = 8.6938
	old_data_grads_norm = 7.8037
	sim_grads_norm_tr = 0.0179
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5888
	data_grads_norm = 7.2319
	new_data_grads_norm = 8.9560
	old_data_grads_norm = 10.4302
	sim_grads_norm_tr = -0.0089
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8868
	data_grads_norm = 5.6242
	new_data_grads_norm = 8.4800
	old_data_grads_norm = 6.9552
	sim_grads_norm_tr = -0.0054
-- Starting training on experience 175 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0330
	data_grads_norm = 6.1054
	new_data_grads_norm = 10.2143
	old_data_grads_norm = 7.1244
	sim_grads_norm_tr = -0.0131
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5930
	data_grads_norm = 6.3875
	new_data_grads_norm = 9.6844
	old_data_grads_norm = 7.8531
	sim_grads_norm_tr = 0.0445
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1491
	data_grads_norm = 5.4087
	new_data_grads_norm = 9.3844
	old_data_grads_norm = 4.9084
	sim_grads_norm_tr = -0.0061
-- Starting training on experience 176 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0121
	data_grads_norm = 5.0061
	new_data_grads_norm = 9.5347
	old_data_grads_norm = 5.2217
	sim_grads_norm_tr = 0.0044
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1445
	data_grads_norm = 4.6637
	new_data_grads_norm = 9.0523
	old_data_grads_norm = 4.5982
	sim_grads_norm_tr = -0.0002
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4119
	data_grads_norm = 6.0756
	new_data_grads_norm = 9.3199
	old_data_grads_norm = 6.5993
	sim_grads_norm_tr = -0.0090
-- Starting training on experience 177 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0803
	data_grads_norm = 5.2456
	new_data_grads_norm = 7.9546
	old_data_grads_norm = 7.2440
	sim_grads_norm_tr = -0.0043
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4307
	data_grads_norm = 5.1988
	new_data_grads_norm = 7.7358
	old_data_grads_norm = 6.7790
	sim_grads_norm_tr = 0.0014
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5122
	data_grads_norm = 5.1736
	new_data_grads_norm = 9.2677
	old_data_grads_norm = 5.8646
	sim_grads_norm_tr = 0.0891
-- Starting training on experience 178 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7681
	data_grads_norm = 5.8973
	new_data_grads_norm = 8.8238
	old_data_grads_norm = 6.7862
	sim_grads_norm_tr = -0.0098
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7051
	data_grads_norm = 5.7897
	new_data_grads_norm = 8.0584
	old_data_grads_norm = 7.5981
	sim_grads_norm_tr = 0.0212
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8896
	data_grads_norm = 5.9920
	new_data_grads_norm = 9.7207
	old_data_grads_norm = 5.0928
	sim_grads_norm_tr = 0.0510
-- Starting training on experience 179 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0295
	data_grads_norm = 6.5319
	new_data_grads_norm = 9.5659
	old_data_grads_norm = 7.5195
	sim_grads_norm_tr = -0.0359
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1175
	data_grads_norm = 5.2061
	new_data_grads_norm = 9.4942
	old_data_grads_norm = 6.3360
	sim_grads_norm_tr = 0.0125
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8500
	data_grads_norm = 4.7790
	new_data_grads_norm = 9.6225
	old_data_grads_norm = 5.5575
	sim_grads_norm_tr = -0.0128
-- Starting training on experience 180 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8493
	data_grads_norm = 6.2773
	new_data_grads_norm = 9.2738
	old_data_grads_norm = 7.7091
	sim_grads_norm_tr = -0.0229
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8686
	data_grads_norm = 6.9134
	new_data_grads_norm = 9.8911
	old_data_grads_norm = 7.4664
	sim_grads_norm_tr = 0.1525
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6037
	data_grads_norm = 6.0230
	new_data_grads_norm = 9.5071
	old_data_grads_norm = 4.8893
	sim_grads_norm_tr = -0.0213
-- Starting training on experience 181 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0050
	data_grads_norm = 6.3388
	new_data_grads_norm = 8.4473
	old_data_grads_norm = 8.5031
	sim_grads_norm_tr = 0.0914
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4782
	data_grads_norm = 5.0828
	new_data_grads_norm = 8.0348
	old_data_grads_norm = 7.8152
	sim_grads_norm_tr = 0.0201
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4014
	data_grads_norm = 6.2242
	new_data_grads_norm = 7.4849
	old_data_grads_norm = 10.8600
	sim_grads_norm_tr = -0.0220
-- Starting training on experience 182 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2448
	data_grads_norm = 6.4685
	new_data_grads_norm = 10.4271
	old_data_grads_norm = 6.3398
	sim_grads_norm_tr = -0.0347
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1823
	data_grads_norm = 6.5596
	new_data_grads_norm = 10.2998
	old_data_grads_norm = 7.6713
	sim_grads_norm_tr = 0.0031
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9698
	data_grads_norm = 5.7927
	new_data_grads_norm = 9.5375
	old_data_grads_norm = 8.3668
	sim_grads_norm_tr = -0.0057
-- Starting training on experience 183 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8551
	data_grads_norm = 6.3315
	new_data_grads_norm = 8.6886
	old_data_grads_norm = 7.7974
	sim_grads_norm_tr = 0.0024
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3371
	data_grads_norm = 6.1743
	new_data_grads_norm = 9.2390
	old_data_grads_norm = 6.8972
	sim_grads_norm_tr = 0.0420
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0119
	data_grads_norm = 6.7587
	new_data_grads_norm = 9.1663
	old_data_grads_norm = 9.7266
	sim_grads_norm_tr = 0.0021
-- Starting training on experience 184 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9421
	data_grads_norm = 7.4258
	new_data_grads_norm = 10.5152
	old_data_grads_norm = 9.4633
	sim_grads_norm_tr = -0.0006
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1959
	data_grads_norm = 7.2605
	new_data_grads_norm = 9.8011
	old_data_grads_norm = 9.4490
	sim_grads_norm_tr = -0.0046
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4817
	data_grads_norm = 6.6647
	new_data_grads_norm = 10.2530
	old_data_grads_norm = 7.3940
	sim_grads_norm_tr = 0.0208
-- Starting training on experience 185 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3590
	data_grads_norm = 5.9080
	new_data_grads_norm = 8.4438
	old_data_grads_norm = 6.2749
	sim_grads_norm_tr = 0.0173
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3553
	data_grads_norm = 6.7324
	new_data_grads_norm = 9.2977
	old_data_grads_norm = 8.2211
	sim_grads_norm_tr = 0.0236
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4182
	data_grads_norm = 5.8334
	new_data_grads_norm = 9.7681
	old_data_grads_norm = 4.8770
	sim_grads_norm_tr = -0.0089
-- Starting training on experience 186 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0687
	data_grads_norm = 5.3348
	new_data_grads_norm = 7.9171
	old_data_grads_norm = 6.9615
	sim_grads_norm_tr = 0.0047
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3354
	data_grads_norm = 6.3442
	new_data_grads_norm = 9.6922
	old_data_grads_norm = 6.6491
	sim_grads_norm_tr = -0.0017
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7394
	data_grads_norm = 6.3574
	new_data_grads_norm = 8.1511
	old_data_grads_norm = 7.7259
	sim_grads_norm_tr = 0.1113
-- Starting training on experience 187 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9335
	data_grads_norm = 5.9529
	new_data_grads_norm = 9.8358
	old_data_grads_norm = 5.6620
	sim_grads_norm_tr = 0.0205
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0226
	data_grads_norm = 6.7186
	new_data_grads_norm = 9.6173
	old_data_grads_norm = 8.7059
	sim_grads_norm_tr = -0.0437
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8903
	data_grads_norm = 6.1182
	new_data_grads_norm = 9.5520
	old_data_grads_norm = 7.7608
	sim_grads_norm_tr = -0.0053
-- Starting training on experience 188 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9860
	data_grads_norm = 5.0323
	new_data_grads_norm = 8.6772
	old_data_grads_norm = 7.1100
	sim_grads_norm_tr = 0.0031
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1390
	data_grads_norm = 5.1973
	new_data_grads_norm = 8.9075
	old_data_grads_norm = 8.0287
	sim_grads_norm_tr = -0.0094
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4759
	data_grads_norm = 5.7733
	new_data_grads_norm = 7.7933
	old_data_grads_norm = 7.9445
	sim_grads_norm_tr = 0.0391
-- Starting training on experience 189 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3886
	data_grads_norm = 5.8158
	new_data_grads_norm = 9.9475
	old_data_grads_norm = 4.4880
	sim_grads_norm_tr = 0.0425
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7317
	data_grads_norm = 6.8229
	new_data_grads_norm = 9.8994
	old_data_grads_norm = 8.7429
	sim_grads_norm_tr = -0.0052
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0849
	data_grads_norm = 5.6607
	new_data_grads_norm = 9.5791
	old_data_grads_norm = 5.2993
	sim_grads_norm_tr = 0.0711
-- Starting training on experience 190 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7586
	data_grads_norm = 6.8210
	new_data_grads_norm = 9.7454
	old_data_grads_norm = 8.6025
	sim_grads_norm_tr = -0.0049
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3448
	data_grads_norm = 5.4465
	new_data_grads_norm = 8.5166
	old_data_grads_norm = 5.5291
	sim_grads_norm_tr = 0.0069
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3545
	data_grads_norm = 5.7373
	new_data_grads_norm = 8.3242
	old_data_grads_norm = 6.1423
	sim_grads_norm_tr = 0.0132
-- Starting training on experience 191 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9427
	data_grads_norm = 5.5610
	new_data_grads_norm = 9.4182
	old_data_grads_norm = 5.6536
	sim_grads_norm_tr = 0.1072
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5506
	data_grads_norm = 5.5500
	new_data_grads_norm = 8.1464
	old_data_grads_norm = 7.3804
	sim_grads_norm_tr = 0.0775
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7465
	data_grads_norm = 5.1924
	new_data_grads_norm = 8.0923
	old_data_grads_norm = 6.3814
	sim_grads_norm_tr = 0.0644
-- Starting training on experience 192 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4453
	data_grads_norm = 5.9393
	new_data_grads_norm = 11.2906
	old_data_grads_norm = 6.3925
	sim_grads_norm_tr = -0.0091
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7903
	data_grads_norm = 6.9591
	new_data_grads_norm = 10.9022
	old_data_grads_norm = 8.7722
	sim_grads_norm_tr = -0.0208
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6954
	data_grads_norm = 6.3914
	new_data_grads_norm = 10.4368
	old_data_grads_norm = 6.8488
	sim_grads_norm_tr = 0.0074
-- Starting training on experience 193 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9935
	data_grads_norm = 5.9749
	new_data_grads_norm = 9.8573
	old_data_grads_norm = 7.1268
	sim_grads_norm_tr = -0.0072
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2485
	data_grads_norm = 5.7809
	new_data_grads_norm = 9.3620
	old_data_grads_norm = 5.3493
	sim_grads_norm_tr = -0.0425
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3473
	data_grads_norm = 5.9946
	new_data_grads_norm = 8.8464
	old_data_grads_norm = 7.4289
	sim_grads_norm_tr = 0.0195
-- Starting training on experience 194 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6583
	data_grads_norm = 4.8121
	new_data_grads_norm = 7.2647
	old_data_grads_norm = 5.3572
	sim_grads_norm_tr = 0.0284
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7176
	data_grads_norm = 4.9301
	new_data_grads_norm = 8.0691
	old_data_grads_norm = 7.5859
	sim_grads_norm_tr = -0.0151
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5255
	data_grads_norm = 5.0804
	new_data_grads_norm = 8.5557
	old_data_grads_norm = 5.9754
	sim_grads_norm_tr = -0.0171
-- Starting training on experience 195 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5830
	data_grads_norm = 4.9398
	new_data_grads_norm = 7.5738
	old_data_grads_norm = 6.5864
	sim_grads_norm_tr = -0.0218
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6889
	data_grads_norm = 5.1631
	new_data_grads_norm = 8.4814
	old_data_grads_norm = 6.4027
	sim_grads_norm_tr = -0.0107
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0628
	data_grads_norm = 5.8453
	new_data_grads_norm = 8.6890
	old_data_grads_norm = 7.3833
	sim_grads_norm_tr = -0.0375
-- Starting training on experience 196 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2306
	data_grads_norm = 6.0110
	new_data_grads_norm = 11.2707
	old_data_grads_norm = 7.2688
	sim_grads_norm_tr = 0.0073
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4468
	data_grads_norm = 5.7431
	new_data_grads_norm = 10.2043
	old_data_grads_norm = 6.7095
	sim_grads_norm_tr = 0.0187
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2367
	data_grads_norm = 5.9946
	new_data_grads_norm = 10.3707
	old_data_grads_norm = 6.8540
	sim_grads_norm_tr = -0.0319
-- Starting training on experience 197 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9602
	data_grads_norm = 5.0701
	new_data_grads_norm = 7.8299
	old_data_grads_norm = 7.0907
	sim_grads_norm_tr = 0.0014
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7579
	data_grads_norm = 5.3001
	new_data_grads_norm = 8.4634
	old_data_grads_norm = 8.8014
	sim_grads_norm_tr = -0.0244
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8719
	data_grads_norm = 5.5354
	new_data_grads_norm = 9.4004
	old_data_grads_norm = 6.2416
	sim_grads_norm_tr = -0.0391
-- Starting training on experience 198 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4359
	data_grads_norm = 6.0759
	new_data_grads_norm = 8.5913
	old_data_grads_norm = 7.9465
	sim_grads_norm_tr = 0.0520
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1362
	data_grads_norm = 5.7396
	new_data_grads_norm = 8.1631
	old_data_grads_norm = 8.7433
	sim_grads_norm_tr = -0.0107
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9684
	data_grads_norm = 5.5553
	new_data_grads_norm = 8.4695
	old_data_grads_norm = 8.8290
	sim_grads_norm_tr = 0.0030
-- Starting training on experience 199 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7789
	data_grads_norm = 6.9344
	new_data_grads_norm = 10.8626
	old_data_grads_norm = 8.3529
	sim_grads_norm_tr = 0.0043
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6287
	data_grads_norm = 6.1980
	new_data_grads_norm = 10.7018
	old_data_grads_norm = 6.4918
	sim_grads_norm_tr = 0.0188
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5677
	data_grads_norm = 6.6741
	new_data_grads_norm = 10.6468
	old_data_grads_norm = 7.6682
	sim_grads_norm_tr = 0.0028
-- Starting training on experience 200 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1817
	data_grads_norm = 5.5308
	new_data_grads_norm = 9.0310
	old_data_grads_norm = 4.5078
	sim_grads_norm_tr = 0.0108
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3715
	data_grads_norm = 5.1545
	new_data_grads_norm = 8.1412
	old_data_grads_norm = 6.0014
	sim_grads_norm_tr = -0.0195
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8127
	data_grads_norm = 6.0153
	new_data_grads_norm = 9.7198
	old_data_grads_norm = 6.4324
	sim_grads_norm_tr = 0.0005
-- Starting training on experience 201 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3214
	data_grads_norm = 5.9960
	new_data_grads_norm = 9.0890
	old_data_grads_norm = 5.5159
	sim_grads_norm_tr = 0.0209
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8694
	data_grads_norm = 6.1273
	new_data_grads_norm = 7.6240
	old_data_grads_norm = 8.6171
	sim_grads_norm_tr = 0.0084
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5791
	data_grads_norm = 5.1886
	new_data_grads_norm = 9.3485
	old_data_grads_norm = 3.9777
	sim_grads_norm_tr = 0.0440
-- Starting training on experience 202 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4226
	data_grads_norm = 5.2808
	new_data_grads_norm = 7.8658
	old_data_grads_norm = 6.2156
	sim_grads_norm_tr = 0.0551
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0568
	data_grads_norm = 5.1851
	new_data_grads_norm = 6.9992
	old_data_grads_norm = 6.6582
	sim_grads_norm_tr = 0.0278
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0373
	data_grads_norm = 5.7066
	new_data_grads_norm = 6.9546
	old_data_grads_norm = 8.9289
	sim_grads_norm_tr = 0.0033
-- Starting training on experience 203 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2780
	data_grads_norm = 6.1394
	new_data_grads_norm = 8.2112
	old_data_grads_norm = 7.2242
	sim_grads_norm_tr = 0.0313
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2740
	data_grads_norm = 6.3876
	new_data_grads_norm = 8.7054
	old_data_grads_norm = 9.1150
	sim_grads_norm_tr = 0.0214
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0718
	data_grads_norm = 5.2320
	new_data_grads_norm = 7.8788
	old_data_grads_norm = 6.1520
	sim_grads_norm_tr = -0.0365
-- Starting training on experience 204 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7537
	data_grads_norm = 5.3282
	new_data_grads_norm = 9.6115
	old_data_grads_norm = 4.7664
	sim_grads_norm_tr = 0.0851
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6456
	data_grads_norm = 6.1763
	new_data_grads_norm = 9.4109
	old_data_grads_norm = 9.4135
	sim_grads_norm_tr = 0.0057
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9463
	data_grads_norm = 5.1751
	new_data_grads_norm = 8.7297
	old_data_grads_norm = 5.5755
	sim_grads_norm_tr = -0.0210
-- Starting training on experience 205 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0731
	data_grads_norm = 5.5973
	new_data_grads_norm = 7.2899
	old_data_grads_norm = 7.9943
	sim_grads_norm_tr = -0.0203
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0127
	data_grads_norm = 5.6375
	new_data_grads_norm = 8.6605
	old_data_grads_norm = 6.3055
	sim_grads_norm_tr = 0.0105
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2083
	data_grads_norm = 5.1822
	new_data_grads_norm = 8.6972
	old_data_grads_norm = 7.2427
	sim_grads_norm_tr = -0.0313
-- Starting training on experience 206 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9107
	data_grads_norm = 5.9574
	new_data_grads_norm = 10.1352
	old_data_grads_norm = 5.3732
	sim_grads_norm_tr = -0.0054
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9951
	data_grads_norm = 4.8192
	new_data_grads_norm = 8.8574
	old_data_grads_norm = 5.6749
	sim_grads_norm_tr = 0.0066
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4379
	data_grads_norm = 5.5566
	new_data_grads_norm = 9.0639
	old_data_grads_norm = 7.3151
	sim_grads_norm_tr = -0.0298
-- Starting training on experience 207 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1668
	data_grads_norm = 6.8444
	new_data_grads_norm = 8.2188
	old_data_grads_norm = 7.9597
	sim_grads_norm_tr = 0.0033
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6439
	data_grads_norm = 4.6531
	new_data_grads_norm = 8.4181
	old_data_grads_norm = 4.0137
	sim_grads_norm_tr = -0.0054
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0888
	data_grads_norm = 5.4724
	new_data_grads_norm = 9.0745
	old_data_grads_norm = 6.2934
	sim_grads_norm_tr = -0.0140
-- Starting training on experience 208 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8128
	data_grads_norm = 4.4358
	new_data_grads_norm = 8.4264
	old_data_grads_norm = 5.4824
	sim_grads_norm_tr = 0.0132
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0611
	data_grads_norm = 4.7546
	new_data_grads_norm = 8.2961
	old_data_grads_norm = 5.5906
	sim_grads_norm_tr = -0.0339
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8120
	data_grads_norm = 4.4272
	new_data_grads_norm = 7.5829
	old_data_grads_norm = 5.1037
	sim_grads_norm_tr = -0.0403
-- Starting training on experience 209 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9654
	data_grads_norm = 4.7148
	new_data_grads_norm = 7.6293
	old_data_grads_norm = 3.1963
	sim_grads_norm_tr = -0.0262
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6309
	data_grads_norm = 6.3261
	new_data_grads_norm = 7.5710
	old_data_grads_norm = 9.3439
	sim_grads_norm_tr = -0.0113
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1757
	data_grads_norm = 5.7465
	new_data_grads_norm = 9.2778
	old_data_grads_norm = 6.2445
	sim_grads_norm_tr = 0.0140
-- Starting training on experience 210 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1904
	data_grads_norm = 6.6781
	new_data_grads_norm = 9.5530
	old_data_grads_norm = 8.8127
	sim_grads_norm_tr = -0.0480
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9775
	data_grads_norm = 6.4152
	new_data_grads_norm = 9.3299
	old_data_grads_norm = 9.5371
	sim_grads_norm_tr = 0.0053
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4505
	data_grads_norm = 6.2452
	new_data_grads_norm = 10.1814
	old_data_grads_norm = 7.5253
	sim_grads_norm_tr = 0.0886
-- Starting training on experience 211 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6915
	data_grads_norm = 5.6555
	new_data_grads_norm = 9.5068
	old_data_grads_norm = 5.3186
	sim_grads_norm_tr = 0.0504
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4410
	data_grads_norm = 5.9205
	new_data_grads_norm = 10.3335
	old_data_grads_norm = 6.1668
	sim_grads_norm_tr = 0.0069
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6835
	data_grads_norm = 5.2286
	new_data_grads_norm = 8.9082
	old_data_grads_norm = 6.9052
	sim_grads_norm_tr = -0.0609
-- Starting training on experience 212 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8508
	data_grads_norm = 6.0875
	new_data_grads_norm = 10.2283
	old_data_grads_norm = 9.0512
	sim_grads_norm_tr = 0.0091
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9049
	data_grads_norm = 4.2937
	new_data_grads_norm = 8.8838
	old_data_grads_norm = 4.2667
	sim_grads_norm_tr = 0.0081
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8521
	data_grads_norm = 5.8501
	new_data_grads_norm = 9.6081
	old_data_grads_norm = 8.2249
	sim_grads_norm_tr = -0.0284
-- Starting training on experience 213 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3341
	data_grads_norm = 6.3666
	new_data_grads_norm = 9.9674
	old_data_grads_norm = 11.3135
	sim_grads_norm_tr = -0.0238
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8211
	data_grads_norm = 6.6710
	new_data_grads_norm = 10.2337
	old_data_grads_norm = 8.5657
	sim_grads_norm_tr = 0.0060
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5659
	data_grads_norm = 6.0635
	new_data_grads_norm = 10.1773
	old_data_grads_norm = 7.1445
	sim_grads_norm_tr = 0.0029
-- Starting training on experience 214 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8575
	data_grads_norm = 6.0701
	new_data_grads_norm = 9.4044
	old_data_grads_norm = 6.3284
	sim_grads_norm_tr = 0.0098
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5305
	data_grads_norm = 5.9425
	new_data_grads_norm = 9.0366
	old_data_grads_norm = 6.5533
	sim_grads_norm_tr = 0.0162
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1754
	data_grads_norm = 6.2482
	new_data_grads_norm = 8.5499
	old_data_grads_norm = 9.3621
	sim_grads_norm_tr = 0.0484
-- Starting training on experience 215 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0428
	data_grads_norm = 4.7744
	new_data_grads_norm = 8.4227
	old_data_grads_norm = 4.9584
	sim_grads_norm_tr = -0.0003
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5641
	data_grads_norm = 5.7018
	new_data_grads_norm = 8.4171
	old_data_grads_norm = 6.9128
	sim_grads_norm_tr = 0.0243
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1252
	data_grads_norm = 5.0152
	new_data_grads_norm = 8.1852
	old_data_grads_norm = 4.8947
	sim_grads_norm_tr = 0.0766
-- Starting training on experience 216 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5983
	data_grads_norm = 4.1888
	new_data_grads_norm = 7.2606
	old_data_grads_norm = 6.4723
	sim_grads_norm_tr = -0.0051
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6323
	data_grads_norm = 4.7447
	new_data_grads_norm = 7.9735
	old_data_grads_norm = 4.3795
	sim_grads_norm_tr = 0.0004
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8202
	data_grads_norm = 5.3407
	new_data_grads_norm = 8.2503
	old_data_grads_norm = 5.8367
	sim_grads_norm_tr = -0.0177
-- Starting training on experience 217 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1929
	data_grads_norm = 5.0801
	new_data_grads_norm = 8.7766
	old_data_grads_norm = 6.8462
	sim_grads_norm_tr = 0.0027
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6748
	data_grads_norm = 5.2826
	new_data_grads_norm = 8.6321
	old_data_grads_norm = 5.1384
	sim_grads_norm_tr = 0.0224
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8750
	data_grads_norm = 6.7011
	new_data_grads_norm = 8.9038
	old_data_grads_norm = 8.5654
	sim_grads_norm_tr = 0.0679
-- Starting training on experience 218 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0863
	data_grads_norm = 5.7770
	new_data_grads_norm = 8.4530
	old_data_grads_norm = 6.7858
	sim_grads_norm_tr = 0.0090
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3215
	data_grads_norm = 5.9792
	new_data_grads_norm = 8.1730
	old_data_grads_norm = 7.9173
	sim_grads_norm_tr = -0.0079
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9783
	data_grads_norm = 4.8323
	new_data_grads_norm = 7.6080
	old_data_grads_norm = 4.5558
	sim_grads_norm_tr = 0.1008
-- Starting training on experience 219 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2571
	data_grads_norm = 6.3990
	new_data_grads_norm = 10.1790
	old_data_grads_norm = 6.7811
	sim_grads_norm_tr = -0.0199
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9614
	data_grads_norm = 5.5063
	new_data_grads_norm = 9.5417
	old_data_grads_norm = 5.5332
	sim_grads_norm_tr = 0.2141
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6596
	data_grads_norm = 5.0808
	new_data_grads_norm = 8.6134
	old_data_grads_norm = 6.1569
	sim_grads_norm_tr = -0.0512
-- Starting training on experience 220 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3495
	data_grads_norm = 5.3203
	new_data_grads_norm = 8.6590
	old_data_grads_norm = 7.1244
	sim_grads_norm_tr = 0.0138
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0929
	data_grads_norm = 5.0116
	new_data_grads_norm = 8.0040
	old_data_grads_norm = 4.7361
	sim_grads_norm_tr = 0.0438
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3309
	data_grads_norm = 5.0762
	new_data_grads_norm = 8.5655
	old_data_grads_norm = 5.2718
	sim_grads_norm_tr = 0.0400
-- Starting training on experience 221 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8853
	data_grads_norm = 5.6855
	new_data_grads_norm = 7.8223
	old_data_grads_norm = 7.3849
	sim_grads_norm_tr = -0.0133
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6603
	data_grads_norm = 5.4813
	new_data_grads_norm = 8.0727
	old_data_grads_norm = 6.2476
	sim_grads_norm_tr = 0.0005
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9797
	data_grads_norm = 5.0950
	new_data_grads_norm = 8.3262
	old_data_grads_norm = 7.9763
	sim_grads_norm_tr = -0.0004
-- Starting training on experience 222 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1091
	data_grads_norm = 5.4079
	new_data_grads_norm = 8.6731
	old_data_grads_norm = 6.9191
	sim_grads_norm_tr = 0.0175
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2942
	data_grads_norm = 6.8544
	new_data_grads_norm = 9.3614
	old_data_grads_norm = 8.7767
	sim_grads_norm_tr = -0.0402
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7860
	data_grads_norm = 7.5728
	new_data_grads_norm = 8.2707
	old_data_grads_norm = 9.4255
	sim_grads_norm_tr = 0.0472
-- Starting training on experience 223 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3832
	data_grads_norm = 6.0660
	new_data_grads_norm = 10.3456
	old_data_grads_norm = 5.7092
	sim_grads_norm_tr = 0.0401
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2871
	data_grads_norm = 5.8966
	new_data_grads_norm = 9.8948
	old_data_grads_norm = 5.4736
	sim_grads_norm_tr = -0.0002
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3148
	data_grads_norm = 5.6798
	new_data_grads_norm = 8.8594
	old_data_grads_norm = 8.3560
	sim_grads_norm_tr = -0.0101
-- Starting training on experience 224 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2514
	data_grads_norm = 7.0423
	new_data_grads_norm = 9.5109
	old_data_grads_norm = 7.6365
	sim_grads_norm_tr = 0.0002
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4049
	data_grads_norm = 5.0653
	new_data_grads_norm = 9.5595
	old_data_grads_norm = 5.5116
	sim_grads_norm_tr = -0.0165
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7413
	data_grads_norm = 5.5223
	new_data_grads_norm = 8.4831
	old_data_grads_norm = 6.3047
	sim_grads_norm_tr = -0.0237
-- Starting training on experience 225 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4034
	data_grads_norm = 6.7199
	new_data_grads_norm = 10.5671
	old_data_grads_norm = 6.9492
	sim_grads_norm_tr = 0.0141
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9687
	data_grads_norm = 5.5106
	new_data_grads_norm = 9.6145
	old_data_grads_norm = 5.1977
	sim_grads_norm_tr = 0.0925
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3833
	data_grads_norm = 6.5244
	new_data_grads_norm = 9.8874
	old_data_grads_norm = 8.2104
	sim_grads_norm_tr = 0.0897
-- Starting training on experience 226 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8787
	data_grads_norm = 7.4028
	new_data_grads_norm = 9.7246
	old_data_grads_norm = 9.2693
	sim_grads_norm_tr = -0.0395
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2550
	data_grads_norm = 6.3289
	new_data_grads_norm = 9.8774
	old_data_grads_norm = 5.3825
	sim_grads_norm_tr = -0.0074
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4583
	data_grads_norm = 6.4840
	new_data_grads_norm = 11.7145
	old_data_grads_norm = 5.9785
	sim_grads_norm_tr = -0.0254
-- Starting training on experience 227 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1304
	data_grads_norm = 7.0211
	new_data_grads_norm = 9.3966
	old_data_grads_norm = 9.0759
	sim_grads_norm_tr = -0.0100
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9893
	data_grads_norm = 6.2191
	new_data_grads_norm = 10.5823
	old_data_grads_norm = 7.1542
	sim_grads_norm_tr = -0.0252
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5429
	data_grads_norm = 4.2595
	new_data_grads_norm = 8.2343
	old_data_grads_norm = 6.1423
	sim_grads_norm_tr = -0.0063
-- Starting training on experience 228 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5309
	data_grads_norm = 4.8100
	new_data_grads_norm = 8.9025
	old_data_grads_norm = 5.5462
	sim_grads_norm_tr = 0.0050
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6234
	data_grads_norm = 5.4515
	new_data_grads_norm = 8.6224
	old_data_grads_norm = 3.5096
	sim_grads_norm_tr = -0.0278
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1644
	data_grads_norm = 5.9887
	new_data_grads_norm = 9.6956
	old_data_grads_norm = 5.5668
	sim_grads_norm_tr = 0.0980
-- Starting training on experience 229 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6436
	data_grads_norm = 6.7325
	new_data_grads_norm = 9.3363
	old_data_grads_norm = 8.9348
	sim_grads_norm_tr = 0.0497
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8381
	data_grads_norm = 5.2276
	new_data_grads_norm = 8.3651
	old_data_grads_norm = 5.5482
	sim_grads_norm_tr = -0.0382
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3164
	data_grads_norm = 6.0613
	new_data_grads_norm = 9.9644
	old_data_grads_norm = 7.1748
	sim_grads_norm_tr = -0.0288
-- Starting training on experience 230 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3714
	data_grads_norm = 6.5399
	new_data_grads_norm = 8.8828
	old_data_grads_norm = 8.6877
	sim_grads_norm_tr = -0.0216
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4493
	data_grads_norm = 6.1494
	new_data_grads_norm = 10.6128
	old_data_grads_norm = 7.2207
	sim_grads_norm_tr = -0.0257
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3478
	data_grads_norm = 5.3676
	new_data_grads_norm = 9.5391
	old_data_grads_norm = 5.3877
	sim_grads_norm_tr = 0.0353
-- Starting training on experience 231 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4408
	data_grads_norm = 6.6304
	new_data_grads_norm = 9.2236
	old_data_grads_norm = 7.9112
	sim_grads_norm_tr = 0.0507
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0196
	data_grads_norm = 5.8328
	new_data_grads_norm = 8.5017
	old_data_grads_norm = 4.1081
	sim_grads_norm_tr = -0.0300
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2547
	data_grads_norm = 6.1499
	new_data_grads_norm = 9.2255
	old_data_grads_norm = 6.4584
	sim_grads_norm_tr = 0.0321
-- Starting training on experience 232 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9764
	data_grads_norm = 5.2955
	new_data_grads_norm = 7.7540
	old_data_grads_norm = 7.3424
	sim_grads_norm_tr = -0.0149
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7080
	data_grads_norm = 4.9882
	new_data_grads_norm = 7.9528
	old_data_grads_norm = 5.2107
	sim_grads_norm_tr = -0.0186
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9208
	data_grads_norm = 5.7694
	new_data_grads_norm = 8.2547
	old_data_grads_norm = 8.0997
	sim_grads_norm_tr = -0.0127
-- Starting training on experience 233 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2277
	data_grads_norm = 5.5073
	new_data_grads_norm = 8.7136
	old_data_grads_norm = 5.7012
	sim_grads_norm_tr = 0.0140
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4801
	data_grads_norm = 5.8338
	new_data_grads_norm = 8.5495
	old_data_grads_norm = 6.5818
	sim_grads_norm_tr = 0.0288
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3934
	data_grads_norm = 5.3179
	new_data_grads_norm = 8.4765
	old_data_grads_norm = 9.6108
	sim_grads_norm_tr = 0.0178
-- Starting training on experience 234 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5729
	data_grads_norm = 5.1632
	new_data_grads_norm = 8.5598
	old_data_grads_norm = 8.5926
	sim_grads_norm_tr = 0.0021
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6902
	data_grads_norm = 5.3257
	new_data_grads_norm = 8.6215
	old_data_grads_norm = 5.8849
	sim_grads_norm_tr = -0.0387
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0697
	data_grads_norm = 5.5372
	new_data_grads_norm = 9.3128
	old_data_grads_norm = 7.5316
	sim_grads_norm_tr = -0.0424
-- Starting training on experience 235 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3532
	data_grads_norm = 6.0932
	new_data_grads_norm = 9.2769
	old_data_grads_norm = 5.7799
	sim_grads_norm_tr = 0.0328
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9837
	data_grads_norm = 5.9612
	new_data_grads_norm = 8.6941
	old_data_grads_norm = 8.0810
	sim_grads_norm_tr = -0.0166
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9648
	data_grads_norm = 5.8551
	new_data_grads_norm = 8.9540
	old_data_grads_norm = 6.4795
	sim_grads_norm_tr = 0.0051
-- Starting training on experience 236 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1913
	data_grads_norm = 5.9275
	new_data_grads_norm = 10.1372
	old_data_grads_norm = 7.1665
	sim_grads_norm_tr = 0.0118
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6958
	data_grads_norm = 5.5935
	new_data_grads_norm = 8.7958
	old_data_grads_norm = 8.3569
	sim_grads_norm_tr = -0.0029
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9503
	data_grads_norm = 5.9447
	new_data_grads_norm = 10.2887
	old_data_grads_norm = 5.2867
	sim_grads_norm_tr = 0.0639
-- Starting training on experience 237 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
-- >> End of training phase << --
-- >> Start of eval phase << --
-- Starting eval on experience 0 (Task 0) from test stream --
> Eval on experience 0 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp000 = 4.6957
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.2260
	mb_index = 4522
	time = 1937.2674
-- Starting eval on experience 1 (Task 0) from test stream --
> Eval on experience 1 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp001 = 2.7624
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.4660
-- Starting eval on experience 2 (Task 0) from test stream --
> Eval on experience 2 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp002 = 5.2765
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.2360
-- Starting eval on experience 3 (Task 0) from test stream --
> Eval on experience 3 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp003 = 3.4885
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.4060
-- Starting eval on experience 4 (Task 0) from test stream --
> Eval on experience 4 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp004 = 5.2273
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.1900
-- Starting eval on experience 5 (Task 0) from test stream --
> Eval on experience 5 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp005 = 4.7640
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.2480
-- Starting eval on experience 6 (Task 0) from test stream --
> Eval on experience 6 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp006 = 3.5697
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp006 = 0.3420
-- Starting eval on experience 7 (Task 0) from test stream --
> Eval on experience 7 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp007 = 3.7691
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp007 = 0.3660
-- Starting eval on experience 8 (Task 0) from test stream --
> Eval on experience 8 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp008 = 4.5062
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp008 = 0.3140
-- Starting eval on experience 9 (Task 0) from test stream --
> Eval on experience 9 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp009 = 3.7493
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp009 = 0.3060
-- Starting eval on experience 10 (Task 0) from test stream --
> Eval on experience 10 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp010 = 4.2192
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp010 = 0.2040
-- Starting eval on experience 11 (Task 0) from test stream --
> Eval on experience 11 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp011 = 2.7942
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp011 = 0.4420
-- Starting eval on experience 12 (Task 0) from test stream --
> Eval on experience 12 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp012 = 5.1781
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp012 = 0.0880
-- Starting eval on experience 13 (Task 0) from test stream --
> Eval on experience 13 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp013 = 3.1988
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp013 = 0.2860
-- Starting eval on experience 14 (Task 0) from test stream --
> Eval on experience 14 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp014 = 3.2371
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp014 = 0.2820
-- Starting eval on experience 15 (Task 0) from test stream --
> Eval on experience 15 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp015 = 3.7903
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp015 = 0.2580
-- Starting eval on experience 16 (Task 0) from test stream --
> Eval on experience 16 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp016 = 3.4216
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp016 = 0.2680
-- Starting eval on experience 17 (Task 0) from test stream --
> Eval on experience 17 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp017 = 4.0922
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp017 = 0.1540
-- Starting eval on experience 18 (Task 0) from test stream --
> Eval on experience 18 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp018 = 4.0065
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp018 = 0.0840
-- >> End of eval phase << --
	CumulativeAccuracy/eval_phase/test_stream/Exp000 = 0.7380
	CumulativeAccuracy/eval_phase/test_stream/Exp001 = 0.6780
	CumulativeAccuracy/eval_phase/test_stream/Exp002 = 0.5720
	CumulativeAccuracy/eval_phase/test_stream/Exp003 = 0.5465
	CumulativeAccuracy/eval_phase/test_stream/Exp004 = 0.5032
	CumulativeAccuracy/eval_phase/test_stream/Exp005 = 0.4657
	CumulativeAccuracy/eval_phase/test_stream/Exp006 = 0.4337
	CumulativeAccuracy/eval_phase/test_stream/Exp007 = 0.4143
	CumulativeAccuracy/eval_phase/test_stream/Exp008 = 0.3969
	CumulativeAccuracy/eval_phase/test_stream/Exp009 = 0.3848
	CumulativeAccuracy/eval_phase/test_stream/Exp010 = 0.3629
	CumulativeAccuracy/eval_phase/test_stream/Exp011 = 0.3572
	CumulativeAccuracy/eval_phase/test_stream/Exp012 = 0.3366
	CumulativeAccuracy/eval_phase/test_stream/Exp013 = 0.3256
	CumulativeAccuracy/eval_phase/test_stream/Exp014 = 0.3164
	CumulativeAccuracy/eval_phase/test_stream/Exp015 = 0.3048
	CumulativeAccuracy/eval_phase/test_stream/Exp016 = 0.2955
	CumulativeAccuracy/eval_phase/test_stream/Exp017 = 0.2840
	CumulativeAccuracy/eval_phase/test_stream/Exp018 = 0.2719
	Loss_Stream/eval_phase/test_stream/Task000 = 3.9867
	Top1_Acc_Stream/eval_phase/test_stream/Task000 = 0.2719
-- >> Start of training phase << --
-- Starting training on experience 0 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.1989
	data_grads_norm = 7.8124
	new_data_grads_norm = 9.6354
	old_data_grads_norm = 8.8429
	sim_grads_norm_tr = 0.0175
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.0223
	data_grads_norm = 6.6546
	new_data_grads_norm = 9.6847
	old_data_grads_norm = 7.2372
	sim_grads_norm_tr = 0.0130
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.2290
	data_grads_norm = 6.3416
	new_data_grads_norm = 9.2517
	old_data_grads_norm = 5.6271
	sim_grads_norm_tr = -0.0083
-- Starting training on experience 1 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4903
	data_grads_norm = 5.2063
	new_data_grads_norm = 8.6587
	old_data_grads_norm = 6.6604
	sim_grads_norm_tr = 0.0015
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.8219
	data_grads_norm = 6.1097
	new_data_grads_norm = 9.9373
	old_data_grads_norm = 6.8970
	sim_grads_norm_tr = -0.0088
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4763
	data_grads_norm = 5.3353
	new_data_grads_norm = 8.4946
	old_data_grads_norm = 4.9796
	sim_grads_norm_tr = 0.0044
-- Starting training on experience 2 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4095
	data_grads_norm = 5.6665
	new_data_grads_norm = 10.9550
	old_data_grads_norm = 3.4559
	sim_grads_norm_tr = 0.0291
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.7431
	data_grads_norm = 6.3545
	new_data_grads_norm = 10.5248
	old_data_grads_norm = 7.5900
	sim_grads_norm_tr = 0.0051
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.7272
	data_grads_norm = 6.1167
	new_data_grads_norm = 10.8776
	old_data_grads_norm = 4.7183
	sim_grads_norm_tr = -0.0037
-- Starting training on experience 3 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.3418
	data_grads_norm = 6.8379
	new_data_grads_norm = 11.8558
	old_data_grads_norm = 6.1594
	sim_grads_norm_tr = -0.0024
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.8479
	data_grads_norm = 7.3540
	new_data_grads_norm = 11.1881
	old_data_grads_norm = 7.9344
	sim_grads_norm_tr = 0.0152
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.3828
	data_grads_norm = 6.8688
	new_data_grads_norm = 10.6458
	old_data_grads_norm = 8.0071
	sim_grads_norm_tr = 0.0072
-- Starting training on experience 4 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.4416
	data_grads_norm = 6.7028
	new_data_grads_norm = 10.0998
	old_data_grads_norm = 7.3081
	sim_grads_norm_tr = -0.0025
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.4207
	data_grads_norm = 6.6527
	new_data_grads_norm = 9.2712
	old_data_grads_norm = 9.1066
	sim_grads_norm_tr = 0.0043
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.0704
	data_grads_norm = 6.3056
	new_data_grads_norm = 9.7238
	old_data_grads_norm = 7.2748
	sim_grads_norm_tr = 0.0084
-- Starting training on experience 5 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6687
	data_grads_norm = 5.5625
	new_data_grads_norm = 9.1123
	old_data_grads_norm = 5.8485
	sim_grads_norm_tr = 0.0005
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4965
	data_grads_norm = 5.3382
	new_data_grads_norm = 8.7960
	old_data_grads_norm = 4.2110
	sim_grads_norm_tr = 0.0098
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5796
	data_grads_norm = 5.8761
	new_data_grads_norm = 8.2836
	old_data_grads_norm = 7.4162
	sim_grads_norm_tr = 0.0195
-- Starting training on experience 6 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.9858
	data_grads_norm = 4.8695
	new_data_grads_norm = 9.0758
	old_data_grads_norm = 5.8627
	sim_grads_norm_tr = 0.0016
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3799
	data_grads_norm = 4.8010
	new_data_grads_norm = 8.0691
	old_data_grads_norm = 5.6942
	sim_grads_norm_tr = -0.0105
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.0900
	data_grads_norm = 6.1473
	new_data_grads_norm = 8.7483
	old_data_grads_norm = 9.7898
	sim_grads_norm_tr = 0.0061
-- Starting training on experience 7 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.6731
	data_grads_norm = 5.8558
	new_data_grads_norm = 9.4582
	old_data_grads_norm = 6.1538
	sim_grads_norm_tr = 0.0471
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.7827
	data_grads_norm = 5.7497
	new_data_grads_norm = 8.7087
	old_data_grads_norm = 5.9101
	sim_grads_norm_tr = 0.0161
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.0306
	data_grads_norm = 6.2840
	new_data_grads_norm = 8.9935
	old_data_grads_norm = 6.7874
	sim_grads_norm_tr = 0.0054
-- Starting training on experience 8 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.3413
	data_grads_norm = 5.9905
	new_data_grads_norm = 8.8680
	old_data_grads_norm = 4.0903
	sim_grads_norm_tr = 0.0960
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.3267
	data_grads_norm = 6.5251
	new_data_grads_norm = 9.8993
	old_data_grads_norm = 8.3435
	sim_grads_norm_tr = 0.0151
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.4764
	data_grads_norm = 7.3819
	new_data_grads_norm = 10.0558
	old_data_grads_norm = 9.7499
	sim_grads_norm_tr = 0.0055
-- Starting training on experience 9 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.6176
	data_grads_norm = 6.3845
	new_data_grads_norm = 8.7863
	old_data_grads_norm = 7.3749
	sim_grads_norm_tr = 0.0383
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.8131
	data_grads_norm = 7.0971
	new_data_grads_norm = 8.9570
	old_data_grads_norm = 10.2356
	sim_grads_norm_tr = 0.0279
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.9705
	data_grads_norm = 6.7127
	new_data_grads_norm = 8.7493
	old_data_grads_norm = 8.2908
	sim_grads_norm_tr = 0.0010
-- Starting training on experience 10 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.8386
	data_grads_norm = 5.8179
	new_data_grads_norm = 9.2721
	old_data_grads_norm = 5.5787
	sim_grads_norm_tr = 0.1494
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6867
	data_grads_norm = 5.7006
	new_data_grads_norm = 9.9688
	old_data_grads_norm = 5.4464
	sim_grads_norm_tr = -0.0018
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5384
	data_grads_norm = 5.6578
	new_data_grads_norm = 9.4863
	old_data_grads_norm = 5.0437
	sim_grads_norm_tr = 0.0989
-- Starting training on experience 11 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.8988
	data_grads_norm = 5.9675
	new_data_grads_norm = 9.3394
	old_data_grads_norm = 8.6199
	sim_grads_norm_tr = 0.0379
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3203
	data_grads_norm = 6.0695
	new_data_grads_norm = 8.4061
	old_data_grads_norm = 9.5129
	sim_grads_norm_tr = -0.0057
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.9378
	data_grads_norm = 5.4614
	new_data_grads_norm = 8.3477
	old_data_grads_norm = 5.5633
	sim_grads_norm_tr = 0.1093
-- Starting training on experience 12 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8586
	data_grads_norm = 5.7417
	new_data_grads_norm = 8.3894
	old_data_grads_norm = 8.6428
	sim_grads_norm_tr = -0.0331
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4030
	data_grads_norm = 6.4035
	new_data_grads_norm = 9.3577
	old_data_grads_norm = 6.9770
	sim_grads_norm_tr = 0.0609
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2966
	data_grads_norm = 7.3257
	new_data_grads_norm = 8.5503
	old_data_grads_norm = 11.0742
	sim_grads_norm_tr = -0.0066
-- Starting training on experience 13 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.9123
	data_grads_norm = 5.9634
	new_data_grads_norm = 10.6336
	old_data_grads_norm = 5.1654
	sim_grads_norm_tr = 0.0523
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1894
	data_grads_norm = 6.0528
	new_data_grads_norm = 9.4533
	old_data_grads_norm = 7.2047
	sim_grads_norm_tr = 0.0079
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.7434
	data_grads_norm = 7.0818
	new_data_grads_norm = 9.6540
	old_data_grads_norm = 8.7850
	sim_grads_norm_tr = 0.0044
-- Starting training on experience 14 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0002
	data_grads_norm = 6.1019
	new_data_grads_norm = 8.5165
	old_data_grads_norm = 7.1125
	sim_grads_norm_tr = 0.0108
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8593
	data_grads_norm = 4.8702
	new_data_grads_norm = 7.7833
	old_data_grads_norm = 4.9953
	sim_grads_norm_tr = 0.0993
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5761
	data_grads_norm = 5.1026
	new_data_grads_norm = 7.5689
	old_data_grads_norm = 7.1225
	sim_grads_norm_tr = -0.0012
-- Starting training on experience 15 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1380
	data_grads_norm = 5.9128
	new_data_grads_norm = 10.1173
	old_data_grads_norm = 4.7529
	sim_grads_norm_tr = 0.0195
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4625
	data_grads_norm = 7.2117
	new_data_grads_norm = 10.4764
	old_data_grads_norm = 6.4811
	sim_grads_norm_tr = 0.0522
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.2076
	data_grads_norm = 7.0494
	new_data_grads_norm = 10.3513
	old_data_grads_norm = 8.8075
	sim_grads_norm_tr = 0.0555
-- Starting training on experience 16 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9267
	data_grads_norm = 5.6705
	new_data_grads_norm = 8.0654
	old_data_grads_norm = 7.2860
	sim_grads_norm_tr = 0.0008
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3034
	data_grads_norm = 6.2213
	new_data_grads_norm = 8.3558
	old_data_grads_norm = 7.5664
	sim_grads_norm_tr = 0.0661
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4234
	data_grads_norm = 4.4793
	new_data_grads_norm = 7.7423
	old_data_grads_norm = 5.0393
	sim_grads_norm_tr = -0.0105
-- Starting training on experience 17 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7516
	data_grads_norm = 5.1152
	new_data_grads_norm = 7.7719
	old_data_grads_norm = 5.3958
	sim_grads_norm_tr = -0.0127
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1396
	data_grads_norm = 5.8958
	new_data_grads_norm = 8.9432
	old_data_grads_norm = 7.2176
	sim_grads_norm_tr = 0.0235
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8822
	data_grads_norm = 5.7199
	new_data_grads_norm = 8.9533
	old_data_grads_norm = 6.0604
	sim_grads_norm_tr = 0.0033
-- Starting training on experience 18 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.8330
	data_grads_norm = 6.4521
	new_data_grads_norm = 8.0738
	old_data_grads_norm = 8.7846
	sim_grads_norm_tr = 0.0009
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3898
	data_grads_norm = 6.4444
	new_data_grads_norm = 7.9824
	old_data_grads_norm = 9.0475
	sim_grads_norm_tr = 0.0159
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2358
	data_grads_norm = 5.8541
	new_data_grads_norm = 8.1531
	old_data_grads_norm = 6.8177
	sim_grads_norm_tr = 0.1289
-- Starting training on experience 19 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4512
	data_grads_norm = 4.9572
	new_data_grads_norm = 7.7718
	old_data_grads_norm = 5.4721
	sim_grads_norm_tr = 0.0647
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1187
	data_grads_norm = 4.9425
	new_data_grads_norm = 7.3749
	old_data_grads_norm = 6.7993
	sim_grads_norm_tr = -0.0015
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7365
	data_grads_norm = 4.9704
	new_data_grads_norm = 7.6058
	old_data_grads_norm = 7.3764
	sim_grads_norm_tr = -0.0047
-- Starting training on experience 20 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2150
	data_grads_norm = 5.3480
	new_data_grads_norm = 7.7902
	old_data_grads_norm = 6.4192
	sim_grads_norm_tr = -0.0162
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4627
	data_grads_norm = 5.9920
	new_data_grads_norm = 8.5933
	old_data_grads_norm = 6.5059
	sim_grads_norm_tr = -0.0154
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7446
	data_grads_norm = 6.4196
	new_data_grads_norm = 9.3678
	old_data_grads_norm = 6.8950
	sim_grads_norm_tr = 0.0277
-- Starting training on experience 21 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1340
	data_grads_norm = 6.8949
	new_data_grads_norm = 9.2032
	old_data_grads_norm = 9.3847
	sim_grads_norm_tr = 0.0280
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4756
	data_grads_norm = 5.0572
	new_data_grads_norm = 8.2406
	old_data_grads_norm = 5.6267
	sim_grads_norm_tr = 0.0077
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3088
	data_grads_norm = 4.6562
	new_data_grads_norm = 8.8068
	old_data_grads_norm = 3.7483
	sim_grads_norm_tr = -0.0116
-- Starting training on experience 22 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4418
	data_grads_norm = 5.0636
	new_data_grads_norm = 8.2746
	old_data_grads_norm = 4.1029
	sim_grads_norm_tr = -0.0075
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7128
	data_grads_norm = 6.2930
	new_data_grads_norm = 8.7934
	old_data_grads_norm = 8.5733
	sim_grads_norm_tr = 0.0211
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4110
	data_grads_norm = 5.5829
	new_data_grads_norm = 8.9174
	old_data_grads_norm = 6.6099
	sim_grads_norm_tr = 0.0674
-- Starting training on experience 23 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3674
	data_grads_norm = 4.8602
	new_data_grads_norm = 8.1221
	old_data_grads_norm = 4.9796
	sim_grads_norm_tr = 0.0048
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4709
	data_grads_norm = 5.1117
	new_data_grads_norm = 7.6196
	old_data_grads_norm = 7.2214
	sim_grads_norm_tr = 0.0176
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6160
	data_grads_norm = 6.3515
	new_data_grads_norm = 9.4406
	old_data_grads_norm = 8.6084
	sim_grads_norm_tr = -0.0217
-- Starting training on experience 24 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1075
	data_grads_norm = 4.8847
	new_data_grads_norm = 8.4831
	old_data_grads_norm = 5.3722
	sim_grads_norm_tr = 0.0016
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2943
	data_grads_norm = 5.2901
	new_data_grads_norm = 8.3272
	old_data_grads_norm = 7.0080
	sim_grads_norm_tr = 0.0287
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4707
	data_grads_norm = 5.1719
	new_data_grads_norm = 8.6859
	old_data_grads_norm = 6.5291
	sim_grads_norm_tr = 0.0527
-- Starting training on experience 25 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3470
	data_grads_norm = 6.1416
	new_data_grads_norm = 9.9719
	old_data_grads_norm = 6.7516
	sim_grads_norm_tr = -0.0115
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6442
	data_grads_norm = 5.8933
	new_data_grads_norm = 9.5739
	old_data_grads_norm = 4.8318
	sim_grads_norm_tr = 0.0642
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0852
	data_grads_norm = 4.9129
	new_data_grads_norm = 9.2840
	old_data_grads_norm = 4.5936
	sim_grads_norm_tr = 0.0061
-- Starting training on experience 26 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0337
	data_grads_norm = 4.9069
	new_data_grads_norm = 8.4932
	old_data_grads_norm = 5.8774
	sim_grads_norm_tr = 0.0007
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6721
	data_grads_norm = 5.5836
	new_data_grads_norm = 8.2837
	old_data_grads_norm = 6.8975
	sim_grads_norm_tr = 0.0166
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0300
	data_grads_norm = 4.9826
	new_data_grads_norm = 8.7575
	old_data_grads_norm = 3.3293
	sim_grads_norm_tr = -0.0237
-- Starting training on experience 27 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4618
	data_grads_norm = 5.9331
	new_data_grads_norm = 8.3358
	old_data_grads_norm = 6.6720
	sim_grads_norm_tr = 0.0482
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6934
	data_grads_norm = 6.7614
	new_data_grads_norm = 8.3974
	old_data_grads_norm = 8.8505
	sim_grads_norm_tr = 0.0533
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7758
	data_grads_norm = 4.6585
	new_data_grads_norm = 7.0310
	old_data_grads_norm = 5.3047
	sim_grads_norm_tr = -0.0028
-- Starting training on experience 28 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6469
	data_grads_norm = 6.6623
	new_data_grads_norm = 10.8905
	old_data_grads_norm = 6.1951
	sim_grads_norm_tr = -0.0178
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4493
	data_grads_norm = 6.4805
	new_data_grads_norm = 10.8809
	old_data_grads_norm = 7.6470
	sim_grads_norm_tr = 0.0092
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5824
	data_grads_norm = 6.8921
	new_data_grads_norm = 10.5074
	old_data_grads_norm = 7.2855
	sim_grads_norm_tr = -0.0240
-- Starting training on experience 29 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9492
	data_grads_norm = 4.8647
	new_data_grads_norm = 6.5794
	old_data_grads_norm = 7.2561
	sim_grads_norm_tr = 0.0819
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8306
	data_grads_norm = 5.6170
	new_data_grads_norm = 7.2896
	old_data_grads_norm = 7.4577
	sim_grads_norm_tr = 0.0109
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9692
	data_grads_norm = 5.5733
	new_data_grads_norm = 6.9534
	old_data_grads_norm = 8.4598
	sim_grads_norm_tr = -0.0409
-- Starting training on experience 30 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5160
	data_grads_norm = 6.3926
	new_data_grads_norm = 8.1850
	old_data_grads_norm = 8.7576
	sim_grads_norm_tr = 0.0076
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0486
	data_grads_norm = 4.8902
	new_data_grads_norm = 8.9605
	old_data_grads_norm = 5.5928
	sim_grads_norm_tr = -0.0158
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1940
	data_grads_norm = 4.8364
	new_data_grads_norm = 8.9865
	old_data_grads_norm = 4.5116
	sim_grads_norm_tr = 0.0365
-- Starting training on experience 31 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8979
	data_grads_norm = 6.2421
	new_data_grads_norm = 10.9518
	old_data_grads_norm = 6.5907
	sim_grads_norm_tr = 0.0272
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4953
	data_grads_norm = 4.8791
	new_data_grads_norm = 8.0583
	old_data_grads_norm = 6.0300
	sim_grads_norm_tr = -0.0445
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2887
	data_grads_norm = 6.6443
	new_data_grads_norm = 8.3509
	old_data_grads_norm = 9.7565
	sim_grads_norm_tr = 0.0397
-- Starting training on experience 32 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7364
	data_grads_norm = 5.3081
	new_data_grads_norm = 8.4933
	old_data_grads_norm = 6.3188
	sim_grads_norm_tr = -0.0027
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7167
	data_grads_norm = 5.5375
	new_data_grads_norm = 7.7549
	old_data_grads_norm = 6.9577
	sim_grads_norm_tr = 0.0006
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0537
	data_grads_norm = 6.1282
	new_data_grads_norm = 7.7663
	old_data_grads_norm = 6.8314
	sim_grads_norm_tr = 0.0623
-- Starting training on experience 33 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3083
	data_grads_norm = 6.1379
	new_data_grads_norm = 9.6954
	old_data_grads_norm = 8.3373
	sim_grads_norm_tr = -0.0220
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0566
	data_grads_norm = 5.7521
	new_data_grads_norm = 9.9115
	old_data_grads_norm = 6.0915
	sim_grads_norm_tr = 0.0135
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6727
	data_grads_norm = 4.4518
	new_data_grads_norm = 8.3076
	old_data_grads_norm = 4.5384
	sim_grads_norm_tr = 0.0091
-- Starting training on experience 34 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3096
	data_grads_norm = 6.3010
	new_data_grads_norm = 8.2403
	old_data_grads_norm = 8.3635
	sim_grads_norm_tr = 0.0425
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9337
	data_grads_norm = 5.7832
	new_data_grads_norm = 7.9528
	old_data_grads_norm = 5.4775
	sim_grads_norm_tr = 0.0445
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0415
	data_grads_norm = 5.6285
	new_data_grads_norm = 7.7313
	old_data_grads_norm = 5.7069
	sim_grads_norm_tr = 0.0124
-- Starting training on experience 35 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5637
	data_grads_norm = 5.5732
	new_data_grads_norm = 8.6291
	old_data_grads_norm = 6.9775
	sim_grads_norm_tr = -0.0446
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0345
	data_grads_norm = 5.3475
	new_data_grads_norm = 8.9145
	old_data_grads_norm = 6.5694
	sim_grads_norm_tr = -0.0016
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3350
	data_grads_norm = 6.2519
	new_data_grads_norm = 8.8053
	old_data_grads_norm = 7.4720
	sim_grads_norm_tr = 0.0076
-- Starting training on experience 36 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8227
	data_grads_norm = 4.7419
	new_data_grads_norm = 8.2179
	old_data_grads_norm = 4.7658
	sim_grads_norm_tr = 0.0456
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6046
	data_grads_norm = 5.7469
	new_data_grads_norm = 8.1125
	old_data_grads_norm = 7.6418
	sim_grads_norm_tr = -0.0069
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0965
	data_grads_norm = 6.0838
	new_data_grads_norm = 9.2295
	old_data_grads_norm = 6.3181
	sim_grads_norm_tr = 0.0272
-- Starting training on experience 37 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4320
	data_grads_norm = 4.6563
	new_data_grads_norm = 6.8036
	old_data_grads_norm = 4.9758
	sim_grads_norm_tr = 0.0014
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7045
	data_grads_norm = 5.3230
	new_data_grads_norm = 8.2146
	old_data_grads_norm = 5.9176
	sim_grads_norm_tr = -0.0076
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5056
	data_grads_norm = 5.4798
	new_data_grads_norm = 7.9949
	old_data_grads_norm = 7.7297
	sim_grads_norm_tr = 0.0055
-- Starting training on experience 38 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0615
	data_grads_norm = 5.4948
	new_data_grads_norm = 9.1595
	old_data_grads_norm = 6.0945
	sim_grads_norm_tr = 0.0045
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5293
	data_grads_norm = 4.8864
	new_data_grads_norm = 8.4145
	old_data_grads_norm = 4.7627
	sim_grads_norm_tr = -0.0158
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6293
	data_grads_norm = 5.2674
	new_data_grads_norm = 9.4103
	old_data_grads_norm = 4.3853
	sim_grads_norm_tr = 0.0034
-- Starting training on experience 39 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3427
	data_grads_norm = 5.9953
	new_data_grads_norm = 9.1144
	old_data_grads_norm = 7.2913
	sim_grads_norm_tr = 0.0375
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0632
	data_grads_norm = 5.6696
	new_data_grads_norm = 9.5586
	old_data_grads_norm = 6.0326
	sim_grads_norm_tr = -0.0066
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6832
	data_grads_norm = 6.9560
	new_data_grads_norm = 8.8532
	old_data_grads_norm = 9.6473
	sim_grads_norm_tr = -0.0169
-- Starting training on experience 40 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4931
	data_grads_norm = 7.2609
	new_data_grads_norm = 9.0040
	old_data_grads_norm = 9.0140
	sim_grads_norm_tr = 0.0343
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1834
	data_grads_norm = 6.0715
	new_data_grads_norm = 8.7175
	old_data_grads_norm = 7.5896
	sim_grads_norm_tr = 0.0219
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0784
	data_grads_norm = 5.7697
	new_data_grads_norm = 8.6596
	old_data_grads_norm = 5.8648
	sim_grads_norm_tr = -0.0210
-- Starting training on experience 41 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6762
	data_grads_norm = 5.2962
	new_data_grads_norm = 7.6591
	old_data_grads_norm = 6.6603
	sim_grads_norm_tr = 0.0023
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0407
	data_grads_norm = 5.8971
	new_data_grads_norm = 8.1006
	old_data_grads_norm = 7.3828
	sim_grads_norm_tr = 0.0344
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6007
	data_grads_norm = 4.7193
	new_data_grads_norm = 7.6157
	old_data_grads_norm = 6.7670
	sim_grads_norm_tr = -0.0051
-- Starting training on experience 42 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7984
	data_grads_norm = 5.6469
	new_data_grads_norm = 8.6540
	old_data_grads_norm = 7.5463
	sim_grads_norm_tr = 0.0242
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6781
	data_grads_norm = 4.8697
	new_data_grads_norm = 7.8180
	old_data_grads_norm = 6.7057
	sim_grads_norm_tr = 0.0261
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6872
	data_grads_norm = 5.3734
	new_data_grads_norm = 8.6141
	old_data_grads_norm = 8.2653
	sim_grads_norm_tr = -0.0025
-- Starting training on experience 43 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2360
	data_grads_norm = 6.4259
	new_data_grads_norm = 8.3551
	old_data_grads_norm = 9.2485
	sim_grads_norm_tr = 0.0005
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7153
	data_grads_norm = 6.5601
	new_data_grads_norm = 8.5298
	old_data_grads_norm = 7.4916
	sim_grads_norm_tr = 0.1175
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6423
	data_grads_norm = 5.8080
	new_data_grads_norm = 8.0200
	old_data_grads_norm = 7.6047
	sim_grads_norm_tr = 0.0393
-- Starting training on experience 44 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0802
	data_grads_norm = 6.1634
	new_data_grads_norm = 7.9574
	old_data_grads_norm = 6.8321
	sim_grads_norm_tr = 0.0026
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9991
	data_grads_norm = 5.9993
	new_data_grads_norm = 8.7498
	old_data_grads_norm = 7.5725
	sim_grads_norm_tr = 0.0075
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4744
	data_grads_norm = 5.3954
	new_data_grads_norm = 9.0268
	old_data_grads_norm = 5.0990
	sim_grads_norm_tr = -0.0147
-- Starting training on experience 45 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7609
	data_grads_norm = 5.5015
	new_data_grads_norm = 8.0027
	old_data_grads_norm = 9.5290
	sim_grads_norm_tr = 0.0072
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6893
	data_grads_norm = 5.6867
	new_data_grads_norm = 8.0141
	old_data_grads_norm = 9.8324
	sim_grads_norm_tr = 0.0115
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7834
	data_grads_norm = 6.6878
	new_data_grads_norm = 8.2395
	old_data_grads_norm = 10.3572
	sim_grads_norm_tr = -0.0107
-- Starting training on experience 46 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8797
	data_grads_norm = 5.8612
	new_data_grads_norm = 8.4551
	old_data_grads_norm = 7.2478
	sim_grads_norm_tr = -0.0083
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8894
	data_grads_norm = 5.8710
	new_data_grads_norm = 8.1444
	old_data_grads_norm = 8.8678
	sim_grads_norm_tr = 0.0017
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0599
	data_grads_norm = 6.3445
	new_data_grads_norm = 7.9281
	old_data_grads_norm = 8.2428
	sim_grads_norm_tr = -0.0273
-- Starting training on experience 47 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5921
	data_grads_norm = 4.7909
	new_data_grads_norm = 8.0842
	old_data_grads_norm = 5.1091
	sim_grads_norm_tr = 0.0128
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7514
	data_grads_norm = 5.5756
	new_data_grads_norm = 7.4638
	old_data_grads_norm = 7.7563
	sim_grads_norm_tr = -0.0027
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7040
	data_grads_norm = 5.3363
	new_data_grads_norm = 8.2194
	old_data_grads_norm = 7.1054
	sim_grads_norm_tr = -0.0196
-- Starting training on experience 48 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8237
	data_grads_norm = 5.5065
	new_data_grads_norm = 7.5607
	old_data_grads_norm = 7.3664
	sim_grads_norm_tr = -0.0318
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6735
	data_grads_norm = 4.7671
	new_data_grads_norm = 8.4270
	old_data_grads_norm = 5.9687
	sim_grads_norm_tr = -0.0210
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4835
	data_grads_norm = 5.1547
	new_data_grads_norm = 7.9654
	old_data_grads_norm = 7.1422
	sim_grads_norm_tr = 0.0214
-- Starting training on experience 49 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2634
	data_grads_norm = 6.6039
	new_data_grads_norm = 9.3608
	old_data_grads_norm = 8.0964
	sim_grads_norm_tr = -0.0061
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1079
	data_grads_norm = 5.9748
	new_data_grads_norm = 9.9177
	old_data_grads_norm = 6.4514
	sim_grads_norm_tr = 0.0020
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8125
	data_grads_norm = 5.7282
	new_data_grads_norm = 9.5915
	old_data_grads_norm = 6.5014
	sim_grads_norm_tr = 0.0027
-- Starting training on experience 50 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1994
	data_grads_norm = 6.3184
	new_data_grads_norm = 8.9611
	old_data_grads_norm = 8.7369
	sim_grads_norm_tr = -0.0102
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6890
	data_grads_norm = 5.0781
	new_data_grads_norm = 9.1178
	old_data_grads_norm = 5.6053
	sim_grads_norm_tr = 0.0578
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0315
	data_grads_norm = 4.9548
	new_data_grads_norm = 8.4011
	old_data_grads_norm = 5.6491
	sim_grads_norm_tr = 0.0655
-- Starting training on experience 51 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9956
	data_grads_norm = 6.8420
	new_data_grads_norm = 10.1038
	old_data_grads_norm = 6.1399
	sim_grads_norm_tr = -0.0077
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5993
	data_grads_norm = 5.7940
	new_data_grads_norm = 9.9203
	old_data_grads_norm = 7.5601
	sim_grads_norm_tr = 0.0121
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5578
	data_grads_norm = 7.0431
	new_data_grads_norm = 10.5686
	old_data_grads_norm = 7.8536
	sim_grads_norm_tr = -0.0237
-- Starting training on experience 52 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9283
	data_grads_norm = 5.9578
	new_data_grads_norm = 10.3886
	old_data_grads_norm = 3.5540
	sim_grads_norm_tr = -0.0132
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9820
	data_grads_norm = 7.2775
	new_data_grads_norm = 10.1491
	old_data_grads_norm = 8.7137
	sim_grads_norm_tr = -0.0090
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3685
	data_grads_norm = 5.7585
	new_data_grads_norm = 8.9910
	old_data_grads_norm = 5.9474
	sim_grads_norm_tr = 0.0645
-- Starting training on experience 53 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6332
	data_grads_norm = 4.8563
	new_data_grads_norm = 7.2372
	old_data_grads_norm = 6.1419
	sim_grads_norm_tr = -0.0120
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7482
	data_grads_norm = 4.4046
	new_data_grads_norm = 7.3535
	old_data_grads_norm = 5.5020
	sim_grads_norm_tr = -0.0312
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0210
	data_grads_norm = 5.4405
	new_data_grads_norm = 8.0958
	old_data_grads_norm = 8.4099
	sim_grads_norm_tr = -0.0343
-- Starting training on experience 54 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7204
	data_grads_norm = 5.5166
	new_data_grads_norm = 8.0755
	old_data_grads_norm = 8.7971
	sim_grads_norm_tr = 0.0044
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8404
	data_grads_norm = 6.1506
	new_data_grads_norm = 9.1582
	old_data_grads_norm = 8.9613
	sim_grads_norm_tr = 0.0047
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4716
	data_grads_norm = 6.7717
	new_data_grads_norm = 9.0255
	old_data_grads_norm = 10.4827
	sim_grads_norm_tr = 0.0239
-- Starting training on experience 55 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8906
	data_grads_norm = 5.5718
	new_data_grads_norm = 8.8587
	old_data_grads_norm = 9.3481
	sim_grads_norm_tr = 0.0194
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2034
	data_grads_norm = 6.3704
	new_data_grads_norm = 8.2241
	old_data_grads_norm = 9.0723
	sim_grads_norm_tr = 0.0289
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8088
	data_grads_norm = 5.0061
	new_data_grads_norm = 8.2280
	old_data_grads_norm = 5.6225
	sim_grads_norm_tr = -0.0095
-- Starting training on experience 56 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7632
	data_grads_norm = 5.4347
	new_data_grads_norm = 6.9481
	old_data_grads_norm = 8.0768
	sim_grads_norm_tr = -0.0246
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9904
	data_grads_norm = 5.9718
	new_data_grads_norm = 8.0505
	old_data_grads_norm = 8.7013
	sim_grads_norm_tr = 0.0158
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1314
	data_grads_norm = 5.7355
	new_data_grads_norm = 7.6767
	old_data_grads_norm = 8.1135
	sim_grads_norm_tr = -0.0237
-- Starting training on experience 57 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7331
	data_grads_norm = 5.1059
	new_data_grads_norm = 8.6725
	old_data_grads_norm = 7.7137
	sim_grads_norm_tr = 0.0704
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6752
	data_grads_norm = 4.9811
	new_data_grads_norm = 7.9419
	old_data_grads_norm = 5.3551
	sim_grads_norm_tr = 0.0543
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4389
	data_grads_norm = 5.3184
	new_data_grads_norm = 9.0216
	old_data_grads_norm = 5.5273
	sim_grads_norm_tr = 0.0021
-- Starting training on experience 58 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6301
	data_grads_norm = 5.5713
	new_data_grads_norm = 8.9401
	old_data_grads_norm = 4.6339
	sim_grads_norm_tr = -0.0129
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4494
	data_grads_norm = 6.7424
	new_data_grads_norm = 9.2038
	old_data_grads_norm = 8.3451
	sim_grads_norm_tr = -0.0038
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8602
	data_grads_norm = 6.5307
	new_data_grads_norm = 10.2688
	old_data_grads_norm = 7.3317
	sim_grads_norm_tr = -0.0215
-- Starting training on experience 59 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9846
	data_grads_norm = 5.1849
	new_data_grads_norm = 7.0358
	old_data_grads_norm = 7.8382
	sim_grads_norm_tr = 0.0119
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7507
	data_grads_norm = 4.7726
	new_data_grads_norm = 7.4317
	old_data_grads_norm = 5.8735
	sim_grads_norm_tr = 0.0944
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8620
	data_grads_norm = 5.1500
	new_data_grads_norm = 7.0971
	old_data_grads_norm = 6.7777
	sim_grads_norm_tr = -0.0189
-- Starting training on experience 60 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8626
	data_grads_norm = 5.4700
	new_data_grads_norm = 7.0393
	old_data_grads_norm = 7.1728
	sim_grads_norm_tr = 0.0410
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7455
	data_grads_norm = 4.9042
	new_data_grads_norm = 7.9058
	old_data_grads_norm = 4.2393
	sim_grads_norm_tr = 0.0605
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0305
	data_grads_norm = 5.4149
	new_data_grads_norm = 8.1289
	old_data_grads_norm = 6.6024
	sim_grads_norm_tr = 0.0365
-- Starting training on experience 61 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5882
	data_grads_norm = 5.4586
	new_data_grads_norm = 8.1081
	old_data_grads_norm = 5.9915
	sim_grads_norm_tr = 0.0572
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3392
	data_grads_norm = 4.7538
	new_data_grads_norm = 8.1323
	old_data_grads_norm = 7.4221
	sim_grads_norm_tr = -0.0156
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9643
	data_grads_norm = 6.1842
	new_data_grads_norm = 8.6042
	old_data_grads_norm = 7.7656
	sim_grads_norm_tr = 0.0027
-- Starting training on experience 62 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4576
	data_grads_norm = 4.5732
	new_data_grads_norm = 7.2954
	old_data_grads_norm = 5.9658
	sim_grads_norm_tr = -0.0284
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7514
	data_grads_norm = 5.0822
	new_data_grads_norm = 7.4283
	old_data_grads_norm = 6.2346
	sim_grads_norm_tr = 0.0801
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5720
	data_grads_norm = 5.0941
	new_data_grads_norm = 7.7902
	old_data_grads_norm = 6.3243
	sim_grads_norm_tr = -0.0052
-- Starting training on experience 63 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2199
	data_grads_norm = 6.6271
	new_data_grads_norm = 9.1458
	old_data_grads_norm = 8.3674
	sim_grads_norm_tr = -0.0020
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4092
	data_grads_norm = 6.8586
	new_data_grads_norm = 9.1346
	old_data_grads_norm = 7.5400
	sim_grads_norm_tr = -0.0098
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4285
	data_grads_norm = 6.8993
	new_data_grads_norm = 8.7969
	old_data_grads_norm = 8.5859
	sim_grads_norm_tr = 0.0005
-- Starting training on experience 64 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1335
	data_grads_norm = 5.6397
	new_data_grads_norm = 7.7274
	old_data_grads_norm = 7.7399
	sim_grads_norm_tr = 0.0309
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0482
	data_grads_norm = 5.3189
	new_data_grads_norm = 7.7744
	old_data_grads_norm = 6.8645
	sim_grads_norm_tr = -0.0165
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7785
	data_grads_norm = 5.2450
	new_data_grads_norm = 8.4754
	old_data_grads_norm = 7.1938
	sim_grads_norm_tr = -0.0006
-- Starting training on experience 65 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6176
	data_grads_norm = 5.7216
	new_data_grads_norm = 9.5913
	old_data_grads_norm = 5.5748
	sim_grads_norm_tr = 0.0142
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9023
	data_grads_norm = 5.9991
	new_data_grads_norm = 9.3259
	old_data_grads_norm = 7.3441
	sim_grads_norm_tr = -0.0050
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9398
	data_grads_norm = 5.4029
	new_data_grads_norm = 9.3336
	old_data_grads_norm = 5.3196
	sim_grads_norm_tr = -0.0185
-- Starting training on experience 66 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1286
	data_grads_norm = 6.2651
	new_data_grads_norm = 9.8790
	old_data_grads_norm = 7.0378
	sim_grads_norm_tr = -0.0122
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6632
	data_grads_norm = 5.8199
	new_data_grads_norm = 9.7007
	old_data_grads_norm = 6.3355
	sim_grads_norm_tr = -0.0196
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0658
	data_grads_norm = 5.9203
	new_data_grads_norm = 10.5479
	old_data_grads_norm = 4.8669
	sim_grads_norm_tr = 0.0056
-- Starting training on experience 67 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7974
	data_grads_norm = 5.5425
	new_data_grads_norm = 7.4844
	old_data_grads_norm = 6.2194
	sim_grads_norm_tr = -0.0332
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8329
	data_grads_norm = 5.1794
	new_data_grads_norm = 8.3887
	old_data_grads_norm = 6.9817
	sim_grads_norm_tr = -0.0004
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4910
	data_grads_norm = 4.3546
	new_data_grads_norm = 8.0698
	old_data_grads_norm = 3.1177
	sim_grads_norm_tr = 0.0580
-- Starting training on experience 68 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0334
	data_grads_norm = 6.3154
	new_data_grads_norm = 9.9581
	old_data_grads_norm = 8.1246
	sim_grads_norm_tr = 0.0340
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7066
	data_grads_norm = 5.1817
	new_data_grads_norm = 8.6973
	old_data_grads_norm = 8.2569
	sim_grads_norm_tr = 0.0323
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6749
	data_grads_norm = 5.0839
	new_data_grads_norm = 9.8218
	old_data_grads_norm = 5.1777
	sim_grads_norm_tr = -0.0214
-- Starting training on experience 69 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9033
	data_grads_norm = 5.7109
	new_data_grads_norm = 8.8585
	old_data_grads_norm = 7.9122
	sim_grads_norm_tr = -0.0006
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3771
	data_grads_norm = 6.0317
	new_data_grads_norm = 8.5755
	old_data_grads_norm = 7.3033
	sim_grads_norm_tr = -0.0288
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2590
	data_grads_norm = 6.5527
	new_data_grads_norm = 9.5576
	old_data_grads_norm = 10.2108
	sim_grads_norm_tr = 0.0256
-- Starting training on experience 70 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5570
	data_grads_norm = 4.7820
	new_data_grads_norm = 7.8875
	old_data_grads_norm = 5.2198
	sim_grads_norm_tr = 0.0005
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3856
	data_grads_norm = 4.8370
	new_data_grads_norm = 6.9106
	old_data_grads_norm = 6.3470
	sim_grads_norm_tr = -0.0175
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5362
	data_grads_norm = 4.9298
	new_data_grads_norm = 7.6272
	old_data_grads_norm = 7.4387
	sim_grads_norm_tr = -0.0043
-- Starting training on experience 71 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0240
	data_grads_norm = 5.3787
	new_data_grads_norm = 8.0669
	old_data_grads_norm = 5.6214
	sim_grads_norm_tr = -0.0073
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1276
	data_grads_norm = 5.7926
	new_data_grads_norm = 9.0064
	old_data_grads_norm = 7.4677
	sim_grads_norm_tr = -0.0272
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8611
	data_grads_norm = 5.2419
	new_data_grads_norm = 9.1047
	old_data_grads_norm = 4.2311
	sim_grads_norm_tr = 0.0128
-- Starting training on experience 72 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1857
	data_grads_norm = 5.9889
	new_data_grads_norm = 9.7581
	old_data_grads_norm = 6.6398
	sim_grads_norm_tr = 0.0292
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9317
	data_grads_norm = 5.3215
	new_data_grads_norm = 8.9778
	old_data_grads_norm = 8.9905
	sim_grads_norm_tr = -0.0076
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1890
	data_grads_norm = 4.8803
	new_data_grads_norm = 8.3881
	old_data_grads_norm = 5.7850
	sim_grads_norm_tr = 0.0922
-- Starting training on experience 73 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9221
	data_grads_norm = 5.9819
	new_data_grads_norm = 8.4583
	old_data_grads_norm = 7.7150
	sim_grads_norm_tr = -0.0303
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7739
	data_grads_norm = 5.5803
	new_data_grads_norm = 8.4798
	old_data_grads_norm = 7.1025
	sim_grads_norm_tr = 0.0208
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6308
	data_grads_norm = 4.7689
	new_data_grads_norm = 7.9989
	old_data_grads_norm = 5.3118
	sim_grads_norm_tr = 0.0311
-- Starting training on experience 74 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7834
	data_grads_norm = 4.9443
	new_data_grads_norm = 7.5749
	old_data_grads_norm = 8.1740
	sim_grads_norm_tr = -0.0204
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4448
	data_grads_norm = 4.8120
	new_data_grads_norm = 6.9887
	old_data_grads_norm = 6.4720
	sim_grads_norm_tr = 0.0128
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9503
	data_grads_norm = 5.3049
	new_data_grads_norm = 7.5673
	old_data_grads_norm = 7.4019
	sim_grads_norm_tr = 0.0878
-- Starting training on experience 75 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6711
	data_grads_norm = 4.8344
	new_data_grads_norm = 7.3638
	old_data_grads_norm = 5.9856
	sim_grads_norm_tr = 0.0616
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3455
	data_grads_norm = 4.8650
	new_data_grads_norm = 7.1276
	old_data_grads_norm = 7.8346
	sim_grads_norm_tr = -0.0297
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7402
	data_grads_norm = 5.7586
	new_data_grads_norm = 7.3210
	old_data_grads_norm = 8.6191
	sim_grads_norm_tr = 0.0431
-- Starting training on experience 76 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7480
	data_grads_norm = 6.0499
	new_data_grads_norm = 8.9311
	old_data_grads_norm = 7.2489
	sim_grads_norm_tr = 0.0314
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5495
	data_grads_norm = 5.1899
	new_data_grads_norm = 8.9715
	old_data_grads_norm = 4.1335
	sim_grads_norm_tr = 0.0635
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7197
	data_grads_norm = 5.9194
	new_data_grads_norm = 9.5375
	old_data_grads_norm = 5.8065
	sim_grads_norm_tr = -0.0049
-- Starting training on experience 77 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0096
	data_grads_norm = 6.6525
	new_data_grads_norm = 10.6475
	old_data_grads_norm = 7.1382
	sim_grads_norm_tr = 0.0830
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3951
	data_grads_norm = 5.3109
	new_data_grads_norm = 8.8253
	old_data_grads_norm = 5.6413
	sim_grads_norm_tr = -0.0073
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5034
	data_grads_norm = 5.3210
	new_data_grads_norm = 8.8285
	old_data_grads_norm = 7.8525
	sim_grads_norm_tr = -0.0122
-- Starting training on experience 78 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9175
	data_grads_norm = 6.7970
	new_data_grads_norm = 9.4465
	old_data_grads_norm = 8.1972
	sim_grads_norm_tr = 0.0155
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8303
	data_grads_norm = 6.1879
	new_data_grads_norm = 8.5873
	old_data_grads_norm = 6.6867
	sim_grads_norm_tr = 0.0034
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9778
	data_grads_norm = 5.6823
	new_data_grads_norm = 8.5847
	old_data_grads_norm = 8.1349
	sim_grads_norm_tr = 0.0656
-- Starting training on experience 79 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7277
	data_grads_norm = 6.2972
	new_data_grads_norm = 9.2125
	old_data_grads_norm = 8.6029
	sim_grads_norm_tr = 0.0210
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9592
	data_grads_norm = 6.3733
	new_data_grads_norm = 9.3179
	old_data_grads_norm = 8.7840
	sim_grads_norm_tr = -0.0171
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7714
	data_grads_norm = 5.7831
	new_data_grads_norm = 9.3845
	old_data_grads_norm = 7.3430
	sim_grads_norm_tr = 0.0128
-- Starting training on experience 80 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0553
	data_grads_norm = 6.3209
	new_data_grads_norm = 9.7180
	old_data_grads_norm = 7.7904
	sim_grads_norm_tr = 0.0456
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9068
	data_grads_norm = 6.0150
	new_data_grads_norm = 9.2760
	old_data_grads_norm = 7.9266
	sim_grads_norm_tr = -0.0637
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7170
	data_grads_norm = 5.1570
	new_data_grads_norm = 8.1217
	old_data_grads_norm = 6.8655
	sim_grads_norm_tr = -0.0045
-- Starting training on experience 81 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0692
	data_grads_norm = 5.0698
	new_data_grads_norm = 6.7770
	old_data_grads_norm = 5.2672
	sim_grads_norm_tr = 0.0947
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9169
	data_grads_norm = 5.0671
	new_data_grads_norm = 7.6488
	old_data_grads_norm = 5.5909
	sim_grads_norm_tr = -0.0011
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9260
	data_grads_norm = 5.1814
	new_data_grads_norm = 7.3406
	old_data_grads_norm = 6.6782
	sim_grads_norm_tr = -0.0278
-- Starting training on experience 82 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6967
	data_grads_norm = 6.0095
	new_data_grads_norm = 9.1571
	old_data_grads_norm = 7.0546
	sim_grads_norm_tr = -0.0248
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1305
	data_grads_norm = 6.7986
	new_data_grads_norm = 9.8297
	old_data_grads_norm = 10.0833
	sim_grads_norm_tr = 0.0077
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6258
	data_grads_norm = 7.1767
	new_data_grads_norm = 8.7080
	old_data_grads_norm = 10.1351
	sim_grads_norm_tr = 0.0093
-- Starting training on experience 83 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3912
	data_grads_norm = 4.9343
	new_data_grads_norm = 8.8590
	old_data_grads_norm = 6.7745
	sim_grads_norm_tr = -0.0448
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9617
	data_grads_norm = 6.3480
	new_data_grads_norm = 9.1908
	old_data_grads_norm = 7.4548
	sim_grads_norm_tr = 0.0067
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6323
	data_grads_norm = 5.8251
	new_data_grads_norm = 10.5188
	old_data_grads_norm = 5.8639
	sim_grads_norm_tr = 0.0280
-- Starting training on experience 84 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1398
	data_grads_norm = 5.5801
	new_data_grads_norm = 7.8768
	old_data_grads_norm = 7.5871
	sim_grads_norm_tr = 0.0103
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7613
	data_grads_norm = 4.7331
	new_data_grads_norm = 7.2395
	old_data_grads_norm = 5.0316
	sim_grads_norm_tr = -0.0062
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0136
	data_grads_norm = 6.6290
	new_data_grads_norm = 7.7135
	old_data_grads_norm = 12.1690
	sim_grads_norm_tr = -0.0154
-- Starting training on experience 85 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1688
	data_grads_norm = 6.3079
	new_data_grads_norm = 10.2378
	old_data_grads_norm = 6.9483
	sim_grads_norm_tr = 0.0123
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4123
	data_grads_norm = 6.4819
	new_data_grads_norm = 9.6456
	old_data_grads_norm = 8.9290
	sim_grads_norm_tr = -0.0233
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5513
	data_grads_norm = 6.6547
	new_data_grads_norm = 9.3647
	old_data_grads_norm = 7.6911
	sim_grads_norm_tr = -0.0074
-- Starting training on experience 86 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8097
	data_grads_norm = 6.1100
	new_data_grads_norm = 9.4845
	old_data_grads_norm = 7.4103
	sim_grads_norm_tr = 0.0025
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9583
	data_grads_norm = 5.9156
	new_data_grads_norm = 10.7523
	old_data_grads_norm = 4.9991
	sim_grads_norm_tr = 0.0040
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7837
	data_grads_norm = 6.5953
	new_data_grads_norm = 10.2401
	old_data_grads_norm = 8.4338
	sim_grads_norm_tr = -0.0032
-- Starting training on experience 87 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7514
	data_grads_norm = 6.1482
	new_data_grads_norm = 9.8064
	old_data_grads_norm = 7.7500
	sim_grads_norm_tr = 0.0197
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6213
	data_grads_norm = 5.0686
	new_data_grads_norm = 9.9973
	old_data_grads_norm = 4.8376
	sim_grads_norm_tr = 0.0221
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4604
	data_grads_norm = 4.5133
	new_data_grads_norm = 8.0056
	old_data_grads_norm = 7.0855
	sim_grads_norm_tr = -0.0285
-- Starting training on experience 88 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4459
	data_grads_norm = 5.8094
	new_data_grads_norm = 8.3704
	old_data_grads_norm = 8.3188
	sim_grads_norm_tr = 0.0160
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0671
	data_grads_norm = 4.7265
	new_data_grads_norm = 7.2963
	old_data_grads_norm = 5.7454
	sim_grads_norm_tr = 0.0818
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9058
	data_grads_norm = 5.9668
	new_data_grads_norm = 7.0119
	old_data_grads_norm = 7.7805
	sim_grads_norm_tr = -0.0293
-- Starting training on experience 89 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1169
	data_grads_norm = 8.0661
	new_data_grads_norm = 8.2183
	old_data_grads_norm = 12.8979
	sim_grads_norm_tr = 0.0078
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5068
	data_grads_norm = 6.2882
	new_data_grads_norm = 9.2450
	old_data_grads_norm = 7.5429
	sim_grads_norm_tr = 0.0070
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8969
	data_grads_norm = 6.3613
	new_data_grads_norm = 8.8663
	old_data_grads_norm = 7.5951
	sim_grads_norm_tr = 0.0256
-- Starting training on experience 90 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7866
	data_grads_norm = 5.8506
	new_data_grads_norm = 8.9339
	old_data_grads_norm = 5.8657
	sim_grads_norm_tr = 0.0097
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7694
	data_grads_norm = 6.0010
	new_data_grads_norm = 9.0964
	old_data_grads_norm = 6.3945
	sim_grads_norm_tr = -0.0078
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7169
	data_grads_norm = 5.9759
	new_data_grads_norm = 8.7709
	old_data_grads_norm = 5.3146
	sim_grads_norm_tr = 0.0477
-- Starting training on experience 91 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1965
	data_grads_norm = 5.5314
	new_data_grads_norm = 9.1044
	old_data_grads_norm = 5.0930
	sim_grads_norm_tr = -0.0050
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8030
	data_grads_norm = 6.0145
	new_data_grads_norm = 9.4831
	old_data_grads_norm = 7.3558
	sim_grads_norm_tr = 0.0086
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6445
	data_grads_norm = 6.4325
	new_data_grads_norm = 9.4755
	old_data_grads_norm = 7.2011
	sim_grads_norm_tr = -0.0186
-- Starting training on experience 92 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4971
	data_grads_norm = 6.4792
	new_data_grads_norm = 8.2648
	old_data_grads_norm = 9.0459
	sim_grads_norm_tr = -0.0053
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0473
	data_grads_norm = 5.2100
	new_data_grads_norm = 8.2799
	old_data_grads_norm = 6.4298
	sim_grads_norm_tr = -0.0126
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3978
	data_grads_norm = 5.7072
	new_data_grads_norm = 8.2993
	old_data_grads_norm = 6.2835
	sim_grads_norm_tr = 0.0033
-- Starting training on experience 93 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5996
	data_grads_norm = 5.4738
	new_data_grads_norm = 8.5862
	old_data_grads_norm = 8.5672
	sim_grads_norm_tr = 0.0068
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2909
	data_grads_norm = 5.2843
	new_data_grads_norm = 8.8740
	old_data_grads_norm = 6.1703
	sim_grads_norm_tr = -0.0204
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1328
	data_grads_norm = 5.0166
	new_data_grads_norm = 8.7211
	old_data_grads_norm = 7.4959
	sim_grads_norm_tr = -0.0097
-- Starting training on experience 94 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6659
	data_grads_norm = 5.3247
	new_data_grads_norm = 8.6458
	old_data_grads_norm = 6.8235
	sim_grads_norm_tr = -0.0083
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8052
	data_grads_norm = 6.3218
	new_data_grads_norm = 8.4138
	old_data_grads_norm = 7.6431
	sim_grads_norm_tr = 0.0507
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4346
	data_grads_norm = 5.7266
	new_data_grads_norm = 8.5268
	old_data_grads_norm = 7.5262
	sim_grads_norm_tr = -0.0033
-- Starting training on experience 95 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3314
	data_grads_norm = 6.5155
	new_data_grads_norm = 8.4021
	old_data_grads_norm = 9.4132
	sim_grads_norm_tr = -0.0315
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8476
	data_grads_norm = 6.0456
	new_data_grads_norm = 8.5769
	old_data_grads_norm = 6.7142
	sim_grads_norm_tr = 0.1172
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1461
	data_grads_norm = 5.1043
	new_data_grads_norm = 7.9925
	old_data_grads_norm = 6.3204
	sim_grads_norm_tr = 0.0267
-- Starting training on experience 96 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0852
	data_grads_norm = 5.3274
	new_data_grads_norm = 9.5210
	old_data_grads_norm = 6.6934
	sim_grads_norm_tr = -0.0194
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8281
	data_grads_norm = 6.5822
	new_data_grads_norm = 10.0980
	old_data_grads_norm = 6.6755
	sim_grads_norm_tr = -0.0081
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4182
	data_grads_norm = 5.6959
	new_data_grads_norm = 10.4480
	old_data_grads_norm = 6.0714
	sim_grads_norm_tr = -0.0137
-- Starting training on experience 97 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7034
	data_grads_norm = 6.4976
	new_data_grads_norm = 9.7410
	old_data_grads_norm = 7.9480
	sim_grads_norm_tr = -0.0076
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8306
	data_grads_norm = 5.7419
	new_data_grads_norm = 9.1676
	old_data_grads_norm = 6.3773
	sim_grads_norm_tr = 0.0160
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5694
	data_grads_norm = 5.4103
	new_data_grads_norm = 8.7697
	old_data_grads_norm = 6.8522
	sim_grads_norm_tr = 0.0003
-- Starting training on experience 98 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6047
	data_grads_norm = 4.9055
	new_data_grads_norm = 7.6390
	old_data_grads_norm = 4.9117
	sim_grads_norm_tr = 0.0179
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1178
	data_grads_norm = 5.4650
	new_data_grads_norm = 7.5542
	old_data_grads_norm = 6.9336
	sim_grads_norm_tr = -0.0233
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7125
	data_grads_norm = 5.8484
	new_data_grads_norm = 8.2729
	old_data_grads_norm = 10.7456
	sim_grads_norm_tr = -0.0009
-- Starting training on experience 99 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8025
	data_grads_norm = 6.0931
	new_data_grads_norm = 11.0519
	old_data_grads_norm = 4.7523
	sim_grads_norm_tr = 0.0246
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8995
	data_grads_norm = 6.6096
	new_data_grads_norm = 11.4030
	old_data_grads_norm = 5.9406
	sim_grads_norm_tr = 0.0219
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0986
	data_grads_norm = 6.7524
	new_data_grads_norm = 11.8100
	old_data_grads_norm = 6.0681
	sim_grads_norm_tr = 0.0813
-- Starting training on experience 100 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7570
	data_grads_norm = 6.9062
	new_data_grads_norm = 10.0723
	old_data_grads_norm = 7.8908
	sim_grads_norm_tr = -0.0009
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2029
	data_grads_norm = 5.7179
	new_data_grads_norm = 8.9254
	old_data_grads_norm = 7.7993
	sim_grads_norm_tr = 0.0242
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8030
	data_grads_norm = 6.4374
	new_data_grads_norm = 9.5168
	old_data_grads_norm = 8.2767
	sim_grads_norm_tr = 0.0140
-- Starting training on experience 101 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4756
	data_grads_norm = 6.5569
	new_data_grads_norm = 9.6832
	old_data_grads_norm = 8.1945
	sim_grads_norm_tr = 0.0485
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0872
	data_grads_norm = 6.4726
	new_data_grads_norm = 9.8341
	old_data_grads_norm = 8.3222
	sim_grads_norm_tr = -0.0032
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9486
	data_grads_norm = 6.4906
	new_data_grads_norm = 9.7167
	old_data_grads_norm = 8.2226
	sim_grads_norm_tr = 0.0316
-- Starting training on experience 102 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7402
	data_grads_norm = 5.9278
	new_data_grads_norm = 8.6136
	old_data_grads_norm = 6.6131
	sim_grads_norm_tr = 0.0267
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0244
	data_grads_norm = 6.2170
	new_data_grads_norm = 8.3234
	old_data_grads_norm = 9.6281
	sim_grads_norm_tr = 0.0258
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3783
	data_grads_norm = 5.2100
	new_data_grads_norm = 9.2169
	old_data_grads_norm = 3.7392
	sim_grads_norm_tr = -0.0112
-- Starting training on experience 103 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3355
	data_grads_norm = 5.3484
	new_data_grads_norm = 8.2124
	old_data_grads_norm = 7.1827
	sim_grads_norm_tr = -0.0140
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7125
	data_grads_norm = 6.7758
	new_data_grads_norm = 10.7507
	old_data_grads_norm = 9.1199
	sim_grads_norm_tr = 0.0250
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5269
	data_grads_norm = 5.3511
	new_data_grads_norm = 8.2516
	old_data_grads_norm = 7.1277
	sim_grads_norm_tr = -0.0031
-- Starting training on experience 104 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0465
	data_grads_norm = 6.4589
	new_data_grads_norm = 10.2437
	old_data_grads_norm = 6.6057
	sim_grads_norm_tr = 0.0111
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1782
	data_grads_norm = 6.4293
	new_data_grads_norm = 10.9314
	old_data_grads_norm = 6.9956
	sim_grads_norm_tr = 0.0031
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0425
	data_grads_norm = 6.3920
	new_data_grads_norm = 9.9806
	old_data_grads_norm = 6.9780
	sim_grads_norm_tr = -0.0172
-- Starting training on experience 105 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4477
	data_grads_norm = 5.8008
	new_data_grads_norm = 9.4352
	old_data_grads_norm = 6.6351
	sim_grads_norm_tr = -0.0038
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0998
	data_grads_norm = 6.6936
	new_data_grads_norm = 8.7628
	old_data_grads_norm = 7.6499
	sim_grads_norm_tr = 0.0635
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6062
	data_grads_norm = 6.2543
	new_data_grads_norm = 8.5846
	old_data_grads_norm = 8.1595
	sim_grads_norm_tr = 0.0177
-- Starting training on experience 106 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8895
	data_grads_norm = 4.2139
	new_data_grads_norm = 7.8326
	old_data_grads_norm = 3.5227
	sim_grads_norm_tr = -0.0112
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7235
	data_grads_norm = 5.3081
	new_data_grads_norm = 7.4817
	old_data_grads_norm = 8.3497
	sim_grads_norm_tr = 0.0691
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3371
	data_grads_norm = 5.0081
	new_data_grads_norm = 6.9017
	old_data_grads_norm = 5.8246
	sim_grads_norm_tr = 0.0606
-- Starting training on experience 107 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0192
	data_grads_norm = 4.1583
	new_data_grads_norm = 6.6920
	old_data_grads_norm = 5.1157
	sim_grads_norm_tr = -0.0167
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3726
	data_grads_norm = 5.1513
	new_data_grads_norm = 7.1692
	old_data_grads_norm = 8.1288
	sim_grads_norm_tr = -0.0472
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5291
	data_grads_norm = 4.6807
	new_data_grads_norm = 7.6974
	old_data_grads_norm = 6.6577
	sim_grads_norm_tr = 0.0728
-- Starting training on experience 108 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6325
	data_grads_norm = 5.5233
	new_data_grads_norm = 9.1646
	old_data_grads_norm = 4.6518
	sim_grads_norm_tr = 0.0188
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8175
	data_grads_norm = 6.1291
	new_data_grads_norm = 9.1040
	old_data_grads_norm = 7.0335
	sim_grads_norm_tr = 0.0179
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5663
	data_grads_norm = 5.3282
	new_data_grads_norm = 7.9770
	old_data_grads_norm = 6.2981
	sim_grads_norm_tr = -0.0130
-- Starting training on experience 109 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4034
	data_grads_norm = 5.3034
	new_data_grads_norm = 7.6705
	old_data_grads_norm = 6.2095
	sim_grads_norm_tr = 0.0691
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6359
	data_grads_norm = 5.2316
	new_data_grads_norm = 8.0533
	old_data_grads_norm = 7.3784
	sim_grads_norm_tr = -0.0493
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4332
	data_grads_norm = 5.3521
	new_data_grads_norm = 8.1832
	old_data_grads_norm = 5.2918
	sim_grads_norm_tr = -0.0157
-- Starting training on experience 110 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2761
	data_grads_norm = 4.8239
	new_data_grads_norm = 8.2407
	old_data_grads_norm = 4.5772
	sim_grads_norm_tr = 0.0325
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3680
	data_grads_norm = 4.9522
	new_data_grads_norm = 8.8528
	old_data_grads_norm = 6.0273
	sim_grads_norm_tr = -0.0637
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2779
	data_grads_norm = 4.9808
	new_data_grads_norm = 8.4000
	old_data_grads_norm = 5.9204
	sim_grads_norm_tr = 0.0024
-- Starting training on experience 111 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1833
	data_grads_norm = 4.4963
	new_data_grads_norm = 7.3016
	old_data_grads_norm = 5.6432
	sim_grads_norm_tr = -0.0048
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5016
	data_grads_norm = 5.4517
	new_data_grads_norm = 8.0116
	old_data_grads_norm = 6.2499
	sim_grads_norm_tr = 0.0739
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4650
	data_grads_norm = 5.3064
	new_data_grads_norm = 8.0550
	old_data_grads_norm = 5.7387
	sim_grads_norm_tr = 0.0048
-- Starting training on experience 112 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4992
	data_grads_norm = 5.3560
	new_data_grads_norm = 8.4009
	old_data_grads_norm = 8.4881
	sim_grads_norm_tr = -0.0163
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4362
	data_grads_norm = 5.2884
	new_data_grads_norm = 7.6735
	old_data_grads_norm = 6.3050
	sim_grads_norm_tr = 0.0497
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4491
	data_grads_norm = 5.6453
	new_data_grads_norm = 7.9741
	old_data_grads_norm = 7.9434
	sim_grads_norm_tr = 0.0236
-- Starting training on experience 113 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3193
	data_grads_norm = 4.6022
	new_data_grads_norm = 8.9672
	old_data_grads_norm = 5.1195
	sim_grads_norm_tr = -0.0181
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6364
	data_grads_norm = 5.3523
	new_data_grads_norm = 8.9629
	old_data_grads_norm = 6.7806
	sim_grads_norm_tr = 0.0169
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1884
	data_grads_norm = 4.5583
	new_data_grads_norm = 8.5799
	old_data_grads_norm = 5.1061
	sim_grads_norm_tr = 0.0115
-- Starting training on experience 114 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8104
	data_grads_norm = 5.1498
	new_data_grads_norm = 9.3380
	old_data_grads_norm = 4.6477
	sim_grads_norm_tr = -0.0413
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1042
	data_grads_norm = 6.7800
	new_data_grads_norm = 9.7153
	old_data_grads_norm = 8.3923
	sim_grads_norm_tr = 0.0198
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6640
	data_grads_norm = 5.6464
	new_data_grads_norm = 9.0403
	old_data_grads_norm = 6.1766
	sim_grads_norm_tr = -0.0154
-- Starting training on experience 115 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2326
	data_grads_norm = 5.6053
	new_data_grads_norm = 9.0173
	old_data_grads_norm = 6.7254
	sim_grads_norm_tr = -0.0081
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9726
	data_grads_norm = 6.0018
	new_data_grads_norm = 9.1423
	old_data_grads_norm = 7.9569
	sim_grads_norm_tr = 0.0114
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8885
	data_grads_norm = 6.3202
	new_data_grads_norm = 8.9725
	old_data_grads_norm = 7.3440
	sim_grads_norm_tr = 0.0471
-- Starting training on experience 116 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4179
	data_grads_norm = 5.0617
	new_data_grads_norm = 8.8947
	old_data_grads_norm = 5.9440
	sim_grads_norm_tr = -0.0154
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2617
	data_grads_norm = 5.4260
	new_data_grads_norm = 8.5339
	old_data_grads_norm = 6.0014
	sim_grads_norm_tr = -0.0101
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7088
	data_grads_norm = 6.0384
	new_data_grads_norm = 7.8067
	old_data_grads_norm = 7.8265
	sim_grads_norm_tr = -0.0038
-- Starting training on experience 117 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9130
	data_grads_norm = 6.0651
	new_data_grads_norm = 8.8721
	old_data_grads_norm = 6.8086
	sim_grads_norm_tr = 0.1261
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4802
	data_grads_norm = 5.4483
	new_data_grads_norm = 8.1505
	old_data_grads_norm = 7.2880
	sim_grads_norm_tr = -0.0059
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3832
	data_grads_norm = 5.4356
	new_data_grads_norm = 7.9883
	old_data_grads_norm = 8.9021
	sim_grads_norm_tr = -0.0287
-- Starting training on experience 118 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3103
	data_grads_norm = 6.3831
	new_data_grads_norm = 9.1348
	old_data_grads_norm = 8.5900
	sim_grads_norm_tr = -0.0042
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3915
	data_grads_norm = 5.0836
	new_data_grads_norm = 8.9808
	old_data_grads_norm = 5.5043
	sim_grads_norm_tr = -0.0532
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5001
	data_grads_norm = 5.1038
	new_data_grads_norm = 8.4833
	old_data_grads_norm = 4.9318
	sim_grads_norm_tr = -0.0214
-- Starting training on experience 119 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7275
	data_grads_norm = 5.7186
	new_data_grads_norm = 9.2047
	old_data_grads_norm = 8.7310
	sim_grads_norm_tr = -0.0272
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6432
	data_grads_norm = 5.9030
	new_data_grads_norm = 9.4734
	old_data_grads_norm = 6.9337
	sim_grads_norm_tr = 0.0097
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5375
	data_grads_norm = 4.9838
	new_data_grads_norm = 7.5159
	old_data_grads_norm = 6.7951
	sim_grads_norm_tr = -0.0233
-- Starting training on experience 120 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6441
	data_grads_norm = 5.6590
	new_data_grads_norm = 8.3712
	old_data_grads_norm = 7.4375
	sim_grads_norm_tr = -0.0050
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7332
	data_grads_norm = 5.3911
	new_data_grads_norm = 10.2668
	old_data_grads_norm = 6.0464
	sim_grads_norm_tr = 0.0035
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1112
	data_grads_norm = 4.6006
	new_data_grads_norm = 8.6093
	old_data_grads_norm = 4.4036
	sim_grads_norm_tr = 0.0032
-- Starting training on experience 121 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4480
	data_grads_norm = 5.3234
	new_data_grads_norm = 7.6112
	old_data_grads_norm = 6.8647
	sim_grads_norm_tr = 0.0214
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0600
	data_grads_norm = 4.3147
	new_data_grads_norm = 8.0933
	old_data_grads_norm = 3.3572
	sim_grads_norm_tr = -0.0115
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4003
	data_grads_norm = 5.8173
	new_data_grads_norm = 7.9013
	old_data_grads_norm = 8.0669
	sim_grads_norm_tr = -0.0221
-- Starting training on experience 122 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1544
	data_grads_norm = 5.2998
	new_data_grads_norm = 8.6910
	old_data_grads_norm = 8.0450
	sim_grads_norm_tr = -0.0341
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6121
	data_grads_norm = 6.0872
	new_data_grads_norm = 9.3351
	old_data_grads_norm = 7.2507
	sim_grads_norm_tr = 0.0049
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3927
	data_grads_norm = 5.7712
	new_data_grads_norm = 9.6500
	old_data_grads_norm = 8.0302
	sim_grads_norm_tr = -0.0401
-- Starting training on experience 123 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6325
	data_grads_norm = 6.4391
	new_data_grads_norm = 9.2790
	old_data_grads_norm = 8.5049
	sim_grads_norm_tr = 0.0150
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8061
	data_grads_norm = 5.9798
	new_data_grads_norm = 9.3673
	old_data_grads_norm = 6.1604
	sim_grads_norm_tr = 0.0847
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9315
	data_grads_norm = 6.0979
	new_data_grads_norm = 9.3168
	old_data_grads_norm = 6.1130
	sim_grads_norm_tr = 0.0397
-- Starting training on experience 124 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6148
	data_grads_norm = 5.6847
	new_data_grads_norm = 9.5497
	old_data_grads_norm = 5.7008
	sim_grads_norm_tr = 0.0254
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6551
	data_grads_norm = 6.1203
	new_data_grads_norm = 9.3290
	old_data_grads_norm = 6.6249
	sim_grads_norm_tr = -0.0084
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8744
	data_grads_norm = 6.0660
	new_data_grads_norm = 9.2380
	old_data_grads_norm = 6.0795
	sim_grads_norm_tr = 0.0011
-- Starting training on experience 125 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7594
	data_grads_norm = 5.9550
	new_data_grads_norm = 9.7222
	old_data_grads_norm = 7.0646
	sim_grads_norm_tr = -0.0095
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4850
	data_grads_norm = 5.3889
	new_data_grads_norm = 7.9375
	old_data_grads_norm = 7.6526
	sim_grads_norm_tr = -0.0162
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2701
	data_grads_norm = 5.4085
	new_data_grads_norm = 8.9727
	old_data_grads_norm = 5.7502
	sim_grads_norm_tr = -0.0021
-- Starting training on experience 126 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5631
	data_grads_norm = 6.5520
	new_data_grads_norm = 7.0066
	old_data_grads_norm = 9.5267
	sim_grads_norm_tr = -0.0044
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7152
	data_grads_norm = 6.1180
	new_data_grads_norm = 8.3184
	old_data_grads_norm = 7.9426
	sim_grads_norm_tr = 0.0459
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3998
	data_grads_norm = 5.6110
	new_data_grads_norm = 8.0629
	old_data_grads_norm = 8.0694
	sim_grads_norm_tr = -0.0156
-- Starting training on experience 127 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1601
	data_grads_norm = 5.5444
	new_data_grads_norm = 7.4952
	old_data_grads_norm = 8.1286
	sim_grads_norm_tr = -0.0049
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3832
	data_grads_norm = 5.8882
	new_data_grads_norm = 7.8093
	old_data_grads_norm = 8.7315
	sim_grads_norm_tr = 0.0398
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7800
	data_grads_norm = 4.5664
	new_data_grads_norm = 8.5405
	old_data_grads_norm = 5.8862
	sim_grads_norm_tr = 0.0205
-- Starting training on experience 128 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3855
	data_grads_norm = 5.1849
	new_data_grads_norm = 9.0788
	old_data_grads_norm = 6.4302
	sim_grads_norm_tr = -0.0091
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3343
	data_grads_norm = 5.0996
	new_data_grads_norm = 7.5639
	old_data_grads_norm = 5.7440
	sim_grads_norm_tr = 0.0094
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6370
	data_grads_norm = 5.9839
	new_data_grads_norm = 8.5670
	old_data_grads_norm = 7.8881
	sim_grads_norm_tr = -0.0066
-- Starting training on experience 129 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8720
	data_grads_norm = 7.1263
	new_data_grads_norm = 9.4489
	old_data_grads_norm = 9.5844
	sim_grads_norm_tr = 0.0165
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2377
	data_grads_norm = 6.0651
	new_data_grads_norm = 9.6562
	old_data_grads_norm = 7.0726
	sim_grads_norm_tr = 0.0295
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2761
	data_grads_norm = 6.2192
	new_data_grads_norm = 9.8316
	old_data_grads_norm = 8.1802
	sim_grads_norm_tr = 0.0119
-- Starting training on experience 130 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9773
	data_grads_norm = 5.5273
	new_data_grads_norm = 9.1429
	old_data_grads_norm = 5.0639
	sim_grads_norm_tr = -0.0089
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9599
	data_grads_norm = 5.2506
	new_data_grads_norm = 9.4498
	old_data_grads_norm = 5.6051
	sim_grads_norm_tr = -0.0120
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5380
	data_grads_norm = 5.4728
	new_data_grads_norm = 8.2567
	old_data_grads_norm = 6.1360
	sim_grads_norm_tr = 0.0181
-- Starting training on experience 131 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3185
	data_grads_norm = 5.5849
	new_data_grads_norm = 7.9266
	old_data_grads_norm = 7.1063
	sim_grads_norm_tr = 0.0103
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6651
	data_grads_norm = 6.2063
	new_data_grads_norm = 9.8693
	old_data_grads_norm = 6.7696
	sim_grads_norm_tr = 0.0024
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9844
	data_grads_norm = 6.2713
	new_data_grads_norm = 9.6055
	old_data_grads_norm = 8.4801
	sim_grads_norm_tr = -0.0191
-- Starting training on experience 132 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8331
	data_grads_norm = 7.4028
	new_data_grads_norm = 9.0077
	old_data_grads_norm = 8.7399
	sim_grads_norm_tr = 0.0248
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6576
	data_grads_norm = 6.4356
	new_data_grads_norm = 10.2420
	old_data_grads_norm = 6.5841
	sim_grads_norm_tr = 0.0447
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4252
	data_grads_norm = 5.8655
	new_data_grads_norm = 9.7829
	old_data_grads_norm = 6.3636
	sim_grads_norm_tr = -0.0322
-- Starting training on experience 133 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2199
	data_grads_norm = 5.7043
	new_data_grads_norm = 9.0105
	old_data_grads_norm = 6.8263
	sim_grads_norm_tr = 0.0077
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1654
	data_grads_norm = 5.4671
	new_data_grads_norm = 9.0256
	old_data_grads_norm = 5.9765
	sim_grads_norm_tr = -0.0042
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2592
	data_grads_norm = 6.0829
	new_data_grads_norm = 9.1015
	old_data_grads_norm = 7.2610
	sim_grads_norm_tr = -0.0005
-- Starting training on experience 134 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8044
	data_grads_norm = 4.7124
	new_data_grads_norm = 6.6033
	old_data_grads_norm = 5.8619
	sim_grads_norm_tr = 0.0058
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9284
	data_grads_norm = 4.9519
	new_data_grads_norm = 7.9410
	old_data_grads_norm = 7.4380
	sim_grads_norm_tr = 0.0446
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4974
	data_grads_norm = 4.4696
	new_data_grads_norm = 7.1581
	old_data_grads_norm = 5.5425
	sim_grads_norm_tr = -0.0194
-- Starting training on experience 135 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0809
	data_grads_norm = 4.8991
	new_data_grads_norm = 8.2803
	old_data_grads_norm = 5.3322
	sim_grads_norm_tr = -0.0160
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1298
	data_grads_norm = 4.9603
	new_data_grads_norm = 8.9136
	old_data_grads_norm = 5.4884
	sim_grads_norm_tr = 0.0103
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7091
	data_grads_norm = 6.5888
	new_data_grads_norm = 8.9636
	old_data_grads_norm = 8.3085
	sim_grads_norm_tr = 0.0131
-- Starting training on experience 136 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5676
	data_grads_norm = 5.8658
	new_data_grads_norm = 10.2413
	old_data_grads_norm = 6.1797
	sim_grads_norm_tr = -0.0233
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4360
	data_grads_norm = 5.7688
	new_data_grads_norm = 8.7600
	old_data_grads_norm = 6.8783
	sim_grads_norm_tr = -0.0073
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5605
	data_grads_norm = 6.0209
	new_data_grads_norm = 9.3299
	old_data_grads_norm = 7.8533
	sim_grads_norm_tr = 0.0588
-- Starting training on experience 137 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1481
	data_grads_norm = 5.5449
	new_data_grads_norm = 8.6351
	old_data_grads_norm = 5.1483
	sim_grads_norm_tr = -0.0009
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1558
	data_grads_norm = 5.2758
	new_data_grads_norm = 8.5961
	old_data_grads_norm = 6.3501
	sim_grads_norm_tr = 0.0298
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4115
	data_grads_norm = 5.7173
	new_data_grads_norm = 7.9516
	old_data_grads_norm = 8.3292
	sim_grads_norm_tr = -0.0201
-- Starting training on experience 138 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3592
	data_grads_norm = 6.1908
	new_data_grads_norm = 10.7150
	old_data_grads_norm = 6.3974
	sim_grads_norm_tr = 0.0579
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4033
	data_grads_norm = 5.3754
	new_data_grads_norm = 9.0646
	old_data_grads_norm = 5.6991
	sim_grads_norm_tr = 0.0152
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2361
	data_grads_norm = 5.4622
	new_data_grads_norm = 8.9491
	old_data_grads_norm = 6.0037
	sim_grads_norm_tr = 0.0240
-- Starting training on experience 139 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0002
	data_grads_norm = 4.3855
	new_data_grads_norm = 7.9653
	old_data_grads_norm = 6.7855
	sim_grads_norm_tr = 0.0065
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9261
	data_grads_norm = 4.3765
	new_data_grads_norm = 8.8151
	old_data_grads_norm = 3.9277
	sim_grads_norm_tr = 0.0118
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0785
	data_grads_norm = 4.7627
	new_data_grads_norm = 8.0793
	old_data_grads_norm = 6.5990
	sim_grads_norm_tr = 0.0272
-- Starting training on experience 140 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1799
	data_grads_norm = 4.7241
	new_data_grads_norm = 7.4600
	old_data_grads_norm = 4.9620
	sim_grads_norm_tr = 0.0617
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9170
	data_grads_norm = 4.9585
	new_data_grads_norm = 7.9278
	old_data_grads_norm = 6.5150
	sim_grads_norm_tr = -0.0020
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0539
	data_grads_norm = 5.3449
	new_data_grads_norm = 9.8836
	old_data_grads_norm = 3.4731
	sim_grads_norm_tr = -0.0179
-- Starting training on experience 141 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3506
	data_grads_norm = 6.1549
	new_data_grads_norm = 8.9297
	old_data_grads_norm = 6.9710
	sim_grads_norm_tr = -0.0074
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6004
	data_grads_norm = 5.5037
	new_data_grads_norm = 8.4056
	old_data_grads_norm = 5.9099
	sim_grads_norm_tr = 0.0429
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7485
	data_grads_norm = 5.7247
	new_data_grads_norm = 8.6941
	old_data_grads_norm = 8.5440
	sim_grads_norm_tr = 0.0031
-- Starting training on experience 142 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0054
	data_grads_norm = 4.9427
	new_data_grads_norm = 7.1140
	old_data_grads_norm = 5.3717
	sim_grads_norm_tr = 0.0070
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6428
	data_grads_norm = 4.6166
	new_data_grads_norm = 7.1743
	old_data_grads_norm = 5.4456
	sim_grads_norm_tr = 0.0039
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2116
	data_grads_norm = 5.3586
	new_data_grads_norm = 7.7919
	old_data_grads_norm = 6.6560
	sim_grads_norm_tr = -0.0268
-- Starting training on experience 143 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8851
	data_grads_norm = 4.8935
	new_data_grads_norm = 7.0422
	old_data_grads_norm = 5.3310
	sim_grads_norm_tr = 0.0440
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0744
	data_grads_norm = 5.3983
	new_data_grads_norm = 8.0117
	old_data_grads_norm = 7.2918
	sim_grads_norm_tr = -0.0214
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3609
	data_grads_norm = 5.3561
	new_data_grads_norm = 8.6166
	old_data_grads_norm = 6.6045
	sim_grads_norm_tr = 0.0403
-- Starting training on experience 144 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3128
	data_grads_norm = 6.2553
	new_data_grads_norm = 9.4808
	old_data_grads_norm = 7.4719
	sim_grads_norm_tr = -0.0028
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6590
	data_grads_norm = 6.6707
	new_data_grads_norm = 10.0499
	old_data_grads_norm = 9.0387
	sim_grads_norm_tr = -0.0013
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4258
	data_grads_norm = 6.3155
	new_data_grads_norm = 9.7382
	old_data_grads_norm = 8.1607
	sim_grads_norm_tr = 0.0306
-- Starting training on experience 145 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4261
	data_grads_norm = 6.2643
	new_data_grads_norm = 9.8657
	old_data_grads_norm = 8.7442
	sim_grads_norm_tr = 0.0264
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3808
	data_grads_norm = 5.2204
	new_data_grads_norm = 10.7363
	old_data_grads_norm = 6.7498
	sim_grads_norm_tr = 0.0053
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8097
	data_grads_norm = 6.4506
	new_data_grads_norm = 10.4837
	old_data_grads_norm = 6.9119
	sim_grads_norm_tr = 0.0164
-- Starting training on experience 146 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9612
	data_grads_norm = 5.7156
	new_data_grads_norm = 8.4011
	old_data_grads_norm = 7.3872
	sim_grads_norm_tr = -0.0004
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5089
	data_grads_norm = 5.8526
	new_data_grads_norm = 8.8069
	old_data_grads_norm = 7.6560
	sim_grads_norm_tr = -0.0026
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4199
	data_grads_norm = 4.3068
	new_data_grads_norm = 7.8610
	old_data_grads_norm = 3.9259
	sim_grads_norm_tr = 0.1305
-- Starting training on experience 147 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2508
	data_grads_norm = 6.2448
	new_data_grads_norm = 8.9159
	old_data_grads_norm = 7.1588
	sim_grads_norm_tr = -0.0274
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0268
	data_grads_norm = 5.5681
	new_data_grads_norm = 9.1656
	old_data_grads_norm = 5.1793
	sim_grads_norm_tr = 0.0111
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0222
	data_grads_norm = 5.1504
	new_data_grads_norm = 8.0641
	old_data_grads_norm = 5.3199
	sim_grads_norm_tr = -0.0325
-- Starting training on experience 148 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2318
	data_grads_norm = 4.8992
	new_data_grads_norm = 9.7358
	old_data_grads_norm = 4.1781
	sim_grads_norm_tr = 0.0143
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4644
	data_grads_norm = 5.3036
	new_data_grads_norm = 8.4602
	old_data_grads_norm = 6.7092
	sim_grads_norm_tr = -0.0085
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8206
	data_grads_norm = 6.4248
	new_data_grads_norm = 10.8611
	old_data_grads_norm = 6.9894
	sim_grads_norm_tr = -0.0053
-- Starting training on experience 149 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3968
	data_grads_norm = 5.5589
	new_data_grads_norm = 9.4648
	old_data_grads_norm = 6.3697
	sim_grads_norm_tr = -0.0113
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6092
	data_grads_norm = 5.9761
	new_data_grads_norm = 9.1546
	old_data_grads_norm = 6.4120
	sim_grads_norm_tr = 0.0146
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4844
	data_grads_norm = 5.2841
	new_data_grads_norm = 9.3274
	old_data_grads_norm = 5.8317
	sim_grads_norm_tr = 0.0175
-- Starting training on experience 150 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4827
	data_grads_norm = 6.9730
	new_data_grads_norm = 9.2974
	old_data_grads_norm = 8.1696
	sim_grads_norm_tr = 0.0294
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4192
	data_grads_norm = 5.6698
	new_data_grads_norm = 8.1535
	old_data_grads_norm = 7.0447
	sim_grads_norm_tr = 0.0257
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9363
	data_grads_norm = 5.2059
	new_data_grads_norm = 8.7377
	old_data_grads_norm = 6.6775
	sim_grads_norm_tr = -0.0168
-- Starting training on experience 151 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2259
	data_grads_norm = 6.0079
	new_data_grads_norm = 8.6117
	old_data_grads_norm = 6.4595
	sim_grads_norm_tr = 0.0130
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7189
	data_grads_norm = 4.1617
	new_data_grads_norm = 8.7556
	old_data_grads_norm = 5.1412
	sim_grads_norm_tr = -0.0161
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4317
	data_grads_norm = 6.0032
	new_data_grads_norm = 9.8084
	old_data_grads_norm = 7.2831
	sim_grads_norm_tr = -0.0115
-- Starting training on experience 152 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4385
	data_grads_norm = 6.5298
	new_data_grads_norm = 9.2091
	old_data_grads_norm = 7.6650
	sim_grads_norm_tr = 0.0210
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6842
	data_grads_norm = 6.1744
	new_data_grads_norm = 8.8622
	old_data_grads_norm = 8.9248
	sim_grads_norm_tr = 0.0146
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9701
	data_grads_norm = 6.4253
	new_data_grads_norm = 9.9311
	old_data_grads_norm = 8.7453
	sim_grads_norm_tr = -0.0193
-- Starting training on experience 153 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2505
	data_grads_norm = 5.5423
	new_data_grads_norm = 9.1367
	old_data_grads_norm = 5.7013
	sim_grads_norm_tr = 0.0328
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4893
	data_grads_norm = 6.4310
	new_data_grads_norm = 10.3296
	old_data_grads_norm = 8.7002
	sim_grads_norm_tr = 0.0168
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6115
	data_grads_norm = 7.0484
	new_data_grads_norm = 9.4479
	old_data_grads_norm = 11.0775
	sim_grads_norm_tr = -0.0432
-- Starting training on experience 154 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5557
	data_grads_norm = 5.9096
	new_data_grads_norm = 9.4116
	old_data_grads_norm = 6.6420
	sim_grads_norm_tr = 0.0369
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7143
	data_grads_norm = 6.1099
	new_data_grads_norm = 8.8724
	old_data_grads_norm = 6.7137
	sim_grads_norm_tr = 0.0047
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0133
	data_grads_norm = 4.5842
	new_data_grads_norm = 8.5450
	old_data_grads_norm = 4.4107
	sim_grads_norm_tr = -0.0337
-- Starting training on experience 155 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5717
	data_grads_norm = 5.6536
	new_data_grads_norm = 9.7369
	old_data_grads_norm = 5.7868
	sim_grads_norm_tr = -0.0286
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5999
	data_grads_norm = 5.0838
	new_data_grads_norm = 8.1629
	old_data_grads_norm = 5.6811
	sim_grads_norm_tr = 0.0146
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6752
	data_grads_norm = 6.3654
	new_data_grads_norm = 9.1706
	old_data_grads_norm = 7.9370
	sim_grads_norm_tr = -0.0211
-- Starting training on experience 156 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1681
	data_grads_norm = 5.8807
	new_data_grads_norm = 9.1586
	old_data_grads_norm = 8.4967
	sim_grads_norm_tr = -0.0300
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6929
	data_grads_norm = 6.4463
	new_data_grads_norm = 9.6284
	old_data_grads_norm = 7.4653
	sim_grads_norm_tr = -0.0301
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4938
	data_grads_norm = 5.9192
	new_data_grads_norm = 10.3591
	old_data_grads_norm = 5.7509
	sim_grads_norm_tr = -0.0050
-- Starting training on experience 157 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7254
	data_grads_norm = 6.6718
	new_data_grads_norm = 10.0675
	old_data_grads_norm = 8.2359
	sim_grads_norm_tr = 0.0191
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4922
	data_grads_norm = 6.5438
	new_data_grads_norm = 9.2559
	old_data_grads_norm = 8.9583
	sim_grads_norm_tr = 0.0162
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5345
	data_grads_norm = 5.8362
	new_data_grads_norm = 8.9555
	old_data_grads_norm = 7.2456
	sim_grads_norm_tr = 0.0004
-- Starting training on experience 158 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6083
	data_grads_norm = 5.6057
	new_data_grads_norm = 7.9025
	old_data_grads_norm = 5.1660
	sim_grads_norm_tr = 0.0781
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4626
	data_grads_norm = 4.9451
	new_data_grads_norm = 8.6212
	old_data_grads_norm = 5.5138
	sim_grads_norm_tr = -0.0365
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5271
	data_grads_norm = 5.6814
	new_data_grads_norm = 8.2850
	old_data_grads_norm = 7.8654
	sim_grads_norm_tr = -0.0019
-- Starting training on experience 159 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6056
	data_grads_norm = 6.1156
	new_data_grads_norm = 10.5868
	old_data_grads_norm = 6.9219
	sim_grads_norm_tr = 0.0299
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1978
	data_grads_norm = 5.9817
	new_data_grads_norm = 9.1962
	old_data_grads_norm = 6.5969
	sim_grads_norm_tr = 0.0286
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0333
	data_grads_norm = 5.4298
	new_data_grads_norm = 9.8193
	old_data_grads_norm = 3.6823
	sim_grads_norm_tr = 0.0007
-- Starting training on experience 160 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2041
	data_grads_norm = 5.5650
	new_data_grads_norm = 8.5517
	old_data_grads_norm = 7.2816
	sim_grads_norm_tr = 0.0168
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8961
	data_grads_norm = 6.2631
	new_data_grads_norm = 8.9468
	old_data_grads_norm = 7.9928
	sim_grads_norm_tr = 0.0595
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4162
	data_grads_norm = 6.5508
	new_data_grads_norm = 8.3296
	old_data_grads_norm = 5.8556
	sim_grads_norm_tr = 0.0702
-- Starting training on experience 161 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4132
	data_grads_norm = 5.6654
	new_data_grads_norm = 8.4988
	old_data_grads_norm = 6.3560
	sim_grads_norm_tr = -0.0020
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5269
	data_grads_norm = 5.6019
	new_data_grads_norm = 8.5693
	old_data_grads_norm = 7.5153
	sim_grads_norm_tr = -0.0420
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8995
	data_grads_norm = 5.1698
	new_data_grads_norm = 8.2643
	old_data_grads_norm = 5.0582
	sim_grads_norm_tr = -0.0019
-- Starting training on experience 162 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4310
	data_grads_norm = 6.2388
	new_data_grads_norm = 8.6336
	old_data_grads_norm = 5.8316
	sim_grads_norm_tr = -0.0024
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2743
	data_grads_norm = 5.8859
	new_data_grads_norm = 9.0551
	old_data_grads_norm = 6.9205
	sim_grads_norm_tr = -0.0115
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3595
	data_grads_norm = 5.9900
	new_data_grads_norm = 8.9174
	old_data_grads_norm = 7.8704
	sim_grads_norm_tr = -0.0038
-- Starting training on experience 163 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2331
	data_grads_norm = 5.8845
	new_data_grads_norm = 9.4503
	old_data_grads_norm = 5.4254
	sim_grads_norm_tr = -0.0139
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6872
	data_grads_norm = 6.7394
	new_data_grads_norm = 10.4379
	old_data_grads_norm = 6.2104
	sim_grads_norm_tr = 0.0543
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4278
	data_grads_norm = 5.9713
	new_data_grads_norm = 10.3553
	old_data_grads_norm = 7.1717
	sim_grads_norm_tr = -0.0184
-- Starting training on experience 164 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1107
	data_grads_norm = 4.5669
	new_data_grads_norm = 7.2544
	old_data_grads_norm = 5.1323
	sim_grads_norm_tr = 0.0274
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4887
	data_grads_norm = 5.6827
	new_data_grads_norm = 7.4284
	old_data_grads_norm = 8.1709
	sim_grads_norm_tr = -0.0025
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3412
	data_grads_norm = 4.6906
	new_data_grads_norm = 7.3336
	old_data_grads_norm = 5.4156
	sim_grads_norm_tr = -0.0128
-- Starting training on experience 165 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3320
	data_grads_norm = 4.9135
	new_data_grads_norm = 7.9639
	old_data_grads_norm = 6.8101
	sim_grads_norm_tr = -0.0033
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1638
	data_grads_norm = 4.9310
	new_data_grads_norm = 7.8703
	old_data_grads_norm = 6.7736
	sim_grads_norm_tr = -0.0132
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2909
	data_grads_norm = 4.9924
	new_data_grads_norm = 7.6767
	old_data_grads_norm = 5.9145
	sim_grads_norm_tr = -0.0221
-- Starting training on experience 166 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5286
	data_grads_norm = 5.3484
	new_data_grads_norm = 7.8763
	old_data_grads_norm = 5.0406
	sim_grads_norm_tr = 0.0128
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8209
	data_grads_norm = 5.7193
	new_data_grads_norm = 8.5195
	old_data_grads_norm = 8.7312
	sim_grads_norm_tr = 0.0203
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4242
	data_grads_norm = 4.7832
	new_data_grads_norm = 7.7819
	old_data_grads_norm = 4.5468
	sim_grads_norm_tr = -0.0230
-- Starting training on experience 167 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9729
	data_grads_norm = 4.6934
	new_data_grads_norm = 7.9043
	old_data_grads_norm = 5.5814
	sim_grads_norm_tr = -0.0010
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2818
	data_grads_norm = 6.4451
	new_data_grads_norm = 7.8292
	old_data_grads_norm = 9.0250
	sim_grads_norm_tr = 0.0585
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3089
	data_grads_norm = 5.6145
	new_data_grads_norm = 7.8055
	old_data_grads_norm = 7.6513
	sim_grads_norm_tr = -0.0047
-- Starting training on experience 168 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8216
	data_grads_norm = 6.3740
	new_data_grads_norm = 10.2082
	old_data_grads_norm = 6.6783
	sim_grads_norm_tr = 0.0780
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4564
	data_grads_norm = 5.7911
	new_data_grads_norm = 9.4521
	old_data_grads_norm = 8.2678
	sim_grads_norm_tr = 0.0222
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1930
	data_grads_norm = 5.8043
	new_data_grads_norm = 9.6123
	old_data_grads_norm = 6.3120
	sim_grads_norm_tr = -0.0039
-- Starting training on experience 169 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4901
	data_grads_norm = 5.4935
	new_data_grads_norm = 9.5712
	old_data_grads_norm = 2.8250
	sim_grads_norm_tr = 0.1206
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7032
	data_grads_norm = 6.4631
	new_data_grads_norm = 9.4640
	old_data_grads_norm = 6.8877
	sim_grads_norm_tr = 0.0204
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2224
	data_grads_norm = 5.9988
	new_data_grads_norm = 8.5447
	old_data_grads_norm = 8.2219
	sim_grads_norm_tr = 0.0126
-- Starting training on experience 170 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3848
	data_grads_norm = 5.8629
	new_data_grads_norm = 9.2405
	old_data_grads_norm = 7.9287
	sim_grads_norm_tr = 0.0068
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7568
	data_grads_norm = 5.8998
	new_data_grads_norm = 9.1439
	old_data_grads_norm = 7.3748
	sim_grads_norm_tr = -0.0102
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4015
	data_grads_norm = 5.2656
	new_data_grads_norm = 9.0646
	old_data_grads_norm = 4.1829
	sim_grads_norm_tr = -0.0078
-- Starting training on experience 171 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6846
	data_grads_norm = 6.0065
	new_data_grads_norm = 10.0779
	old_data_grads_norm = 5.8490
	sim_grads_norm_tr = -0.0255
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0664
	data_grads_norm = 7.1437
	new_data_grads_norm = 11.3512
	old_data_grads_norm = 7.5623
	sim_grads_norm_tr = 0.0150
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4021
	data_grads_norm = 6.0758
	new_data_grads_norm = 9.6362
	old_data_grads_norm = 5.8051
	sim_grads_norm_tr = 0.0045
-- Starting training on experience 172 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4146
	data_grads_norm = 5.8390
	new_data_grads_norm = 8.8602
	old_data_grads_norm = 7.2251
	sim_grads_norm_tr = 0.0051
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6261
	data_grads_norm = 6.2573
	new_data_grads_norm = 9.1314
	old_data_grads_norm = 7.1247
	sim_grads_norm_tr = 0.1078
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7807
	data_grads_norm = 4.9936
	new_data_grads_norm = 7.3274
	old_data_grads_norm = 6.2274
	sim_grads_norm_tr = 0.0087
-- Starting training on experience 173 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1500
	data_grads_norm = 5.6832
	new_data_grads_norm = 7.8440
	old_data_grads_norm = 6.9828
	sim_grads_norm_tr = 0.0059
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0961
	data_grads_norm = 5.9154
	new_data_grads_norm = 9.0278
	old_data_grads_norm = 6.8746
	sim_grads_norm_tr = 0.0200
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6089
	data_grads_norm = 4.8618
	new_data_grads_norm = 8.4487
	old_data_grads_norm = 5.0508
	sim_grads_norm_tr = 0.0029
-- Starting training on experience 174 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4721
	data_grads_norm = 4.4803
	new_data_grads_norm = 7.4164
	old_data_grads_norm = 4.4527
	sim_grads_norm_tr = -0.0239
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5222
	data_grads_norm = 4.9208
	new_data_grads_norm = 8.5442
	old_data_grads_norm = 3.5133
	sim_grads_norm_tr = 0.0118
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5046
	data_grads_norm = 6.3181
	new_data_grads_norm = 9.8546
	old_data_grads_norm = 7.3017
	sim_grads_norm_tr = 0.0418
-- Starting training on experience 175 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5432
	data_grads_norm = 6.2398
	new_data_grads_norm = 9.0474
	old_data_grads_norm = 8.3836
	sim_grads_norm_tr = -0.0051
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9360
	data_grads_norm = 5.2581
	new_data_grads_norm = 8.9601
	old_data_grads_norm = 5.0779
	sim_grads_norm_tr = 0.0006
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2754
	data_grads_norm = 5.4280
	new_data_grads_norm = 8.9895
	old_data_grads_norm = 6.4718
	sim_grads_norm_tr = -0.0005
-- Starting training on experience 176 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1380
	data_grads_norm = 5.1220
	new_data_grads_norm = 7.7707
	old_data_grads_norm = 8.6428
	sim_grads_norm_tr = -0.0061
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6864
	data_grads_norm = 5.5728
	new_data_grads_norm = 7.6104
	old_data_grads_norm = 7.6947
	sim_grads_norm_tr = 0.0056
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4628
	data_grads_norm = 5.2188
	new_data_grads_norm = 8.0643
	old_data_grads_norm = 7.0931
	sim_grads_norm_tr = -0.0557
-- Starting training on experience 177 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3820
	data_grads_norm = 6.9020
	new_data_grads_norm = 9.7441
	old_data_grads_norm = 6.0077
	sim_grads_norm_tr = 0.0710
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4560
	data_grads_norm = 7.0649
	new_data_grads_norm = 9.2804
	old_data_grads_norm = 8.1497
	sim_grads_norm_tr = 0.0317
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9832
	data_grads_norm = 5.4179
	new_data_grads_norm = 8.8779
	old_data_grads_norm = 6.2323
	sim_grads_norm_tr = -0.0613
-- Starting training on experience 178 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1894
	data_grads_norm = 4.9220
	new_data_grads_norm = 8.7101
	old_data_grads_norm = 5.1077
	sim_grads_norm_tr = -0.0295
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1451
	data_grads_norm = 5.5937
	new_data_grads_norm = 9.2666
	old_data_grads_norm = 6.1368
	sim_grads_norm_tr = 0.0215
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4460
	data_grads_norm = 6.1443
	new_data_grads_norm = 9.1403
	old_data_grads_norm = 7.8969
	sim_grads_norm_tr = -0.0021
-- Starting training on experience 179 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8335
	data_grads_norm = 6.0680
	new_data_grads_norm = 9.0910
	old_data_grads_norm = 6.4479
	sim_grads_norm_tr = 0.0394
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4871
	data_grads_norm = 4.6955
	new_data_grads_norm = 7.6360
	old_data_grads_norm = 4.6438
	sim_grads_norm_tr = -0.0171
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6871
	data_grads_norm = 5.3676
	new_data_grads_norm = 8.7132
	old_data_grads_norm = 6.4512
	sim_grads_norm_tr = -0.0021
-- Starting training on experience 180 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1755
	data_grads_norm = 6.4360
	new_data_grads_norm = 9.7968
	old_data_grads_norm = 8.2615
	sim_grads_norm_tr = 0.0127
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9430
	data_grads_norm = 5.6266
	new_data_grads_norm = 10.4010
	old_data_grads_norm = 5.3226
	sim_grads_norm_tr = -0.0244
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8480
	data_grads_norm = 5.2784
	new_data_grads_norm = 9.0685
	old_data_grads_norm = 5.9835
	sim_grads_norm_tr = 0.0871
-- Starting training on experience 181 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9718
	data_grads_norm = 5.9715
	new_data_grads_norm = 9.9943
	old_data_grads_norm = 7.8167
	sim_grads_norm_tr = -0.0360
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1891
	data_grads_norm = 6.2176
	new_data_grads_norm = 9.1379
	old_data_grads_norm = 8.8006
	sim_grads_norm_tr = 0.0072
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1500
	data_grads_norm = 6.3893
	new_data_grads_norm = 9.2998
	old_data_grads_norm = 6.6966
	sim_grads_norm_tr = 0.0138
-- Starting training on experience 182 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2674
	data_grads_norm = 5.0010
	new_data_grads_norm = 8.9588
	old_data_grads_norm = 4.0591
	sim_grads_norm_tr = -0.0072
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7411
	data_grads_norm = 5.4894
	new_data_grads_norm = 9.5448
	old_data_grads_norm = 5.7418
	sim_grads_norm_tr = 0.0528
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4459
	data_grads_norm = 6.0037
	new_data_grads_norm = 10.7394
	old_data_grads_norm = 6.6386
	sim_grads_norm_tr = -0.0261
-- Starting training on experience 183 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2390
	data_grads_norm = 6.6785
	new_data_grads_norm = 7.6548
	old_data_grads_norm = 8.7357
	sim_grads_norm_tr = 0.0341
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2294
	data_grads_norm = 5.9531
	new_data_grads_norm = 7.6441
	old_data_grads_norm = 7.5954
	sim_grads_norm_tr = 0.0233
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1362
	data_grads_norm = 5.4283
	new_data_grads_norm = 7.5129
	old_data_grads_norm = 8.2495
	sim_grads_norm_tr = 0.0349
-- Starting training on experience 184 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3670
	data_grads_norm = 5.8763
	new_data_grads_norm = 8.8263
	old_data_grads_norm = 8.1957
	sim_grads_norm_tr = 0.0313
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8211
	data_grads_norm = 4.3844
	new_data_grads_norm = 8.5173
	old_data_grads_norm = 3.0618
	sim_grads_norm_tr = 0.0080
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0393
	data_grads_norm = 5.6954
	new_data_grads_norm = 8.3086
	old_data_grads_norm = 7.0988
	sim_grads_norm_tr = -0.0050
-- Starting training on experience 185 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4451
	data_grads_norm = 5.3733
	new_data_grads_norm = 9.4276
	old_data_grads_norm = 4.8758
	sim_grads_norm_tr = -0.0154
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0984
	data_grads_norm = 6.5314
	new_data_grads_norm = 10.0783
	old_data_grads_norm = 6.9036
	sim_grads_norm_tr = -0.0079
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5541
	data_grads_norm = 5.6343
	new_data_grads_norm = 8.5120
	old_data_grads_norm = 6.9942
	sim_grads_norm_tr = 0.0149
-- Starting training on experience 186 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4422
	data_grads_norm = 5.6989
	new_data_grads_norm = 9.2834
	old_data_grads_norm = 6.2753
	sim_grads_norm_tr = 0.0675
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2866
	data_grads_norm = 5.8350
	new_data_grads_norm = 9.3270
	old_data_grads_norm = 7.5218
	sim_grads_norm_tr = -0.0061
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3690
	data_grads_norm = 5.6728
	new_data_grads_norm = 9.1445
	old_data_grads_norm = 5.5352
	sim_grads_norm_tr = 0.0309
-- Starting training on experience 187 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0325
	data_grads_norm = 5.1515
	new_data_grads_norm = 8.6267
	old_data_grads_norm = 5.8806
	sim_grads_norm_tr = -0.0077
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3051
	data_grads_norm = 5.7802
	new_data_grads_norm = 7.9508
	old_data_grads_norm = 7.9870
	sim_grads_norm_tr = 0.0715
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9609
	data_grads_norm = 6.0684
	new_data_grads_norm = 9.6502
	old_data_grads_norm = 8.9293
	sim_grads_norm_tr = -0.0316
-- Starting training on experience 188 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5282
	data_grads_norm = 5.4844
	new_data_grads_norm = 8.9005
	old_data_grads_norm = 7.0660
	sim_grads_norm_tr = 0.0130
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4396
	data_grads_norm = 4.8101
	new_data_grads_norm = 8.4524
	old_data_grads_norm = 5.2767
	sim_grads_norm_tr = -0.0154
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7008
	data_grads_norm = 6.0629
	new_data_grads_norm = 9.6403
	old_data_grads_norm = 8.1723
	sim_grads_norm_tr = 0.0074
-- Starting training on experience 189 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5220
	data_grads_norm = 5.8989
	new_data_grads_norm = 9.3011
	old_data_grads_norm = 7.2370
	sim_grads_norm_tr = -0.0131
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2040
	data_grads_norm = 5.2220
	new_data_grads_norm = 9.4243
	old_data_grads_norm = 4.3996
	sim_grads_norm_tr = -0.0127
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3842
	data_grads_norm = 5.5366
	new_data_grads_norm = 9.2433
	old_data_grads_norm = 6.6173
	sim_grads_norm_tr = -0.0261
-- Starting training on experience 190 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2502
	data_grads_norm = 6.0191
	new_data_grads_norm = 9.5170
	old_data_grads_norm = 6.8132
	sim_grads_norm_tr = 0.0025
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4286
	data_grads_norm = 5.9219
	new_data_grads_norm = 8.2345
	old_data_grads_norm = 6.2608
	sim_grads_norm_tr = 0.0451
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0645
	data_grads_norm = 5.8370
	new_data_grads_norm = 8.9285
	old_data_grads_norm = 7.2003
	sim_grads_norm_tr = -0.0348
-- Starting training on experience 191 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9789
	data_grads_norm = 5.9940
	new_data_grads_norm = 10.0108
	old_data_grads_norm = 7.4141
	sim_grads_norm_tr = 0.0367
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5652
	data_grads_norm = 6.1876
	new_data_grads_norm = 10.3942
	old_data_grads_norm = 7.1234
	sim_grads_norm_tr = 0.0189
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0428
	data_grads_norm = 4.5100
	new_data_grads_norm = 8.7524
	old_data_grads_norm = 1.6999
	sim_grads_norm_tr = 0.1835
-- Starting training on experience 192 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2204
	data_grads_norm = 5.6341
	new_data_grads_norm = 9.9085
	old_data_grads_norm = 4.2963
	sim_grads_norm_tr = -0.0130
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3413
	data_grads_norm = 6.2956
	new_data_grads_norm = 9.3993
	old_data_grads_norm = 6.3419
	sim_grads_norm_tr = -0.0014
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5158
	data_grads_norm = 6.4491
	new_data_grads_norm = 10.4968
	old_data_grads_norm = 6.5600
	sim_grads_norm_tr = 0.0156
-- Starting training on experience 193 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2443
	data_grads_norm = 4.7780
	new_data_grads_norm = 7.7321
	old_data_grads_norm = 4.9459
	sim_grads_norm_tr = 0.0409
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2231
	data_grads_norm = 5.0845
	new_data_grads_norm = 8.4393
	old_data_grads_norm = 6.0797
	sim_grads_norm_tr = 0.0035
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2928
	data_grads_norm = 5.4179
	new_data_grads_norm = 7.9194
	old_data_grads_norm = 7.1023
	sim_grads_norm_tr = -0.0259
-- Starting training on experience 194 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1405
	data_grads_norm = 4.8588
	new_data_grads_norm = 8.0027
	old_data_grads_norm = 5.7034
	sim_grads_norm_tr = 0.0018
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3330
	data_grads_norm = 6.5511
	new_data_grads_norm = 10.3125
	old_data_grads_norm = 8.2046
	sim_grads_norm_tr = 0.0153
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8530
	data_grads_norm = 5.1467
	new_data_grads_norm = 8.3826
	old_data_grads_norm = 8.0057
	sim_grads_norm_tr = -0.0135
-- Starting training on experience 195 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8193
	data_grads_norm = 5.5707
	new_data_grads_norm = 9.6689
	old_data_grads_norm = 5.8806
	sim_grads_norm_tr = 0.0856
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3112
	data_grads_norm = 6.2762
	new_data_grads_norm = 8.8092
	old_data_grads_norm = 8.2860
	sim_grads_norm_tr = -0.0170
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3715
	data_grads_norm = 6.1857
	new_data_grads_norm = 9.3601
	old_data_grads_norm = 6.9553
	sim_grads_norm_tr = 0.0017
-- Starting training on experience 196 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8738
	data_grads_norm = 5.2160
	new_data_grads_norm = 8.9657
	old_data_grads_norm = 5.8020
	sim_grads_norm_tr = -0.0319
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2945
	data_grads_norm = 6.5412
	new_data_grads_norm = 10.5842
	old_data_grads_norm = 4.9710
	sim_grads_norm_tr = -0.0149
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0869
	data_grads_norm = 5.5038
	new_data_grads_norm = 9.5322
	old_data_grads_norm = 5.1396
	sim_grads_norm_tr = 0.0757
-- Starting training on experience 197 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5010
	data_grads_norm = 5.2899
	new_data_grads_norm = 8.5778
	old_data_grads_norm = 5.6301
	sim_grads_norm_tr = -0.0284
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1940
	data_grads_norm = 4.7792
	new_data_grads_norm = 8.1936
	old_data_grads_norm = 6.2339
	sim_grads_norm_tr = 0.0041
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1880
	data_grads_norm = 4.9132
	new_data_grads_norm = 8.5208
	old_data_grads_norm = 5.3283
	sim_grads_norm_tr = 0.0184
-- Starting training on experience 198 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2683
	data_grads_norm = 6.2622
	new_data_grads_norm = 10.3976
	old_data_grads_norm = 7.5368
	sim_grads_norm_tr = 0.0130
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3919
	data_grads_norm = 5.4011
	new_data_grads_norm = 10.5138
	old_data_grads_norm = 6.8718
	sim_grads_norm_tr = -0.0238
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3454
	data_grads_norm = 5.7071
	new_data_grads_norm = 9.0570
	old_data_grads_norm = 6.3095
	sim_grads_norm_tr = -0.0212
-- Starting training on experience 199 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1210
	data_grads_norm = 5.6308
	new_data_grads_norm = 8.0660
	old_data_grads_norm = 8.1116
	sim_grads_norm_tr = 0.0061
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4128
	data_grads_norm = 6.0756
	new_data_grads_norm = 9.7039
	old_data_grads_norm = 7.4123
	sim_grads_norm_tr = -0.0212
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7047
	data_grads_norm = 6.3307
	new_data_grads_norm = 9.7666
	old_data_grads_norm = 4.9204
	sim_grads_norm_tr = 0.2110
-- Starting training on experience 200 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4583
	data_grads_norm = 6.0303
	new_data_grads_norm = 9.4477
	old_data_grads_norm = 7.1417
	sim_grads_norm_tr = -0.0114
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5567
	data_grads_norm = 5.3151
	new_data_grads_norm = 10.6925
	old_data_grads_norm = 4.9774
	sim_grads_norm_tr = -0.0484
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2114
	data_grads_norm = 5.6447
	new_data_grads_norm = 10.2805
	old_data_grads_norm = 6.8969
	sim_grads_norm_tr = -0.0280
-- Starting training on experience 201 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0499
	data_grads_norm = 6.0222
	new_data_grads_norm = 8.8490
	old_data_grads_norm = 8.2711
	sim_grads_norm_tr = -0.0111
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9408
	data_grads_norm = 5.5307
	new_data_grads_norm = 8.2910
	old_data_grads_norm = 5.7566
	sim_grads_norm_tr = -0.0150
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4792
	data_grads_norm = 5.6837
	new_data_grads_norm = 6.8708
	old_data_grads_norm = 8.2389
	sim_grads_norm_tr = -0.0067
-- Starting training on experience 202 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1067
	data_grads_norm = 7.1793
	new_data_grads_norm = 10.7051
	old_data_grads_norm = 7.4627
	sim_grads_norm_tr = -0.0157
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1088
	data_grads_norm = 7.2174
	new_data_grads_norm = 10.3143
	old_data_grads_norm = 7.5410
	sim_grads_norm_tr = 0.1039
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1106
	data_grads_norm = 5.0097
	new_data_grads_norm = 9.7359
	old_data_grads_norm = 3.5080
	sim_grads_norm_tr = -0.0207
-- Starting training on experience 203 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8369
	data_grads_norm = 4.8512
	new_data_grads_norm = 8.0108
	old_data_grads_norm = 4.3748
	sim_grads_norm_tr = -0.0146
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6109
	data_grads_norm = 4.7607
	new_data_grads_norm = 8.0951
	old_data_grads_norm = 6.6330
	sim_grads_norm_tr = -0.0126
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4277
	data_grads_norm = 6.6881
	new_data_grads_norm = 10.0294
	old_data_grads_norm = 8.8513
	sim_grads_norm_tr = 0.0077
-- Starting training on experience 204 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7756
	data_grads_norm = 5.3342
	new_data_grads_norm = 9.5079
	old_data_grads_norm = 5.3749
	sim_grads_norm_tr = -0.0083
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0414
	data_grads_norm = 5.1966
	new_data_grads_norm = 9.4612
	old_data_grads_norm = 5.8168
	sim_grads_norm_tr = 0.0099
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1881
	data_grads_norm = 5.8736
	new_data_grads_norm = 9.2510
	old_data_grads_norm = 7.0329
	sim_grads_norm_tr = -0.0030
-- Starting training on experience 205 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8910
	data_grads_norm = 6.7960
	new_data_grads_norm = 10.4135
	old_data_grads_norm = 8.5944
	sim_grads_norm_tr = -0.0193
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9496
	data_grads_norm = 5.9291
	new_data_grads_norm = 10.0099
	old_data_grads_norm = 4.9694
	sim_grads_norm_tr = 0.0117
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8709
	data_grads_norm = 6.0855
	new_data_grads_norm = 9.8063
	old_data_grads_norm = 6.6758
	sim_grads_norm_tr = 0.0626
-- Starting training on experience 206 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4749
	data_grads_norm = 6.0932
	new_data_grads_norm = 9.1492
	old_data_grads_norm = 6.4700
	sim_grads_norm_tr = -0.0356
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2948
	data_grads_norm = 6.2262
	new_data_grads_norm = 9.9705
	old_data_grads_norm = 7.6344
	sim_grads_norm_tr = -0.0015
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9457
	data_grads_norm = 6.2648
	new_data_grads_norm = 9.0072
	old_data_grads_norm = 8.3154
	sim_grads_norm_tr = 0.0466
-- Starting training on experience 207 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1777
	data_grads_norm = 5.8890
	new_data_grads_norm = 8.5885
	old_data_grads_norm = 7.7091
	sim_grads_norm_tr = 0.0163
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3809
	data_grads_norm = 6.1612
	new_data_grads_norm = 9.2450
	old_data_grads_norm = 8.7850
	sim_grads_norm_tr = -0.0131
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1290
	data_grads_norm = 4.7861
	new_data_grads_norm = 8.3575
	old_data_grads_norm = 6.9443
	sim_grads_norm_tr = -0.0651
-- Starting training on experience 208 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2793
	data_grads_norm = 6.1990
	new_data_grads_norm = 8.7759
	old_data_grads_norm = 8.0447
	sim_grads_norm_tr = 0.0768
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1369
	data_grads_norm = 5.6275
	new_data_grads_norm = 7.8822
	old_data_grads_norm = 7.3057
	sim_grads_norm_tr = 0.0391
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1307
	data_grads_norm = 5.8773
	new_data_grads_norm = 7.5024
	old_data_grads_norm = 7.5488
	sim_grads_norm_tr = -0.0212
-- Starting training on experience 209 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1989
	data_grads_norm = 5.0601
	new_data_grads_norm = 8.3429
	old_data_grads_norm = 6.3494
	sim_grads_norm_tr = 0.0064
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1080
	data_grads_norm = 4.8853
	new_data_grads_norm = 8.7707
	old_data_grads_norm = 3.5224
	sim_grads_norm_tr = -0.0177
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5507
	data_grads_norm = 6.4428
	new_data_grads_norm = 8.8146
	old_data_grads_norm = 8.0612
	sim_grads_norm_tr = 0.0646
-- Starting training on experience 210 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8508
	data_grads_norm = 4.9871
	new_data_grads_norm = 8.4669
	old_data_grads_norm = 4.2421
	sim_grads_norm_tr = -0.0335
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0434
	data_grads_norm = 5.5678
	new_data_grads_norm = 8.3231
	old_data_grads_norm = 4.8467
	sim_grads_norm_tr = -0.0096
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9776
	data_grads_norm = 5.6758
	new_data_grads_norm = 8.9161
	old_data_grads_norm = 5.0312
	sim_grads_norm_tr = -0.0348
-- Starting training on experience 211 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4055
	data_grads_norm = 5.7518
	new_data_grads_norm = 8.4408
	old_data_grads_norm = 6.9714
	sim_grads_norm_tr = -0.0379
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9963
	data_grads_norm = 5.1601
	new_data_grads_norm = 8.6213
	old_data_grads_norm = 4.5969
	sim_grads_norm_tr = 0.0863
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1286
	data_grads_norm = 4.8535
	new_data_grads_norm = 7.3045
	old_data_grads_norm = 5.4475
	sim_grads_norm_tr = 0.0015
-- Starting training on experience 212 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0471
	data_grads_norm = 5.0745
	new_data_grads_norm = 9.0553
	old_data_grads_norm = 4.9867
	sim_grads_norm_tr = -0.0179
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4777
	data_grads_norm = 6.1275
	new_data_grads_norm = 8.9882
	old_data_grads_norm = 9.4398
	sim_grads_norm_tr = -0.0173
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3906
	data_grads_norm = 5.5142
	new_data_grads_norm = 7.9492
	old_data_grads_norm = 7.4678
	sim_grads_norm_tr = 0.0444
-- Starting training on experience 213 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6337
	data_grads_norm = 4.7201
	new_data_grads_norm = 7.1279
	old_data_grads_norm = 6.9975
	sim_grads_norm_tr = 0.0115
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6754
	data_grads_norm = 4.6851
	new_data_grads_norm = 7.5580
	old_data_grads_norm = 6.3706
	sim_grads_norm_tr = -0.0328
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6220
	data_grads_norm = 5.6526
	new_data_grads_norm = 7.4290
	old_data_grads_norm = 7.5691
	sim_grads_norm_tr = 0.0656
-- Starting training on experience 214 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4631
	data_grads_norm = 6.3534
	new_data_grads_norm = 10.4555
	old_data_grads_norm = 6.8366
	sim_grads_norm_tr = -0.0212
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5588
	data_grads_norm = 6.1577
	new_data_grads_norm = 10.2924
	old_data_grads_norm = 5.3053
	sim_grads_norm_tr = -0.0049
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7194
	data_grads_norm = 5.8087
	new_data_grads_norm = 9.3246
	old_data_grads_norm = 7.5133
	sim_grads_norm_tr = -0.0126
-- Starting training on experience 215 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2601
	data_grads_norm = 6.2335
	new_data_grads_norm = 8.2865
	old_data_grads_norm = 7.7182
	sim_grads_norm_tr = 0.0394
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3847
	data_grads_norm = 4.0138
	new_data_grads_norm = 7.0840
	old_data_grads_norm = 4.2504
	sim_grads_norm_tr = -0.0622
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6955
	data_grads_norm = 4.1012
	new_data_grads_norm = 7.2327
	old_data_grads_norm = 3.1715
	sim_grads_norm_tr = 0.0327
-- Starting training on experience 216 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2291
	data_grads_norm = 5.4674
	new_data_grads_norm = 8.8692
	old_data_grads_norm = 6.8104
	sim_grads_norm_tr = 0.0388
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3308
	data_grads_norm = 5.9220
	new_data_grads_norm = 8.5607
	old_data_grads_norm = 8.5317
	sim_grads_norm_tr = 0.0124
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2105
	data_grads_norm = 5.2013
	new_data_grads_norm = 9.3189
	old_data_grads_norm = 4.9937
	sim_grads_norm_tr = -0.0380
-- Starting training on experience 217 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0252
	data_grads_norm = 6.0029
	new_data_grads_norm = 10.0126
	old_data_grads_norm = 5.6278
	sim_grads_norm_tr = -0.0121
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2638
	data_grads_norm = 5.7879
	new_data_grads_norm = 9.5836
	old_data_grads_norm = 4.9085
	sim_grads_norm_tr = 0.0358
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1935
	data_grads_norm = 5.6286
	new_data_grads_norm = 9.5497
	old_data_grads_norm = 4.7250
	sim_grads_norm_tr = 0.0487
-- Starting training on experience 218 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7061
	data_grads_norm = 4.1890
	new_data_grads_norm = 7.5683
	old_data_grads_norm = 5.1218
	sim_grads_norm_tr = -0.0178
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6806
	data_grads_norm = 4.1475
	new_data_grads_norm = 7.8121
	old_data_grads_norm = 4.8584
	sim_grads_norm_tr = -0.0157
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8258
	data_grads_norm = 4.3752
	new_data_grads_norm = 8.5444
	old_data_grads_norm = 4.8074
	sim_grads_norm_tr = -0.0361
-- Starting training on experience 219 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2031
	data_grads_norm = 5.5661
	new_data_grads_norm = 9.5774
	old_data_grads_norm = 5.6601
	sim_grads_norm_tr = -0.0027
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5242
	data_grads_norm = 5.6670
	new_data_grads_norm = 8.0815
	old_data_grads_norm = 8.2227
	sim_grads_norm_tr = 0.0167
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2629
	data_grads_norm = 6.1390
	new_data_grads_norm = 8.6927
	old_data_grads_norm = 6.6380
	sim_grads_norm_tr = 0.0274
-- Starting training on experience 220 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3480
	data_grads_norm = 5.6160
	new_data_grads_norm = 8.5488
	old_data_grads_norm = 7.6429
	sim_grads_norm_tr = -0.0022
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2139
	data_grads_norm = 5.4385
	new_data_grads_norm = 8.2379
	old_data_grads_norm = 7.3642
	sim_grads_norm_tr = 0.0298
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9165
	data_grads_norm = 5.2837
	new_data_grads_norm = 8.7890
	old_data_grads_norm = 8.0104
	sim_grads_norm_tr = -0.0057
-- Starting training on experience 221 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0347
	data_grads_norm = 5.8367
	new_data_grads_norm = 9.3119
	old_data_grads_norm = 6.1669
	sim_grads_norm_tr = 0.0083
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8922
	data_grads_norm = 5.5811
	new_data_grads_norm = 8.5110
	old_data_grads_norm = 6.3061
	sim_grads_norm_tr = 0.0208
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1588
	data_grads_norm = 5.7892
	new_data_grads_norm = 8.1814
	old_data_grads_norm = 7.1278
	sim_grads_norm_tr = -0.0200
-- Starting training on experience 222 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1482
	data_grads_norm = 6.3943
	new_data_grads_norm = 9.2835
	old_data_grads_norm = 7.4179
	sim_grads_norm_tr = -0.0140
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6743
	data_grads_norm = 5.0270
	new_data_grads_norm = 9.1779
	old_data_grads_norm = 6.0268
	sim_grads_norm_tr = -0.0516
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0521
	data_grads_norm = 5.7631
	new_data_grads_norm = 9.5751
	old_data_grads_norm = 6.9998
	sim_grads_norm_tr = 0.0210
-- Starting training on experience 223 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1665
	data_grads_norm = 6.9329
	new_data_grads_norm = 8.2960
	old_data_grads_norm = 8.2697
	sim_grads_norm_tr = 0.0607
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2307
	data_grads_norm = 6.4430
	new_data_grads_norm = 8.1244
	old_data_grads_norm = 9.3627
	sim_grads_norm_tr = -0.0277
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6478
	data_grads_norm = 7.7060
	new_data_grads_norm = 8.2757
	old_data_grads_norm = 11.6125
	sim_grads_norm_tr = 0.0713
-- Starting training on experience 224 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0834
	data_grads_norm = 5.8476
	new_data_grads_norm = 9.3491
	old_data_grads_norm = 7.0867
	sim_grads_norm_tr = -0.0105
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3141
	data_grads_norm = 6.1355
	new_data_grads_norm = 9.4889
	old_data_grads_norm = 8.6389
	sim_grads_norm_tr = -0.0022
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3377
	data_grads_norm = 5.9332
	new_data_grads_norm = 10.4516
	old_data_grads_norm = 8.6837
	sim_grads_norm_tr = 0.0622
-- Starting training on experience 225 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3665
	data_grads_norm = 6.0830
	new_data_grads_norm = 9.4265
	old_data_grads_norm = 7.4014
	sim_grads_norm_tr = 0.0466
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5859
	data_grads_norm = 6.5614
	new_data_grads_norm = 9.7802
	old_data_grads_norm = 7.9750
	sim_grads_norm_tr = -0.0066
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1133
	data_grads_norm = 5.4522
	new_data_grads_norm = 9.2192
	old_data_grads_norm = 6.7991
	sim_grads_norm_tr = -0.0231
-- Starting training on experience 226 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1100
	data_grads_norm = 6.2503
	new_data_grads_norm = 8.3900
	old_data_grads_norm = 7.9866
	sim_grads_norm_tr = -0.0195
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9928
	data_grads_norm = 5.2573
	new_data_grads_norm = 8.5654
	old_data_grads_norm = 7.9757
	sim_grads_norm_tr = -0.0163
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3503
	data_grads_norm = 5.1099
	new_data_grads_norm = 8.3197
	old_data_grads_norm = 5.9236
	sim_grads_norm_tr = -0.0250
-- Starting training on experience 227 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0533
	data_grads_norm = 5.0992
	new_data_grads_norm = 7.7609
	old_data_grads_norm = 5.1784
	sim_grads_norm_tr = 0.0322
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6633
	data_grads_norm = 4.6191
	new_data_grads_norm = 7.9990
	old_data_grads_norm = 4.8389
	sim_grads_norm_tr = -0.0211
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9738
	data_grads_norm = 4.6714
	new_data_grads_norm = 8.7916
	old_data_grads_norm = 4.0964
	sim_grads_norm_tr = -0.0455
-- Starting training on experience 228 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1730
	data_grads_norm = 5.4569
	new_data_grads_norm = 8.2137
	old_data_grads_norm = 8.4824
	sim_grads_norm_tr = -0.0005
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7470
	data_grads_norm = 6.2791
	new_data_grads_norm = 8.7829
	old_data_grads_norm = 8.5315
	sim_grads_norm_tr = 0.0121
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5217
	data_grads_norm = 6.0706
	new_data_grads_norm = 9.0326
	old_data_grads_norm = 7.1235
	sim_grads_norm_tr = 0.0203
-- Starting training on experience 229 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6065
	data_grads_norm = 6.3445
	new_data_grads_norm = 9.0872
	old_data_grads_norm = 7.3107
	sim_grads_norm_tr = 0.1008
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1599
	data_grads_norm = 5.3426
	new_data_grads_norm = 9.2028
	old_data_grads_norm = 9.3720
	sim_grads_norm_tr = 0.0143
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7115
	data_grads_norm = 4.8555
	new_data_grads_norm = 8.2590
	old_data_grads_norm = 3.4647
	sim_grads_norm_tr = -0.0409
-- Starting training on experience 230 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7686
	data_grads_norm = 5.2592
	new_data_grads_norm = 10.4670
	old_data_grads_norm = 4.7166
	sim_grads_norm_tr = -0.0156
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2511
	data_grads_norm = 7.0370
	new_data_grads_norm = 9.5187
	old_data_grads_norm = 8.1890
	sim_grads_norm_tr = -0.0449
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9802
	data_grads_norm = 4.7877
	new_data_grads_norm = 8.4490
	old_data_grads_norm = 5.7062
	sim_grads_norm_tr = -0.0156
-- Starting training on experience 231 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7055
	data_grads_norm = 6.3710
	new_data_grads_norm = 8.1560
	old_data_grads_norm = 9.4099
	sim_grads_norm_tr = 0.0101
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4457
	data_grads_norm = 5.6888
	new_data_grads_norm = 7.3506
	old_data_grads_norm = 8.3885
	sim_grads_norm_tr = 0.0550
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7656
	data_grads_norm = 4.5091
	new_data_grads_norm = 7.4318
	old_data_grads_norm = 4.9095
	sim_grads_norm_tr = -0.0021
-- Starting training on experience 232 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3738
	data_grads_norm = 6.5102
	new_data_grads_norm = 8.5808
	old_data_grads_norm = 9.3988
	sim_grads_norm_tr = 0.0149
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8419
	data_grads_norm = 5.5422
	new_data_grads_norm = 8.4767
	old_data_grads_norm = 6.1240
	sim_grads_norm_tr = -0.0103
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9039
	data_grads_norm = 5.1947
	new_data_grads_norm = 8.3294
	old_data_grads_norm = 5.4308
	sim_grads_norm_tr = -0.0301
-- Starting training on experience 233 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1648
	data_grads_norm = 6.1916
	new_data_grads_norm = 11.6222
	old_data_grads_norm = 5.7297
	sim_grads_norm_tr = 0.0047
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4212
	data_grads_norm = 7.0382
	new_data_grads_norm = 10.5212
	old_data_grads_norm = 7.9621
	sim_grads_norm_tr = 0.0235
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3340
	data_grads_norm = 6.9511
	new_data_grads_norm = 10.4935
	old_data_grads_norm = 9.3372
	sim_grads_norm_tr = -0.0217
-- Starting training on experience 234 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5034
	data_grads_norm = 6.4170
	new_data_grads_norm = 10.3859
	old_data_grads_norm = 7.2221
	sim_grads_norm_tr = -0.0054
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7351
	data_grads_norm = 6.3570
	new_data_grads_norm = 10.8642
	old_data_grads_norm = 6.5481
	sim_grads_norm_tr = -0.0130
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3724
	data_grads_norm = 5.5563
	new_data_grads_norm = 10.9063
	old_data_grads_norm = 4.0843
	sim_grads_norm_tr = -0.0309
-- Starting training on experience 235 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2175
	data_grads_norm = 5.8757
	new_data_grads_norm = 9.2365
	old_data_grads_norm = 5.7806
	sim_grads_norm_tr = 0.0122
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9355
	data_grads_norm = 5.9436
	new_data_grads_norm = 8.9500
	old_data_grads_norm = 6.9829
	sim_grads_norm_tr = -0.0143
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1874
	data_grads_norm = 5.7413
	new_data_grads_norm = 8.7955
	old_data_grads_norm = 6.4142
	sim_grads_norm_tr = 0.0275
-- Starting training on experience 236 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8241
	data_grads_norm = 5.3912
	new_data_grads_norm = 9.4136
	old_data_grads_norm = 6.1107
	sim_grads_norm_tr = 0.0364
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9505
	data_grads_norm = 5.6072
	new_data_grads_norm = 9.0980
	old_data_grads_norm = 9.0361
	sim_grads_norm_tr = 0.0389
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7974
	data_grads_norm = 5.0535
	new_data_grads_norm = 8.9363
	old_data_grads_norm = 5.5664
	sim_grads_norm_tr = 0.0074
-- Starting training on experience 237 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
-- >> End of training phase << --
-- >> Start of eval phase << --
-- Starting eval on experience 0 (Task 0) from test stream --
> Eval on experience 0 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp000 = 5.0096
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.2300
	mb_index = 4760
	time = 2103.2402
-- Starting eval on experience 1 (Task 0) from test stream --
> Eval on experience 1 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp001 = 3.4089
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.3640
-- Starting eval on experience 2 (Task 0) from test stream --
> Eval on experience 2 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp002 = 5.8277
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.1480
-- Starting eval on experience 3 (Task 0) from test stream --
> Eval on experience 3 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp003 = 3.5935
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.3820
-- Starting eval on experience 4 (Task 0) from test stream --
> Eval on experience 4 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp004 = 5.5288
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.1980
-- Starting eval on experience 5 (Task 0) from test stream --
> Eval on experience 5 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp005 = 4.7027
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.3060
-- Starting eval on experience 6 (Task 0) from test stream --
> Eval on experience 6 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp006 = 4.7153
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp006 = 0.1960
-- Starting eval on experience 7 (Task 0) from test stream --
> Eval on experience 7 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp007 = 4.7020
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp007 = 0.3120
-- Starting eval on experience 8 (Task 0) from test stream --
> Eval on experience 8 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp008 = 3.9158
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp008 = 0.3180
-- Starting eval on experience 9 (Task 0) from test stream --
> Eval on experience 9 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp009 = 3.8997
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp009 = 0.3420
-- Starting eval on experience 10 (Task 0) from test stream --
> Eval on experience 10 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp010 = 5.0287
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp010 = 0.2000
-- Starting eval on experience 11 (Task 0) from test stream --
> Eval on experience 11 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp011 = 3.2781
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp011 = 0.4200
-- Starting eval on experience 12 (Task 0) from test stream --
> Eval on experience 12 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp012 = 4.6191
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp012 = 0.1920
-- Starting eval on experience 13 (Task 0) from test stream --
> Eval on experience 13 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp013 = 3.7677
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp013 = 0.2520
-- Starting eval on experience 14 (Task 0) from test stream --
> Eval on experience 14 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp014 = 3.5271
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp014 = 0.2760
-- Starting eval on experience 15 (Task 0) from test stream --
> Eval on experience 15 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp015 = 3.2669
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp015 = 0.2860
-- Starting eval on experience 16 (Task 0) from test stream --
> Eval on experience 16 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp016 = 3.3219
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp016 = 0.2960
-- Starting eval on experience 17 (Task 0) from test stream --
> Eval on experience 17 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp017 = 3.9402
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp017 = 0.1320
-- Starting eval on experience 18 (Task 0) from test stream --
> Eval on experience 18 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp018 = 3.7220
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp018 = 0.1760
-- Starting eval on experience 19 (Task 0) from test stream --
> Eval on experience 19 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp019 = 3.7419
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp019 = 0.1120
-- >> End of eval phase << --
	CumulativeAccuracy/eval_phase/test_stream/Exp000 = 0.6920
	CumulativeAccuracy/eval_phase/test_stream/Exp001 = 0.6520
	CumulativeAccuracy/eval_phase/test_stream/Exp002 = 0.5273
	CumulativeAccuracy/eval_phase/test_stream/Exp003 = 0.5295
	CumulativeAccuracy/eval_phase/test_stream/Exp004 = 0.4896
	CumulativeAccuracy/eval_phase/test_stream/Exp005 = 0.4620
	CumulativeAccuracy/eval_phase/test_stream/Exp006 = 0.4377
	CumulativeAccuracy/eval_phase/test_stream/Exp007 = 0.4193
	CumulativeAccuracy/eval_phase/test_stream/Exp008 = 0.4056
	CumulativeAccuracy/eval_phase/test_stream/Exp009 = 0.3898
	CumulativeAccuracy/eval_phase/test_stream/Exp010 = 0.3660
	CumulativeAccuracy/eval_phase/test_stream/Exp011 = 0.3532
	CumulativeAccuracy/eval_phase/test_stream/Exp012 = 0.3285
	CumulativeAccuracy/eval_phase/test_stream/Exp013 = 0.3173
	CumulativeAccuracy/eval_phase/test_stream/Exp014 = 0.3069
	CumulativeAccuracy/eval_phase/test_stream/Exp015 = 0.2955
	CumulativeAccuracy/eval_phase/test_stream/Exp016 = 0.2884
	CumulativeAccuracy/eval_phase/test_stream/Exp017 = 0.2771
	CumulativeAccuracy/eval_phase/test_stream/Exp018 = 0.2666
	CumulativeAccuracy/eval_phase/test_stream/Exp019 = 0.2569
	Loss_Stream/eval_phase/test_stream/Task000 = 4.1759
	Top1_Acc_Stream/eval_phase/test_stream/Task000 = 0.2569
