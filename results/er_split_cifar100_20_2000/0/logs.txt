-- >> Start of training phase << --
-- Starting training on experience 0 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9439
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0083
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7141
-- Starting training on experience 1 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4806
	data_grads_norm = 8.1588
	new_data_grads_norm = 11.0062
	old_data_grads_norm = 8.4118
	sim_grads_norm = -0.0028
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6248
	data_grads_norm = 7.5392
	new_data_grads_norm = 8.7738
	old_data_grads_norm = 11.9672
	sim_grads_norm = -0.0387
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9908
	data_grads_norm = 6.8011
	new_data_grads_norm = 9.5949
	old_data_grads_norm = 6.6100
	sim_grads_norm = -0.1593
-- Starting training on experience 2 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9874
	data_grads_norm = 8.0237
	new_data_grads_norm = 11.3199
	old_data_grads_norm = 8.6404
	sim_grads_norm = 0.3215
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4321
	data_grads_norm = 7.3240
	new_data_grads_norm = 10.3071
	old_data_grads_norm = 7.8100
	sim_grads_norm = 0.2226
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7812
	data_grads_norm = 4.9898
	new_data_grads_norm = 8.4708
	old_data_grads_norm = 6.4482
	sim_grads_norm = 0.1976
-- Starting training on experience 3 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1196
	data_grads_norm = 5.5658
	new_data_grads_norm = 7.3060
	old_data_grads_norm = 7.5750
	sim_grads_norm = 0.2749
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0014
	data_grads_norm = 6.2015
	new_data_grads_norm = 7.9441
	old_data_grads_norm = 7.0295
	sim_grads_norm = 0.4222
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1625
	data_grads_norm = 4.8062
	new_data_grads_norm = 5.7003
	old_data_grads_norm = 6.0679
	sim_grads_norm = 0.3193
-- Starting training on experience 4 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5150
	data_grads_norm = 3.5796
	new_data_grads_norm = 5.5878
	old_data_grads_norm = 3.6418
	sim_grads_norm = 0.0684
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7749
	data_grads_norm = 4.3137
	new_data_grads_norm = 5.8002
	old_data_grads_norm = 3.9573
	sim_grads_norm = 0.4088
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3805
	data_grads_norm = 2.3881
	new_data_grads_norm = 6.7055
	old_data_grads_norm = 2.7148
	sim_grads_norm = -0.0766
-- Starting training on experience 5 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2447
	data_grads_norm = 4.9812
	new_data_grads_norm = 7.1230
	old_data_grads_norm = 4.7523
	sim_grads_norm = 0.2373
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2389
	data_grads_norm = 5.9403
	new_data_grads_norm = 7.4943
	old_data_grads_norm = 7.1919
	sim_grads_norm = 0.2353
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8005
	data_grads_norm = 6.2262
	new_data_grads_norm = 7.8710
	old_data_grads_norm = 7.6954
	sim_grads_norm = 0.5713
-- Starting training on experience 6 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6871
	data_grads_norm = 3.3892
	new_data_grads_norm = 5.2112
	old_data_grads_norm = 3.8563
	sim_grads_norm = 0.1739
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5238
	data_grads_norm = 2.6275
	new_data_grads_norm = 5.0237
	old_data_grads_norm = 2.3993
	sim_grads_norm = -0.1700
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0781
	data_grads_norm = 4.8044
	new_data_grads_norm = 5.9662
	old_data_grads_norm = 5.1712
	sim_grads_norm = 0.5338
-- Starting training on experience 7 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7611
	data_grads_norm = 3.8634
	new_data_grads_norm = 4.5746
	old_data_grads_norm = 4.9681
	sim_grads_norm = 0.3791
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6469
	data_grads_norm = 3.6873
	new_data_grads_norm = 4.2987
	old_data_grads_norm = 4.4798
	sim_grads_norm = 0.5091
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2202
	data_grads_norm = 2.6907
	new_data_grads_norm = 2.9312
	old_data_grads_norm = 3.7355
	sim_grads_norm = 0.2898
-- Starting training on experience 8 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8433
	data_grads_norm = 3.6810
	new_data_grads_norm = 4.7848
	old_data_grads_norm = 5.8631
	sim_grads_norm = 0.4962
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9533
	data_grads_norm = 4.0412
	new_data_grads_norm = 4.4648
	old_data_grads_norm = 5.5108
	sim_grads_norm = 0.3253
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9684
	data_grads_norm = 4.2401
	new_data_grads_norm = 4.8896
	old_data_grads_norm = 6.7250
	sim_grads_norm = 0.2337
-- Starting training on experience 9 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6036
	data_grads_norm = 3.2380
	new_data_grads_norm = 5.8755
	old_data_grads_norm = 2.5093
	sim_grads_norm = 0.0983
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0390
	data_grads_norm = 5.2837
	new_data_grads_norm = 7.4447
	old_data_grads_norm = 6.0469
	sim_grads_norm = 0.0626
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2327
	data_grads_norm = 5.5475
	new_data_grads_norm = 7.0602
	old_data_grads_norm = 6.6804
	sim_grads_norm = 0.3734
-- Starting training on experience 10 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9841
	data_grads_norm = 3.9833
	new_data_grads_norm = 4.8805
	old_data_grads_norm = 4.3468
	sim_grads_norm = 0.3522
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9309
	data_grads_norm = 3.9079
	new_data_grads_norm = 4.9166
	old_data_grads_norm = 4.0065
	sim_grads_norm = 0.5105
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4274
	data_grads_norm = 1.9614
	new_data_grads_norm = 3.0764
	old_data_grads_norm = 2.8036
	sim_grads_norm = 0.0432
-- Starting training on experience 11 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9906
	data_grads_norm = 3.9689
	new_data_grads_norm = 5.8720
	old_data_grads_norm = 3.4130
	sim_grads_norm = 0.4348
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7140
	data_grads_norm = 3.6248
	new_data_grads_norm = 5.2397
	old_data_grads_norm = 3.9839
	sim_grads_norm = 0.2314
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8179
	data_grads_norm = 3.2400
	new_data_grads_norm = 5.1234
	old_data_grads_norm = 5.3589
	sim_grads_norm = 0.0849
-- Starting training on experience 12 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9308
	data_grads_norm = 3.4987
	new_data_grads_norm = 4.1961
	old_data_grads_norm = 4.3484
	sim_grads_norm = 0.4144
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1682
	data_grads_norm = 4.3390
	new_data_grads_norm = 4.2885
	old_data_grads_norm = 6.1375
	sim_grads_norm = 0.5646
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7101
	data_grads_norm = 3.2838
	new_data_grads_norm = 4.6463
	old_data_grads_norm = 3.1616
	sim_grads_norm = 0.3790
-- Starting training on experience 13 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4159
	data_grads_norm = 2.2774
	new_data_grads_norm = 3.6147
	old_data_grads_norm = 3.2563
	sim_grads_norm = 0.0751
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5677
	data_grads_norm = 2.5572
	new_data_grads_norm = 3.4256
	old_data_grads_norm = 3.6202
	sim_grads_norm = 0.1863
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6105
	data_grads_norm = 2.2595
	new_data_grads_norm = 3.3281
	old_data_grads_norm = 3.3518
	sim_grads_norm = 0.2399
-- Starting training on experience 14 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6814
	data_grads_norm = 3.7167
	new_data_grads_norm = 4.1171
	old_data_grads_norm = 6.0724
	sim_grads_norm = 0.3190
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6666
	data_grads_norm = 2.4469
	new_data_grads_norm = 3.0859
	old_data_grads_norm = 3.1214
	sim_grads_norm = 0.3023
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4991
	data_grads_norm = 1.8389
	new_data_grads_norm = 2.7383
	old_data_grads_norm = 2.3890
	sim_grads_norm = -0.0694
-- Starting training on experience 15 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4739
	data_grads_norm = 1.8131
	new_data_grads_norm = 5.0537
	old_data_grads_norm = 2.2001
	sim_grads_norm = 0.1214
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5295
	data_grads_norm = 1.7248
	new_data_grads_norm = 4.0481
	old_data_grads_norm = 2.7543
	sim_grads_norm = -0.2214
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9532
	data_grads_norm = 3.8564
	new_data_grads_norm = 5.8443
	old_data_grads_norm = 3.7727
	sim_grads_norm = 0.5445
-- Starting training on experience 16 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7536
	data_grads_norm = 2.9513
	new_data_grads_norm = 3.5691
	old_data_grads_norm = 3.9496
	sim_grads_norm = 0.2079
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8121
	data_grads_norm = 2.7184
	new_data_grads_norm = 3.3373
	old_data_grads_norm = 4.8756
	sim_grads_norm = 0.1551
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7429
	data_grads_norm = 2.6579
	new_data_grads_norm = 4.4791
	old_data_grads_norm = 2.8647
	sim_grads_norm = 0.3125
-- Starting training on experience 17 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6615
	data_grads_norm = 2.4899
	new_data_grads_norm = 4.1530
	old_data_grads_norm = 2.8547
	sim_grads_norm = -0.3067
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7090
	data_grads_norm = 2.9871
	new_data_grads_norm = 5.5716
	old_data_grads_norm = 2.1604
	sim_grads_norm = 0.2093
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9528
	data_grads_norm = 4.2188
	new_data_grads_norm = 5.6654
	old_data_grads_norm = 3.5803
	sim_grads_norm = 0.6315
-- Starting training on experience 18 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6898
	data_grads_norm = 2.4746
	new_data_grads_norm = 3.1098
	old_data_grads_norm = 3.1692
	sim_grads_norm = 0.2320
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5094
	data_grads_norm = 2.1611
	new_data_grads_norm = 3.2180
	old_data_grads_norm = 2.9068
	sim_grads_norm = 0.2461
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3851
	data_grads_norm = 1.9607
	new_data_grads_norm = 2.6626
	old_data_grads_norm = 2.4603
	sim_grads_norm = -0.0330
-- Starting training on experience 19 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1248
	data_grads_norm = 2.0326
	new_data_grads_norm = 3.1954
	old_data_grads_norm = 3.2567
	sim_grads_norm = 0.1022
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5803
	data_grads_norm = 2.5882
	new_data_grads_norm = 3.9480
	old_data_grads_norm = 4.1777
	sim_grads_norm = 0.2559
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6617
	data_grads_norm = 2.7964
	new_data_grads_norm = 4.1065
	old_data_grads_norm = 3.2180
	sim_grads_norm = 0.1927
-- Starting training on experience 20 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4418
	data_grads_norm = 1.5626
	new_data_grads_norm = 2.5061
	old_data_grads_norm = 2.7835
	sim_grads_norm = -0.1883
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5011
	data_grads_norm = 2.4952
	new_data_grads_norm = 2.9557
	old_data_grads_norm = 3.4414
	sim_grads_norm = 0.2511
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4468
	data_grads_norm = 2.1427
	new_data_grads_norm = 2.7863
	old_data_grads_norm = 2.6016
	sim_grads_norm = 0.2844
-- Starting training on experience 21 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5849
	data_grads_norm = 2.1364
	new_data_grads_norm = 3.3833
	old_data_grads_norm = 2.5163
	sim_grads_norm = 0.2534
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5853
	data_grads_norm = 2.5420
	new_data_grads_norm = 3.0683
	old_data_grads_norm = 3.9172
	sim_grads_norm = 0.1788
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5940
	data_grads_norm = 2.0318
	new_data_grads_norm = 3.2782
	old_data_grads_norm = 2.8129
	sim_grads_norm = 0.0634
-- Starting training on experience 22 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5965
	data_grads_norm = 2.3629
	new_data_grads_norm = 3.3873
	old_data_grads_norm = 3.1794
	sim_grads_norm = 0.1332
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7218
	data_grads_norm = 2.8608
	new_data_grads_norm = 3.2598
	old_data_grads_norm = 4.5738
	sim_grads_norm = 0.0406
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8887
	data_grads_norm = 2.8289
	new_data_grads_norm = 3.4027
	old_data_grads_norm = 4.1823
	sim_grads_norm = 0.0705
-- Starting training on experience 23 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5078
	data_grads_norm = 2.6822
	new_data_grads_norm = 4.1937
	old_data_grads_norm = 2.7792
	sim_grads_norm = 0.1295
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6199
	data_grads_norm = 2.6980
	new_data_grads_norm = 4.5190
	old_data_grads_norm = 3.0506
	sim_grads_norm = 0.0926
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9062
	data_grads_norm = 2.9060
	new_data_grads_norm = 4.5700
	old_data_grads_norm = 3.3631
	sim_grads_norm = 0.4993
-- Starting training on experience 24 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6171
	data_grads_norm = 2.2899
	new_data_grads_norm = 3.2816
	old_data_grads_norm = 3.5546
	sim_grads_norm = 0.1540
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4739
	data_grads_norm = 2.4599
	new_data_grads_norm = 3.0789
	old_data_grads_norm = 3.1332
	sim_grads_norm = 0.3033
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2921
	data_grads_norm = 2.4935
	new_data_grads_norm = 3.3142
	old_data_grads_norm = 3.1875
	sim_grads_norm = 0.2253
-- Starting training on experience 25 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3562
	data_grads_norm = 2.1469
	new_data_grads_norm = 3.3999
	old_data_grads_norm = 4.3736
	sim_grads_norm = -0.1112
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5719
	data_grads_norm = 3.1603
	new_data_grads_norm = 4.6829
	old_data_grads_norm = 3.0328
	sim_grads_norm = 0.1331
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6141
	data_grads_norm = 3.0549
	new_data_grads_norm = 5.0439
	old_data_grads_norm = 4.3054
	sim_grads_norm = 0.0893
-- Starting training on experience 26 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5999
	data_grads_norm = 3.4465
	new_data_grads_norm = 4.0637
	old_data_grads_norm = 4.4567
	sim_grads_norm = 0.2877
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6476
	data_grads_norm = 3.5169
	new_data_grads_norm = 3.6656
	old_data_grads_norm = 3.6730
	sim_grads_norm = 0.5545
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5106
	data_grads_norm = 2.4284
	new_data_grads_norm = 2.9146
	old_data_grads_norm = 3.5768
	sim_grads_norm = 0.1153
-- Starting training on experience 27 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5862
	data_grads_norm = 2.2729
	new_data_grads_norm = 3.2459
	old_data_grads_norm = 2.9115
	sim_grads_norm = 0.3350
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4555
	data_grads_norm = 2.2502
	new_data_grads_norm = 3.4149
	old_data_grads_norm = 3.3737
	sim_grads_norm = 0.3758
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4023
	data_grads_norm = 1.9469
	new_data_grads_norm = 2.6567
	old_data_grads_norm = 2.6162
	sim_grads_norm = 0.0529
-- Starting training on experience 28 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6064
	data_grads_norm = 3.5318
	new_data_grads_norm = 4.1018
	old_data_grads_norm = 4.8157
	sim_grads_norm = 0.4049
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4525
	data_grads_norm = 2.5272
	new_data_grads_norm = 2.9259
	old_data_grads_norm = 3.5096
	sim_grads_norm = 0.1432
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2555
	data_grads_norm = 1.8806
	new_data_grads_norm = 3.1007
	old_data_grads_norm = 2.6136
	sim_grads_norm = 0.0330
-- Starting training on experience 29 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2753
	data_grads_norm = 2.4471
	new_data_grads_norm = 3.6668
	old_data_grads_norm = 2.5155
	sim_grads_norm = 0.0520
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6020
	data_grads_norm = 3.7313
	new_data_grads_norm = 3.8343
	old_data_grads_norm = 4.8598
	sim_grads_norm = 0.5871
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1816
	data_grads_norm = 2.0728
	new_data_grads_norm = 2.8692
	old_data_grads_norm = 2.9865
	sim_grads_norm = 0.2995
-- Starting training on experience 30 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6862
	data_grads_norm = 2.9922
	new_data_grads_norm = 4.5010
	old_data_grads_norm = 3.4291
	sim_grads_norm = 0.4309
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5272
	data_grads_norm = 2.3026
	new_data_grads_norm = 3.1211
	old_data_grads_norm = 3.3514
	sim_grads_norm = -0.0693
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4836
	data_grads_norm = 1.8738
	new_data_grads_norm = 3.3363
	old_data_grads_norm = 2.6122
	sim_grads_norm = -0.0385
-- Starting training on experience 31 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5061
	data_grads_norm = 2.1896
	new_data_grads_norm = 2.5234
	old_data_grads_norm = 2.9055
	sim_grads_norm = 0.3292
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5731
	data_grads_norm = 2.3710
	new_data_grads_norm = 3.0167
	old_data_grads_norm = 2.8928
	sim_grads_norm = 0.3317
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3755
	data_grads_norm = 2.0010
	new_data_grads_norm = 2.6039
	old_data_grads_norm = 2.6995
	sim_grads_norm = -0.2365
-- Starting training on experience 32 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2995
	data_grads_norm = 1.9873
	new_data_grads_norm = 2.4730
	old_data_grads_norm = 2.8009
	sim_grads_norm = 0.0067
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4854
	data_grads_norm = 2.1764
	new_data_grads_norm = 3.2770
	old_data_grads_norm = 3.5224
	sim_grads_norm = -0.0160
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3110
	data_grads_norm = 2.9399
	new_data_grads_norm = 3.0164
	old_data_grads_norm = 4.1155
	sim_grads_norm = 0.2175
-- Starting training on experience 33 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6454
	data_grads_norm = 3.4169
	new_data_grads_norm = 5.5703
	old_data_grads_norm = 3.8739
	sim_grads_norm = 0.2537
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5567
	data_grads_norm = 2.5358
	new_data_grads_norm = 4.5022
	old_data_grads_norm = 3.3516
	sim_grads_norm = -0.0006
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8944
	data_grads_norm = 3.1217
	new_data_grads_norm = 4.8928
	old_data_grads_norm = 3.0811
	sim_grads_norm = 0.2407
-- Starting training on experience 34 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6331
	data_grads_norm = 2.7074
	new_data_grads_norm = 3.1067
	old_data_grads_norm = 3.2276
	sim_grads_norm = 0.5174
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2099
	data_grads_norm = 1.6050
	new_data_grads_norm = 2.1004
	old_data_grads_norm = 1.8684
	sim_grads_norm = -0.1779
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4292
	data_grads_norm = 1.7016
	new_data_grads_norm = 2.6678
	old_data_grads_norm = 2.6196
	sim_grads_norm = -0.3957
-- Starting training on experience 35 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4546
	data_grads_norm = 2.6252
	new_data_grads_norm = 3.2177
	old_data_grads_norm = 3.1556
	sim_grads_norm = 0.3942
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2959
	data_grads_norm = 2.0690
	new_data_grads_norm = 2.3316
	old_data_grads_norm = 2.5903
	sim_grads_norm = 0.3019
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3781
	data_grads_norm = 2.2649
	new_data_grads_norm = 2.0780
	old_data_grads_norm = 3.3931
	sim_grads_norm = 0.2344
-- Starting training on experience 36 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6502
	data_grads_norm = 2.5368
	new_data_grads_norm = 3.7293
	old_data_grads_norm = 3.6631
	sim_grads_norm = -0.0299
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8581
	data_grads_norm = 3.4225
	new_data_grads_norm = 4.3281
	old_data_grads_norm = 6.2149
	sim_grads_norm = -0.0646
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0602
	data_grads_norm = 3.7832
	new_data_grads_norm = 4.0464
	old_data_grads_norm = 4.8839
	sim_grads_norm = 0.4026
-- Starting training on experience 37 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3050
	data_grads_norm = 1.4512
	new_data_grads_norm = 1.9778
	old_data_grads_norm = 2.8710
	sim_grads_norm = -0.2208
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4562
	data_grads_norm = 2.5265
	new_data_grads_norm = 2.8256
	old_data_grads_norm = 2.7408
	sim_grads_norm = 0.6805
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1909
	data_grads_norm = 1.3457
	new_data_grads_norm = 1.6878
	old_data_grads_norm = 2.7983
	sim_grads_norm = -0.1599
-- Starting training on experience 38 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2897
	data_grads_norm = 1.2583
	new_data_grads_norm = 2.1047
	old_data_grads_norm = 2.0428
	sim_grads_norm = -0.2104
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2277
	data_grads_norm = 1.4980
	new_data_grads_norm = 1.9672
	old_data_grads_norm = 2.6037
	sim_grads_norm = -0.4855
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7027
	data_grads_norm = 3.0924
	new_data_grads_norm = 3.6951
	old_data_grads_norm = 3.4776
	sim_grads_norm = 0.5887
-- Starting training on experience 39 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4341
	data_grads_norm = 2.2172
	new_data_grads_norm = 2.3880
	old_data_grads_norm = 3.2297
	sim_grads_norm = 0.1933
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4000
	data_grads_norm = 2.2797
	new_data_grads_norm = 2.6248
	old_data_grads_norm = 3.4063
	sim_grads_norm = 0.1259
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3750
	data_grads_norm = 2.5239
	new_data_grads_norm = 2.6393
	old_data_grads_norm = 3.1322
	sim_grads_norm = 0.3008
-- Starting training on experience 40 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1601
	data_grads_norm = 2.3162
	new_data_grads_norm = 3.2162
	old_data_grads_norm = 2.9942
	sim_grads_norm = 0.1525
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3669
	data_grads_norm = 2.2447
	new_data_grads_norm = 3.9682
	old_data_grads_norm = 2.8115
	sim_grads_norm = -0.2140
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5447
	data_grads_norm = 3.1434
	new_data_grads_norm = 4.2433
	old_data_grads_norm = 2.9749
	sim_grads_norm = 0.4410
-- Starting training on experience 41 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5511
	data_grads_norm = 2.2077
	new_data_grads_norm = 3.5187
	old_data_grads_norm = 3.5082
	sim_grads_norm = 0.1461
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4541
	data_grads_norm = 2.4894
	new_data_grads_norm = 3.1247
	old_data_grads_norm = 3.2725
	sim_grads_norm = 0.2163
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5590
	data_grads_norm = 2.9781
	new_data_grads_norm = 3.3423
	old_data_grads_norm = 4.8909
	sim_grads_norm = 0.3549
-- Starting training on experience 42 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5412
	data_grads_norm = 2.4344
	new_data_grads_norm = 3.6427
	old_data_grads_norm = 3.0235
	sim_grads_norm = 0.1669
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2175
	data_grads_norm = 2.1661
	new_data_grads_norm = 3.2974
	old_data_grads_norm = 1.9563
	sim_grads_norm = -0.0753
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4172
	data_grads_norm = 3.3288
	new_data_grads_norm = 4.5387
	old_data_grads_norm = 3.4447
	sim_grads_norm = -0.0799
-- Starting training on experience 43 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3608
	data_grads_norm = 2.5368
	new_data_grads_norm = 2.7805
	old_data_grads_norm = 3.4021
	sim_grads_norm = 0.0564
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4249
	data_grads_norm = 2.2858
	new_data_grads_norm = 3.4644
	old_data_grads_norm = 2.6832
	sim_grads_norm = 0.1656
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5530
	data_grads_norm = 2.5050
	new_data_grads_norm = 2.7134
	old_data_grads_norm = 4.2507
	sim_grads_norm = 0.0093
-- Starting training on experience 44 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5987
	data_grads_norm = 2.2880
	new_data_grads_norm = 3.4777
	old_data_grads_norm = 2.6517
	sim_grads_norm = -0.0220
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6278
	data_grads_norm = 2.5128
	new_data_grads_norm = 3.4026
	old_data_grads_norm = 3.3526
	sim_grads_norm = 0.2823
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5226
	data_grads_norm = 2.6863
	new_data_grads_norm = 4.4148
	old_data_grads_norm = 2.8154
	sim_grads_norm = 0.2011
-- Starting training on experience 45 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2713
	data_grads_norm = 2.5982
	new_data_grads_norm = 4.2241
	old_data_grads_norm = 4.1649
	sim_grads_norm = 0.2784
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2962
	data_grads_norm = 2.6846
	new_data_grads_norm = 3.8170
	old_data_grads_norm = 2.9787
	sim_grads_norm = 0.0454
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4726
	data_grads_norm = 3.0084
	new_data_grads_norm = 4.1423
	old_data_grads_norm = 4.8101
	sim_grads_norm = -0.0736
-- Starting training on experience 46 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2295
	data_grads_norm = 2.0652
	new_data_grads_norm = 2.6261
	old_data_grads_norm = 3.2062
	sim_grads_norm = 0.1107
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5981
	data_grads_norm = 3.4421
	new_data_grads_norm = 2.8910
	old_data_grads_norm = 5.2486
	sim_grads_norm = 0.2642
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4960
	data_grads_norm = 2.4888
	new_data_grads_norm = 3.3717
	old_data_grads_norm = 3.0758
	sim_grads_norm = 0.1918
-- Starting training on experience 47 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2709
	data_grads_norm = 2.4960
	new_data_grads_norm = 2.6043
	old_data_grads_norm = 3.1042
	sim_grads_norm = 0.5810
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3815
	data_grads_norm = 2.3646
	new_data_grads_norm = 2.4122
	old_data_grads_norm = 3.8049
	sim_grads_norm = -0.1970
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3901
	data_grads_norm = 2.0271
	new_data_grads_norm = 1.9046
	old_data_grads_norm = 4.1835
	sim_grads_norm = 0.1166
-- Starting training on experience 48 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3672
	data_grads_norm = 3.4241
	new_data_grads_norm = 3.7276
	old_data_grads_norm = 4.3168
	sim_grads_norm = 0.4305
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4584
	data_grads_norm = 2.5547
	new_data_grads_norm = 3.5304
	old_data_grads_norm = 3.4363
	sim_grads_norm = 0.1324
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3057
	data_grads_norm = 2.5976
	new_data_grads_norm = 3.0470
	old_data_grads_norm = 2.9433
	sim_grads_norm = 0.4498
-- Starting training on experience 49 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8786
	data_grads_norm = 3.9862
	new_data_grads_norm = 4.7535
	old_data_grads_norm = 4.5642
	sim_grads_norm = 0.3547
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0795
	data_grads_norm = 2.0785
	new_data_grads_norm = 4.0972
	old_data_grads_norm = 2.3158
	sim_grads_norm = -0.2721
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7338
	data_grads_norm = 3.4650
	new_data_grads_norm = 4.3944
	old_data_grads_norm = 4.4662
	sim_grads_norm = 0.2295
-- Starting training on experience 50 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1885
	data_grads_norm = 2.2332
	new_data_grads_norm = 3.5429
	old_data_grads_norm = 2.1537
	sim_grads_norm = 0.2711
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2662
	data_grads_norm = 3.0456
	new_data_grads_norm = 3.4371
	old_data_grads_norm = 3.6809
	sim_grads_norm = 0.3886
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4782
	data_grads_norm = 2.9899
	new_data_grads_norm = 3.5277
	old_data_grads_norm = 3.0971
	sim_grads_norm = 0.1623
-- Starting training on experience 51 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5303
	data_grads_norm = 2.8894
	new_data_grads_norm = 3.3239
	old_data_grads_norm = 3.6169
	sim_grads_norm = 0.3837
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2789
	data_grads_norm = 2.1685
	new_data_grads_norm = 3.1162
	old_data_grads_norm = 3.2262
	sim_grads_norm = 0.0897
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3461
	data_grads_norm = 2.9327
	new_data_grads_norm = 3.5157
	old_data_grads_norm = 3.3933
	sim_grads_norm = 0.3657
-- Starting training on experience 52 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7042
	data_grads_norm = 2.8797
	new_data_grads_norm = 2.9972
	old_data_grads_norm = 4.9251
	sim_grads_norm = 0.3220
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2762
	data_grads_norm = 1.6458
	new_data_grads_norm = 2.0049
	old_data_grads_norm = 2.9641
	sim_grads_norm = 0.3171
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5863
	data_grads_norm = 2.0401
	new_data_grads_norm = 2.2653
	old_data_grads_norm = 3.5247
	sim_grads_norm = 0.0846
-- Starting training on experience 53 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6500
	data_grads_norm = 2.8604
	new_data_grads_norm = 3.2226
	old_data_grads_norm = 3.4538
	sim_grads_norm = 0.3570
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2535
	data_grads_norm = 1.5725
	new_data_grads_norm = 2.8360
	old_data_grads_norm = 2.8821
	sim_grads_norm = -0.2265
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7336
	data_grads_norm = 2.5232
	new_data_grads_norm = 3.0053
	old_data_grads_norm = 3.4837
	sim_grads_norm = 0.3072
-- Starting training on experience 54 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4876
	data_grads_norm = 2.2841
	new_data_grads_norm = 2.5012
	old_data_grads_norm = 3.3321
	sim_grads_norm = 0.2364
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3159
	data_grads_norm = 1.5976
	new_data_grads_norm = 2.4910
	old_data_grads_norm = 2.4236
	sim_grads_norm = 0.1712
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1818
	data_grads_norm = 1.4949
	new_data_grads_norm = 2.9016
	old_data_grads_norm = 1.9171
	sim_grads_norm = -0.0002
-- Starting training on experience 55 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2897
	data_grads_norm = 1.5974
	new_data_grads_norm = 2.6697
	old_data_grads_norm = 1.8449
	sim_grads_norm = 0.0121
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2662
	data_grads_norm = 1.9281
	new_data_grads_norm = 3.2708
	old_data_grads_norm = 2.6405
	sim_grads_norm = -0.0372
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1436
	data_grads_norm = 1.8531
	new_data_grads_norm = 3.2417
	old_data_grads_norm = 1.9472
	sim_grads_norm = 0.2214
-- Starting training on experience 56 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3277
	data_grads_norm = 2.0319
	new_data_grads_norm = 2.8341
	old_data_grads_norm = 2.1130
	sim_grads_norm = 0.2256
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3839
	data_grads_norm = 2.3394
	new_data_grads_norm = 2.8425
	old_data_grads_norm = 3.3644
	sim_grads_norm = 0.1641
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3686
	data_grads_norm = 2.2678
	new_data_grads_norm = 2.3394
	old_data_grads_norm = 3.6835
	sim_grads_norm = 0.2653
-- Starting training on experience 57 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4112
	data_grads_norm = 3.0592
	new_data_grads_norm = 3.8319
	old_data_grads_norm = 3.8910
	sim_grads_norm = 0.4885
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2652
	data_grads_norm = 2.4913
	new_data_grads_norm = 2.5049
	old_data_grads_norm = 3.9393
	sim_grads_norm = 0.1312
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3334
	data_grads_norm = 2.5099
	new_data_grads_norm = 3.4579
	old_data_grads_norm = 3.0094
	sim_grads_norm = 0.1069
-- Starting training on experience 58 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4736
	data_grads_norm = 2.6247
	new_data_grads_norm = 2.8633
	old_data_grads_norm = 2.9085
	sim_grads_norm = 0.3132
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4556
	data_grads_norm = 2.4237
	new_data_grads_norm = 2.5710
	old_data_grads_norm = 2.9517
	sim_grads_norm = 0.1622
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3311
	data_grads_norm = 1.8871
	new_data_grads_norm = 3.3409
	old_data_grads_norm = 3.0945
	sim_grads_norm = -0.1487
-- Starting training on experience 59 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0154
	data_grads_norm = 1.7741
	new_data_grads_norm = 2.6944
	old_data_grads_norm = 2.3480
	sim_grads_norm = 0.0714
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3935
	data_grads_norm = 2.5134
	new_data_grads_norm = 3.0971
	old_data_grads_norm = 4.3396
	sim_grads_norm = 0.1448
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3712
	data_grads_norm = 2.2539
	new_data_grads_norm = 3.4477
	old_data_grads_norm = 2.9106
	sim_grads_norm = 0.3033
-- Starting training on experience 60 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3264
	data_grads_norm = 1.9548
	new_data_grads_norm = 2.0565
	old_data_grads_norm = 2.8605
	sim_grads_norm = 0.1098
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2860
	data_grads_norm = 1.7976
	new_data_grads_norm = 2.2070
	old_data_grads_norm = 3.5056
	sim_grads_norm = 0.2556
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2540
	data_grads_norm = 1.9434
	new_data_grads_norm = 2.4512
	old_data_grads_norm = 3.2513
	sim_grads_norm = 0.1519
-- Starting training on experience 61 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3012
	data_grads_norm = 2.4578
	new_data_grads_norm = 2.9010
	old_data_grads_norm = 3.2782
	sim_grads_norm = 0.0689
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2873
	data_grads_norm = 2.4345
	new_data_grads_norm = 4.0217
	old_data_grads_norm = 2.0864
	sim_grads_norm = 0.3212
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1548
	data_grads_norm = 2.1699
	new_data_grads_norm = 3.5213
	old_data_grads_norm = 2.7810
	sim_grads_norm = 0.2063
-- Starting training on experience 62 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1417
	data_grads_norm = 1.6321
	new_data_grads_norm = 2.8241
	old_data_grads_norm = 2.8019
	sim_grads_norm = -0.1242
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3259
	data_grads_norm = 1.9514
	new_data_grads_norm = 2.9626
	old_data_grads_norm = 2.7098
	sim_grads_norm = -0.0994
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6252
	data_grads_norm = 2.7546
	new_data_grads_norm = 3.4313
	old_data_grads_norm = 3.6711
	sim_grads_norm = 0.4065
-- Starting training on experience 63 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1568
	data_grads_norm = 1.9025
	new_data_grads_norm = 3.3374
	old_data_grads_norm = 1.8409
	sim_grads_norm = -0.0999
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2113
	data_grads_norm = 2.1110
	new_data_grads_norm = 4.2531
	old_data_grads_norm = 2.4644
	sim_grads_norm = -0.0129
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3756
	data_grads_norm = 2.2251
	new_data_grads_norm = 4.8255
	old_data_grads_norm = 2.9011
	sim_grads_norm = -0.0001
-- Starting training on experience 64 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5554
	data_grads_norm = 2.4959
	new_data_grads_norm = 3.4962
	old_data_grads_norm = 3.3146
	sim_grads_norm = 0.2908
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2657
	data_grads_norm = 2.4371
	new_data_grads_norm = 2.6631
	old_data_grads_norm = 3.9345
	sim_grads_norm = 0.2185
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3700
	data_grads_norm = 2.5327
	new_data_grads_norm = 3.4516
	old_data_grads_norm = 2.4458
	sim_grads_norm = 0.4316
-- Starting training on experience 65 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2004
	data_grads_norm = 2.5015
	new_data_grads_norm = 4.4206
	old_data_grads_norm = 2.8599
	sim_grads_norm = 0.0554
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3569
	data_grads_norm = 3.0022
	new_data_grads_norm = 4.4194
	old_data_grads_norm = 3.3476
	sim_grads_norm = 0.3409
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1968
	data_grads_norm = 2.8157
	new_data_grads_norm = 3.3168
	old_data_grads_norm = 4.7602
	sim_grads_norm = 0.0564
-- Starting training on experience 66 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5244
	data_grads_norm = 2.8145
	new_data_grads_norm = 3.9930
	old_data_grads_norm = 4.6113
	sim_grads_norm = 0.2413
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5475
	data_grads_norm = 2.0037
	new_data_grads_norm = 4.2675
	old_data_grads_norm = 2.9222
	sim_grads_norm = -0.1630
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9187
	data_grads_norm = 2.8562
	new_data_grads_norm = 4.5716
	old_data_grads_norm = 2.2476
	sim_grads_norm = 0.4523
-- Starting training on experience 67 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4314
	data_grads_norm = 2.5146
	new_data_grads_norm = 2.7142
	old_data_grads_norm = 3.7047
	sim_grads_norm = 0.4196
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2285
	data_grads_norm = 1.6525
	new_data_grads_norm = 3.0948
	old_data_grads_norm = 2.4879
	sim_grads_norm = -0.0171
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2309
	data_grads_norm = 1.6246
	new_data_grads_norm = 2.9221
	old_data_grads_norm = 2.4505
	sim_grads_norm = -0.0994
-- Starting training on experience 68 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3010
	data_grads_norm = 2.4483
	new_data_grads_norm = 3.3934
	old_data_grads_norm = 3.1711
	sim_grads_norm = 0.1111
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4424
	data_grads_norm = 2.3693
	new_data_grads_norm = 3.7988
	old_data_grads_norm = 3.2908
	sim_grads_norm = -0.0718
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8214
	data_grads_norm = 4.3252
	new_data_grads_norm = 4.7692
	old_data_grads_norm = 4.7302
	sim_grads_norm = 0.5642
-- Starting training on experience 69 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4838
	data_grads_norm = 2.3595
	new_data_grads_norm = 3.7126
	old_data_grads_norm = 2.2226
	sim_grads_norm = 0.5004
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3669
	data_grads_norm = 2.2019
	new_data_grads_norm = 2.6736
	old_data_grads_norm = 2.9085
	sim_grads_norm = 0.2570
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1025
	data_grads_norm = 3.1632
	new_data_grads_norm = 3.9942
	old_data_grads_norm = 3.5231
	sim_grads_norm = 0.5647
-- Starting training on experience 70 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2304
	data_grads_norm = 2.3818
	new_data_grads_norm = 2.9753
	old_data_grads_norm = 4.6723
	sim_grads_norm = 0.0671
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3671
	data_grads_norm = 3.2370
	new_data_grads_norm = 3.6588
	old_data_grads_norm = 4.0502
	sim_grads_norm = 0.4198
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3162
	data_grads_norm = 2.4897
	new_data_grads_norm = 2.2517
	old_data_grads_norm = 4.2204
	sim_grads_norm = 0.3839
-- Starting training on experience 71 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1194
	data_grads_norm = 1.9717
	new_data_grads_norm = 3.0384
	old_data_grads_norm = 2.1054
	sim_grads_norm = 0.2148
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1846
	data_grads_norm = 1.9957
	new_data_grads_norm = 2.8963
	old_data_grads_norm = 2.3797
	sim_grads_norm = -0.0698
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2152
	data_grads_norm = 2.5522
	new_data_grads_norm = 3.5770
	old_data_grads_norm = 4.1928
	sim_grads_norm = -0.0337
-- Starting training on experience 72 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4182
	data_grads_norm = 3.1548
	new_data_grads_norm = 2.4633
	old_data_grads_norm = 4.3748
	sim_grads_norm = 0.2394
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0766
	data_grads_norm = 2.5525
	new_data_grads_norm = 2.6822
	old_data_grads_norm = 3.6318
	sim_grads_norm = -0.1500
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7882
	data_grads_norm = 3.2615
	new_data_grads_norm = 3.2131
	old_data_grads_norm = 4.5028
	sim_grads_norm = 0.2806
-- Starting training on experience 73 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1791
	data_grads_norm = 2.8367
	new_data_grads_norm = 3.4626
	old_data_grads_norm = 2.8524
	sim_grads_norm = 0.5146
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0550
	data_grads_norm = 1.9520
	new_data_grads_norm = 2.1568
	old_data_grads_norm = 2.6627
	sim_grads_norm = 0.2580
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8392
	data_grads_norm = 1.3039
	new_data_grads_norm = 2.1017
	old_data_grads_norm = 1.6215
	sim_grads_norm = 0.0042
-- Starting training on experience 74 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4740
	data_grads_norm = 2.8609
	new_data_grads_norm = 3.0882
	old_data_grads_norm = 3.8579
	sim_grads_norm = 0.2874
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4666
	data_grads_norm = 2.4483
	new_data_grads_norm = 2.7608
	old_data_grads_norm = 3.8253
	sim_grads_norm = 0.2709
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2336
	data_grads_norm = 1.7710
	new_data_grads_norm = 2.1489
	old_data_grads_norm = 2.3204
	sim_grads_norm = 0.3488
-- Starting training on experience 75 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2892
	data_grads_norm = 1.6164
	new_data_grads_norm = 2.4310
	old_data_grads_norm = 2.2378
	sim_grads_norm = 0.0125
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9129
	data_grads_norm = 1.5292
	new_data_grads_norm = 1.9729
	old_data_grads_norm = 2.2875
	sim_grads_norm = 0.0761
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9230
	data_grads_norm = 1.5378
	new_data_grads_norm = 2.5186
	old_data_grads_norm = 2.3887
	sim_grads_norm = -0.2397
-- Starting training on experience 76 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2827
	data_grads_norm = 2.9804
	new_data_grads_norm = 3.9499
	old_data_grads_norm = 3.7397
	sim_grads_norm = 0.3874
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3551
	data_grads_norm = 3.0781
	new_data_grads_norm = 3.9030
	old_data_grads_norm = 4.2386
	sim_grads_norm = 0.3755
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3583
	data_grads_norm = 2.8589
	new_data_grads_norm = 3.9373
	old_data_grads_norm = 2.8603
	sim_grads_norm = 0.2248
-- Starting training on experience 77 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5610
	data_grads_norm = 2.2377
	new_data_grads_norm = 2.9468
	old_data_grads_norm = 2.7278
	sim_grads_norm = -0.0070
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4353
	data_grads_norm = 2.4011
	new_data_grads_norm = 3.2992
	old_data_grads_norm = 3.1087
	sim_grads_norm = -0.0001
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8359
	data_grads_norm = 3.6061
	new_data_grads_norm = 4.2012
	old_data_grads_norm = 4.7560
	sim_grads_norm = 0.4840
-- Starting training on experience 78 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3883
	data_grads_norm = 2.3767
	new_data_grads_norm = 3.4248
	old_data_grads_norm = 3.2856
	sim_grads_norm = 0.0735
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0624
	data_grads_norm = 2.0181
	new_data_grads_norm = 3.3976
	old_data_grads_norm = 1.9022
	sim_grads_norm = -0.3426
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5608
	data_grads_norm = 2.9135
	new_data_grads_norm = 4.2338
	old_data_grads_norm = 3.0837
	sim_grads_norm = 0.3930
-- Starting training on experience 79 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0231
	data_grads_norm = 1.5951
	new_data_grads_norm = 3.1425
	old_data_grads_norm = 1.6417
	sim_grads_norm = -0.0835
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1609
	data_grads_norm = 1.9481
	new_data_grads_norm = 2.8990
	old_data_grads_norm = 2.2360
	sim_grads_norm = 0.1506
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2136
	data_grads_norm = 2.4705
	new_data_grads_norm = 2.9912
	old_data_grads_norm = 3.0078
	sim_grads_norm = 0.1322
-- Starting training on experience 80 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3369
	data_grads_norm = 2.5605
	new_data_grads_norm = 3.9838
	old_data_grads_norm = 2.9802
	sim_grads_norm = 0.0979
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1863
	data_grads_norm = 2.2716
	new_data_grads_norm = 3.6929
	old_data_grads_norm = 1.9717
	sim_grads_norm = 0.4254
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1200
	data_grads_norm = 1.7052
	new_data_grads_norm = 3.5734
	old_data_grads_norm = 3.2529
	sim_grads_norm = 0.0188
-- Starting training on experience 81 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1898
	data_grads_norm = 2.0441
	new_data_grads_norm = 2.4426
	old_data_grads_norm = 3.2770
	sim_grads_norm = 0.2519
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4260
	data_grads_norm = 2.4970
	new_data_grads_norm = 2.4538
	old_data_grads_norm = 3.3852
	sim_grads_norm = 0.5581
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1176
	data_grads_norm = 1.5815
	new_data_grads_norm = 2.3617
	old_data_grads_norm = 2.4561
	sim_grads_norm = -0.2615
-- Starting training on experience 82 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4156
	data_grads_norm = 2.2900
	new_data_grads_norm = 3.1737
	old_data_grads_norm = 3.1188
	sim_grads_norm = 0.0811
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2906
	data_grads_norm = 1.8940
	new_data_grads_norm = 3.1132
	old_data_grads_norm = 3.0104
	sim_grads_norm = -0.2495
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3614
	data_grads_norm = 2.4408
	new_data_grads_norm = 3.5503
	old_data_grads_norm = 3.2454
	sim_grads_norm = 0.1257
-- Starting training on experience 83 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0929
	data_grads_norm = 2.6784
	new_data_grads_norm = 3.4159
	old_data_grads_norm = 3.0113
	sim_grads_norm = -0.0932
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1468
	data_grads_norm = 2.3322
	new_data_grads_norm = 3.4854
	old_data_grads_norm = 3.4148
	sim_grads_norm = -0.1311
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2555
	data_grads_norm = 3.1706
	new_data_grads_norm = 4.3222
	old_data_grads_norm = 3.5096
	sim_grads_norm = 0.2913
-- Starting training on experience 84 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3338
	data_grads_norm = 2.3951
	new_data_grads_norm = 3.5914
	old_data_grads_norm = 3.4829
	sim_grads_norm = 0.0787
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2993
	data_grads_norm = 2.0043
	new_data_grads_norm = 3.6782
	old_data_grads_norm = 1.8532
	sim_grads_norm = 0.1712
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3807
	data_grads_norm = 2.5561
	new_data_grads_norm = 3.1203
	old_data_grads_norm = 3.3051
	sim_grads_norm = 0.3755
-- Starting training on experience 85 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2586
	data_grads_norm = 1.9535
	new_data_grads_norm = 3.6704
	old_data_grads_norm = 3.2237
	sim_grads_norm = -0.2933
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4777
	data_grads_norm = 2.9647
	new_data_grads_norm = 3.7390
	old_data_grads_norm = 3.9041
	sim_grads_norm = 0.5492
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2705
	data_grads_norm = 2.0238
	new_data_grads_norm = 3.1155
	old_data_grads_norm = 3.0355
	sim_grads_norm = -0.0307
-- Starting training on experience 86 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6006
	data_grads_norm = 3.1063
	new_data_grads_norm = 5.0395
	old_data_grads_norm = 3.3642
	sim_grads_norm = 0.0766
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5976
	data_grads_norm = 2.7841
	new_data_grads_norm = 4.4068
	old_data_grads_norm = 2.8798
	sim_grads_norm = -0.0912
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5669
	data_grads_norm = 2.9871
	new_data_grads_norm = 4.6192
	old_data_grads_norm = 2.6265
	sim_grads_norm = 0.3440
-- Starting training on experience 87 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0769
	data_grads_norm = 2.7884
	new_data_grads_norm = 3.9522
	old_data_grads_norm = 3.2177
	sim_grads_norm = 0.1953
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0752
	data_grads_norm = 2.4722
	new_data_grads_norm = 4.7557
	old_data_grads_norm = 1.9866
	sim_grads_norm = 0.0594
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9758
	data_grads_norm = 2.8053
	new_data_grads_norm = 3.7632
	old_data_grads_norm = 2.7449
	sim_grads_norm = 0.5537
-- Starting training on experience 88 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8608
	data_grads_norm = 2.0573
	new_data_grads_norm = 4.2669
	old_data_grads_norm = 2.7129
	sim_grads_norm = -0.1233
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3263
	data_grads_norm = 3.2024
	new_data_grads_norm = 4.3906
	old_data_grads_norm = 3.7643
	sim_grads_norm = 0.1327
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1508
	data_grads_norm = 2.7391
	new_data_grads_norm = 5.5524
	old_data_grads_norm = 3.0939
	sim_grads_norm = 0.1311
-- Starting training on experience 89 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0131
	data_grads_norm = 2.5282
	new_data_grads_norm = 3.7136
	old_data_grads_norm = 2.6696
	sim_grads_norm = 0.0886
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2635
	data_grads_norm = 2.4913
	new_data_grads_norm = 3.8376
	old_data_grads_norm = 4.1682
	sim_grads_norm = 0.1712
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4186
	data_grads_norm = 2.6656
	new_data_grads_norm = 4.0989
	old_data_grads_norm = 3.1663
	sim_grads_norm = 0.2185
-- Starting training on experience 90 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7197
	data_grads_norm = 4.3575
	new_data_grads_norm = 3.7780
	old_data_grads_norm = 5.1880
	sim_grads_norm = 0.4720
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2488
	data_grads_norm = 1.7567
	new_data_grads_norm = 1.7353
	old_data_grads_norm = 3.1919
	sim_grads_norm = 0.1535
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2544
	data_grads_norm = 1.6772
	new_data_grads_norm = 1.9782
	old_data_grads_norm = 3.0333
	sim_grads_norm = 0.1332
-- Starting training on experience 91 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3835
	data_grads_norm = 2.3925
	new_data_grads_norm = 2.6143
	old_data_grads_norm = 4.2935
	sim_grads_norm = -0.0718
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5883
	data_grads_norm = 2.5909
	new_data_grads_norm = 3.3217
	old_data_grads_norm = 3.3435
	sim_grads_norm = 0.2730
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2126
	data_grads_norm = 2.0040
	new_data_grads_norm = 2.7780
	old_data_grads_norm = 2.7899
	sim_grads_norm = 0.2452
-- Starting training on experience 92 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4620
	data_grads_norm = 1.9349
	new_data_grads_norm = 3.4568
	old_data_grads_norm = 2.0498
	sim_grads_norm = 0.1279
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3228
	data_grads_norm = 1.9154
	new_data_grads_norm = 2.8249
	old_data_grads_norm = 3.1875
	sim_grads_norm = -0.2023
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4848
	data_grads_norm = 2.4786
	new_data_grads_norm = 3.6324
	old_data_grads_norm = 2.8978
	sim_grads_norm = 0.1406
-- Starting training on experience 93 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6426
	data_grads_norm = 2.2630
	new_data_grads_norm = 2.6605
	old_data_grads_norm = 3.2239
	sim_grads_norm = 0.1414
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1985
	data_grads_norm = 1.5714
	new_data_grads_norm = 2.3231
	old_data_grads_norm = 2.4258
	sim_grads_norm = 0.0650
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1133
	data_grads_norm = 1.8074
	new_data_grads_norm = 2.6942
	old_data_grads_norm = 2.1678
	sim_grads_norm = 0.0396
-- Starting training on experience 94 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1993
	data_grads_norm = 1.8614
	new_data_grads_norm = 2.2523
	old_data_grads_norm = 2.3568
	sim_grads_norm = 0.4040
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7854
	data_grads_norm = 1.0252
	new_data_grads_norm = 1.6897
	old_data_grads_norm = 1.6440
	sim_grads_norm = -0.1751
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8855
	data_grads_norm = 1.4190
	new_data_grads_norm = 1.9597
	old_data_grads_norm = 3.0534
	sim_grads_norm = -0.0682
-- Starting training on experience 95 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9611
	data_grads_norm = 1.5919
	new_data_grads_norm = 2.4991
	old_data_grads_norm = 2.4089
	sim_grads_norm = -0.1073
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0739
	data_grads_norm = 2.4126
	new_data_grads_norm = 3.9199
	old_data_grads_norm = 2.3505
	sim_grads_norm = 0.0636
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2633
	data_grads_norm = 3.1756
	new_data_grads_norm = 4.0220
	old_data_grads_norm = 4.7403
	sim_grads_norm = 0.2081
-- Starting training on experience 96 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9376
	data_grads_norm = 4.0581
	new_data_grads_norm = 5.1009
	old_data_grads_norm = 3.8559
	sim_grads_norm = 0.4422
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1004
	data_grads_norm = 2.1405
	new_data_grads_norm = 3.2355
	old_data_grads_norm = 2.3645
	sim_grads_norm = 0.2724
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1763
	data_grads_norm = 2.0185
	new_data_grads_norm = 2.6095
	old_data_grads_norm = 4.7395
	sim_grads_norm = 0.0434
-- Starting training on experience 97 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1855
	data_grads_norm = 1.9750
	new_data_grads_norm = 3.5208
	old_data_grads_norm = 2.4236
	sim_grads_norm = 0.0253
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3702
	data_grads_norm = 2.3190
	new_data_grads_norm = 3.7205
	old_data_grads_norm = 2.6793
	sim_grads_norm = 0.3354
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1508
	data_grads_norm = 2.3156
	new_data_grads_norm = 3.0364
	old_data_grads_norm = 2.9455
	sim_grads_norm = 0.3225
-- Starting training on experience 98 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9587
	data_grads_norm = 4.0645
	new_data_grads_norm = 4.7467
	old_data_grads_norm = 4.5102
	sim_grads_norm = 0.2800
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2727
	data_grads_norm = 1.7913
	new_data_grads_norm = 2.8146
	old_data_grads_norm = 2.6203
	sim_grads_norm = 0.1544
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1637
	data_grads_norm = 1.8125
	new_data_grads_norm = 2.6430
	old_data_grads_norm = 2.4881
	sim_grads_norm = 0.0883
-- Starting training on experience 99 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2454
	data_grads_norm = 2.0103
	new_data_grads_norm = 2.4493
	old_data_grads_norm = 2.1121
	sim_grads_norm = 0.3384
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5353
	data_grads_norm = 2.2807
	new_data_grads_norm = 2.0763
	old_data_grads_norm = 3.3615
	sim_grads_norm = 0.2595
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2068
	data_grads_norm = 1.2199
	new_data_grads_norm = 2.0491
	old_data_grads_norm = 1.6957
	sim_grads_norm = 0.0783
-- Starting training on experience 100 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3290
	data_grads_norm = 1.9022
	new_data_grads_norm = 2.5536
	old_data_grads_norm = 2.1449
	sim_grads_norm = 0.1081
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3292
	data_grads_norm = 1.7679
	new_data_grads_norm = 2.6570
	old_data_grads_norm = 3.7365
	sim_grads_norm = -0.0729
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5308
	data_grads_norm = 2.1788
	new_data_grads_norm = 3.3254
	old_data_grads_norm = 2.4271
	sim_grads_norm = 0.0631
-- Starting training on experience 101 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8772
	data_grads_norm = 1.7112
	new_data_grads_norm = 2.0644
	old_data_grads_norm = 2.5913
	sim_grads_norm = 0.1497
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0054
	data_grads_norm = 1.9320
	new_data_grads_norm = 2.6001
	old_data_grads_norm = 2.6284
	sim_grads_norm = 0.0993
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2706
	data_grads_norm = 1.8191
	new_data_grads_norm = 2.6125
	old_data_grads_norm = 3.0303
	sim_grads_norm = -0.2111
-- Starting training on experience 102 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5379
	data_grads_norm = 2.3318
	new_data_grads_norm = 3.6580
	old_data_grads_norm = 2.7861
	sim_grads_norm = 0.2221
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4552
	data_grads_norm = 1.6631
	new_data_grads_norm = 3.0059
	old_data_grads_norm = 2.1116
	sim_grads_norm = -0.2376
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4221
	data_grads_norm = 1.6171
	new_data_grads_norm = 3.3452
	old_data_grads_norm = 1.9104
	sim_grads_norm = -0.0577
-- Starting training on experience 103 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2932
	data_grads_norm = 2.1302
	new_data_grads_norm = 3.0936
	old_data_grads_norm = 2.4241
	sim_grads_norm = 0.0871
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3739
	data_grads_norm = 2.0639
	new_data_grads_norm = 3.0906
	old_data_grads_norm = 2.0706
	sim_grads_norm = 0.2093
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4125
	data_grads_norm = 1.9535
	new_data_grads_norm = 2.8253
	old_data_grads_norm = 2.8109
	sim_grads_norm = 0.2366
-- Starting training on experience 104 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1694
	data_grads_norm = 1.9945
	new_data_grads_norm = 2.9241
	old_data_grads_norm = 3.4881
	sim_grads_norm = -0.1876
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4467
	data_grads_norm = 2.9080
	new_data_grads_norm = 3.6297
	old_data_grads_norm = 2.7793
	sim_grads_norm = 0.3424
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3608
	data_grads_norm = 2.2623
	new_data_grads_norm = 3.3936
	old_data_grads_norm = 2.4878
	sim_grads_norm = 0.1698
-- Starting training on experience 105 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1145
	data_grads_norm = 1.8346
	new_data_grads_norm = 3.5247
	old_data_grads_norm = 1.4926
	sim_grads_norm = 0.0456
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2309
	data_grads_norm = 2.2542
	new_data_grads_norm = 3.2432
	old_data_grads_norm = 2.1675
	sim_grads_norm = 0.2680
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3576
	data_grads_norm = 2.2836
	new_data_grads_norm = 3.1201
	old_data_grads_norm = 3.3872
	sim_grads_norm = 0.1058
-- Starting training on experience 106 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1386
	data_grads_norm = 1.4938
	new_data_grads_norm = 2.7012
	old_data_grads_norm = 2.4452
	sim_grads_norm = -0.1278
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1871
	data_grads_norm = 2.0273
	new_data_grads_norm = 3.1216
	old_data_grads_norm = 2.3668
	sim_grads_norm = 0.3572
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3642
	data_grads_norm = 2.2625
	new_data_grads_norm = 2.7484
	old_data_grads_norm = 3.0081
	sim_grads_norm = 0.2495
-- Starting training on experience 107 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2733
	data_grads_norm = 1.6779
	new_data_grads_norm = 2.5487
	old_data_grads_norm = 2.1998
	sim_grads_norm = -0.0467
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2566
	data_grads_norm = 2.0849
	new_data_grads_norm = 2.7029
	old_data_grads_norm = 2.4903
	sim_grads_norm = 0.2072
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3304
	data_grads_norm = 2.0845
	new_data_grads_norm = 3.0428
	old_data_grads_norm = 2.3040
	sim_grads_norm = 0.0406
-- Starting training on experience 108 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2774
	data_grads_norm = 2.0255
	new_data_grads_norm = 3.2177
	old_data_grads_norm = 3.6420
	sim_grads_norm = -0.2916
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4943
	data_grads_norm = 2.3074
	new_data_grads_norm = 4.3702
	old_data_grads_norm = 2.3009
	sim_grads_norm = 0.3279
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2773
	data_grads_norm = 2.7890
	new_data_grads_norm = 3.8945
	old_data_grads_norm = 3.3933
	sim_grads_norm = 0.3120
-- Starting training on experience 109 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2411
	data_grads_norm = 2.0280
	new_data_grads_norm = 2.8301
	old_data_grads_norm = 2.8897
	sim_grads_norm = 0.0162
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4450
	data_grads_norm = 1.9645
	new_data_grads_norm = 2.7764
	old_data_grads_norm = 1.9865
	sim_grads_norm = 0.2980
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2050
	data_grads_norm = 2.1639
	new_data_grads_norm = 2.7405
	old_data_grads_norm = 2.8054
	sim_grads_norm = 0.0256
-- Starting training on experience 110 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5479
	data_grads_norm = 2.3510
	new_data_grads_norm = 3.6786
	old_data_grads_norm = 3.0685
	sim_grads_norm = 0.2928
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2939
	data_grads_norm = 1.7213
	new_data_grads_norm = 3.7721
	old_data_grads_norm = 2.1430
	sim_grads_norm = 0.0597
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3212
	data_grads_norm = 1.5469
	new_data_grads_norm = 3.5527
	old_data_grads_norm = 1.6904
	sim_grads_norm = 0.1372
-- Starting training on experience 111 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1315
	data_grads_norm = 1.5390
	new_data_grads_norm = 2.0467
	old_data_grads_norm = 2.5166
	sim_grads_norm = -0.1151
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2751
	data_grads_norm = 1.6353
	new_data_grads_norm = 2.0009
	old_data_grads_norm = 3.7053
	sim_grads_norm = 0.0781
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3142
	data_grads_norm = 1.8115
	new_data_grads_norm = 2.4515
	old_data_grads_norm = 2.3533
	sim_grads_norm = 0.3678
-- Starting training on experience 112 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0539
	data_grads_norm = 1.7698
	new_data_grads_norm = 2.7810
	old_data_grads_norm = 1.6105
	sim_grads_norm = 0.3435
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9588
	data_grads_norm = 1.4631
	new_data_grads_norm = 2.0308
	old_data_grads_norm = 1.9089
	sim_grads_norm = 0.1693
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8400
	data_grads_norm = 1.4006
	new_data_grads_norm = 2.3948
	old_data_grads_norm = 2.1365
	sim_grads_norm = -0.0970
-- Starting training on experience 113 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3730
	data_grads_norm = 1.9570
	new_data_grads_norm = 2.5932
	old_data_grads_norm = 1.9347
	sim_grads_norm = 0.4499
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3562
	data_grads_norm = 1.8531
	new_data_grads_norm = 2.6916
	old_data_grads_norm = 2.3933
	sim_grads_norm = 0.0336
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2626
	data_grads_norm = 1.8722
	new_data_grads_norm = 3.0051
	old_data_grads_norm = 2.2222
	sim_grads_norm = 0.1033
-- Starting training on experience 114 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0629
	data_grads_norm = 1.4675
	new_data_grads_norm = 2.8621
	old_data_grads_norm = 1.9995
	sim_grads_norm = -0.3268
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2577
	data_grads_norm = 2.2569
	new_data_grads_norm = 3.1766
	old_data_grads_norm = 2.8311
	sim_grads_norm = 0.4137
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2937
	data_grads_norm = 2.6749
	new_data_grads_norm = 2.9409
	old_data_grads_norm = 3.7170
	sim_grads_norm = 0.1265
-- Starting training on experience 115 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0576
	data_grads_norm = 1.9469
	new_data_grads_norm = 3.4325
	old_data_grads_norm = 4.1815
	sim_grads_norm = -0.1765
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3182
	data_grads_norm = 3.0867
	new_data_grads_norm = 3.0511
	old_data_grads_norm = 3.5236
	sim_grads_norm = 0.2699
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1599
	data_grads_norm = 2.0834
	new_data_grads_norm = 3.0998
	old_data_grads_norm = 2.4160
	sim_grads_norm = 0.2135
-- Starting training on experience 116 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2412
	data_grads_norm = 2.4210
	new_data_grads_norm = 3.0483
	old_data_grads_norm = 3.1123
	sim_grads_norm = 0.2647
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3714
	data_grads_norm = 2.4643
	new_data_grads_norm = 3.4358
	old_data_grads_norm = 3.0985
	sim_grads_norm = 0.1835
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1707
	data_grads_norm = 1.8630
	new_data_grads_norm = 2.9033
	old_data_grads_norm = 2.3590
	sim_grads_norm = -0.1105
-- Starting training on experience 117 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9011
	data_grads_norm = 1.8624
	new_data_grads_norm = 1.9939
	old_data_grads_norm = 3.6145
	sim_grads_norm = -0.1732
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9581
	data_grads_norm = 1.3412
	new_data_grads_norm = 1.9833
	old_data_grads_norm = 2.2491
	sim_grads_norm = -0.1127
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0026
	data_grads_norm = 1.6211
	new_data_grads_norm = 2.0498
	old_data_grads_norm = 2.1679
	sim_grads_norm = 0.3329
-- Starting training on experience 118 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9351
	data_grads_norm = 2.0807
	new_data_grads_norm = 2.6933
	old_data_grads_norm = 2.7320
	sim_grads_norm = 0.0226
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2505
	data_grads_norm = 2.2464
	new_data_grads_norm = 2.5320
	old_data_grads_norm = 3.4422
	sim_grads_norm = 0.0979
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0545
	data_grads_norm = 2.3687
	new_data_grads_norm = 4.0156
	old_data_grads_norm = 2.8535
	sim_grads_norm = 0.1546
-- Starting training on experience 119 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3767
	data_grads_norm = 2.9591
	new_data_grads_norm = 3.6051
	old_data_grads_norm = 4.4082
	sim_grads_norm = 0.2029
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0714
	data_grads_norm = 1.7514
	new_data_grads_norm = 2.1179
	old_data_grads_norm = 2.3914
	sim_grads_norm = 0.1792
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2752
	data_grads_norm = 2.0167
	new_data_grads_norm = 2.0794
	old_data_grads_norm = 3.9985
	sim_grads_norm = -0.0623
-- Starting training on experience 120 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3191
	data_grads_norm = 2.4507
	new_data_grads_norm = 2.9464
	old_data_grads_norm = 4.4216
	sim_grads_norm = 0.1094
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3120
	data_grads_norm = 1.9338
	new_data_grads_norm = 2.9546
	old_data_grads_norm = 2.3368
	sim_grads_norm = -0.0032
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4283
	data_grads_norm = 2.2245
	new_data_grads_norm = 2.8326
	old_data_grads_norm = 3.2908
	sim_grads_norm = 0.0922
-- Starting training on experience 121 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0845
	data_grads_norm = 1.4734
	new_data_grads_norm = 2.3938
	old_data_grads_norm = 1.8245
	sim_grads_norm = 0.0803
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2013
	data_grads_norm = 1.6788
	new_data_grads_norm = 2.3656
	old_data_grads_norm = 3.5324
	sim_grads_norm = 0.0146
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4013
	data_grads_norm = 2.2394
	new_data_grads_norm = 2.6944
	old_data_grads_norm = 3.0990
	sim_grads_norm = 0.1463
-- Starting training on experience 122 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4106
	data_grads_norm = 2.0745
	new_data_grads_norm = 2.9951
	old_data_grads_norm = 2.6629
	sim_grads_norm = 0.2849
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0451
	data_grads_norm = 1.9455
	new_data_grads_norm = 2.4786
	old_data_grads_norm = 2.6835
	sim_grads_norm = 0.0464
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4944
	data_grads_norm = 2.3184
	new_data_grads_norm = 2.5283
	old_data_grads_norm = 3.2437
	sim_grads_norm = 0.3140
-- Starting training on experience 123 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2701
	data_grads_norm = 1.5147
	new_data_grads_norm = 2.6556
	old_data_grads_norm = 2.3229
	sim_grads_norm = 0.0250
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1899
	data_grads_norm = 1.7020
	new_data_grads_norm = 2.6241
	old_data_grads_norm = 1.9384
	sim_grads_norm = -0.0503
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3479
	data_grads_norm = 2.0139
	new_data_grads_norm = 2.3356
	old_data_grads_norm = 2.6315
	sim_grads_norm = 0.3703
-- Starting training on experience 124 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2028
	data_grads_norm = 1.5671
	new_data_grads_norm = 2.0801
	old_data_grads_norm = 2.2934
	sim_grads_norm = 0.0571
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0188
	data_grads_norm = 0.8840
	new_data_grads_norm = 1.7795
	old_data_grads_norm = 1.3494
	sim_grads_norm = -0.0939
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2084
	data_grads_norm = 1.6536
	new_data_grads_norm = 2.2673
	old_data_grads_norm = 1.5965
	sim_grads_norm = 0.0990
-- Starting training on experience 125 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3569
	data_grads_norm = 2.1096
	new_data_grads_norm = 2.6803
	old_data_grads_norm = 2.9358
	sim_grads_norm = 0.3322
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1669
	data_grads_norm = 1.3953
	new_data_grads_norm = 2.4841
	old_data_grads_norm = 2.1790
	sim_grads_norm = -0.0919
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0734
	data_grads_norm = 1.7233
	new_data_grads_norm = 3.0604
	old_data_grads_norm = 3.0282
	sim_grads_norm = 0.0098
-- Starting training on experience 126 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0655
	data_grads_norm = 1.2306
	new_data_grads_norm = 1.5811
	old_data_grads_norm = 1.5419
	sim_grads_norm = 0.0348
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9807
	data_grads_norm = 1.2492
	new_data_grads_norm = 1.5084
	old_data_grads_norm = 2.0972
	sim_grads_norm = 0.0756
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0657
	data_grads_norm = 1.2907
	new_data_grads_norm = 2.0112
	old_data_grads_norm = 1.7687
	sim_grads_norm = -0.1045
-- Starting training on experience 127 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6232
	data_grads_norm = 2.7576
	new_data_grads_norm = 2.7342
	old_data_grads_norm = 4.3197
	sim_grads_norm = 0.1884
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1217
	data_grads_norm = 1.1972
	new_data_grads_norm = 1.5495
	old_data_grads_norm = 1.5112
	sim_grads_norm = 0.1992
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0401
	data_grads_norm = 1.1489
	new_data_grads_norm = 1.5739
	old_data_grads_norm = 2.1935
	sim_grads_norm = -0.1681
-- Starting training on experience 128 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3014
	data_grads_norm = 1.9617
	new_data_grads_norm = 3.4884
	old_data_grads_norm = 2.0226
	sim_grads_norm = 0.0725
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1448
	data_grads_norm = 1.4093
	new_data_grads_norm = 4.0067
	old_data_grads_norm = 2.0096
	sim_grads_norm = -0.5272
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5577
	data_grads_norm = 3.1407
	new_data_grads_norm = 3.7346
	old_data_grads_norm = 4.0428
	sim_grads_norm = 0.5831
-- Starting training on experience 129 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1233
	data_grads_norm = 2.2204
	new_data_grads_norm = 2.1820
	old_data_grads_norm = 2.7634
	sim_grads_norm = 0.4795
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8735
	data_grads_norm = 1.3168
	new_data_grads_norm = 1.4000
	old_data_grads_norm = 2.1406
	sim_grads_norm = 0.0617
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0061
	data_grads_norm = 1.5553
	new_data_grads_norm = 1.5932
	old_data_grads_norm = 2.4125
	sim_grads_norm = 0.1591
-- Starting training on experience 130 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1290
	data_grads_norm = 1.2322
	new_data_grads_norm = 1.4541
	old_data_grads_norm = 2.8973
	sim_grads_norm = -0.1679
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2983
	data_grads_norm = 1.7893
	new_data_grads_norm = 1.7436
	old_data_grads_norm = 3.2565
	sim_grads_norm = 0.4793
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9999
	data_grads_norm = 1.2487
	new_data_grads_norm = 1.4155
	old_data_grads_norm = 2.6163
	sim_grads_norm = 0.1637
-- Starting training on experience 131 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0614
	data_grads_norm = 0.9580
	new_data_grads_norm = 2.1513
	old_data_grads_norm = 1.1971
	sim_grads_norm = -0.0830
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2205
	data_grads_norm = 1.9518
	new_data_grads_norm = 2.4813
	old_data_grads_norm = 2.0763
	sim_grads_norm = 0.0886
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1164
	data_grads_norm = 1.5107
	new_data_grads_norm = 2.4654
	old_data_grads_norm = 2.0923
	sim_grads_norm = 0.1661
-- Starting training on experience 132 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1164
	data_grads_norm = 1.8665
	new_data_grads_norm = 2.6558
	old_data_grads_norm = 3.0331
	sim_grads_norm = -0.0836
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3853
	data_grads_norm = 1.6473
	new_data_grads_norm = 3.3361
	old_data_grads_norm = 1.9106
	sim_grads_norm = -0.0722
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3248
	data_grads_norm = 2.1136
	new_data_grads_norm = 3.2226
	old_data_grads_norm = 2.3656
	sim_grads_norm = -0.0488
-- Starting training on experience 133 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0630
	data_grads_norm = 2.8106
	new_data_grads_norm = 5.2835
	old_data_grads_norm = 2.7832
	sim_grads_norm = 0.2349
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0278
	data_grads_norm = 1.7752
	new_data_grads_norm = 3.5345
	old_data_grads_norm = 2.2865
	sim_grads_norm = 0.1439
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8448
	data_grads_norm = 1.3726
	new_data_grads_norm = 2.0551
	old_data_grads_norm = 2.3836
	sim_grads_norm = -0.2424
-- Starting training on experience 134 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2092
	data_grads_norm = 1.9421
	new_data_grads_norm = 2.9983
	old_data_grads_norm = 2.7670
	sim_grads_norm = -0.1159
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1694
	data_grads_norm = 1.6137
	new_data_grads_norm = 3.0638
	old_data_grads_norm = 1.7110
	sim_grads_norm = 0.2890
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0349
	data_grads_norm = 1.8388
	new_data_grads_norm = 2.9246
	old_data_grads_norm = 2.7229
	sim_grads_norm = 0.0543
-- Starting training on experience 135 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4820
	data_grads_norm = 3.2121
	new_data_grads_norm = 4.6967
	old_data_grads_norm = 3.6072
	sim_grads_norm = 0.5780
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1187
	data_grads_norm = 2.1396
	new_data_grads_norm = 2.1144
	old_data_grads_norm = 3.6111
	sim_grads_norm = 0.1333
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1493
	data_grads_norm = 1.7534
	new_data_grads_norm = 2.2100
	old_data_grads_norm = 2.8342
	sim_grads_norm = 0.1659
-- Starting training on experience 136 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2201
	data_grads_norm = 2.3998
	new_data_grads_norm = 3.3510
	old_data_grads_norm = 2.9142
	sim_grads_norm = 0.2422
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1499
	data_grads_norm = 2.1026
	new_data_grads_norm = 2.9086
	old_data_grads_norm = 1.5126
	sim_grads_norm = 0.0934
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2610
	data_grads_norm = 2.2663
	new_data_grads_norm = 2.8717
	old_data_grads_norm = 3.3154
	sim_grads_norm = 0.0618
-- Starting training on experience 137 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2366
	data_grads_norm = 2.4516
	new_data_grads_norm = 3.3898
	old_data_grads_norm = 2.8596
	sim_grads_norm = 0.2082
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2538
	data_grads_norm = 2.2835
	new_data_grads_norm = 3.2709
	old_data_grads_norm = 3.9139
	sim_grads_norm = 0.0257
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6494
	data_grads_norm = 2.8549
	new_data_grads_norm = 3.2129
	old_data_grads_norm = 3.4511
	sim_grads_norm = 0.1106
-- Starting training on experience 138 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0816
	data_grads_norm = 1.5563
	new_data_grads_norm = 1.3894
	old_data_grads_norm = 2.8528
	sim_grads_norm = 0.0151
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8579
	data_grads_norm = 1.2685
	new_data_grads_norm = 1.8717
	old_data_grads_norm = 2.1144
	sim_grads_norm = -0.1539
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1497
	data_grads_norm = 1.4382
	new_data_grads_norm = 2.2871
	old_data_grads_norm = 2.8853
	sim_grads_norm = -0.2262
-- Starting training on experience 139 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0862
	data_grads_norm = 2.0668
	new_data_grads_norm = 2.3922
	old_data_grads_norm = 2.8162
	sim_grads_norm = 0.0051
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2660
	data_grads_norm = 2.0047
	new_data_grads_norm = 2.9385
	old_data_grads_norm = 2.3872
	sim_grads_norm = 0.3415
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9517
	data_grads_norm = 1.5950
	new_data_grads_norm = 2.5375
	old_data_grads_norm = 1.7691
	sim_grads_norm = -0.0580
-- Starting training on experience 140 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0478
	data_grads_norm = 2.1535
	new_data_grads_norm = 3.1343
	old_data_grads_norm = 2.4975
	sim_grads_norm = 0.0693
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2376
	data_grads_norm = 2.5628
	new_data_grads_norm = 2.4653
	old_data_grads_norm = 4.4116
	sim_grads_norm = 0.1827
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4408
	data_grads_norm = 2.2562
	new_data_grads_norm = 2.6502
	old_data_grads_norm = 3.8317
	sim_grads_norm = 0.1363
-- Starting training on experience 141 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3196
	data_grads_norm = 2.4462
	new_data_grads_norm = 3.9627
	old_data_grads_norm = 3.0010
	sim_grads_norm = 0.0451
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3593
	data_grads_norm = 2.3201
	new_data_grads_norm = 3.9460
	old_data_grads_norm = 3.4889
	sim_grads_norm = -0.1047
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3868
	data_grads_norm = 2.6160
	new_data_grads_norm = 3.9361
	old_data_grads_norm = 2.6311
	sim_grads_norm = 0.1668
-- Starting training on experience 142 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4345
	data_grads_norm = 2.1845
	new_data_grads_norm = 3.4951
	old_data_grads_norm = 2.3222
	sim_grads_norm = 0.1030
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4943
	data_grads_norm = 2.3723
	new_data_grads_norm = 3.2592
	old_data_grads_norm = 2.9201
	sim_grads_norm = 0.3335
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3702
	data_grads_norm = 2.0871
	new_data_grads_norm = 3.1590
	old_data_grads_norm = 2.2613
	sim_grads_norm = 0.3168
-- Starting training on experience 143 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0684
	data_grads_norm = 1.7145
	new_data_grads_norm = 1.7167
	old_data_grads_norm = 2.5717
	sim_grads_norm = 0.2391
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0198
	data_grads_norm = 1.4956
	new_data_grads_norm = 1.8563
	old_data_grads_norm = 1.9981
	sim_grads_norm = 0.2516
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9819
	data_grads_norm = 1.7170
	new_data_grads_norm = 1.8794
	old_data_grads_norm = 2.5302
	sim_grads_norm = -0.0033
-- Starting training on experience 144 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0913
	data_grads_norm = 1.4995
	new_data_grads_norm = 2.0892
	old_data_grads_norm = 2.2786
	sim_grads_norm = 0.0531
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1850
	data_grads_norm = 1.7856
	new_data_grads_norm = 2.6848
	old_data_grads_norm = 2.6412
	sim_grads_norm = -0.0113
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1884
	data_grads_norm = 1.8542
	new_data_grads_norm = 2.7493
	old_data_grads_norm = 2.6048
	sim_grads_norm = 0.0485
-- Starting training on experience 145 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9042
	data_grads_norm = 1.1695
	new_data_grads_norm = 1.7766
	old_data_grads_norm = 2.3830
	sim_grads_norm = -0.2333
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1560
	data_grads_norm = 1.6841
	new_data_grads_norm = 2.7237
	old_data_grads_norm = 2.2751
	sim_grads_norm = -0.0551
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2479
	data_grads_norm = 2.5124
	new_data_grads_norm = 2.6362
	old_data_grads_norm = 3.2615
	sim_grads_norm = 0.4635
-- Starting training on experience 146 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0294
	data_grads_norm = 1.9465
	new_data_grads_norm = 2.3402
	old_data_grads_norm = 2.2557
	sim_grads_norm = 0.5101
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1346
	data_grads_norm = 1.6323
	new_data_grads_norm = 1.9215
	old_data_grads_norm = 2.9755
	sim_grads_norm = -0.0118
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1303
	data_grads_norm = 1.8720
	new_data_grads_norm = 2.9569
	old_data_grads_norm = 2.6107
	sim_grads_norm = 0.0403
-- Starting training on experience 147 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0258
	data_grads_norm = 1.9149
	new_data_grads_norm = 2.2827
	old_data_grads_norm = 2.5000
	sim_grads_norm = 0.1427
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1297
	data_grads_norm = 2.0283
	new_data_grads_norm = 2.9775
	old_data_grads_norm = 2.6888
	sim_grads_norm = 0.0919
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2758
	data_grads_norm = 2.3320
	new_data_grads_norm = 3.6283
	old_data_grads_norm = 2.7242
	sim_grads_norm = 0.1982
-- Starting training on experience 148 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8245
	data_grads_norm = 1.8036
	new_data_grads_norm = 3.5948
	old_data_grads_norm = 2.5008
	sim_grads_norm = -0.2382
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9352
	data_grads_norm = 2.1395
	new_data_grads_norm = 4.2662
	old_data_grads_norm = 1.4690
	sim_grads_norm = 0.1647
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9608
	data_grads_norm = 1.6845
	new_data_grads_norm = 4.0240
	old_data_grads_norm = 2.7695
	sim_grads_norm = -0.1408
-- Starting training on experience 149 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3680
	data_grads_norm = 2.4136
	new_data_grads_norm = 3.2381
	old_data_grads_norm = 3.3141
	sim_grads_norm = 0.1011
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0175
	data_grads_norm = 1.9397
	new_data_grads_norm = 2.9356
	old_data_grads_norm = 2.1625
	sim_grads_norm = 0.3672
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0457
	data_grads_norm = 1.9865
	new_data_grads_norm = 3.0378
	old_data_grads_norm = 2.9083
	sim_grads_norm = 0.1931
-- Starting training on experience 150 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1801
	data_grads_norm = 1.7964
	new_data_grads_norm = 2.2389
	old_data_grads_norm = 2.5450
	sim_grads_norm = 0.1940
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1613
	data_grads_norm = 2.5453
	new_data_grads_norm = 2.5231
	old_data_grads_norm = 4.8664
	sim_grads_norm = 0.1780
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5069
	data_grads_norm = 2.2611
	new_data_grads_norm = 2.3787
	old_data_grads_norm = 3.7303
	sim_grads_norm = 0.2640
-- Starting training on experience 151 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1981
	data_grads_norm = 2.1891
	new_data_grads_norm = 2.3215
	old_data_grads_norm = 3.2702
	sim_grads_norm = 0.1344
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2059
	data_grads_norm = 1.7254
	new_data_grads_norm = 1.9662
	old_data_grads_norm = 3.3817
	sim_grads_norm = -0.0527
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2251
	data_grads_norm = 2.0846
	new_data_grads_norm = 2.5320
	old_data_grads_norm = 2.7699
	sim_grads_norm = 0.2474
-- Starting training on experience 152 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2998
	data_grads_norm = 1.6845
	new_data_grads_norm = 1.9329
	old_data_grads_norm = 2.7058
	sim_grads_norm = 0.0428
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5201
	data_grads_norm = 1.5336
	new_data_grads_norm = 2.1311
	old_data_grads_norm = 2.3750
	sim_grads_norm = -0.0222
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1860
	data_grads_norm = 1.7812
	new_data_grads_norm = 1.9782
	old_data_grads_norm = 2.5076
	sim_grads_norm = 0.3462
-- Starting training on experience 153 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2994
	data_grads_norm = 2.1971
	new_data_grads_norm = 2.4996
	old_data_grads_norm = 2.6794
	sim_grads_norm = 0.3514
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1326
	data_grads_norm = 1.5157
	new_data_grads_norm = 1.8497
	old_data_grads_norm = 2.7717
	sim_grads_norm = -0.0918
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2252
	data_grads_norm = 2.1669
	new_data_grads_norm = 2.6523
	old_data_grads_norm = 4.2777
	sim_grads_norm = 0.2633
-- Starting training on experience 154 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2179
	data_grads_norm = 2.4002
	new_data_grads_norm = 3.0993
	old_data_grads_norm = 2.3686
	sim_grads_norm = 0.5909
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9960
	data_grads_norm = 1.3471
	new_data_grads_norm = 2.0358
	old_data_grads_norm = 2.5523
	sim_grads_norm = -0.2398
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0134
	data_grads_norm = 1.9409
	new_data_grads_norm = 2.9664
	old_data_grads_norm = 2.4189
	sim_grads_norm = -0.0226
-- Starting training on experience 155 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3003
	data_grads_norm = 2.2547
	new_data_grads_norm = 3.0263
	old_data_grads_norm = 2.7457
	sim_grads_norm = 0.1503
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2861
	data_grads_norm = 2.1313
	new_data_grads_norm = 3.5940
	old_data_grads_norm = 2.2072
	sim_grads_norm = 0.2002
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3341
	data_grads_norm = 2.1732
	new_data_grads_norm = 2.8791
	old_data_grads_norm = 3.5632
	sim_grads_norm = 0.1622
-- Starting training on experience 156 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9999
	data_grads_norm = 2.1287
	new_data_grads_norm = 4.3504
	old_data_grads_norm = 1.5750
	sim_grads_norm = 0.0571
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4885
	data_grads_norm = 4.3004
	new_data_grads_norm = 4.9785
	old_data_grads_norm = 4.0022
	sim_grads_norm = 0.1336
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9528
	data_grads_norm = 1.3827
	new_data_grads_norm = 2.7084
	old_data_grads_norm = 1.9171
	sim_grads_norm = -0.0282
-- Starting training on experience 157 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2908
	data_grads_norm = 1.6104
	new_data_grads_norm = 2.5849
	old_data_grads_norm = 1.9918
	sim_grads_norm = -0.0920
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2093
	data_grads_norm = 1.4222
	new_data_grads_norm = 2.6729
	old_data_grads_norm = 1.4651
	sim_grads_norm = 0.0573
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3437
	data_grads_norm = 2.4733
	new_data_grads_norm = 3.7246
	old_data_grads_norm = 2.5386
	sim_grads_norm = 0.1178
-- Starting training on experience 158 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0052
	data_grads_norm = 1.9354
	new_data_grads_norm = 2.5248
	old_data_grads_norm = 2.4858
	sim_grads_norm = 0.1646
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0267
	data_grads_norm = 1.8335
	new_data_grads_norm = 2.5354
	old_data_grads_norm = 2.6517
	sim_grads_norm = 0.1625
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0766
	data_grads_norm = 1.5772
	new_data_grads_norm = 3.9043
	old_data_grads_norm = 2.8266
	sim_grads_norm = -0.2689
-- Starting training on experience 159 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9779
	data_grads_norm = 1.7288
	new_data_grads_norm = 2.2745
	old_data_grads_norm = 2.5946
	sim_grads_norm = 0.2086
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9632
	data_grads_norm = 1.6892
	new_data_grads_norm = 2.0522
	old_data_grads_norm = 2.4720
	sim_grads_norm = 0.1675
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1503
	data_grads_norm = 1.6859
	new_data_grads_norm = 1.8873
	old_data_grads_norm = 2.5913
	sim_grads_norm = -0.0279
-- Starting training on experience 160 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1497
	data_grads_norm = 1.4707
	new_data_grads_norm = 2.1693
	old_data_grads_norm = 1.9631
	sim_grads_norm = -0.1391
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3259
	data_grads_norm = 1.9954
	new_data_grads_norm = 2.3968
	old_data_grads_norm = 2.8957
	sim_grads_norm = 0.2603
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0122
	data_grads_norm = 1.4101
	new_data_grads_norm = 2.2026
	old_data_grads_norm = 3.0217
	sim_grads_norm = 0.2364
-- Starting training on experience 161 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0984
	data_grads_norm = 1.6663
	new_data_grads_norm = 2.2164
	old_data_grads_norm = 2.6468
	sim_grads_norm = 0.1229
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0363
	data_grads_norm = 1.9185
	new_data_grads_norm = 2.0506
	old_data_grads_norm = 3.0717
	sim_grads_norm = 0.1211
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1905
	data_grads_norm = 2.0825
	new_data_grads_norm = 2.1202
	old_data_grads_norm = 3.1173
	sim_grads_norm = 0.2676
-- Starting training on experience 162 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9996
	data_grads_norm = 1.2914
	new_data_grads_norm = 1.9163
	old_data_grads_norm = 1.7038
	sim_grads_norm = 0.0728
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0875
	data_grads_norm = 1.3550
	new_data_grads_norm = 1.7242
	old_data_grads_norm = 1.9604
	sim_grads_norm = 0.0554
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2242
	data_grads_norm = 1.6688
	new_data_grads_norm = 2.4432
	old_data_grads_norm = 2.5490
	sim_grads_norm = 0.0786
-- Starting training on experience 163 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1445
	data_grads_norm = 2.2374
	new_data_grads_norm = 2.0590
	old_data_grads_norm = 3.8128
	sim_grads_norm = 0.1180
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0332
	data_grads_norm = 2.0491
	new_data_grads_norm = 2.4972
	old_data_grads_norm = 3.2437
	sim_grads_norm = 0.1493
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1092
	data_grads_norm = 1.7627
	new_data_grads_norm = 2.3111
	old_data_grads_norm = 1.7096
	sim_grads_norm = 0.5054
-- Starting training on experience 164 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0374
	data_grads_norm = 1.3183
	new_data_grads_norm = 2.2679
	old_data_grads_norm = 1.6524
	sim_grads_norm = 0.0064
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0557
	data_grads_norm = 1.5703
	new_data_grads_norm = 1.9827
	old_data_grads_norm = 2.4191
	sim_grads_norm = 0.0427
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1989
	data_grads_norm = 1.7893
	new_data_grads_norm = 2.1309
	old_data_grads_norm = 3.2032
	sim_grads_norm = 0.0128
-- Starting training on experience 165 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9355
	data_grads_norm = 1.2342
	new_data_grads_norm = 1.8119
	old_data_grads_norm = 2.1668
	sim_grads_norm = -0.0391
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0334
	data_grads_norm = 1.8893
	new_data_grads_norm = 2.1741
	old_data_grads_norm = 2.1853
	sim_grads_norm = 0.2385
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1685
	data_grads_norm = 1.2462
	new_data_grads_norm = 1.8681
	old_data_grads_norm = 2.2550
	sim_grads_norm = -0.0094
-- Starting training on experience 166 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1749
	data_grads_norm = 1.3304
	new_data_grads_norm = 2.5333
	old_data_grads_norm = 2.6340
	sim_grads_norm = -0.3840
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2573
	data_grads_norm = 1.9251
	new_data_grads_norm = 3.3535
	old_data_grads_norm = 1.7543
	sim_grads_norm = 0.0768
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1183
	data_grads_norm = 1.5978
	new_data_grads_norm = 3.3617
	old_data_grads_norm = 1.9911
	sim_grads_norm = -0.3760
-- Starting training on experience 167 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0823
	data_grads_norm = 3.8196
	new_data_grads_norm = 6.8901
	old_data_grads_norm = 3.9511
	sim_grads_norm = 0.4282
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2509
	data_grads_norm = 2.0225
	new_data_grads_norm = 4.5166
	old_data_grads_norm = 2.3558
	sim_grads_norm = -0.2293
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5380
	data_grads_norm = 3.2007
	new_data_grads_norm = 4.6950
	old_data_grads_norm = 3.5777
	sim_grads_norm = 0.1974
-- Starting training on experience 168 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3697
	data_grads_norm = 2.1792
	new_data_grads_norm = 3.0315
	old_data_grads_norm = 2.1103
	sim_grads_norm = 0.1060
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5119
	data_grads_norm = 3.3075
	new_data_grads_norm = 2.9991
	old_data_grads_norm = 4.2556
	sim_grads_norm = 0.3563
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2903
	data_grads_norm = 2.0889
	new_data_grads_norm = 2.6799
	old_data_grads_norm = 2.8410
	sim_grads_norm = -0.0577
-- Starting training on experience 169 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0451
	data_grads_norm = 1.5263
	new_data_grads_norm = 2.8040
	old_data_grads_norm = 2.2013
	sim_grads_norm = -0.0631
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1692
	data_grads_norm = 1.7968
	new_data_grads_norm = 2.4973
	old_data_grads_norm = 3.1020
	sim_grads_norm = -0.2184
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4012
	data_grads_norm = 2.6351
	new_data_grads_norm = 3.8330
	old_data_grads_norm = 2.7600
	sim_grads_norm = 0.4076
-- Starting training on experience 170 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4889
	data_grads_norm = 2.2169
	new_data_grads_norm = 3.6281
	old_data_grads_norm = 2.4487
	sim_grads_norm = 0.0664
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1125
	data_grads_norm = 1.8963
	new_data_grads_norm = 3.3688
	old_data_grads_norm = 1.8487
	sim_grads_norm = 0.1618
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2406
	data_grads_norm = 2.1581
	new_data_grads_norm = 3.8117
	old_data_grads_norm = 2.4001
	sim_grads_norm = 0.0186
-- Starting training on experience 171 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8364
	data_grads_norm = 1.2410
	new_data_grads_norm = 2.5158
	old_data_grads_norm = 1.9003
	sim_grads_norm = -0.1823
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9742
	data_grads_norm = 1.5136
	new_data_grads_norm = 2.6654
	old_data_grads_norm = 1.8703
	sim_grads_norm = 0.0558
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1516
	data_grads_norm = 1.7487
	new_data_grads_norm = 2.7010
	old_data_grads_norm = 2.5475
	sim_grads_norm = -0.0210
-- Starting training on experience 172 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9770
	data_grads_norm = 1.4400
	new_data_grads_norm = 3.0559
	old_data_grads_norm = 2.0331
	sim_grads_norm = 0.1348
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0619
	data_grads_norm = 1.7394
	new_data_grads_norm = 3.0304
	old_data_grads_norm = 2.0111
	sim_grads_norm = 0.2662
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0342
	data_grads_norm = 1.5878
	new_data_grads_norm = 2.8224
	old_data_grads_norm = 2.3144
	sim_grads_norm = 0.1923
-- Starting training on experience 173 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1938
	data_grads_norm = 2.3968
	new_data_grads_norm = 3.9066
	old_data_grads_norm = 1.9105
	sim_grads_norm = 0.3492
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1713
	data_grads_norm = 2.7769
	new_data_grads_norm = 3.8871
	old_data_grads_norm = 3.7326
	sim_grads_norm = 0.2254
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8203
	data_grads_norm = 1.6067
	new_data_grads_norm = 2.9801
	old_data_grads_norm = 2.3139
	sim_grads_norm = 0.1437
-- Starting training on experience 174 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5822
	data_grads_norm = 3.5442
	new_data_grads_norm = 5.5091
	old_data_grads_norm = 3.6739
	sim_grads_norm = 0.2924
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4951
	data_grads_norm = 2.5126
	new_data_grads_norm = 3.9232
	old_data_grads_norm = 3.2871
	sim_grads_norm = 0.0749
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2724
	data_grads_norm = 2.6728
	new_data_grads_norm = 5.1346
	old_data_grads_norm = 2.6882
	sim_grads_norm = 0.1205
-- Starting training on experience 175 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7656
	data_grads_norm = 3.3498
	new_data_grads_norm = 3.8081
	old_data_grads_norm = 4.2734
	sim_grads_norm = 0.3545
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2400
	data_grads_norm = 1.7185
	new_data_grads_norm = 2.3026
	old_data_grads_norm = 2.0995
	sim_grads_norm = 0.3304
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9763
	data_grads_norm = 1.4761
	new_data_grads_norm = 1.9343
	old_data_grads_norm = 2.0653
	sim_grads_norm = -0.0117
-- Starting training on experience 176 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1004
	data_grads_norm = 1.8013
	new_data_grads_norm = 2.8068
	old_data_grads_norm = 2.2283
	sim_grads_norm = 0.0768
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9976
	data_grads_norm = 1.8864
	new_data_grads_norm = 2.5950
	old_data_grads_norm = 3.5112
	sim_grads_norm = -0.1899
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3177
	data_grads_norm = 1.9902
	new_data_grads_norm = 3.0148
	old_data_grads_norm = 2.2641
	sim_grads_norm = 0.0213
-- Starting training on experience 177 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0864
	data_grads_norm = 2.2330
	new_data_grads_norm = 2.9383
	old_data_grads_norm = 2.7377
	sim_grads_norm = 0.2495
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9823
	data_grads_norm = 1.5569
	new_data_grads_norm = 2.1913
	old_data_grads_norm = 3.4749
	sim_grads_norm = -0.0821
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1537
	data_grads_norm = 1.9797
	new_data_grads_norm = 2.1152
	old_data_grads_norm = 3.3486
	sim_grads_norm = 0.2378
-- Starting training on experience 178 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2877
	data_grads_norm = 1.9685
	new_data_grads_norm = 2.0952
	old_data_grads_norm = 2.7812
	sim_grads_norm = 0.3787
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3791
	data_grads_norm = 2.6027
	new_data_grads_norm = 2.1152
	old_data_grads_norm = 4.1533
	sim_grads_norm = 0.0465
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3299
	data_grads_norm = 2.2930
	new_data_grads_norm = 2.1945
	old_data_grads_norm = 5.9977
	sim_grads_norm = 0.3008
-- Starting training on experience 179 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3556
	data_grads_norm = 2.9162
	new_data_grads_norm = 4.2748
	old_data_grads_norm = 3.5114
	sim_grads_norm = 0.3030
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1411
	data_grads_norm = 2.1992
	new_data_grads_norm = 3.6740
	old_data_grads_norm = 2.7788
	sim_grads_norm = -0.0157
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2088
	data_grads_norm = 2.4980
	new_data_grads_norm = 4.1014
	old_data_grads_norm = 3.1833
	sim_grads_norm = -0.1296
-- Starting training on experience 180 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0898
	data_grads_norm = 2.2921
	new_data_grads_norm = 2.7944
	old_data_grads_norm = 2.7096
	sim_grads_norm = 0.4101
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0532
	data_grads_norm = 1.7168
	new_data_grads_norm = 1.9487
	old_data_grads_norm = 3.2582
	sim_grads_norm = 0.2448
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7362
	data_grads_norm = 1.3302
	new_data_grads_norm = 2.0027
	old_data_grads_norm = 1.7574
	sim_grads_norm = 0.1290
-- Starting training on experience 181 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1668
	data_grads_norm = 1.8660
	new_data_grads_norm = 2.8201
	old_data_grads_norm = 2.2391
	sim_grads_norm = 0.1806
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2242
	data_grads_norm = 2.0307
	new_data_grads_norm = 2.5652
	old_data_grads_norm = 2.6795
	sim_grads_norm = 0.1714
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1699
	data_grads_norm = 1.7222
	new_data_grads_norm = 2.3515
	old_data_grads_norm = 2.0493
	sim_grads_norm = 0.2099
-- Starting training on experience 182 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2922
	data_grads_norm = 2.1768
	new_data_grads_norm = 2.1261
	old_data_grads_norm = 4.5933
	sim_grads_norm = 0.1909
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0887
	data_grads_norm = 1.5972
	new_data_grads_norm = 1.8602
	old_data_grads_norm = 1.9876
	sim_grads_norm = 0.0869
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3640
	data_grads_norm = 2.0107
	new_data_grads_norm = 1.8745
	old_data_grads_norm = 3.8949
	sim_grads_norm = 0.3927
-- Starting training on experience 183 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0694
	data_grads_norm = 1.4360
	new_data_grads_norm = 1.9798
	old_data_grads_norm = 1.7196
	sim_grads_norm = 0.0444
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0000
	data_grads_norm = 1.6064
	new_data_grads_norm = 2.4809
	old_data_grads_norm = 2.4367
	sim_grads_norm = 0.0721
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9609
	data_grads_norm = 1.7611
	new_data_grads_norm = 1.7815
	old_data_grads_norm = 2.3194
	sim_grads_norm = 0.0537
-- Starting training on experience 184 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1264
	data_grads_norm = 2.3329
	new_data_grads_norm = 2.8280
	old_data_grads_norm = 2.8273
	sim_grads_norm = 0.3506
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8671
	data_grads_norm = 1.4722
	new_data_grads_norm = 2.2274
	old_data_grads_norm = 1.9403
	sim_grads_norm = -0.0309
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9451
	data_grads_norm = 1.4866
	new_data_grads_norm = 1.9329
	old_data_grads_norm = 2.2753
	sim_grads_norm = -0.1605
-- Starting training on experience 185 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2160
	data_grads_norm = 1.7833
	new_data_grads_norm = 3.4646
	old_data_grads_norm = 2.1779
	sim_grads_norm = 0.0053
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0938
	data_grads_norm = 1.9004
	new_data_grads_norm = 3.2588
	old_data_grads_norm = 1.7643
	sim_grads_norm = 0.4338
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8700
	data_grads_norm = 1.9911
	new_data_grads_norm = 3.0469
	old_data_grads_norm = 2.3182
	sim_grads_norm = 0.2614
-- Starting training on experience 186 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1911
	data_grads_norm = 2.2222
	new_data_grads_norm = 2.9722
	old_data_grads_norm = 3.4651
	sim_grads_norm = -0.0042
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1866
	data_grads_norm = 1.9484
	new_data_grads_norm = 3.0892
	old_data_grads_norm = 2.5903
	sim_grads_norm = 0.2261
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0250
	data_grads_norm = 1.6567
	new_data_grads_norm = 2.6637
	old_data_grads_norm = 1.8862
	sim_grads_norm = 0.2167
-- Starting training on experience 187 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9408
	data_grads_norm = 1.9558
	new_data_grads_norm = 3.1241
	old_data_grads_norm = 2.0064
	sim_grads_norm = 0.0931
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1860
	data_grads_norm = 2.6878
	new_data_grads_norm = 3.2779
	old_data_grads_norm = 2.3998
	sim_grads_norm = 0.2163
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8232
	data_grads_norm = 2.4132
	new_data_grads_norm = 3.1549
	old_data_grads_norm = 2.7380
	sim_grads_norm = 0.2897
-- Starting training on experience 188 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7978
	data_grads_norm = 1.3466
	new_data_grads_norm = 1.8649
	old_data_grads_norm = 2.3594
	sim_grads_norm = -0.1477
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9668
	data_grads_norm = 1.7432
	new_data_grads_norm = 2.4508
	old_data_grads_norm = 2.2637
	sim_grads_norm = 0.2197
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1382
	data_grads_norm = 1.6924
	new_data_grads_norm = 2.5598
	old_data_grads_norm = 2.1309
	sim_grads_norm = 0.1212
-- Starting training on experience 189 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7963
	data_grads_norm = 1.4884
	new_data_grads_norm = 1.7014
	old_data_grads_norm = 2.3298
	sim_grads_norm = 0.1588
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8491
	data_grads_norm = 2.2143
	new_data_grads_norm = 1.9444
	old_data_grads_norm = 3.3371
	sim_grads_norm = -0.0295
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1500
	data_grads_norm = 2.3453
	new_data_grads_norm = 2.3024
	old_data_grads_norm = 4.0104
	sim_grads_norm = 0.1456
-- Starting training on experience 190 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5228
	data_grads_norm = 2.5200
	new_data_grads_norm = 3.3540
	old_data_grads_norm = 4.0026
	sim_grads_norm = 0.0116
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1705
	data_grads_norm = 2.0232
	new_data_grads_norm = 3.3578
	old_data_grads_norm = 2.8345
	sim_grads_norm = 0.0263
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2119
	data_grads_norm = 2.2603
	new_data_grads_norm = 3.4067
	old_data_grads_norm = 2.8370
	sim_grads_norm = 0.2520
-- Starting training on experience 191 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3336
	data_grads_norm = 2.3263
	new_data_grads_norm = 2.4580
	old_data_grads_norm = 3.3825
	sim_grads_norm = 0.1554
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3391
	data_grads_norm = 1.6366
	new_data_grads_norm = 2.2728
	old_data_grads_norm = 3.0629
	sim_grads_norm = -0.0543
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0525
	data_grads_norm = 1.8014
	new_data_grads_norm = 2.7552
	old_data_grads_norm = 2.0382
	sim_grads_norm = 0.0641
-- Starting training on experience 192 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1409
	data_grads_norm = 1.3263
	new_data_grads_norm = 1.7708
	old_data_grads_norm = 2.2435
	sim_grads_norm = -0.0899
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3961
	data_grads_norm = 2.0927
	new_data_grads_norm = 2.1797
	old_data_grads_norm = 3.4767
	sim_grads_norm = 0.1167
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2818
	data_grads_norm = 1.7074
	new_data_grads_norm = 2.0288
	old_data_grads_norm = 2.9376
	sim_grads_norm = 0.2571
-- Starting training on experience 193 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2171
	data_grads_norm = 1.9245
	new_data_grads_norm = 2.1930
	old_data_grads_norm = 2.3698
	sim_grads_norm = 0.3134
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1610
	data_grads_norm = 1.4464
	new_data_grads_norm = 1.5450
	old_data_grads_norm = 2.7945
	sim_grads_norm = 0.1133
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0386
	data_grads_norm = 1.3181
	new_data_grads_norm = 1.4675
	old_data_grads_norm = 2.0417
	sim_grads_norm = 0.1546
-- Starting training on experience 194 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9510
	data_grads_norm = 1.7666
	new_data_grads_norm = 1.9510
	old_data_grads_norm = 3.1540
	sim_grads_norm = 0.2600
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9856
	data_grads_norm = 1.4536
	new_data_grads_norm = 1.4371
	old_data_grads_norm = 3.9957
	sim_grads_norm = -0.2365
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0559
	data_grads_norm = 1.8981
	new_data_grads_norm = 2.4396
	old_data_grads_norm = 2.2483
	sim_grads_norm = 0.2338
-- Starting training on experience 195 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3012
	data_grads_norm = 2.0460
	new_data_grads_norm = 2.8466
	old_data_grads_norm = 2.8755
	sim_grads_norm = 0.0301
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1885
	data_grads_norm = 1.9682
	new_data_grads_norm = 2.9806
	old_data_grads_norm = 2.4952
	sim_grads_norm = 0.2033
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0384
	data_grads_norm = 1.4118
	new_data_grads_norm = 2.7318
	old_data_grads_norm = 3.2765
	sim_grads_norm = -0.1894
-- Starting training on experience 196 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1302
	data_grads_norm = 1.4354
	new_data_grads_norm = 1.5145
	old_data_grads_norm = 2.2210
	sim_grads_norm = -0.1334
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0722
	data_grads_norm = 1.4459
	new_data_grads_norm = 1.4897
	old_data_grads_norm = 2.6875
	sim_grads_norm = -0.0278
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1084
	data_grads_norm = 1.3427
	new_data_grads_norm = 1.7474
	old_data_grads_norm = 2.3165
	sim_grads_norm = 0.0279
-- Starting training on experience 197 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1907
	data_grads_norm = 1.8091
	new_data_grads_norm = 1.9724
	old_data_grads_norm = 2.8807
	sim_grads_norm = 0.2108
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9401
	data_grads_norm = 1.3719
	new_data_grads_norm = 1.9669
	old_data_grads_norm = 1.9240
	sim_grads_norm = -0.0503
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1674
	data_grads_norm = 1.6015
	new_data_grads_norm = 2.0732
	old_data_grads_norm = 2.4646
	sim_grads_norm = -0.0343
-- Starting training on experience 198 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2558
	data_grads_norm = 2.7224
	new_data_grads_norm = 3.4833
	old_data_grads_norm = 3.0079
	sim_grads_norm = 0.2480
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1113
	data_grads_norm = 2.3786
	new_data_grads_norm = 3.1077
	old_data_grads_norm = 2.3628
	sim_grads_norm = -0.0247
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1866
	data_grads_norm = 2.9356
	new_data_grads_norm = 4.1418
	old_data_grads_norm = 3.2773
	sim_grads_norm = 0.1725
-- Starting training on experience 199 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4626
	data_grads_norm = 2.3358
	new_data_grads_norm = 3.4605
	old_data_grads_norm = 3.2859
	sim_grads_norm = 0.0304
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3448
	data_grads_norm = 2.0852
	new_data_grads_norm = 2.9776
	old_data_grads_norm = 2.7433
	sim_grads_norm = 0.0971
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2021
	data_grads_norm = 1.7765
	new_data_grads_norm = 2.7286
	old_data_grads_norm = 2.2404
	sim_grads_norm = -0.0387
-- Starting training on experience 200 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8418
	data_grads_norm = 1.5615
	new_data_grads_norm = 2.6219
	old_data_grads_norm = 2.4496
	sim_grads_norm = -0.0385
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2454
	data_grads_norm = 2.0761
	new_data_grads_norm = 3.2174
	old_data_grads_norm = 2.6153
	sim_grads_norm = 0.1532
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8828
	data_grads_norm = 1.7152
	new_data_grads_norm = 2.8192
	old_data_grads_norm = 1.9869
	sim_grads_norm = 0.1653
-- Starting training on experience 201 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1404
	data_grads_norm = 2.1870
	new_data_grads_norm = 2.4875
	old_data_grads_norm = 2.6118
	sim_grads_norm = 0.3075
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1124
	data_grads_norm = 1.7960
	new_data_grads_norm = 2.7404
	old_data_grads_norm = 2.1242
	sim_grads_norm = -0.0626
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1323
	data_grads_norm = 1.9071
	new_data_grads_norm = 2.7773
	old_data_grads_norm = 2.2116
	sim_grads_norm = -0.0652
-- Starting training on experience 202 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3763
	data_grads_norm = 2.0386
	new_data_grads_norm = 3.0900
	old_data_grads_norm = 2.0727
	sim_grads_norm = 0.2990
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1953
	data_grads_norm = 1.7750
	new_data_grads_norm = 2.5011
	old_data_grads_norm = 1.9418
	sim_grads_norm = -0.0628
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1167
	data_grads_norm = 1.6824
	new_data_grads_norm = 3.0669
	old_data_grads_norm = 2.3382
	sim_grads_norm = -0.1805
-- Starting training on experience 203 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2815
	data_grads_norm = 2.1742
	new_data_grads_norm = 2.9263
	old_data_grads_norm = 2.6725
	sim_grads_norm = 0.1603
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9621
	data_grads_norm = 1.6346
	new_data_grads_norm = 2.8112
	old_data_grads_norm = 1.9502
	sim_grads_norm = 0.1431
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9256
	data_grads_norm = 1.8725
	new_data_grads_norm = 2.7865
	old_data_grads_norm = 2.2325
	sim_grads_norm = 0.2773
-- Starting training on experience 204 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1090
	data_grads_norm = 1.5051
	new_data_grads_norm = 3.2546
	old_data_grads_norm = 1.9332
	sim_grads_norm = -0.1403
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2634
	data_grads_norm = 2.5104
	new_data_grads_norm = 3.3976
	old_data_grads_norm = 2.2758
	sim_grads_norm = 0.3796
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3086
	data_grads_norm = 2.3709
	new_data_grads_norm = 3.3580
	old_data_grads_norm = 2.8248
	sim_grads_norm = 0.0865
-- Starting training on experience 205 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1305
	data_grads_norm = 1.8693
	new_data_grads_norm = 2.1746
	old_data_grads_norm = 4.0919
	sim_grads_norm = -0.2738
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4265
	data_grads_norm = 2.1834
	new_data_grads_norm = 2.9486
	old_data_grads_norm = 3.4713
	sim_grads_norm = 0.0292
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0198
	data_grads_norm = 1.7113
	new_data_grads_norm = 2.7608
	old_data_grads_norm = 1.7964
	sim_grads_norm = 0.0831
-- Starting training on experience 206 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4042
	data_grads_norm = 2.7869
	new_data_grads_norm = 3.7943
	old_data_grads_norm = 3.3097
	sim_grads_norm = 0.5723
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2503
	data_grads_norm = 2.3496
	new_data_grads_norm = 2.5951
	old_data_grads_norm = 3.0659
	sim_grads_norm = 0.2706
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9360
	data_grads_norm = 1.6860
	new_data_grads_norm = 1.8551
	old_data_grads_norm = 2.5133
	sim_grads_norm = 0.1438
-- Starting training on experience 207 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2150
	data_grads_norm = 2.2098
	new_data_grads_norm = 4.1642
	old_data_grads_norm = 2.1556
	sim_grads_norm = 0.0959
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1945
	data_grads_norm = 1.8119
	new_data_grads_norm = 2.5594
	old_data_grads_norm = 2.6505
	sim_grads_norm = 0.0342
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2415
	data_grads_norm = 1.7644
	new_data_grads_norm = 3.2919
	old_data_grads_norm = 1.9693
	sim_grads_norm = -0.0036
-- Starting training on experience 208 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1175
	data_grads_norm = 1.7473
	new_data_grads_norm = 2.7707
	old_data_grads_norm = 3.3749
	sim_grads_norm = 0.1954
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9655
	data_grads_norm = 1.3879
	new_data_grads_norm = 2.4007
	old_data_grads_norm = 1.7513
	sim_grads_norm = -0.1469
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1800
	data_grads_norm = 1.8207
	new_data_grads_norm = 2.6365
	old_data_grads_norm = 2.5734
	sim_grads_norm = -0.0068
-- Starting training on experience 209 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0342
	data_grads_norm = 1.8871
	new_data_grads_norm = 2.4392
	old_data_grads_norm = 2.9832
	sim_grads_norm = -0.1836
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2560
	data_grads_norm = 2.3368
	new_data_grads_norm = 3.6143
	old_data_grads_norm = 1.5186
	sim_grads_norm = 0.2321
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3376
	data_grads_norm = 2.7182
	new_data_grads_norm = 3.0618
	old_data_grads_norm = 3.3109
	sim_grads_norm = 0.5389
-- Starting training on experience 210 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8396
	data_grads_norm = 1.4293
	new_data_grads_norm = 3.1967
	old_data_grads_norm = 1.8746
	sim_grads_norm = -0.2680
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9574
	data_grads_norm = 1.6731
	new_data_grads_norm = 3.1833
	old_data_grads_norm = 2.1017
	sim_grads_norm = -0.0476
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1104
	data_grads_norm = 2.5401
	new_data_grads_norm = 4.2825
	old_data_grads_norm = 2.6233
	sim_grads_norm = 0.2654
-- Starting training on experience 211 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2389
	data_grads_norm = 1.9024
	new_data_grads_norm = 2.6306
	old_data_grads_norm = 3.1299
	sim_grads_norm = -0.0855
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3353
	data_grads_norm = 2.4219
	new_data_grads_norm = 2.7711
	old_data_grads_norm = 3.0664
	sim_grads_norm = 0.4076
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8718
	data_grads_norm = 1.5924
	new_data_grads_norm = 2.3278
	old_data_grads_norm = 2.2855
	sim_grads_norm = -0.0189
-- Starting training on experience 212 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8673
	data_grads_norm = 1.1221
	new_data_grads_norm = 1.4276
	old_data_grads_norm = 2.0124
	sim_grads_norm = -0.0883
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9286
	data_grads_norm = 1.4080
	new_data_grads_norm = 1.9437
	old_data_grads_norm = 2.2849
	sim_grads_norm = -0.1219
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7223
	data_grads_norm = 1.5864
	new_data_grads_norm = 1.9492
	old_data_grads_norm = 2.3392
	sim_grads_norm = 0.0349
-- Starting training on experience 213 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1165
	data_grads_norm = 1.4928
	new_data_grads_norm = 1.5379
	old_data_grads_norm = 2.1160
	sim_grads_norm = 0.2392
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3156
	data_grads_norm = 1.9034
	new_data_grads_norm = 1.4593
	old_data_grads_norm = 2.4949
	sim_grads_norm = 0.1233
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9029
	data_grads_norm = 1.3377
	new_data_grads_norm = 1.2355
	old_data_grads_norm = 2.3776
	sim_grads_norm = 0.1225
-- Starting training on experience 214 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9743
	data_grads_norm = 1.5844
	new_data_grads_norm = 2.3560
	old_data_grads_norm = 2.6665
	sim_grads_norm = -0.1606
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9578
	data_grads_norm = 1.6576
	new_data_grads_norm = 2.2361
	old_data_grads_norm = 1.9930
	sim_grads_norm = 0.2006
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0704
	data_grads_norm = 1.5771
	new_data_grads_norm = 2.1599
	old_data_grads_norm = 3.0889
	sim_grads_norm = 0.1325
-- Starting training on experience 215 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0194
	data_grads_norm = 1.9692
	new_data_grads_norm = 2.8024
	old_data_grads_norm = 2.3934
	sim_grads_norm = 0.2444
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9268
	data_grads_norm = 1.5976
	new_data_grads_norm = 2.3254
	old_data_grads_norm = 2.3513
	sim_grads_norm = -0.1175
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1316
	data_grads_norm = 2.4776
	new_data_grads_norm = 2.7157
	old_data_grads_norm = 3.8013
	sim_grads_norm = 0.2288
-- Starting training on experience 216 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3247
	data_grads_norm = 2.2633
	new_data_grads_norm = 1.7529
	old_data_grads_norm = 4.2486
	sim_grads_norm = -0.0544
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2860
	data_grads_norm = 2.1671
	new_data_grads_norm = 2.4541
	old_data_grads_norm = 3.2708
	sim_grads_norm = 0.0031
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0229
	data_grads_norm = 1.3854
	new_data_grads_norm = 2.1833
	old_data_grads_norm = 1.8379
	sim_grads_norm = -0.0986
-- Starting training on experience 217 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0062
	data_grads_norm = 1.4797
	new_data_grads_norm = 1.5524
	old_data_grads_norm = 2.5938
	sim_grads_norm = 0.0017
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0433
	data_grads_norm = 1.8472
	new_data_grads_norm = 1.7204
	old_data_grads_norm = 3.1750
	sim_grads_norm = 0.2276
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8262
	data_grads_norm = 1.3350
	new_data_grads_norm = 1.4217
	old_data_grads_norm = 1.9308
	sim_grads_norm = 0.2149
-- Starting training on experience 218 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4915
	data_grads_norm = 2.8529
	new_data_grads_norm = 3.1077
	old_data_grads_norm = 4.3759
	sim_grads_norm = 0.2839
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8870
	data_grads_norm = 1.4741
	new_data_grads_norm = 2.7225
	old_data_grads_norm = 1.3104
	sim_grads_norm = 0.1041
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3291
	data_grads_norm = 2.4573
	new_data_grads_norm = 3.1539
	old_data_grads_norm = 3.7670
	sim_grads_norm = 0.0418
-- Starting training on experience 219 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2205
	data_grads_norm = 2.2912
	new_data_grads_norm = 3.2986
	old_data_grads_norm = 2.8962
	sim_grads_norm = 0.1515
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1050
	data_grads_norm = 1.5542
	new_data_grads_norm = 3.3753
	old_data_grads_norm = 2.4904
	sim_grads_norm = -0.3069
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7783
	data_grads_norm = 2.5110
	new_data_grads_norm = 3.7094
	old_data_grads_norm = 3.0654
	sim_grads_norm = 0.1797
-- Starting training on experience 220 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8839
	data_grads_norm = 1.4102
	new_data_grads_norm = 2.2615
	old_data_grads_norm = 2.2970
	sim_grads_norm = -0.0879
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9193
	data_grads_norm = 1.9965
	new_data_grads_norm = 2.3492
	old_data_grads_norm = 2.6555
	sim_grads_norm = 0.1467
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0038
	data_grads_norm = 1.8436
	new_data_grads_norm = 3.0113
	old_data_grads_norm = 1.9899
	sim_grads_norm = -0.2021
-- Starting training on experience 221 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4319
	data_grads_norm = 2.5818
	new_data_grads_norm = 3.6532
	old_data_grads_norm = 2.8397
	sim_grads_norm = 0.2043
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4602
	data_grads_norm = 2.9635
	new_data_grads_norm = 3.4177
	old_data_grads_norm = 3.8843
	sim_grads_norm = 0.3545
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9142
	data_grads_norm = 2.0182
	new_data_grads_norm = 3.1078
	old_data_grads_norm = 3.4372
	sim_grads_norm = -0.0553
-- Starting training on experience 222 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3354
	data_grads_norm = 2.2176
	new_data_grads_norm = 2.7245
	old_data_grads_norm = 2.9152
	sim_grads_norm = 0.2721
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9742
	data_grads_norm = 1.8227
	new_data_grads_norm = 2.3859
	old_data_grads_norm = 2.4251
	sim_grads_norm = 0.2305
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8309
	data_grads_norm = 1.6295
	new_data_grads_norm = 2.5032
	old_data_grads_norm = 2.8406
	sim_grads_norm = -0.1027
-- Starting training on experience 223 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8710
	data_grads_norm = 1.8532
	new_data_grads_norm = 1.9677
	old_data_grads_norm = 3.1139
	sim_grads_norm = 0.0670
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2005
	data_grads_norm = 2.9589
	new_data_grads_norm = 3.3980
	old_data_grads_norm = 2.8574
	sim_grads_norm = 0.4189
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7226
	data_grads_norm = 1.4965
	new_data_grads_norm = 2.6028
	old_data_grads_norm = 2.2459
	sim_grads_norm = -0.1667
-- Starting training on experience 224 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8946
	data_grads_norm = 1.7674
	new_data_grads_norm = 2.8598
	old_data_grads_norm = 3.6652
	sim_grads_norm = 0.0182
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8269
	data_grads_norm = 2.4159
	new_data_grads_norm = 3.6766
	old_data_grads_norm = 3.8240
	sim_grads_norm = 0.1280
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8917
	data_grads_norm = 2.1954
	new_data_grads_norm = 2.7357
	old_data_grads_norm = 3.3074
	sim_grads_norm = 0.1452
-- Starting training on experience 225 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3703
	data_grads_norm = 1.9416
	new_data_grads_norm = 2.2754
	old_data_grads_norm = 3.2416
	sim_grads_norm = 0.0941
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0664
	data_grads_norm = 1.8515
	new_data_grads_norm = 2.4297
	old_data_grads_norm = 2.3943
	sim_grads_norm = 0.0325
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9274
	data_grads_norm = 1.7537
	new_data_grads_norm = 2.2015
	old_data_grads_norm = 2.3063
	sim_grads_norm = 0.1214
-- Starting training on experience 226 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9423
	data_grads_norm = 1.6215
	new_data_grads_norm = 1.8118
	old_data_grads_norm = 3.6955
	sim_grads_norm = -0.0501
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0956
	data_grads_norm = 1.7057
	new_data_grads_norm = 2.6618
	old_data_grads_norm = 3.3122
	sim_grads_norm = -0.0978
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7860
	data_grads_norm = 3.3824
	new_data_grads_norm = 3.0122
	old_data_grads_norm = 4.7566
	sim_grads_norm = 0.3770
-- Starting training on experience 227 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2416
	data_grads_norm = 2.1632
	new_data_grads_norm = 3.3366
	old_data_grads_norm = 3.2549
	sim_grads_norm = -0.0065
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8894
	data_grads_norm = 1.7581
	new_data_grads_norm = 2.8275
	old_data_grads_norm = 2.0643
	sim_grads_norm = 0.0619
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1009
	data_grads_norm = 1.7318
	new_data_grads_norm = 2.8982
	old_data_grads_norm = 2.3940
	sim_grads_norm = 0.0812
-- Starting training on experience 228 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9760
	data_grads_norm = 1.4213
	new_data_grads_norm = 2.0885
	old_data_grads_norm = 2.6538
	sim_grads_norm = 0.0120
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1882
	data_grads_norm = 1.9048
	new_data_grads_norm = 2.6004
	old_data_grads_norm = 2.8288
	sim_grads_norm = -0.0607
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2091
	data_grads_norm = 1.7640
	new_data_grads_norm = 2.2341
	old_data_grads_norm = 2.2986
	sim_grads_norm = 0.3938
-- Starting training on experience 229 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2306
	data_grads_norm = 1.7045
	new_data_grads_norm = 2.6073
	old_data_grads_norm = 3.1424
	sim_grads_norm = 0.0055
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4190
	data_grads_norm = 2.5388
	new_data_grads_norm = 2.6395
	old_data_grads_norm = 2.7115
	sim_grads_norm = 0.5306
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0051
	data_grads_norm = 1.5778
	new_data_grads_norm = 1.8780
	old_data_grads_norm = 2.5336
	sim_grads_norm = 0.1778
-- Starting training on experience 230 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0263
	data_grads_norm = 2.1662
	new_data_grads_norm = 3.2869
	old_data_grads_norm = 1.5777
	sim_grads_norm = 0.5164
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3113
	data_grads_norm = 2.1471
	new_data_grads_norm = 2.6041
	old_data_grads_norm = 2.9520
	sim_grads_norm = -0.0568
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2345
	data_grads_norm = 2.0739
	new_data_grads_norm = 2.0861
	old_data_grads_norm = 4.0036
	sim_grads_norm = 0.2627
-- Starting training on experience 231 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1005
	data_grads_norm = 1.6030
	new_data_grads_norm = 2.7185
	old_data_grads_norm = 3.0335
	sim_grads_norm = 0.0177
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8269
	data_grads_norm = 1.4604
	new_data_grads_norm = 2.1974
	old_data_grads_norm = 1.6499
	sim_grads_norm = -0.0226
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9529
	data_grads_norm = 1.5177
	new_data_grads_norm = 2.2117
	old_data_grads_norm = 1.5629
	sim_grads_norm = 0.2445
-- Starting training on experience 232 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0775
	data_grads_norm = 2.1702
	new_data_grads_norm = 2.1367
	old_data_grads_norm = 3.0828
	sim_grads_norm = 0.3873
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8715
	data_grads_norm = 1.1410
	new_data_grads_norm = 1.5185
	old_data_grads_norm = 2.1608
	sim_grads_norm = -0.3096
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8259
	data_grads_norm = 1.1437
	new_data_grads_norm = 2.0124
	old_data_grads_norm = 2.6997
	sim_grads_norm = -0.3937
-- Starting training on experience 233 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9319
	data_grads_norm = 1.1529
	new_data_grads_norm = 3.0331
	old_data_grads_norm = 1.2160
	sim_grads_norm = -0.0027
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0643
	data_grads_norm = 2.7479
	new_data_grads_norm = 3.9375
	old_data_grads_norm = 3.5121
	sim_grads_norm = 0.2276
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9431
	data_grads_norm = 1.5188
	new_data_grads_norm = 3.2591
	old_data_grads_norm = 1.8063
	sim_grads_norm = 0.0210
-- Starting training on experience 234 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9367
	data_grads_norm = 1.6463
	new_data_grads_norm = 2.6462
	old_data_grads_norm = 3.0803
	sim_grads_norm = -0.3151
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1117
	data_grads_norm = 2.1682
	new_data_grads_norm = 3.6972
	old_data_grads_norm = 2.2107
	sim_grads_norm = 0.3181
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8347
	data_grads_norm = 1.6195
	new_data_grads_norm = 3.3193
	old_data_grads_norm = 2.2956
	sim_grads_norm = -0.1189
-- Starting training on experience 235 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1482
	data_grads_norm = 2.2049
	new_data_grads_norm = 4.2759
	old_data_grads_norm = 2.0180
	sim_grads_norm = 0.0551
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4216
	data_grads_norm = 3.3299
	new_data_grads_norm = 5.0298
	old_data_grads_norm = 3.2013
	sim_grads_norm = 0.1225
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2085
	data_grads_norm = 2.9087
	new_data_grads_norm = 4.0954
	old_data_grads_norm = 2.8788
	sim_grads_norm = 0.2978
-- Starting training on experience 236 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.5498
	data_grads_norm = 1.1053
	new_data_grads_norm = 1.8365
	old_data_grads_norm = 1.3998
	sim_grads_norm = -0.1602
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9147
	data_grads_norm = 1.5469
	new_data_grads_norm = 2.0563
	old_data_grads_norm = 2.5554
	sim_grads_norm = -0.0321
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4764
	data_grads_norm = 2.7903
	new_data_grads_norm = 2.6390
	old_data_grads_norm = 4.3546
	sim_grads_norm = 0.0805
-- Starting training on experience 237 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
-- >> End of training phase << --
-- >> Start of eval phase << --
-- Starting eval on experience 0 (Task 0) from test stream --
> Eval on experience 0 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp000 = 1.2639
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.5100
	mb_index = 238
	time = 28.2442
-- >> End of eval phase << --
	CumulativeAccuracy/eval_phase/test_stream/Exp000 = 0.5100
	Loss_Stream/eval_phase/test_stream/Task000 = 1.2639
	Top1_Acc_Stream/eval_phase/test_stream/Task000 = 0.5100
-- >> Start of training phase << --
-- Starting training on experience 0 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2547
	data_grads_norm = 2.3791
	new_data_grads_norm = 3.5855
	old_data_grads_norm = 3.5835
	sim_grads_norm = -0.2169
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0671
	data_grads_norm = 2.1600
	new_data_grads_norm = 3.9138
	old_data_grads_norm = 2.0821
	sim_grads_norm = -0.1838
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2664
	data_grads_norm = 2.1817
	new_data_grads_norm = 4.6167
	old_data_grads_norm = 2.1771
	sim_grads_norm = -0.0526
-- Starting training on experience 1 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3466
	data_grads_norm = 2.1865
	new_data_grads_norm = 4.3894
	old_data_grads_norm = 2.3353
	sim_grads_norm = -0.1055
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3351
	data_grads_norm = 2.5772
	new_data_grads_norm = 4.5196
	old_data_grads_norm = 3.0527
	sim_grads_norm = -0.1457
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2708
	data_grads_norm = 2.6571
	new_data_grads_norm = 4.9370
	old_data_grads_norm = 2.0299
	sim_grads_norm = 0.0162
-- Starting training on experience 2 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5177
	data_grads_norm = 2.5848
	new_data_grads_norm = 4.2106
	old_data_grads_norm = 3.2133
	sim_grads_norm = 0.0050
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3678
	data_grads_norm = 2.3307
	new_data_grads_norm = 4.4415
	old_data_grads_norm = 2.0555
	sim_grads_norm = -0.1787
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3264
	data_grads_norm = 2.3353
	new_data_grads_norm = 5.0109
	old_data_grads_norm = 1.8790
	sim_grads_norm = -0.0002
-- Starting training on experience 3 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6597
	data_grads_norm = 2.6509
	new_data_grads_norm = 4.4177
	old_data_grads_norm = 2.0855
	sim_grads_norm = 0.1094
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7743
	data_grads_norm = 3.3676
	new_data_grads_norm = 4.5060
	old_data_grads_norm = 3.7450
	sim_grads_norm = 0.1486
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2244
	data_grads_norm = 2.0469
	new_data_grads_norm = 4.2525
	old_data_grads_norm = 1.8127
	sim_grads_norm = -0.2095
-- Starting training on experience 4 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8776
	data_grads_norm = 3.9641
	new_data_grads_norm = 6.6158
	old_data_grads_norm = 3.2734
	sim_grads_norm = 0.0287
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0478
	data_grads_norm = 4.7765
	new_data_grads_norm = 5.7434
	old_data_grads_norm = 5.2478
	sim_grads_norm = 0.1192
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6497
	data_grads_norm = 3.2878
	new_data_grads_norm = 5.5237
	old_data_grads_norm = 2.2633
	sim_grads_norm = -0.0463
-- Starting training on experience 5 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7896
	data_grads_norm = 3.0948
	new_data_grads_norm = 5.5097
	old_data_grads_norm = 2.9780
	sim_grads_norm = 0.1655
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4250
	data_grads_norm = 2.5246
	new_data_grads_norm = 5.6902
	old_data_grads_norm = 1.9925
	sim_grads_norm = -0.2134
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1850
	data_grads_norm = 3.4665
	new_data_grads_norm = 5.7811
	old_data_grads_norm = 3.1521
	sim_grads_norm = 0.0827
-- Starting training on experience 6 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4916
	data_grads_norm = 2.8684
	new_data_grads_norm = 4.7925
	old_data_grads_norm = 2.6116
	sim_grads_norm = 0.1817
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5073
	data_grads_norm = 2.4782
	new_data_grads_norm = 4.8253
	old_data_grads_norm = 2.2027
	sim_grads_norm = 0.0286
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0497
	data_grads_norm = 3.8977
	new_data_grads_norm = 5.2107
	old_data_grads_norm = 4.4208
	sim_grads_norm = 0.1395
-- Starting training on experience 7 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3934
	data_grads_norm = 2.7573
	new_data_grads_norm = 5.0549
	old_data_grads_norm = 3.4362
	sim_grads_norm = -0.2427
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0355
	data_grads_norm = 3.4987
	new_data_grads_norm = 6.0380
	old_data_grads_norm = 2.0339
	sim_grads_norm = 0.0638
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4402
	data_grads_norm = 4.5208
	new_data_grads_norm = 6.4736
	old_data_grads_norm = 4.5148
	sim_grads_norm = 0.1443
-- Starting training on experience 8 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9368
	data_grads_norm = 3.9992
	new_data_grads_norm = 6.1498
	old_data_grads_norm = 3.7283
	sim_grads_norm = 0.0709
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9259
	data_grads_norm = 2.9812
	new_data_grads_norm = 5.0261
	old_data_grads_norm = 2.4939
	sim_grads_norm = 0.0791
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9970
	data_grads_norm = 2.8772
	new_data_grads_norm = 5.3540
	old_data_grads_norm = 2.7725
	sim_grads_norm = 0.2051
-- Starting training on experience 9 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3474
	data_grads_norm = 2.0089
	new_data_grads_norm = 4.5623
	old_data_grads_norm = 2.2391
	sim_grads_norm = -0.2536
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4869
	data_grads_norm = 3.1378
	new_data_grads_norm = 5.9919
	old_data_grads_norm = 2.0078
	sim_grads_norm = -0.0037
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6442
	data_grads_norm = 2.9980
	new_data_grads_norm = 5.5118
	old_data_grads_norm = 2.8215
	sim_grads_norm = -0.1487
-- Starting training on experience 10 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4389
	data_grads_norm = 2.7618
	new_data_grads_norm = 5.7081
	old_data_grads_norm = 1.6947
	sim_grads_norm = -0.0979
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9227
	data_grads_norm = 3.4343
	new_data_grads_norm = 6.7815
	old_data_grads_norm = 2.9331
	sim_grads_norm = 0.0623
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8846
	data_grads_norm = 3.2315
	new_data_grads_norm = 5.3299
	old_data_grads_norm = 3.0761
	sim_grads_norm = -0.0955
-- Starting training on experience 11 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0773
	data_grads_norm = 3.6716
	new_data_grads_norm = 6.3686
	old_data_grads_norm = 2.8072
	sim_grads_norm = 0.0755
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9306
	data_grads_norm = 3.2047
	new_data_grads_norm = 6.5273
	old_data_grads_norm = 2.0982
	sim_grads_norm = -0.0320
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2190
	data_grads_norm = 3.6021
	new_data_grads_norm = 6.1453
	old_data_grads_norm = 4.2867
	sim_grads_norm = -0.0760
-- Starting training on experience 12 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9797
	data_grads_norm = 3.7771
	new_data_grads_norm = 6.2372
	old_data_grads_norm = 3.3941
	sim_grads_norm = 0.1418
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0233
	data_grads_norm = 4.0428
	new_data_grads_norm = 6.7064
	old_data_grads_norm = 4.3251
	sim_grads_norm = 0.0654
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2096
	data_grads_norm = 5.7654
	new_data_grads_norm = 6.2585
	old_data_grads_norm = 7.2477
	sim_grads_norm = 0.1677
-- Starting training on experience 13 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2771
	data_grads_norm = 3.9228
	new_data_grads_norm = 5.6123
	old_data_grads_norm = 3.0705
	sim_grads_norm = 0.0913
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7936
	data_grads_norm = 3.3263
	new_data_grads_norm = 5.5836
	old_data_grads_norm = 2.2749
	sim_grads_norm = -0.0889
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3494
	data_grads_norm = 4.0804
	new_data_grads_norm = 5.8319
	old_data_grads_norm = 4.3177
	sim_grads_norm = 0.3221
-- Starting training on experience 14 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4714
	data_grads_norm = 2.5201
	new_data_grads_norm = 4.8927
	old_data_grads_norm = 2.0335
	sim_grads_norm = -0.1077
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4003
	data_grads_norm = 2.1375
	new_data_grads_norm = 5.3166
	old_data_grads_norm = 1.6594
	sim_grads_norm = -0.1980
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9912
	data_grads_norm = 4.2112
	new_data_grads_norm = 5.7061
	old_data_grads_norm = 4.6080
	sim_grads_norm = 0.4115
-- Starting training on experience 15 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8088
	data_grads_norm = 2.9994
	new_data_grads_norm = 4.5366
	old_data_grads_norm = 3.0591
	sim_grads_norm = 0.1679
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2143
	data_grads_norm = 2.1275
	new_data_grads_norm = 4.1473
	old_data_grads_norm = 1.9549
	sim_grads_norm = -0.1694
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5571
	data_grads_norm = 2.3338
	new_data_grads_norm = 5.2091
	old_data_grads_norm = 1.9669
	sim_grads_norm = 0.0968
-- Starting training on experience 16 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6181
	data_grads_norm = 2.4848
	new_data_grads_norm = 4.3493
	old_data_grads_norm = 2.9446
	sim_grads_norm = 0.1144
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8155
	data_grads_norm = 2.4307
	new_data_grads_norm = 4.2358
	old_data_grads_norm = 2.4750
	sim_grads_norm = 0.1757
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0778
	data_grads_norm = 2.7048
	new_data_grads_norm = 3.8627
	old_data_grads_norm = 2.4632
	sim_grads_norm = 0.4002
-- Starting training on experience 17 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2346
	data_grads_norm = 1.5761
	new_data_grads_norm = 3.8728
	old_data_grads_norm = 1.5164
	sim_grads_norm = -0.0248
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6655
	data_grads_norm = 2.8002
	new_data_grads_norm = 4.3719
	old_data_grads_norm = 2.9536
	sim_grads_norm = 0.0778
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3316
	data_grads_norm = 2.0571
	new_data_grads_norm = 3.5875
	old_data_grads_norm = 2.0616
	sim_grads_norm = 0.0841
-- Starting training on experience 18 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2538
	data_grads_norm = 3.2250
	new_data_grads_norm = 4.5943
	old_data_grads_norm = 3.6081
	sim_grads_norm = 0.3366
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3730
	data_grads_norm = 2.1247
	new_data_grads_norm = 3.6940
	old_data_grads_norm = 2.8135
	sim_grads_norm = -0.0307
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3625
	data_grads_norm = 2.1810
	new_data_grads_norm = 3.7807
	old_data_grads_norm = 2.9374
	sim_grads_norm = -0.0160
-- Starting training on experience 19 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2905
	data_grads_norm = 1.9535
	new_data_grads_norm = 4.0201
	old_data_grads_norm = 2.3324
	sim_grads_norm = -0.1453
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4850
	data_grads_norm = 2.3290
	new_data_grads_norm = 4.1051
	old_data_grads_norm = 2.4151
	sim_grads_norm = -0.0458
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5340
	data_grads_norm = 2.5956
	new_data_grads_norm = 4.2389
	old_data_grads_norm = 2.4329
	sim_grads_norm = -0.1201
-- Starting training on experience 20 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7807
	data_grads_norm = 3.0902
	new_data_grads_norm = 4.1738
	old_data_grads_norm = 2.8910
	sim_grads_norm = 0.1722
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6973
	data_grads_norm = 2.7553
	new_data_grads_norm = 4.4514
	old_data_grads_norm = 3.1505
	sim_grads_norm = 0.1172
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1919
	data_grads_norm = 1.7962
	new_data_grads_norm = 3.9623
	old_data_grads_norm = 1.7638
	sim_grads_norm = -0.2695
-- Starting training on experience 21 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8574
	data_grads_norm = 3.4457
	new_data_grads_norm = 5.9860
	old_data_grads_norm = 4.2640
	sim_grads_norm = 0.0824
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0384
	data_grads_norm = 3.3565
	new_data_grads_norm = 5.0026
	old_data_grads_norm = 2.5138
	sim_grads_norm = 0.1710
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4456
	data_grads_norm = 2.5754
	new_data_grads_norm = 5.6492
	old_data_grads_norm = 2.3674
	sim_grads_norm = 0.0122
-- Starting training on experience 22 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5674
	data_grads_norm = 2.7626
	new_data_grads_norm = 4.4195
	old_data_grads_norm = 2.7942
	sim_grads_norm = 0.3403
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0365
	data_grads_norm = 1.8377
	new_data_grads_norm = 3.6388
	old_data_grads_norm = 2.9481
	sim_grads_norm = 0.0381
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4559
	data_grads_norm = 2.2552
	new_data_grads_norm = 3.6660
	old_data_grads_norm = 2.3249
	sim_grads_norm = 0.0499
-- Starting training on experience 23 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5190
	data_grads_norm = 2.3987
	new_data_grads_norm = 3.9546
	old_data_grads_norm = 1.6875
	sim_grads_norm = 0.2469
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4309
	data_grads_norm = 2.0893
	new_data_grads_norm = 3.6107
	old_data_grads_norm = 1.8007
	sim_grads_norm = 0.0722
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5507
	data_grads_norm = 2.7204
	new_data_grads_norm = 3.8893
	old_data_grads_norm = 2.6291
	sim_grads_norm = 0.2760
-- Starting training on experience 24 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1759
	data_grads_norm = 2.6680
	new_data_grads_norm = 3.7331
	old_data_grads_norm = 3.7828
	sim_grads_norm = 0.0864
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2703
	data_grads_norm = 2.1316
	new_data_grads_norm = 3.2196
	old_data_grads_norm = 2.1254
	sim_grads_norm = -0.0263
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2492
	data_grads_norm = 2.1910
	new_data_grads_norm = 3.4894
	old_data_grads_norm = 2.1314
	sim_grads_norm = 0.0233
-- Starting training on experience 25 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3523
	data_grads_norm = 2.3387
	new_data_grads_norm = 3.7633
	old_data_grads_norm = 1.9743
	sim_grads_norm = 0.0364
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2099
	data_grads_norm = 2.2573
	new_data_grads_norm = 4.1831
	old_data_grads_norm = 2.1996
	sim_grads_norm = -0.2703
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6711
	data_grads_norm = 3.3668
	new_data_grads_norm = 5.8876
	old_data_grads_norm = 2.1467
	sim_grads_norm = 0.0521
-- Starting training on experience 26 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1623
	data_grads_norm = 2.0948
	new_data_grads_norm = 3.6237
	old_data_grads_norm = 2.3788
	sim_grads_norm = -0.1073
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7031
	data_grads_norm = 2.6465
	new_data_grads_norm = 4.2450
	old_data_grads_norm = 3.2791
	sim_grads_norm = 0.0750
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5514
	data_grads_norm = 2.2802
	new_data_grads_norm = 3.8198
	old_data_grads_norm = 2.3219
	sim_grads_norm = -0.0828
-- Starting training on experience 27 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1181
	data_grads_norm = 2.0870
	new_data_grads_norm = 3.6858
	old_data_grads_norm = 2.1992
	sim_grads_norm = -0.0110
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4385
	data_grads_norm = 2.3652
	new_data_grads_norm = 3.5220
	old_data_grads_norm = 3.8233
	sim_grads_norm = 0.1591
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3328
	data_grads_norm = 2.6260
	new_data_grads_norm = 4.2871
	old_data_grads_norm = 2.1510
	sim_grads_norm = 0.0681
-- Starting training on experience 28 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3235
	data_grads_norm = 2.6888
	new_data_grads_norm = 3.9213
	old_data_grads_norm = 3.3755
	sim_grads_norm = 0.0673
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1217
	data_grads_norm = 2.4780
	new_data_grads_norm = 4.7541
	old_data_grads_norm = 2.4437
	sim_grads_norm = 0.0764
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2950
	data_grads_norm = 2.7680
	new_data_grads_norm = 4.6614
	old_data_grads_norm = 3.0981
	sim_grads_norm = 0.1538
-- Starting training on experience 29 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1149
	data_grads_norm = 2.4955
	new_data_grads_norm = 4.2775
	old_data_grads_norm = 3.1758
	sim_grads_norm = 0.0150
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1078
	data_grads_norm = 2.4809
	new_data_grads_norm = 4.6618
	old_data_grads_norm = 1.9524
	sim_grads_norm = 0.0707
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1544
	data_grads_norm = 2.2044
	new_data_grads_norm = 4.1019
	old_data_grads_norm = 2.3626
	sim_grads_norm = 0.1409
-- Starting training on experience 30 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1386
	data_grads_norm = 2.5818
	new_data_grads_norm = 5.4063
	old_data_grads_norm = 2.2289
	sim_grads_norm = 0.0145
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7835
	data_grads_norm = 3.1904
	new_data_grads_norm = 4.9811
	old_data_grads_norm = 2.6543
	sim_grads_norm = 0.1867
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6850
	data_grads_norm = 3.9390
	new_data_grads_norm = 5.2514
	old_data_grads_norm = 3.5010
	sim_grads_norm = 0.1669
-- Starting training on experience 31 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4089
	data_grads_norm = 2.8906
	new_data_grads_norm = 4.6969
	old_data_grads_norm = 2.6167
	sim_grads_norm = 0.1901
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5213
	data_grads_norm = 3.5698
	new_data_grads_norm = 4.7910
	old_data_grads_norm = 3.9327
	sim_grads_norm = 0.2633
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3154
	data_grads_norm = 2.8631
	new_data_grads_norm = 5.0117
	old_data_grads_norm = 2.6421
	sim_grads_norm = 0.0721
-- Starting training on experience 32 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2938
	data_grads_norm = 3.1633
	new_data_grads_norm = 5.8842
	old_data_grads_norm = 3.0473
	sim_grads_norm = -0.1265
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4663
	data_grads_norm = 3.4617
	new_data_grads_norm = 5.0852
	old_data_grads_norm = 3.2621
	sim_grads_norm = 0.3087
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1330
	data_grads_norm = 2.9104
	new_data_grads_norm = 4.5488
	old_data_grads_norm = 3.4953
	sim_grads_norm = 0.0476
-- Starting training on experience 33 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2688
	data_grads_norm = 3.0673
	new_data_grads_norm = 3.9882
	old_data_grads_norm = 3.6856
	sim_grads_norm = 0.2268
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0212
	data_grads_norm = 2.2367
	new_data_grads_norm = 3.8727
	old_data_grads_norm = 2.6666
	sim_grads_norm = -0.0494
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2783
	data_grads_norm = 2.5834
	new_data_grads_norm = 3.8873
	old_data_grads_norm = 3.0410
	sim_grads_norm = 0.1806
-- Starting training on experience 34 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0218
	data_grads_norm = 2.0006
	new_data_grads_norm = 3.7339
	old_data_grads_norm = 2.6104
	sim_grads_norm = -0.0306
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9480
	data_grads_norm = 2.6520
	new_data_grads_norm = 4.3512
	old_data_grads_norm = 2.1587
	sim_grads_norm = 0.2350
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0096
	data_grads_norm = 3.0185
	new_data_grads_norm = 4.0842
	old_data_grads_norm = 3.4956
	sim_grads_norm = -0.1623
-- Starting training on experience 35 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6113
	data_grads_norm = 1.9214
	new_data_grads_norm = 3.1067
	old_data_grads_norm = 4.5505
	sim_grads_norm = -0.0710
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1441
	data_grads_norm = 2.5203
	new_data_grads_norm = 3.4039
	old_data_grads_norm = 3.1920
	sim_grads_norm = 0.1531
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0314
	data_grads_norm = 2.1317
	new_data_grads_norm = 3.4874
	old_data_grads_norm = 2.1847
	sim_grads_norm = 0.1910
-- Starting training on experience 36 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9333
	data_grads_norm = 1.9660
	new_data_grads_norm = 3.9659
	old_data_grads_norm = 2.4558
	sim_grads_norm = -0.0998
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3495
	data_grads_norm = 3.1075
	new_data_grads_norm = 4.3018
	old_data_grads_norm = 3.8088
	sim_grads_norm = 0.0153
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0777
	data_grads_norm = 2.0197
	new_data_grads_norm = 4.2790
	old_data_grads_norm = 2.0267
	sim_grads_norm = 0.1790
-- Starting training on experience 37 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9123
	data_grads_norm = 2.2260
	new_data_grads_norm = 4.0093
	old_data_grads_norm = 2.7990
	sim_grads_norm = -0.1041
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0483
	data_grads_norm = 2.4613
	new_data_grads_norm = 4.1595
	old_data_grads_norm = 2.3601
	sim_grads_norm = 0.0511
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4163
	data_grads_norm = 3.1304
	new_data_grads_norm = 4.4301
	old_data_grads_norm = 4.2995
	sim_grads_norm = -0.0837
-- Starting training on experience 38 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3759
	data_grads_norm = 3.6254
	new_data_grads_norm = 4.5858
	old_data_grads_norm = 4.4315
	sim_grads_norm = 0.0845
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3752
	data_grads_norm = 2.8607
	new_data_grads_norm = 4.7853
	old_data_grads_norm = 3.1597
	sim_grads_norm = -0.0225
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2939
	data_grads_norm = 2.7146
	new_data_grads_norm = 4.7683
	old_data_grads_norm = 3.5047
	sim_grads_norm = 0.0013
-- Starting training on experience 39 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2863
	data_grads_norm = 3.6139
	new_data_grads_norm = 5.5627
	old_data_grads_norm = 3.1641
	sim_grads_norm = 0.3034
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0602
	data_grads_norm = 3.5026
	new_data_grads_norm = 4.4675
	old_data_grads_norm = 3.0238
	sim_grads_norm = -0.0102
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0867
	data_grads_norm = 2.6312
	new_data_grads_norm = 3.7581
	old_data_grads_norm = 3.0713
	sim_grads_norm = 0.1991
-- Starting training on experience 40 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0793
	data_grads_norm = 2.5515
	new_data_grads_norm = 3.0812
	old_data_grads_norm = 2.9985
	sim_grads_norm = -0.1606
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3473
	data_grads_norm = 3.4645
	new_data_grads_norm = 4.6469
	old_data_grads_norm = 3.2133
	sim_grads_norm = 0.2120
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7159
	data_grads_norm = 1.7661
	new_data_grads_norm = 4.4726
	old_data_grads_norm = 3.2690
	sim_grads_norm = -0.1199
-- Starting training on experience 41 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1231
	data_grads_norm = 2.6723
	new_data_grads_norm = 4.8390
	old_data_grads_norm = 1.7604
	sim_grads_norm = -0.0499
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5362
	data_grads_norm = 3.1498
	new_data_grads_norm = 4.8954
	old_data_grads_norm = 3.5352
	sim_grads_norm = 0.1568
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4212
	data_grads_norm = 3.3459
	new_data_grads_norm = 4.4612
	old_data_grads_norm = 3.8739
	sim_grads_norm = 0.2162
-- Starting training on experience 42 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0739
	data_grads_norm = 2.2999
	new_data_grads_norm = 4.0288
	old_data_grads_norm = 2.1672
	sim_grads_norm = 0.0713
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1924
	data_grads_norm = 2.5371
	new_data_grads_norm = 3.9274
	old_data_grads_norm = 2.4656
	sim_grads_norm = 0.1794
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0216
	data_grads_norm = 2.1389
	new_data_grads_norm = 3.9050
	old_data_grads_norm = 3.0586
	sim_grads_norm = -0.3179
-- Starting training on experience 43 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1248
	data_grads_norm = 2.9555
	new_data_grads_norm = 3.8175
	old_data_grads_norm = 3.5792
	sim_grads_norm = 0.1714
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0573
	data_grads_norm = 2.7856
	new_data_grads_norm = 3.9833
	old_data_grads_norm = 3.1051
	sim_grads_norm = 0.0522
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0421
	data_grads_norm = 2.0416
	new_data_grads_norm = 3.4848
	old_data_grads_norm = 2.5353
	sim_grads_norm = -0.0371
-- Starting training on experience 44 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0069
	data_grads_norm = 2.3924
	new_data_grads_norm = 3.3465
	old_data_grads_norm = 2.6699
	sim_grads_norm = 0.1034
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2891
	data_grads_norm = 2.3860
	new_data_grads_norm = 2.8423
	old_data_grads_norm = 3.2679
	sim_grads_norm = 0.1332
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1006
	data_grads_norm = 2.2158
	new_data_grads_norm = 2.7776
	old_data_grads_norm = 3.3381
	sim_grads_norm = -0.0368
-- Starting training on experience 45 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2530
	data_grads_norm = 2.4665
	new_data_grads_norm = 3.6700
	old_data_grads_norm = 3.7813
	sim_grads_norm = 0.1482
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1559
	data_grads_norm = 2.2115
	new_data_grads_norm = 3.6097
	old_data_grads_norm = 2.2264
	sim_grads_norm = 0.2823
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9079
	data_grads_norm = 1.9651
	new_data_grads_norm = 3.2696
	old_data_grads_norm = 2.2358
	sim_grads_norm = -0.0946
-- Starting training on experience 46 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2947
	data_grads_norm = 2.5841
	new_data_grads_norm = 3.8080
	old_data_grads_norm = 2.6721
	sim_grads_norm = 0.3239
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6959
	data_grads_norm = 2.0520
	new_data_grads_norm = 3.3055
	old_data_grads_norm = 2.8210
	sim_grads_norm = -0.0631
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6794
	data_grads_norm = 2.3334
	new_data_grads_norm = 4.0048
	old_data_grads_norm = 2.4295
	sim_grads_norm = 0.0534
-- Starting training on experience 47 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3743
	data_grads_norm = 2.9529
	new_data_grads_norm = 3.1888
	old_data_grads_norm = 4.2978
	sim_grads_norm = 0.0399
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2657
	data_grads_norm = 2.4715
	new_data_grads_norm = 3.5628
	old_data_grads_norm = 2.8306
	sim_grads_norm = -0.0668
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1415
	data_grads_norm = 2.0901
	new_data_grads_norm = 3.4392
	old_data_grads_norm = 2.0618
	sim_grads_norm = 0.0897
-- Starting training on experience 48 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8032
	data_grads_norm = 2.3262
	new_data_grads_norm = 3.3093
	old_data_grads_norm = 3.0587
	sim_grads_norm = 0.0826
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9500
	data_grads_norm = 2.3975
	new_data_grads_norm = 3.2585
	old_data_grads_norm = 3.4147
	sim_grads_norm = -0.0109
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2239
	data_grads_norm = 2.9578
	new_data_grads_norm = 3.6588
	old_data_grads_norm = 3.7495
	sim_grads_norm = 0.1742
-- Starting training on experience 49 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6425
	data_grads_norm = 2.0133
	new_data_grads_norm = 3.8671
	old_data_grads_norm = 1.8499
	sim_grads_norm = 0.1848
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0679
	data_grads_norm = 2.2793
	new_data_grads_norm = 3.8107
	old_data_grads_norm = 2.7358
	sim_grads_norm = 0.0321
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0746
	data_grads_norm = 2.2902
	new_data_grads_norm = 3.5515
	old_data_grads_norm = 3.6880
	sim_grads_norm = -0.1592
-- Starting training on experience 50 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0696
	data_grads_norm = 2.4741
	new_data_grads_norm = 3.9283
	old_data_grads_norm = 3.3983
	sim_grads_norm = -0.0836
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3658
	data_grads_norm = 2.9019
	new_data_grads_norm = 4.4025
	old_data_grads_norm = 3.3094
	sim_grads_norm = 0.2819
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0023
	data_grads_norm = 1.9434
	new_data_grads_norm = 3.7193
	old_data_grads_norm = 2.0944
	sim_grads_norm = 0.0527
-- Starting training on experience 51 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9265
	data_grads_norm = 2.2841
	new_data_grads_norm = 4.3209
	old_data_grads_norm = 2.6266
	sim_grads_norm = 0.0155
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2028
	data_grads_norm = 3.1013
	new_data_grads_norm = 4.6641
	old_data_grads_norm = 3.8751
	sim_grads_norm = 0.1498
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0818
	data_grads_norm = 2.3947
	new_data_grads_norm = 4.0794
	old_data_grads_norm = 3.2924
	sim_grads_norm = -0.0748
-- Starting training on experience 52 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2217
	data_grads_norm = 2.4013
	new_data_grads_norm = 4.1186
	old_data_grads_norm = 2.4809
	sim_grads_norm = 0.0673
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2664
	data_grads_norm = 2.0620
	new_data_grads_norm = 4.0017
	old_data_grads_norm = 2.5815
	sim_grads_norm = -0.0873
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6006
	data_grads_norm = 3.2897
	new_data_grads_norm = 4.2741
	old_data_grads_norm = 3.4811
	sim_grads_norm = 0.3163
-- Starting training on experience 53 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0514
	data_grads_norm = 2.2454
	new_data_grads_norm = 3.3807
	old_data_grads_norm = 2.7065
	sim_grads_norm = 0.1402
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8242
	data_grads_norm = 2.3119
	new_data_grads_norm = 3.3166
	old_data_grads_norm = 2.8867
	sim_grads_norm = -0.0030
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2065
	data_grads_norm = 2.4292
	new_data_grads_norm = 3.6700
	old_data_grads_norm = 3.5275
	sim_grads_norm = -0.0794
-- Starting training on experience 54 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9882
	data_grads_norm = 2.9082
	new_data_grads_norm = 4.2994
	old_data_grads_norm = 3.1536
	sim_grads_norm = 0.0433
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6966
	data_grads_norm = 2.5066
	new_data_grads_norm = 3.5320
	old_data_grads_norm = 3.2193
	sim_grads_norm = 0.1293
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8795
	data_grads_norm = 2.2905
	new_data_grads_norm = 4.4461
	old_data_grads_norm = 3.1599
	sim_grads_norm = -0.0922
-- Starting training on experience 55 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7688
	data_grads_norm = 2.3808
	new_data_grads_norm = 3.3935
	old_data_grads_norm = 3.3569
	sim_grads_norm = -0.0013
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8894
	data_grads_norm = 1.9121
	new_data_grads_norm = 3.6831
	old_data_grads_norm = 2.5553
	sim_grads_norm = -0.1337
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2359
	data_grads_norm = 3.1821
	new_data_grads_norm = 3.6267
	old_data_grads_norm = 4.2697
	sim_grads_norm = 0.4145
-- Starting training on experience 56 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5324
	data_grads_norm = 2.0010
	new_data_grads_norm = 3.2652
	old_data_grads_norm = 2.7510
	sim_grads_norm = -0.1788
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2341
	data_grads_norm = 1.7808
	new_data_grads_norm = 3.5673
	old_data_grads_norm = 2.4905
	sim_grads_norm = -0.3186
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4756
	data_grads_norm = 1.8825
	new_data_grads_norm = 4.0025
	old_data_grads_norm = 2.2099
	sim_grads_norm = -0.1925
-- Starting training on experience 57 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2097
	data_grads_norm = 2.4111
	new_data_grads_norm = 4.2008
	old_data_grads_norm = 2.3628
	sim_grads_norm = -0.0660
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2729
	data_grads_norm = 2.9445
	new_data_grads_norm = 4.4893
	old_data_grads_norm = 3.1593
	sim_grads_norm = 0.2280
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3219
	data_grads_norm = 2.9196
	new_data_grads_norm = 3.5535
	old_data_grads_norm = 3.8262
	sim_grads_norm = 0.1313
-- Starting training on experience 58 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6526
	data_grads_norm = 2.2243
	new_data_grads_norm = 4.0078
	old_data_grads_norm = 2.3542
	sim_grads_norm = 0.0729
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7153
	data_grads_norm = 2.2704
	new_data_grads_norm = 3.6737
	old_data_grads_norm = 2.9867
	sim_grads_norm = 0.1492
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8175
	data_grads_norm = 2.4563
	new_data_grads_norm = 4.0285
	old_data_grads_norm = 3.1084
	sim_grads_norm = 0.0339
-- Starting training on experience 59 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9919
	data_grads_norm = 2.7886
	new_data_grads_norm = 4.0171
	old_data_grads_norm = 3.6651
	sim_grads_norm = 0.0989
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8884
	data_grads_norm = 2.7936
	new_data_grads_norm = 3.6944
	old_data_grads_norm = 3.6885
	sim_grads_norm = 0.0325
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7479
	data_grads_norm = 1.8256
	new_data_grads_norm = 3.8663
	old_data_grads_norm = 2.2412
	sim_grads_norm = -0.0785
-- Starting training on experience 60 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3282
	data_grads_norm = 2.6741
	new_data_grads_norm = 3.5396
	old_data_grads_norm = 3.8367
	sim_grads_norm = 0.0732
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0274
	data_grads_norm = 2.7618
	new_data_grads_norm = 4.1783
	old_data_grads_norm = 2.6637
	sim_grads_norm = 0.3155
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6370
	data_grads_norm = 2.1895
	new_data_grads_norm = 4.0429
	old_data_grads_norm = 2.7388
	sim_grads_norm = -0.2374
-- Starting training on experience 61 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8653
	data_grads_norm = 2.5826
	new_data_grads_norm = 4.9533
	old_data_grads_norm = 1.8848
	sim_grads_norm = -0.0153
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9188
	data_grads_norm = 2.9419
	new_data_grads_norm = 4.3047
	old_data_grads_norm = 2.6867
	sim_grads_norm = 0.0993
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0288
	data_grads_norm = 3.2481
	new_data_grads_norm = 4.8763
	old_data_grads_norm = 2.7018
	sim_grads_norm = 0.0978
-- Starting training on experience 62 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8649
	data_grads_norm = 3.2497
	new_data_grads_norm = 4.7150
	old_data_grads_norm = 3.1400
	sim_grads_norm = -0.1646
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9029
	data_grads_norm = 3.0053
	new_data_grads_norm = 4.6455
	old_data_grads_norm = 2.7618
	sim_grads_norm = 0.2375
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6012
	data_grads_norm = 2.6227
	new_data_grads_norm = 4.8947
	old_data_grads_norm = 2.6710
	sim_grads_norm = -0.0656
-- Starting training on experience 63 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9484
	data_grads_norm = 2.7451
	new_data_grads_norm = 4.3603
	old_data_grads_norm = 3.4945
	sim_grads_norm = 0.1893
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6950
	data_grads_norm = 2.3783
	new_data_grads_norm = 3.6682
	old_data_grads_norm = 3.0152
	sim_grads_norm = -0.0674
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5398
	data_grads_norm = 2.9392
	new_data_grads_norm = 4.0684
	old_data_grads_norm = 4.1543
	sim_grads_norm = 0.0370
-- Starting training on experience 64 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0068
	data_grads_norm = 2.3407
	new_data_grads_norm = 3.9418
	old_data_grads_norm = 3.3106
	sim_grads_norm = -0.1570
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5398
	data_grads_norm = 3.7251
	new_data_grads_norm = 4.3887
	old_data_grads_norm = 4.9890
	sim_grads_norm = 0.0111
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0357
	data_grads_norm = 2.6035
	new_data_grads_norm = 5.0652
	old_data_grads_norm = 2.3958
	sim_grads_norm = 0.1512
-- Starting training on experience 65 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0192
	data_grads_norm = 2.8257
	new_data_grads_norm = 4.4056
	old_data_grads_norm = 2.8347
	sim_grads_norm = 0.0677
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1413
	data_grads_norm = 3.6858
	new_data_grads_norm = 4.5953
	old_data_grads_norm = 4.2376
	sim_grads_norm = 0.2518
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2338
	data_grads_norm = 2.7284
	new_data_grads_norm = 4.3439
	old_data_grads_norm = 3.9167
	sim_grads_norm = 0.0247
-- Starting training on experience 66 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1359
	data_grads_norm = 2.4949
	new_data_grads_norm = 3.5199
	old_data_grads_norm = 3.4670
	sim_grads_norm = -0.1090
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1333
	data_grads_norm = 2.8148
	new_data_grads_norm = 3.7755
	old_data_grads_norm = 2.9725
	sim_grads_norm = 0.0908
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0884
	data_grads_norm = 2.6279
	new_data_grads_norm = 3.6649
	old_data_grads_norm = 2.5272
	sim_grads_norm = 0.0941
-- Starting training on experience 67 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8581
	data_grads_norm = 2.8281
	new_data_grads_norm = 4.2893
	old_data_grads_norm = 3.6831
	sim_grads_norm = -0.0523
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0701
	data_grads_norm = 3.1268
	new_data_grads_norm = 6.1716
	old_data_grads_norm = 4.2097
	sim_grads_norm = 0.0729
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7728
	data_grads_norm = 2.3111
	new_data_grads_norm = 5.0466
	old_data_grads_norm = 2.4688
	sim_grads_norm = -0.0765
-- Starting training on experience 68 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4549
	data_grads_norm = 4.3079
	new_data_grads_norm = 5.3029
	old_data_grads_norm = 2.9596
	sim_grads_norm = 0.0896
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0240
	data_grads_norm = 3.8680
	new_data_grads_norm = 4.9628
	old_data_grads_norm = 3.7053
	sim_grads_norm = 0.1045
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1884
	data_grads_norm = 4.4299
	new_data_grads_norm = 6.3935
	old_data_grads_norm = 3.4124
	sim_grads_norm = 0.3699
-- Starting training on experience 69 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0330
	data_grads_norm = 3.0141
	new_data_grads_norm = 3.9277
	old_data_grads_norm = 4.7883
	sim_grads_norm = 0.2017
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4669
	data_grads_norm = 2.5759
	new_data_grads_norm = 3.3474
	old_data_grads_norm = 3.3141
	sim_grads_norm = 0.2424
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6078
	data_grads_norm = 2.2025
	new_data_grads_norm = 3.4559
	old_data_grads_norm = 3.5844
	sim_grads_norm = -0.0055
-- Starting training on experience 70 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5964
	data_grads_norm = 2.2368
	new_data_grads_norm = 4.2406
	old_data_grads_norm = 2.4089
	sim_grads_norm = 0.0880
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6990
	data_grads_norm = 2.3521
	new_data_grads_norm = 3.5541
	old_data_grads_norm = 3.3890
	sim_grads_norm = -0.0487
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5267
	data_grads_norm = 2.4902
	new_data_grads_norm = 3.5229
	old_data_grads_norm = 3.0375
	sim_grads_norm = 0.1625
-- Starting training on experience 71 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6271
	data_grads_norm = 2.1871
	new_data_grads_norm = 3.4793
	old_data_grads_norm = 2.6258
	sim_grads_norm = -0.0082
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3934
	data_grads_norm = 1.6983
	new_data_grads_norm = 3.6366
	old_data_grads_norm = 1.6756
	sim_grads_norm = -0.0446
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9306
	data_grads_norm = 2.4927
	new_data_grads_norm = 3.8981
	old_data_grads_norm = 3.2958
	sim_grads_norm = 0.0313
-- Starting training on experience 72 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8895
	data_grads_norm = 2.9745
	new_data_grads_norm = 3.9818
	old_data_grads_norm = 4.8394
	sim_grads_norm = -0.0074
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2069
	data_grads_norm = 2.9918
	new_data_grads_norm = 3.7016
	old_data_grads_norm = 4.2655
	sim_grads_norm = 0.2988
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7970
	data_grads_norm = 2.2846
	new_data_grads_norm = 3.5150
	old_data_grads_norm = 3.7275
	sim_grads_norm = 0.2100
-- Starting training on experience 73 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7946
	data_grads_norm = 2.1668
	new_data_grads_norm = 3.2047
	old_data_grads_norm = 2.4400
	sim_grads_norm = 0.0834
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7898
	data_grads_norm = 2.2013
	new_data_grads_norm = 3.1045
	old_data_grads_norm = 3.4022
	sim_grads_norm = -0.0137
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7491
	data_grads_norm = 2.4238
	new_data_grads_norm = 3.7690
	old_data_grads_norm = 2.6106
	sim_grads_norm = 0.1511
-- Starting training on experience 74 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3840
	data_grads_norm = 2.5387
	new_data_grads_norm = 4.4261
	old_data_grads_norm = 3.4992
	sim_grads_norm = -0.0733
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4796
	data_grads_norm = 2.4690
	new_data_grads_norm = 4.3144
	old_data_grads_norm = 2.9745
	sim_grads_norm = -0.0528
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2616
	data_grads_norm = 4.2454
	new_data_grads_norm = 5.1327
	old_data_grads_norm = 5.0560
	sim_grads_norm = 0.2874
-- Starting training on experience 75 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2642
	data_grads_norm = 2.2333
	new_data_grads_norm = 3.3773
	old_data_grads_norm = 2.6513
	sim_grads_norm = 0.2166
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5120
	data_grads_norm = 2.1773
	new_data_grads_norm = 2.5011
	old_data_grads_norm = 3.1466
	sim_grads_norm = -0.0857
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5089
	data_grads_norm = 2.0365
	new_data_grads_norm = 2.6853
	old_data_grads_norm = 3.1684
	sim_grads_norm = -0.1910
-- Starting training on experience 76 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9132
	data_grads_norm = 2.1523
	new_data_grads_norm = 2.9961
	old_data_grads_norm = 3.3727
	sim_grads_norm = -0.0124
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8546
	data_grads_norm = 2.6552
	new_data_grads_norm = 3.1524
	old_data_grads_norm = 4.3428
	sim_grads_norm = 0.0022
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9752
	data_grads_norm = 2.5256
	new_data_grads_norm = 3.5719
	old_data_grads_norm = 2.2172
	sim_grads_norm = 0.1876
-- Starting training on experience 77 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5972
	data_grads_norm = 1.8956
	new_data_grads_norm = 2.6118
	old_data_grads_norm = 3.2317
	sim_grads_norm = -0.1855
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8361
	data_grads_norm = 1.9267
	new_data_grads_norm = 3.2654
	old_data_grads_norm = 2.4319
	sim_grads_norm = 0.0110
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6777
	data_grads_norm = 1.7310
	new_data_grads_norm = 2.9305
	old_data_grads_norm = 2.2561
	sim_grads_norm = -0.1700
-- Starting training on experience 78 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9191
	data_grads_norm = 2.3108
	new_data_grads_norm = 3.8878
	old_data_grads_norm = 2.3124
	sim_grads_norm = 0.1029
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7427
	data_grads_norm = 2.6585
	new_data_grads_norm = 4.1450
	old_data_grads_norm = 3.0864
	sim_grads_norm = 0.1960
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7060
	data_grads_norm = 2.3093
	new_data_grads_norm = 3.6375
	old_data_grads_norm = 2.4450
	sim_grads_norm = 0.2011
-- Starting training on experience 79 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8097
	data_grads_norm = 2.3661
	new_data_grads_norm = 2.9997
	old_data_grads_norm = 3.0396
	sim_grads_norm = 0.2099
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6767
	data_grads_norm = 1.9958
	new_data_grads_norm = 2.8125
	old_data_grads_norm = 2.3127
	sim_grads_norm = 0.2539
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4588
	data_grads_norm = 1.7480
	new_data_grads_norm = 2.4574
	old_data_grads_norm = 2.7128
	sim_grads_norm = -0.0402
-- Starting training on experience 80 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8567
	data_grads_norm = 2.4841
	new_data_grads_norm = 3.7744
	old_data_grads_norm = 2.9215
	sim_grads_norm = 0.1940
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7780
	data_grads_norm = 2.2764
	new_data_grads_norm = 3.5151
	old_data_grads_norm = 2.8968
	sim_grads_norm = -0.1960
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5364
	data_grads_norm = 2.4737
	new_data_grads_norm = 3.5325
	old_data_grads_norm = 2.3447
	sim_grads_norm = 0.1685
-- Starting training on experience 81 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6706
	data_grads_norm = 2.5358
	new_data_grads_norm = 4.6107
	old_data_grads_norm = 2.9730
	sim_grads_norm = -0.1643
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7511
	data_grads_norm = 2.6403
	new_data_grads_norm = 4.7302
	old_data_grads_norm = 2.4581
	sim_grads_norm = -0.0932
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9017
	data_grads_norm = 3.1562
	new_data_grads_norm = 4.9188
	old_data_grads_norm = 2.7732
	sim_grads_norm = 0.3816
-- Starting training on experience 82 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6169
	data_grads_norm = 2.5899
	new_data_grads_norm = 2.6949
	old_data_grads_norm = 2.9962
	sim_grads_norm = 0.3454
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5363
	data_grads_norm = 1.8505
	new_data_grads_norm = 2.5786
	old_data_grads_norm = 2.6622
	sim_grads_norm = -0.0923
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2681
	data_grads_norm = 1.7357
	new_data_grads_norm = 2.5844
	old_data_grads_norm = 2.7502
	sim_grads_norm = -0.0011
-- Starting training on experience 83 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7498
	data_grads_norm = 2.1897
	new_data_grads_norm = 3.5838
	old_data_grads_norm = 3.3690
	sim_grads_norm = -0.1338
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7743
	data_grads_norm = 2.5375
	new_data_grads_norm = 4.1038
	old_data_grads_norm = 2.5146
	sim_grads_norm = 0.1936
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8817
	data_grads_norm = 3.0631
	new_data_grads_norm = 3.8138
	old_data_grads_norm = 3.1301
	sim_grads_norm = 0.4226
-- Starting training on experience 84 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9561
	data_grads_norm = 2.4291
	new_data_grads_norm = 3.0963
	old_data_grads_norm = 3.9562
	sim_grads_norm = 0.0298
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9334
	data_grads_norm = 2.2535
	new_data_grads_norm = 2.7348
	old_data_grads_norm = 2.7879
	sim_grads_norm = 0.1412
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7051
	data_grads_norm = 2.0750
	new_data_grads_norm = 2.9173
	old_data_grads_norm = 2.3959
	sim_grads_norm = 0.1294
-- Starting training on experience 85 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7541
	data_grads_norm = 2.5664
	new_data_grads_norm = 3.6022
	old_data_grads_norm = 3.9083
	sim_grads_norm = -0.2057
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6901
	data_grads_norm = 2.6434
	new_data_grads_norm = 4.4361
	old_data_grads_norm = 2.2307
	sim_grads_norm = 0.0260
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6575
	data_grads_norm = 2.5443
	new_data_grads_norm = 4.4597
	old_data_grads_norm = 2.3585
	sim_grads_norm = -0.2738
-- Starting training on experience 86 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8469
	data_grads_norm = 2.7559
	new_data_grads_norm = 5.4427
	old_data_grads_norm = 3.5236
	sim_grads_norm = 0.1391
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6086
	data_grads_norm = 2.3214
	new_data_grads_norm = 4.2676
	old_data_grads_norm = 1.8375
	sim_grads_norm = -0.0215
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6588
	data_grads_norm = 2.4814
	new_data_grads_norm = 4.1536
	old_data_grads_norm = 2.3920
	sim_grads_norm = 0.1041
-- Starting training on experience 87 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5373
	data_grads_norm = 2.5843
	new_data_grads_norm = 3.9214
	old_data_grads_norm = 2.6297
	sim_grads_norm = 0.1259
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2495
	data_grads_norm = 2.3692
	new_data_grads_norm = 3.8157
	old_data_grads_norm = 3.0979
	sim_grads_norm = 0.1197
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4792
	data_grads_norm = 2.3860
	new_data_grads_norm = 3.6073
	old_data_grads_norm = 2.4135
	sim_grads_norm = 0.1529
-- Starting training on experience 88 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3651
	data_grads_norm = 2.4856
	new_data_grads_norm = 3.2679
	old_data_grads_norm = 5.6069
	sim_grads_norm = -0.2320
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0391
	data_grads_norm = 3.3666
	new_data_grads_norm = 4.5950
	old_data_grads_norm = 3.2304
	sim_grads_norm = 0.5539
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5063
	data_grads_norm = 2.3679
	new_data_grads_norm = 3.4793
	old_data_grads_norm = 2.4214
	sim_grads_norm = 0.1838
-- Starting training on experience 89 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5354
	data_grads_norm = 2.1041
	new_data_grads_norm = 3.2503
	old_data_grads_norm = 2.4772
	sim_grads_norm = -0.0486
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6245
	data_grads_norm = 2.0865
	new_data_grads_norm = 3.3114
	old_data_grads_norm = 2.9892
	sim_grads_norm = 0.1440
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6971
	data_grads_norm = 2.3528
	new_data_grads_norm = 3.4867
	old_data_grads_norm = 3.2983
	sim_grads_norm = 0.0051
-- Starting training on experience 90 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5195
	data_grads_norm = 2.5612
	new_data_grads_norm = 3.8419
	old_data_grads_norm = 3.1629
	sim_grads_norm = 0.0323
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5615
	data_grads_norm = 2.7415
	new_data_grads_norm = 4.5819
	old_data_grads_norm = 3.0665
	sim_grads_norm = 0.0624
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5928
	data_grads_norm = 2.7269
	new_data_grads_norm = 4.3761
	old_data_grads_norm = 3.9365
	sim_grads_norm = 0.1881
-- Starting training on experience 91 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3798
	data_grads_norm = 2.1856
	new_data_grads_norm = 4.2860
	old_data_grads_norm = 3.0766
	sim_grads_norm = -0.1347
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7154
	data_grads_norm = 2.7155
	new_data_grads_norm = 3.9071
	old_data_grads_norm = 3.2315
	sim_grads_norm = 0.1365
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7102
	data_grads_norm = 2.3928
	new_data_grads_norm = 4.4203
	old_data_grads_norm = 2.8261
	sim_grads_norm = 0.0873
-- Starting training on experience 92 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6845
	data_grads_norm = 3.2405
	new_data_grads_norm = 5.0906
	old_data_grads_norm = 4.5443
	sim_grads_norm = -0.0279
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8595
	data_grads_norm = 2.8115
	new_data_grads_norm = 4.3239
	old_data_grads_norm = 2.7967
	sim_grads_norm = 0.1173
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5732
	data_grads_norm = 2.2041
	new_data_grads_norm = 3.3509
	old_data_grads_norm = 2.8206
	sim_grads_norm = -0.0970
-- Starting training on experience 93 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4177
	data_grads_norm = 2.8737
	new_data_grads_norm = 4.1524
	old_data_grads_norm = 3.3176
	sim_grads_norm = 0.0384
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4741
	data_grads_norm = 2.6276
	new_data_grads_norm = 4.2488
	old_data_grads_norm = 3.1930
	sim_grads_norm = -0.0914
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5812
	data_grads_norm = 2.3763
	new_data_grads_norm = 3.6204
	old_data_grads_norm = 2.8616
	sim_grads_norm = -0.1116
-- Starting training on experience 94 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1388
	data_grads_norm = 2.8184
	new_data_grads_norm = 4.1561
	old_data_grads_norm = 2.9232
	sim_grads_norm = 0.2803
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5915
	data_grads_norm = 2.2337
	new_data_grads_norm = 3.9657
	old_data_grads_norm = 3.0429
	sim_grads_norm = 0.0075
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7387
	data_grads_norm = 2.2978
	new_data_grads_norm = 4.2298
	old_data_grads_norm = 2.5673
	sim_grads_norm = 0.1752
-- Starting training on experience 95 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8220
	data_grads_norm = 2.3526
	new_data_grads_norm = 3.9592
	old_data_grads_norm = 3.0196
	sim_grads_norm = 0.0827
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8010
	data_grads_norm = 2.4780
	new_data_grads_norm = 3.6455
	old_data_grads_norm = 3.1629
	sim_grads_norm = 0.0893
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4242
	data_grads_norm = 2.3601
	new_data_grads_norm = 3.4032
	old_data_grads_norm = 2.8827
	sim_grads_norm = 0.1540
-- Starting training on experience 96 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3978
	data_grads_norm = 1.9812
	new_data_grads_norm = 2.9877
	old_data_grads_norm = 2.7879
	sim_grads_norm = 0.0985
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5194
	data_grads_norm = 2.6322
	new_data_grads_norm = 2.8181
	old_data_grads_norm = 4.9451
	sim_grads_norm = -0.1664
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9903
	data_grads_norm = 4.0053
	new_data_grads_norm = 3.5817
	old_data_grads_norm = 4.6247
	sim_grads_norm = 0.2039
-- Starting training on experience 97 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0154
	data_grads_norm = 2.9608
	new_data_grads_norm = 3.8480
	old_data_grads_norm = 3.2075
	sim_grads_norm = 0.3311
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6056
	data_grads_norm = 2.0658
	new_data_grads_norm = 3.5017
	old_data_grads_norm = 2.6301
	sim_grads_norm = -0.0397
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7685
	data_grads_norm = 2.4238
	new_data_grads_norm = 4.0050
	old_data_grads_norm = 2.9105
	sim_grads_norm = 0.0992
-- Starting training on experience 98 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2718
	data_grads_norm = 2.1271
	new_data_grads_norm = 3.4755
	old_data_grads_norm = 2.4517
	sim_grads_norm = -0.0047
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3993
	data_grads_norm = 2.0209
	new_data_grads_norm = 3.4484
	old_data_grads_norm = 2.4825
	sim_grads_norm = -0.1131
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1923
	data_grads_norm = 1.8222
	new_data_grads_norm = 4.1057
	old_data_grads_norm = 2.2574
	sim_grads_norm = -0.2178
-- Starting training on experience 99 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7145
	data_grads_norm = 2.9409
	new_data_grads_norm = 4.7631
	old_data_grads_norm = 2.9672
	sim_grads_norm = 0.0422
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4680
	data_grads_norm = 3.3224
	new_data_grads_norm = 5.5847
	old_data_grads_norm = 3.2359
	sim_grads_norm = 0.1504
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4371
	data_grads_norm = 2.1412
	new_data_grads_norm = 6.5954
	old_data_grads_norm = 3.7273
	sim_grads_norm = 0.0228
-- Starting training on experience 100 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2777
	data_grads_norm = 3.0551
	new_data_grads_norm = 4.8380
	old_data_grads_norm = 2.9108
	sim_grads_norm = 0.2374
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6003
	data_grads_norm = 2.5248
	new_data_grads_norm = 4.3666
	old_data_grads_norm = 2.9676
	sim_grads_norm = -0.0032
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4301
	data_grads_norm = 2.4330
	new_data_grads_norm = 4.4318
	old_data_grads_norm = 4.2234
	sim_grads_norm = -0.2404
-- Starting training on experience 101 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8730
	data_grads_norm = 3.0903
	new_data_grads_norm = 2.8714
	old_data_grads_norm = 4.9338
	sim_grads_norm = 0.1639
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5698
	data_grads_norm = 2.1818
	new_data_grads_norm = 2.8302
	old_data_grads_norm = 3.5504
	sim_grads_norm = 0.0139
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4034
	data_grads_norm = 2.2423
	new_data_grads_norm = 2.6363
	old_data_grads_norm = 2.6920
	sim_grads_norm = 0.0744
-- Starting training on experience 102 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5044
	data_grads_norm = 2.1115
	new_data_grads_norm = 2.7221
	old_data_grads_norm = 3.1729
	sim_grads_norm = -0.0262
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1770
	data_grads_norm = 1.9025
	new_data_grads_norm = 2.8518
	old_data_grads_norm = 2.1349
	sim_grads_norm = 0.1268
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3775
	data_grads_norm = 2.3061
	new_data_grads_norm = 3.1677
	old_data_grads_norm = 4.4990
	sim_grads_norm = 0.1535
-- Starting training on experience 103 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5664
	data_grads_norm = 2.6491
	new_data_grads_norm = 2.9920
	old_data_grads_norm = 3.7805
	sim_grads_norm = 0.1694
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1870
	data_grads_norm = 1.9224
	new_data_grads_norm = 2.9555
	old_data_grads_norm = 2.8022
	sim_grads_norm = -0.0321
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4324
	data_grads_norm = 2.2651
	new_data_grads_norm = 3.1645
	old_data_grads_norm = 3.8614
	sim_grads_norm = -0.0414
-- Starting training on experience 104 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5397
	data_grads_norm = 2.2790
	new_data_grads_norm = 3.7507
	old_data_grads_norm = 2.6917
	sim_grads_norm = 0.1177
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3839
	data_grads_norm = 2.4398
	new_data_grads_norm = 3.7836
	old_data_grads_norm = 2.9777
	sim_grads_norm = 0.0835
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4528
	data_grads_norm = 2.3189
	new_data_grads_norm = 3.6237
	old_data_grads_norm = 2.6877
	sim_grads_norm = 0.1881
-- Starting training on experience 105 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7877
	data_grads_norm = 2.4872
	new_data_grads_norm = 3.4480
	old_data_grads_norm = 3.6961
	sim_grads_norm = -0.0712
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7765
	data_grads_norm = 2.3098
	new_data_grads_norm = 3.9120
	old_data_grads_norm = 3.4670
	sim_grads_norm = -0.2465
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0573
	data_grads_norm = 2.9809
	new_data_grads_norm = 4.3335
	old_data_grads_norm = 3.3004
	sim_grads_norm = 0.2134
-- Starting training on experience 106 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4833
	data_grads_norm = 2.1899
	new_data_grads_norm = 3.9188
	old_data_grads_norm = 2.0913
	sim_grads_norm = -0.0607
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6108
	data_grads_norm = 3.0387
	new_data_grads_norm = 5.1677
	old_data_grads_norm = 3.1978
	sim_grads_norm = 0.1705
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7657
	data_grads_norm = 2.8264
	new_data_grads_norm = 3.8092
	old_data_grads_norm = 3.1752
	sim_grads_norm = 0.1514
-- Starting training on experience 107 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3390
	data_grads_norm = 2.0087
	new_data_grads_norm = 4.6150
	old_data_grads_norm = 2.2128
	sim_grads_norm = -0.1560
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7799
	data_grads_norm = 3.0661
	new_data_grads_norm = 4.9672
	old_data_grads_norm = 3.9322
	sim_grads_norm = 0.0311
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7487
	data_grads_norm = 2.9817
	new_data_grads_norm = 5.2025
	old_data_grads_norm = 3.1533
	sim_grads_norm = 0.1366
-- Starting training on experience 108 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5671
	data_grads_norm = 3.5438
	new_data_grads_norm = 3.8750
	old_data_grads_norm = 3.4743
	sim_grads_norm = -0.0568
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8408
	data_grads_norm = 3.3750
	new_data_grads_norm = 3.7425
	old_data_grads_norm = 3.4302
	sim_grads_norm = 0.3861
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0766
	data_grads_norm = 2.4429
	new_data_grads_norm = 3.7458
	old_data_grads_norm = 3.0856
	sim_grads_norm = -0.0163
-- Starting training on experience 109 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4463
	data_grads_norm = 2.8661
	new_data_grads_norm = 5.3005
	old_data_grads_norm = 3.9201
	sim_grads_norm = 0.0551
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3815
	data_grads_norm = 2.4020
	new_data_grads_norm = 3.4188
	old_data_grads_norm = 3.1634
	sim_grads_norm = -0.0940
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4464
	data_grads_norm = 2.1487
	new_data_grads_norm = 3.6406
	old_data_grads_norm = 3.2899
	sim_grads_norm = -0.0823
-- Starting training on experience 110 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6479
	data_grads_norm = 3.6282
	new_data_grads_norm = 5.3151
	old_data_grads_norm = 5.8510
	sim_grads_norm = -0.0485
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8655
	data_grads_norm = 3.5524
	new_data_grads_norm = 5.4772
	old_data_grads_norm = 3.1579
	sim_grads_norm = 0.0870
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1301
	data_grads_norm = 4.8000
	new_data_grads_norm = 6.9489
	old_data_grads_norm = 4.5397
	sim_grads_norm = 0.0842
-- Starting training on experience 111 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6096
	data_grads_norm = 2.8723
	new_data_grads_norm = 3.5552
	old_data_grads_norm = 2.8036
	sim_grads_norm = -0.1157
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5620
	data_grads_norm = 2.4651
	new_data_grads_norm = 4.0715
	old_data_grads_norm = 2.4207
	sim_grads_norm = 0.1531
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4785
	data_grads_norm = 3.1480
	new_data_grads_norm = 3.5280
	old_data_grads_norm = 5.8327
	sim_grads_norm = 0.2916
-- Starting training on experience 112 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4280
	data_grads_norm = 2.2760
	new_data_grads_norm = 3.4472
	old_data_grads_norm = 3.6079
	sim_grads_norm = 0.0105
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4220
	data_grads_norm = 2.4682
	new_data_grads_norm = 3.3120
	old_data_grads_norm = 3.4347
	sim_grads_norm = -0.1632
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7341
	data_grads_norm = 2.9321
	new_data_grads_norm = 3.8874
	old_data_grads_norm = 3.9199
	sim_grads_norm = 0.0502
-- Starting training on experience 113 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5547
	data_grads_norm = 2.9228
	new_data_grads_norm = 3.9719
	old_data_grads_norm = 3.3459
	sim_grads_norm = 0.2912
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4138
	data_grads_norm = 2.6353
	new_data_grads_norm = 3.7636
	old_data_grads_norm = 4.1371
	sim_grads_norm = -0.0407
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9939
	data_grads_norm = 3.6161
	new_data_grads_norm = 4.8162
	old_data_grads_norm = 4.5276
	sim_grads_norm = 0.1094
-- Starting training on experience 114 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5613
	data_grads_norm = 2.9650
	new_data_grads_norm = 3.9361
	old_data_grads_norm = 3.6737
	sim_grads_norm = 0.2385
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5129
	data_grads_norm = 2.5698
	new_data_grads_norm = 3.5677
	old_data_grads_norm = 4.1369
	sim_grads_norm = -0.1204
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4554
	data_grads_norm = 2.5952
	new_data_grads_norm = 4.6821
	old_data_grads_norm = 2.6076
	sim_grads_norm = 0.0771
-- Starting training on experience 115 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8639
	data_grads_norm = 2.0554
	new_data_grads_norm = 2.8662
	old_data_grads_norm = 2.7167
	sim_grads_norm = -0.0234
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5164
	data_grads_norm = 1.7383
	new_data_grads_norm = 2.9141
	old_data_grads_norm = 1.8320
	sim_grads_norm = 0.1479
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7328
	data_grads_norm = 2.0100
	new_data_grads_norm = 2.8408
	old_data_grads_norm = 2.7830
	sim_grads_norm = 0.1648
-- Starting training on experience 116 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5786
	data_grads_norm = 1.9011
	new_data_grads_norm = 2.8976
	old_data_grads_norm = 3.1184
	sim_grads_norm = -0.1294
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8427
	data_grads_norm = 2.1604
	new_data_grads_norm = 3.1872
	old_data_grads_norm = 2.8792
	sim_grads_norm = 0.1280
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5365
	data_grads_norm = 1.8973
	new_data_grads_norm = 3.0207
	old_data_grads_norm = 2.0321
	sim_grads_norm = 0.2123
-- Starting training on experience 117 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5211
	data_grads_norm = 2.1666
	new_data_grads_norm = 3.5352
	old_data_grads_norm = 2.4495
	sim_grads_norm = 0.1139
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6377
	data_grads_norm = 2.9170
	new_data_grads_norm = 3.7665
	old_data_grads_norm = 4.4235
	sim_grads_norm = 0.0305
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7623
	data_grads_norm = 2.7377
	new_data_grads_norm = 3.6758
	old_data_grads_norm = 3.0354
	sim_grads_norm = 0.1168
-- Starting training on experience 118 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6437
	data_grads_norm = 2.3064
	new_data_grads_norm = 3.4756
	old_data_grads_norm = 3.4403
	sim_grads_norm = 0.0325
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4912
	data_grads_norm = 2.1863
	new_data_grads_norm = 3.5780
	old_data_grads_norm = 2.7306
	sim_grads_norm = -0.1144
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5863
	data_grads_norm = 2.2596
	new_data_grads_norm = 3.7337
	old_data_grads_norm = 2.9162
	sim_grads_norm = -0.0039
-- Starting training on experience 119 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5626
	data_grads_norm = 2.4504
	new_data_grads_norm = 3.7396
	old_data_grads_norm = 3.4291
	sim_grads_norm = 0.0276
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5673
	data_grads_norm = 2.3310
	new_data_grads_norm = 3.6348
	old_data_grads_norm = 3.6767
	sim_grads_norm = 0.0026
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6541
	data_grads_norm = 2.2161
	new_data_grads_norm = 4.1147
	old_data_grads_norm = 2.5159
	sim_grads_norm = 0.1156
-- Starting training on experience 120 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6345
	data_grads_norm = 3.0189
	new_data_grads_norm = 3.6052
	old_data_grads_norm = 3.7900
	sim_grads_norm = 0.2907
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3583
	data_grads_norm = 2.6960
	new_data_grads_norm = 3.3605
	old_data_grads_norm = 3.4260
	sim_grads_norm = 0.0331
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5995
	data_grads_norm = 3.5231
	new_data_grads_norm = 4.7427
	old_data_grads_norm = 3.5267
	sim_grads_norm = 0.2546
-- Starting training on experience 121 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2095
	data_grads_norm = 3.2310
	new_data_grads_norm = 2.3967
	old_data_grads_norm = 3.8657
	sim_grads_norm = -0.0052
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1122
	data_grads_norm = 1.7080
	new_data_grads_norm = 1.9837
	old_data_grads_norm = 2.3967
	sim_grads_norm = 0.0318
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2740
	data_grads_norm = 2.0606
	new_data_grads_norm = 2.1484
	old_data_grads_norm = 3.6154
	sim_grads_norm = -0.0120
-- Starting training on experience 122 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8933
	data_grads_norm = 2.5566
	new_data_grads_norm = 3.7973
	old_data_grads_norm = 3.9187
	sim_grads_norm = -0.0702
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1957
	data_grads_norm = 2.1253
	new_data_grads_norm = 3.6711
	old_data_grads_norm = 2.1955
	sim_grads_norm = -0.0722
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4601
	data_grads_norm = 2.1921
	new_data_grads_norm = 3.4074
	old_data_grads_norm = 2.5213
	sim_grads_norm = -0.0245
-- Starting training on experience 123 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7579
	data_grads_norm = 2.2934
	new_data_grads_norm = 4.1210
	old_data_grads_norm = 2.7753
	sim_grads_norm = 0.0324
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7459
	data_grads_norm = 2.6318
	new_data_grads_norm = 4.0129
	old_data_grads_norm = 3.3566
	sim_grads_norm = 0.1855
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6718
	data_grads_norm = 2.2956
	new_data_grads_norm = 4.2715
	old_data_grads_norm = 2.7449
	sim_grads_norm = 0.1344
-- Starting training on experience 124 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4772
	data_grads_norm = 2.3182
	new_data_grads_norm = 3.3815
	old_data_grads_norm = 2.4750
	sim_grads_norm = 0.0999
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3816
	data_grads_norm = 1.9428
	new_data_grads_norm = 3.1574
	old_data_grads_norm = 3.2183
	sim_grads_norm = -0.2001
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5790
	data_grads_norm = 2.8249
	new_data_grads_norm = 3.5719
	old_data_grads_norm = 2.9076
	sim_grads_norm = 0.1434
-- Starting training on experience 125 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5521
	data_grads_norm = 2.4307
	new_data_grads_norm = 4.6571
	old_data_grads_norm = 2.5556
	sim_grads_norm = -0.1242
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7436
	data_grads_norm = 3.0386
	new_data_grads_norm = 4.1932
	old_data_grads_norm = 3.6312
	sim_grads_norm = 0.1301
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9070
	data_grads_norm = 2.5062
	new_data_grads_norm = 3.9740
	old_data_grads_norm = 3.5636
	sim_grads_norm = -0.1133
-- Starting training on experience 126 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6254
	data_grads_norm = 2.6289
	new_data_grads_norm = 3.7544
	old_data_grads_norm = 2.6212
	sim_grads_norm = 0.1347
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4306
	data_grads_norm = 1.9412
	new_data_grads_norm = 3.5632
	old_data_grads_norm = 2.6754
	sim_grads_norm = -0.2630
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0116
	data_grads_norm = 2.5938
	new_data_grads_norm = 3.9932
	old_data_grads_norm = 3.8915
	sim_grads_norm = -0.0055
-- Starting training on experience 127 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9443
	data_grads_norm = 3.1356
	new_data_grads_norm = 5.0185
	old_data_grads_norm = 3.8876
	sim_grads_norm = 0.0353
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0065
	data_grads_norm = 3.2948
	new_data_grads_norm = 5.4045
	old_data_grads_norm = 3.9608
	sim_grads_norm = 0.2588
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8477
	data_grads_norm = 3.1200
	new_data_grads_norm = 4.7940
	old_data_grads_norm = 2.7757
	sim_grads_norm = 0.1804
-- Starting training on experience 128 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4230
	data_grads_norm = 2.3662
	new_data_grads_norm = 3.8275
	old_data_grads_norm = 2.2543
	sim_grads_norm = 0.1782
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3743
	data_grads_norm = 2.2864
	new_data_grads_norm = 3.2691
	old_data_grads_norm = 2.3585
	sim_grads_norm = 0.1699
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6288
	data_grads_norm = 2.1349
	new_data_grads_norm = 3.5736
	old_data_grads_norm = 3.2875
	sim_grads_norm = -0.0113
-- Starting training on experience 129 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3648
	data_grads_norm = 1.8959
	new_data_grads_norm = 2.8206
	old_data_grads_norm = 3.1430
	sim_grads_norm = 0.0359
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3916
	data_grads_norm = 2.5993
	new_data_grads_norm = 3.2517
	old_data_grads_norm = 3.6512
	sim_grads_norm = 0.1093
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4854
	data_grads_norm = 2.6056
	new_data_grads_norm = 3.3186
	old_data_grads_norm = 3.1979
	sim_grads_norm = 0.1750
-- Starting training on experience 130 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2976
	data_grads_norm = 2.9761
	new_data_grads_norm = 3.4954
	old_data_grads_norm = 4.3795
	sim_grads_norm = 0.4544
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2536
	data_grads_norm = 2.0387
	new_data_grads_norm = 2.5367
	old_data_grads_norm = 3.9058
	sim_grads_norm = -0.1429
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2461
	data_grads_norm = 2.5563
	new_data_grads_norm = 3.5716
	old_data_grads_norm = 2.8491
	sim_grads_norm = 0.1199
-- Starting training on experience 131 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6736
	data_grads_norm = 2.3643
	new_data_grads_norm = 5.0866
	old_data_grads_norm = 3.0851
	sim_grads_norm = 0.0809
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4543
	data_grads_norm = 2.3148
	new_data_grads_norm = 3.9920
	old_data_grads_norm = 2.5624
	sim_grads_norm = -0.0637
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5819
	data_grads_norm = 2.3702
	new_data_grads_norm = 4.4317
	old_data_grads_norm = 2.7545
	sim_grads_norm = 0.0947
-- Starting training on experience 132 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3023
	data_grads_norm = 2.5237
	new_data_grads_norm = 3.5804
	old_data_grads_norm = 2.3238
	sim_grads_norm = -0.1353
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6054
	data_grads_norm = 2.3055
	new_data_grads_norm = 4.0431
	old_data_grads_norm = 2.6611
	sim_grads_norm = 0.1751
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8047
	data_grads_norm = 3.5129
	new_data_grads_norm = 4.4939
	old_data_grads_norm = 3.9534
	sim_grads_norm = 0.2444
-- Starting training on experience 133 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5268
	data_grads_norm = 3.2403
	new_data_grads_norm = 3.1808
	old_data_grads_norm = 5.3353
	sim_grads_norm = 0.0356
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4146
	data_grads_norm = 3.0689
	new_data_grads_norm = 3.7389
	old_data_grads_norm = 3.9676
	sim_grads_norm = 0.3953
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9672
	data_grads_norm = 2.2317
	new_data_grads_norm = 3.0011
	old_data_grads_norm = 3.2539
	sim_grads_norm = 0.0093
-- Starting training on experience 134 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5409
	data_grads_norm = 2.5062
	new_data_grads_norm = 4.1708
	old_data_grads_norm = 3.0145
	sim_grads_norm = 0.0229
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3339
	data_grads_norm = 2.9201
	new_data_grads_norm = 4.7620
	old_data_grads_norm = 3.2948
	sim_grads_norm = -0.0731
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4687
	data_grads_norm = 2.6808
	new_data_grads_norm = 4.7835
	old_data_grads_norm = 3.5172
	sim_grads_norm = 0.0907
-- Starting training on experience 135 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6406
	data_grads_norm = 2.3553
	new_data_grads_norm = 4.0444
	old_data_grads_norm = 2.7989
	sim_grads_norm = -0.1310
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4258
	data_grads_norm = 4.0337
	new_data_grads_norm = 4.6610
	old_data_grads_norm = 5.3911
	sim_grads_norm = 0.2520
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6118
	data_grads_norm = 2.8542
	new_data_grads_norm = 3.9604
	old_data_grads_norm = 3.6975
	sim_grads_norm = 0.1317
-- Starting training on experience 136 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8016
	data_grads_norm = 3.5375
	new_data_grads_norm = 3.3663
	old_data_grads_norm = 4.4284
	sim_grads_norm = 0.3722
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2767
	data_grads_norm = 2.8006
	new_data_grads_norm = 2.5996
	old_data_grads_norm = 5.1356
	sim_grads_norm = 0.2042
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2904
	data_grads_norm = 2.1877
	new_data_grads_norm = 2.4528
	old_data_grads_norm = 5.3318
	sim_grads_norm = 0.0240
-- Starting training on experience 137 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9650
	data_grads_norm = 3.4199
	new_data_grads_norm = 5.1500
	old_data_grads_norm = 3.7381
	sim_grads_norm = 0.2074
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6771
	data_grads_norm = 2.2833
	new_data_grads_norm = 4.4641
	old_data_grads_norm = 2.8847
	sim_grads_norm = -0.0906
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0162
	data_grads_norm = 2.9462
	new_data_grads_norm = 4.5705
	old_data_grads_norm = 3.0488
	sim_grads_norm = 0.1116
-- Starting training on experience 138 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6562
	data_grads_norm = 2.4989
	new_data_grads_norm = 3.6741
	old_data_grads_norm = 2.8827
	sim_grads_norm = 0.1084
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5660
	data_grads_norm = 2.3782
	new_data_grads_norm = 4.0168
	old_data_grads_norm = 2.8360
	sim_grads_norm = -0.0347
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7393
	data_grads_norm = 2.4775
	new_data_grads_norm = 3.9243
	old_data_grads_norm = 3.1043
	sim_grads_norm = -0.0015
-- Starting training on experience 139 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4191
	data_grads_norm = 2.3497
	new_data_grads_norm = 3.4401
	old_data_grads_norm = 2.9546
	sim_grads_norm = 0.0005
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6974
	data_grads_norm = 2.5869
	new_data_grads_norm = 3.5796
	old_data_grads_norm = 3.1879
	sim_grads_norm = 0.1865
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7163
	data_grads_norm = 2.3293
	new_data_grads_norm = 3.6363
	old_data_grads_norm = 3.1054
	sim_grads_norm = 0.1288
-- Starting training on experience 140 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7921
	data_grads_norm = 2.6484
	new_data_grads_norm = 4.1215
	old_data_grads_norm = 2.6719
	sim_grads_norm = 0.2274
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9106
	data_grads_norm = 2.8581
	new_data_grads_norm = 3.8053
	old_data_grads_norm = 3.7011
	sim_grads_norm = 0.0694
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5631
	data_grads_norm = 2.1803
	new_data_grads_norm = 3.0974
	old_data_grads_norm = 2.4556
	sim_grads_norm = -0.1099
-- Starting training on experience 141 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0230
	data_grads_norm = 2.5352
	new_data_grads_norm = 3.6724
	old_data_grads_norm = 3.8654
	sim_grads_norm = -0.0285
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6190
	data_grads_norm = 2.5133
	new_data_grads_norm = 3.7308
	old_data_grads_norm = 3.1294
	sim_grads_norm = 0.1710
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8987
	data_grads_norm = 2.7240
	new_data_grads_norm = 3.6596
	old_data_grads_norm = 2.6499
	sim_grads_norm = 0.2875
-- Starting training on experience 142 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1249
	data_grads_norm = 2.5933
	new_data_grads_norm = 4.5842
	old_data_grads_norm = 2.8363
	sim_grads_norm = 0.0160
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0350
	data_grads_norm = 2.8312
	new_data_grads_norm = 4.8914
	old_data_grads_norm = 3.7126
	sim_grads_norm = -0.0525
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8540
	data_grads_norm = 2.8628
	new_data_grads_norm = 4.6330
	old_data_grads_norm = 2.9741
	sim_grads_norm = 0.0570
-- Starting training on experience 143 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7345
	data_grads_norm = 2.7809
	new_data_grads_norm = 4.5544
	old_data_grads_norm = 2.7807
	sim_grads_norm = -0.0567
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1052
	data_grads_norm = 3.2530
	new_data_grads_norm = 4.9311
	old_data_grads_norm = 3.5292
	sim_grads_norm = 0.2127
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6857
	data_grads_norm = 3.2132
	new_data_grads_norm = 4.7166
	old_data_grads_norm = 3.1133
	sim_grads_norm = 0.3136
-- Starting training on experience 144 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2716
	data_grads_norm = 2.1944
	new_data_grads_norm = 3.2214
	old_data_grads_norm = 4.4790
	sim_grads_norm = -0.0945
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2918
	data_grads_norm = 2.5040
	new_data_grads_norm = 3.9114
	old_data_grads_norm = 3.3140
	sim_grads_norm = 0.1126
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0412
	data_grads_norm = 1.6679
	new_data_grads_norm = 3.4934
	old_data_grads_norm = 2.5754
	sim_grads_norm = -0.2754
-- Starting training on experience 145 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5906
	data_grads_norm = 2.8076
	new_data_grads_norm = 5.0645
	old_data_grads_norm = 2.7543
	sim_grads_norm = 0.1336
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5811
	data_grads_norm = 2.3657
	new_data_grads_norm = 5.2872
	old_data_grads_norm = 1.8313
	sim_grads_norm = -0.0470
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5034
	data_grads_norm = 3.1595
	new_data_grads_norm = 5.0777
	old_data_grads_norm = 2.5084
	sim_grads_norm = 0.3321
-- Starting training on experience 146 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6115
	data_grads_norm = 3.2575
	new_data_grads_norm = 5.2414
	old_data_grads_norm = 2.9523
	sim_grads_norm = 0.1114
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5498
	data_grads_norm = 3.0705
	new_data_grads_norm = 4.9116
	old_data_grads_norm = 3.0378
	sim_grads_norm = 0.1503
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4028
	data_grads_norm = 2.6399
	new_data_grads_norm = 4.1919
	old_data_grads_norm = 3.6471
	sim_grads_norm = -0.1708
-- Starting training on experience 147 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4786
	data_grads_norm = 2.8268
	new_data_grads_norm = 5.1231
	old_data_grads_norm = 2.8576
	sim_grads_norm = 0.0588
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7886
	data_grads_norm = 2.9679
	new_data_grads_norm = 5.2890
	old_data_grads_norm = 4.2135
	sim_grads_norm = 0.0808
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5654
	data_grads_norm = 3.0934
	new_data_grads_norm = 4.7294
	old_data_grads_norm = 3.1382
	sim_grads_norm = -0.1086
-- Starting training on experience 148 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1383
	data_grads_norm = 3.7789
	new_data_grads_norm = 5.4874
	old_data_grads_norm = 4.2751
	sim_grads_norm = 0.0759
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0432
	data_grads_norm = 2.9439
	new_data_grads_norm = 3.9839
	old_data_grads_norm = 2.8417
	sim_grads_norm = 0.3077
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6498
	data_grads_norm = 3.0214
	new_data_grads_norm = 4.5488
	old_data_grads_norm = 2.9268
	sim_grads_norm = 0.1198
-- Starting training on experience 149 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5779
	data_grads_norm = 2.4696
	new_data_grads_norm = 3.4395
	old_data_grads_norm = 3.7644
	sim_grads_norm = 0.0902
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6715
	data_grads_norm = 3.0656
	new_data_grads_norm = 3.6765
	old_data_grads_norm = 3.6767
	sim_grads_norm = 0.1169
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6812
	data_grads_norm = 2.2024
	new_data_grads_norm = 3.3074
	old_data_grads_norm = 3.0184
	sim_grads_norm = -0.0091
-- Starting training on experience 150 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5583
	data_grads_norm = 2.4730
	new_data_grads_norm = 4.3608
	old_data_grads_norm = 2.4098
	sim_grads_norm = 0.1475
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4474
	data_grads_norm = 2.3320
	new_data_grads_norm = 3.7238
	old_data_grads_norm = 2.4581
	sim_grads_norm = 0.0510
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4796
	data_grads_norm = 2.4100
	new_data_grads_norm = 4.6920
	old_data_grads_norm = 3.1102
	sim_grads_norm = 0.1707
-- Starting training on experience 151 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2978
	data_grads_norm = 2.1210
	new_data_grads_norm = 3.2452
	old_data_grads_norm = 3.1214
	sim_grads_norm = -0.1299
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3209
	data_grads_norm = 2.3299
	new_data_grads_norm = 3.8907
	old_data_grads_norm = 2.4415
	sim_grads_norm = 0.2719
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6628
	data_grads_norm = 2.8903
	new_data_grads_norm = 3.5568
	old_data_grads_norm = 4.2735
	sim_grads_norm = 0.0338
-- Starting training on experience 152 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6141
	data_grads_norm = 2.5651
	new_data_grads_norm = 3.8374
	old_data_grads_norm = 3.2218
	sim_grads_norm = -0.1607
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3294
	data_grads_norm = 2.0024
	new_data_grads_norm = 3.8848
	old_data_grads_norm = 2.2204
	sim_grads_norm = -0.1334
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7068
	data_grads_norm = 2.5664
	new_data_grads_norm = 4.9232
	old_data_grads_norm = 2.5939
	sim_grads_norm = 0.0284
-- Starting training on experience 153 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5208
	data_grads_norm = 2.8542
	new_data_grads_norm = 3.8323
	old_data_grads_norm = 3.8437
	sim_grads_norm = -0.1011
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9915
	data_grads_norm = 2.6915
	new_data_grads_norm = 3.7994
	old_data_grads_norm = 4.6117
	sim_grads_norm = 0.0425
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6700
	data_grads_norm = 2.5234
	new_data_grads_norm = 4.2130
	old_data_grads_norm = 2.8515
	sim_grads_norm = 0.0060
-- Starting training on experience 154 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3899
	data_grads_norm = 2.1477
	new_data_grads_norm = 2.9438
	old_data_grads_norm = 2.6858
	sim_grads_norm = 0.0181
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2469
	data_grads_norm = 2.0089
	new_data_grads_norm = 3.4720
	old_data_grads_norm = 2.3609
	sim_grads_norm = 0.0417
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2698
	data_grads_norm = 1.8993
	new_data_grads_norm = 3.4737
	old_data_grads_norm = 2.2545
	sim_grads_norm = -0.1073
-- Starting training on experience 155 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6476
	data_grads_norm = 2.2008
	new_data_grads_norm = 2.8339
	old_data_grads_norm = 2.4068
	sim_grads_norm = 0.1463
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7316
	data_grads_norm = 2.2945
	new_data_grads_norm = 3.1179
	old_data_grads_norm = 2.8470
	sim_grads_norm = 0.1978
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6682
	data_grads_norm = 2.7734
	new_data_grads_norm = 2.9347
	old_data_grads_norm = 3.6135
	sim_grads_norm = 0.1368
-- Starting training on experience 156 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3647
	data_grads_norm = 2.1229
	new_data_grads_norm = 2.5428
	old_data_grads_norm = 3.4310
	sim_grads_norm = -0.0769
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2526
	data_grads_norm = 1.9590
	new_data_grads_norm = 2.6824
	old_data_grads_norm = 2.9970
	sim_grads_norm = 0.0005
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2981
	data_grads_norm = 1.9354
	new_data_grads_norm = 2.8416
	old_data_grads_norm = 2.5144
	sim_grads_norm = 0.0434
-- Starting training on experience 157 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4668
	data_grads_norm = 2.2447
	new_data_grads_norm = 3.3389
	old_data_grads_norm = 3.2388
	sim_grads_norm = -0.2007
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5012
	data_grads_norm = 2.2853
	new_data_grads_norm = 2.9580
	old_data_grads_norm = 2.5343
	sim_grads_norm = 0.0613
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6141
	data_grads_norm = 2.4165
	new_data_grads_norm = 3.4964
	old_data_grads_norm = 4.1696
	sim_grads_norm = 0.0614
-- Starting training on experience 158 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7485
	data_grads_norm = 2.6678
	new_data_grads_norm = 3.4839
	old_data_grads_norm = 3.0073
	sim_grads_norm = 0.3119
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4131
	data_grads_norm = 4.0618
	new_data_grads_norm = 3.4558
	old_data_grads_norm = 4.6165
	sim_grads_norm = 0.3633
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4052
	data_grads_norm = 1.8266
	new_data_grads_norm = 2.7765
	old_data_grads_norm = 2.6580
	sim_grads_norm = -0.1140
-- Starting training on experience 159 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6538
	data_grads_norm = 2.5832
	new_data_grads_norm = 3.5681
	old_data_grads_norm = 3.3424
	sim_grads_norm = 0.1052
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3300
	data_grads_norm = 1.9444
	new_data_grads_norm = 3.0513
	old_data_grads_norm = 2.2341
	sim_grads_norm = -0.0886
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3548
	data_grads_norm = 2.1787
	new_data_grads_norm = 4.0381
	old_data_grads_norm = 3.4897
	sim_grads_norm = -0.0603
-- Starting training on experience 160 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5194
	data_grads_norm = 2.2329
	new_data_grads_norm = 2.9691
	old_data_grads_norm = 3.1490
	sim_grads_norm = 0.0741
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6391
	data_grads_norm = 1.8267
	new_data_grads_norm = 3.3024
	old_data_grads_norm = 2.2147
	sim_grads_norm = 0.0399
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5690
	data_grads_norm = 2.0165
	new_data_grads_norm = 3.0582
	old_data_grads_norm = 2.6332
	sim_grads_norm = -0.0604
-- Starting training on experience 161 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5710
	data_grads_norm = 2.6478
	new_data_grads_norm = 4.1821
	old_data_grads_norm = 3.2504
	sim_grads_norm = 0.1407
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5811
	data_grads_norm = 2.6403
	new_data_grads_norm = 4.8332
	old_data_grads_norm = 3.1041
	sim_grads_norm = -0.1182
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4801
	data_grads_norm = 2.5029
	new_data_grads_norm = 5.5497
	old_data_grads_norm = 2.5351
	sim_grads_norm = -0.0464
-- Starting training on experience 162 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7463
	data_grads_norm = 3.1284
	new_data_grads_norm = 4.5736
	old_data_grads_norm = 3.0034
	sim_grads_norm = 0.0957
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6713
	data_grads_norm = 3.6740
	new_data_grads_norm = 4.6213
	old_data_grads_norm = 3.2378
	sim_grads_norm = 0.2753
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1945
	data_grads_norm = 2.2281
	new_data_grads_norm = 3.5152
	old_data_grads_norm = 2.6357
	sim_grads_norm = -0.0070
-- Starting training on experience 163 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4942
	data_grads_norm = 2.3323
	new_data_grads_norm = 3.7930
	old_data_grads_norm = 3.1990
	sim_grads_norm = 0.0169
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3353
	data_grads_norm = 2.2633
	new_data_grads_norm = 4.0726
	old_data_grads_norm = 2.6600
	sim_grads_norm = 0.0409
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4718
	data_grads_norm = 2.3867
	new_data_grads_norm = 3.6977
	old_data_grads_norm = 2.4640
	sim_grads_norm = 0.2228
-- Starting training on experience 164 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6594
	data_grads_norm = 3.5159
	new_data_grads_norm = 4.4010
	old_data_grads_norm = 2.9584
	sim_grads_norm = 0.2132
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0059
	data_grads_norm = 2.8638
	new_data_grads_norm = 3.9474
	old_data_grads_norm = 3.5510
	sim_grads_norm = -0.0905
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9618
	data_grads_norm = 2.9530
	new_data_grads_norm = 4.4171
	old_data_grads_norm = 3.6757
	sim_grads_norm = 0.0825
-- Starting training on experience 165 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5635
	data_grads_norm = 2.4619
	new_data_grads_norm = 4.2202
	old_data_grads_norm = 4.1875
	sim_grads_norm = -0.0782
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6506
	data_grads_norm = 2.4722
	new_data_grads_norm = 4.0800
	old_data_grads_norm = 2.5022
	sim_grads_norm = -0.0189
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4626
	data_grads_norm = 2.3047
	new_data_grads_norm = 4.0085
	old_data_grads_norm = 2.4274
	sim_grads_norm = 0.1426
-- Starting training on experience 166 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0359
	data_grads_norm = 3.2528
	new_data_grads_norm = 5.5273
	old_data_grads_norm = 3.7834
	sim_grads_norm = 0.1011
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4599
	data_grads_norm = 2.4194
	new_data_grads_norm = 4.5365
	old_data_grads_norm = 2.6714
	sim_grads_norm = -0.0341
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9368
	data_grads_norm = 2.4513
	new_data_grads_norm = 3.9166
	old_data_grads_norm = 3.7868
	sim_grads_norm = -0.0286
-- Starting training on experience 167 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7345
	data_grads_norm = 2.4240
	new_data_grads_norm = 3.1013
	old_data_grads_norm = 3.6126
	sim_grads_norm = 0.0506
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3491
	data_grads_norm = 1.9733
	new_data_grads_norm = 2.8355
	old_data_grads_norm = 2.8129
	sim_grads_norm = 0.0433
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2651
	data_grads_norm = 1.8896
	new_data_grads_norm = 2.9319
	old_data_grads_norm = 2.9024
	sim_grads_norm = -0.0370
-- Starting training on experience 168 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7895
	data_grads_norm = 2.3299
	new_data_grads_norm = 4.0717
	old_data_grads_norm = 2.2012
	sim_grads_norm = 0.0189
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8329
	data_grads_norm = 2.5788
	new_data_grads_norm = 4.0352
	old_data_grads_norm = 2.6677
	sim_grads_norm = 0.0635
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9474
	data_grads_norm = 3.0143
	new_data_grads_norm = 4.3158
	old_data_grads_norm = 3.7857
	sim_grads_norm = 0.0952
-- Starting training on experience 169 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8798
	data_grads_norm = 2.8264
	new_data_grads_norm = 4.0998
	old_data_grads_norm = 5.0899
	sim_grads_norm = 0.1550
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8432
	data_grads_norm = 2.4643
	new_data_grads_norm = 3.6440
	old_data_grads_norm = 2.8226
	sim_grads_norm = 0.1114
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8368
	data_grads_norm = 2.4453
	new_data_grads_norm = 3.7304
	old_data_grads_norm = 3.3077
	sim_grads_norm = 0.0519
-- Starting training on experience 170 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1174
	data_grads_norm = 3.2587
	new_data_grads_norm = 4.4180
	old_data_grads_norm = 3.0095
	sim_grads_norm = 0.1967
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0109
	data_grads_norm = 3.3027
	new_data_grads_norm = 4.2454
	old_data_grads_norm = 3.9547
	sim_grads_norm = 0.0903
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5760
	data_grads_norm = 3.1931
	new_data_grads_norm = 4.4153
	old_data_grads_norm = 3.3353
	sim_grads_norm = 0.2205
-- Starting training on experience 171 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2454
	data_grads_norm = 2.2323
	new_data_grads_norm = 4.7293
	old_data_grads_norm = 2.9783
	sim_grads_norm = -0.1906
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8153
	data_grads_norm = 3.4768
	new_data_grads_norm = 4.6989
	old_data_grads_norm = 3.6249
	sim_grads_norm = 0.2265
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6780
	data_grads_norm = 2.9573
	new_data_grads_norm = 3.5016
	old_data_grads_norm = 3.6569
	sim_grads_norm = 0.1804
-- Starting training on experience 172 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7577
	data_grads_norm = 3.6725
	new_data_grads_norm = 4.7329
	old_data_grads_norm = 4.2343
	sim_grads_norm = 0.2072
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8655
	data_grads_norm = 4.0053
	new_data_grads_norm = 5.2698
	old_data_grads_norm = 4.7712
	sim_grads_norm = 0.1692
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8856
	data_grads_norm = 2.9628
	new_data_grads_norm = 4.6227
	old_data_grads_norm = 3.0336
	sim_grads_norm = 0.0848
-- Starting training on experience 173 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4842
	data_grads_norm = 2.2840
	new_data_grads_norm = 3.4251
	old_data_grads_norm = 2.5540
	sim_grads_norm = 0.3653
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4139
	data_grads_norm = 2.0576
	new_data_grads_norm = 3.2188
	old_data_grads_norm = 3.2039
	sim_grads_norm = -0.1670
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4771
	data_grads_norm = 2.2234
	new_data_grads_norm = 3.3340
	old_data_grads_norm = 2.6102
	sim_grads_norm = 0.1560
-- Starting training on experience 174 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1247
	data_grads_norm = 2.3903
	new_data_grads_norm = 3.8300
	old_data_grads_norm = 2.6376
	sim_grads_norm = 0.3429
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3137
	data_grads_norm = 2.4528
	new_data_grads_norm = 3.3671
	old_data_grads_norm = 3.1679
	sim_grads_norm = 0.1872
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0453
	data_grads_norm = 1.8304
	new_data_grads_norm = 3.1299
	old_data_grads_norm = 2.2006
	sim_grads_norm = 0.0955
-- Starting training on experience 175 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3279
	data_grads_norm = 2.3860
	new_data_grads_norm = 3.6162
	old_data_grads_norm = 3.4725
	sim_grads_norm = 0.0921
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2811
	data_grads_norm = 2.1519
	new_data_grads_norm = 3.7275
	old_data_grads_norm = 2.7466
	sim_grads_norm = -0.1476
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6549
	data_grads_norm = 2.3131
	new_data_grads_norm = 3.6607
	old_data_grads_norm = 2.5012
	sim_grads_norm = 0.1117
-- Starting training on experience 176 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1650
	data_grads_norm = 2.1207
	new_data_grads_norm = 3.5728
	old_data_grads_norm = 2.2006
	sim_grads_norm = 0.1737
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4264
	data_grads_norm = 2.7951
	new_data_grads_norm = 3.2270
	old_data_grads_norm = 4.3240
	sim_grads_norm = 0.1804
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3325
	data_grads_norm = 2.2500
	new_data_grads_norm = 3.0895
	old_data_grads_norm = 2.9060
	sim_grads_norm = 0.1065
-- Starting training on experience 177 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3208
	data_grads_norm = 2.6562
	new_data_grads_norm = 3.4075
	old_data_grads_norm = 3.6404
	sim_grads_norm = -0.0310
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8129
	data_grads_norm = 3.2934
	new_data_grads_norm = 3.5268
	old_data_grads_norm = 4.5684
	sim_grads_norm = 0.0215
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6292
	data_grads_norm = 2.5137
	new_data_grads_norm = 3.7066
	old_data_grads_norm = 3.1330
	sim_grads_norm = 0.0708
-- Starting training on experience 178 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4607
	data_grads_norm = 2.5605
	new_data_grads_norm = 3.3630
	old_data_grads_norm = 3.8507
	sim_grads_norm = 0.1875
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3215
	data_grads_norm = 2.2970
	new_data_grads_norm = 3.3165
	old_data_grads_norm = 3.2455
	sim_grads_norm = -0.0110
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6318
	data_grads_norm = 2.8709
	new_data_grads_norm = 4.3468
	old_data_grads_norm = 3.5040
	sim_grads_norm = 0.0315
-- Starting training on experience 179 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4304
	data_grads_norm = 2.0645
	new_data_grads_norm = 2.9229
	old_data_grads_norm = 3.1898
	sim_grads_norm = 0.0005
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3445
	data_grads_norm = 2.3941
	new_data_grads_norm = 3.2032
	old_data_grads_norm = 3.1497
	sim_grads_norm = 0.0050
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2966
	data_grads_norm = 1.9411
	new_data_grads_norm = 2.8767
	old_data_grads_norm = 2.5308
	sim_grads_norm = -0.0418
-- Starting training on experience 180 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6812
	data_grads_norm = 2.6041
	new_data_grads_norm = 3.7135
	old_data_grads_norm = 3.3682
	sim_grads_norm = 0.1349
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1035
	data_grads_norm = 2.2354
	new_data_grads_norm = 3.5734
	old_data_grads_norm = 3.2134
	sim_grads_norm = 0.1324
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1001
	data_grads_norm = 2.0115
	new_data_grads_norm = 3.1748
	old_data_grads_norm = 1.9684
	sim_grads_norm = -0.0743
-- Starting training on experience 181 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4278
	data_grads_norm = 2.3493
	new_data_grads_norm = 3.8669
	old_data_grads_norm = 2.8610
	sim_grads_norm = 0.0021
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5075
	data_grads_norm = 2.7280
	new_data_grads_norm = 3.7849
	old_data_grads_norm = 4.4598
	sim_grads_norm = 0.0175
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8147
	data_grads_norm = 2.5616
	new_data_grads_norm = 3.9120
	old_data_grads_norm = 3.0286
	sim_grads_norm = 0.0740
-- Starting training on experience 182 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2787
	data_grads_norm = 2.7402
	new_data_grads_norm = 3.7359
	old_data_grads_norm = 2.7029
	sim_grads_norm = 0.2302
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3541
	data_grads_norm = 2.9189
	new_data_grads_norm = 3.6346
	old_data_grads_norm = 4.4062
	sim_grads_norm = 0.0501
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3302
	data_grads_norm = 2.7876
	new_data_grads_norm = 3.8852
	old_data_grads_norm = 4.0124
	sim_grads_norm = 0.0781
-- Starting training on experience 183 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6874
	data_grads_norm = 2.5398
	new_data_grads_norm = 4.0911
	old_data_grads_norm = 3.1083
	sim_grads_norm = -0.0285
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7067
	data_grads_norm = 3.1299
	new_data_grads_norm = 4.0675
	old_data_grads_norm = 3.7109
	sim_grads_norm = 0.1973
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5703
	data_grads_norm = 2.7011
	new_data_grads_norm = 3.7812
	old_data_grads_norm = 3.5582
	sim_grads_norm = 0.0849
-- Starting training on experience 184 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4238
	data_grads_norm = 3.2096
	new_data_grads_norm = 4.2867
	old_data_grads_norm = 4.2686
	sim_grads_norm = 0.6614
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9438
	data_grads_norm = 1.9555
	new_data_grads_norm = 2.7028
	old_data_grads_norm = 3.3639
	sim_grads_norm = -0.0131
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1173
	data_grads_norm = 2.0114
	new_data_grads_norm = 2.6261
	old_data_grads_norm = 3.6965
	sim_grads_norm = -0.1251
-- Starting training on experience 185 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2790
	data_grads_norm = 2.6723
	new_data_grads_norm = 4.8569
	old_data_grads_norm = 3.5300
	sim_grads_norm = -0.1136
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4707
	data_grads_norm = 2.6609
	new_data_grads_norm = 4.4214
	old_data_grads_norm = 3.5312
	sim_grads_norm = -0.1679
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4184
	data_grads_norm = 4.0848
	new_data_grads_norm = 5.1193
	old_data_grads_norm = 4.4998
	sim_grads_norm = 0.3988
-- Starting training on experience 186 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4313
	data_grads_norm = 2.7029
	new_data_grads_norm = 3.6469
	old_data_grads_norm = 3.0205
	sim_grads_norm = 0.1256
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3294
	data_grads_norm = 3.0419
	new_data_grads_norm = 4.0246
	old_data_grads_norm = 3.7747
	sim_grads_norm = 0.1014
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4762
	data_grads_norm = 2.4489
	new_data_grads_norm = 3.7315
	old_data_grads_norm = 3.2138
	sim_grads_norm = -0.0338
-- Starting training on experience 187 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2506
	data_grads_norm = 2.3675
	new_data_grads_norm = 3.9683
	old_data_grads_norm = 2.9989
	sim_grads_norm = -0.0661
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7025
	data_grads_norm = 3.7545
	new_data_grads_norm = 4.6204
	old_data_grads_norm = 5.6385
	sim_grads_norm = 0.0017
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4009
	data_grads_norm = 2.6964
	new_data_grads_norm = 3.7713
	old_data_grads_norm = 3.4222
	sim_grads_norm = 0.1325
-- Starting training on experience 188 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1981
	data_grads_norm = 2.0205
	new_data_grads_norm = 4.1556
	old_data_grads_norm = 2.9778
	sim_grads_norm = -0.1339
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7322
	data_grads_norm = 3.0036
	new_data_grads_norm = 4.7840
	old_data_grads_norm = 3.6677
	sim_grads_norm = 0.1494
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2983
	data_grads_norm = 2.3456
	new_data_grads_norm = 3.9496
	old_data_grads_norm = 2.5048
	sim_grads_norm = 0.1944
-- Starting training on experience 189 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3656
	data_grads_norm = 2.5459
	new_data_grads_norm = 3.4553
	old_data_grads_norm = 3.6504
	sim_grads_norm = 0.0603
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3712
	data_grads_norm = 2.8048
	new_data_grads_norm = 3.9257
	old_data_grads_norm = 3.2704
	sim_grads_norm = 0.1448
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3269
	data_grads_norm = 2.3267
	new_data_grads_norm = 3.0654
	old_data_grads_norm = 2.9980
	sim_grads_norm = -0.0562
-- Starting training on experience 190 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6561
	data_grads_norm = 1.8736
	new_data_grads_norm = 2.8709
	old_data_grads_norm = 3.1043
	sim_grads_norm = -0.0679
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5134
	data_grads_norm = 2.3008
	new_data_grads_norm = 3.0514
	old_data_grads_norm = 4.6551
	sim_grads_norm = -0.1374
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8842
	data_grads_norm = 2.8114
	new_data_grads_norm = 3.6469
	old_data_grads_norm = 3.1896
	sim_grads_norm = 0.3269
-- Starting training on experience 191 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3098
	data_grads_norm = 2.1663
	new_data_grads_norm = 4.6859
	old_data_grads_norm = 2.3117
	sim_grads_norm = -0.0772
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9178
	data_grads_norm = 3.1664
	new_data_grads_norm = 4.4657
	old_data_grads_norm = 3.2382
	sim_grads_norm = 0.2685
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3610
	data_grads_norm = 2.9039
	new_data_grads_norm = 4.2684
	old_data_grads_norm = 3.5397
	sim_grads_norm = 0.2295
-- Starting training on experience 192 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2577
	data_grads_norm = 2.1899
	new_data_grads_norm = 3.8979
	old_data_grads_norm = 2.6340
	sim_grads_norm = -0.0507
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6304
	data_grads_norm = 3.1269
	new_data_grads_norm = 4.7483
	old_data_grads_norm = 3.3863
	sim_grads_norm = 0.1914
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3072
	data_grads_norm = 2.6241
	new_data_grads_norm = 3.6962
	old_data_grads_norm = 3.0869
	sim_grads_norm = 0.0502
-- Starting training on experience 193 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5145
	data_grads_norm = 2.2617
	new_data_grads_norm = 3.2514
	old_data_grads_norm = 2.7342
	sim_grads_norm = -0.0208
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4826
	data_grads_norm = 2.8127
	new_data_grads_norm = 3.5412
	old_data_grads_norm = 3.8297
	sim_grads_norm = 0.2343
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1877
	data_grads_norm = 2.4997
	new_data_grads_norm = 3.3651
	old_data_grads_norm = 3.2708
	sim_grads_norm = -0.0066
-- Starting training on experience 194 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7536
	data_grads_norm = 2.9075
	new_data_grads_norm = 4.2762
	old_data_grads_norm = 3.4189
	sim_grads_norm = 0.2525
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4254
	data_grads_norm = 2.6419
	new_data_grads_norm = 3.8357
	old_data_grads_norm = 3.1253
	sim_grads_norm = 0.2912
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2150
	data_grads_norm = 2.3451
	new_data_grads_norm = 3.7014
	old_data_grads_norm = 3.0057
	sim_grads_norm = 0.0140
-- Starting training on experience 195 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2159
	data_grads_norm = 2.4412
	new_data_grads_norm = 3.4028
	old_data_grads_norm = 3.2794
	sim_grads_norm = 0.1574
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4111
	data_grads_norm = 2.5453
	new_data_grads_norm = 3.5203
	old_data_grads_norm = 3.6159
	sim_grads_norm = 0.1412
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0908
	data_grads_norm = 2.6614
	new_data_grads_norm = 3.3077
	old_data_grads_norm = 3.5810
	sim_grads_norm = 0.1958
-- Starting training on experience 196 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2604
	data_grads_norm = 3.2266
	new_data_grads_norm = 4.6747
	old_data_grads_norm = 3.5682
	sim_grads_norm = -0.0569
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4129
	data_grads_norm = 3.9784
	new_data_grads_norm = 6.2897
	old_data_grads_norm = 4.4595
	sim_grads_norm = 0.1578
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4074
	data_grads_norm = 3.5798
	new_data_grads_norm = 5.7791
	old_data_grads_norm = 3.5409
	sim_grads_norm = 0.1716
-- Starting training on experience 197 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6353
	data_grads_norm = 3.1846
	new_data_grads_norm = 6.2856
	old_data_grads_norm = 3.6869
	sim_grads_norm = -0.0248
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6694
	data_grads_norm = 3.2931
	new_data_grads_norm = 6.2211
	old_data_grads_norm = 4.0463
	sim_grads_norm = 0.2369
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5660
	data_grads_norm = 3.0676
	new_data_grads_norm = 5.3477
	old_data_grads_norm = 3.7394
	sim_grads_norm = 0.0021
-- Starting training on experience 198 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4571
	data_grads_norm = 2.9495
	new_data_grads_norm = 4.3353
	old_data_grads_norm = 3.3733
	sim_grads_norm = 0.0528
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4902
	data_grads_norm = 2.7408
	new_data_grads_norm = 4.1843
	old_data_grads_norm = 4.2909
	sim_grads_norm = 0.0298
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4690
	data_grads_norm = 2.4537
	new_data_grads_norm = 4.5034
	old_data_grads_norm = 3.4997
	sim_grads_norm = -0.1622
-- Starting training on experience 199 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1092
	data_grads_norm = 2.3165
	new_data_grads_norm = 4.4013
	old_data_grads_norm = 2.3207
	sim_grads_norm = 0.1411
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3089
	data_grads_norm = 2.4628
	new_data_grads_norm = 3.9289
	old_data_grads_norm = 3.4163
	sim_grads_norm = 0.0474
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5079
	data_grads_norm = 2.7956
	new_data_grads_norm = 3.9566
	old_data_grads_norm = 3.4952
	sim_grads_norm = 0.0591
-- Starting training on experience 200 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8250
	data_grads_norm = 3.4813
	new_data_grads_norm = 5.5800
	old_data_grads_norm = 3.6529
	sim_grads_norm = 0.3232
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3012
	data_grads_norm = 2.8729
	new_data_grads_norm = 4.8821
	old_data_grads_norm = 3.1690
	sim_grads_norm = -0.0728
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6921
	data_grads_norm = 3.2959
	new_data_grads_norm = 4.9047
	old_data_grads_norm = 3.9833
	sim_grads_norm = 0.2645
-- Starting training on experience 201 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8400
	data_grads_norm = 2.8372
	new_data_grads_norm = 5.1179
	old_data_grads_norm = 3.3830
	sim_grads_norm = 0.1306
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7911
	data_grads_norm = 3.0634
	new_data_grads_norm = 4.2675
	old_data_grads_norm = 3.7721
	sim_grads_norm = 0.0073
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1999
	data_grads_norm = 3.9340
	new_data_grads_norm = 3.7433
	old_data_grads_norm = 4.9058
	sim_grads_norm = 0.0578
-- Starting training on experience 202 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4718
	data_grads_norm = 3.7730
	new_data_grads_norm = 5.4348
	old_data_grads_norm = 2.6662
	sim_grads_norm = 0.3253
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6458
	data_grads_norm = 3.1924
	new_data_grads_norm = 4.5730
	old_data_grads_norm = 4.0237
	sim_grads_norm = 0.1678
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1788
	data_grads_norm = 2.6345
	new_data_grads_norm = 3.6370
	old_data_grads_norm = 2.8978
	sim_grads_norm = 0.0133
-- Starting training on experience 203 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2243
	data_grads_norm = 3.1359
	new_data_grads_norm = 3.7044
	old_data_grads_norm = 4.1572
	sim_grads_norm = 0.1759
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3597
	data_grads_norm = 2.4813
	new_data_grads_norm = 3.2621
	old_data_grads_norm = 4.8051
	sim_grads_norm = -0.0408
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0815
	data_grads_norm = 2.0956
	new_data_grads_norm = 3.4405
	old_data_grads_norm = 2.8253
	sim_grads_norm = 0.1204
-- Starting training on experience 204 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3120
	data_grads_norm = 2.7478
	new_data_grads_norm = 5.5620
	old_data_grads_norm = 2.5545
	sim_grads_norm = 0.0870
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3969
	data_grads_norm = 2.7836
	new_data_grads_norm = 5.0968
	old_data_grads_norm = 5.0208
	sim_grads_norm = -0.1467
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6880
	data_grads_norm = 2.8814
	new_data_grads_norm = 4.3539
	old_data_grads_norm = 3.7254
	sim_grads_norm = 0.0506
-- Starting training on experience 205 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8679
	data_grads_norm = 3.9927
	new_data_grads_norm = 5.4237
	old_data_grads_norm = 4.9778
	sim_grads_norm = 0.2703
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1262
	data_grads_norm = 2.0995
	new_data_grads_norm = 3.3682
	old_data_grads_norm = 3.6477
	sim_grads_norm = 0.0758
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3326
	data_grads_norm = 2.3562
	new_data_grads_norm = 3.6274
	old_data_grads_norm = 2.7351
	sim_grads_norm = -0.0741
-- Starting training on experience 206 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3167
	data_grads_norm = 2.0933
	new_data_grads_norm = 3.0220
	old_data_grads_norm = 3.1045
	sim_grads_norm = -0.1812
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4352
	data_grads_norm = 2.4856
	new_data_grads_norm = 3.3170
	old_data_grads_norm = 3.1064
	sim_grads_norm = 0.2204
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3827
	data_grads_norm = 2.2251
	new_data_grads_norm = 3.0579
	old_data_grads_norm = 2.8603
	sim_grads_norm = -0.0270
-- Starting training on experience 207 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1149
	data_grads_norm = 2.1534
	new_data_grads_norm = 3.5262
	old_data_grads_norm = 3.3713
	sim_grads_norm = -0.1312
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5726
	data_grads_norm = 3.1946
	new_data_grads_norm = 3.8298
	old_data_grads_norm = 5.2091
	sim_grads_norm = -0.1233
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7133
	data_grads_norm = 3.3748
	new_data_grads_norm = 4.0075
	old_data_grads_norm = 4.2263
	sim_grads_norm = 0.4367
-- Starting training on experience 208 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7426
	data_grads_norm = 2.7503
	new_data_grads_norm = 3.6684
	old_data_grads_norm = 3.8846
	sim_grads_norm = 0.0114
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1582
	data_grads_norm = 2.3601
	new_data_grads_norm = 3.7166
	old_data_grads_norm = 2.4988
	sim_grads_norm = 0.2325
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6348
	data_grads_norm = 2.7383
	new_data_grads_norm = 3.4884
	old_data_grads_norm = 4.3098
	sim_grads_norm = 0.0668
-- Starting training on experience 209 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9767
	data_grads_norm = 2.0221
	new_data_grads_norm = 4.1065
	old_data_grads_norm = 2.1551
	sim_grads_norm = -0.0943
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6240
	data_grads_norm = 2.7826
	new_data_grads_norm = 4.1587
	old_data_grads_norm = 3.3994
	sim_grads_norm = -0.0279
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4440
	data_grads_norm = 2.8082
	new_data_grads_norm = 4.3950
	old_data_grads_norm = 3.7189
	sim_grads_norm = 0.0001
-- Starting training on experience 210 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1110
	data_grads_norm = 2.4679
	new_data_grads_norm = 4.1796
	old_data_grads_norm = 2.9497
	sim_grads_norm = 0.0536
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1299
	data_grads_norm = 2.6364
	new_data_grads_norm = 4.4970
	old_data_grads_norm = 2.9047
	sim_grads_norm = 0.1405
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2431
	data_grads_norm = 2.2779
	new_data_grads_norm = 3.9718
	old_data_grads_norm = 2.8292
	sim_grads_norm = -0.1663
-- Starting training on experience 211 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4168
	data_grads_norm = 2.7166
	new_data_grads_norm = 4.1083
	old_data_grads_norm = 3.2812
	sim_grads_norm = 0.0171
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3464
	data_grads_norm = 2.5180
	new_data_grads_norm = 4.2493
	old_data_grads_norm = 2.5441
	sim_grads_norm = 0.0822
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4172
	data_grads_norm = 2.6775
	new_data_grads_norm = 4.5487
	old_data_grads_norm = 3.3070
	sim_grads_norm = -0.0013
-- Starting training on experience 212 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1856
	data_grads_norm = 2.5877
	new_data_grads_norm = 3.4432
	old_data_grads_norm = 3.5421
	sim_grads_norm = 0.0675
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2740
	data_grads_norm = 3.2657
	new_data_grads_norm = 4.3993
	old_data_grads_norm = 3.3391
	sim_grads_norm = 0.1693
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1298
	data_grads_norm = 2.9560
	new_data_grads_norm = 4.2409
	old_data_grads_norm = 3.8860
	sim_grads_norm = 0.0127
-- Starting training on experience 213 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1755
	data_grads_norm = 2.5108
	new_data_grads_norm = 3.6030
	old_data_grads_norm = 3.9499
	sim_grads_norm = -0.0250
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5013
	data_grads_norm = 2.6962
	new_data_grads_norm = 3.6575
	old_data_grads_norm = 3.2039
	sim_grads_norm = 0.0082
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4992
	data_grads_norm = 2.5490
	new_data_grads_norm = 3.6295
	old_data_grads_norm = 3.1474
	sim_grads_norm = 0.0981
-- Starting training on experience 214 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1166
	data_grads_norm = 2.2218
	new_data_grads_norm = 4.5062
	old_data_grads_norm = 2.9799
	sim_grads_norm = -0.1574
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5863
	data_grads_norm = 4.0106
	new_data_grads_norm = 5.1310
	old_data_grads_norm = 5.3458
	sim_grads_norm = 0.2975
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3788
	data_grads_norm = 3.0257
	new_data_grads_norm = 4.3987
	old_data_grads_norm = 4.4093
	sim_grads_norm = -0.1829
-- Starting training on experience 215 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3764
	data_grads_norm = 2.6135
	new_data_grads_norm = 3.3288
	old_data_grads_norm = 3.7180
	sim_grads_norm = 0.0545
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3924
	data_grads_norm = 2.7615
	new_data_grads_norm = 3.7248
	old_data_grads_norm = 4.4925
	sim_grads_norm = 0.1499
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0938
	data_grads_norm = 2.3912
	new_data_grads_norm = 3.0429
	old_data_grads_norm = 3.7395
	sim_grads_norm = -0.1444
-- Starting training on experience 216 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4160
	data_grads_norm = 2.5848
	new_data_grads_norm = 3.2119
	old_data_grads_norm = 3.5473
	sim_grads_norm = 0.1269
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5237
	data_grads_norm = 2.5009
	new_data_grads_norm = 3.4235
	old_data_grads_norm = 3.5415
	sim_grads_norm = 0.1531
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6174
	data_grads_norm = 2.3048
	new_data_grads_norm = 3.1017
	old_data_grads_norm = 3.9424
	sim_grads_norm = -0.2842
-- Starting training on experience 217 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0036
	data_grads_norm = 4.0592
	new_data_grads_norm = 6.2447
	old_data_grads_norm = 3.8495
	sim_grads_norm = 0.3577
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7752
	data_grads_norm = 3.0289
	new_data_grads_norm = 5.4603
	old_data_grads_norm = 3.7071
	sim_grads_norm = -0.0275
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5453
	data_grads_norm = 3.1084
	new_data_grads_norm = 5.1200
	old_data_grads_norm = 3.0447
	sim_grads_norm = -0.0058
-- Starting training on experience 218 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0890
	data_grads_norm = 2.2943
	new_data_grads_norm = 3.4565
	old_data_grads_norm = 2.1748
	sim_grads_norm = 0.2117
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5454
	data_grads_norm = 2.4383
	new_data_grads_norm = 3.1487
	old_data_grads_norm = 3.2143
	sim_grads_norm = 0.1828
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2652
	data_grads_norm = 2.6194
	new_data_grads_norm = 3.5762
	old_data_grads_norm = 3.7721
	sim_grads_norm = 0.1684
-- Starting training on experience 219 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5826
	data_grads_norm = 2.8208
	new_data_grads_norm = 3.8278
	old_data_grads_norm = 4.1245
	sim_grads_norm = 0.0233
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3075
	data_grads_norm = 2.2126
	new_data_grads_norm = 3.7561
	old_data_grads_norm = 2.8351
	sim_grads_norm = -0.0528
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1910
	data_grads_norm = 2.5758
	new_data_grads_norm = 4.0432
	old_data_grads_norm = 3.5552
	sim_grads_norm = -0.1088
-- Starting training on experience 220 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0716
	data_grads_norm = 2.2223
	new_data_grads_norm = 3.4775
	old_data_grads_norm = 2.8372
	sim_grads_norm = 0.0006
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4267
	data_grads_norm = 2.1692
	new_data_grads_norm = 3.6680
	old_data_grads_norm = 2.2944
	sim_grads_norm = -0.0880
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9535
	data_grads_norm = 2.1600
	new_data_grads_norm = 3.0564
	old_data_grads_norm = 2.5435
	sim_grads_norm = 0.2876
-- Starting training on experience 221 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1368
	data_grads_norm = 3.5808
	new_data_grads_norm = 4.9972
	old_data_grads_norm = 4.4754
	sim_grads_norm = 0.1481
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4196
	data_grads_norm = 2.2556
	new_data_grads_norm = 3.5304
	old_data_grads_norm = 2.7308
	sim_grads_norm = 0.1098
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2316
	data_grads_norm = 2.1045
	new_data_grads_norm = 3.6266
	old_data_grads_norm = 2.4486
	sim_grads_norm = -0.0238
-- Starting training on experience 222 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2816
	data_grads_norm = 2.1572
	new_data_grads_norm = 3.4044
	old_data_grads_norm = 2.2989
	sim_grads_norm = -0.0018
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5009
	data_grads_norm = 2.8348
	new_data_grads_norm = 3.0106
	old_data_grads_norm = 4.0849
	sim_grads_norm = 0.1388
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0847
	data_grads_norm = 2.1637
	new_data_grads_norm = 2.9040
	old_data_grads_norm = 2.6322
	sim_grads_norm = 0.1046
-- Starting training on experience 223 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5609
	data_grads_norm = 2.0918
	new_data_grads_norm = 3.4487
	old_data_grads_norm = 2.6526
	sim_grads_norm = 0.1155
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4939
	data_grads_norm = 2.2317
	new_data_grads_norm = 3.4175
	old_data_grads_norm = 2.7809
	sim_grads_norm = -0.0051
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6857
	data_grads_norm = 2.8151
	new_data_grads_norm = 3.5827
	old_data_grads_norm = 4.0580
	sim_grads_norm = 0.2240
-- Starting training on experience 224 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9082
	data_grads_norm = 2.6684
	new_data_grads_norm = 5.6344
	old_data_grads_norm = 2.9259
	sim_grads_norm = 0.0517
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6934
	data_grads_norm = 3.0801
	new_data_grads_norm = 6.1412
	old_data_grads_norm = 2.6225
	sim_grads_norm = 0.1627
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7659
	data_grads_norm = 3.0370
	new_data_grads_norm = 5.7175
	old_data_grads_norm = 3.3084
	sim_grads_norm = -0.0067
-- Starting training on experience 225 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1782
	data_grads_norm = 2.1397
	new_data_grads_norm = 3.4038
	old_data_grads_norm = 2.9445
	sim_grads_norm = -0.1376
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5399
	data_grads_norm = 2.5826
	new_data_grads_norm = 4.3764
	old_data_grads_norm = 3.3314
	sim_grads_norm = -0.0580
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5081
	data_grads_norm = 2.5419
	new_data_grads_norm = 4.6531
	old_data_grads_norm = 3.3205
	sim_grads_norm = -0.0172
-- Starting training on experience 226 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4364
	data_grads_norm = 2.8035
	new_data_grads_norm = 4.2153
	old_data_grads_norm = 3.1321
	sim_grads_norm = 0.0280
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5194
	data_grads_norm = 3.5450
	new_data_grads_norm = 4.4603
	old_data_grads_norm = 4.3784
	sim_grads_norm = 0.1349
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3218
	data_grads_norm = 3.3490
	new_data_grads_norm = 4.7130
	old_data_grads_norm = 3.8845
	sim_grads_norm = 0.2968
-- Starting training on experience 227 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0249
	data_grads_norm = 2.7105
	new_data_grads_norm = 3.8937
	old_data_grads_norm = 3.5752
	sim_grads_norm = 0.0740
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7926
	data_grads_norm = 2.6098
	new_data_grads_norm = 4.2707
	old_data_grads_norm = 3.5718
	sim_grads_norm = -0.0177
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0653
	data_grads_norm = 2.7542
	new_data_grads_norm = 3.8104
	old_data_grads_norm = 3.5719
	sim_grads_norm = 0.0545
-- Starting training on experience 228 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2301
	data_grads_norm = 1.8666
	new_data_grads_norm = 4.2950
	old_data_grads_norm = 1.8409
	sim_grads_norm = -0.0890
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5451
	data_grads_norm = 2.9945
	new_data_grads_norm = 4.4421
	old_data_grads_norm = 4.6697
	sim_grads_norm = 0.0654
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8801
	data_grads_norm = 3.1227
	new_data_grads_norm = 4.5735
	old_data_grads_norm = 5.2016
	sim_grads_norm = 0.0981
-- Starting training on experience 229 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4761
	data_grads_norm = 3.1111
	new_data_grads_norm = 4.5105
	old_data_grads_norm = 3.8867
	sim_grads_norm = -0.0394
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1461
	data_grads_norm = 3.3022
	new_data_grads_norm = 4.4411
	old_data_grads_norm = 3.8655
	sim_grads_norm = 0.1819
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3213
	data_grads_norm = 2.8888
	new_data_grads_norm = 4.4333
	old_data_grads_norm = 3.6406
	sim_grads_norm = 0.1355
-- Starting training on experience 230 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8748
	data_grads_norm = 2.9730
	new_data_grads_norm = 4.3610
	old_data_grads_norm = 4.3815
	sim_grads_norm = -0.0600
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7530
	data_grads_norm = 3.1925
	new_data_grads_norm = 4.1597
	old_data_grads_norm = 4.0304
	sim_grads_norm = 0.1741
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6716
	data_grads_norm = 2.9187
	new_data_grads_norm = 4.3786
	old_data_grads_norm = 3.3329
	sim_grads_norm = 0.0485
-- Starting training on experience 231 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6478
	data_grads_norm = 3.6939
	new_data_grads_norm = 4.8200
	old_data_grads_norm = 4.9202
	sim_grads_norm = 0.1764
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5156
	data_grads_norm = 2.8822
	new_data_grads_norm = 3.8472
	old_data_grads_norm = 4.3711
	sim_grads_norm = -0.1495
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4621
	data_grads_norm = 2.4265
	new_data_grads_norm = 4.0452
	old_data_grads_norm = 2.5633
	sim_grads_norm = 0.1947
-- Starting training on experience 232 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4859
	data_grads_norm = 2.7743
	new_data_grads_norm = 3.8624
	old_data_grads_norm = 4.0644
	sim_grads_norm = 0.0402
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4289
	data_grads_norm = 2.2631
	new_data_grads_norm = 4.1145
	old_data_grads_norm = 2.7343
	sim_grads_norm = -0.0388
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4063
	data_grads_norm = 2.4443
	new_data_grads_norm = 3.7701
	old_data_grads_norm = 3.0375
	sim_grads_norm = 0.2034
-- Starting training on experience 233 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4508
	data_grads_norm = 2.6163
	new_data_grads_norm = 3.9517
	old_data_grads_norm = 4.4869
	sim_grads_norm = -0.0110
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0940
	data_grads_norm = 2.7354
	new_data_grads_norm = 4.0853
	old_data_grads_norm = 2.7499
	sim_grads_norm = 0.1607
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4060
	data_grads_norm = 2.9665
	new_data_grads_norm = 4.2037
	old_data_grads_norm = 3.6586
	sim_grads_norm = 0.0069
-- Starting training on experience 234 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3332
	data_grads_norm = 3.0501
	new_data_grads_norm = 5.1194
	old_data_grads_norm = 2.9408
	sim_grads_norm = 0.3142
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2478
	data_grads_norm = 3.0887
	new_data_grads_norm = 5.3307
	old_data_grads_norm = 3.8887
	sim_grads_norm = 0.1208
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6029
	data_grads_norm = 3.3000
	new_data_grads_norm = 4.4712
	old_data_grads_norm = 3.7908
	sim_grads_norm = 0.1607
-- Starting training on experience 235 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3705
	data_grads_norm = 3.9268
	new_data_grads_norm = 6.2422
	old_data_grads_norm = 3.9766
	sim_grads_norm = 0.0061
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2108
	data_grads_norm = 2.5942
	new_data_grads_norm = 5.9005
	old_data_grads_norm = 3.8198
	sim_grads_norm = -0.1779
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2628
	data_grads_norm = 3.0715
	new_data_grads_norm = 6.2098
	old_data_grads_norm = 2.2169
	sim_grads_norm = 0.0778
-- Starting training on experience 236 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2003
	data_grads_norm = 2.7926
	new_data_grads_norm = 3.7944
	old_data_grads_norm = 3.6300
	sim_grads_norm = 0.1534
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2395
	data_grads_norm = 2.9496
	new_data_grads_norm = 3.3724
	old_data_grads_norm = 3.9229
	sim_grads_norm = 0.0266
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9878
	data_grads_norm = 2.8892
	new_data_grads_norm = 3.6337
	old_data_grads_norm = 4.0559
	sim_grads_norm = 0.2080
-- Starting training on experience 237 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
-- >> End of training phase << --
-- >> Start of eval phase << --
-- Starting eval on experience 0 (Task 0) from test stream --
> Eval on experience 0 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp000 = 1.9244
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.3380
	mb_index = 476
	time = 60.6958
-- Starting eval on experience 1 (Task 0) from test stream --
> Eval on experience 1 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp001 = 1.0873
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.6580
-- >> End of eval phase << --
	CumulativeAccuracy/eval_phase/test_stream/Exp000 = 0.6180
	CumulativeAccuracy/eval_phase/test_stream/Exp001 = 0.4980
	Loss_Stream/eval_phase/test_stream/Task000 = 1.5058
	Top1_Acc_Stream/eval_phase/test_stream/Task000 = 0.4980
-- >> Start of training phase << --
-- Starting training on experience 0 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4561
	data_grads_norm = 3.2361
	new_data_grads_norm = 3.0902
	old_data_grads_norm = 4.7363
	sim_grads_norm = -0.0019
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4413
	data_grads_norm = 2.2381
	new_data_grads_norm = 2.9483
	old_data_grads_norm = 3.2238
	sim_grads_norm = -0.0131
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8036
	data_grads_norm = 3.0059
	new_data_grads_norm = 3.1348
	old_data_grads_norm = 4.2001
	sim_grads_norm = -0.1262
-- Starting training on experience 1 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8246
	data_grads_norm = 2.9226
	new_data_grads_norm = 4.9213
	old_data_grads_norm = 3.5530
	sim_grads_norm = -0.2192
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0916
	data_grads_norm = 3.5599
	new_data_grads_norm = 5.5058
	old_data_grads_norm = 4.1152
	sim_grads_norm = 0.0407
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9772
	data_grads_norm = 3.5841
	new_data_grads_norm = 5.0993
	old_data_grads_norm = 4.2067
	sim_grads_norm = 0.1256
-- Starting training on experience 2 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7946
	data_grads_norm = 3.3072
	new_data_grads_norm = 4.0064
	old_data_grads_norm = 4.1196
	sim_grads_norm = 0.0201
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7511
	data_grads_norm = 2.8210
	new_data_grads_norm = 3.8815
	old_data_grads_norm = 3.4785
	sim_grads_norm = 0.0078
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6497
	data_grads_norm = 2.7687
	new_data_grads_norm = 4.1519
	old_data_grads_norm = 3.5580
	sim_grads_norm = -0.0035
-- Starting training on experience 3 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5900
	data_grads_norm = 2.7233
	new_data_grads_norm = 3.1518
	old_data_grads_norm = 4.1294
	sim_grads_norm = -0.0172
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8340
	data_grads_norm = 2.8673
	new_data_grads_norm = 3.5273
	old_data_grads_norm = 4.3153
	sim_grads_norm = -0.0224
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6746
	data_grads_norm = 2.6353
	new_data_grads_norm = 3.4022
	old_data_grads_norm = 3.5950
	sim_grads_norm = 0.0699
-- Starting training on experience 4 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8392
	data_grads_norm = 2.9844
	new_data_grads_norm = 4.4997
	old_data_grads_norm = 3.4764
	sim_grads_norm = -0.0360
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8832
	data_grads_norm = 3.1274
	new_data_grads_norm = 3.9253
	old_data_grads_norm = 4.1495
	sim_grads_norm = -0.0390
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9896
	data_grads_norm = 2.6959
	new_data_grads_norm = 4.5388
	old_data_grads_norm = 2.9013
	sim_grads_norm = 0.0899
-- Starting training on experience 5 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6261
	data_grads_norm = 2.2067
	new_data_grads_norm = 3.4111
	old_data_grads_norm = 2.9618
	sim_grads_norm = -0.0809
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0837
	data_grads_norm = 3.3813
	new_data_grads_norm = 4.2573
	old_data_grads_norm = 3.9168
	sim_grads_norm = 0.1052
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9140
	data_grads_norm = 2.7458
	new_data_grads_norm = 3.8306
	old_data_grads_norm = 3.1265
	sim_grads_norm = -0.1572
-- Starting training on experience 6 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0758
	data_grads_norm = 3.5778
	new_data_grads_norm = 5.4108
	old_data_grads_norm = 3.7196
	sim_grads_norm = 0.1560
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0032
	data_grads_norm = 3.2030
	new_data_grads_norm = 4.5849
	old_data_grads_norm = 4.4118
	sim_grads_norm = 0.1052
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8728
	data_grads_norm = 2.8139
	new_data_grads_norm = 4.2376
	old_data_grads_norm = 3.0891
	sim_grads_norm = 0.0463
-- Starting training on experience 7 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2345
	data_grads_norm = 3.3625
	new_data_grads_norm = 4.2602
	old_data_grads_norm = 4.1828
	sim_grads_norm = 0.0700
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9446
	data_grads_norm = 2.8349
	new_data_grads_norm = 4.8809
	old_data_grads_norm = 4.1289
	sim_grads_norm = 0.1476
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0618
	data_grads_norm = 3.1231
	new_data_grads_norm = 4.5411
	old_data_grads_norm = 4.4610
	sim_grads_norm = -0.0105
-- Starting training on experience 8 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1947
	data_grads_norm = 3.2873
	new_data_grads_norm = 4.1381
	old_data_grads_norm = 4.0161
	sim_grads_norm = 0.0911
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0640
	data_grads_norm = 2.8219
	new_data_grads_norm = 4.5485
	old_data_grads_norm = 3.4467
	sim_grads_norm = 0.0538
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1242
	data_grads_norm = 3.0333
	new_data_grads_norm = 4.3913
	old_data_grads_norm = 3.6018
	sim_grads_norm = 0.0077
-- Starting training on experience 9 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7722
	data_grads_norm = 2.3949
	new_data_grads_norm = 4.6280
	old_data_grads_norm = 2.8003
	sim_grads_norm = 0.0760
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5517
	data_grads_norm = 2.5679
	new_data_grads_norm = 4.5035
	old_data_grads_norm = 4.8199
	sim_grads_norm = -0.0328
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4987
	data_grads_norm = 3.3191
	new_data_grads_norm = 4.2690
	old_data_grads_norm = 3.6616
	sim_grads_norm = 0.1526
-- Starting training on experience 10 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8910
	data_grads_norm = 2.7276
	new_data_grads_norm = 4.9936
	old_data_grads_norm = 2.8765
	sim_grads_norm = -0.0905
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9584
	data_grads_norm = 2.9832
	new_data_grads_norm = 4.3377
	old_data_grads_norm = 3.9085
	sim_grads_norm = 0.0227
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2010
	data_grads_norm = 3.4633
	new_data_grads_norm = 4.5319
	old_data_grads_norm = 3.6151
	sim_grads_norm = 0.1054
-- Starting training on experience 11 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5387
	data_grads_norm = 2.6337
	new_data_grads_norm = 4.3274
	old_data_grads_norm = 3.6231
	sim_grads_norm = -0.1801
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4278
	data_grads_norm = 3.1280
	new_data_grads_norm = 4.5889
	old_data_grads_norm = 3.3048
	sim_grads_norm = 0.0211
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4892
	data_grads_norm = 3.4271
	new_data_grads_norm = 4.4692
	old_data_grads_norm = 3.4360
	sim_grads_norm = 0.1866
-- Starting training on experience 12 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8173
	data_grads_norm = 4.9947
	new_data_grads_norm = 4.0912
	old_data_grads_norm = 5.2423
	sim_grads_norm = 0.1043
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1144
	data_grads_norm = 2.9016
	new_data_grads_norm = 4.2966
	old_data_grads_norm = 3.4644
	sim_grads_norm = 0.1901
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6179
	data_grads_norm = 3.1319
	new_data_grads_norm = 3.9704
	old_data_grads_norm = 4.2283
	sim_grads_norm = 0.1796
-- Starting training on experience 13 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5234
	data_grads_norm = 2.1313
	new_data_grads_norm = 3.4213
	old_data_grads_norm = 3.1719
	sim_grads_norm = -0.0626
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5536
	data_grads_norm = 2.2147
	new_data_grads_norm = 3.9618
	old_data_grads_norm = 3.2854
	sim_grads_norm = 0.0094
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2310
	data_grads_norm = 3.1872
	new_data_grads_norm = 3.8874
	old_data_grads_norm = 4.6634
	sim_grads_norm = 0.1026
-- Starting training on experience 14 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6513
	data_grads_norm = 2.2949
	new_data_grads_norm = 3.4383
	old_data_grads_norm = 3.5217
	sim_grads_norm = -0.0576
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2816
	data_grads_norm = 2.8475
	new_data_grads_norm = 4.3308
	old_data_grads_norm = 3.1854
	sim_grads_norm = 0.0717
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9994
	data_grads_norm = 2.1464
	new_data_grads_norm = 3.7304
	old_data_grads_norm = 2.3684
	sim_grads_norm = 0.1178
-- Starting training on experience 15 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8619
	data_grads_norm = 3.1499
	new_data_grads_norm = 3.7865
	old_data_grads_norm = 4.7038
	sim_grads_norm = 0.0509
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7676
	data_grads_norm = 2.3477
	new_data_grads_norm = 3.4491
	old_data_grads_norm = 2.8375
	sim_grads_norm = -0.0274
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9083
	data_grads_norm = 2.5500
	new_data_grads_norm = 3.6634
	old_data_grads_norm = 2.9538
	sim_grads_norm = 0.0557
-- Starting training on experience 16 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6898
	data_grads_norm = 2.4260
	new_data_grads_norm = 3.5294
	old_data_grads_norm = 3.3351
	sim_grads_norm = -0.0520
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6976
	data_grads_norm = 2.2505
	new_data_grads_norm = 3.1171
	old_data_grads_norm = 2.6873
	sim_grads_norm = 0.0144
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0078
	data_grads_norm = 2.6473
	new_data_grads_norm = 3.7371
	old_data_grads_norm = 3.3420
	sim_grads_norm = -0.0503
-- Starting training on experience 17 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4598
	data_grads_norm = 2.2962
	new_data_grads_norm = 3.6006
	old_data_grads_norm = 3.7670
	sim_grads_norm = -0.0553
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1727
	data_grads_norm = 3.5609
	new_data_grads_norm = 4.4917
	old_data_grads_norm = 4.1778
	sim_grads_norm = 0.3409
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6833
	data_grads_norm = 2.3770
	new_data_grads_norm = 3.8022
	old_data_grads_norm = 3.8409
	sim_grads_norm = -0.0509
-- Starting training on experience 18 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7086
	data_grads_norm = 2.6504
	new_data_grads_norm = 3.5355
	old_data_grads_norm = 2.9533
	sim_grads_norm = 0.0753
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8561
	data_grads_norm = 2.5350
	new_data_grads_norm = 3.8678
	old_data_grads_norm = 2.7880
	sim_grads_norm = 0.1270
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7100
	data_grads_norm = 2.3943
	new_data_grads_norm = 3.7313
	old_data_grads_norm = 2.6959
	sim_grads_norm = 0.2318
-- Starting training on experience 19 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2596
	data_grads_norm = 1.4756
	new_data_grads_norm = 3.8637
	old_data_grads_norm = 2.1049
	sim_grads_norm = -0.0445
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2176
	data_grads_norm = 1.9981
	new_data_grads_norm = 3.6151
	old_data_grads_norm = 2.7097
	sim_grads_norm = -0.0586
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0771
	data_grads_norm = 3.5067
	new_data_grads_norm = 4.0914
	old_data_grads_norm = 5.0245
	sim_grads_norm = 0.1600
-- Starting training on experience 20 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9901
	data_grads_norm = 2.5226
	new_data_grads_norm = 4.4342
	old_data_grads_norm = 2.8071
	sim_grads_norm = 0.3828
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9954
	data_grads_norm = 2.6782
	new_data_grads_norm = 3.5174
	old_data_grads_norm = 3.8075
	sim_grads_norm = 0.0853
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7950
	data_grads_norm = 2.2144
	new_data_grads_norm = 2.6428
	old_data_grads_norm = 2.8267
	sim_grads_norm = 0.2860
-- Starting training on experience 21 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6119
	data_grads_norm = 2.1844
	new_data_grads_norm = 4.5667
	old_data_grads_norm = 1.6764
	sim_grads_norm = -0.0527
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8557
	data_grads_norm = 2.8234
	new_data_grads_norm = 4.6828
	old_data_grads_norm = 2.7721
	sim_grads_norm = -0.0486
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5739
	data_grads_norm = 2.3767
	new_data_grads_norm = 4.3578
	old_data_grads_norm = 2.6098
	sim_grads_norm = 0.0688
-- Starting training on experience 22 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4007
	data_grads_norm = 1.8414
	new_data_grads_norm = 2.8945
	old_data_grads_norm = 2.2951
	sim_grads_norm = 0.1519
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2455
	data_grads_norm = 1.7563
	new_data_grads_norm = 2.8557
	old_data_grads_norm = 2.7337
	sim_grads_norm = -0.0780
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9320
	data_grads_norm = 2.3852
	new_data_grads_norm = 3.1458
	old_data_grads_norm = 3.1180
	sim_grads_norm = 0.1412
-- Starting training on experience 23 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6382
	data_grads_norm = 2.0006
	new_data_grads_norm = 2.9701
	old_data_grads_norm = 2.1991
	sim_grads_norm = 0.1587
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5033
	data_grads_norm = 2.0842
	new_data_grads_norm = 3.4462
	old_data_grads_norm = 2.5959
	sim_grads_norm = -0.0597
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9320
	data_grads_norm = 2.3812
	new_data_grads_norm = 3.0049
	old_data_grads_norm = 3.0332
	sim_grads_norm = 0.1799
-- Starting training on experience 24 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2017
	data_grads_norm = 1.9187
	new_data_grads_norm = 2.9778
	old_data_grads_norm = 2.8122
	sim_grads_norm = -0.1628
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5432
	data_grads_norm = 2.2008
	new_data_grads_norm = 3.3022
	old_data_grads_norm = 2.4438
	sim_grads_norm = 0.0954
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4534
	data_grads_norm = 2.2782
	new_data_grads_norm = 3.0871
	old_data_grads_norm = 3.5141
	sim_grads_norm = -0.0040
-- Starting training on experience 25 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9868
	data_grads_norm = 3.3157
	new_data_grads_norm = 3.9516
	old_data_grads_norm = 4.7759
	sim_grads_norm = 0.1584
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8882
	data_grads_norm = 2.2285
	new_data_grads_norm = 2.9545
	old_data_grads_norm = 2.8779
	sim_grads_norm = 0.1133
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3611
	data_grads_norm = 2.0936
	new_data_grads_norm = 3.1922
	old_data_grads_norm = 4.1027
	sim_grads_norm = -0.1779
-- Starting training on experience 26 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1722
	data_grads_norm = 4.1240
	new_data_grads_norm = 3.6295
	old_data_grads_norm = 4.3330
	sim_grads_norm = 0.3096
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7196
	data_grads_norm = 2.4334
	new_data_grads_norm = 2.7916
	old_data_grads_norm = 3.6319
	sim_grads_norm = -0.0556
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6663
	data_grads_norm = 2.3769
	new_data_grads_norm = 3.5022
	old_data_grads_norm = 3.5026
	sim_grads_norm = -0.0128
-- Starting training on experience 27 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2658
	data_grads_norm = 2.8084
	new_data_grads_norm = 3.2661
	old_data_grads_norm = 3.4689
	sim_grads_norm = 0.0625
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3797
	data_grads_norm = 2.4110
	new_data_grads_norm = 4.0702
	old_data_grads_norm = 2.9659
	sim_grads_norm = -0.0528
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3787
	data_grads_norm = 2.3173
	new_data_grads_norm = 3.7256
	old_data_grads_norm = 2.5041
	sim_grads_norm = 0.0669
-- Starting training on experience 28 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4347
	data_grads_norm = 2.3128
	new_data_grads_norm = 4.0922
	old_data_grads_norm = 2.5337
	sim_grads_norm = -0.0316
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7438
	data_grads_norm = 4.9812
	new_data_grads_norm = 4.4282
	old_data_grads_norm = 2.8809
	sim_grads_norm = 0.1005
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1364
	data_grads_norm = 3.2502
	new_data_grads_norm = 4.3179
	old_data_grads_norm = 3.5424
	sim_grads_norm = 0.4920
-- Starting training on experience 29 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3764
	data_grads_norm = 2.1187
	new_data_grads_norm = 3.2182
	old_data_grads_norm = 2.2321
	sim_grads_norm = 0.0476
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2278
	data_grads_norm = 2.0840
	new_data_grads_norm = 3.1639
	old_data_grads_norm = 2.5961
	sim_grads_norm = 0.0745
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4168
	data_grads_norm = 2.1241
	new_data_grads_norm = 2.9275
	old_data_grads_norm = 3.0800
	sim_grads_norm = -0.0934
-- Starting training on experience 30 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4083
	data_grads_norm = 2.0476
	new_data_grads_norm = 2.6847
	old_data_grads_norm = 2.6107
	sim_grads_norm = 0.1307
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4100
	data_grads_norm = 2.3505
	new_data_grads_norm = 2.8998
	old_data_grads_norm = 4.3762
	sim_grads_norm = 0.0901
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3915
	data_grads_norm = 2.4074
	new_data_grads_norm = 2.4397
	old_data_grads_norm = 3.9429
	sim_grads_norm = -0.1128
-- Starting training on experience 31 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3340
	data_grads_norm = 2.0608
	new_data_grads_norm = 3.1513
	old_data_grads_norm = 2.3403
	sim_grads_norm = -0.0142
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1840
	data_grads_norm = 1.7215
	new_data_grads_norm = 3.2910
	old_data_grads_norm = 1.9814
	sim_grads_norm = 0.1900
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8948
	data_grads_norm = 2.5715
	new_data_grads_norm = 3.4033
	old_data_grads_norm = 3.9945
	sim_grads_norm = 0.0870
-- Starting training on experience 32 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7988
	data_grads_norm = 2.6497
	new_data_grads_norm = 3.4250
	old_data_grads_norm = 3.7205
	sim_grads_norm = 0.1183
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3738
	data_grads_norm = 2.6324
	new_data_grads_norm = 3.4902
	old_data_grads_norm = 3.3411
	sim_grads_norm = 0.0546
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0689
	data_grads_norm = 1.7806
	new_data_grads_norm = 3.2012
	old_data_grads_norm = 2.8142
	sim_grads_norm = -0.1365
-- Starting training on experience 33 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3758
	data_grads_norm = 2.8729
	new_data_grads_norm = 3.8429
	old_data_grads_norm = 3.1865
	sim_grads_norm = 0.0284
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7863
	data_grads_norm = 3.0179
	new_data_grads_norm = 4.6922
	old_data_grads_norm = 3.3773
	sim_grads_norm = 0.1483
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0718
	data_grads_norm = 2.1211
	new_data_grads_norm = 3.9068
	old_data_grads_norm = 2.2057
	sim_grads_norm = 0.0966
-- Starting training on experience 34 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4438
	data_grads_norm = 2.8828
	new_data_grads_norm = 3.1789
	old_data_grads_norm = 4.0917
	sim_grads_norm = 0.0336
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4179
	data_grads_norm = 2.2331
	new_data_grads_norm = 3.6064
	old_data_grads_norm = 3.0318
	sim_grads_norm = 0.1063
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4083
	data_grads_norm = 2.3104
	new_data_grads_norm = 3.2919
	old_data_grads_norm = 2.8016
	sim_grads_norm = 0.2353
-- Starting training on experience 35 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6989
	data_grads_norm = 1.5343
	new_data_grads_norm = 2.8711
	old_data_grads_norm = 2.9414
	sim_grads_norm = -0.1939
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2814
	data_grads_norm = 2.1825
	new_data_grads_norm = 3.0202
	old_data_grads_norm = 2.8470
	sim_grads_norm = -0.0829
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2592
	data_grads_norm = 2.1281
	new_data_grads_norm = 3.2139
	old_data_grads_norm = 2.0490
	sim_grads_norm = -0.0303
-- Starting training on experience 36 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5939
	data_grads_norm = 2.7120
	new_data_grads_norm = 3.1510
	old_data_grads_norm = 3.2995
	sim_grads_norm = 0.0555
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6260
	data_grads_norm = 2.2164
	new_data_grads_norm = 3.0609
	old_data_grads_norm = 2.8032
	sim_grads_norm = 0.2186
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0779
	data_grads_norm = 1.8127
	new_data_grads_norm = 2.6501
	old_data_grads_norm = 3.2140
	sim_grads_norm = -0.0666
-- Starting training on experience 37 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2878
	data_grads_norm = 2.5336
	new_data_grads_norm = 3.9325
	old_data_grads_norm = 2.8835
	sim_grads_norm = -0.0221
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8933
	data_grads_norm = 2.8268
	new_data_grads_norm = 3.6723
	old_data_grads_norm = 3.5831
	sim_grads_norm = 0.1947
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5019
	data_grads_norm = 2.6053
	new_data_grads_norm = 3.1567
	old_data_grads_norm = 4.2962
	sim_grads_norm = 0.0389
-- Starting training on experience 38 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3579
	data_grads_norm = 2.7844
	new_data_grads_norm = 3.7020
	old_data_grads_norm = 3.8869
	sim_grads_norm = 0.0145
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2623
	data_grads_norm = 1.9338
	new_data_grads_norm = 4.1000
	old_data_grads_norm = 2.2296
	sim_grads_norm = -0.0096
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4614
	data_grads_norm = 2.4747
	new_data_grads_norm = 3.9533
	old_data_grads_norm = 3.0679
	sim_grads_norm = -0.0657
-- Starting training on experience 39 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3588
	data_grads_norm = 2.3171
	new_data_grads_norm = 3.5568
	old_data_grads_norm = 2.6801
	sim_grads_norm = 0.0192
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5702
	data_grads_norm = 2.5359
	new_data_grads_norm = 3.7395
	old_data_grads_norm = 3.1910
	sim_grads_norm = 0.0348
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5980
	data_grads_norm = 2.7340
	new_data_grads_norm = 3.7424
	old_data_grads_norm = 3.3432
	sim_grads_norm = 0.0179
-- Starting training on experience 40 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0490
	data_grads_norm = 2.0777
	new_data_grads_norm = 3.4114
	old_data_grads_norm = 2.4771
	sim_grads_norm = 0.1070
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3230
	data_grads_norm = 2.4415
	new_data_grads_norm = 3.8730
	old_data_grads_norm = 2.7785
	sim_grads_norm = 0.1899
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6585
	data_grads_norm = 2.8419
	new_data_grads_norm = 3.3299
	old_data_grads_norm = 3.6407
	sim_grads_norm = 0.1929
-- Starting training on experience 41 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2690
	data_grads_norm = 1.9288
	new_data_grads_norm = 2.3226
	old_data_grads_norm = 3.1615
	sim_grads_norm = -0.0038
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1409
	data_grads_norm = 2.4998
	new_data_grads_norm = 3.0916
	old_data_grads_norm = 2.8763
	sim_grads_norm = -0.0978
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4480
	data_grads_norm = 3.0507
	new_data_grads_norm = 3.2967
	old_data_grads_norm = 4.0683
	sim_grads_norm = 0.4566
-- Starting training on experience 42 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4004
	data_grads_norm = 1.8618
	new_data_grads_norm = 2.5972
	old_data_grads_norm = 3.1045
	sim_grads_norm = -0.0651
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1050
	data_grads_norm = 1.8159
	new_data_grads_norm = 3.0339
	old_data_grads_norm = 2.5318
	sim_grads_norm = -0.1630
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3443
	data_grads_norm = 1.9570
	new_data_grads_norm = 3.1076
	old_data_grads_norm = 2.5971
	sim_grads_norm = -0.0577
-- Starting training on experience 43 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4573
	data_grads_norm = 2.6135
	new_data_grads_norm = 2.7714
	old_data_grads_norm = 3.0444
	sim_grads_norm = 0.2512
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4128
	data_grads_norm = 2.8233
	new_data_grads_norm = 2.6913
	old_data_grads_norm = 4.7852
	sim_grads_norm = 0.1228
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2775
	data_grads_norm = 2.0829
	new_data_grads_norm = 2.6815
	old_data_grads_norm = 3.1564
	sim_grads_norm = -0.0924
-- Starting training on experience 44 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3170
	data_grads_norm = 2.1167
	new_data_grads_norm = 3.0114
	old_data_grads_norm = 2.7267
	sim_grads_norm = 0.1675
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2048
	data_grads_norm = 1.7207
	new_data_grads_norm = 2.9374
	old_data_grads_norm = 2.1682
	sim_grads_norm = 0.1278
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0741
	data_grads_norm = 2.3147
	new_data_grads_norm = 3.4035
	old_data_grads_norm = 2.4881
	sim_grads_norm = 0.1551
-- Starting training on experience 45 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4557
	data_grads_norm = 2.6886
	new_data_grads_norm = 2.6258
	old_data_grads_norm = 3.7021
	sim_grads_norm = 0.0686
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1454
	data_grads_norm = 3.1202
	new_data_grads_norm = 2.7674
	old_data_grads_norm = 3.6047
	sim_grads_norm = 0.0682
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0503
	data_grads_norm = 1.9835
	new_data_grads_norm = 2.6693
	old_data_grads_norm = 3.2370
	sim_grads_norm = -0.1324
-- Starting training on experience 46 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9395
	data_grads_norm = 1.6272
	new_data_grads_norm = 2.3689
	old_data_grads_norm = 2.5557
	sim_grads_norm = -0.0645
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1884
	data_grads_norm = 2.1939
	new_data_grads_norm = 2.8951
	old_data_grads_norm = 2.9322
	sim_grads_norm = 0.0265
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8205
	data_grads_norm = 1.6897
	new_data_grads_norm = 2.4558
	old_data_grads_norm = 2.7065
	sim_grads_norm = -0.0761
-- Starting training on experience 47 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9432
	data_grads_norm = 2.5073
	new_data_grads_norm = 3.1610
	old_data_grads_norm = 3.9781
	sim_grads_norm = -0.0072
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1436
	data_grads_norm = 2.2254
	new_data_grads_norm = 3.3158
	old_data_grads_norm = 3.1224
	sim_grads_norm = 0.0466
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9107
	data_grads_norm = 2.6110
	new_data_grads_norm = 3.2713
	old_data_grads_norm = 3.0509
	sim_grads_norm = 0.0368
-- Starting training on experience 48 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9922
	data_grads_norm = 2.3369
	new_data_grads_norm = 2.7594
	old_data_grads_norm = 3.9734
	sim_grads_norm = -0.0902
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2836
	data_grads_norm = 2.6347
	new_data_grads_norm = 3.7196
	old_data_grads_norm = 3.8623
	sim_grads_norm = 0.0717
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7587
	data_grads_norm = 3.0560
	new_data_grads_norm = 3.0887
	old_data_grads_norm = 4.3897
	sim_grads_norm = 0.2328
-- Starting training on experience 49 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0283
	data_grads_norm = 1.8623
	new_data_grads_norm = 2.9392
	old_data_grads_norm = 3.5069
	sim_grads_norm = -0.1114
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3688
	data_grads_norm = 2.2046
	new_data_grads_norm = 3.9594
	old_data_grads_norm = 2.6106
	sim_grads_norm = 0.0438
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8638
	data_grads_norm = 3.6051
	new_data_grads_norm = 4.2253
	old_data_grads_norm = 5.5206
	sim_grads_norm = 0.1170
-- Starting training on experience 50 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1772
	data_grads_norm = 2.6630
	new_data_grads_norm = 3.5334
	old_data_grads_norm = 3.5570
	sim_grads_norm = 0.0323
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0074
	data_grads_norm = 2.1207
	new_data_grads_norm = 3.5942
	old_data_grads_norm = 2.2064
	sim_grads_norm = -0.0108
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1350
	data_grads_norm = 2.2816
	new_data_grads_norm = 3.6062
	old_data_grads_norm = 3.2720
	sim_grads_norm = -0.0402
-- Starting training on experience 51 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5991
	data_grads_norm = 2.7366
	new_data_grads_norm = 3.5575
	old_data_grads_norm = 3.3395
	sim_grads_norm = -0.0073
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5065
	data_grads_norm = 3.1406
	new_data_grads_norm = 3.1162
	old_data_grads_norm = 5.3912
	sim_grads_norm = 0.0776
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7698
	data_grads_norm = 2.2475
	new_data_grads_norm = 2.9720
	old_data_grads_norm = 3.4036
	sim_grads_norm = 0.0052
-- Starting training on experience 52 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9479
	data_grads_norm = 2.3869
	new_data_grads_norm = 2.8873
	old_data_grads_norm = 4.0948
	sim_grads_norm = -0.0046
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2060
	data_grads_norm = 2.7057
	new_data_grads_norm = 3.0521
	old_data_grads_norm = 4.7380
	sim_grads_norm = 0.0795
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4459
	data_grads_norm = 3.3847
	new_data_grads_norm = 3.2207
	old_data_grads_norm = 5.6001
	sim_grads_norm = 0.1096
-- Starting training on experience 53 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3015
	data_grads_norm = 2.4696
	new_data_grads_norm = 2.9589
	old_data_grads_norm = 4.0206
	sim_grads_norm = 0.0061
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5047
	data_grads_norm = 2.6029
	new_data_grads_norm = 3.7986
	old_data_grads_norm = 2.8937
	sim_grads_norm = 0.1034
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0742
	data_grads_norm = 2.2646
	new_data_grads_norm = 3.4592
	old_data_grads_norm = 3.1874
	sim_grads_norm = -0.1011
-- Starting training on experience 54 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3874
	data_grads_norm = 2.7882
	new_data_grads_norm = 3.6987
	old_data_grads_norm = 3.4178
	sim_grads_norm = 0.3177
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1703
	data_grads_norm = 2.1197
	new_data_grads_norm = 2.8666
	old_data_grads_norm = 2.5545
	sim_grads_norm = 0.0377
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4602
	data_grads_norm = 3.9805
	new_data_grads_norm = 3.0806
	old_data_grads_norm = 5.3645
	sim_grads_norm = 0.0456
-- Starting training on experience 55 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2656
	data_grads_norm = 2.3140
	new_data_grads_norm = 3.3608
	old_data_grads_norm = 2.5067
	sim_grads_norm = 0.2182
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4183
	data_grads_norm = 2.4009
	new_data_grads_norm = 3.0698
	old_data_grads_norm = 4.1135
	sim_grads_norm = 0.0058
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0721
	data_grads_norm = 3.1103
	new_data_grads_norm = 3.6557
	old_data_grads_norm = 4.3905
	sim_grads_norm = 0.0862
-- Starting training on experience 56 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7399
	data_grads_norm = 3.5434
	new_data_grads_norm = 3.9899
	old_data_grads_norm = 4.1930
	sim_grads_norm = 0.3345
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1102
	data_grads_norm = 1.9847
	new_data_grads_norm = 3.0661
	old_data_grads_norm = 3.4847
	sim_grads_norm = -0.1378
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3367
	data_grads_norm = 2.4467
	new_data_grads_norm = 3.5259
	old_data_grads_norm = 3.0962
	sim_grads_norm = 0.0750
-- Starting training on experience 57 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1514
	data_grads_norm = 2.5333
	new_data_grads_norm = 3.3794
	old_data_grads_norm = 3.5527
	sim_grads_norm = -0.0155
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1933
	data_grads_norm = 2.4001
	new_data_grads_norm = 3.3677
	old_data_grads_norm = 3.4190
	sim_grads_norm = -0.0415
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5103
	data_grads_norm = 2.4421
	new_data_grads_norm = 3.4888
	old_data_grads_norm = 3.1616
	sim_grads_norm = 0.2892
-- Starting training on experience 58 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2719
	data_grads_norm = 2.3405
	new_data_grads_norm = 2.9065
	old_data_grads_norm = 3.2436
	sim_grads_norm = 0.0877
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9935
	data_grads_norm = 2.4250
	new_data_grads_norm = 2.8027
	old_data_grads_norm = 2.9197
	sim_grads_norm = 0.0179
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9542
	data_grads_norm = 2.3605
	new_data_grads_norm = 3.2041
	old_data_grads_norm = 2.9946
	sim_grads_norm = 0.1645
-- Starting training on experience 59 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9300
	data_grads_norm = 2.1882
	new_data_grads_norm = 3.2297
	old_data_grads_norm = 2.5370
	sim_grads_norm = -0.0107
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9772
	data_grads_norm = 2.7644
	new_data_grads_norm = 3.1710
	old_data_grads_norm = 4.7833
	sim_grads_norm = 0.0883
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3384
	data_grads_norm = 2.8273
	new_data_grads_norm = 3.4585
	old_data_grads_norm = 4.1886
	sim_grads_norm = 0.0716
-- Starting training on experience 60 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3830
	data_grads_norm = 2.8004
	new_data_grads_norm = 3.6877
	old_data_grads_norm = 3.8618
	sim_grads_norm = 0.0896
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7207
	data_grads_norm = 2.9385
	new_data_grads_norm = 3.3704
	old_data_grads_norm = 4.1335
	sim_grads_norm = 0.3610
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9244
	data_grads_norm = 2.1748
	new_data_grads_norm = 2.5661
	old_data_grads_norm = 3.4304
	sim_grads_norm = -0.1309
-- Starting training on experience 61 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0378
	data_grads_norm = 2.4886
	new_data_grads_norm = 3.4863
	old_data_grads_norm = 3.4182
	sim_grads_norm = 0.0517
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9231
	data_grads_norm = 2.0842
	new_data_grads_norm = 3.7750
	old_data_grads_norm = 2.7551
	sim_grads_norm = -0.0478
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8812
	data_grads_norm = 1.8487
	new_data_grads_norm = 3.7805
	old_data_grads_norm = 1.8748
	sim_grads_norm = 0.0659
-- Starting training on experience 62 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0891
	data_grads_norm = 1.9024
	new_data_grads_norm = 2.5789
	old_data_grads_norm = 2.2784
	sim_grads_norm = 0.2279
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6406
	data_grads_norm = 1.7147
	new_data_grads_norm = 2.3930
	old_data_grads_norm = 2.4401
	sim_grads_norm = -0.0651
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0546
	data_grads_norm = 2.1594
	new_data_grads_norm = 3.0133
	old_data_grads_norm = 3.3159
	sim_grads_norm = 0.0563
-- Starting training on experience 63 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4130
	data_grads_norm = 2.6260
	new_data_grads_norm = 3.4326
	old_data_grads_norm = 3.1586
	sim_grads_norm = 0.1083
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8636
	data_grads_norm = 2.1283
	new_data_grads_norm = 3.2779
	old_data_grads_norm = 2.8234
	sim_grads_norm = 0.1296
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7895
	data_grads_norm = 1.6204
	new_data_grads_norm = 2.9271
	old_data_grads_norm = 2.0296
	sim_grads_norm = -0.0511
-- Starting training on experience 64 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9130
	data_grads_norm = 2.1237
	new_data_grads_norm = 3.0081
	old_data_grads_norm = 3.2601
	sim_grads_norm = -0.0126
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2062
	data_grads_norm = 2.6359
	new_data_grads_norm = 3.0610
	old_data_grads_norm = 4.0115
	sim_grads_norm = 0.0560
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1339
	data_grads_norm = 2.5420
	new_data_grads_norm = 3.0298
	old_data_grads_norm = 4.9099
	sim_grads_norm = -0.0178
-- Starting training on experience 65 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1835
	data_grads_norm = 3.5076
	new_data_grads_norm = 3.5734
	old_data_grads_norm = 5.2386
	sim_grads_norm = 0.1739
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4394
	data_grads_norm = 2.7059
	new_data_grads_norm = 2.7620
	old_data_grads_norm = 4.4139
	sim_grads_norm = 0.0283
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7781
	data_grads_norm = 1.6041
	new_data_grads_norm = 2.8130
	old_data_grads_norm = 1.9175
	sim_grads_norm = -0.1068
-- Starting training on experience 66 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0975
	data_grads_norm = 2.5998
	new_data_grads_norm = 2.7075
	old_data_grads_norm = 4.9743
	sim_grads_norm = -0.0581
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2199
	data_grads_norm = 2.6701
	new_data_grads_norm = 3.9647
	old_data_grads_norm = 3.5016
	sim_grads_norm = -0.0063
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9686
	data_grads_norm = 2.4810
	new_data_grads_norm = 4.1393
	old_data_grads_norm = 3.5516
	sim_grads_norm = -0.0951
-- Starting training on experience 67 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7017
	data_grads_norm = 3.5432
	new_data_grads_norm = 4.3137
	old_data_grads_norm = 5.2880
	sim_grads_norm = 0.1498
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9224
	data_grads_norm = 2.3361
	new_data_grads_norm = 3.5587
	old_data_grads_norm = 3.8397
	sim_grads_norm = 0.0205
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2835
	data_grads_norm = 2.8384
	new_data_grads_norm = 3.7011
	old_data_grads_norm = 4.0022
	sim_grads_norm = 0.0037
-- Starting training on experience 68 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0744
	data_grads_norm = 2.4832
	new_data_grads_norm = 3.1934
	old_data_grads_norm = 3.5586
	sim_grads_norm = 0.0033
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1097
	data_grads_norm = 3.1876
	new_data_grads_norm = 3.1219
	old_data_grads_norm = 4.8691
	sim_grads_norm = -0.1258
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2715
	data_grads_norm = 2.6215
	new_data_grads_norm = 3.8643
	old_data_grads_norm = 3.4521
	sim_grads_norm = 0.0788
-- Starting training on experience 69 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2763
	data_grads_norm = 2.8355
	new_data_grads_norm = 3.5205
	old_data_grads_norm = 3.7268
	sim_grads_norm = 0.1591
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7100
	data_grads_norm = 3.3192
	new_data_grads_norm = 3.5328
	old_data_grads_norm = 5.2904
	sim_grads_norm = 0.1985
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0237
	data_grads_norm = 2.2585
	new_data_grads_norm = 2.8355
	old_data_grads_norm = 3.3622
	sim_grads_norm = -0.1049
-- Starting training on experience 70 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2392
	data_grads_norm = 3.1607
	new_data_grads_norm = 3.5150
	old_data_grads_norm = 3.8680
	sim_grads_norm = 0.1639
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9980
	data_grads_norm = 2.4137
	new_data_grads_norm = 2.9006
	old_data_grads_norm = 3.3284
	sim_grads_norm = -0.0276
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4817
	data_grads_norm = 3.1099
	new_data_grads_norm = 3.0841
	old_data_grads_norm = 5.5987
	sim_grads_norm = 0.0767
-- Starting training on experience 71 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5706
	data_grads_norm = 2.9500
	new_data_grads_norm = 2.6100
	old_data_grads_norm = 5.1443
	sim_grads_norm = 0.1248
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1488
	data_grads_norm = 2.2579
	new_data_grads_norm = 2.5589
	old_data_grads_norm = 3.0766
	sim_grads_norm = 0.2133
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9298
	data_grads_norm = 1.6533
	new_data_grads_norm = 2.3086
	old_data_grads_norm = 2.6877
	sim_grads_norm = -0.0678
-- Starting training on experience 72 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0165
	data_grads_norm = 2.3858
	new_data_grads_norm = 2.6350
	old_data_grads_norm = 3.4411
	sim_grads_norm = 0.0731
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1777
	data_grads_norm = 1.9186
	new_data_grads_norm = 2.6684
	old_data_grads_norm = 2.5124
	sim_grads_norm = 0.0267
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3578
	data_grads_norm = 2.3226
	new_data_grads_norm = 2.7670
	old_data_grads_norm = 2.9125
	sim_grads_norm = 0.2317
-- Starting training on experience 73 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9593
	data_grads_norm = 1.6396
	new_data_grads_norm = 2.9411
	old_data_grads_norm = 2.3381
	sim_grads_norm = -0.1905
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4882
	data_grads_norm = 2.2468
	new_data_grads_norm = 2.8753
	old_data_grads_norm = 3.1811
	sim_grads_norm = 0.0701
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4815
	data_grads_norm = 2.7043
	new_data_grads_norm = 2.9894
	old_data_grads_norm = 3.5482
	sim_grads_norm = 0.2666
-- Starting training on experience 74 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8570
	data_grads_norm = 1.7953
	new_data_grads_norm = 2.5223
	old_data_grads_norm = 3.1997
	sim_grads_norm = -0.0604
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0252
	data_grads_norm = 2.0499
	new_data_grads_norm = 2.6123
	old_data_grads_norm = 2.2478
	sim_grads_norm = 0.1460
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2151
	data_grads_norm = 2.2775
	new_data_grads_norm = 2.6626
	old_data_grads_norm = 3.6959
	sim_grads_norm = 0.1041
-- Starting training on experience 75 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2761
	data_grads_norm = 2.0697
	new_data_grads_norm = 2.6914
	old_data_grads_norm = 3.3449
	sim_grads_norm = -0.0664
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3071
	data_grads_norm = 2.0509
	new_data_grads_norm = 2.5401
	old_data_grads_norm = 3.0502
	sim_grads_norm = 0.0918
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7942
	data_grads_norm = 1.6193
	new_data_grads_norm = 2.6012
	old_data_grads_norm = 2.3764
	sim_grads_norm = -0.1682
-- Starting training on experience 76 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8122
	data_grads_norm = 1.9854
	new_data_grads_norm = 3.3458
	old_data_grads_norm = 2.2296
	sim_grads_norm = 0.0369
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2132
	data_grads_norm = 2.4473
	new_data_grads_norm = 3.5724
	old_data_grads_norm = 3.1856
	sim_grads_norm = 0.0651
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4172
	data_grads_norm = 2.4073
	new_data_grads_norm = 3.4471
	old_data_grads_norm = 3.0892
	sim_grads_norm = 0.0799
-- Starting training on experience 77 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9797
	data_grads_norm = 1.9870
	new_data_grads_norm = 3.2321
	old_data_grads_norm = 2.6524
	sim_grads_norm = -0.0827
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4164
	data_grads_norm = 2.6200
	new_data_grads_norm = 3.7884
	old_data_grads_norm = 3.0942
	sim_grads_norm = 0.1277
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2661
	data_grads_norm = 2.4956
	new_data_grads_norm = 3.5081
	old_data_grads_norm = 3.7503
	sim_grads_norm = -0.0747
-- Starting training on experience 78 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1316
	data_grads_norm = 2.0982
	new_data_grads_norm = 3.2179
	old_data_grads_norm = 2.4276
	sim_grads_norm = 0.1802
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9550
	data_grads_norm = 2.2302
	new_data_grads_norm = 3.2426
	old_data_grads_norm = 3.0205
	sim_grads_norm = 0.0100
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1733
	data_grads_norm = 2.2124
	new_data_grads_norm = 3.2977
	old_data_grads_norm = 3.7876
	sim_grads_norm = -0.0658
-- Starting training on experience 79 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9959
	data_grads_norm = 2.1442
	new_data_grads_norm = 3.3130
	old_data_grads_norm = 2.3626
	sim_grads_norm = 0.0060
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1682
	data_grads_norm = 2.1777
	new_data_grads_norm = 3.6947
	old_data_grads_norm = 2.2576
	sim_grads_norm = 0.0490
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3618
	data_grads_norm = 2.5118
	new_data_grads_norm = 3.2086
	old_data_grads_norm = 2.8551
	sim_grads_norm = 0.3846
-- Starting training on experience 80 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8748
	data_grads_norm = 2.1502
	new_data_grads_norm = 2.7395
	old_data_grads_norm = 3.1961
	sim_grads_norm = 0.0327
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1832
	data_grads_norm = 2.3529
	new_data_grads_norm = 3.0677
	old_data_grads_norm = 3.4862
	sim_grads_norm = -0.1913
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0331
	data_grads_norm = 2.5497
	new_data_grads_norm = 3.8302
	old_data_grads_norm = 3.0058
	sim_grads_norm = 0.0457
-- Starting training on experience 81 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4131
	data_grads_norm = 2.7101
	new_data_grads_norm = 3.4467
	old_data_grads_norm = 3.1916
	sim_grads_norm = 0.0886
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3193
	data_grads_norm = 2.4950
	new_data_grads_norm = 3.4636
	old_data_grads_norm = 3.6612
	sim_grads_norm = 0.0918
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2315
	data_grads_norm = 2.4142
	new_data_grads_norm = 3.5815
	old_data_grads_norm = 3.1431
	sim_grads_norm = 0.0127
-- Starting training on experience 82 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0931
	data_grads_norm = 1.9265
	new_data_grads_norm = 3.3174
	old_data_grads_norm = 3.1839
	sim_grads_norm = -0.0637
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4578
	data_grads_norm = 2.6201
	new_data_grads_norm = 3.6137
	old_data_grads_norm = 4.0480
	sim_grads_norm = 0.1401
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3733
	data_grads_norm = 2.3488
	new_data_grads_norm = 2.8794
	old_data_grads_norm = 3.3797
	sim_grads_norm = 0.0113
-- Starting training on experience 83 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1145
	data_grads_norm = 2.1359
	new_data_grads_norm = 3.0873
	old_data_grads_norm = 3.7239
	sim_grads_norm = -0.0575
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5157
	data_grads_norm = 2.5262
	new_data_grads_norm = 3.6013
	old_data_grads_norm = 3.0184
	sim_grads_norm = 0.2178
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0459
	data_grads_norm = 2.0659
	new_data_grads_norm = 2.9926
	old_data_grads_norm = 3.1064
	sim_grads_norm = -0.1484
-- Starting training on experience 84 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0911
	data_grads_norm = 1.9166
	new_data_grads_norm = 2.6960
	old_data_grads_norm = 2.5228
	sim_grads_norm = 0.0625
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2835
	data_grads_norm = 2.2564
	new_data_grads_norm = 2.8321
	old_data_grads_norm = 3.4190
	sim_grads_norm = 0.0214
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4233
	data_grads_norm = 2.1748
	new_data_grads_norm = 2.6299
	old_data_grads_norm = 3.1917
	sim_grads_norm = 0.1683
-- Starting training on experience 85 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4764
	data_grads_norm = 2.1004
	new_data_grads_norm = 3.2098
	old_data_grads_norm = 2.9388
	sim_grads_norm = 0.1471
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9170
	data_grads_norm = 1.8573
	new_data_grads_norm = 2.8820
	old_data_grads_norm = 2.3847
	sim_grads_norm = -0.0759
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1510
	data_grads_norm = 1.7747
	new_data_grads_norm = 3.2116
	old_data_grads_norm = 2.3882
	sim_grads_norm = 0.0227
-- Starting training on experience 86 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1096
	data_grads_norm = 1.8218
	new_data_grads_norm = 3.1094
	old_data_grads_norm = 2.5914
	sim_grads_norm = 0.0153
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6836
	data_grads_norm = 1.8049
	new_data_grads_norm = 3.2770
	old_data_grads_norm = 2.4789
	sim_grads_norm = 0.0652
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3476
	data_grads_norm = 2.9437
	new_data_grads_norm = 3.0917
	old_data_grads_norm = 4.3187
	sim_grads_norm = 0.2043
-- Starting training on experience 87 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1594
	data_grads_norm = 2.7873
	new_data_grads_norm = 3.2015
	old_data_grads_norm = 3.9205
	sim_grads_norm = 0.0790
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1398
	data_grads_norm = 2.4041
	new_data_grads_norm = 3.0190
	old_data_grads_norm = 3.5860
	sim_grads_norm = 0.0314
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2885
	data_grads_norm = 3.0160
	new_data_grads_norm = 3.2006
	old_data_grads_norm = 4.3574
	sim_grads_norm = 0.1608
-- Starting training on experience 88 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2293
	data_grads_norm = 2.4638
	new_data_grads_norm = 3.0076
	old_data_grads_norm = 3.6822
	sim_grads_norm = -0.0689
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3060
	data_grads_norm = 2.5712
	new_data_grads_norm = 3.7679
	old_data_grads_norm = 3.5260
	sim_grads_norm = -0.0077
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2907
	data_grads_norm = 2.0244
	new_data_grads_norm = 3.2538
	old_data_grads_norm = 2.2175
	sim_grads_norm = 0.0869
-- Starting training on experience 89 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1714
	data_grads_norm = 2.3187
	new_data_grads_norm = 3.0315
	old_data_grads_norm = 3.7237
	sim_grads_norm = -0.0489
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0811
	data_grads_norm = 2.2524
	new_data_grads_norm = 3.0562
	old_data_grads_norm = 3.0831
	sim_grads_norm = 0.0225
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2884
	data_grads_norm = 2.5194
	new_data_grads_norm = 2.9944
	old_data_grads_norm = 3.5833
	sim_grads_norm = 0.1877
-- Starting training on experience 90 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8266
	data_grads_norm = 2.9483
	new_data_grads_norm = 4.3208
	old_data_grads_norm = 3.2443
	sim_grads_norm = -0.0380
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7163
	data_grads_norm = 3.4280
	new_data_grads_norm = 4.6295
	old_data_grads_norm = 3.8654
	sim_grads_norm = 0.1187
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0134
	data_grads_norm = 2.1916
	new_data_grads_norm = 3.6826
	old_data_grads_norm = 2.6474
	sim_grads_norm = -0.1182
-- Starting training on experience 91 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3818
	data_grads_norm = 2.3235
	new_data_grads_norm = 3.1325
	old_data_grads_norm = 3.3828
	sim_grads_norm = 0.0087
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9440
	data_grads_norm = 2.1382
	new_data_grads_norm = 2.9060
	old_data_grads_norm = 3.6977
	sim_grads_norm = -0.0637
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3464
	data_grads_norm = 2.2909
	new_data_grads_norm = 3.0472
	old_data_grads_norm = 3.2265
	sim_grads_norm = 0.0857
-- Starting training on experience 92 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7177
	data_grads_norm = 1.7880
	new_data_grads_norm = 2.7175
	old_data_grads_norm = 2.0449
	sim_grads_norm = 0.1695
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7636
	data_grads_norm = 1.8004
	new_data_grads_norm = 2.4531
	old_data_grads_norm = 2.6444
	sim_grads_norm = 0.0452
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0125
	data_grads_norm = 1.9032
	new_data_grads_norm = 2.9719
	old_data_grads_norm = 2.3847
	sim_grads_norm = 0.0741
-- Starting training on experience 93 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6598
	data_grads_norm = 2.0999
	new_data_grads_norm = 1.9761
	old_data_grads_norm = 3.1691
	sim_grads_norm = -0.1315
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1048
	data_grads_norm = 2.4175
	new_data_grads_norm = 2.6574
	old_data_grads_norm = 2.8812
	sim_grads_norm = 0.1097
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0778
	data_grads_norm = 2.3230
	new_data_grads_norm = 2.5513
	old_data_grads_norm = 3.3914
	sim_grads_norm = 0.0650
-- Starting training on experience 94 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8167
	data_grads_norm = 2.0469
	new_data_grads_norm = 3.6060
	old_data_grads_norm = 2.4818
	sim_grads_norm = -0.0669
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9258
	data_grads_norm = 2.2873
	new_data_grads_norm = 4.0080
	old_data_grads_norm = 2.9892
	sim_grads_norm = -0.0895
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8026
	data_grads_norm = 2.3240
	new_data_grads_norm = 3.9123
	old_data_grads_norm = 3.0984
	sim_grads_norm = 0.0113
-- Starting training on experience 95 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1438
	data_grads_norm = 2.1776
	new_data_grads_norm = 2.6012
	old_data_grads_norm = 3.4469
	sim_grads_norm = 0.0659
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7979
	data_grads_norm = 2.1639
	new_data_grads_norm = 2.4628
	old_data_grads_norm = 3.5097
	sim_grads_norm = 0.0231
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7883
	data_grads_norm = 2.3863
	new_data_grads_norm = 2.6239
	old_data_grads_norm = 3.2965
	sim_grads_norm = 0.1231
-- Starting training on experience 96 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9370
	data_grads_norm = 2.3130
	new_data_grads_norm = 3.1343
	old_data_grads_norm = 3.3080
	sim_grads_norm = -0.0766
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8889
	data_grads_norm = 2.4738
	new_data_grads_norm = 2.9351
	old_data_grads_norm = 3.1890
	sim_grads_norm = 0.3131
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0648
	data_grads_norm = 2.3024
	new_data_grads_norm = 2.7463
	old_data_grads_norm = 3.4363
	sim_grads_norm = -0.0115
-- Starting training on experience 97 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6303
	data_grads_norm = 1.8641
	new_data_grads_norm = 2.8012
	old_data_grads_norm = 2.2309
	sim_grads_norm = 0.1688
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0267
	data_grads_norm = 2.0930
	new_data_grads_norm = 2.5219
	old_data_grads_norm = 2.8384
	sim_grads_norm = 0.1405
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6301
	data_grads_norm = 1.7953
	new_data_grads_norm = 2.3692
	old_data_grads_norm = 2.1626
	sim_grads_norm = 0.1958
-- Starting training on experience 98 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0558
	data_grads_norm = 1.9234
	new_data_grads_norm = 3.4837
	old_data_grads_norm = 2.3447
	sim_grads_norm = 0.0517
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9089
	data_grads_norm = 1.9354
	new_data_grads_norm = 3.7710
	old_data_grads_norm = 2.6330
	sim_grads_norm = 0.0257
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8931
	data_grads_norm = 2.2773
	new_data_grads_norm = 3.7044
	old_data_grads_norm = 3.2326
	sim_grads_norm = -0.0046
-- Starting training on experience 99 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6830
	data_grads_norm = 1.8919
	new_data_grads_norm = 3.2468
	old_data_grads_norm = 3.0894
	sim_grads_norm = -0.0850
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7485
	data_grads_norm = 2.3027
	new_data_grads_norm = 4.5138
	old_data_grads_norm = 3.4370
	sim_grads_norm = -0.0251
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9163
	data_grads_norm = 2.6321
	new_data_grads_norm = 4.8023
	old_data_grads_norm = 3.4651
	sim_grads_norm = -0.0288
-- Starting training on experience 100 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2408
	data_grads_norm = 2.3930
	new_data_grads_norm = 3.9930
	old_data_grads_norm = 2.9730
	sim_grads_norm = 0.0495
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3323
	data_grads_norm = 3.8612
	new_data_grads_norm = 3.6095
	old_data_grads_norm = 5.0560
	sim_grads_norm = 0.0554
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1202
	data_grads_norm = 2.8852
	new_data_grads_norm = 3.4515
	old_data_grads_norm = 4.1866
	sim_grads_norm = 0.1071
-- Starting training on experience 101 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3080
	data_grads_norm = 2.4242
	new_data_grads_norm = 3.5486
	old_data_grads_norm = 3.2346
	sim_grads_norm = 0.0655
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8859
	data_grads_norm = 1.9518
	new_data_grads_norm = 3.6907
	old_data_grads_norm = 2.7349
	sim_grads_norm = -0.0844
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4446
	data_grads_norm = 2.6891
	new_data_grads_norm = 3.5778
	old_data_grads_norm = 3.5188
	sim_grads_norm = 0.1627
-- Starting training on experience 102 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8197
	data_grads_norm = 2.5584
	new_data_grads_norm = 3.0229
	old_data_grads_norm = 4.3293
	sim_grads_norm = -0.0116
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0239
	data_grads_norm = 2.1420
	new_data_grads_norm = 3.0343
	old_data_grads_norm = 2.6557
	sim_grads_norm = 0.0491
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6505
	data_grads_norm = 1.9685
	new_data_grads_norm = 3.3139
	old_data_grads_norm = 3.1561
	sim_grads_norm = -0.1557
-- Starting training on experience 103 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9966
	data_grads_norm = 2.3122
	new_data_grads_norm = 3.4023
	old_data_grads_norm = 2.8325
	sim_grads_norm = 0.1725
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9273
	data_grads_norm = 2.6365
	new_data_grads_norm = 3.4775
	old_data_grads_norm = 3.8953
	sim_grads_norm = 0.0521
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1527
	data_grads_norm = 2.5836
	new_data_grads_norm = 3.6079
	old_data_grads_norm = 3.3587
	sim_grads_norm = 0.1399
-- Starting training on experience 104 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6937
	data_grads_norm = 1.9181
	new_data_grads_norm = 2.4558
	old_data_grads_norm = 2.9846
	sim_grads_norm = -0.1632
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0873
	data_grads_norm = 2.2474
	new_data_grads_norm = 3.0360
	old_data_grads_norm = 2.8409
	sim_grads_norm = 0.2170
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8528
	data_grads_norm = 2.5365
	new_data_grads_norm = 3.1370
	old_data_grads_norm = 4.1279
	sim_grads_norm = 0.0218
-- Starting training on experience 105 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0065
	data_grads_norm = 2.4799
	new_data_grads_norm = 3.7591
	old_data_grads_norm = 3.4608
	sim_grads_norm = -0.0703
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6986
	data_grads_norm = 1.9434
	new_data_grads_norm = 3.6534
	old_data_grads_norm = 2.5822
	sim_grads_norm = -0.2172
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6762
	data_grads_norm = 3.4142
	new_data_grads_norm = 4.5213
	old_data_grads_norm = 4.4068
	sim_grads_norm = 0.2428
-- Starting training on experience 106 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4180
	data_grads_norm = 2.7706
	new_data_grads_norm = 3.5969
	old_data_grads_norm = 3.5336
	sim_grads_norm = 0.0223
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2056
	data_grads_norm = 1.9052
	new_data_grads_norm = 3.2641
	old_data_grads_norm = 2.1375
	sim_grads_norm = -0.0169
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2420
	data_grads_norm = 2.1012
	new_data_grads_norm = 3.3588
	old_data_grads_norm = 2.2473
	sim_grads_norm = 0.2139
-- Starting training on experience 107 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9015
	data_grads_norm = 1.9111
	new_data_grads_norm = 2.4723
	old_data_grads_norm = 2.8653
	sim_grads_norm = -0.0588
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9878
	data_grads_norm = 2.0957
	new_data_grads_norm = 2.9481
	old_data_grads_norm = 2.3356
	sim_grads_norm = 0.2559
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9206
	data_grads_norm = 1.9548
	new_data_grads_norm = 3.0266
	old_data_grads_norm = 2.5711
	sim_grads_norm = -0.0309
-- Starting training on experience 108 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5174
	data_grads_norm = 2.7587
	new_data_grads_norm = 3.6460
	old_data_grads_norm = 3.3772
	sim_grads_norm = 0.0166
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1975
	data_grads_norm = 2.8414
	new_data_grads_norm = 4.4240
	old_data_grads_norm = 3.2849
	sim_grads_norm = 0.1443
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2448
	data_grads_norm = 2.6790
	new_data_grads_norm = 4.0882
	old_data_grads_norm = 4.0292
	sim_grads_norm = -0.0098
-- Starting training on experience 109 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4387
	data_grads_norm = 2.9373
	new_data_grads_norm = 3.8995
	old_data_grads_norm = 3.5613
	sim_grads_norm = 0.1361
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9580
	data_grads_norm = 1.9541
	new_data_grads_norm = 3.6492
	old_data_grads_norm = 2.5022
	sim_grads_norm = -0.1245
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9828
	data_grads_norm = 2.6732
	new_data_grads_norm = 4.0474
	old_data_grads_norm = 3.2270
	sim_grads_norm = 0.1171
-- Starting training on experience 110 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8733
	data_grads_norm = 2.6210
	new_data_grads_norm = 3.6032
	old_data_grads_norm = 3.4411
	sim_grads_norm = 0.0652
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7602
	data_grads_norm = 2.2031
	new_data_grads_norm = 3.4292
	old_data_grads_norm = 2.6672
	sim_grads_norm = 0.0002
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7077
	data_grads_norm = 2.2174
	new_data_grads_norm = 3.5060
	old_data_grads_norm = 2.9182
	sim_grads_norm = 0.0341
-- Starting training on experience 111 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8597
	data_grads_norm = 2.3632
	new_data_grads_norm = 2.8263
	old_data_grads_norm = 3.7352
	sim_grads_norm = 0.0132
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9881
	data_grads_norm = 2.2531
	new_data_grads_norm = 2.9720
	old_data_grads_norm = 3.4041
	sim_grads_norm = -0.0239
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0130
	data_grads_norm = 2.0630
	new_data_grads_norm = 3.0257
	old_data_grads_norm = 2.8937
	sim_grads_norm = 0.1214
-- Starting training on experience 112 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3145
	data_grads_norm = 3.1246
	new_data_grads_norm = 5.0540
	old_data_grads_norm = 3.1569
	sim_grads_norm = -0.0119
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1015
	data_grads_norm = 2.9966
	new_data_grads_norm = 4.0866
	old_data_grads_norm = 3.7683
	sim_grads_norm = 0.0816
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8058
	data_grads_norm = 3.3474
	new_data_grads_norm = 4.4289
	old_data_grads_norm = 2.9880
	sim_grads_norm = -0.0614
-- Starting training on experience 113 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7692
	data_grads_norm = 1.9115
	new_data_grads_norm = 3.7176
	old_data_grads_norm = 2.4863
	sim_grads_norm = -0.1255
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8699
	data_grads_norm = 2.1963
	new_data_grads_norm = 3.8222
	old_data_grads_norm = 3.7949
	sim_grads_norm = -0.0482
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9928
	data_grads_norm = 2.7692
	new_data_grads_norm = 4.1709
	old_data_grads_norm = 3.7168
	sim_grads_norm = -0.0626
-- Starting training on experience 114 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4757
	data_grads_norm = 3.0442
	new_data_grads_norm = 3.9086
	old_data_grads_norm = 4.4744
	sim_grads_norm = -0.0059
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7798
	data_grads_norm = 2.1584
	new_data_grads_norm = 3.2288
	old_data_grads_norm = 3.2944
	sim_grads_norm = -0.0798
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7189
	data_grads_norm = 3.2936
	new_data_grads_norm = 3.6623
	old_data_grads_norm = 4.8027
	sim_grads_norm = 0.2183
-- Starting training on experience 115 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1182
	data_grads_norm = 2.4934
	new_data_grads_norm = 3.0821
	old_data_grads_norm = 3.1891
	sim_grads_norm = 0.1638
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8047
	data_grads_norm = 1.4536
	new_data_grads_norm = 2.7766
	old_data_grads_norm = 2.0134
	sim_grads_norm = -0.1624
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8726
	data_grads_norm = 2.7599
	new_data_grads_norm = 3.1558
	old_data_grads_norm = 4.1798
	sim_grads_norm = -0.0990
-- Starting training on experience 116 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7938
	data_grads_norm = 2.6260
	new_data_grads_norm = 3.9451
	old_data_grads_norm = 3.4330
	sim_grads_norm = 0.0366
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5961
	data_grads_norm = 2.4665
	new_data_grads_norm = 3.9988
	old_data_grads_norm = 2.8498
	sim_grads_norm = -0.0245
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8562
	data_grads_norm = 2.6970
	new_data_grads_norm = 4.1469
	old_data_grads_norm = 3.5699
	sim_grads_norm = -0.0739
-- Starting training on experience 117 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4304
	data_grads_norm = 3.2837
	new_data_grads_norm = 4.7637
	old_data_grads_norm = 3.6449
	sim_grads_norm = 0.2172
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1259
	data_grads_norm = 3.0421
	new_data_grads_norm = 3.6350
	old_data_grads_norm = 3.0781
	sim_grads_norm = 0.0668
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3779
	data_grads_norm = 2.7479
	new_data_grads_norm = 3.6970
	old_data_grads_norm = 4.0710
	sim_grads_norm = 0.0531
-- Starting training on experience 118 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2352
	data_grads_norm = 2.6098
	new_data_grads_norm = 3.4984
	old_data_grads_norm = 3.2736
	sim_grads_norm = 0.1493
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0051
	data_grads_norm = 2.6380
	new_data_grads_norm = 2.6557
	old_data_grads_norm = 5.3818
	sim_grads_norm = -0.0023
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8005
	data_grads_norm = 2.1215
	new_data_grads_norm = 2.8507
	old_data_grads_norm = 2.4761
	sim_grads_norm = 0.1898
-- Starting training on experience 119 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9350
	data_grads_norm = 2.0294
	new_data_grads_norm = 3.0741
	old_data_grads_norm = 2.7892
	sim_grads_norm = 0.0118
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3159
	data_grads_norm = 2.5635
	new_data_grads_norm = 3.4184
	old_data_grads_norm = 3.5291
	sim_grads_norm = -0.0283
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5414
	data_grads_norm = 2.0765
	new_data_grads_norm = 3.6076
	old_data_grads_norm = 2.3638
	sim_grads_norm = -0.0846
-- Starting training on experience 120 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4888
	data_grads_norm = 3.2104
	new_data_grads_norm = 4.4105
	old_data_grads_norm = 4.2635
	sim_grads_norm = 0.0608
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4188
	data_grads_norm = 3.1567
	new_data_grads_norm = 4.2029
	old_data_grads_norm = 4.1311
	sim_grads_norm = 0.1075
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4957
	data_grads_norm = 3.3560
	new_data_grads_norm = 3.7798
	old_data_grads_norm = 4.3823
	sim_grads_norm = 0.0933
-- Starting training on experience 121 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2511
	data_grads_norm = 2.9946
	new_data_grads_norm = 4.0892
	old_data_grads_norm = 3.9127
	sim_grads_norm = 0.1271
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9269
	data_grads_norm = 2.1262
	new_data_grads_norm = 3.5000
	old_data_grads_norm = 2.4097
	sim_grads_norm = -0.0031
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4577
	data_grads_norm = 3.0948
	new_data_grads_norm = 3.7002
	old_data_grads_norm = 5.0820
	sim_grads_norm = 0.0173
-- Starting training on experience 122 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8784
	data_grads_norm = 2.6544
	new_data_grads_norm = 3.2651
	old_data_grads_norm = 3.2117
	sim_grads_norm = 0.1964
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8000
	data_grads_norm = 2.1142
	new_data_grads_norm = 3.0951
	old_data_grads_norm = 2.4499
	sim_grads_norm = 0.0570
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1925
	data_grads_norm = 2.4375
	new_data_grads_norm = 3.1169
	old_data_grads_norm = 3.2255
	sim_grads_norm = 0.1105
-- Starting training on experience 123 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8503
	data_grads_norm = 2.3562
	new_data_grads_norm = 3.0773
	old_data_grads_norm = 3.6020
	sim_grads_norm = -0.0741
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8392
	data_grads_norm = 2.0702
	new_data_grads_norm = 3.0884
	old_data_grads_norm = 2.6566
	sim_grads_norm = -0.0640
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7545
	data_grads_norm = 2.0065
	new_data_grads_norm = 2.9575
	old_data_grads_norm = 2.6813
	sim_grads_norm = -0.0614
-- Starting training on experience 124 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8323
	data_grads_norm = 2.0970
	new_data_grads_norm = 2.7031
	old_data_grads_norm = 3.7674
	sim_grads_norm = -0.0678
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9030
	data_grads_norm = 2.1472
	new_data_grads_norm = 2.8879
	old_data_grads_norm = 2.5123
	sim_grads_norm = 0.2378
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9231
	data_grads_norm = 2.0869
	new_data_grads_norm = 2.8794
	old_data_grads_norm = 2.7460
	sim_grads_norm = 0.0919
-- Starting training on experience 125 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4710
	data_grads_norm = 2.8042
	new_data_grads_norm = 5.0287
	old_data_grads_norm = 2.8311
	sim_grads_norm = 0.1665
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9070
	data_grads_norm = 2.3390
	new_data_grads_norm = 4.2064
	old_data_grads_norm = 2.9648
	sim_grads_norm = -0.0227
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9002
	data_grads_norm = 2.5997
	new_data_grads_norm = 4.4579
	old_data_grads_norm = 3.7636
	sim_grads_norm = 0.0781
-- Starting training on experience 126 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2359
	data_grads_norm = 3.1728
	new_data_grads_norm = 3.5264
	old_data_grads_norm = 4.9771
	sim_grads_norm = 0.0033
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3496
	data_grads_norm = 2.0364
	new_data_grads_norm = 2.9746
	old_data_grads_norm = 4.3564
	sim_grads_norm = -0.1149
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1224
	data_grads_norm = 3.0569
	new_data_grads_norm = 3.8784
	old_data_grads_norm = 4.2580
	sim_grads_norm = -0.0330
-- Starting training on experience 127 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9355
	data_grads_norm = 2.3081
	new_data_grads_norm = 3.4123
	old_data_grads_norm = 3.3011
	sim_grads_norm = -0.0488
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6530
	data_grads_norm = 3.0318
	new_data_grads_norm = 3.8154
	old_data_grads_norm = 4.6891
	sim_grads_norm = 0.0158
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2178
	data_grads_norm = 3.4400
	new_data_grads_norm = 3.3064
	old_data_grads_norm = 5.4424
	sim_grads_norm = 0.0380
-- Starting training on experience 128 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3103
	data_grads_norm = 2.7823
	new_data_grads_norm = 4.3362
	old_data_grads_norm = 3.3739
	sim_grads_norm = 0.1759
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0492
	data_grads_norm = 2.4069
	new_data_grads_norm = 3.7588
	old_data_grads_norm = 3.1130
	sim_grads_norm = -0.1604
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1857
	data_grads_norm = 2.4343
	new_data_grads_norm = 3.8501
	old_data_grads_norm = 3.5682
	sim_grads_norm = 0.0182
-- Starting training on experience 129 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5344
	data_grads_norm = 2.2792
	new_data_grads_norm = 3.7438
	old_data_grads_norm = 2.5828
	sim_grads_norm = 0.0672
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2601
	data_grads_norm = 3.1994
	new_data_grads_norm = 3.8312
	old_data_grads_norm = 4.7636
	sim_grads_norm = -0.0353
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3960
	data_grads_norm = 2.3814
	new_data_grads_norm = 3.7204
	old_data_grads_norm = 3.1816
	sim_grads_norm = 0.0444
-- Starting training on experience 130 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2529
	data_grads_norm = 2.4416
	new_data_grads_norm = 3.3896
	old_data_grads_norm = 3.1687
	sim_grads_norm = 0.1551
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0303
	data_grads_norm = 2.1592
	new_data_grads_norm = 3.1621
	old_data_grads_norm = 2.4364
	sim_grads_norm = 0.0622
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3252
	data_grads_norm = 2.4383
	new_data_grads_norm = 3.0240
	old_data_grads_norm = 3.4052
	sim_grads_norm = 0.0246
-- Starting training on experience 131 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0652
	data_grads_norm = 2.6120
	new_data_grads_norm = 3.1132
	old_data_grads_norm = 3.4567
	sim_grads_norm = 0.1903
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1539
	data_grads_norm = 2.3762
	new_data_grads_norm = 3.3499
	old_data_grads_norm = 3.1013
	sim_grads_norm = 0.1476
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7291
	data_grads_norm = 1.8720
	new_data_grads_norm = 3.1708
	old_data_grads_norm = 2.3445
	sim_grads_norm = -0.0536
-- Starting training on experience 132 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2096
	data_grads_norm = 2.3306
	new_data_grads_norm = 2.5170
	old_data_grads_norm = 3.1751
	sim_grads_norm = 0.1926
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0556
	data_grads_norm = 1.8360
	new_data_grads_norm = 2.5296
	old_data_grads_norm = 2.5014
	sim_grads_norm = 0.1264
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2846
	data_grads_norm = 2.3341
	new_data_grads_norm = 2.1694
	old_data_grads_norm = 3.3028
	sim_grads_norm = 0.0543
-- Starting training on experience 133 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9778
	data_grads_norm = 2.1849
	new_data_grads_norm = 3.0352
	old_data_grads_norm = 2.8430
	sim_grads_norm = 0.0034
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1740
	data_grads_norm = 2.4378
	new_data_grads_norm = 3.3226
	old_data_grads_norm = 4.0806
	sim_grads_norm = 0.0089
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1759
	data_grads_norm = 2.5737
	new_data_grads_norm = 3.3104
	old_data_grads_norm = 3.5460
	sim_grads_norm = 0.0578
-- Starting training on experience 134 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7558
	data_grads_norm = 2.3131
	new_data_grads_norm = 4.0299
	old_data_grads_norm = 3.4622
	sim_grads_norm = -0.0639
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1576
	data_grads_norm = 2.8591
	new_data_grads_norm = 3.9749
	old_data_grads_norm = 3.2326
	sim_grads_norm = 0.0999
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9396
	data_grads_norm = 2.4233
	new_data_grads_norm = 3.9231
	old_data_grads_norm = 3.3335
	sim_grads_norm = 0.1184
-- Starting training on experience 135 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8619
	data_grads_norm = 2.4784
	new_data_grads_norm = 3.9131
	old_data_grads_norm = 2.8987
	sim_grads_norm = 0.0512
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1303
	data_grads_norm = 2.5570
	new_data_grads_norm = 4.2438
	old_data_grads_norm = 2.6755
	sim_grads_norm = 0.2949
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2598
	data_grads_norm = 3.0788
	new_data_grads_norm = 3.7226
	old_data_grads_norm = 3.3739
	sim_grads_norm = 0.0078
-- Starting training on experience 136 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6769
	data_grads_norm = 2.3121
	new_data_grads_norm = 2.9535
	old_data_grads_norm = 3.4223
	sim_grads_norm = -0.0730
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7414
	data_grads_norm = 2.6248
	new_data_grads_norm = 3.4186
	old_data_grads_norm = 2.8314
	sim_grads_norm = 0.1719
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4668
	data_grads_norm = 2.2939
	new_data_grads_norm = 3.4031
	old_data_grads_norm = 2.6410
	sim_grads_norm = -0.0991
-- Starting training on experience 137 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0763
	data_grads_norm = 2.8643
	new_data_grads_norm = 3.2859
	old_data_grads_norm = 4.0010
	sim_grads_norm = 0.0399
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0223
	data_grads_norm = 2.9213
	new_data_grads_norm = 3.3134
	old_data_grads_norm = 3.6891
	sim_grads_norm = -0.0211
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0922
	data_grads_norm = 2.6748
	new_data_grads_norm = 3.7491
	old_data_grads_norm = 3.8451
	sim_grads_norm = 0.0499
-- Starting training on experience 138 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2270
	data_grads_norm = 2.6627
	new_data_grads_norm = 3.9487
	old_data_grads_norm = 3.8735
	sim_grads_norm = 0.0304
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2253
	data_grads_norm = 3.0279
	new_data_grads_norm = 3.7932
	old_data_grads_norm = 4.9090
	sim_grads_norm = 0.0767
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0757
	data_grads_norm = 2.5716
	new_data_grads_norm = 3.6585
	old_data_grads_norm = 3.8197
	sim_grads_norm = 0.0931
-- Starting training on experience 139 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0113
	data_grads_norm = 2.4211
	new_data_grads_norm = 3.6558
	old_data_grads_norm = 2.9596
	sim_grads_norm = 0.0261
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0159
	data_grads_norm = 2.2274
	new_data_grads_norm = 3.3782
	old_data_grads_norm = 2.6245
	sim_grads_norm = 0.1824
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8963
	data_grads_norm = 2.3302
	new_data_grads_norm = 3.2460
	old_data_grads_norm = 3.2773
	sim_grads_norm = -0.0040
-- Starting training on experience 140 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0889
	data_grads_norm = 2.8431
	new_data_grads_norm = 4.5893
	old_data_grads_norm = 4.1313
	sim_grads_norm = -0.0670
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0614
	data_grads_norm = 2.4656
	new_data_grads_norm = 5.1023
	old_data_grads_norm = 2.9396
	sim_grads_norm = 0.0380
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3888
	data_grads_norm = 2.9619
	new_data_grads_norm = 4.7534
	old_data_grads_norm = 4.4529
	sim_grads_norm = -0.0114
-- Starting training on experience 141 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6931
	data_grads_norm = 2.2552
	new_data_grads_norm = 3.5034
	old_data_grads_norm = 2.4543
	sim_grads_norm = 0.0662
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1052
	data_grads_norm = 2.9711
	new_data_grads_norm = 3.6808
	old_data_grads_norm = 3.7501
	sim_grads_norm = 0.3361
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8657
	data_grads_norm = 2.2741
	new_data_grads_norm = 3.0174
	old_data_grads_norm = 3.2289
	sim_grads_norm = 0.0731
-- Starting training on experience 142 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1440
	data_grads_norm = 2.6342
	new_data_grads_norm = 3.5712
	old_data_grads_norm = 2.8866
	sim_grads_norm = 0.2272
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7995
	data_grads_norm = 2.3900
	new_data_grads_norm = 2.9297
	old_data_grads_norm = 3.9274
	sim_grads_norm = -0.0358
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8439
	data_grads_norm = 2.5451
	new_data_grads_norm = 3.3616
	old_data_grads_norm = 4.6530
	sim_grads_norm = -0.0080
-- Starting training on experience 143 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2019
	data_grads_norm = 3.4635
	new_data_grads_norm = 4.8820
	old_data_grads_norm = 4.1732
	sim_grads_norm = 0.1452
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1826
	data_grads_norm = 2.9219
	new_data_grads_norm = 5.3708
	old_data_grads_norm = 3.1171
	sim_grads_norm = 0.0152
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8179
	data_grads_norm = 2.5300
	new_data_grads_norm = 5.1796
	old_data_grads_norm = 2.9220
	sim_grads_norm = 0.0471
-- Starting training on experience 144 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7017
	data_grads_norm = 2.1589
	new_data_grads_norm = 3.7475
	old_data_grads_norm = 2.4045
	sim_grads_norm = -0.0663
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2287
	data_grads_norm = 3.1322
	new_data_grads_norm = 3.6376
	old_data_grads_norm = 3.7362
	sim_grads_norm = 0.0277
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9584
	data_grads_norm = 2.9091
	new_data_grads_norm = 4.2291
	old_data_grads_norm = 2.7312
	sim_grads_norm = 0.1124
-- Starting training on experience 145 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4374
	data_grads_norm = 3.7778
	new_data_grads_norm = 6.1030
	old_data_grads_norm = 3.1358
	sim_grads_norm = 0.2145
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5042
	data_grads_norm = 3.2524
	new_data_grads_norm = 5.0640
	old_data_grads_norm = 3.7335
	sim_grads_norm = -0.0167
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3078
	data_grads_norm = 3.0675
	new_data_grads_norm = 5.0421
	old_data_grads_norm = 3.5903
	sim_grads_norm = 0.0561
-- Starting training on experience 146 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7354
	data_grads_norm = 1.8660
	new_data_grads_norm = 3.0112
	old_data_grads_norm = 3.0753
	sim_grads_norm = -0.0608
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9746
	data_grads_norm = 2.4335
	new_data_grads_norm = 3.5972
	old_data_grads_norm = 3.2494
	sim_grads_norm = 0.1556
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9807
	data_grads_norm = 2.4738
	new_data_grads_norm = 2.8923
	old_data_grads_norm = 2.9810
	sim_grads_norm = -0.0854
-- Starting training on experience 147 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8933
	data_grads_norm = 2.3461
	new_data_grads_norm = 3.1869
	old_data_grads_norm = 4.2969
	sim_grads_norm = -0.1515
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2847
	data_grads_norm = 2.9020
	new_data_grads_norm = 4.0271
	old_data_grads_norm = 3.7906
	sim_grads_norm = 0.0498
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6801
	data_grads_norm = 2.6486
	new_data_grads_norm = 4.2031
	old_data_grads_norm = 3.1980
	sim_grads_norm = 0.0513
-- Starting training on experience 148 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7017
	data_grads_norm = 2.7953
	new_data_grads_norm = 3.7694
	old_data_grads_norm = 4.3006
	sim_grads_norm = 0.0815
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8869
	data_grads_norm = 2.6659
	new_data_grads_norm = 4.1731
	old_data_grads_norm = 3.4026
	sim_grads_norm = 0.1671
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8961
	data_grads_norm = 3.2411
	new_data_grads_norm = 4.5785
	old_data_grads_norm = 3.5334
	sim_grads_norm = 0.0016
-- Starting training on experience 149 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4239
	data_grads_norm = 3.1198
	new_data_grads_norm = 4.2170
	old_data_grads_norm = 3.8940
	sim_grads_norm = 0.2144
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0303
	data_grads_norm = 2.4971
	new_data_grads_norm = 3.8586
	old_data_grads_norm = 2.7431
	sim_grads_norm = -0.0801
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0998
	data_grads_norm = 2.6909
	new_data_grads_norm = 3.7808
	old_data_grads_norm = 3.2292
	sim_grads_norm = 0.0959
-- Starting training on experience 150 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8442
	data_grads_norm = 2.3089
	new_data_grads_norm = 3.9818
	old_data_grads_norm = 3.7970
	sim_grads_norm = -0.1784
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0807
	data_grads_norm = 2.6909
	new_data_grads_norm = 4.0884
	old_data_grads_norm = 2.9505
	sim_grads_norm = 0.1760
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1056
	data_grads_norm = 2.5372
	new_data_grads_norm = 4.1043
	old_data_grads_norm = 2.6708
	sim_grads_norm = 0.1333
-- Starting training on experience 151 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6180
	data_grads_norm = 2.3307
	new_data_grads_norm = 4.0454
	old_data_grads_norm = 2.9141
	sim_grads_norm = -0.0034
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2438
	data_grads_norm = 3.5658
	new_data_grads_norm = 4.3386
	old_data_grads_norm = 2.8211
	sim_grads_norm = 0.3083
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6981
	data_grads_norm = 2.4518
	new_data_grads_norm = 4.0334
	old_data_grads_norm = 3.5254
	sim_grads_norm = -0.1129
-- Starting training on experience 152 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9863
	data_grads_norm = 2.6362
	new_data_grads_norm = 3.8437
	old_data_grads_norm = 3.3312
	sim_grads_norm = 0.0409
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1678
	data_grads_norm = 2.7513
	new_data_grads_norm = 2.9335
	old_data_grads_norm = 3.7219
	sim_grads_norm = 0.2789
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9330
	data_grads_norm = 2.3297
	new_data_grads_norm = 2.7150
	old_data_grads_norm = 3.6881
	sim_grads_norm = -0.0049
-- Starting training on experience 153 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0831
	data_grads_norm = 2.4343
	new_data_grads_norm = 3.0565
	old_data_grads_norm = 3.7980
	sim_grads_norm = -0.1364
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0664
	data_grads_norm = 2.8425
	new_data_grads_norm = 3.3870
	old_data_grads_norm = 3.9347
	sim_grads_norm = 0.0841
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2701
	data_grads_norm = 2.6870
	new_data_grads_norm = 3.1264
	old_data_grads_norm = 3.9755
	sim_grads_norm = 0.0419
-- Starting training on experience 154 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9629
	data_grads_norm = 2.4607
	new_data_grads_norm = 2.6957
	old_data_grads_norm = 3.6454
	sim_grads_norm = -0.0814
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1308
	data_grads_norm = 3.3065
	new_data_grads_norm = 3.6112
	old_data_grads_norm = 4.7854
	sim_grads_norm = 0.0099
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2482
	data_grads_norm = 2.9548
	new_data_grads_norm = 3.2975
	old_data_grads_norm = 4.6496
	sim_grads_norm = 0.0667
-- Starting training on experience 155 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3514
	data_grads_norm = 3.1617
	new_data_grads_norm = 3.4169
	old_data_grads_norm = 4.8771
	sim_grads_norm = -0.0713
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9977
	data_grads_norm = 1.9183
	new_data_grads_norm = 3.6375
	old_data_grads_norm = 2.3233
	sim_grads_norm = -0.0991
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1519
	data_grads_norm = 2.7983
	new_data_grads_norm = 4.1085
	old_data_grads_norm = 3.3739
	sim_grads_norm = 0.2172
-- Starting training on experience 156 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9296
	data_grads_norm = 2.5954
	new_data_grads_norm = 3.3265
	old_data_grads_norm = 3.0746
	sim_grads_norm = 0.1725
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0891
	data_grads_norm = 2.5010
	new_data_grads_norm = 3.3528
	old_data_grads_norm = 3.3918
	sim_grads_norm = 0.0130
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9135
	data_grads_norm = 2.5336
	new_data_grads_norm = 3.6108
	old_data_grads_norm = 3.9002
	sim_grads_norm = 0.0628
-- Starting training on experience 157 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4703
	data_grads_norm = 3.0327
	new_data_grads_norm = 4.0227
	old_data_grads_norm = 3.8716
	sim_grads_norm = 0.0473
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0061
	data_grads_norm = 2.3222
	new_data_grads_norm = 3.6014
	old_data_grads_norm = 3.6225
	sim_grads_norm = -0.1244
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1354
	data_grads_norm = 2.8713
	new_data_grads_norm = 4.2579
	old_data_grads_norm = 2.7773
	sim_grads_norm = 0.0967
-- Starting training on experience 158 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2884
	data_grads_norm = 2.6142
	new_data_grads_norm = 4.5197
	old_data_grads_norm = 3.0015
	sim_grads_norm = 0.1592
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9776
	data_grads_norm = 2.5507
	new_data_grads_norm = 4.3290
	old_data_grads_norm = 3.2977
	sim_grads_norm = 0.0310
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5469
	data_grads_norm = 3.3751
	new_data_grads_norm = 4.7243
	old_data_grads_norm = 4.1467
	sim_grads_norm = 0.1819
-- Starting training on experience 159 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6466
	data_grads_norm = 1.5648
	new_data_grads_norm = 3.5120
	old_data_grads_norm = 2.6916
	sim_grads_norm = -0.2001
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2887
	data_grads_norm = 2.2265
	new_data_grads_norm = 3.1005
	old_data_grads_norm = 3.0296
	sim_grads_norm = 0.1317
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3797
	data_grads_norm = 2.5974
	new_data_grads_norm = 2.9690
	old_data_grads_norm = 4.1210
	sim_grads_norm = 0.0614
-- Starting training on experience 160 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8954
	data_grads_norm = 2.1956
	new_data_grads_norm = 3.0730
	old_data_grads_norm = 3.2599
	sim_grads_norm = -0.0528
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8358
	data_grads_norm = 2.1235
	new_data_grads_norm = 3.2348
	old_data_grads_norm = 2.8635
	sim_grads_norm = 0.0261
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2369
	data_grads_norm = 3.2430
	new_data_grads_norm = 3.5087
	old_data_grads_norm = 4.9795
	sim_grads_norm = 0.0414
-- Starting training on experience 161 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6252
	data_grads_norm = 1.9032
	new_data_grads_norm = 2.6942
	old_data_grads_norm = 3.4987
	sim_grads_norm = -0.0408
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6225
	data_grads_norm = 2.9204
	new_data_grads_norm = 3.2428
	old_data_grads_norm = 4.4398
	sim_grads_norm = 0.1419
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2978
	data_grads_norm = 2.3799
	new_data_grads_norm = 2.5148
	old_data_grads_norm = 4.0278
	sim_grads_norm = -0.0107
-- Starting training on experience 162 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9118
	data_grads_norm = 2.1854
	new_data_grads_norm = 2.6710
	old_data_grads_norm = 3.3907
	sim_grads_norm = 0.1573
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0383
	data_grads_norm = 2.3452
	new_data_grads_norm = 3.1093
	old_data_grads_norm = 3.2887
	sim_grads_norm = 0.0370
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2395
	data_grads_norm = 2.1473
	new_data_grads_norm = 3.0932
	old_data_grads_norm = 2.9784
	sim_grads_norm = 0.0067
-- Starting training on experience 163 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9149
	data_grads_norm = 2.2705
	new_data_grads_norm = 3.8069
	old_data_grads_norm = 2.1176
	sim_grads_norm = 0.0100
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6586
	data_grads_norm = 3.2125
	new_data_grads_norm = 4.0967
	old_data_grads_norm = 4.1791
	sim_grads_norm = -0.0085
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3235
	data_grads_norm = 2.6599
	new_data_grads_norm = 4.2691
	old_data_grads_norm = 3.6567
	sim_grads_norm = -0.0869
-- Starting training on experience 164 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0022
	data_grads_norm = 2.1808
	new_data_grads_norm = 3.0856
	old_data_grads_norm = 2.4667
	sim_grads_norm = 0.1026
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1132
	data_grads_norm = 2.1043
	new_data_grads_norm = 2.7811
	old_data_grads_norm = 3.6164
	sim_grads_norm = -0.0755
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0215
	data_grads_norm = 2.2598
	new_data_grads_norm = 3.1543
	old_data_grads_norm = 2.7842
	sim_grads_norm = -0.0323
-- Starting training on experience 165 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1117
	data_grads_norm = 2.1068
	new_data_grads_norm = 3.7889
	old_data_grads_norm = 2.5193
	sim_grads_norm = 0.0756
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1791
	data_grads_norm = 2.6246
	new_data_grads_norm = 3.7289
	old_data_grads_norm = 3.3544
	sim_grads_norm = 0.1601
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0059
	data_grads_norm = 2.1051
	new_data_grads_norm = 3.9177
	old_data_grads_norm = 2.7154
	sim_grads_norm = 0.0669
-- Starting training on experience 166 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4840
	data_grads_norm = 1.8527
	new_data_grads_norm = 2.6241
	old_data_grads_norm = 2.6470
	sim_grads_norm = 0.0289
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3406
	data_grads_norm = 1.6790
	new_data_grads_norm = 2.8633
	old_data_grads_norm = 2.6258
	sim_grads_norm = -0.1261
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9311
	data_grads_norm = 2.4257
	new_data_grads_norm = 2.9188
	old_data_grads_norm = 3.6057
	sim_grads_norm = -0.0402
-- Starting training on experience 167 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0253
	data_grads_norm = 2.6174
	new_data_grads_norm = 2.7995
	old_data_grads_norm = 4.5689
	sim_grads_norm = -0.0359
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8312
	data_grads_norm = 2.2606
	new_data_grads_norm = 3.1945
	old_data_grads_norm = 2.5523
	sim_grads_norm = 0.2638
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5490
	data_grads_norm = 1.9770
	new_data_grads_norm = 2.8567
	old_data_grads_norm = 2.9893
	sim_grads_norm = -0.0271
-- Starting training on experience 168 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8582
	data_grads_norm = 2.6759
	new_data_grads_norm = 3.7338
	old_data_grads_norm = 3.9442
	sim_grads_norm = 0.0062
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0594
	data_grads_norm = 2.3199
	new_data_grads_norm = 3.1370
	old_data_grads_norm = 3.7191
	sim_grads_norm = -0.0679
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7265
	data_grads_norm = 2.3340
	new_data_grads_norm = 3.3486
	old_data_grads_norm = 3.2743
	sim_grads_norm = -0.0483
-- Starting training on experience 169 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1370
	data_grads_norm = 3.2783
	new_data_grads_norm = 4.9393
	old_data_grads_norm = 2.8331
	sim_grads_norm = 0.1432
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0612
	data_grads_norm = 3.1519
	new_data_grads_norm = 4.4569
	old_data_grads_norm = 3.9053
	sim_grads_norm = -0.0859
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3923
	data_grads_norm = 4.2057
	new_data_grads_norm = 4.8923
	old_data_grads_norm = 4.4974
	sim_grads_norm = 0.0876
-- Starting training on experience 170 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3114
	data_grads_norm = 2.7895
	new_data_grads_norm = 3.1592
	old_data_grads_norm = 3.6345
	sim_grads_norm = 0.2933
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7771
	data_grads_norm = 2.3160
	new_data_grads_norm = 3.1765
	old_data_grads_norm = 3.4800
	sim_grads_norm = 0.0074
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0900
	data_grads_norm = 3.0431
	new_data_grads_norm = 3.4257
	old_data_grads_norm = 3.8495
	sim_grads_norm = 0.0445
-- Starting training on experience 171 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8814
	data_grads_norm = 2.5245
	new_data_grads_norm = 3.9616
	old_data_grads_norm = 3.6476
	sim_grads_norm = 0.1018
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7588
	data_grads_norm = 2.1556
	new_data_grads_norm = 3.8133
	old_data_grads_norm = 2.5126
	sim_grads_norm = -0.0603
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1534
	data_grads_norm = 2.8807
	new_data_grads_norm = 4.0926
	old_data_grads_norm = 3.6759
	sim_grads_norm = 0.0858
-- Starting training on experience 172 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2506
	data_grads_norm = 2.7878
	new_data_grads_norm = 4.3422
	old_data_grads_norm = 3.5474
	sim_grads_norm = -0.0576
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3180
	data_grads_norm = 3.1006
	new_data_grads_norm = 4.7595
	old_data_grads_norm = 3.8986
	sim_grads_norm = 0.0762
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2028
	data_grads_norm = 2.5145
	new_data_grads_norm = 4.1793
	old_data_grads_norm = 3.3672
	sim_grads_norm = -0.1303
-- Starting training on experience 173 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9491
	data_grads_norm = 2.8388
	new_data_grads_norm = 3.7773
	old_data_grads_norm = 3.6816
	sim_grads_norm = 0.0878
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1083
	data_grads_norm = 2.6219
	new_data_grads_norm = 3.7350
	old_data_grads_norm = 3.1781
	sim_grads_norm = 0.0965
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3765
	data_grads_norm = 3.0758
	new_data_grads_norm = 3.5490
	old_data_grads_norm = 4.0309
	sim_grads_norm = 0.2235
-- Starting training on experience 174 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2300
	data_grads_norm = 2.7294
	new_data_grads_norm = 3.4072
	old_data_grads_norm = 3.2413
	sim_grads_norm = 0.0812
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7790
	data_grads_norm = 2.5554
	new_data_grads_norm = 3.3003
	old_data_grads_norm = 3.4202
	sim_grads_norm = 0.1564
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9039
	data_grads_norm = 2.0225
	new_data_grads_norm = 3.2663
	old_data_grads_norm = 2.0599
	sim_grads_norm = 0.2112
-- Starting training on experience 175 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9518
	data_grads_norm = 2.8116
	new_data_grads_norm = 3.8301
	old_data_grads_norm = 4.0208
	sim_grads_norm = 0.0102
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1118
	data_grads_norm = 2.4183
	new_data_grads_norm = 3.7395
	old_data_grads_norm = 2.9602
	sim_grads_norm = -0.0715
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8683
	data_grads_norm = 2.9504
	new_data_grads_norm = 3.8680
	old_data_grads_norm = 4.0963
	sim_grads_norm = 0.0860
-- Starting training on experience 176 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0534
	data_grads_norm = 2.9443
	new_data_grads_norm = 4.9247
	old_data_grads_norm = 3.1516
	sim_grads_norm = 0.1807
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0957
	data_grads_norm = 2.9962
	new_data_grads_norm = 4.0561
	old_data_grads_norm = 4.5441
	sim_grads_norm = 0.1148
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9226
	data_grads_norm = 2.6741
	new_data_grads_norm = 4.1509
	old_data_grads_norm = 3.5577
	sim_grads_norm = 0.0492
-- Starting training on experience 177 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5403
	data_grads_norm = 3.2202
	new_data_grads_norm = 3.5296
	old_data_grads_norm = 4.7253
	sim_grads_norm = -0.0075
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3098
	data_grads_norm = 2.7992
	new_data_grads_norm = 4.2577
	old_data_grads_norm = 3.6301
	sim_grads_norm = 0.0698
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8910
	data_grads_norm = 2.3782
	new_data_grads_norm = 3.6991
	old_data_grads_norm = 4.7671
	sim_grads_norm = -0.1156
-- Starting training on experience 178 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3050
	data_grads_norm = 2.6934
	new_data_grads_norm = 3.7357
	old_data_grads_norm = 3.5809
	sim_grads_norm = 0.0763
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8401
	data_grads_norm = 2.5495
	new_data_grads_norm = 3.5462
	old_data_grads_norm = 3.3978
	sim_grads_norm = -0.0039
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9884
	data_grads_norm = 2.7035
	new_data_grads_norm = 3.8448
	old_data_grads_norm = 3.7682
	sim_grads_norm = 0.1107
-- Starting training on experience 179 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6848
	data_grads_norm = 2.2829
	new_data_grads_norm = 3.4405
	old_data_grads_norm = 2.6851
	sim_grads_norm = 0.0324
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8964
	data_grads_norm = 2.4465
	new_data_grads_norm = 3.3444
	old_data_grads_norm = 4.7082
	sim_grads_norm = -0.0280
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0612
	data_grads_norm = 2.6130
	new_data_grads_norm = 3.5853
	old_data_grads_norm = 3.4524
	sim_grads_norm = 0.0663
-- Starting training on experience 180 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2707
	data_grads_norm = 2.8524
	new_data_grads_norm = 4.5629
	old_data_grads_norm = 3.5967
	sim_grads_norm = 0.0109
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4790
	data_grads_norm = 3.6294
	new_data_grads_norm = 4.6342
	old_data_grads_norm = 5.3564
	sim_grads_norm = 0.1358
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2229
	data_grads_norm = 2.8061
	new_data_grads_norm = 4.2836
	old_data_grads_norm = 3.5315
	sim_grads_norm = -0.0077
-- Starting training on experience 181 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9660
	data_grads_norm = 2.8091
	new_data_grads_norm = 4.0562
	old_data_grads_norm = 4.5212
	sim_grads_norm = 0.0572
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2780
	data_grads_norm = 3.4573
	new_data_grads_norm = 5.1089
	old_data_grads_norm = 4.7146
	sim_grads_norm = 0.1057
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8085
	data_grads_norm = 3.6356
	new_data_grads_norm = 3.4941
	old_data_grads_norm = 7.1754
	sim_grads_norm = -0.0026
-- Starting training on experience 182 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3408
	data_grads_norm = 2.7041
	new_data_grads_norm = 4.1968
	old_data_grads_norm = 3.2870
	sim_grads_norm = 0.0076
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2361
	data_grads_norm = 2.6300
	new_data_grads_norm = 4.5448
	old_data_grads_norm = 2.9378
	sim_grads_norm = 0.1224
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9292
	data_grads_norm = 2.2753
	new_data_grads_norm = 3.4623
	old_data_grads_norm = 3.6795
	sim_grads_norm = -0.1116
-- Starting training on experience 183 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0408
	data_grads_norm = 1.9542
	new_data_grads_norm = 3.9952
	old_data_grads_norm = 2.1308
	sim_grads_norm = 0.0239
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2557
	data_grads_norm = 2.6097
	new_data_grads_norm = 4.0549
	old_data_grads_norm = 3.7063
	sim_grads_norm = 0.1410
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0919
	data_grads_norm = 2.5644
	new_data_grads_norm = 3.6733
	old_data_grads_norm = 4.1541
	sim_grads_norm = 0.1373
-- Starting training on experience 184 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5070
	data_grads_norm = 3.1633
	new_data_grads_norm = 2.9743
	old_data_grads_norm = 4.8882
	sim_grads_norm = 0.0872
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0431
	data_grads_norm = 1.8699
	new_data_grads_norm = 2.5917
	old_data_grads_norm = 2.6440
	sim_grads_norm = -0.0520
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7506
	data_grads_norm = 2.1481
	new_data_grads_norm = 2.8542
	old_data_grads_norm = 2.7993
	sim_grads_norm = 0.0164
-- Starting training on experience 185 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7131
	data_grads_norm = 2.3135
	new_data_grads_norm = 2.6193
	old_data_grads_norm = 4.4109
	sim_grads_norm = -0.0029
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6509
	data_grads_norm = 2.0716
	new_data_grads_norm = 2.8135
	old_data_grads_norm = 2.9802
	sim_grads_norm = -0.1117
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9510
	data_grads_norm = 2.3564
	new_data_grads_norm = 3.0402
	old_data_grads_norm = 3.0309
	sim_grads_norm = 0.2033
-- Starting training on experience 186 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8958
	data_grads_norm = 2.0917
	new_data_grads_norm = 2.6580
	old_data_grads_norm = 3.0321
	sim_grads_norm = -0.0314
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9128
	data_grads_norm = 1.6769
	new_data_grads_norm = 2.5950
	old_data_grads_norm = 2.2668
	sim_grads_norm = -0.0126
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7591
	data_grads_norm = 2.0702
	new_data_grads_norm = 2.7921
	old_data_grads_norm = 2.1275
	sim_grads_norm = 0.4720
-- Starting training on experience 187 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7030
	data_grads_norm = 2.0112
	new_data_grads_norm = 3.4699
	old_data_grads_norm = 2.7476
	sim_grads_norm = -0.0855
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6728
	data_grads_norm = 2.4731
	new_data_grads_norm = 4.3342
	old_data_grads_norm = 3.5291
	sim_grads_norm = -0.2129
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6521
	data_grads_norm = 2.2092
	new_data_grads_norm = 3.8415
	old_data_grads_norm = 3.3324
	sim_grads_norm = 0.0646
-- Starting training on experience 188 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7640
	data_grads_norm = 2.6183
	new_data_grads_norm = 3.1210
	old_data_grads_norm = 3.1115
	sim_grads_norm = 0.2536
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3396
	data_grads_norm = 1.6977
	new_data_grads_norm = 2.6322
	old_data_grads_norm = 2.9778
	sim_grads_norm = -0.1309
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4730
	data_grads_norm = 2.0072
	new_data_grads_norm = 2.7960
	old_data_grads_norm = 2.4051
	sim_grads_norm = 0.0694
-- Starting training on experience 189 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6605
	data_grads_norm = 3.8334
	new_data_grads_norm = 4.4709
	old_data_grads_norm = 4.9143
	sim_grads_norm = 0.3332
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4399
	data_grads_norm = 1.9719
	new_data_grads_norm = 3.5955
	old_data_grads_norm = 3.2334
	sim_grads_norm = -0.0923
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6445
	data_grads_norm = 2.6015
	new_data_grads_norm = 3.5783
	old_data_grads_norm = 3.7809
	sim_grads_norm = 0.1455
-- Starting training on experience 190 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9987
	data_grads_norm = 2.5536
	new_data_grads_norm = 2.6656
	old_data_grads_norm = 4.1631
	sim_grads_norm = 0.1201
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9269
	data_grads_norm = 2.7253
	new_data_grads_norm = 2.7966
	old_data_grads_norm = 4.4786
	sim_grads_norm = -0.0078
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7607
	data_grads_norm = 2.1045
	new_data_grads_norm = 2.6645
	old_data_grads_norm = 3.4317
	sim_grads_norm = -0.0990
-- Starting training on experience 191 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7737
	data_grads_norm = 2.4497
	new_data_grads_norm = 2.9423
	old_data_grads_norm = 3.4226
	sim_grads_norm = 0.1092
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6464
	data_grads_norm = 2.2893
	new_data_grads_norm = 3.0510
	old_data_grads_norm = 3.2402
	sim_grads_norm = -0.0613
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8124
	data_grads_norm = 2.3992
	new_data_grads_norm = 3.0240
	old_data_grads_norm = 4.1270
	sim_grads_norm = -0.0923
-- Starting training on experience 192 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7046
	data_grads_norm = 1.9463
	new_data_grads_norm = 3.3145
	old_data_grads_norm = 2.4542
	sim_grads_norm = -0.0368
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9067
	data_grads_norm = 2.5818
	new_data_grads_norm = 3.9035
	old_data_grads_norm = 2.9021
	sim_grads_norm = 0.0550
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7472
	data_grads_norm = 2.7181
	new_data_grads_norm = 4.1814
	old_data_grads_norm = 5.0397
	sim_grads_norm = -0.0642
-- Starting training on experience 193 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8155
	data_grads_norm = 4.0963
	new_data_grads_norm = 5.8124
	old_data_grads_norm = 4.3530
	sim_grads_norm = 0.2241
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8574
	data_grads_norm = 2.6280
	new_data_grads_norm = 5.6164
	old_data_grads_norm = 4.0142
	sim_grads_norm = -0.0322
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7208
	data_grads_norm = 2.6162
	new_data_grads_norm = 5.3547
	old_data_grads_norm = 2.6295
	sim_grads_norm = -0.0808
-- Starting training on experience 194 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2407
	data_grads_norm = 2.3313
	new_data_grads_norm = 4.5534
	old_data_grads_norm = 2.3612
	sim_grads_norm = 0.0964
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2948
	data_grads_norm = 2.8966
	new_data_grads_norm = 4.7112
	old_data_grads_norm = 3.0931
	sim_grads_norm = 0.1559
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8532
	data_grads_norm = 2.2350
	new_data_grads_norm = 4.4699
	old_data_grads_norm = 2.3077
	sim_grads_norm = 0.0011
-- Starting training on experience 195 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1070
	data_grads_norm = 3.2115
	new_data_grads_norm = 3.1289
	old_data_grads_norm = 5.3814
	sim_grads_norm = 0.0845
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5799
	data_grads_norm = 1.8590
	new_data_grads_norm = 3.1090
	old_data_grads_norm = 2.5854
	sim_grads_norm = -0.1491
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1177
	data_grads_norm = 2.5550
	new_data_grads_norm = 3.2729
	old_data_grads_norm = 3.5133
	sim_grads_norm = 0.1084
-- Starting training on experience 196 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0862
	data_grads_norm = 2.3699
	new_data_grads_norm = 3.3206
	old_data_grads_norm = 2.7998
	sim_grads_norm = 0.1188
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5994
	data_grads_norm = 1.8287
	new_data_grads_norm = 3.2760
	old_data_grads_norm = 2.2023
	sim_grads_norm = -0.0330
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9548
	data_grads_norm = 2.2238
	new_data_grads_norm = 3.6611
	old_data_grads_norm = 3.6017
	sim_grads_norm = -0.0623
-- Starting training on experience 197 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1362
	data_grads_norm = 2.4248
	new_data_grads_norm = 3.4405
	old_data_grads_norm = 3.3450
	sim_grads_norm = 0.0510
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5144
	data_grads_norm = 2.1958
	new_data_grads_norm = 3.4228
	old_data_grads_norm = 2.2626
	sim_grads_norm = 0.1233
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9680
	data_grads_norm = 2.4501
	new_data_grads_norm = 3.2770
	old_data_grads_norm = 3.1986
	sim_grads_norm = 0.1036
-- Starting training on experience 198 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8376
	data_grads_norm = 2.4714
	new_data_grads_norm = 3.0847
	old_data_grads_norm = 3.2726
	sim_grads_norm = 0.1253
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0877
	data_grads_norm = 3.1674
	new_data_grads_norm = 4.2069
	old_data_grads_norm = 3.6603
	sim_grads_norm = -0.0904
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3904
	data_grads_norm = 2.8550
	new_data_grads_norm = 3.8028
	old_data_grads_norm = 5.1007
	sim_grads_norm = 0.0296
-- Starting training on experience 199 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6107
	data_grads_norm = 3.7731
	new_data_grads_norm = 5.5237
	old_data_grads_norm = 4.3052
	sim_grads_norm = 0.0262
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9584
	data_grads_norm = 2.5029
	new_data_grads_norm = 4.2847
	old_data_grads_norm = 3.1780
	sim_grads_norm = -0.1333
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9366
	data_grads_norm = 3.0017
	new_data_grads_norm = 4.5522
	old_data_grads_norm = 3.9165
	sim_grads_norm = -0.0618
-- Starting training on experience 200 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1584
	data_grads_norm = 3.2516
	new_data_grads_norm = 3.5932
	old_data_grads_norm = 5.0381
	sim_grads_norm = -0.0870
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2287
	data_grads_norm = 3.1430
	new_data_grads_norm = 3.8767
	old_data_grads_norm = 4.6115
	sim_grads_norm = 0.1976
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7470
	data_grads_norm = 2.0919
	new_data_grads_norm = 3.3091
	old_data_grads_norm = 3.1446
	sim_grads_norm = -0.0885
-- Starting training on experience 201 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1514
	data_grads_norm = 3.7142
	new_data_grads_norm = 4.3555
	old_data_grads_norm = 5.3751
	sim_grads_norm = 0.1509
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4928
	data_grads_norm = 2.4383
	new_data_grads_norm = 4.1213
	old_data_grads_norm = 4.4100
	sim_grads_norm = -0.1574
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1242
	data_grads_norm = 2.7988
	new_data_grads_norm = 3.9640
	old_data_grads_norm = 4.1324
	sim_grads_norm = 0.1120
-- Starting training on experience 202 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3856
	data_grads_norm = 2.7461
	new_data_grads_norm = 3.8250
	old_data_grads_norm = 4.0782
	sim_grads_norm = 0.1312
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3296
	data_grads_norm = 2.9157
	new_data_grads_norm = 3.5488
	old_data_grads_norm = 4.0091
	sim_grads_norm = 0.1143
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8908
	data_grads_norm = 1.9789
	new_data_grads_norm = 3.3912
	old_data_grads_norm = 2.3667
	sim_grads_norm = 0.0309
-- Starting training on experience 203 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3485
	data_grads_norm = 2.5624
	new_data_grads_norm = 3.7682
	old_data_grads_norm = 3.3300
	sim_grads_norm = 0.2122
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6476
	data_grads_norm = 2.1428
	new_data_grads_norm = 3.2798
	old_data_grads_norm = 3.1060
	sim_grads_norm = -0.0622
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6295
	data_grads_norm = 2.1415
	new_data_grads_norm = 3.7417
	old_data_grads_norm = 2.7256
	sim_grads_norm = -0.1309
-- Starting training on experience 204 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2111
	data_grads_norm = 2.9969
	new_data_grads_norm = 4.5024
	old_data_grads_norm = 3.3858
	sim_grads_norm = 0.0090
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4971
	data_grads_norm = 3.7417
	new_data_grads_norm = 5.1665
	old_data_grads_norm = 4.5770
	sim_grads_norm = 0.0694
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2830
	data_grads_norm = 2.7652
	new_data_grads_norm = 4.9939
	old_data_grads_norm = 2.4371
	sim_grads_norm = 0.1843
-- Starting training on experience 205 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7351
	data_grads_norm = 1.9277
	new_data_grads_norm = 2.7700
	old_data_grads_norm = 2.5073
	sim_grads_norm = -0.0118
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7582
	data_grads_norm = 1.7852
	new_data_grads_norm = 2.7555
	old_data_grads_norm = 2.2844
	sim_grads_norm = 0.1209
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5854
	data_grads_norm = 1.6638
	new_data_grads_norm = 2.7663
	old_data_grads_norm = 2.2202
	sim_grads_norm = 0.0159
-- Starting training on experience 206 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5882
	data_grads_norm = 1.9351
	new_data_grads_norm = 2.6223
	old_data_grads_norm = 2.9199
	sim_grads_norm = -0.0233
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9004
	data_grads_norm = 2.7637
	new_data_grads_norm = 3.3179
	old_data_grads_norm = 3.7656
	sim_grads_norm = 0.1960
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8681
	data_grads_norm = 2.4366
	new_data_grads_norm = 2.8215
	old_data_grads_norm = 3.2423
	sim_grads_norm = 0.2449
-- Starting training on experience 207 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5827
	data_grads_norm = 1.8817
	new_data_grads_norm = 2.5892
	old_data_grads_norm = 2.6805
	sim_grads_norm = -0.0186
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0733
	data_grads_norm = 2.1284
	new_data_grads_norm = 2.5479
	old_data_grads_norm = 3.4831
	sim_grads_norm = -0.1418
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9769
	data_grads_norm = 2.3839
	new_data_grads_norm = 2.7551
	old_data_grads_norm = 4.0159
	sim_grads_norm = -0.0035
-- Starting training on experience 208 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1000
	data_grads_norm = 2.2288
	new_data_grads_norm = 3.3051
	old_data_grads_norm = 2.7423
	sim_grads_norm = -0.0379
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1669
	data_grads_norm = 2.6026
	new_data_grads_norm = 3.9404
	old_data_grads_norm = 3.4820
	sim_grads_norm = 0.0712
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9579
	data_grads_norm = 2.1151
	new_data_grads_norm = 3.4169
	old_data_grads_norm = 3.2691
	sim_grads_norm = 0.0169
-- Starting training on experience 209 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0451
	data_grads_norm = 2.0438
	new_data_grads_norm = 3.0940
	old_data_grads_norm = 2.7729
	sim_grads_norm = -0.1068
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5690
	data_grads_norm = 2.8843
	new_data_grads_norm = 3.4135
	old_data_grads_norm = 4.2547
	sim_grads_norm = 0.0704
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9616
	data_grads_norm = 2.8613
	new_data_grads_norm = 2.9499
	old_data_grads_norm = 3.6835
	sim_grads_norm = 0.0530
-- Starting training on experience 210 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9841
	data_grads_norm = 2.9718
	new_data_grads_norm = 3.3118
	old_data_grads_norm = 4.6862
	sim_grads_norm = -0.0407
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6652
	data_grads_norm = 2.5429
	new_data_grads_norm = 3.5312
	old_data_grads_norm = 2.8342
	sim_grads_norm = 0.0304
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8560
	data_grads_norm = 2.5630
	new_data_grads_norm = 3.8078
	old_data_grads_norm = 3.3696
	sim_grads_norm = -0.0383
-- Starting training on experience 211 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1372
	data_grads_norm = 2.8545
	new_data_grads_norm = 3.7969
	old_data_grads_norm = 3.0304
	sim_grads_norm = 0.2863
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9586
	data_grads_norm = 2.3280
	new_data_grads_norm = 3.7544
	old_data_grads_norm = 3.1634
	sim_grads_norm = 0.0472
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2162
	data_grads_norm = 2.4103
	new_data_grads_norm = 3.4819
	old_data_grads_norm = 3.2818
	sim_grads_norm = -0.0255
-- Starting training on experience 212 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4231
	data_grads_norm = 2.7370
	new_data_grads_norm = 3.1624
	old_data_grads_norm = 3.3955
	sim_grads_norm = -0.1277
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1572
	data_grads_norm = 2.4455
	new_data_grads_norm = 3.2119
	old_data_grads_norm = 2.8242
	sim_grads_norm = 0.1464
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1561
	data_grads_norm = 2.2206
	new_data_grads_norm = 3.1591
	old_data_grads_norm = 3.7924
	sim_grads_norm = -0.1017
-- Starting training on experience 213 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9986
	data_grads_norm = 2.3291
	new_data_grads_norm = 3.6875
	old_data_grads_norm = 3.0990
	sim_grads_norm = 0.0246
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5886
	data_grads_norm = 2.7713
	new_data_grads_norm = 3.3531
	old_data_grads_norm = 3.2537
	sim_grads_norm = 0.1062
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9459
	data_grads_norm = 2.4451
	new_data_grads_norm = 3.5085
	old_data_grads_norm = 2.7302
	sim_grads_norm = 0.2559
-- Starting training on experience 214 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8389
	data_grads_norm = 2.1792
	new_data_grads_norm = 2.9337
	old_data_grads_norm = 2.6964
	sim_grads_norm = 0.1625
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9923
	data_grads_norm = 2.2540
	new_data_grads_norm = 2.7854
	old_data_grads_norm = 2.6858
	sim_grads_norm = 0.1659
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7674
	data_grads_norm = 2.4839
	new_data_grads_norm = 3.0408
	old_data_grads_norm = 3.0341
	sim_grads_norm = 0.0746
-- Starting training on experience 215 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6179
	data_grads_norm = 2.1783
	new_data_grads_norm = 3.1683
	old_data_grads_norm = 2.9369
	sim_grads_norm = -0.0575
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9472
	data_grads_norm = 2.6875
	new_data_grads_norm = 3.1200
	old_data_grads_norm = 4.7092
	sim_grads_norm = -0.0336
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7125
	data_grads_norm = 2.2984
	new_data_grads_norm = 3.3953
	old_data_grads_norm = 3.3057
	sim_grads_norm = -0.1623
-- Starting training on experience 216 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9820
	data_grads_norm = 2.3396
	new_data_grads_norm = 3.3555
	old_data_grads_norm = 3.2375
	sim_grads_norm = -0.0548
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1003
	data_grads_norm = 2.6538
	new_data_grads_norm = 3.5355
	old_data_grads_norm = 4.0884
	sim_grads_norm = 0.2300
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7954
	data_grads_norm = 2.1038
	new_data_grads_norm = 3.4085
	old_data_grads_norm = 2.8535
	sim_grads_norm = -0.0914
-- Starting training on experience 217 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2386
	data_grads_norm = 3.3402
	new_data_grads_norm = 4.0394
	old_data_grads_norm = 4.4551
	sim_grads_norm = 0.0893
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0382
	data_grads_norm = 2.7335
	new_data_grads_norm = 4.1324
	old_data_grads_norm = 3.2051
	sim_grads_norm = 0.1416
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9805
	data_grads_norm = 2.1793
	new_data_grads_norm = 3.9363
	old_data_grads_norm = 2.5175
	sim_grads_norm = -0.1238
-- Starting training on experience 218 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8668
	data_grads_norm = 2.5031
	new_data_grads_norm = 3.5338
	old_data_grads_norm = 3.2676
	sim_grads_norm = 0.1825
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0087
	data_grads_norm = 2.1942
	new_data_grads_norm = 3.2113
	old_data_grads_norm = 2.4227
	sim_grads_norm = 0.0564
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0066
	data_grads_norm = 2.4992
	new_data_grads_norm = 3.2200
	old_data_grads_norm = 3.4075
	sim_grads_norm = 0.0568
-- Starting training on experience 219 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1190
	data_grads_norm = 2.2644
	new_data_grads_norm = 3.4292
	old_data_grads_norm = 2.8857
	sim_grads_norm = -0.0395
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9343
	data_grads_norm = 2.0382
	new_data_grads_norm = 3.1813
	old_data_grads_norm = 2.5958
	sim_grads_norm = 0.0315
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0700
	data_grads_norm = 2.6714
	new_data_grads_norm = 3.6967
	old_data_grads_norm = 3.3777
	sim_grads_norm = 0.2171
-- Starting training on experience 220 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4254
	data_grads_norm = 1.9882
	new_data_grads_norm = 3.0162
	old_data_grads_norm = 2.7379
	sim_grads_norm = -0.0825
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6787
	data_grads_norm = 2.7275
	new_data_grads_norm = 3.1129
	old_data_grads_norm = 4.4741
	sim_grads_norm = -0.0779
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0308
	data_grads_norm = 2.8483
	new_data_grads_norm = 4.1296
	old_data_grads_norm = 3.8679
	sim_grads_norm = -0.0535
-- Starting training on experience 221 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9222
	data_grads_norm = 2.5622
	new_data_grads_norm = 3.6236
	old_data_grads_norm = 3.2550
	sim_grads_norm = -0.0111
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5885
	data_grads_norm = 2.3706
	new_data_grads_norm = 3.9034
	old_data_grads_norm = 4.0163
	sim_grads_norm = -0.0144
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5883
	data_grads_norm = 2.4261
	new_data_grads_norm = 4.1057
	old_data_grads_norm = 3.5439
	sim_grads_norm = -0.0500
-- Starting training on experience 222 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8189
	data_grads_norm = 3.0416
	new_data_grads_norm = 4.2508
	old_data_grads_norm = 4.4688
	sim_grads_norm = 0.1581
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4165
	data_grads_norm = 3.0907
	new_data_grads_norm = 3.6672
	old_data_grads_norm = 4.1453
	sim_grads_norm = 0.0838
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9495
	data_grads_norm = 2.5293
	new_data_grads_norm = 3.4210
	old_data_grads_norm = 3.7933
	sim_grads_norm = 0.1850
-- Starting training on experience 223 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0012
	data_grads_norm = 2.8546
	new_data_grads_norm = 3.6144
	old_data_grads_norm = 4.1527
	sim_grads_norm = 0.0372
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6763
	data_grads_norm = 2.3249
	new_data_grads_norm = 3.6138
	old_data_grads_norm = 2.5861
	sim_grads_norm = -0.0874
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0020
	data_grads_norm = 2.7136
	new_data_grads_norm = 3.6650
	old_data_grads_norm = 3.9315
	sim_grads_norm = 0.0557
-- Starting training on experience 224 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2026
	data_grads_norm = 2.5355
	new_data_grads_norm = 4.3373
	old_data_grads_norm = 2.6662
	sim_grads_norm = 0.1097
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2536
	data_grads_norm = 3.1727
	new_data_grads_norm = 4.2768
	old_data_grads_norm = 4.4901
	sim_grads_norm = 0.1192
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9338
	data_grads_norm = 2.2832
	new_data_grads_norm = 3.7585
	old_data_grads_norm = 3.2161
	sim_grads_norm = -0.0788
-- Starting training on experience 225 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0075
	data_grads_norm = 2.2703
	new_data_grads_norm = 3.6423
	old_data_grads_norm = 2.8804
	sim_grads_norm = -0.0866
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8743
	data_grads_norm = 2.6331
	new_data_grads_norm = 4.0548
	old_data_grads_norm = 3.2554
	sim_grads_norm = 0.0740
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1136
	data_grads_norm = 3.2923
	new_data_grads_norm = 3.5869
	old_data_grads_norm = 4.5569
	sim_grads_norm = 0.0025
-- Starting training on experience 226 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0615
	data_grads_norm = 2.3993
	new_data_grads_norm = 3.2714
	old_data_grads_norm = 3.3058
	sim_grads_norm = 0.0986
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6554
	data_grads_norm = 2.4580
	new_data_grads_norm = 2.9761
	old_data_grads_norm = 3.4584
	sim_grads_norm = 0.0270
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8227
	data_grads_norm = 2.2808
	new_data_grads_norm = 3.1937
	old_data_grads_norm = 2.7387
	sim_grads_norm = 0.0848
-- Starting training on experience 227 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7982
	data_grads_norm = 2.1933
	new_data_grads_norm = 3.1619
	old_data_grads_norm = 3.2471
	sim_grads_norm = -0.0292
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6658
	data_grads_norm = 2.1178
	new_data_grads_norm = 3.5573
	old_data_grads_norm = 2.8297
	sim_grads_norm = -0.0978
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9156
	data_grads_norm = 2.6825
	new_data_grads_norm = 4.0201
	old_data_grads_norm = 3.8291
	sim_grads_norm = -0.0493
-- Starting training on experience 228 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6493
	data_grads_norm = 2.0022
	new_data_grads_norm = 2.9873
	old_data_grads_norm = 3.4113
	sim_grads_norm = -0.0146
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6475
	data_grads_norm = 2.5210
	new_data_grads_norm = 3.8057
	old_data_grads_norm = 3.0869
	sim_grads_norm = 0.1221
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4183
	data_grads_norm = 2.0569
	new_data_grads_norm = 3.0137
	old_data_grads_norm = 2.4881
	sim_grads_norm = -0.0295
-- Starting training on experience 229 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5641
	data_grads_norm = 1.7679
	new_data_grads_norm = 3.9622
	old_data_grads_norm = 2.3372
	sim_grads_norm = -0.0642
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2244
	data_grads_norm = 3.1708
	new_data_grads_norm = 3.6660
	old_data_grads_norm = 4.4518
	sim_grads_norm = 0.0520
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5745
	data_grads_norm = 2.1023
	new_data_grads_norm = 3.3016
	old_data_grads_norm = 2.4163
	sim_grads_norm = -0.0542
-- Starting training on experience 230 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5234
	data_grads_norm = 2.4357
	new_data_grads_norm = 3.5765
	old_data_grads_norm = 3.0624
	sim_grads_norm = 0.0555
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7013
	data_grads_norm = 2.3538
	new_data_grads_norm = 3.6949
	old_data_grads_norm = 3.1009
	sim_grads_norm = 0.1351
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4466
	data_grads_norm = 2.3241
	new_data_grads_norm = 3.6403
	old_data_grads_norm = 3.1210
	sim_grads_norm = 0.0708
-- Starting training on experience 231 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8088
	data_grads_norm = 3.3288
	new_data_grads_norm = 4.7740
	old_data_grads_norm = 3.2907
	sim_grads_norm = 0.0564
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6007
	data_grads_norm = 2.7148
	new_data_grads_norm = 4.7085
	old_data_grads_norm = 2.9237
	sim_grads_norm = -0.1252
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2521
	data_grads_norm = 3.8302
	new_data_grads_norm = 5.4653
	old_data_grads_norm = 3.9881
	sim_grads_norm = 0.1081
-- Starting training on experience 232 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9461
	data_grads_norm = 2.2746
	new_data_grads_norm = 3.9251
	old_data_grads_norm = 3.0718
	sim_grads_norm = -0.0838
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9243
	data_grads_norm = 3.2738
	new_data_grads_norm = 5.1370
	old_data_grads_norm = 3.5613
	sim_grads_norm = 0.0105
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2378
	data_grads_norm = 3.4774
	new_data_grads_norm = 4.4731
	old_data_grads_norm = 4.4444
	sim_grads_norm = 0.0139
-- Starting training on experience 233 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1934
	data_grads_norm = 4.2299
	new_data_grads_norm = 3.8910
	old_data_grads_norm = 7.5029
	sim_grads_norm = -0.0859
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0721
	data_grads_norm = 2.5566
	new_data_grads_norm = 4.0103
	old_data_grads_norm = 2.6503
	sim_grads_norm = -0.0825
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5226
	data_grads_norm = 2.7657
	new_data_grads_norm = 4.2300
	old_data_grads_norm = 3.1718
	sim_grads_norm = 0.1878
-- Starting training on experience 234 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7997
	data_grads_norm = 1.8560
	new_data_grads_norm = 2.9110
	old_data_grads_norm = 2.2249
	sim_grads_norm = -0.0950
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7383
	data_grads_norm = 2.8651
	new_data_grads_norm = 3.2887
	old_data_grads_norm = 4.7822
	sim_grads_norm = 0.1123
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0684
	data_grads_norm = 2.8015
	new_data_grads_norm = 3.1615
	old_data_grads_norm = 3.6900
	sim_grads_norm = 0.0635
-- Starting training on experience 235 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6450
	data_grads_norm = 2.2240
	new_data_grads_norm = 3.1094
	old_data_grads_norm = 3.4161
	sim_grads_norm = -0.1296
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8040
	data_grads_norm = 2.5452
	new_data_grads_norm = 3.6778
	old_data_grads_norm = 4.2465
	sim_grads_norm = 0.0730
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9204
	data_grads_norm = 2.1809
	new_data_grads_norm = 3.7927
	old_data_grads_norm = 2.6615
	sim_grads_norm = -0.1343
-- Starting training on experience 236 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5626
	data_grads_norm = 2.9721
	new_data_grads_norm = 3.6291
	old_data_grads_norm = 4.2415
	sim_grads_norm = 0.0766
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2378
	data_grads_norm = 2.6658
	new_data_grads_norm = 4.5971
	old_data_grads_norm = 3.7284
	sim_grads_norm = 0.0282
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2210
	data_grads_norm = 2.6970
	new_data_grads_norm = 4.0804
	old_data_grads_norm = 3.5533
	sim_grads_norm = 0.0740
-- Starting training on experience 237 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
-- >> End of training phase << --
-- >> Start of eval phase << --
-- Starting eval on experience 0 (Task 0) from test stream --
> Eval on experience 0 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp000 = 1.9547
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.3980
	mb_index = 714
	time = 99.8636
-- Starting eval on experience 1 (Task 0) from test stream --
> Eval on experience 1 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp001 = 1.1347
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.6640
-- Starting eval on experience 2 (Task 0) from test stream --
> Eval on experience 2 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp002 = 2.1979
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.1900
-- >> End of eval phase << --
	CumulativeAccuracy/eval_phase/test_stream/Exp000 = 0.6440
	CumulativeAccuracy/eval_phase/test_stream/Exp001 = 0.5740
	CumulativeAccuracy/eval_phase/test_stream/Exp002 = 0.4173
	Loss_Stream/eval_phase/test_stream/Task000 = 1.7624
	Top1_Acc_Stream/eval_phase/test_stream/Task000 = 0.4173
-- >> Start of training phase << --
-- Starting training on experience 0 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7935
	data_grads_norm = 2.3961
	new_data_grads_norm = 3.3712
	old_data_grads_norm = 3.8604
	sim_grads_norm = -0.0982
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8412
	data_grads_norm = 2.6705
	new_data_grads_norm = 3.5053
	old_data_grads_norm = 3.7454
	sim_grads_norm = -0.0177
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3471
	data_grads_norm = 3.0498
	new_data_grads_norm = 4.0430
	old_data_grads_norm = 4.4473
	sim_grads_norm = 0.0570
-- Starting training on experience 1 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1931
	data_grads_norm = 4.2384
	new_data_grads_norm = 4.3270
	old_data_grads_norm = 3.7836
	sim_grads_norm = 0.0836
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0861
	data_grads_norm = 3.7987
	new_data_grads_norm = 3.9453
	old_data_grads_norm = 3.8491
	sim_grads_norm = -0.0497
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2516
	data_grads_norm = 3.4780
	new_data_grads_norm = 4.7416
	old_data_grads_norm = 4.1882
	sim_grads_norm = -0.0032
-- Starting training on experience 2 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0006
	data_grads_norm = 3.4165
	new_data_grads_norm = 3.6734
	old_data_grads_norm = 2.7134
	sim_grads_norm = -0.1331
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7953
	data_grads_norm = 2.6128
	new_data_grads_norm = 4.0730
	old_data_grads_norm = 2.4614
	sim_grads_norm = -0.1300
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2850
	data_grads_norm = 3.5220
	new_data_grads_norm = 3.9773
	old_data_grads_norm = 3.5555
	sim_grads_norm = 0.0060
-- Starting training on experience 3 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5494
	data_grads_norm = 3.5369
	new_data_grads_norm = 5.4869
	old_data_grads_norm = 3.8018
	sim_grads_norm = -0.0349
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1130
	data_grads_norm = 3.5866
	new_data_grads_norm = 5.2069
	old_data_grads_norm = 4.0622
	sim_grads_norm = 0.0111
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4208
	data_grads_norm = 3.2971
	new_data_grads_norm = 5.6799
	old_data_grads_norm = 3.6678
	sim_grads_norm = 0.0188
-- Starting training on experience 4 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3602
	data_grads_norm = 3.6208
	new_data_grads_norm = 4.7745
	old_data_grads_norm = 3.9793
	sim_grads_norm = 0.3281
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9964
	data_grads_norm = 2.9690
	new_data_grads_norm = 4.1487
	old_data_grads_norm = 4.2239
	sim_grads_norm = -0.0653
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1627
	data_grads_norm = 2.6617
	new_data_grads_norm = 4.3937
	old_data_grads_norm = 3.3953
	sim_grads_norm = -0.1094
-- Starting training on experience 5 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7758
	data_grads_norm = 3.3824
	new_data_grads_norm = 4.4994
	old_data_grads_norm = 4.1706
	sim_grads_norm = 0.1030
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2006
	data_grads_norm = 2.6080
	new_data_grads_norm = 4.3072
	old_data_grads_norm = 3.3204
	sim_grads_norm = -0.0439
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3170
	data_grads_norm = 3.0608
	new_data_grads_norm = 4.9450
	old_data_grads_norm = 2.8816
	sim_grads_norm = 0.0403
-- Starting training on experience 6 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3597
	data_grads_norm = 3.2842
	new_data_grads_norm = 4.4547
	old_data_grads_norm = 3.6493
	sim_grads_norm = 0.0561
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2309
	data_grads_norm = 3.1785
	new_data_grads_norm = 4.6858
	old_data_grads_norm = 2.9089
	sim_grads_norm = -0.0267
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2078
	data_grads_norm = 2.9413
	new_data_grads_norm = 4.6775
	old_data_grads_norm = 3.2103
	sim_grads_norm = 0.0271
-- Starting training on experience 7 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2748
	data_grads_norm = 3.3076
	new_data_grads_norm = 5.0421
	old_data_grads_norm = 4.1242
	sim_grads_norm = -0.0236
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7789
	data_grads_norm = 2.7272
	new_data_grads_norm = 4.3712
	old_data_grads_norm = 3.2150
	sim_grads_norm = -0.0545
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3145
	data_grads_norm = 3.8392
	new_data_grads_norm = 5.4692
	old_data_grads_norm = 4.2041
	sim_grads_norm = 0.1889
-- Starting training on experience 8 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2791
	data_grads_norm = 3.4640
	new_data_grads_norm = 3.9763
	old_data_grads_norm = 4.7838
	sim_grads_norm = 0.1251
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7082
	data_grads_norm = 3.1719
	new_data_grads_norm = 3.3945
	old_data_grads_norm = 4.4022
	sim_grads_norm = 0.2039
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7455
	data_grads_norm = 2.3541
	new_data_grads_norm = 3.6261
	old_data_grads_norm = 3.4301
	sim_grads_norm = -0.0564
-- Starting training on experience 9 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3276
	data_grads_norm = 3.0732
	new_data_grads_norm = 4.0285
	old_data_grads_norm = 3.9797
	sim_grads_norm = 0.1644
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1810
	data_grads_norm = 2.4686
	new_data_grads_norm = 3.5307
	old_data_grads_norm = 2.8763
	sim_grads_norm = -0.0069
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3060
	data_grads_norm = 2.7498
	new_data_grads_norm = 3.7207
	old_data_grads_norm = 3.3441
	sim_grads_norm = 0.0172
-- Starting training on experience 10 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8462
	data_grads_norm = 2.3008
	new_data_grads_norm = 3.4337
	old_data_grads_norm = 3.4099
	sim_grads_norm = -0.1076
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0217
	data_grads_norm = 2.7054
	new_data_grads_norm = 4.2970
	old_data_grads_norm = 3.0829
	sim_grads_norm = -0.0028
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0334
	data_grads_norm = 2.5290
	new_data_grads_norm = 4.1690
	old_data_grads_norm = 3.2087
	sim_grads_norm = -0.0575
-- Starting training on experience 11 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6868
	data_grads_norm = 3.3470
	new_data_grads_norm = 4.6657
	old_data_grads_norm = 4.2276
	sim_grads_norm = -0.0562
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2943
	data_grads_norm = 2.8653
	new_data_grads_norm = 4.6094
	old_data_grads_norm = 3.5412
	sim_grads_norm = -0.0007
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3936
	data_grads_norm = 3.1122
	new_data_grads_norm = 5.2204
	old_data_grads_norm = 3.3849
	sim_grads_norm = 0.1294
-- Starting training on experience 12 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7616
	data_grads_norm = 2.6345
	new_data_grads_norm = 3.9496
	old_data_grads_norm = 3.1209
	sim_grads_norm = 0.0042
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4102
	data_grads_norm = 2.8678
	new_data_grads_norm = 4.0082
	old_data_grads_norm = 3.6423
	sim_grads_norm = 0.0060
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1751
	data_grads_norm = 3.1954
	new_data_grads_norm = 4.0628
	old_data_grads_norm = 4.8747
	sim_grads_norm = 0.1205
-- Starting training on experience 13 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7007
	data_grads_norm = 2.2834
	new_data_grads_norm = 4.3109
	old_data_grads_norm = 3.0695
	sim_grads_norm = -0.0112
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6548
	data_grads_norm = 2.2970
	new_data_grads_norm = 3.9925
	old_data_grads_norm = 2.9121
	sim_grads_norm = -0.1104
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6034
	data_grads_norm = 3.1614
	new_data_grads_norm = 4.2246
	old_data_grads_norm = 3.9291
	sim_grads_norm = 0.1341
-- Starting training on experience 14 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5380
	data_grads_norm = 2.6775
	new_data_grads_norm = 3.6944
	old_data_grads_norm = 3.6239
	sim_grads_norm = 0.0573
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0496
	data_grads_norm = 2.3063
	new_data_grads_norm = 3.7209
	old_data_grads_norm = 2.6258
	sim_grads_norm = -0.0947
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5158
	data_grads_norm = 2.9927
	new_data_grads_norm = 3.8876
	old_data_grads_norm = 4.4225
	sim_grads_norm = 0.1019
-- Starting training on experience 15 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5011
	data_grads_norm = 3.1755
	new_data_grads_norm = 4.6594
	old_data_grads_norm = 3.4550
	sim_grads_norm = 0.0090
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8332
	data_grads_norm = 2.1808
	new_data_grads_norm = 4.0622
	old_data_grads_norm = 2.0314
	sim_grads_norm = 0.0630
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2975
	data_grads_norm = 2.9506
	new_data_grads_norm = 4.0244
	old_data_grads_norm = 3.4703
	sim_grads_norm = -0.0106
-- Starting training on experience 16 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1975
	data_grads_norm = 2.7768
	new_data_grads_norm = 3.3158
	old_data_grads_norm = 3.8262
	sim_grads_norm = 0.0523
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6111
	data_grads_norm = 2.1082
	new_data_grads_norm = 3.1831
	old_data_grads_norm = 2.5739
	sim_grads_norm = -0.0936
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9217
	data_grads_norm = 2.5923
	new_data_grads_norm = 3.4526
	old_data_grads_norm = 3.8806
	sim_grads_norm = -0.0042
-- Starting training on experience 17 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3639
	data_grads_norm = 3.2441
	new_data_grads_norm = 4.8952
	old_data_grads_norm = 3.9030
	sim_grads_norm = 0.0257
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1772
	data_grads_norm = 3.1387
	new_data_grads_norm = 4.7267
	old_data_grads_norm = 3.2992
	sim_grads_norm = 0.0336
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4671
	data_grads_norm = 2.8909
	new_data_grads_norm = 4.7610
	old_data_grads_norm = 2.9689
	sim_grads_norm = 0.0511
-- Starting training on experience 18 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5915
	data_grads_norm = 2.8128
	new_data_grads_norm = 4.4325
	old_data_grads_norm = 4.1241
	sim_grads_norm = -0.1459
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5987
	data_grads_norm = 3.5075
	new_data_grads_norm = 4.9708
	old_data_grads_norm = 3.3817
	sim_grads_norm = 0.4388
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2131
	data_grads_norm = 2.8457
	new_data_grads_norm = 3.9883
	old_data_grads_norm = 3.3823
	sim_grads_norm = -0.0026
-- Starting training on experience 19 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9006
	data_grads_norm = 2.7498
	new_data_grads_norm = 3.7211
	old_data_grads_norm = 3.7443
	sim_grads_norm = 0.0184
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8513
	data_grads_norm = 2.7771
	new_data_grads_norm = 3.8057
	old_data_grads_norm = 3.1440
	sim_grads_norm = -0.0184
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6697
	data_grads_norm = 2.5665
	new_data_grads_norm = 3.5799
	old_data_grads_norm = 3.7144
	sim_grads_norm = -0.0784
-- Starting training on experience 20 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7475
	data_grads_norm = 3.3261
	new_data_grads_norm = 4.8151
	old_data_grads_norm = 3.7147
	sim_grads_norm = 0.1176
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3732
	data_grads_norm = 2.6109
	new_data_grads_norm = 4.2593
	old_data_grads_norm = 3.5075
	sim_grads_norm = 0.0688
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3313
	data_grads_norm = 2.5823
	new_data_grads_norm = 4.2675
	old_data_grads_norm = 2.7823
	sim_grads_norm = 0.0528
-- Starting training on experience 21 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0231
	data_grads_norm = 2.9747
	new_data_grads_norm = 4.2429
	old_data_grads_norm = 3.5180
	sim_grads_norm = 0.1726
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6779
	data_grads_norm = 2.4975
	new_data_grads_norm = 3.9763
	old_data_grads_norm = 2.8077
	sim_grads_norm = 0.0507
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7891
	data_grads_norm = 2.7291
	new_data_grads_norm = 4.0980
	old_data_grads_norm = 3.2241
	sim_grads_norm = 0.0736
-- Starting training on experience 22 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8418
	data_grads_norm = 2.4575
	new_data_grads_norm = 3.7837
	old_data_grads_norm = 2.7699
	sim_grads_norm = -0.0073
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8922
	data_grads_norm = 2.8407
	new_data_grads_norm = 4.0951
	old_data_grads_norm = 3.8601
	sim_grads_norm = 0.0234
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5353
	data_grads_norm = 3.3254
	new_data_grads_norm = 4.0049
	old_data_grads_norm = 5.4324
	sim_grads_norm = 0.0652
-- Starting training on experience 23 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3639
	data_grads_norm = 2.7635
	new_data_grads_norm = 3.6811
	old_data_grads_norm = 3.1511
	sim_grads_norm = 0.2179
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0710
	data_grads_norm = 2.8689
	new_data_grads_norm = 3.5882
	old_data_grads_norm = 3.8902
	sim_grads_norm = 0.1248
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5518
	data_grads_norm = 2.1645
	new_data_grads_norm = 3.4161
	old_data_grads_norm = 2.6498
	sim_grads_norm = -0.0530
-- Starting training on experience 24 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7686
	data_grads_norm = 2.7713
	new_data_grads_norm = 3.9362
	old_data_grads_norm = 3.1260
	sim_grads_norm = 0.1686
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1322
	data_grads_norm = 3.3253
	new_data_grads_norm = 4.3303
	old_data_grads_norm = 4.8584
	sim_grads_norm = 0.0134
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4407
	data_grads_norm = 2.4869
	new_data_grads_norm = 4.3468
	old_data_grads_norm = 3.4766
	sim_grads_norm = -0.1668
-- Starting training on experience 25 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8557
	data_grads_norm = 3.2289
	new_data_grads_norm = 4.0593
	old_data_grads_norm = 4.0464
	sim_grads_norm = 0.2030
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7956
	data_grads_norm = 3.1513
	new_data_grads_norm = 3.8303
	old_data_grads_norm = 5.1278
	sim_grads_norm = -0.0445
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3798
	data_grads_norm = 2.4882
	new_data_grads_norm = 3.0654
	old_data_grads_norm = 3.7549
	sim_grads_norm = 0.0494
-- Starting training on experience 26 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0077
	data_grads_norm = 2.6130
	new_data_grads_norm = 3.9706
	old_data_grads_norm = 3.0050
	sim_grads_norm = 0.0734
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9261
	data_grads_norm = 2.8269
	new_data_grads_norm = 3.8191
	old_data_grads_norm = 3.3943
	sim_grads_norm = 0.0620
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0032
	data_grads_norm = 2.5351
	new_data_grads_norm = 3.8640
	old_data_grads_norm = 3.0061
	sim_grads_norm = 0.0969
-- Starting training on experience 27 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5833
	data_grads_norm = 3.0663
	new_data_grads_norm = 4.2833
	old_data_grads_norm = 3.9189
	sim_grads_norm = 0.0529
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5913
	data_grads_norm = 2.9014
	new_data_grads_norm = 4.0691
	old_data_grads_norm = 3.2076
	sim_grads_norm = -0.0493
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8976
	data_grads_norm = 3.1254
	new_data_grads_norm = 4.4419
	old_data_grads_norm = 3.7187
	sim_grads_norm = -0.0118
-- Starting training on experience 28 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8713
	data_grads_norm = 3.0602
	new_data_grads_norm = 3.9238
	old_data_grads_norm = 3.5530
	sim_grads_norm = 0.0370
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3551
	data_grads_norm = 2.8329
	new_data_grads_norm = 3.4386
	old_data_grads_norm = 3.4612
	sim_grads_norm = -0.0490
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4423
	data_grads_norm = 2.3865
	new_data_grads_norm = 3.8607
	old_data_grads_norm = 2.6979
	sim_grads_norm = 0.0180
-- Starting training on experience 29 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8055
	data_grads_norm = 2.5908
	new_data_grads_norm = 3.7443
	old_data_grads_norm = 3.2959
	sim_grads_norm = 0.0440
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9001
	data_grads_norm = 2.6087
	new_data_grads_norm = 3.5712
	old_data_grads_norm = 3.0823
	sim_grads_norm = 0.0239
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9522
	data_grads_norm = 2.9555
	new_data_grads_norm = 3.5395
	old_data_grads_norm = 4.4526
	sim_grads_norm = 0.0253
-- Starting training on experience 30 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6809
	data_grads_norm = 2.5845
	new_data_grads_norm = 3.4465
	old_data_grads_norm = 3.3434
	sim_grads_norm = 0.1471
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7383
	data_grads_norm = 2.5781
	new_data_grads_norm = 3.4942
	old_data_grads_norm = 3.7507
	sim_grads_norm = 0.0680
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9100
	data_grads_norm = 2.6984
	new_data_grads_norm = 3.2755
	old_data_grads_norm = 3.6334
	sim_grads_norm = 0.0097
-- Starting training on experience 31 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2150
	data_grads_norm = 3.0876
	new_data_grads_norm = 3.6824
	old_data_grads_norm = 4.3976
	sim_grads_norm = 0.1288
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6646
	data_grads_norm = 2.5302
	new_data_grads_norm = 3.5003
	old_data_grads_norm = 2.8789
	sim_grads_norm = 0.1637
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3274
	data_grads_norm = 2.1481
	new_data_grads_norm = 3.2813
	old_data_grads_norm = 4.0837
	sim_grads_norm = -0.1226
-- Starting training on experience 32 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4828
	data_grads_norm = 2.3107
	new_data_grads_norm = 3.0768
	old_data_grads_norm = 3.1592
	sim_grads_norm = -0.0950
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2887
	data_grads_norm = 2.6318
	new_data_grads_norm = 3.8395
	old_data_grads_norm = 3.4522
	sim_grads_norm = 0.0419
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2047
	data_grads_norm = 2.4308
	new_data_grads_norm = 3.1838
	old_data_grads_norm = 3.5865
	sim_grads_norm = -0.0162
-- Starting training on experience 33 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8295
	data_grads_norm = 2.9126
	new_data_grads_norm = 4.0190
	old_data_grads_norm = 3.5865
	sim_grads_norm = 0.0637
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6867
	data_grads_norm = 2.6733
	new_data_grads_norm = 3.5679
	old_data_grads_norm = 3.5721
	sim_grads_norm = -0.0117
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8476
	data_grads_norm = 2.7839
	new_data_grads_norm = 3.7379
	old_data_grads_norm = 3.2985
	sim_grads_norm = 0.0206
-- Starting training on experience 34 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6997
	data_grads_norm = 2.6651
	new_data_grads_norm = 3.2089
	old_data_grads_norm = 3.6703
	sim_grads_norm = 0.0956
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5862
	data_grads_norm = 2.7124
	new_data_grads_norm = 3.6686
	old_data_grads_norm = 3.4970
	sim_grads_norm = 0.0253
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0842
	data_grads_norm = 3.3246
	new_data_grads_norm = 3.8394
	old_data_grads_norm = 4.2230
	sim_grads_norm = 0.0918
-- Starting training on experience 35 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7469
	data_grads_norm = 2.8249
	new_data_grads_norm = 3.4195
	old_data_grads_norm = 3.5680
	sim_grads_norm = 0.1549
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4196
	data_grads_norm = 2.5792
	new_data_grads_norm = 3.6767
	old_data_grads_norm = 2.7213
	sim_grads_norm = -0.0264
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9472
	data_grads_norm = 3.1116
	new_data_grads_norm = 4.4290
	old_data_grads_norm = 3.1972
	sim_grads_norm = 0.1597
-- Starting training on experience 36 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6233
	data_grads_norm = 1.9834
	new_data_grads_norm = 2.9041
	old_data_grads_norm = 2.4536
	sim_grads_norm = 0.0839
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3401
	data_grads_norm = 2.1838
	new_data_grads_norm = 3.1884
	old_data_grads_norm = 2.3332
	sim_grads_norm = 0.0721
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6776
	data_grads_norm = 2.6518
	new_data_grads_norm = 2.8926
	old_data_grads_norm = 3.8029
	sim_grads_norm = 0.1189
-- Starting training on experience 37 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4049
	data_grads_norm = 2.3740
	new_data_grads_norm = 3.2589
	old_data_grads_norm = 2.8942
	sim_grads_norm = 0.0455
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5325
	data_grads_norm = 2.5391
	new_data_grads_norm = 3.4290
	old_data_grads_norm = 3.2354
	sim_grads_norm = 0.1407
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6179
	data_grads_norm = 2.8024
	new_data_grads_norm = 3.3975
	old_data_grads_norm = 4.0667
	sim_grads_norm = 0.1041
-- Starting training on experience 38 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6493
	data_grads_norm = 2.2996
	new_data_grads_norm = 2.7439
	old_data_grads_norm = 3.4587
	sim_grads_norm = 0.0484
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5047
	data_grads_norm = 2.5649
	new_data_grads_norm = 2.7707
	old_data_grads_norm = 4.8475
	sim_grads_norm = 0.1799
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6572
	data_grads_norm = 2.3120
	new_data_grads_norm = 2.5546
	old_data_grads_norm = 4.4963
	sim_grads_norm = 0.1637
-- Starting training on experience 39 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8638
	data_grads_norm = 2.7608
	new_data_grads_norm = 3.9450
	old_data_grads_norm = 3.5221
	sim_grads_norm = 0.0725
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3053
	data_grads_norm = 2.4104
	new_data_grads_norm = 3.5483
	old_data_grads_norm = 3.2376
	sim_grads_norm = -0.0440
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2149
	data_grads_norm = 2.2551
	new_data_grads_norm = 3.6451
	old_data_grads_norm = 2.4882
	sim_grads_norm = -0.1134
-- Starting training on experience 40 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7173
	data_grads_norm = 2.7276
	new_data_grads_norm = 4.5760
	old_data_grads_norm = 2.4935
	sim_grads_norm = 0.0428
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4912
	data_grads_norm = 2.6685
	new_data_grads_norm = 4.3914
	old_data_grads_norm = 3.1955
	sim_grads_norm = 0.0958
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9314
	data_grads_norm = 3.0860
	new_data_grads_norm = 4.2659
	old_data_grads_norm = 3.1199
	sim_grads_norm = 0.2733
-- Starting training on experience 41 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7111
	data_grads_norm = 2.5625
	new_data_grads_norm = 3.8093
	old_data_grads_norm = 3.4599
	sim_grads_norm = -0.0330
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6613
	data_grads_norm = 2.3897
	new_data_grads_norm = 3.6944
	old_data_grads_norm = 2.6817
	sim_grads_norm = 0.0607
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6075
	data_grads_norm = 2.5638
	new_data_grads_norm = 3.5329
	old_data_grads_norm = 3.1586
	sim_grads_norm = 0.0112
-- Starting training on experience 42 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4000
	data_grads_norm = 2.2065
	new_data_grads_norm = 2.6656
	old_data_grads_norm = 3.1748
	sim_grads_norm = 0.0178
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4099
	data_grads_norm = 2.7724
	new_data_grads_norm = 3.1758
	old_data_grads_norm = 3.8798
	sim_grads_norm = 0.1823
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5794
	data_grads_norm = 2.6464
	new_data_grads_norm = 3.4097
	old_data_grads_norm = 3.5365
	sim_grads_norm = 0.1210
-- Starting training on experience 43 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7011
	data_grads_norm = 2.5383
	new_data_grads_norm = 3.1316
	old_data_grads_norm = 3.2711
	sim_grads_norm = 0.1982
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2857
	data_grads_norm = 2.1907
	new_data_grads_norm = 3.1493
	old_data_grads_norm = 2.9586
	sim_grads_norm = 0.0513
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1892
	data_grads_norm = 1.9617
	new_data_grads_norm = 3.2061
	old_data_grads_norm = 2.3327
	sim_grads_norm = 0.0659
-- Starting training on experience 44 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1316
	data_grads_norm = 2.0401
	new_data_grads_norm = 2.3944
	old_data_grads_norm = 2.9434
	sim_grads_norm = 0.1591
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0165
	data_grads_norm = 1.9821
	new_data_grads_norm = 2.4165
	old_data_grads_norm = 2.8754
	sim_grads_norm = -0.1253
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3322
	data_grads_norm = 2.3924
	new_data_grads_norm = 2.4895
	old_data_grads_norm = 3.7727
	sim_grads_norm = 0.0398
-- Starting training on experience 45 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6185
	data_grads_norm = 2.7309
	new_data_grads_norm = 2.8906
	old_data_grads_norm = 4.0756
	sim_grads_norm = 0.2531
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1569
	data_grads_norm = 2.2951
	new_data_grads_norm = 3.1155
	old_data_grads_norm = 2.7545
	sim_grads_norm = 0.0585
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9465
	data_grads_norm = 2.2372
	new_data_grads_norm = 3.2076
	old_data_grads_norm = 3.6928
	sim_grads_norm = -0.1202
-- Starting training on experience 46 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9181
	data_grads_norm = 2.6261
	new_data_grads_norm = 4.0097
	old_data_grads_norm = 3.0013
	sim_grads_norm = 0.0021
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3085
	data_grads_norm = 2.9495
	new_data_grads_norm = 4.1853
	old_data_grads_norm = 3.0381
	sim_grads_norm = 0.0359
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2314
	data_grads_norm = 2.9899
	new_data_grads_norm = 4.1100
	old_data_grads_norm = 2.9543
	sim_grads_norm = -0.0377
-- Starting training on experience 47 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7372
	data_grads_norm = 3.1746
	new_data_grads_norm = 3.6017
	old_data_grads_norm = 4.3606
	sim_grads_norm = 0.0498
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5777
	data_grads_norm = 2.4772
	new_data_grads_norm = 3.3937
	old_data_grads_norm = 3.5986
	sim_grads_norm = -0.0694
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8521
	data_grads_norm = 2.9399
	new_data_grads_norm = 3.4406
	old_data_grads_norm = 3.9434
	sim_grads_norm = 0.0555
-- Starting training on experience 48 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0555
	data_grads_norm = 2.4147
	new_data_grads_norm = 3.3459
	old_data_grads_norm = 3.2394
	sim_grads_norm = -0.0971
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5471
	data_grads_norm = 3.1483
	new_data_grads_norm = 3.4718
	old_data_grads_norm = 4.4500
	sim_grads_norm = 0.0112
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1965
	data_grads_norm = 2.5930
	new_data_grads_norm = 3.4190
	old_data_grads_norm = 3.5361
	sim_grads_norm = 0.0807
-- Starting training on experience 49 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7022
	data_grads_norm = 3.0088
	new_data_grads_norm = 3.4422
	old_data_grads_norm = 4.1214
	sim_grads_norm = 0.2641
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2762
	data_grads_norm = 2.2801
	new_data_grads_norm = 3.6109
	old_data_grads_norm = 2.6890
	sim_grads_norm = 0.1577
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2599
	data_grads_norm = 2.6079
	new_data_grads_norm = 3.4828
	old_data_grads_norm = 3.1918
	sim_grads_norm = 0.2787
-- Starting training on experience 50 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0770
	data_grads_norm = 2.3349
	new_data_grads_norm = 3.2105
	old_data_grads_norm = 3.2841
	sim_grads_norm = -0.0491
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2657
	data_grads_norm = 2.7445
	new_data_grads_norm = 4.0993
	old_data_grads_norm = 3.1765
	sim_grads_norm = 0.0500
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0903
	data_grads_norm = 2.4114
	new_data_grads_norm = 3.6612
	old_data_grads_norm = 3.1768
	sim_grads_norm = -0.0443
-- Starting training on experience 51 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7302
	data_grads_norm = 3.1252
	new_data_grads_norm = 3.6818
	old_data_grads_norm = 3.9491
	sim_grads_norm = 0.1550
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0160
	data_grads_norm = 2.6277
	new_data_grads_norm = 3.4089
	old_data_grads_norm = 3.3391
	sim_grads_norm = -0.0224
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8757
	data_grads_norm = 2.3404
	new_data_grads_norm = 3.1679
	old_data_grads_norm = 3.1446
	sim_grads_norm = 0.0625
-- Starting training on experience 52 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0671
	data_grads_norm = 2.4484
	new_data_grads_norm = 3.2506
	old_data_grads_norm = 3.1558
	sim_grads_norm = 0.1525
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0749
	data_grads_norm = 3.0822
	new_data_grads_norm = 3.1985
	old_data_grads_norm = 5.0769
	sim_grads_norm = 0.1133
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0550
	data_grads_norm = 2.4780
	new_data_grads_norm = 3.1337
	old_data_grads_norm = 3.6966
	sim_grads_norm = -0.0033
-- Starting training on experience 53 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3006
	data_grads_norm = 2.8299
	new_data_grads_norm = 3.4015
	old_data_grads_norm = 3.8547
	sim_grads_norm = 0.2060
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2710
	data_grads_norm = 2.5696
	new_data_grads_norm = 3.5561
	old_data_grads_norm = 3.1622
	sim_grads_norm = 0.0155
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2953
	data_grads_norm = 2.6009
	new_data_grads_norm = 3.4974
	old_data_grads_norm = 3.4147
	sim_grads_norm = 0.1149
-- Starting training on experience 54 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0019
	data_grads_norm = 2.3552
	new_data_grads_norm = 3.1340
	old_data_grads_norm = 3.7056
	sim_grads_norm = -0.0658
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9018
	data_grads_norm = 2.3130
	new_data_grads_norm = 3.2518
	old_data_grads_norm = 4.0549
	sim_grads_norm = -0.1001
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0219
	data_grads_norm = 2.8546
	new_data_grads_norm = 3.6364
	old_data_grads_norm = 4.5153
	sim_grads_norm = 0.0378
-- Starting training on experience 55 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6752
	data_grads_norm = 2.4645
	new_data_grads_norm = 3.4828
	old_data_grads_norm = 3.9112
	sim_grads_norm = -0.0116
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2145
	data_grads_norm = 2.4041
	new_data_grads_norm = 3.2366
	old_data_grads_norm = 2.7315
	sim_grads_norm = 0.0966
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0809
	data_grads_norm = 2.4803
	new_data_grads_norm = 3.4643
	old_data_grads_norm = 2.4789
	sim_grads_norm = 0.0332
-- Starting training on experience 56 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7986
	data_grads_norm = 2.8317
	new_data_grads_norm = 4.7982
	old_data_grads_norm = 3.6757
	sim_grads_norm = -0.0106
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8376
	data_grads_norm = 2.9851
	new_data_grads_norm = 4.9668
	old_data_grads_norm = 3.4996
	sim_grads_norm = 0.0703
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4777
	data_grads_norm = 3.3773
	new_data_grads_norm = 5.0714
	old_data_grads_norm = 3.8169
	sim_grads_norm = -0.0251
-- Starting training on experience 57 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3635
	data_grads_norm = 2.9313
	new_data_grads_norm = 5.1210
	old_data_grads_norm = 3.2654
	sim_grads_norm = 0.0212
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1503
	data_grads_norm = 3.1820
	new_data_grads_norm = 5.5425
	old_data_grads_norm = 4.0511
	sim_grads_norm = -0.0431
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5137
	data_grads_norm = 4.1488
	new_data_grads_norm = 5.5987
	old_data_grads_norm = 5.7444
	sim_grads_norm = 0.0228
-- Starting training on experience 58 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5440
	data_grads_norm = 2.7425
	new_data_grads_norm = 4.6507
	old_data_grads_norm = 2.9683
	sim_grads_norm = -0.1042
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2832
	data_grads_norm = 2.7357
	new_data_grads_norm = 4.5326
	old_data_grads_norm = 3.3377
	sim_grads_norm = 0.0078
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1879
	data_grads_norm = 2.4389
	new_data_grads_norm = 4.5316
	old_data_grads_norm = 3.4057
	sim_grads_norm = -0.0874
-- Starting training on experience 59 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3642
	data_grads_norm = 2.8854
	new_data_grads_norm = 3.7739
	old_data_grads_norm = 3.9560
	sim_grads_norm = 0.0871
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0770
	data_grads_norm = 2.6694
	new_data_grads_norm = 3.7487
	old_data_grads_norm = 3.5738
	sim_grads_norm = 0.0241
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1702
	data_grads_norm = 2.9307
	new_data_grads_norm = 3.6631
	old_data_grads_norm = 3.3259
	sim_grads_norm = 0.3135
-- Starting training on experience 60 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1677
	data_grads_norm = 2.6715
	new_data_grads_norm = 3.8288
	old_data_grads_norm = 3.2728
	sim_grads_norm = 0.0570
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2574
	data_grads_norm = 2.9134
	new_data_grads_norm = 3.7588
	old_data_grads_norm = 4.3878
	sim_grads_norm = 0.0693
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1566
	data_grads_norm = 2.3438
	new_data_grads_norm = 3.6061
	old_data_grads_norm = 2.8107
	sim_grads_norm = -0.0065
-- Starting training on experience 61 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5290
	data_grads_norm = 2.5341
	new_data_grads_norm = 3.5105
	old_data_grads_norm = 3.4340
	sim_grads_norm = 0.0044
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3743
	data_grads_norm = 2.3766
	new_data_grads_norm = 3.5845
	old_data_grads_norm = 2.7995
	sim_grads_norm = 0.0973
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5475
	data_grads_norm = 3.2084
	new_data_grads_norm = 3.3199
	old_data_grads_norm = 4.9993
	sim_grads_norm = -0.1393
-- Starting training on experience 62 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2743
	data_grads_norm = 3.2427
	new_data_grads_norm = 4.6911
	old_data_grads_norm = 4.5614
	sim_grads_norm = 0.0362
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4504
	data_grads_norm = 2.8109
	new_data_grads_norm = 4.4895
	old_data_grads_norm = 3.6984
	sim_grads_norm = -0.0458
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6221
	data_grads_norm = 3.1677
	new_data_grads_norm = 4.0200
	old_data_grads_norm = 4.0366
	sim_grads_norm = 0.2381
-- Starting training on experience 63 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2701
	data_grads_norm = 2.8382
	new_data_grads_norm = 3.7385
	old_data_grads_norm = 4.1727
	sim_grads_norm = -0.1650
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5958
	data_grads_norm = 2.9531
	new_data_grads_norm = 4.4810
	old_data_grads_norm = 3.3160
	sim_grads_norm = 0.1591
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1559
	data_grads_norm = 2.4179
	new_data_grads_norm = 3.7057
	old_data_grads_norm = 2.6642
	sim_grads_norm = -0.0318
-- Starting training on experience 64 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6979
	data_grads_norm = 3.1416
	new_data_grads_norm = 4.6089
	old_data_grads_norm = 3.4391
	sim_grads_norm = 0.1557
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5649
	data_grads_norm = 3.1825
	new_data_grads_norm = 4.3856
	old_data_grads_norm = 3.5909
	sim_grads_norm = 0.0943
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5460
	data_grads_norm = 3.2372
	new_data_grads_norm = 3.9657
	old_data_grads_norm = 4.0731
	sim_grads_norm = 0.2352
-- Starting training on experience 65 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3898
	data_grads_norm = 2.6766
	new_data_grads_norm = 4.2779
	old_data_grads_norm = 2.2715
	sim_grads_norm = 0.0255
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5174
	data_grads_norm = 2.6732
	new_data_grads_norm = 3.7474
	old_data_grads_norm = 3.2192
	sim_grads_norm = -0.1868
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6522
	data_grads_norm = 2.8404
	new_data_grads_norm = 3.9905
	old_data_grads_norm = 3.2984
	sim_grads_norm = 0.0652
-- Starting training on experience 66 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4117
	data_grads_norm = 2.5846
	new_data_grads_norm = 3.6401
	old_data_grads_norm = 3.5053
	sim_grads_norm = 0.0399
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3903
	data_grads_norm = 2.7375
	new_data_grads_norm = 3.7508
	old_data_grads_norm = 3.9277
	sim_grads_norm = 0.0362
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1963
	data_grads_norm = 2.7239
	new_data_grads_norm = 3.8502
	old_data_grads_norm = 3.5220
	sim_grads_norm = -0.0824
-- Starting training on experience 67 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2255
	data_grads_norm = 2.5263
	new_data_grads_norm = 3.8943
	old_data_grads_norm = 3.0547
	sim_grads_norm = 0.0578
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2871
	data_grads_norm = 2.4601
	new_data_grads_norm = 3.5143
	old_data_grads_norm = 3.7027
	sim_grads_norm = -0.0279
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4251
	data_grads_norm = 2.4654
	new_data_grads_norm = 3.6480
	old_data_grads_norm = 2.6861
	sim_grads_norm = 0.1226
-- Starting training on experience 68 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2245
	data_grads_norm = 2.3039
	new_data_grads_norm = 3.3873
	old_data_grads_norm = 3.2676
	sim_grads_norm = -0.0053
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4147
	data_grads_norm = 2.7314
	new_data_grads_norm = 3.8833
	old_data_grads_norm = 3.0757
	sim_grads_norm = -0.0546
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5470
	data_grads_norm = 2.6615
	new_data_grads_norm = 3.8715
	old_data_grads_norm = 3.1091
	sim_grads_norm = 0.0927
-- Starting training on experience 69 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2561
	data_grads_norm = 2.4733
	new_data_grads_norm = 3.7752
	old_data_grads_norm = 3.0586
	sim_grads_norm = 0.1656
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0318
	data_grads_norm = 2.7637
	new_data_grads_norm = 3.5984
	old_data_grads_norm = 3.4830
	sim_grads_norm = -0.0262
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7851
	data_grads_norm = 2.2323
	new_data_grads_norm = 4.1745
	old_data_grads_norm = 3.1942
	sim_grads_norm = -0.0732
-- Starting training on experience 70 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9209
	data_grads_norm = 2.5669
	new_data_grads_norm = 4.3451
	old_data_grads_norm = 4.1049
	sim_grads_norm = -0.1176
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4993
	data_grads_norm = 3.1996
	new_data_grads_norm = 4.6163
	old_data_grads_norm = 3.7003
	sim_grads_norm = 0.0964
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1876
	data_grads_norm = 2.7287
	new_data_grads_norm = 4.3016
	old_data_grads_norm = 3.4285
	sim_grads_norm = 0.1271
-- Starting training on experience 71 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1421
	data_grads_norm = 2.2965
	new_data_grads_norm = 3.6729
	old_data_grads_norm = 2.8177
	sim_grads_norm = -0.0243
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9671
	data_grads_norm = 2.5372
	new_data_grads_norm = 3.6715
	old_data_grads_norm = 3.0296
	sim_grads_norm = 0.1498
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2045
	data_grads_norm = 2.3493
	new_data_grads_norm = 3.6583
	old_data_grads_norm = 2.8992
	sim_grads_norm = -0.0106
-- Starting training on experience 72 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3800
	data_grads_norm = 2.7260
	new_data_grads_norm = 3.3377
	old_data_grads_norm = 3.3256
	sim_grads_norm = 0.2433
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8394
	data_grads_norm = 2.1063
	new_data_grads_norm = 2.9564
	old_data_grads_norm = 2.6503
	sim_grads_norm = 0.0410
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8797
	data_grads_norm = 2.3999
	new_data_grads_norm = 3.4095
	old_data_grads_norm = 3.6463
	sim_grads_norm = -0.0827
-- Starting training on experience 73 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5222
	data_grads_norm = 2.4707
	new_data_grads_norm = 3.9055
	old_data_grads_norm = 2.9134
	sim_grads_norm = 0.0113
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3547
	data_grads_norm = 2.8048
	new_data_grads_norm = 4.1794
	old_data_grads_norm = 4.0132
	sim_grads_norm = 0.0188
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3998
	data_grads_norm = 2.3653
	new_data_grads_norm = 3.6755
	old_data_grads_norm = 2.6748
	sim_grads_norm = 0.1300
-- Starting training on experience 74 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4320
	data_grads_norm = 3.1107
	new_data_grads_norm = 3.8383
	old_data_grads_norm = 4.1120
	sim_grads_norm = 0.1243
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5382
	data_grads_norm = 2.8246
	new_data_grads_norm = 4.1498
	old_data_grads_norm = 3.8188
	sim_grads_norm = -0.0436
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4764
	data_grads_norm = 2.9998
	new_data_grads_norm = 4.6734
	old_data_grads_norm = 3.1797
	sim_grads_norm = 0.0301
-- Starting training on experience 75 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3109
	data_grads_norm = 2.6466
	new_data_grads_norm = 3.8086
	old_data_grads_norm = 3.1174
	sim_grads_norm = 0.0684
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2078
	data_grads_norm = 2.3550
	new_data_grads_norm = 3.2675
	old_data_grads_norm = 2.9724
	sim_grads_norm = 0.1010
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4742
	data_grads_norm = 3.0814
	new_data_grads_norm = 3.9449
	old_data_grads_norm = 4.6761
	sim_grads_norm = -0.0887
-- Starting training on experience 76 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9624
	data_grads_norm = 2.3536
	new_data_grads_norm = 3.1608
	old_data_grads_norm = 2.9237
	sim_grads_norm = 0.2772
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1425
	data_grads_norm = 2.2508
	new_data_grads_norm = 3.6782
	old_data_grads_norm = 3.0869
	sim_grads_norm = -0.1552
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9951
	data_grads_norm = 2.7924
	new_data_grads_norm = 4.6419
	old_data_grads_norm = 2.5301
	sim_grads_norm = 0.0609
-- Starting training on experience 77 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6058
	data_grads_norm = 2.7789
	new_data_grads_norm = 4.1655
	old_data_grads_norm = 3.7428
	sim_grads_norm = 0.0450
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2604
	data_grads_norm = 2.5211
	new_data_grads_norm = 3.9683
	old_data_grads_norm = 4.3401
	sim_grads_norm = -0.0422
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4401
	data_grads_norm = 2.6158
	new_data_grads_norm = 3.9346
	old_data_grads_norm = 2.9791
	sim_grads_norm = 0.1177
-- Starting training on experience 78 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9354
	data_grads_norm = 2.4263
	new_data_grads_norm = 3.3850
	old_data_grads_norm = 3.2575
	sim_grads_norm = -0.0187
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8928
	data_grads_norm = 2.8804
	new_data_grads_norm = 3.7124
	old_data_grads_norm = 4.3650
	sim_grads_norm = -0.1021
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0044
	data_grads_norm = 2.7128
	new_data_grads_norm = 3.6785
	old_data_grads_norm = 2.8044
	sim_grads_norm = 0.1397
-- Starting training on experience 79 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0595
	data_grads_norm = 2.2823
	new_data_grads_norm = 3.8635
	old_data_grads_norm = 2.8585
	sim_grads_norm = -0.0878
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1075
	data_grads_norm = 2.7074
	new_data_grads_norm = 3.8742
	old_data_grads_norm = 3.6493
	sim_grads_norm = 0.0097
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0017
	data_grads_norm = 2.8427
	new_data_grads_norm = 4.2639
	old_data_grads_norm = 3.8914
	sim_grads_norm = 0.0492
-- Starting training on experience 80 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2023
	data_grads_norm = 3.0753
	new_data_grads_norm = 3.4787
	old_data_grads_norm = 3.9481
	sim_grads_norm = 0.2463
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9370
	data_grads_norm = 2.2259
	new_data_grads_norm = 3.0590
	old_data_grads_norm = 3.3749
	sim_grads_norm = -0.0182
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0513
	data_grads_norm = 2.1348
	new_data_grads_norm = 3.4033
	old_data_grads_norm = 3.1097
	sim_grads_norm = -0.1624
-- Starting training on experience 81 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9008
	data_grads_norm = 2.2667
	new_data_grads_norm = 3.1463
	old_data_grads_norm = 2.9771
	sim_grads_norm = 0.0837
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3928
	data_grads_norm = 2.5662
	new_data_grads_norm = 3.1203
	old_data_grads_norm = 4.2230
	sim_grads_norm = -0.0428
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2563
	data_grads_norm = 2.4402
	new_data_grads_norm = 3.5971
	old_data_grads_norm = 3.5288
	sim_grads_norm = -0.0754
-- Starting training on experience 82 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6582
	data_grads_norm = 2.2091
	new_data_grads_norm = 3.5618
	old_data_grads_norm = 2.1143
	sim_grads_norm = -0.0275
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2252
	data_grads_norm = 2.6476
	new_data_grads_norm = 3.4917
	old_data_grads_norm = 3.6503
	sim_grads_norm = -0.1330
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1466
	data_grads_norm = 2.6067
	new_data_grads_norm = 3.1529
	old_data_grads_norm = 3.6720
	sim_grads_norm = 0.1413
-- Starting training on experience 83 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0934
	data_grads_norm = 2.3822
	new_data_grads_norm = 2.8918
	old_data_grads_norm = 3.6650
	sim_grads_norm = 0.1490
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8623
	data_grads_norm = 2.3896
	new_data_grads_norm = 2.5652
	old_data_grads_norm = 3.2756
	sim_grads_norm = 0.2102
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4979
	data_grads_norm = 1.7190
	new_data_grads_norm = 2.5089
	old_data_grads_norm = 2.1966
	sim_grads_norm = 0.1367
-- Starting training on experience 84 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8876
	data_grads_norm = 2.5705
	new_data_grads_norm = 4.0939
	old_data_grads_norm = 3.0385
	sim_grads_norm = 0.0181
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9499
	data_grads_norm = 2.6917
	new_data_grads_norm = 4.5813
	old_data_grads_norm = 2.5113
	sim_grads_norm = 0.1521
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0117
	data_grads_norm = 2.3788
	new_data_grads_norm = 3.6185
	old_data_grads_norm = 4.0415
	sim_grads_norm = -0.0074
-- Starting training on experience 85 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9812
	data_grads_norm = 2.4667
	new_data_grads_norm = 3.3689
	old_data_grads_norm = 3.3673
	sim_grads_norm = -0.0537
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9626
	data_grads_norm = 2.1762
	new_data_grads_norm = 3.5678
	old_data_grads_norm = 2.6021
	sim_grads_norm = -0.0039
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0291
	data_grads_norm = 2.2811
	new_data_grads_norm = 3.4964
	old_data_grads_norm = 3.1078
	sim_grads_norm = -0.0365
-- Starting training on experience 86 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0847
	data_grads_norm = 2.2535
	new_data_grads_norm = 3.6025
	old_data_grads_norm = 2.9010
	sim_grads_norm = -0.0375
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0743
	data_grads_norm = 2.4366
	new_data_grads_norm = 3.6511
	old_data_grads_norm = 2.8595
	sim_grads_norm = 0.0283
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9448
	data_grads_norm = 2.4414
	new_data_grads_norm = 3.4057
	old_data_grads_norm = 3.6434
	sim_grads_norm = -0.1066
-- Starting training on experience 87 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2711
	data_grads_norm = 2.9536
	new_data_grads_norm = 4.2006
	old_data_grads_norm = 4.0001
	sim_grads_norm = 0.0274
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4698
	data_grads_norm = 3.4737
	new_data_grads_norm = 3.7941
	old_data_grads_norm = 3.6960
	sim_grads_norm = 0.0730
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3030
	data_grads_norm = 2.8818
	new_data_grads_norm = 3.9441
	old_data_grads_norm = 3.0339
	sim_grads_norm = 0.2033
-- Starting training on experience 88 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4996
	data_grads_norm = 2.9256
	new_data_grads_norm = 4.4207
	old_data_grads_norm = 4.5567
	sim_grads_norm = -0.0949
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2679
	data_grads_norm = 2.1586
	new_data_grads_norm = 4.0752
	old_data_grads_norm = 2.4046
	sim_grads_norm = -0.0122
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9767
	data_grads_norm = 3.3168
	new_data_grads_norm = 4.7162
	old_data_grads_norm = 4.4287
	sim_grads_norm = 0.0338
-- Starting training on experience 89 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4312
	data_grads_norm = 3.0861
	new_data_grads_norm = 3.7860
	old_data_grads_norm = 4.3503
	sim_grads_norm = 0.2314
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0270
	data_grads_norm = 3.2925
	new_data_grads_norm = 4.0171
	old_data_grads_norm = 3.2736
	sim_grads_norm = 0.1924
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2830
	data_grads_norm = 2.5102
	new_data_grads_norm = 3.3702
	old_data_grads_norm = 3.7658
	sim_grads_norm = -0.0383
-- Starting training on experience 90 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8642
	data_grads_norm = 2.3357
	new_data_grads_norm = 3.4590
	old_data_grads_norm = 2.6693
	sim_grads_norm = 0.0281
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3746
	data_grads_norm = 2.9679
	new_data_grads_norm = 3.9956
	old_data_grads_norm = 4.1596
	sim_grads_norm = 0.0702
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9017
	data_grads_norm = 2.4321
	new_data_grads_norm = 3.2509
	old_data_grads_norm = 2.7852
	sim_grads_norm = 0.1524
-- Starting training on experience 91 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8785
	data_grads_norm = 2.5295
	new_data_grads_norm = 3.9438
	old_data_grads_norm = 3.3921
	sim_grads_norm = -0.0505
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5047
	data_grads_norm = 2.1654
	new_data_grads_norm = 3.7094
	old_data_grads_norm = 2.3566
	sim_grads_norm = -0.1352
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5758
	data_grads_norm = 2.3591
	new_data_grads_norm = 4.5272
	old_data_grads_norm = 2.4823
	sim_grads_norm = 0.0069
-- Starting training on experience 92 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7864
	data_grads_norm = 2.1858
	new_data_grads_norm = 2.9726
	old_data_grads_norm = 3.5191
	sim_grads_norm = -0.1034
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9739
	data_grads_norm = 2.4953
	new_data_grads_norm = 3.3362
	old_data_grads_norm = 3.4272
	sim_grads_norm = 0.0433
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7295
	data_grads_norm = 2.5117
	new_data_grads_norm = 3.2511
	old_data_grads_norm = 3.4229
	sim_grads_norm = -0.1047
-- Starting training on experience 93 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9227
	data_grads_norm = 3.0468
	new_data_grads_norm = 3.9919
	old_data_grads_norm = 3.7396
	sim_grads_norm = 0.3763
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7181
	data_grads_norm = 2.8318
	new_data_grads_norm = 3.4314
	old_data_grads_norm = 3.9907
	sim_grads_norm = 0.0163
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4134
	data_grads_norm = 2.3233
	new_data_grads_norm = 3.3429
	old_data_grads_norm = 3.2004
	sim_grads_norm = -0.0303
-- Starting training on experience 94 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7466
	data_grads_norm = 2.6138
	new_data_grads_norm = 3.8853
	old_data_grads_norm = 4.0583
	sim_grads_norm = -0.0694
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2580
	data_grads_norm = 3.4818
	new_data_grads_norm = 4.7078
	old_data_grads_norm = 4.4033
	sim_grads_norm = 0.1784
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2029
	data_grads_norm = 3.5354
	new_data_grads_norm = 4.0692
	old_data_grads_norm = 4.2855
	sim_grads_norm = 0.3432
-- Starting training on experience 95 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9628
	data_grads_norm = 2.8325
	new_data_grads_norm = 4.0567
	old_data_grads_norm = 6.4873
	sim_grads_norm = -0.0417
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1517
	data_grads_norm = 3.3464
	new_data_grads_norm = 4.6023
	old_data_grads_norm = 3.7140
	sim_grads_norm = 0.1911
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2347
	data_grads_norm = 2.9562
	new_data_grads_norm = 3.8408
	old_data_grads_norm = 4.3382
	sim_grads_norm = 0.0002
-- Starting training on experience 96 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1130
	data_grads_norm = 2.7484
	new_data_grads_norm = 4.2074
	old_data_grads_norm = 4.1250
	sim_grads_norm = -0.1125
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1697
	data_grads_norm = 3.2287
	new_data_grads_norm = 4.7250
	old_data_grads_norm = 3.6365
	sim_grads_norm = 0.0169
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4753
	data_grads_norm = 4.0076
	new_data_grads_norm = 5.2994
	old_data_grads_norm = 4.7230
	sim_grads_norm = 0.2590
-- Starting training on experience 97 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6729
	data_grads_norm = 4.0436
	new_data_grads_norm = 4.9726
	old_data_grads_norm = 5.2114
	sim_grads_norm = 0.1935
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8749
	data_grads_norm = 2.4920
	new_data_grads_norm = 4.4056
	old_data_grads_norm = 2.9669
	sim_grads_norm = -0.0370
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9277
	data_grads_norm = 3.5744
	new_data_grads_norm = 4.7296
	old_data_grads_norm = 5.5049
	sim_grads_norm = -0.0777
-- Starting training on experience 98 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4986
	data_grads_norm = 3.2492
	new_data_grads_norm = 4.2115
	old_data_grads_norm = 4.0961
	sim_grads_norm = 0.1552
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0330
	data_grads_norm = 2.7687
	new_data_grads_norm = 3.7667
	old_data_grads_norm = 3.8704
	sim_grads_norm = 0.0768
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4451
	data_grads_norm = 3.3897
	new_data_grads_norm = 3.7178
	old_data_grads_norm = 3.6315
	sim_grads_norm = 0.0823
-- Starting training on experience 99 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3642
	data_grads_norm = 2.9495
	new_data_grads_norm = 4.3521
	old_data_grads_norm = 3.1414
	sim_grads_norm = 0.1901
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0066
	data_grads_norm = 2.6528
	new_data_grads_norm = 4.2514
	old_data_grads_norm = 2.5398
	sim_grads_norm = 0.2103
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3030
	data_grads_norm = 2.5377
	new_data_grads_norm = 3.6019
	old_data_grads_norm = 3.8684
	sim_grads_norm = -0.0872
-- Starting training on experience 100 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5297
	data_grads_norm = 2.8919
	new_data_grads_norm = 4.0177
	old_data_grads_norm = 3.6866
	sim_grads_norm = 0.0579
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0902
	data_grads_norm = 2.6914
	new_data_grads_norm = 4.2976
	old_data_grads_norm = 3.2576
	sim_grads_norm = 0.1196
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8700
	data_grads_norm = 2.5590
	new_data_grads_norm = 3.9322
	old_data_grads_norm = 3.8075
	sim_grads_norm = -0.0654
-- Starting training on experience 101 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7848
	data_grads_norm = 2.8687
	new_data_grads_norm = 4.8945
	old_data_grads_norm = 3.0805
	sim_grads_norm = -0.0779
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4995
	data_grads_norm = 2.7069
	new_data_grads_norm = 4.2033
	old_data_grads_norm = 2.7657
	sim_grads_norm = 0.0160
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0190
	data_grads_norm = 2.7968
	new_data_grads_norm = 4.3207
	old_data_grads_norm = 4.1443
	sim_grads_norm = -0.0767
-- Starting training on experience 102 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6706
	data_grads_norm = 2.7181
	new_data_grads_norm = 3.3981
	old_data_grads_norm = 3.8032
	sim_grads_norm = 0.1593
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0610
	data_grads_norm = 2.5375
	new_data_grads_norm = 3.6431
	old_data_grads_norm = 3.3283
	sim_grads_norm = 0.1184
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6065
	data_grads_norm = 2.1758
	new_data_grads_norm = 2.9472
	old_data_grads_norm = 2.6610
	sim_grads_norm = 0.2626
-- Starting training on experience 103 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2934
	data_grads_norm = 2.5806
	new_data_grads_norm = 3.1137
	old_data_grads_norm = 3.9682
	sim_grads_norm = 0.0228
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2067
	data_grads_norm = 2.9092
	new_data_grads_norm = 2.9685
	old_data_grads_norm = 4.2257
	sim_grads_norm = 0.0697
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1105
	data_grads_norm = 2.4291
	new_data_grads_norm = 3.2771
	old_data_grads_norm = 3.5930
	sim_grads_norm = 0.0554
-- Starting training on experience 104 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1436
	data_grads_norm = 2.3523
	new_data_grads_norm = 3.1185
	old_data_grads_norm = 2.8046
	sim_grads_norm = 0.3322
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0431
	data_grads_norm = 2.5103
	new_data_grads_norm = 2.8750
	old_data_grads_norm = 4.2979
	sim_grads_norm = -0.0308
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8244
	data_grads_norm = 2.0372
	new_data_grads_norm = 2.9946
	old_data_grads_norm = 2.7753
	sim_grads_norm = -0.0591
-- Starting training on experience 105 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0786
	data_grads_norm = 3.0314
	new_data_grads_norm = 3.6237
	old_data_grads_norm = 4.2369
	sim_grads_norm = -0.0195
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2212
	data_grads_norm = 2.9852
	new_data_grads_norm = 3.6876
	old_data_grads_norm = 4.1984
	sim_grads_norm = -0.0596
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9234
	data_grads_norm = 2.7236
	new_data_grads_norm = 3.7343
	old_data_grads_norm = 4.3465
	sim_grads_norm = 0.0224
-- Starting training on experience 106 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8453
	data_grads_norm = 2.2778
	new_data_grads_norm = 3.9551
	old_data_grads_norm = 2.5781
	sim_grads_norm = -0.1065
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3173
	data_grads_norm = 2.8826
	new_data_grads_norm = 4.1375
	old_data_grads_norm = 3.2961
	sim_grads_norm = 0.2700
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9494
	data_grads_norm = 2.4979
	new_data_grads_norm = 3.5465
	old_data_grads_norm = 3.6782
	sim_grads_norm = -0.0036
-- Starting training on experience 107 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0140
	data_grads_norm = 2.6262
	new_data_grads_norm = 3.9869
	old_data_grads_norm = 3.1699
	sim_grads_norm = 0.0165
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8012
	data_grads_norm = 2.3751
	new_data_grads_norm = 3.7639
	old_data_grads_norm = 2.9510
	sim_grads_norm = 0.0431
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0293
	data_grads_norm = 2.6556
	new_data_grads_norm = 4.2524
	old_data_grads_norm = 3.4644
	sim_grads_norm = -0.0742
-- Starting training on experience 108 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1218
	data_grads_norm = 3.4010
	new_data_grads_norm = 4.7825
	old_data_grads_norm = 4.0959
	sim_grads_norm = 0.0832
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9902
	data_grads_norm = 3.5350
	new_data_grads_norm = 4.1854
	old_data_grads_norm = 4.5097
	sim_grads_norm = 0.0635
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2261
	data_grads_norm = 3.3586
	new_data_grads_norm = 4.2286
	old_data_grads_norm = 5.4764
	sim_grads_norm = -0.0069
-- Starting training on experience 109 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3060
	data_grads_norm = 2.4308
	new_data_grads_norm = 4.3085
	old_data_grads_norm = 2.6172
	sim_grads_norm = 0.0017
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7051
	data_grads_norm = 2.6022
	new_data_grads_norm = 4.3550
	old_data_grads_norm = 3.5188
	sim_grads_norm = -0.0631
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4955
	data_grads_norm = 2.8398
	new_data_grads_norm = 4.9544
	old_data_grads_norm = 3.5669
	sim_grads_norm = 0.0391
-- Starting training on experience 110 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9668
	data_grads_norm = 2.6477
	new_data_grads_norm = 3.7441
	old_data_grads_norm = 3.2731
	sim_grads_norm = 0.0608
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8978
	data_grads_norm = 2.8870
	new_data_grads_norm = 4.0058
	old_data_grads_norm = 3.4163
	sim_grads_norm = 0.1597
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6082
	data_grads_norm = 2.4654
	new_data_grads_norm = 3.5465
	old_data_grads_norm = 3.3617
	sim_grads_norm = -0.0298
-- Starting training on experience 111 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2435
	data_grads_norm = 2.7282
	new_data_grads_norm = 4.4385
	old_data_grads_norm = 3.3167
	sim_grads_norm = 0.0834
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4241
	data_grads_norm = 2.8803
	new_data_grads_norm = 4.5003
	old_data_grads_norm = 3.7829
	sim_grads_norm = -0.0036
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6878
	data_grads_norm = 2.9797
	new_data_grads_norm = 4.7440
	old_data_grads_norm = 3.9243
	sim_grads_norm = -0.0120
-- Starting training on experience 112 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7731
	data_grads_norm = 2.6522
	new_data_grads_norm = 4.4917
	old_data_grads_norm = 3.5564
	sim_grads_norm = 0.0284
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0032
	data_grads_norm = 3.4389
	new_data_grads_norm = 4.1621
	old_data_grads_norm = 4.9492
	sim_grads_norm = 0.0374
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7458
	data_grads_norm = 3.0809
	new_data_grads_norm = 4.3062
	old_data_grads_norm = 3.5472
	sim_grads_norm = 0.2055
-- Starting training on experience 113 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1601
	data_grads_norm = 3.1490
	new_data_grads_norm = 3.3540
	old_data_grads_norm = 3.3932
	sim_grads_norm = 0.0933
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9180
	data_grads_norm = 2.2471
	new_data_grads_norm = 3.5162
	old_data_grads_norm = 3.0547
	sim_grads_norm = -0.0874
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8654
	data_grads_norm = 2.3045
	new_data_grads_norm = 3.3960
	old_data_grads_norm = 3.3270
	sim_grads_norm = -0.0157
-- Starting training on experience 114 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2011
	data_grads_norm = 3.2323
	new_data_grads_norm = 4.5069
	old_data_grads_norm = 3.8274
	sim_grads_norm = 0.0386
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3810
	data_grads_norm = 3.1159
	new_data_grads_norm = 4.1110
	old_data_grads_norm = 4.1668
	sim_grads_norm = 0.0119
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1090
	data_grads_norm = 2.6288
	new_data_grads_norm = 5.2074
	old_data_grads_norm = 3.6997
	sim_grads_norm = -0.1361
-- Starting training on experience 115 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9127
	data_grads_norm = 2.7687
	new_data_grads_norm = 4.1367
	old_data_grads_norm = 2.9700
	sim_grads_norm = 0.1379
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1453
	data_grads_norm = 3.2457
	new_data_grads_norm = 3.9442
	old_data_grads_norm = 4.9474
	sim_grads_norm = -0.0112
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0353
	data_grads_norm = 2.8441
	new_data_grads_norm = 3.8079
	old_data_grads_norm = 3.5935
	sim_grads_norm = 0.1387
-- Starting training on experience 116 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2658
	data_grads_norm = 3.5909
	new_data_grads_norm = 4.8381
	old_data_grads_norm = 5.6787
	sim_grads_norm = -0.0207
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9992
	data_grads_norm = 2.6716
	new_data_grads_norm = 4.2993
	old_data_grads_norm = 3.2385
	sim_grads_norm = -0.1730
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2065
	data_grads_norm = 3.4241
	new_data_grads_norm = 4.3716
	old_data_grads_norm = 5.1019
	sim_grads_norm = 0.0031
-- Starting training on experience 117 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2676
	data_grads_norm = 3.6214
	new_data_grads_norm = 3.9753
	old_data_grads_norm = 5.4614
	sim_grads_norm = 0.0373
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1106
	data_grads_norm = 2.9986
	new_data_grads_norm = 4.8324
	old_data_grads_norm = 4.4832
	sim_grads_norm = 0.0470
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4912
	data_grads_norm = 3.2451
	new_data_grads_norm = 4.1878
	old_data_grads_norm = 4.2894
	sim_grads_norm = 0.1395
-- Starting training on experience 118 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0277
	data_grads_norm = 2.7611
	new_data_grads_norm = 3.1406
	old_data_grads_norm = 3.9484
	sim_grads_norm = 0.0483
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6760
	data_grads_norm = 2.2314
	new_data_grads_norm = 3.2070
	old_data_grads_norm = 3.4639
	sim_grads_norm = -0.0754
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6536
	data_grads_norm = 2.9188
	new_data_grads_norm = 3.3218
	old_data_grads_norm = 4.4931
	sim_grads_norm = 0.1407
-- Starting training on experience 119 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4199
	data_grads_norm = 3.9525
	new_data_grads_norm = 5.1617
	old_data_grads_norm = 4.6914
	sim_grads_norm = 0.1528
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1644
	data_grads_norm = 3.0053
	new_data_grads_norm = 5.0478
	old_data_grads_norm = 2.8683
	sim_grads_norm = 0.0084
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2179
	data_grads_norm = 2.9448
	new_data_grads_norm = 4.6581
	old_data_grads_norm = 4.0548
	sim_grads_norm = -0.0732
-- Starting training on experience 120 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9731
	data_grads_norm = 2.8238
	new_data_grads_norm = 4.3055
	old_data_grads_norm = 4.1580
	sim_grads_norm = -0.0116
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3110
	data_grads_norm = 3.3759
	new_data_grads_norm = 4.3760
	old_data_grads_norm = 4.2980
	sim_grads_norm = 0.1745
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0265
	data_grads_norm = 3.1098
	new_data_grads_norm = 3.5403
	old_data_grads_norm = 4.5801
	sim_grads_norm = 0.0294
-- Starting training on experience 121 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1733
	data_grads_norm = 2.6686
	new_data_grads_norm = 3.4963
	old_data_grads_norm = 4.4936
	sim_grads_norm = -0.0566
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2603
	data_grads_norm = 2.4943
	new_data_grads_norm = 3.6644
	old_data_grads_norm = 3.0004
	sim_grads_norm = 0.1003
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1932
	data_grads_norm = 2.7202
	new_data_grads_norm = 3.6424
	old_data_grads_norm = 3.7465
	sim_grads_norm = 0.0605
-- Starting training on experience 122 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0794
	data_grads_norm = 2.4851
	new_data_grads_norm = 2.7405
	old_data_grads_norm = 3.7690
	sim_grads_norm = 0.1047
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7065
	data_grads_norm = 1.9362
	new_data_grads_norm = 2.9584
	old_data_grads_norm = 2.9050
	sim_grads_norm = -0.1572
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9207
	data_grads_norm = 2.3328
	new_data_grads_norm = 3.0733
	old_data_grads_norm = 4.0090
	sim_grads_norm = -0.0876
-- Starting training on experience 123 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3071
	data_grads_norm = 3.9087
	new_data_grads_norm = 5.9720
	old_data_grads_norm = 5.2859
	sim_grads_norm = 0.1169
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0640
	data_grads_norm = 2.5473
	new_data_grads_norm = 4.0356
	old_data_grads_norm = 3.0173
	sim_grads_norm = -0.0114
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8924
	data_grads_norm = 3.2197
	new_data_grads_norm = 4.9470
	old_data_grads_norm = 4.2390
	sim_grads_norm = 0.0618
-- Starting training on experience 124 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4244
	data_grads_norm = 3.3132
	new_data_grads_norm = 5.0433
	old_data_grads_norm = 4.0385
	sim_grads_norm = 0.1219
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2059
	data_grads_norm = 2.6323
	new_data_grads_norm = 3.9616
	old_data_grads_norm = 3.4484
	sim_grads_norm = 0.0236
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1741
	data_grads_norm = 3.4013
	new_data_grads_norm = 4.2955
	old_data_grads_norm = 4.2817
	sim_grads_norm = 0.3163
-- Starting training on experience 125 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8481
	data_grads_norm = 2.4598
	new_data_grads_norm = 3.9733
	old_data_grads_norm = 3.2071
	sim_grads_norm = -0.0626
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2824
	data_grads_norm = 3.5903
	new_data_grads_norm = 4.0403
	old_data_grads_norm = 5.0593
	sim_grads_norm = -0.0738
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0820
	data_grads_norm = 2.7973
	new_data_grads_norm = 3.9085
	old_data_grads_norm = 3.1964
	sim_grads_norm = 0.2970
-- Starting training on experience 126 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4316
	data_grads_norm = 2.7973
	new_data_grads_norm = 4.1499
	old_data_grads_norm = 3.6442
	sim_grads_norm = -0.0143
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3169
	data_grads_norm = 2.9191
	new_data_grads_norm = 3.7625
	old_data_grads_norm = 3.9137
	sim_grads_norm = 0.0609
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1846
	data_grads_norm = 2.9305
	new_data_grads_norm = 4.1659
	old_data_grads_norm = 4.2889
	sim_grads_norm = 0.1225
-- Starting training on experience 127 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9620
	data_grads_norm = 2.4120
	new_data_grads_norm = 3.4440
	old_data_grads_norm = 3.3078
	sim_grads_norm = 0.0769
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8156
	data_grads_norm = 2.4496
	new_data_grads_norm = 3.3087
	old_data_grads_norm = 3.6785
	sim_grads_norm = 0.0760
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9497
	data_grads_norm = 2.4345
	new_data_grads_norm = 3.4424
	old_data_grads_norm = 3.0516
	sim_grads_norm = 0.0934
-- Starting training on experience 128 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6485
	data_grads_norm = 3.4511
	new_data_grads_norm = 4.2314
	old_data_grads_norm = 5.0290
	sim_grads_norm = 0.1078
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2850
	data_grads_norm = 2.5988
	new_data_grads_norm = 4.0208
	old_data_grads_norm = 3.2939
	sim_grads_norm = -0.0171
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0252
	data_grads_norm = 2.4139
	new_data_grads_norm = 3.9017
	old_data_grads_norm = 2.5095
	sim_grads_norm = 0.0901
-- Starting training on experience 129 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8854
	data_grads_norm = 2.1504
	new_data_grads_norm = 3.4919
	old_data_grads_norm = 2.3242
	sim_grads_norm = 0.0612
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9924
	data_grads_norm = 2.4611
	new_data_grads_norm = 3.5314
	old_data_grads_norm = 3.2470
	sim_grads_norm = 0.0735
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7395
	data_grads_norm = 2.3878
	new_data_grads_norm = 3.3272
	old_data_grads_norm = 3.6712
	sim_grads_norm = -0.0799
-- Starting training on experience 130 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0404
	data_grads_norm = 2.8184
	new_data_grads_norm = 3.6977
	old_data_grads_norm = 4.3081
	sim_grads_norm = 0.0463
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9555
	data_grads_norm = 2.5801
	new_data_grads_norm = 4.4549
	old_data_grads_norm = 2.7796
	sim_grads_norm = -0.0533
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0500
	data_grads_norm = 2.7788
	new_data_grads_norm = 4.0861
	old_data_grads_norm = 3.5157
	sim_grads_norm = -0.0647
-- Starting training on experience 131 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4607
	data_grads_norm = 4.0653
	new_data_grads_norm = 4.5301
	old_data_grads_norm = 5.3700
	sim_grads_norm = 0.0654
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9355
	data_grads_norm = 2.8555
	new_data_grads_norm = 4.0847
	old_data_grads_norm = 3.9607
	sim_grads_norm = 0.0725
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9738
	data_grads_norm = 3.2935
	new_data_grads_norm = 4.0752
	old_data_grads_norm = 3.8469
	sim_grads_norm = 0.1015
-- Starting training on experience 132 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0363
	data_grads_norm = 3.1173
	new_data_grads_norm = 4.6512
	old_data_grads_norm = 3.3589
	sim_grads_norm = 0.1691
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7835
	data_grads_norm = 2.7718
	new_data_grads_norm = 4.2712
	old_data_grads_norm = 2.9432
	sim_grads_norm = -0.0017
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9966
	data_grads_norm = 2.6022
	new_data_grads_norm = 4.3804
	old_data_grads_norm = 3.5457
	sim_grads_norm = -0.2283
-- Starting training on experience 133 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9334
	data_grads_norm = 3.0501
	new_data_grads_norm = 4.5566
	old_data_grads_norm = 3.7704
	sim_grads_norm = -0.0632
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4751
	data_grads_norm = 3.2590
	new_data_grads_norm = 5.3035
	old_data_grads_norm = 4.0570
	sim_grads_norm = 0.0410
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1066
	data_grads_norm = 2.8201
	new_data_grads_norm = 4.3249
	old_data_grads_norm = 3.2837
	sim_grads_norm = -0.0381
-- Starting training on experience 134 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0904
	data_grads_norm = 3.9007
	new_data_grads_norm = 4.6334
	old_data_grads_norm = 6.1689
	sim_grads_norm = 0.0454
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1845
	data_grads_norm = 4.0553
	new_data_grads_norm = 5.6659
	old_data_grads_norm = 4.8217
	sim_grads_norm = 0.2437
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9640
	data_grads_norm = 2.9913
	new_data_grads_norm = 4.3237
	old_data_grads_norm = 3.2652
	sim_grads_norm = 0.2125
-- Starting training on experience 135 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1308
	data_grads_norm = 2.7350
	new_data_grads_norm = 3.6958
	old_data_grads_norm = 3.7023
	sim_grads_norm = 0.0594
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2037
	data_grads_norm = 2.6233
	new_data_grads_norm = 3.6519
	old_data_grads_norm = 3.5442
	sim_grads_norm = -0.0738
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5501
	data_grads_norm = 2.1256
	new_data_grads_norm = 3.3192
	old_data_grads_norm = 2.7296
	sim_grads_norm = -0.0557
-- Starting training on experience 136 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4144
	data_grads_norm = 3.2648
	new_data_grads_norm = 4.4285
	old_data_grads_norm = 4.0768
	sim_grads_norm = 0.1339
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9142
	data_grads_norm = 2.3980
	new_data_grads_norm = 4.2102
	old_data_grads_norm = 3.3522
	sim_grads_norm = -0.0716
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9860
	data_grads_norm = 2.8801
	new_data_grads_norm = 4.1035
	old_data_grads_norm = 3.0425
	sim_grads_norm = 0.0930
-- Starting training on experience 137 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1165
	data_grads_norm = 2.9718
	new_data_grads_norm = 4.6405
	old_data_grads_norm = 4.1940
	sim_grads_norm = -0.0201
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0618
	data_grads_norm = 3.3400
	new_data_grads_norm = 4.8346
	old_data_grads_norm = 3.1605
	sim_grads_norm = 0.1451
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2478
	data_grads_norm = 3.5377
	new_data_grads_norm = 4.7972
	old_data_grads_norm = 4.1079
	sim_grads_norm = -0.0317
-- Starting training on experience 138 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8903
	data_grads_norm = 3.5891
	new_data_grads_norm = 5.0198
	old_data_grads_norm = 3.4068
	sim_grads_norm = 0.0864
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8648
	data_grads_norm = 3.0503
	new_data_grads_norm = 4.5638
	old_data_grads_norm = 4.4669
	sim_grads_norm = 0.0328
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8380
	data_grads_norm = 2.8785
	new_data_grads_norm = 4.4778
	old_data_grads_norm = 3.3820
	sim_grads_norm = -0.1717
-- Starting training on experience 139 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2836
	data_grads_norm = 2.8723
	new_data_grads_norm = 3.9937
	old_data_grads_norm = 3.5599
	sim_grads_norm = -0.0212
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9733
	data_grads_norm = 2.8351
	new_data_grads_norm = 4.6011
	old_data_grads_norm = 3.9832
	sim_grads_norm = -0.0451
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1597
	data_grads_norm = 2.5775
	new_data_grads_norm = 4.1310
	old_data_grads_norm = 3.3744
	sim_grads_norm = -0.0767
-- Starting training on experience 140 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1804
	data_grads_norm = 2.8211
	new_data_grads_norm = 4.4803
	old_data_grads_norm = 3.5540
	sim_grads_norm = 0.0166
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4939
	data_grads_norm = 3.1171
	new_data_grads_norm = 4.3517
	old_data_grads_norm = 4.1149
	sim_grads_norm = 0.0666
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5514
	data_grads_norm = 3.0441
	new_data_grads_norm = 4.3040
	old_data_grads_norm = 4.2684
	sim_grads_norm = -0.0253
-- Starting training on experience 141 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8713
	data_grads_norm = 2.3711
	new_data_grads_norm = 3.7846
	old_data_grads_norm = 3.0465
	sim_grads_norm = 0.1166
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8095
	data_grads_norm = 2.6831
	new_data_grads_norm = 4.2622
	old_data_grads_norm = 2.8578
	sim_grads_norm = 0.1057
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8582
	data_grads_norm = 2.6846
	new_data_grads_norm = 4.1157
	old_data_grads_norm = 3.0721
	sim_grads_norm = 0.0360
-- Starting training on experience 142 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1722
	data_grads_norm = 2.8812
	new_data_grads_norm = 4.1746
	old_data_grads_norm = 3.6439
	sim_grads_norm = 0.0690
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6265
	data_grads_norm = 3.0810
	new_data_grads_norm = 4.1750
	old_data_grads_norm = 4.2070
	sim_grads_norm = 0.1735
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4027
	data_grads_norm = 2.9149
	new_data_grads_norm = 3.9070
	old_data_grads_norm = 4.0598
	sim_grads_norm = -0.0396
-- Starting training on experience 143 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0238
	data_grads_norm = 2.5431
	new_data_grads_norm = 3.3712
	old_data_grads_norm = 3.8050
	sim_grads_norm = -0.0762
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7940
	data_grads_norm = 2.1012
	new_data_grads_norm = 3.1684
	old_data_grads_norm = 2.9758
	sim_grads_norm = -0.0805
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0842
	data_grads_norm = 2.5997
	new_data_grads_norm = 3.7483
	old_data_grads_norm = 3.4167
	sim_grads_norm = 0.1056
-- Starting training on experience 144 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2884
	data_grads_norm = 3.1573
	new_data_grads_norm = 4.6431
	old_data_grads_norm = 3.5013
	sim_grads_norm = 0.0119
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2014
	data_grads_norm = 3.6615
	new_data_grads_norm = 4.7279
	old_data_grads_norm = 4.3959
	sim_grads_norm = 0.1649
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2139
	data_grads_norm = 3.0819
	new_data_grads_norm = 4.4508
	old_data_grads_norm = 3.0908
	sim_grads_norm = 0.1375
-- Starting training on experience 145 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0027
	data_grads_norm = 2.2921
	new_data_grads_norm = 3.5838
	old_data_grads_norm = 2.9685
	sim_grads_norm = 0.0785
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4069
	data_grads_norm = 2.4982
	new_data_grads_norm = 3.0292
	old_data_grads_norm = 3.5860
	sim_grads_norm = -0.0232
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7528
	data_grads_norm = 2.2728
	new_data_grads_norm = 3.0400
	old_data_grads_norm = 3.2095
	sim_grads_norm = 0.1194
-- Starting training on experience 146 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5391
	data_grads_norm = 2.9736
	new_data_grads_norm = 4.5434
	old_data_grads_norm = 3.7971
	sim_grads_norm = 0.1079
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1021
	data_grads_norm = 3.1093
	new_data_grads_norm = 4.0890
	old_data_grads_norm = 4.2585
	sim_grads_norm = 0.1156
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7826
	data_grads_norm = 2.9019
	new_data_grads_norm = 4.3634
	old_data_grads_norm = 3.1885
	sim_grads_norm = -0.0931
-- Starting training on experience 147 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5982
	data_grads_norm = 2.6438
	new_data_grads_norm = 4.1050
	old_data_grads_norm = 3.0871
	sim_grads_norm = 0.0406
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7360
	data_grads_norm = 2.8162
	new_data_grads_norm = 4.1603
	old_data_grads_norm = 3.3587
	sim_grads_norm = 0.1332
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6001
	data_grads_norm = 2.2561
	new_data_grads_norm = 3.5017
	old_data_grads_norm = 2.9473
	sim_grads_norm = -0.0986
-- Starting training on experience 148 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2581
	data_grads_norm = 2.8073
	new_data_grads_norm = 3.7165
	old_data_grads_norm = 3.7372
	sim_grads_norm = 0.1542
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7023
	data_grads_norm = 2.2800
	new_data_grads_norm = 3.7110
	old_data_grads_norm = 2.8490
	sim_grads_norm = -0.0112
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1033
	data_grads_norm = 2.8983
	new_data_grads_norm = 4.0181
	old_data_grads_norm = 4.5894
	sim_grads_norm = 0.0167
-- Starting training on experience 149 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8979
	data_grads_norm = 2.5184
	new_data_grads_norm = 3.6469
	old_data_grads_norm = 3.2601
	sim_grads_norm = 0.0289
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6324
	data_grads_norm = 2.8249
	new_data_grads_norm = 3.4033
	old_data_grads_norm = 4.2919
	sim_grads_norm = 0.0284
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6637
	data_grads_norm = 2.4125
	new_data_grads_norm = 3.4979
	old_data_grads_norm = 3.4063
	sim_grads_norm = 0.0999
-- Starting training on experience 150 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8831
	data_grads_norm = 2.7924
	new_data_grads_norm = 3.7821
	old_data_grads_norm = 4.4470
	sim_grads_norm = -0.0709
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2456
	data_grads_norm = 2.8466
	new_data_grads_norm = 4.1760
	old_data_grads_norm = 4.1407
	sim_grads_norm = -0.0129
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3509
	data_grads_norm = 3.2226
	new_data_grads_norm = 4.1621
	old_data_grads_norm = 3.4064
	sim_grads_norm = 0.3939
-- Starting training on experience 151 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0125
	data_grads_norm = 2.4550
	new_data_grads_norm = 3.2504
	old_data_grads_norm = 3.7477
	sim_grads_norm = 0.0628
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0140
	data_grads_norm = 2.5178
	new_data_grads_norm = 2.7422
	old_data_grads_norm = 3.8137
	sim_grads_norm = -0.0117
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0890
	data_grads_norm = 2.5124
	new_data_grads_norm = 2.9314
	old_data_grads_norm = 3.8802
	sim_grads_norm = -0.0755
-- Starting training on experience 152 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6299
	data_grads_norm = 1.9021
	new_data_grads_norm = 3.3885
	old_data_grads_norm = 2.6975
	sim_grads_norm = -0.0058
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9150
	data_grads_norm = 2.4083
	new_data_grads_norm = 4.0037
	old_data_grads_norm = 2.9224
	sim_grads_norm = 0.0436
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1159
	data_grads_norm = 2.4428
	new_data_grads_norm = 3.5479
	old_data_grads_norm = 3.0432
	sim_grads_norm = 0.1751
-- Starting training on experience 153 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9246
	data_grads_norm = 3.5271
	new_data_grads_norm = 4.5949
	old_data_grads_norm = 5.2309
	sim_grads_norm = -0.0283
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0011
	data_grads_norm = 3.5879
	new_data_grads_norm = 4.2780
	old_data_grads_norm = 5.0333
	sim_grads_norm = 0.1432
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8847
	data_grads_norm = 2.3692
	new_data_grads_norm = 4.0308
	old_data_grads_norm = 2.7396
	sim_grads_norm = -0.0626
-- Starting training on experience 154 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9645
	data_grads_norm = 2.5997
	new_data_grads_norm = 3.5725
	old_data_grads_norm = 4.0294
	sim_grads_norm = -0.0352
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0640
	data_grads_norm = 2.7752
	new_data_grads_norm = 3.7181
	old_data_grads_norm = 3.9362
	sim_grads_norm = 0.0541
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2235
	data_grads_norm = 3.1483
	new_data_grads_norm = 3.5066
	old_data_grads_norm = 4.5604
	sim_grads_norm = -0.0294
-- Starting training on experience 155 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4474
	data_grads_norm = 2.8672
	new_data_grads_norm = 3.4653
	old_data_grads_norm = 4.5461
	sim_grads_norm = -0.0335
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8859
	data_grads_norm = 2.7107
	new_data_grads_norm = 3.6495
	old_data_grads_norm = 3.6645
	sim_grads_norm = 0.1265
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7294
	data_grads_norm = 2.6883
	new_data_grads_norm = 3.8709
	old_data_grads_norm = 4.3818
	sim_grads_norm = -0.0791
-- Starting training on experience 156 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1216
	data_grads_norm = 3.3003
	new_data_grads_norm = 4.4625
	old_data_grads_norm = 5.4711
	sim_grads_norm = 0.0889
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9108
	data_grads_norm = 2.9083
	new_data_grads_norm = 4.5324
	old_data_grads_norm = 3.6747
	sim_grads_norm = -0.0820
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6889
	data_grads_norm = 3.3291
	new_data_grads_norm = 5.3983
	old_data_grads_norm = 3.0291
	sim_grads_norm = 0.1230
-- Starting training on experience 157 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6704
	data_grads_norm = 2.6062
	new_data_grads_norm = 3.9601
	old_data_grads_norm = 3.6286
	sim_grads_norm = 0.0795
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7814
	data_grads_norm = 2.2243
	new_data_grads_norm = 3.3750
	old_data_grads_norm = 3.2650
	sim_grads_norm = -0.1248
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9719
	data_grads_norm = 2.9544
	new_data_grads_norm = 4.1267
	old_data_grads_norm = 3.4992
	sim_grads_norm = 0.0562
-- Starting training on experience 158 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5680
	data_grads_norm = 3.1047
	new_data_grads_norm = 3.9116
	old_data_grads_norm = 3.9990
	sim_grads_norm = 0.0510
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3662
	data_grads_norm = 3.1753
	new_data_grads_norm = 3.5904
	old_data_grads_norm = 4.4486
	sim_grads_norm = 0.1881
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1280
	data_grads_norm = 2.6220
	new_data_grads_norm = 3.3795
	old_data_grads_norm = 4.2109
	sim_grads_norm = -0.0606
-- Starting training on experience 159 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9337
	data_grads_norm = 2.5869
	new_data_grads_norm = 3.4422
	old_data_grads_norm = 3.9019
	sim_grads_norm = -0.0013
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0775
	data_grads_norm = 2.6792
	new_data_grads_norm = 3.4731
	old_data_grads_norm = 3.7999
	sim_grads_norm = 0.0052
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1695
	data_grads_norm = 2.5971
	new_data_grads_norm = 3.4549
	old_data_grads_norm = 3.4502
	sim_grads_norm = 0.0740
-- Starting training on experience 160 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0304
	data_grads_norm = 2.5212
	new_data_grads_norm = 3.8989
	old_data_grads_norm = 3.2346
	sim_grads_norm = -0.0575
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0491
	data_grads_norm = 2.5895
	new_data_grads_norm = 3.8583
	old_data_grads_norm = 3.7844
	sim_grads_norm = 0.0051
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8542
	data_grads_norm = 2.7769
	new_data_grads_norm = 4.0244
	old_data_grads_norm = 2.9264
	sim_grads_norm = 0.0844
-- Starting training on experience 161 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9167
	data_grads_norm = 2.3540
	new_data_grads_norm = 3.7183
	old_data_grads_norm = 2.3503
	sim_grads_norm = 0.1522
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8062
	data_grads_norm = 2.3941
	new_data_grads_norm = 3.9693
	old_data_grads_norm = 2.7742
	sim_grads_norm = -0.0252
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2022
	data_grads_norm = 2.7119
	new_data_grads_norm = 4.1456
	old_data_grads_norm = 3.4184
	sim_grads_norm = 0.0455
-- Starting training on experience 162 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6711
	data_grads_norm = 2.8068
	new_data_grads_norm = 3.6586
	old_data_grads_norm = 4.0496
	sim_grads_norm = 0.0698
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6070
	data_grads_norm = 2.4270
	new_data_grads_norm = 3.6485
	old_data_grads_norm = 3.1763
	sim_grads_norm = 0.0054
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8614
	data_grads_norm = 2.7846
	new_data_grads_norm = 3.7937
	old_data_grads_norm = 4.2984
	sim_grads_norm = -0.1310
-- Starting training on experience 163 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0117
	data_grads_norm = 2.6127
	new_data_grads_norm = 3.8748
	old_data_grads_norm = 3.4006
	sim_grads_norm = -0.0423
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0411
	data_grads_norm = 2.7713
	new_data_grads_norm = 3.6195
	old_data_grads_norm = 3.8982
	sim_grads_norm = 0.0410
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7860
	data_grads_norm = 2.5257
	new_data_grads_norm = 3.5023
	old_data_grads_norm = 3.3130
	sim_grads_norm = -0.0119
-- Starting training on experience 164 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0700
	data_grads_norm = 2.6953
	new_data_grads_norm = 3.7725
	old_data_grads_norm = 4.1830
	sim_grads_norm = -0.0290
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3246
	data_grads_norm = 2.7440
	new_data_grads_norm = 3.8510
	old_data_grads_norm = 3.9972
	sim_grads_norm = -0.0514
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9931
	data_grads_norm = 2.5907
	new_data_grads_norm = 3.8177
	old_data_grads_norm = 3.4081
	sim_grads_norm = 0.0334
-- Starting training on experience 165 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7849
	data_grads_norm = 2.3371
	new_data_grads_norm = 3.3334
	old_data_grads_norm = 3.1729
	sim_grads_norm = 0.0192
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9070
	data_grads_norm = 2.5176
	new_data_grads_norm = 3.5535
	old_data_grads_norm = 3.2793
	sim_grads_norm = 0.1023
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9423
	data_grads_norm = 2.2502
	new_data_grads_norm = 3.2891
	old_data_grads_norm = 3.1444
	sim_grads_norm = -0.0366
-- Starting training on experience 166 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8405
	data_grads_norm = 2.7087
	new_data_grads_norm = 4.4760
	old_data_grads_norm = 2.7368
	sim_grads_norm = 0.0037
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9460
	data_grads_norm = 2.6750
	new_data_grads_norm = 4.6443
	old_data_grads_norm = 3.0409
	sim_grads_norm = -0.1189
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9406
	data_grads_norm = 2.9659
	new_data_grads_norm = 4.5212
	old_data_grads_norm = 3.4370
	sim_grads_norm = 0.0542
-- Starting training on experience 167 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0036
	data_grads_norm = 3.2812
	new_data_grads_norm = 4.9114
	old_data_grads_norm = 2.8736
	sim_grads_norm = 0.1930
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0326
	data_grads_norm = 2.8836
	new_data_grads_norm = 3.9696
	old_data_grads_norm = 3.8301
	sim_grads_norm = 0.1381
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8169
	data_grads_norm = 2.8589
	new_data_grads_norm = 4.2258
	old_data_grads_norm = 4.0148
	sim_grads_norm = 0.0078
-- Starting training on experience 168 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3187
	data_grads_norm = 3.1102
	new_data_grads_norm = 4.3855
	old_data_grads_norm = 3.5825
	sim_grads_norm = 0.1251
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0407
	data_grads_norm = 3.4837
	new_data_grads_norm = 4.1847
	old_data_grads_norm = 4.9513
	sim_grads_norm = -0.0300
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2778
	data_grads_norm = 3.1317
	new_data_grads_norm = 5.1088
	old_data_grads_norm = 3.0557
	sim_grads_norm = 0.1055
-- Starting training on experience 169 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0273
	data_grads_norm = 2.7729
	new_data_grads_norm = 4.0430
	old_data_grads_norm = 3.1595
	sim_grads_norm = 0.2905
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7488
	data_grads_norm = 2.3701
	new_data_grads_norm = 3.5177
	old_data_grads_norm = 3.9881
	sim_grads_norm = -0.0632
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9921
	data_grads_norm = 3.5775
	new_data_grads_norm = 3.7601
	old_data_grads_norm = 5.0342
	sim_grads_norm = 0.0102
-- Starting training on experience 170 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0103
	data_grads_norm = 2.5535
	new_data_grads_norm = 3.7816
	old_data_grads_norm = 3.0504
	sim_grads_norm = 0.0042
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9602
	data_grads_norm = 2.5239
	new_data_grads_norm = 4.3848
	old_data_grads_norm = 3.2152
	sim_grads_norm = 0.0316
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8624
	data_grads_norm = 2.7561
	new_data_grads_norm = 3.9847
	old_data_grads_norm = 3.6892
	sim_grads_norm = -0.0262
-- Starting training on experience 171 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8259
	data_grads_norm = 2.8647
	new_data_grads_norm = 4.1824
	old_data_grads_norm = 3.3176
	sim_grads_norm = -0.0452
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6227
	data_grads_norm = 2.7389
	new_data_grads_norm = 4.1525
	old_data_grads_norm = 3.8661
	sim_grads_norm = -0.0406
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6727
	data_grads_norm = 2.5058
	new_data_grads_norm = 3.9383
	old_data_grads_norm = 3.0893
	sim_grads_norm = 0.0674
-- Starting training on experience 172 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0819
	data_grads_norm = 2.9050
	new_data_grads_norm = 4.2024
	old_data_grads_norm = 3.5603
	sim_grads_norm = 0.0627
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9545
	data_grads_norm = 2.8122
	new_data_grads_norm = 4.3700
	old_data_grads_norm = 3.1721
	sim_grads_norm = -0.0293
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5132
	data_grads_norm = 2.8566
	new_data_grads_norm = 4.5322
	old_data_grads_norm = 2.6126
	sim_grads_norm = 0.1427
-- Starting training on experience 173 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9535
	data_grads_norm = 3.3005
	new_data_grads_norm = 5.3757
	old_data_grads_norm = 3.6146
	sim_grads_norm = 0.0722
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8179
	data_grads_norm = 3.2134
	new_data_grads_norm = 5.1799
	old_data_grads_norm = 3.6398
	sim_grads_norm = -0.0657
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7100
	data_grads_norm = 3.1627
	new_data_grads_norm = 4.9034
	old_data_grads_norm = 3.4830
	sim_grads_norm = 0.0490
-- Starting training on experience 174 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4145
	data_grads_norm = 2.9086
	new_data_grads_norm = 3.8990
	old_data_grads_norm = 4.3356
	sim_grads_norm = 0.0504
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3443
	data_grads_norm = 3.1161
	new_data_grads_norm = 3.6510
	old_data_grads_norm = 4.8750
	sim_grads_norm = -0.0530
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2301
	data_grads_norm = 2.9908
	new_data_grads_norm = 3.5082
	old_data_grads_norm = 3.8611
	sim_grads_norm = 0.0045
-- Starting training on experience 175 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9248
	data_grads_norm = 3.4006
	new_data_grads_norm = 5.0235
	old_data_grads_norm = 3.2501
	sim_grads_norm = -0.0063
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0917
	data_grads_norm = 3.7887
	new_data_grads_norm = 4.6493
	old_data_grads_norm = 4.5885
	sim_grads_norm = 0.1323
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2776
	data_grads_norm = 3.2187
	new_data_grads_norm = 4.1751
	old_data_grads_norm = 4.1296
	sim_grads_norm = 0.1387
-- Starting training on experience 176 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1128
	data_grads_norm = 2.5504
	new_data_grads_norm = 4.0511
	old_data_grads_norm = 3.3445
	sim_grads_norm = -0.0603
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0632
	data_grads_norm = 2.6186
	new_data_grads_norm = 3.6001
	old_data_grads_norm = 3.4689
	sim_grads_norm = 0.0638
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0563
	data_grads_norm = 2.4633
	new_data_grads_norm = 3.7639
	old_data_grads_norm = 2.6680
	sim_grads_norm = 0.0538
-- Starting training on experience 177 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0598
	data_grads_norm = 2.3455
	new_data_grads_norm = 3.2503
	old_data_grads_norm = 3.2230
	sim_grads_norm = 0.0370
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7523
	data_grads_norm = 2.6186
	new_data_grads_norm = 3.5766
	old_data_grads_norm = 2.9383
	sim_grads_norm = 0.2034
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6465
	data_grads_norm = 2.3337
	new_data_grads_norm = 3.3129
	old_data_grads_norm = 3.5125
	sim_grads_norm = -0.1306
-- Starting training on experience 178 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7234
	data_grads_norm = 2.4460
	new_data_grads_norm = 3.6631
	old_data_grads_norm = 2.7071
	sim_grads_norm = -0.0593
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1849
	data_grads_norm = 2.7944
	new_data_grads_norm = 3.9095
	old_data_grads_norm = 3.7742
	sim_grads_norm = -0.0069
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6462
	data_grads_norm = 2.4915
	new_data_grads_norm = 3.4965
	old_data_grads_norm = 2.9382
	sim_grads_norm = 0.0430
-- Starting training on experience 179 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9318
	data_grads_norm = 2.3902
	new_data_grads_norm = 3.1464
	old_data_grads_norm = 3.8316
	sim_grads_norm = 0.0070
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7930
	data_grads_norm = 2.4131
	new_data_grads_norm = 3.1790
	old_data_grads_norm = 3.5052
	sim_grads_norm = 0.0411
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9091
	data_grads_norm = 2.3373
	new_data_grads_norm = 3.0518
	old_data_grads_norm = 3.2678
	sim_grads_norm = 0.0538
-- Starting training on experience 180 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0177
	data_grads_norm = 2.6335
	new_data_grads_norm = 3.3509
	old_data_grads_norm = 3.3438
	sim_grads_norm = 0.2136
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6815
	data_grads_norm = 2.2013
	new_data_grads_norm = 3.2801
	old_data_grads_norm = 3.3558
	sim_grads_norm = -0.0557
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9197
	data_grads_norm = 2.2421
	new_data_grads_norm = 3.1525
	old_data_grads_norm = 3.6128
	sim_grads_norm = -0.0732
-- Starting training on experience 181 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1950
	data_grads_norm = 2.2499
	new_data_grads_norm = 3.4596
	old_data_grads_norm = 3.6140
	sim_grads_norm = -0.0983
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8502
	data_grads_norm = 3.0313
	new_data_grads_norm = 3.9184
	old_data_grads_norm = 4.6249
	sim_grads_norm = 0.0335
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0164
	data_grads_norm = 3.2804
	new_data_grads_norm = 5.0099
	old_data_grads_norm = 4.2853
	sim_grads_norm = 0.1046
-- Starting training on experience 182 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9806
	data_grads_norm = 3.1647
	new_data_grads_norm = 4.5931
	old_data_grads_norm = 4.4897
	sim_grads_norm = 0.0642
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0510
	data_grads_norm = 3.1724
	new_data_grads_norm = 5.2863
	old_data_grads_norm = 3.0700
	sim_grads_norm = 0.0795
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7210
	data_grads_norm = 2.7803
	new_data_grads_norm = 4.6642
	old_data_grads_norm = 3.6189
	sim_grads_norm = -0.1537
-- Starting training on experience 183 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4734
	data_grads_norm = 4.2601
	new_data_grads_norm = 6.1272
	old_data_grads_norm = 4.7521
	sim_grads_norm = 0.2078
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3426
	data_grads_norm = 3.6129
	new_data_grads_norm = 5.9660
	old_data_grads_norm = 4.4701
	sim_grads_norm = -0.0766
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5645
	data_grads_norm = 3.8018
	new_data_grads_norm = 6.0706
	old_data_grads_norm = 3.4355
	sim_grads_norm = 0.1053
-- Starting training on experience 184 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0520
	data_grads_norm = 2.9354
	new_data_grads_norm = 3.5600
	old_data_grads_norm = 3.8340
	sim_grads_norm = 0.1619
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4702
	data_grads_norm = 2.3836
	new_data_grads_norm = 3.6223
	old_data_grads_norm = 3.5496
	sim_grads_norm = -0.0657
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6676
	data_grads_norm = 2.8380
	new_data_grads_norm = 4.1846
	old_data_grads_norm = 3.8746
	sim_grads_norm = 0.0490
-- Starting training on experience 185 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9974
	data_grads_norm = 2.9298
	new_data_grads_norm = 4.2265
	old_data_grads_norm = 3.2743
	sim_grads_norm = 0.0609
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5226
	data_grads_norm = 3.4833
	new_data_grads_norm = 4.1385
	old_data_grads_norm = 4.9088
	sim_grads_norm = 0.0855
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1251
	data_grads_norm = 3.0075
	new_data_grads_norm = 4.3005
	old_data_grads_norm = 3.9805
	sim_grads_norm = 0.0141
-- Starting training on experience 186 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9298
	data_grads_norm = 3.2489
	new_data_grads_norm = 5.1939
	old_data_grads_norm = 4.0986
	sim_grads_norm = 0.0105
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8200
	data_grads_norm = 3.0632
	new_data_grads_norm = 4.2326
	old_data_grads_norm = 4.3851
	sim_grads_norm = -0.0076
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7524
	data_grads_norm = 3.5406
	new_data_grads_norm = 5.2668
	old_data_grads_norm = 3.5468
	sim_grads_norm = 0.0404
-- Starting training on experience 187 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6822
	data_grads_norm = 2.8460
	new_data_grads_norm = 4.5981
	old_data_grads_norm = 2.8593
	sim_grads_norm = 0.0006
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7765
	data_grads_norm = 2.6390
	new_data_grads_norm = 4.3705
	old_data_grads_norm = 3.4285
	sim_grads_norm = -0.1002
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1957
	data_grads_norm = 3.5970
	new_data_grads_norm = 5.4706
	old_data_grads_norm = 4.3156
	sim_grads_norm = 0.1584
-- Starting training on experience 188 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2905
	data_grads_norm = 3.7026
	new_data_grads_norm = 5.5864
	old_data_grads_norm = 3.9550
	sim_grads_norm = 0.1036
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8808
	data_grads_norm = 3.1629
	new_data_grads_norm = 6.1425
	old_data_grads_norm = 3.7635
	sim_grads_norm = -0.0413
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4788
	data_grads_norm = 4.2481
	new_data_grads_norm = 6.1141
	old_data_grads_norm = 5.2642
	sim_grads_norm = 0.0834
-- Starting training on experience 189 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0490
	data_grads_norm = 3.2507
	new_data_grads_norm = 4.5422
	old_data_grads_norm = 3.5540
	sim_grads_norm = 0.2191
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4130
	data_grads_norm = 2.4433
	new_data_grads_norm = 4.5568
	old_data_grads_norm = 3.2565
	sim_grads_norm = -0.1765
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0839
	data_grads_norm = 3.3716
	new_data_grads_norm = 4.9077
	old_data_grads_norm = 3.6557
	sim_grads_norm = 0.0317
-- Starting training on experience 190 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4807
	data_grads_norm = 2.5071
	new_data_grads_norm = 4.1523
	old_data_grads_norm = 2.9931
	sim_grads_norm = 0.0258
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7104
	data_grads_norm = 2.7470
	new_data_grads_norm = 4.1330
	old_data_grads_norm = 3.2166
	sim_grads_norm = 0.1080
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9115
	data_grads_norm = 3.3365
	new_data_grads_norm = 3.9781
	old_data_grads_norm = 5.2168
	sim_grads_norm = 0.0033
-- Starting training on experience 191 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5744
	data_grads_norm = 2.6492
	new_data_grads_norm = 5.0093
	old_data_grads_norm = 2.8738
	sim_grads_norm = -0.0386
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5147
	data_grads_norm = 3.3600
	new_data_grads_norm = 4.3224
	old_data_grads_norm = 5.0517
	sim_grads_norm = 0.0593
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4225
	data_grads_norm = 3.3355
	new_data_grads_norm = 4.1272
	old_data_grads_norm = 5.1538
	sim_grads_norm = -0.0033
-- Starting training on experience 192 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4987
	data_grads_norm = 3.0986
	new_data_grads_norm = 5.1149
	old_data_grads_norm = 3.3667
	sim_grads_norm = -0.0705
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0147
	data_grads_norm = 3.3101
	new_data_grads_norm = 5.1029
	old_data_grads_norm = 3.4492
	sim_grads_norm = 0.0398
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3549
	data_grads_norm = 3.8126
	new_data_grads_norm = 4.4691
	old_data_grads_norm = 5.0496
	sim_grads_norm = 0.2570
-- Starting training on experience 193 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7893
	data_grads_norm = 2.7408
	new_data_grads_norm = 4.1609
	old_data_grads_norm = 2.9939
	sim_grads_norm = 0.1239
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9746
	data_grads_norm = 2.6861
	new_data_grads_norm = 3.8459
	old_data_grads_norm = 4.2872
	sim_grads_norm = -0.0523
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0354
	data_grads_norm = 2.5253
	new_data_grads_norm = 3.4845
	old_data_grads_norm = 3.3225
	sim_grads_norm = 0.0963
-- Starting training on experience 194 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0011
	data_grads_norm = 2.6155
	new_data_grads_norm = 3.6753
	old_data_grads_norm = 3.3116
	sim_grads_norm = 0.1163
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7829
	data_grads_norm = 2.5354
	new_data_grads_norm = 3.9391
	old_data_grads_norm = 3.4243
	sim_grads_norm = -0.0201
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3398
	data_grads_norm = 3.2923
	new_data_grads_norm = 3.8025
	old_data_grads_norm = 3.6941
	sim_grads_norm = 0.3722
-- Starting training on experience 195 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6516
	data_grads_norm = 2.4260
	new_data_grads_norm = 4.0771
	old_data_grads_norm = 3.3961
	sim_grads_norm = -0.0693
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7169
	data_grads_norm = 2.6282
	new_data_grads_norm = 4.4357
	old_data_grads_norm = 3.6251
	sim_grads_norm = -0.0751
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9045
	data_grads_norm = 2.8783
	new_data_grads_norm = 4.9782
	old_data_grads_norm = 3.7188
	sim_grads_norm = 0.0212
-- Starting training on experience 196 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0384
	data_grads_norm = 2.8751
	new_data_grads_norm = 3.7143
	old_data_grads_norm = 4.3419
	sim_grads_norm = 0.0817
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7482
	data_grads_norm = 2.5618
	new_data_grads_norm = 3.3795
	old_data_grads_norm = 3.8247
	sim_grads_norm = 0.0120
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7066
	data_grads_norm = 2.7627
	new_data_grads_norm = 2.9691
	old_data_grads_norm = 4.3215
	sim_grads_norm = -0.0325
-- Starting training on experience 197 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9599
	data_grads_norm = 2.9584
	new_data_grads_norm = 3.6915
	old_data_grads_norm = 4.0212
	sim_grads_norm = 0.0171
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7074
	data_grads_norm = 2.4770
	new_data_grads_norm = 3.6002
	old_data_grads_norm = 3.3616
	sim_grads_norm = 0.0102
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0357
	data_grads_norm = 3.2920
	new_data_grads_norm = 3.9765
	old_data_grads_norm = 4.4828
	sim_grads_norm = 0.0729
-- Starting training on experience 198 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1922
	data_grads_norm = 3.1262
	new_data_grads_norm = 4.4349
	old_data_grads_norm = 4.3186
	sim_grads_norm = 0.0217
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7126
	data_grads_norm = 2.5854
	new_data_grads_norm = 4.1537
	old_data_grads_norm = 3.5803
	sim_grads_norm = -0.0284
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8273
	data_grads_norm = 2.9262
	new_data_grads_norm = 4.3831
	old_data_grads_norm = 3.3443
	sim_grads_norm = 0.1522
-- Starting training on experience 199 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9279
	data_grads_norm = 2.6978
	new_data_grads_norm = 4.1744
	old_data_grads_norm = 3.0039
	sim_grads_norm = -0.0165
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9113
	data_grads_norm = 2.9514
	new_data_grads_norm = 4.0987
	old_data_grads_norm = 3.5004
	sim_grads_norm = 0.1398
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8162
	data_grads_norm = 2.6874
	new_data_grads_norm = 3.8479
	old_data_grads_norm = 4.3499
	sim_grads_norm = 0.0097
-- Starting training on experience 200 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1123
	data_grads_norm = 3.1245
	new_data_grads_norm = 4.4209
	old_data_grads_norm = 3.7831
	sim_grads_norm = 0.0596
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8717
	data_grads_norm = 3.4928
	new_data_grads_norm = 6.0730
	old_data_grads_norm = 3.9904
	sim_grads_norm = 0.1049
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0839
	data_grads_norm = 3.5879
	new_data_grads_norm = 5.1926
	old_data_grads_norm = 4.7908
	sim_grads_norm = -0.0333
-- Starting training on experience 201 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6089
	data_grads_norm = 2.6502
	new_data_grads_norm = 4.3554
	old_data_grads_norm = 3.6970
	sim_grads_norm = -0.0132
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1515
	data_grads_norm = 3.5423
	new_data_grads_norm = 4.1907
	old_data_grads_norm = 4.5812
	sim_grads_norm = 0.1972
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7724
	data_grads_norm = 2.7861
	new_data_grads_norm = 3.4207
	old_data_grads_norm = 4.0452
	sim_grads_norm = 0.0199
-- Starting training on experience 202 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9080
	data_grads_norm = 3.4457
	new_data_grads_norm = 4.6838
	old_data_grads_norm = 3.9489
	sim_grads_norm = 0.0987
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6647
	data_grads_norm = 2.8183
	new_data_grads_norm = 4.4991
	old_data_grads_norm = 3.6308
	sim_grads_norm = -0.0506
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9516
	data_grads_norm = 3.4335
	new_data_grads_norm = 4.6590
	old_data_grads_norm = 3.7402
	sim_grads_norm = 0.1277
-- Starting training on experience 203 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7930
	data_grads_norm = 3.4156
	new_data_grads_norm = 4.3527
	old_data_grads_norm = 4.3223
	sim_grads_norm = -0.0358
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4038
	data_grads_norm = 3.1614
	new_data_grads_norm = 4.4690
	old_data_grads_norm = 3.7603
	sim_grads_norm = -0.0906
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0748
	data_grads_norm = 3.2185
	new_data_grads_norm = 4.7113
	old_data_grads_norm = 3.3108
	sim_grads_norm = 0.1496
-- Starting training on experience 204 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1265
	data_grads_norm = 2.7445
	new_data_grads_norm = 4.1669
	old_data_grads_norm = 3.2575
	sim_grads_norm = -0.0330
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2059
	data_grads_norm = 3.0692
	new_data_grads_norm = 4.2318
	old_data_grads_norm = 4.3634
	sim_grads_norm = -0.0108
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0739
	data_grads_norm = 3.2477
	new_data_grads_norm = 4.6884
	old_data_grads_norm = 3.5662
	sim_grads_norm = 0.0766
-- Starting training on experience 205 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5774
	data_grads_norm = 2.4302
	new_data_grads_norm = 3.9738
	old_data_grads_norm = 2.7388
	sim_grads_norm = 0.0718
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8773
	data_grads_norm = 2.9870
	new_data_grads_norm = 3.9565
	old_data_grads_norm = 3.9739
	sim_grads_norm = 0.0673
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5279
	data_grads_norm = 2.7757
	new_data_grads_norm = 4.4068
	old_data_grads_norm = 3.7869
	sim_grads_norm = -0.0387
-- Starting training on experience 206 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6599
	data_grads_norm = 2.9006
	new_data_grads_norm = 3.6656
	old_data_grads_norm = 4.9685
	sim_grads_norm = 0.0601
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8828
	data_grads_norm = 3.0204
	new_data_grads_norm = 3.7054
	old_data_grads_norm = 4.2892
	sim_grads_norm = -0.0095
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7309
	data_grads_norm = 2.7521
	new_data_grads_norm = 3.4669
	old_data_grads_norm = 3.5279
	sim_grads_norm = 0.0978
-- Starting training on experience 207 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8868
	data_grads_norm = 2.7919
	new_data_grads_norm = 3.8063
	old_data_grads_norm = 4.0866
	sim_grads_norm = -0.0640
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8534
	data_grads_norm = 2.9589
	new_data_grads_norm = 4.5125
	old_data_grads_norm = 3.5940
	sim_grads_norm = 0.0420
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8762
	data_grads_norm = 3.0987
	new_data_grads_norm = 4.4384
	old_data_grads_norm = 4.1794
	sim_grads_norm = 0.0454
-- Starting training on experience 208 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4945
	data_grads_norm = 4.0748
	new_data_grads_norm = 5.5430
	old_data_grads_norm = 4.2551
	sim_grads_norm = 0.0930
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9121
	data_grads_norm = 4.4970
	new_data_grads_norm = 5.3747
	old_data_grads_norm = 5.2337
	sim_grads_norm = 0.2529
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2303
	data_grads_norm = 3.5614
	new_data_grads_norm = 4.1244
	old_data_grads_norm = 5.4400
	sim_grads_norm = -0.0104
-- Starting training on experience 209 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2764
	data_grads_norm = 3.2721
	new_data_grads_norm = 4.1455
	old_data_grads_norm = 4.1346
	sim_grads_norm = 0.0470
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8718
	data_grads_norm = 2.6340
	new_data_grads_norm = 3.6676
	old_data_grads_norm = 3.6407
	sim_grads_norm = 0.0073
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8040
	data_grads_norm = 2.8628
	new_data_grads_norm = 3.7076
	old_data_grads_norm = 4.2048
	sim_grads_norm = -0.0146
-- Starting training on experience 210 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6008
	data_grads_norm = 2.2801
	new_data_grads_norm = 3.5560
	old_data_grads_norm = 3.0803
	sim_grads_norm = 0.0020
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8703
	data_grads_norm = 3.0764
	new_data_grads_norm = 3.5175
	old_data_grads_norm = 4.4023
	sim_grads_norm = 0.0641
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5141
	data_grads_norm = 2.3084
	new_data_grads_norm = 3.3943
	old_data_grads_norm = 2.9554
	sim_grads_norm = 0.1584
-- Starting training on experience 211 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9005
	data_grads_norm = 3.5826
	new_data_grads_norm = 5.9801
	old_data_grads_norm = 3.5762
	sim_grads_norm = 0.1162
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0219
	data_grads_norm = 3.0749
	new_data_grads_norm = 4.9998
	old_data_grads_norm = 2.7590
	sim_grads_norm = 0.0558
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7615
	data_grads_norm = 3.0578
	new_data_grads_norm = 5.4952
	old_data_grads_norm = 3.4618
	sim_grads_norm = -0.0052
-- Starting training on experience 212 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0996
	data_grads_norm = 3.3556
	new_data_grads_norm = 4.6205
	old_data_grads_norm = 4.3295
	sim_grads_norm = 0.1215
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6290
	data_grads_norm = 2.9877
	new_data_grads_norm = 4.5385
	old_data_grads_norm = 3.5980
	sim_grads_norm = 0.0185
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6142
	data_grads_norm = 2.7527
	new_data_grads_norm = 4.8092
	old_data_grads_norm = 3.4056
	sim_grads_norm = -0.1010
-- Starting training on experience 213 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2244
	data_grads_norm = 3.2567
	new_data_grads_norm = 6.1148
	old_data_grads_norm = 4.0617
	sim_grads_norm = 0.1147
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0940
	data_grads_norm = 3.2833
	new_data_grads_norm = 5.0301
	old_data_grads_norm = 3.9712
	sim_grads_norm = -0.0438
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3328
	data_grads_norm = 3.7192
	new_data_grads_norm = 5.3308
	old_data_grads_norm = 4.1631
	sim_grads_norm = 0.1035
-- Starting training on experience 214 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8780
	data_grads_norm = 2.7668
	new_data_grads_norm = 3.4599
	old_data_grads_norm = 3.9473
	sim_grads_norm = 0.1459
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8739
	data_grads_norm = 2.9155
	new_data_grads_norm = 3.4876
	old_data_grads_norm = 4.2356
	sim_grads_norm = 0.0410
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2326
	data_grads_norm = 3.0884
	new_data_grads_norm = 3.6452
	old_data_grads_norm = 4.4865
	sim_grads_norm = 0.1229
-- Starting training on experience 215 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5224
	data_grads_norm = 2.1765
	new_data_grads_norm = 3.3373
	old_data_grads_norm = 2.9834
	sim_grads_norm = -0.0571
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4821
	data_grads_norm = 2.2851
	new_data_grads_norm = 3.3798
	old_data_grads_norm = 3.1071
	sim_grads_norm = -0.0180
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6300
	data_grads_norm = 2.4917
	new_data_grads_norm = 3.3928
	old_data_grads_norm = 3.3059
	sim_grads_norm = 0.1119
-- Starting training on experience 216 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7669
	data_grads_norm = 2.6697
	new_data_grads_norm = 3.3307
	old_data_grads_norm = 4.1162
	sim_grads_norm = -0.0467
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0677
	data_grads_norm = 2.9821
	new_data_grads_norm = 3.5433
	old_data_grads_norm = 3.8437
	sim_grads_norm = 0.0322
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0809
	data_grads_norm = 2.7748
	new_data_grads_norm = 3.9667
	old_data_grads_norm = 4.0307
	sim_grads_norm = -0.0578
-- Starting training on experience 217 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1555
	data_grads_norm = 2.9038
	new_data_grads_norm = 3.7961
	old_data_grads_norm = 3.9272
	sim_grads_norm = -0.0003
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3310
	data_grads_norm = 3.0882
	new_data_grads_norm = 3.7931
	old_data_grads_norm = 4.4732
	sim_grads_norm = 0.0786
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7393
	data_grads_norm = 3.5027
	new_data_grads_norm = 3.9698
	old_data_grads_norm = 4.0913
	sim_grads_norm = 0.0640
-- Starting training on experience 218 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5583
	data_grads_norm = 2.6015
	new_data_grads_norm = 3.9839
	old_data_grads_norm = 3.8228
	sim_grads_norm = 0.0913
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5523
	data_grads_norm = 2.7815
	new_data_grads_norm = 4.5730
	old_data_grads_norm = 3.8303
	sim_grads_norm = -0.0320
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4326
	data_grads_norm = 2.5932
	new_data_grads_norm = 4.3018
	old_data_grads_norm = 2.9892
	sim_grads_norm = -0.0139
-- Starting training on experience 219 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7153
	data_grads_norm = 2.3444
	new_data_grads_norm = 3.1734
	old_data_grads_norm = 3.4534
	sim_grads_norm = -0.0254
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9172
	data_grads_norm = 2.5257
	new_data_grads_norm = 3.2226
	old_data_grads_norm = 3.4611
	sim_grads_norm = 0.1375
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8842
	data_grads_norm = 2.6023
	new_data_grads_norm = 3.4133
	old_data_grads_norm = 3.7291
	sim_grads_norm = -0.0297
-- Starting training on experience 220 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5666
	data_grads_norm = 3.0564
	new_data_grads_norm = 4.4928
	old_data_grads_norm = 4.4340
	sim_grads_norm = 0.1043
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6015
	data_grads_norm = 2.2467
	new_data_grads_norm = 3.9066
	old_data_grads_norm = 3.0575
	sim_grads_norm = -0.0939
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0156
	data_grads_norm = 2.7533
	new_data_grads_norm = 4.3917
	old_data_grads_norm = 3.4248
	sim_grads_norm = -0.0683
-- Starting training on experience 221 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0961
	data_grads_norm = 3.2216
	new_data_grads_norm = 5.0449
	old_data_grads_norm = 3.3461
	sim_grads_norm = 0.0287
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6764
	data_grads_norm = 2.9055
	new_data_grads_norm = 5.0375
	old_data_grads_norm = 3.3755
	sim_grads_norm = 0.1117
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1137
	data_grads_norm = 3.3225
	new_data_grads_norm = 5.1369
	old_data_grads_norm = 4.2545
	sim_grads_norm = -0.0065
-- Starting training on experience 222 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0641
	data_grads_norm = 3.2970
	new_data_grads_norm = 4.9571
	old_data_grads_norm = 4.5826
	sim_grads_norm = -0.1273
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1504
	data_grads_norm = 3.6295
	new_data_grads_norm = 4.6995
	old_data_grads_norm = 4.4971
	sim_grads_norm = 0.0681
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5609
	data_grads_norm = 3.5167
	new_data_grads_norm = 5.0382
	old_data_grads_norm = 4.7548
	sim_grads_norm = -0.0039
-- Starting training on experience 223 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5909
	data_grads_norm = 2.9455
	new_data_grads_norm = 3.8027
	old_data_grads_norm = 4.0679
	sim_grads_norm = 0.0155
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5396
	data_grads_norm = 2.5711
	new_data_grads_norm = 3.5567
	old_data_grads_norm = 3.4086
	sim_grads_norm = -0.0342
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0525
	data_grads_norm = 3.1669
	new_data_grads_norm = 3.8349
	old_data_grads_norm = 4.8170
	sim_grads_norm = 0.0174
-- Starting training on experience 224 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9509
	data_grads_norm = 3.7169
	new_data_grads_norm = 5.1608
	old_data_grads_norm = 5.3511
	sim_grads_norm = 0.0535
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7413
	data_grads_norm = 3.0394
	new_data_grads_norm = 4.1433
	old_data_grads_norm = 3.6721
	sim_grads_norm = 0.1330
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5443
	data_grads_norm = 3.1000
	new_data_grads_norm = 4.0149
	old_data_grads_norm = 4.2978
	sim_grads_norm = 0.1174
-- Starting training on experience 225 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2889
	data_grads_norm = 3.5062
	new_data_grads_norm = 5.3255
	old_data_grads_norm = 3.9174
	sim_grads_norm = -0.0412
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2540
	data_grads_norm = 3.4053
	new_data_grads_norm = 4.7767
	old_data_grads_norm = 4.0142
	sim_grads_norm = 0.0739
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4282
	data_grads_norm = 3.4278
	new_data_grads_norm = 4.7747
	old_data_grads_norm = 3.8799
	sim_grads_norm = 0.0340
-- Starting training on experience 226 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5778
	data_grads_norm = 3.4237
	new_data_grads_norm = 4.6209
	old_data_grads_norm = 4.4626
	sim_grads_norm = 0.1315
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6333
	data_grads_norm = 2.6364
	new_data_grads_norm = 4.9532
	old_data_grads_norm = 3.2681
	sim_grads_norm = 0.0983
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6317
	data_grads_norm = 2.7160
	new_data_grads_norm = 4.0704
	old_data_grads_norm = 4.2509
	sim_grads_norm = 0.0419
-- Starting training on experience 227 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8440
	data_grads_norm = 3.3556
	new_data_grads_norm = 4.2864
	old_data_grads_norm = 4.1378
	sim_grads_norm = 0.2178
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3744
	data_grads_norm = 2.6891
	new_data_grads_norm = 3.7280
	old_data_grads_norm = 3.6907
	sim_grads_norm = -0.0500
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3792
	data_grads_norm = 2.5984
	new_data_grads_norm = 4.3916
	old_data_grads_norm = 3.5179
	sim_grads_norm = -0.0473
-- Starting training on experience 228 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7074
	data_grads_norm = 3.1315
	new_data_grads_norm = 5.0922
	old_data_grads_norm = 5.2625
	sim_grads_norm = -0.0109
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1292
	data_grads_norm = 3.7361
	new_data_grads_norm = 5.4382
	old_data_grads_norm = 3.8656
	sim_grads_norm = 0.0983
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8567
	data_grads_norm = 3.5133
	new_data_grads_norm = 4.8407
	old_data_grads_norm = 4.1932
	sim_grads_norm = 0.0610
-- Starting training on experience 229 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9122
	data_grads_norm = 3.2268
	new_data_grads_norm = 4.8137
	old_data_grads_norm = 4.0718
	sim_grads_norm = -0.0640
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5542
	data_grads_norm = 3.8749
	new_data_grads_norm = 5.1232
	old_data_grads_norm = 6.4826
	sim_grads_norm = 0.0396
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5099
	data_grads_norm = 3.9891
	new_data_grads_norm = 5.5738
	old_data_grads_norm = 3.9577
	sim_grads_norm = 0.0600
-- Starting training on experience 230 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0842
	data_grads_norm = 3.3090
	new_data_grads_norm = 4.8958
	old_data_grads_norm = 4.3304
	sim_grads_norm = -0.0940
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0106
	data_grads_norm = 3.3182
	new_data_grads_norm = 5.1833
	old_data_grads_norm = 4.1895
	sim_grads_norm = -0.0658
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5302
	data_grads_norm = 3.9388
	new_data_grads_norm = 5.5630
	old_data_grads_norm = 4.3610
	sim_grads_norm = 0.0956
-- Starting training on experience 231 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4503
	data_grads_norm = 3.2252
	new_data_grads_norm = 5.0714
	old_data_grads_norm = 3.8998
	sim_grads_norm = 0.1131
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8546
	data_grads_norm = 4.1284
	new_data_grads_norm = 5.1067
	old_data_grads_norm = 5.4593
	sim_grads_norm = 0.0297
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4488
	data_grads_norm = 3.4406
	new_data_grads_norm = 4.3694
	old_data_grads_norm = 4.8083
	sim_grads_norm = 0.0554
-- Starting training on experience 232 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9612
	data_grads_norm = 3.1093
	new_data_grads_norm = 4.9146
	old_data_grads_norm = 3.9623
	sim_grads_norm = -0.0692
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2276
	data_grads_norm = 3.3598
	new_data_grads_norm = 4.8284
	old_data_grads_norm = 3.6174
	sim_grads_norm = 0.0125
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5771
	data_grads_norm = 3.7513
	new_data_grads_norm = 5.1040
	old_data_grads_norm = 4.5528
	sim_grads_norm = 0.0367
-- Starting training on experience 233 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3849
	data_grads_norm = 2.5562
	new_data_grads_norm = 4.4626
	old_data_grads_norm = 2.9053
	sim_grads_norm = 0.0979
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9769
	data_grads_norm = 3.7943
	new_data_grads_norm = 5.1794
	old_data_grads_norm = 4.6286
	sim_grads_norm = 0.1487
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1234
	data_grads_norm = 3.4644
	new_data_grads_norm = 4.0854
	old_data_grads_norm = 4.2877
	sim_grads_norm = 0.0559
-- Starting training on experience 234 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0582
	data_grads_norm = 3.0642
	new_data_grads_norm = 3.5919
	old_data_grads_norm = 4.9701
	sim_grads_norm = 0.0729
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6347
	data_grads_norm = 2.5467
	new_data_grads_norm = 3.9356
	old_data_grads_norm = 4.0628
	sim_grads_norm = 0.0148
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8221
	data_grads_norm = 3.0439
	new_data_grads_norm = 4.0445
	old_data_grads_norm = 3.2630
	sim_grads_norm = 0.0802
-- Starting training on experience 235 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4180
	data_grads_norm = 4.2350
	new_data_grads_norm = 5.9249
	old_data_grads_norm = 4.8471
	sim_grads_norm = 0.1921
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7259
	data_grads_norm = 3.0364
	new_data_grads_norm = 5.7110
	old_data_grads_norm = 3.2752
	sim_grads_norm = -0.1113
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6434
	data_grads_norm = 2.8192
	new_data_grads_norm = 4.7401
	old_data_grads_norm = 3.3361
	sim_grads_norm = 0.0561
-- Starting training on experience 236 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5834
	data_grads_norm = 2.4433
	new_data_grads_norm = 3.8053
	old_data_grads_norm = 3.5370
	sim_grads_norm = -0.0879
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7449
	data_grads_norm = 2.7913
	new_data_grads_norm = 3.8259
	old_data_grads_norm = 3.7623
	sim_grads_norm = 0.1700
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9364
	data_grads_norm = 3.2515
	new_data_grads_norm = 4.1248
	old_data_grads_norm = 4.3040
	sim_grads_norm = -0.0410
-- Starting training on experience 237 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
-- >> End of training phase << --
-- >> Start of eval phase << --
-- Starting eval on experience 0 (Task 0) from test stream --
> Eval on experience 0 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp000 = 1.6635
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.5040
	mb_index = 952
	time = 143.0910
-- Starting eval on experience 1 (Task 0) from test stream --
> Eval on experience 1 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp001 = 1.4024
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.5760
-- Starting eval on experience 2 (Task 0) from test stream --
> Eval on experience 2 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp002 = 2.1649
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.3060
-- Starting eval on experience 3 (Task 0) from test stream --
> Eval on experience 3 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp003 = 1.7277
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.4200
-- >> End of eval phase << --
	CumulativeAccuracy/eval_phase/test_stream/Exp000 = 0.7200
	CumulativeAccuracy/eval_phase/test_stream/Exp001 = 0.6340
	CumulativeAccuracy/eval_phase/test_stream/Exp002 = 0.4980
	CumulativeAccuracy/eval_phase/test_stream/Exp003 = 0.4515
	Loss_Stream/eval_phase/test_stream/Task000 = 1.7396
	Top1_Acc_Stream/eval_phase/test_stream/Task000 = 0.4515
-- >> Start of training phase << --
-- Starting training on experience 0 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3869
	data_grads_norm = 3.4064
	new_data_grads_norm = 5.6490
	old_data_grads_norm = 3.8722
	sim_grads_norm = -0.0403
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4733
	data_grads_norm = 3.6271
	new_data_grads_norm = 5.4913
	old_data_grads_norm = 4.2643
	sim_grads_norm = 0.1036
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6790
	data_grads_norm = 3.9724
	new_data_grads_norm = 5.1427
	old_data_grads_norm = 4.7247
	sim_grads_norm = 0.0249
-- Starting training on experience 1 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6902
	data_grads_norm = 2.8582
	new_data_grads_norm = 4.6659
	old_data_grads_norm = 4.2971
	sim_grads_norm = -0.0147
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3824
	data_grads_norm = 3.3657
	new_data_grads_norm = 5.0768
	old_data_grads_norm = 4.1093
	sim_grads_norm = 0.0770
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8671
	data_grads_norm = 3.3219
	new_data_grads_norm = 4.5370
	old_data_grads_norm = 2.7786
	sim_grads_norm = -0.0452
-- Starting training on experience 2 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3507
	data_grads_norm = 3.6182
	new_data_grads_norm = 5.0146
	old_data_grads_norm = 5.1498
	sim_grads_norm = -0.0340
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1496
	data_grads_norm = 3.4309
	new_data_grads_norm = 5.4337
	old_data_grads_norm = 2.9306
	sim_grads_norm = -0.0063
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6736
	data_grads_norm = 3.6221
	new_data_grads_norm = 5.6580
	old_data_grads_norm = 4.4121
	sim_grads_norm = -0.0435
-- Starting training on experience 3 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8987
	data_grads_norm = 4.0943
	new_data_grads_norm = 4.6962
	old_data_grads_norm = 6.6041
	sim_grads_norm = 0.2165
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1589
	data_grads_norm = 2.9539
	new_data_grads_norm = 4.0652
	old_data_grads_norm = 3.9979
	sim_grads_norm = -0.0054
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4006
	data_grads_norm = 3.1514
	new_data_grads_norm = 4.1462
	old_data_grads_norm = 4.7614
	sim_grads_norm = 0.0572
-- Starting training on experience 4 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1988
	data_grads_norm = 2.6366
	new_data_grads_norm = 4.1638
	old_data_grads_norm = 3.9030
	sim_grads_norm = 0.0203
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5571
	data_grads_norm = 3.1182
	new_data_grads_norm = 4.2990
	old_data_grads_norm = 3.7373
	sim_grads_norm = 0.1044
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6142
	data_grads_norm = 2.1129
	new_data_grads_norm = 3.4887
	old_data_grads_norm = 2.3114
	sim_grads_norm = -0.1299
-- Starting training on experience 5 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9731
	data_grads_norm = 3.0265
	new_data_grads_norm = 4.4037
	old_data_grads_norm = 3.8298
	sim_grads_norm = 0.0071
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1667
	data_grads_norm = 2.6896
	new_data_grads_norm = 4.5642
	old_data_grads_norm = 4.3438
	sim_grads_norm = -0.0056
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6981
	data_grads_norm = 3.0505
	new_data_grads_norm = 4.7471
	old_data_grads_norm = 4.0478
	sim_grads_norm = 0.0194
-- Starting training on experience 6 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2138
	data_grads_norm = 3.1101
	new_data_grads_norm = 4.1866
	old_data_grads_norm = 4.1192
	sim_grads_norm = -0.0075
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1898
	data_grads_norm = 2.8412
	new_data_grads_norm = 4.6274
	old_data_grads_norm = 3.0150
	sim_grads_norm = -0.0456
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3656
	data_grads_norm = 3.2642
	new_data_grads_norm = 4.6254
	old_data_grads_norm = 3.6195
	sim_grads_norm = -0.0553
-- Starting training on experience 7 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2648
	data_grads_norm = 3.2861
	new_data_grads_norm = 4.9760
	old_data_grads_norm = 4.1610
	sim_grads_norm = 0.0263
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6502
	data_grads_norm = 3.8000
	new_data_grads_norm = 4.6702
	old_data_grads_norm = 4.2406
	sim_grads_norm = 0.0508
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0648
	data_grads_norm = 2.7040
	new_data_grads_norm = 4.4813
	old_data_grads_norm = 3.4666
	sim_grads_norm = -0.0003
-- Starting training on experience 8 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7107
	data_grads_norm = 3.6632
	new_data_grads_norm = 5.3828
	old_data_grads_norm = 3.4202
	sim_grads_norm = -0.0831
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8359
	data_grads_norm = 3.8664
	new_data_grads_norm = 5.9982
	old_data_grads_norm = 3.9427
	sim_grads_norm = 0.0722
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8157
	data_grads_norm = 3.9431
	new_data_grads_norm = 5.7967
	old_data_grads_norm = 2.9643
	sim_grads_norm = 0.0419
-- Starting training on experience 9 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7025
	data_grads_norm = 4.1989
	new_data_grads_norm = 5.5820
	old_data_grads_norm = 4.3133
	sim_grads_norm = 0.1903
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2510
	data_grads_norm = 3.2640
	new_data_grads_norm = 4.6779
	old_data_grads_norm = 4.5624
	sim_grads_norm = -0.0007
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4261
	data_grads_norm = 3.1397
	new_data_grads_norm = 4.5809
	old_data_grads_norm = 3.9332
	sim_grads_norm = -0.0173
-- Starting training on experience 10 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3744
	data_grads_norm = 3.0948
	new_data_grads_norm = 4.4287
	old_data_grads_norm = 3.9394
	sim_grads_norm = 0.1033
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6603
	data_grads_norm = 3.5649
	new_data_grads_norm = 4.6084
	old_data_grads_norm = 4.7351
	sim_grads_norm = 0.0927
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1672
	data_grads_norm = 2.7178
	new_data_grads_norm = 4.3733
	old_data_grads_norm = 3.3685
	sim_grads_norm = -0.0870
-- Starting training on experience 11 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6384
	data_grads_norm = 3.6342
	new_data_grads_norm = 4.7688
	old_data_grads_norm = 3.8841
	sim_grads_norm = 0.0280
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3403
	data_grads_norm = 3.5806
	new_data_grads_norm = 4.9352
	old_data_grads_norm = 4.4968
	sim_grads_norm = 0.0366
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5446
	data_grads_norm = 3.3090
	new_data_grads_norm = 4.6247
	old_data_grads_norm = 3.8595
	sim_grads_norm = 0.1916
-- Starting training on experience 12 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2437
	data_grads_norm = 3.1109
	new_data_grads_norm = 4.8122
	old_data_grads_norm = 3.5063
	sim_grads_norm = 0.1155
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1452
	data_grads_norm = 2.7856
	new_data_grads_norm = 4.7383
	old_data_grads_norm = 3.7603
	sim_grads_norm = 0.0047
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1440
	data_grads_norm = 3.2868
	new_data_grads_norm = 4.9927
	old_data_grads_norm = 3.7562
	sim_grads_norm = -0.0224
-- Starting training on experience 13 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3873
	data_grads_norm = 3.4986
	new_data_grads_norm = 4.4073
	old_data_grads_norm = 5.1918
	sim_grads_norm = 0.0320
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8479
	data_grads_norm = 3.6694
	new_data_grads_norm = 4.6464
	old_data_grads_norm = 4.1529
	sim_grads_norm = 0.0964
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4745
	data_grads_norm = 2.9654
	new_data_grads_norm = 3.6043
	old_data_grads_norm = 3.9867
	sim_grads_norm = 0.0580
-- Starting training on experience 14 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3042
	data_grads_norm = 2.7016
	new_data_grads_norm = 3.3782
	old_data_grads_norm = 3.4117
	sim_grads_norm = 0.0563
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2037
	data_grads_norm = 2.8854
	new_data_grads_norm = 3.7670
	old_data_grads_norm = 3.4668
	sim_grads_norm = -0.0079
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5378
	data_grads_norm = 2.9067
	new_data_grads_norm = 3.6093
	old_data_grads_norm = 4.2270
	sim_grads_norm = 0.0316
-- Starting training on experience 15 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4749
	data_grads_norm = 2.8892
	new_data_grads_norm = 3.7605
	old_data_grads_norm = 3.6501
	sim_grads_norm = 0.1832
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3905
	data_grads_norm = 2.6677
	new_data_grads_norm = 3.4904
	old_data_grads_norm = 3.0802
	sim_grads_norm = 0.3114
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8310
	data_grads_norm = 2.2999
	new_data_grads_norm = 3.4425
	old_data_grads_norm = 2.7355
	sim_grads_norm = 0.0783
-- Starting training on experience 16 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1016
	data_grads_norm = 2.3503
	new_data_grads_norm = 3.1433
	old_data_grads_norm = 3.8779
	sim_grads_norm = -0.1052
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3422
	data_grads_norm = 2.7206
	new_data_grads_norm = 3.8290
	old_data_grads_norm = 2.9458
	sim_grads_norm = 0.0524
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1657
	data_grads_norm = 2.6214
	new_data_grads_norm = 3.5882
	old_data_grads_norm = 3.4716
	sim_grads_norm = 0.0903
-- Starting training on experience 17 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8716
	data_grads_norm = 2.5798
	new_data_grads_norm = 3.7735
	old_data_grads_norm = 3.2882
	sim_grads_norm = -0.0404
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7544
	data_grads_norm = 2.4753
	new_data_grads_norm = 4.1383
	old_data_grads_norm = 2.8829
	sim_grads_norm = 0.0000
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6235
	data_grads_norm = 2.6603
	new_data_grads_norm = 3.9693
	old_data_grads_norm = 3.6768
	sim_grads_norm = -0.0100
-- Starting training on experience 18 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2346
	data_grads_norm = 3.4262
	new_data_grads_norm = 5.0933
	old_data_grads_norm = 4.2086
	sim_grads_norm = 0.1605
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7108
	data_grads_norm = 2.6686
	new_data_grads_norm = 4.3621
	old_data_grads_norm = 3.2827
	sim_grads_norm = -0.0425
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8290
	data_grads_norm = 2.8203
	new_data_grads_norm = 4.6549
	old_data_grads_norm = 4.1634
	sim_grads_norm = -0.0499
-- Starting training on experience 19 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1345
	data_grads_norm = 2.8962
	new_data_grads_norm = 4.1274
	old_data_grads_norm = 3.1017
	sim_grads_norm = 0.0300
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9718
	data_grads_norm = 3.2116
	new_data_grads_norm = 4.3923
	old_data_grads_norm = 3.5385
	sim_grads_norm = 0.1707
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2512
	data_grads_norm = 3.4645
	new_data_grads_norm = 4.2664
	old_data_grads_norm = 5.9977
	sim_grads_norm = -0.0293
-- Starting training on experience 20 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0487
	data_grads_norm = 2.9422
	new_data_grads_norm = 4.3160
	old_data_grads_norm = 3.9188
	sim_grads_norm = 0.0802
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2375
	data_grads_norm = 4.3319
	new_data_grads_norm = 4.1008
	old_data_grads_norm = 5.7880
	sim_grads_norm = 0.1096
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2636
	data_grads_norm = 3.1555
	new_data_grads_norm = 3.8409
	old_data_grads_norm = 4.3297
	sim_grads_norm = 0.1095
-- Starting training on experience 21 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3821
	data_grads_norm = 2.7571
	new_data_grads_norm = 3.8416
	old_data_grads_norm = 3.3055
	sim_grads_norm = 0.0475
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1276
	data_grads_norm = 2.4514
	new_data_grads_norm = 3.5276
	old_data_grads_norm = 3.3757
	sim_grads_norm = 0.0619
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0389
	data_grads_norm = 2.4341
	new_data_grads_norm = 3.3993
	old_data_grads_norm = 3.2173
	sim_grads_norm = 0.0251
-- Starting training on experience 22 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9458
	data_grads_norm = 2.3102
	new_data_grads_norm = 3.1705
	old_data_grads_norm = 3.1782
	sim_grads_norm = 0.1534
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8449
	data_grads_norm = 2.4325
	new_data_grads_norm = 3.0964
	old_data_grads_norm = 2.9631
	sim_grads_norm = 0.0940
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8972
	data_grads_norm = 2.3740
	new_data_grads_norm = 3.1718
	old_data_grads_norm = 3.3141
	sim_grads_norm = 0.0446
-- Starting training on experience 23 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4864
	data_grads_norm = 2.1961
	new_data_grads_norm = 2.9896
	old_data_grads_norm = 2.9570
	sim_grads_norm = -0.0129
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0376
	data_grads_norm = 2.5111
	new_data_grads_norm = 3.0175
	old_data_grads_norm = 3.6855
	sim_grads_norm = 0.0512
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8634
	data_grads_norm = 2.4135
	new_data_grads_norm = 2.9915
	old_data_grads_norm = 3.1957
	sim_grads_norm = 0.0880
-- Starting training on experience 24 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8909
	data_grads_norm = 2.5874
	new_data_grads_norm = 3.9878
	old_data_grads_norm = 3.8603
	sim_grads_norm = 0.0445
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5684
	data_grads_norm = 2.1193
	new_data_grads_norm = 3.8039
	old_data_grads_norm = 3.3476
	sim_grads_norm = -0.0200
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3989
	data_grads_norm = 2.1429
	new_data_grads_norm = 3.6136
	old_data_grads_norm = 3.1728
	sim_grads_norm = 0.0206
-- Starting training on experience 25 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9609
	data_grads_norm = 3.0231
	new_data_grads_norm = 3.4454
	old_data_grads_norm = 3.5884
	sim_grads_norm = -0.1390
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1411
	data_grads_norm = 3.0449
	new_data_grads_norm = 3.6800
	old_data_grads_norm = 3.3374
	sim_grads_norm = 0.0613
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0425
	data_grads_norm = 2.9815
	new_data_grads_norm = 3.6857
	old_data_grads_norm = 3.6104
	sim_grads_norm = 0.1209
-- Starting training on experience 26 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9357
	data_grads_norm = 2.7315
	new_data_grads_norm = 4.0974
	old_data_grads_norm = 3.1238
	sim_grads_norm = -0.0330
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5782
	data_grads_norm = 3.6696
	new_data_grads_norm = 4.5042
	old_data_grads_norm = 4.9588
	sim_grads_norm = 0.1270
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4910
	data_grads_norm = 2.1811
	new_data_grads_norm = 3.3826
	old_data_grads_norm = 2.9243
	sim_grads_norm = -0.0238
-- Starting training on experience 27 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1397
	data_grads_norm = 2.7415
	new_data_grads_norm = 3.5293
	old_data_grads_norm = 3.7832
	sim_grads_norm = 0.1737
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9589
	data_grads_norm = 2.8308
	new_data_grads_norm = 3.8650
	old_data_grads_norm = 4.2665
	sim_grads_norm = 0.0406
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4114
	data_grads_norm = 1.9637
	new_data_grads_norm = 3.0794
	old_data_grads_norm = 2.4267
	sim_grads_norm = -0.0154
-- Starting training on experience 28 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6343
	data_grads_norm = 2.3687
	new_data_grads_norm = 3.5479
	old_data_grads_norm = 2.8554
	sim_grads_norm = -0.0372
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9406
	data_grads_norm = 2.6565
	new_data_grads_norm = 3.6762
	old_data_grads_norm = 3.7934
	sim_grads_norm = -0.0003
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6095
	data_grads_norm = 2.4067
	new_data_grads_norm = 3.6775
	old_data_grads_norm = 3.1320
	sim_grads_norm = -0.0144
-- Starting training on experience 29 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9937
	data_grads_norm = 2.9561
	new_data_grads_norm = 3.1637
	old_data_grads_norm = 4.2695
	sim_grads_norm = 0.1866
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3216
	data_grads_norm = 2.3070
	new_data_grads_norm = 3.4104
	old_data_grads_norm = 2.9501
	sim_grads_norm = -0.0765
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8739
	data_grads_norm = 3.0790
	new_data_grads_norm = 3.5353
	old_data_grads_norm = 4.3471
	sim_grads_norm = 0.0247
-- Starting training on experience 30 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2491
	data_grads_norm = 3.0519
	new_data_grads_norm = 3.5677
	old_data_grads_norm = 3.4054
	sim_grads_norm = -0.0704
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6749
	data_grads_norm = 2.5957
	new_data_grads_norm = 3.4793
	old_data_grads_norm = 3.1735
	sim_grads_norm = 0.0634
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0861
	data_grads_norm = 2.6807
	new_data_grads_norm = 3.9281
	old_data_grads_norm = 3.0661
	sim_grads_norm = 0.1056
-- Starting training on experience 31 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7913
	data_grads_norm = 2.6286
	new_data_grads_norm = 3.2036
	old_data_grads_norm = 3.5502
	sim_grads_norm = 0.1701
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1759
	data_grads_norm = 2.1831
	new_data_grads_norm = 2.9669
	old_data_grads_norm = 3.6179
	sim_grads_norm = -0.1245
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7637
	data_grads_norm = 2.7620
	new_data_grads_norm = 3.7694
	old_data_grads_norm = 3.3804
	sim_grads_norm = 0.0451
-- Starting training on experience 32 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2387
	data_grads_norm = 2.1739
	new_data_grads_norm = 3.7694
	old_data_grads_norm = 3.1700
	sim_grads_norm = -0.0793
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6224
	data_grads_norm = 2.6942
	new_data_grads_norm = 4.0080
	old_data_grads_norm = 3.2099
	sim_grads_norm = 0.0310
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7412
	data_grads_norm = 2.7219
	new_data_grads_norm = 4.2431
	old_data_grads_norm = 3.2303
	sim_grads_norm = 0.0298
-- Starting training on experience 33 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9885
	data_grads_norm = 2.8664
	new_data_grads_norm = 3.6205
	old_data_grads_norm = 3.7926
	sim_grads_norm = 0.1485
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6876
	data_grads_norm = 3.1505
	new_data_grads_norm = 4.0871
	old_data_grads_norm = 4.3850
	sim_grads_norm = -0.0306
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6414
	data_grads_norm = 2.9516
	new_data_grads_norm = 3.9733
	old_data_grads_norm = 3.7637
	sim_grads_norm = 0.0320
-- Starting training on experience 34 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5575
	data_grads_norm = 2.7953
	new_data_grads_norm = 4.3882
	old_data_grads_norm = 3.5381
	sim_grads_norm = -0.0845
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9514
	data_grads_norm = 2.9908
	new_data_grads_norm = 4.4711
	old_data_grads_norm = 3.5901
	sim_grads_norm = 0.0639
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6139
	data_grads_norm = 2.8116
	new_data_grads_norm = 3.9255
	old_data_grads_norm = 3.4498
	sim_grads_norm = 0.1498
-- Starting training on experience 35 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6754
	data_grads_norm = 2.7117
	new_data_grads_norm = 3.9730
	old_data_grads_norm = 3.3341
	sim_grads_norm = 0.3200
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7440
	data_grads_norm = 2.9300
	new_data_grads_norm = 3.5695
	old_data_grads_norm = 4.1825
	sim_grads_norm = -0.0910
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7971
	data_grads_norm = 2.5902
	new_data_grads_norm = 3.6948
	old_data_grads_norm = 3.5320
	sim_grads_norm = 0.0277
-- Starting training on experience 36 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5741
	data_grads_norm = 2.6478
	new_data_grads_norm = 4.0148
	old_data_grads_norm = 3.2886
	sim_grads_norm = 0.0639
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4296
	data_grads_norm = 2.7067
	new_data_grads_norm = 3.9690
	old_data_grads_norm = 3.5115
	sim_grads_norm = 0.0195
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8758
	data_grads_norm = 3.1004
	new_data_grads_norm = 4.5887
	old_data_grads_norm = 3.9443
	sim_grads_norm = -0.0369
-- Starting training on experience 37 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4926
	data_grads_norm = 2.4706
	new_data_grads_norm = 3.4182
	old_data_grads_norm = 2.7251
	sim_grads_norm = 0.3022
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3491
	data_grads_norm = 2.7884
	new_data_grads_norm = 3.4981
	old_data_grads_norm = 4.5178
	sim_grads_norm = -0.0911
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3323
	data_grads_norm = 2.9868
	new_data_grads_norm = 3.7783
	old_data_grads_norm = 3.5399
	sim_grads_norm = 0.1775
-- Starting training on experience 38 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3490
	data_grads_norm = 2.6226
	new_data_grads_norm = 3.2429
	old_data_grads_norm = 3.9633
	sim_grads_norm = -0.0608
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2092
	data_grads_norm = 2.3089
	new_data_grads_norm = 3.2397
	old_data_grads_norm = 3.5844
	sim_grads_norm = -0.0723
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4608
	data_grads_norm = 2.4175
	new_data_grads_norm = 3.7281
	old_data_grads_norm = 2.7591
	sim_grads_norm = 0.0871
-- Starting training on experience 39 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8688
	data_grads_norm = 3.6663
	new_data_grads_norm = 5.5723
	old_data_grads_norm = 5.1377
	sim_grads_norm = 0.0321
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6101
	data_grads_norm = 2.6426
	new_data_grads_norm = 4.5324
	old_data_grads_norm = 3.0178
	sim_grads_norm = 0.0297
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5823
	data_grads_norm = 3.1563
	new_data_grads_norm = 5.5607
	old_data_grads_norm = 4.6820
	sim_grads_norm = -0.0084
-- Starting training on experience 40 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9362
	data_grads_norm = 3.3625
	new_data_grads_norm = 5.1292
	old_data_grads_norm = 4.1975
	sim_grads_norm = -0.0593
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9711
	data_grads_norm = 3.4580
	new_data_grads_norm = 4.8764
	old_data_grads_norm = 4.4098
	sim_grads_norm = 0.0080
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6353
	data_grads_norm = 3.0748
	new_data_grads_norm = 4.5572
	old_data_grads_norm = 3.6145
	sim_grads_norm = 0.1050
-- Starting training on experience 41 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8757
	data_grads_norm = 3.1051
	new_data_grads_norm = 3.5594
	old_data_grads_norm = 4.0068
	sim_grads_norm = 0.0555
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2189
	data_grads_norm = 3.0027
	new_data_grads_norm = 3.4279
	old_data_grads_norm = 4.0054
	sim_grads_norm = 0.1341
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7126
	data_grads_norm = 3.0462
	new_data_grads_norm = 3.3156
	old_data_grads_norm = 4.7039
	sim_grads_norm = 0.0293
-- Starting training on experience 42 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1333
	data_grads_norm = 2.3931
	new_data_grads_norm = 3.9437
	old_data_grads_norm = 2.7733
	sim_grads_norm = -0.0401
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9914
	data_grads_norm = 2.9769
	new_data_grads_norm = 4.2861
	old_data_grads_norm = 4.0525
	sim_grads_norm = 0.0763
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1169
	data_grads_norm = 3.0889
	new_data_grads_norm = 4.0039
	old_data_grads_norm = 4.4496
	sim_grads_norm = 0.0115
-- Starting training on experience 43 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4922
	data_grads_norm = 2.4584
	new_data_grads_norm = 3.9008
	old_data_grads_norm = 3.8443
	sim_grads_norm = -0.1917
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7759
	data_grads_norm = 3.0272
	new_data_grads_norm = 4.1642
	old_data_grads_norm = 3.5309
	sim_grads_norm = 0.1854
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5988
	data_grads_norm = 2.7736
	new_data_grads_norm = 4.2606
	old_data_grads_norm = 3.1209
	sim_grads_norm = 0.0476
-- Starting training on experience 44 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6312
	data_grads_norm = 2.8244
	new_data_grads_norm = 3.6876
	old_data_grads_norm = 3.8434
	sim_grads_norm = 0.0136
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4949
	data_grads_norm = 2.6256
	new_data_grads_norm = 4.1009
	old_data_grads_norm = 3.4331
	sim_grads_norm = -0.0278
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6665
	data_grads_norm = 3.2565
	new_data_grads_norm = 4.2573
	old_data_grads_norm = 4.7552
	sim_grads_norm = 0.0106
-- Starting training on experience 45 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4294
	data_grads_norm = 2.9564
	new_data_grads_norm = 4.6964
	old_data_grads_norm = 3.9677
	sim_grads_norm = -0.0200
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0264
	data_grads_norm = 3.5312
	new_data_grads_norm = 4.9330
	old_data_grads_norm = 4.1824
	sim_grads_norm = 0.2333
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9253
	data_grads_norm = 3.2663
	new_data_grads_norm = 4.1900
	old_data_grads_norm = 4.4883
	sim_grads_norm = 0.1586
-- Starting training on experience 46 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7371
	data_grads_norm = 2.7798
	new_data_grads_norm = 4.3944
	old_data_grads_norm = 4.1810
	sim_grads_norm = 0.0080
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5805
	data_grads_norm = 2.8233
	new_data_grads_norm = 3.9374
	old_data_grads_norm = 3.7633
	sim_grads_norm = 0.0365
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5726
	data_grads_norm = 2.9465
	new_data_grads_norm = 3.6630
	old_data_grads_norm = 4.0098
	sim_grads_norm = 0.1451
-- Starting training on experience 47 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0908
	data_grads_norm = 2.5683
	new_data_grads_norm = 3.8209
	old_data_grads_norm = 3.7836
	sim_grads_norm = -0.1283
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6116
	data_grads_norm = 3.1943
	new_data_grads_norm = 3.7954
	old_data_grads_norm = 4.7859
	sim_grads_norm = 0.0791
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6668
	data_grads_norm = 2.6803
	new_data_grads_norm = 3.9825
	old_data_grads_norm = 3.5507
	sim_grads_norm = 0.0417
-- Starting training on experience 48 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3020
	data_grads_norm = 2.4684
	new_data_grads_norm = 3.6882
	old_data_grads_norm = 2.8868
	sim_grads_norm = 0.0664
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3320
	data_grads_norm = 2.5902
	new_data_grads_norm = 4.2467
	old_data_grads_norm = 3.8452
	sim_grads_norm = 0.0039
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4324
	data_grads_norm = 2.8492
	new_data_grads_norm = 4.1836
	old_data_grads_norm = 4.7925
	sim_grads_norm = 0.0665
-- Starting training on experience 49 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8592
	data_grads_norm = 3.3976
	new_data_grads_norm = 4.9270
	old_data_grads_norm = 4.3771
	sim_grads_norm = 0.0672
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3112
	data_grads_norm = 2.8320
	new_data_grads_norm = 4.1290
	old_data_grads_norm = 4.3110
	sim_grads_norm = 0.0414
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4420
	data_grads_norm = 2.9550
	new_data_grads_norm = 3.9965
	old_data_grads_norm = 3.9120
	sim_grads_norm = -0.0574
-- Starting training on experience 50 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6287
	data_grads_norm = 2.9964
	new_data_grads_norm = 4.4271
	old_data_grads_norm = 4.1726
	sim_grads_norm = 0.0318
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1154
	data_grads_norm = 2.4523
	new_data_grads_norm = 3.7453
	old_data_grads_norm = 3.6180
	sim_grads_norm = -0.0972
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6545
	data_grads_norm = 3.0221
	new_data_grads_norm = 3.4985
	old_data_grads_norm = 4.0798
	sim_grads_norm = 0.0414
-- Starting training on experience 51 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5073
	data_grads_norm = 2.8244
	new_data_grads_norm = 3.3930
	old_data_grads_norm = 3.9934
	sim_grads_norm = 0.0528
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3492
	data_grads_norm = 2.5425
	new_data_grads_norm = 3.8697
	old_data_grads_norm = 3.3700
	sim_grads_norm = 0.1065
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4147
	data_grads_norm = 2.6666
	new_data_grads_norm = 3.6155
	old_data_grads_norm = 3.8237
	sim_grads_norm = -0.0237
-- Starting training on experience 52 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1744
	data_grads_norm = 3.1320
	new_data_grads_norm = 4.8520
	old_data_grads_norm = 4.2521
	sim_grads_norm = 0.0069
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3183
	data_grads_norm = 3.1705
	new_data_grads_norm = 5.1608
	old_data_grads_norm = 3.2375
	sim_grads_norm = 0.0434
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7269
	data_grads_norm = 3.5454
	new_data_grads_norm = 4.5765
	old_data_grads_norm = 3.9372
	sim_grads_norm = 0.0635
-- Starting training on experience 53 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7100
	data_grads_norm = 3.0878
	new_data_grads_norm = 3.4456
	old_data_grads_norm = 4.5881
	sim_grads_norm = 0.0801
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0684
	data_grads_norm = 2.2853
	new_data_grads_norm = 3.2839
	old_data_grads_norm = 3.4847
	sim_grads_norm = 0.0241
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1870
	data_grads_norm = 2.5189
	new_data_grads_norm = 3.4569
	old_data_grads_norm = 3.2179
	sim_grads_norm = 0.0706
-- Starting training on experience 54 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3765
	data_grads_norm = 3.1174
	new_data_grads_norm = 4.3452
	old_data_grads_norm = 3.9702
	sim_grads_norm = 0.0895
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7384
	data_grads_norm = 3.4028
	new_data_grads_norm = 4.6789
	old_data_grads_norm = 4.4665
	sim_grads_norm = -0.0025
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7263
	data_grads_norm = 3.0998
	new_data_grads_norm = 4.2784
	old_data_grads_norm = 3.7855
	sim_grads_norm = 0.0608
-- Starting training on experience 55 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8863
	data_grads_norm = 3.4987
	new_data_grads_norm = 6.0465
	old_data_grads_norm = 3.4725
	sim_grads_norm = -0.1359
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1167
	data_grads_norm = 3.6464
	new_data_grads_norm = 5.9296
	old_data_grads_norm = 3.5632
	sim_grads_norm = 0.1308
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6024
	data_grads_norm = 3.2579
	new_data_grads_norm = 5.0439
	old_data_grads_norm = 4.3967
	sim_grads_norm = -0.0627
-- Starting training on experience 56 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1645
	data_grads_norm = 2.3677
	new_data_grads_norm = 3.6501
	old_data_grads_norm = 2.7735
	sim_grads_norm = 0.0908
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1914
	data_grads_norm = 2.3981
	new_data_grads_norm = 3.5589
	old_data_grads_norm = 3.3221
	sim_grads_norm = -0.0684
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0617
	data_grads_norm = 2.6377
	new_data_grads_norm = 3.9091
	old_data_grads_norm = 3.2136
	sim_grads_norm = -0.0603
-- Starting training on experience 57 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8936
	data_grads_norm = 3.7592
	new_data_grads_norm = 5.1676
	old_data_grads_norm = 4.9986
	sim_grads_norm = 0.0672
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7609
	data_grads_norm = 3.1045
	new_data_grads_norm = 5.2028
	old_data_grads_norm = 4.0016
	sim_grads_norm = 0.0698
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5153
	data_grads_norm = 3.2760
	new_data_grads_norm = 4.5881
	old_data_grads_norm = 4.2996
	sim_grads_norm = 0.1135
-- Starting training on experience 58 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8096
	data_grads_norm = 3.1889
	new_data_grads_norm = 4.8622
	old_data_grads_norm = 3.6839
	sim_grads_norm = 0.1981
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4053
	data_grads_norm = 2.9276
	new_data_grads_norm = 4.6344
	old_data_grads_norm = 3.4405
	sim_grads_norm = 0.0600
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7201
	data_grads_norm = 3.1776
	new_data_grads_norm = 4.3051
	old_data_grads_norm = 4.2322
	sim_grads_norm = 0.0273
-- Starting training on experience 59 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1985
	data_grads_norm = 2.4693
	new_data_grads_norm = 3.7771
	old_data_grads_norm = 2.8850
	sim_grads_norm = 0.0146
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2276
	data_grads_norm = 2.6476
	new_data_grads_norm = 3.8328
	old_data_grads_norm = 3.4936
	sim_grads_norm = 0.0604
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1573
	data_grads_norm = 2.5591
	new_data_grads_norm = 3.7938
	old_data_grads_norm = 2.9044
	sim_grads_norm = 0.1107
-- Starting training on experience 60 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2919
	data_grads_norm = 3.3124
	new_data_grads_norm = 3.6046
	old_data_grads_norm = 5.2936
	sim_grads_norm = 0.0797
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4889
	data_grads_norm = 2.9219
	new_data_grads_norm = 4.0282
	old_data_grads_norm = 4.1764
	sim_grads_norm = -0.0223
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4810
	data_grads_norm = 2.8855
	new_data_grads_norm = 3.8311
	old_data_grads_norm = 4.3364
	sim_grads_norm = -0.0816
-- Starting training on experience 61 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7116
	data_grads_norm = 2.7333
	new_data_grads_norm = 3.5417
	old_data_grads_norm = 3.5626
	sim_grads_norm = 0.0759
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4375
	data_grads_norm = 2.3104
	new_data_grads_norm = 3.8295
	old_data_grads_norm = 2.9560
	sim_grads_norm = -0.0312
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7098
	data_grads_norm = 2.8690
	new_data_grads_norm = 3.7547
	old_data_grads_norm = 4.4581
	sim_grads_norm = 0.0799
-- Starting training on experience 62 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3258
	data_grads_norm = 2.8392
	new_data_grads_norm = 4.8110
	old_data_grads_norm = 3.5699
	sim_grads_norm = -0.0631
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7365
	data_grads_norm = 2.9781
	new_data_grads_norm = 4.9433
	old_data_grads_norm = 3.6857
	sim_grads_norm = -0.0156
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8346
	data_grads_norm = 3.1425
	new_data_grads_norm = 5.2133
	old_data_grads_norm = 4.8463
	sim_grads_norm = -0.0217
-- Starting training on experience 63 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2081
	data_grads_norm = 2.9822
	new_data_grads_norm = 3.9158
	old_data_grads_norm = 3.9043
	sim_grads_norm = 0.0145
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6133
	data_grads_norm = 2.7058
	new_data_grads_norm = 3.4523
	old_data_grads_norm = 3.4286
	sim_grads_norm = -0.0249
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6670
	data_grads_norm = 2.8539
	new_data_grads_norm = 3.5399
	old_data_grads_norm = 4.1098
	sim_grads_norm = -0.0408
-- Starting training on experience 64 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4350
	data_grads_norm = 2.8806
	new_data_grads_norm = 3.8727
	old_data_grads_norm = 4.6034
	sim_grads_norm = 0.0180
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4837
	data_grads_norm = 2.9546
	new_data_grads_norm = 3.7861
	old_data_grads_norm = 4.3926
	sim_grads_norm = 0.0554
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2939
	data_grads_norm = 2.3213
	new_data_grads_norm = 3.2771
	old_data_grads_norm = 3.1878
	sim_grads_norm = 0.0205
-- Starting training on experience 65 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3979
	data_grads_norm = 2.8035
	new_data_grads_norm = 4.2906
	old_data_grads_norm = 4.2670
	sim_grads_norm = -0.0002
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3963
	data_grads_norm = 2.5889
	new_data_grads_norm = 3.5364
	old_data_grads_norm = 3.5661
	sim_grads_norm = 0.0334
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8851
	data_grads_norm = 2.8725
	new_data_grads_norm = 3.8593
	old_data_grads_norm = 3.6206
	sim_grads_norm = 0.0667
-- Starting training on experience 66 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5447
	data_grads_norm = 2.6683
	new_data_grads_norm = 3.6088
	old_data_grads_norm = 3.2914
	sim_grads_norm = 0.0634
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6982
	data_grads_norm = 3.1141
	new_data_grads_norm = 3.6039
	old_data_grads_norm = 4.0234
	sim_grads_norm = 0.0888
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4447
	data_grads_norm = 2.7951
	new_data_grads_norm = 3.7343
	old_data_grads_norm = 3.8675
	sim_grads_norm = 0.0702
-- Starting training on experience 67 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7337
	data_grads_norm = 2.6654
	new_data_grads_norm = 3.7569
	old_data_grads_norm = 4.4258
	sim_grads_norm = 0.0146
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6669
	data_grads_norm = 2.7501
	new_data_grads_norm = 3.6831
	old_data_grads_norm = 3.2091
	sim_grads_norm = 0.0781
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6895
	data_grads_norm = 2.7003
	new_data_grads_norm = 4.4554
	old_data_grads_norm = 3.9001
	sim_grads_norm = -0.0510
-- Starting training on experience 68 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7189
	data_grads_norm = 3.1729
	new_data_grads_norm = 4.2152
	old_data_grads_norm = 3.2375
	sim_grads_norm = 0.1446
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5646
	data_grads_norm = 3.1424
	new_data_grads_norm = 3.8881
	old_data_grads_norm = 4.6497
	sim_grads_norm = 0.1285
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1780
	data_grads_norm = 2.3950
	new_data_grads_norm = 3.3060
	old_data_grads_norm = 3.7144
	sim_grads_norm = 0.0332
-- Starting training on experience 69 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2670
	data_grads_norm = 2.6254
	new_data_grads_norm = 3.3582
	old_data_grads_norm = 3.4471
	sim_grads_norm = 0.1153
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4489
	data_grads_norm = 2.5338
	new_data_grads_norm = 3.1285
	old_data_grads_norm = 4.2267
	sim_grads_norm = 0.0031
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1158
	data_grads_norm = 2.3058
	new_data_grads_norm = 2.9866
	old_data_grads_norm = 3.4330
	sim_grads_norm = 0.0772
-- Starting training on experience 70 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0880
	data_grads_norm = 2.3540
	new_data_grads_norm = 3.5482
	old_data_grads_norm = 2.8734
	sim_grads_norm = -0.0147
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9909
	data_grads_norm = 3.1114
	new_data_grads_norm = 3.5016
	old_data_grads_norm = 4.5324
	sim_grads_norm = 0.0685
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2828
	data_grads_norm = 2.4291
	new_data_grads_norm = 3.0859
	old_data_grads_norm = 3.5296
	sim_grads_norm = 0.1017
-- Starting training on experience 71 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3862
	data_grads_norm = 2.5482
	new_data_grads_norm = 3.8633
	old_data_grads_norm = 3.7347
	sim_grads_norm = -0.0913
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2761
	data_grads_norm = 2.8057
	new_data_grads_norm = 4.3790
	old_data_grads_norm = 3.7703
	sim_grads_norm = -0.1160
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3300
	data_grads_norm = 2.7972
	new_data_grads_norm = 4.1046
	old_data_grads_norm = 3.8644
	sim_grads_norm = 0.0407
-- Starting training on experience 72 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5448
	data_grads_norm = 2.9197
	new_data_grads_norm = 3.8421
	old_data_grads_norm = 3.7340
	sim_grads_norm = 0.0733
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5234
	data_grads_norm = 2.8876
	new_data_grads_norm = 3.9897
	old_data_grads_norm = 4.5791
	sim_grads_norm = -0.1201
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7377
	data_grads_norm = 3.1385
	new_data_grads_norm = 4.0687
	old_data_grads_norm = 4.4104
	sim_grads_norm = -0.0566
-- Starting training on experience 73 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6275
	data_grads_norm = 3.1104
	new_data_grads_norm = 3.5822
	old_data_grads_norm = 4.4333
	sim_grads_norm = -0.0785
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5710
	data_grads_norm = 2.7235
	new_data_grads_norm = 3.9170
	old_data_grads_norm = 3.8643
	sim_grads_norm = -0.0119
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6554
	data_grads_norm = 3.0449
	new_data_grads_norm = 3.9514
	old_data_grads_norm = 4.4370
	sim_grads_norm = 0.0573
-- Starting training on experience 74 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3215
	data_grads_norm = 2.5935
	new_data_grads_norm = 4.1446
	old_data_grads_norm = 3.6641
	sim_grads_norm = -0.0087
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8239
	data_grads_norm = 3.3941
	new_data_grads_norm = 4.7214
	old_data_grads_norm = 4.5785
	sim_grads_norm = 0.0713
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6963
	data_grads_norm = 2.9958
	new_data_grads_norm = 4.3055
	old_data_grads_norm = 3.9753
	sim_grads_norm = -0.0136
-- Starting training on experience 75 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8097
	data_grads_norm = 3.3862
	new_data_grads_norm = 4.6861
	old_data_grads_norm = 4.2781
	sim_grads_norm = 0.0550
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4220
	data_grads_norm = 2.9322
	new_data_grads_norm = 4.1100
	old_data_grads_norm = 4.5348
	sim_grads_norm = -0.0806
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1741
	data_grads_norm = 3.6378
	new_data_grads_norm = 4.4136
	old_data_grads_norm = 5.2919
	sim_grads_norm = 0.1258
-- Starting training on experience 76 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2592
	data_grads_norm = 3.0247
	new_data_grads_norm = 3.8545
	old_data_grads_norm = 4.3522
	sim_grads_norm = 0.1029
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3825
	data_grads_norm = 2.2008
	new_data_grads_norm = 3.4382
	old_data_grads_norm = 2.7234
	sim_grads_norm = 0.0396
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5417
	data_grads_norm = 2.5702
	new_data_grads_norm = 3.4225
	old_data_grads_norm = 3.7250
	sim_grads_norm = -0.0348
-- Starting training on experience 77 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5338
	data_grads_norm = 2.6789
	new_data_grads_norm = 3.7511
	old_data_grads_norm = 3.3251
	sim_grads_norm = 0.0789
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3770
	data_grads_norm = 2.3980
	new_data_grads_norm = 3.7341
	old_data_grads_norm = 3.1261
	sim_grads_norm = 0.0423
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4957
	data_grads_norm = 2.7496
	new_data_grads_norm = 3.7537
	old_data_grads_norm = 4.2033
	sim_grads_norm = -0.0700
-- Starting training on experience 78 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9628
	data_grads_norm = 2.4240
	new_data_grads_norm = 2.9453
	old_data_grads_norm = 4.3106
	sim_grads_norm = -0.1486
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3916
	data_grads_norm = 2.3748
	new_data_grads_norm = 3.3500
	old_data_grads_norm = 2.9918
	sim_grads_norm = -0.0799
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4851
	data_grads_norm = 2.6873
	new_data_grads_norm = 3.4022
	old_data_grads_norm = 3.5716
	sim_grads_norm = 0.1009
-- Starting training on experience 79 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5816
	data_grads_norm = 2.6015
	new_data_grads_norm = 3.1920
	old_data_grads_norm = 3.5876
	sim_grads_norm = 0.0512
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4593
	data_grads_norm = 2.4274
	new_data_grads_norm = 3.0128
	old_data_grads_norm = 2.8745
	sim_grads_norm = 0.1983
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3758
	data_grads_norm = 2.5626
	new_data_grads_norm = 3.0740
	old_data_grads_norm = 3.8659
	sim_grads_norm = -0.0362
-- Starting training on experience 80 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3227
	data_grads_norm = 2.6390
	new_data_grads_norm = 4.0225
	old_data_grads_norm = 3.8562
	sim_grads_norm = -0.1379
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5070
	data_grads_norm = 3.0446
	new_data_grads_norm = 4.0277
	old_data_grads_norm = 3.6752
	sim_grads_norm = 0.1850
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0193
	data_grads_norm = 2.6175
	new_data_grads_norm = 3.8481
	old_data_grads_norm = 3.7095
	sim_grads_norm = -0.0915
-- Starting training on experience 81 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4001
	data_grads_norm = 2.7667
	new_data_grads_norm = 3.8892
	old_data_grads_norm = 3.0014
	sim_grads_norm = 0.2629
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8397
	data_grads_norm = 3.0427
	new_data_grads_norm = 4.1356
	old_data_grads_norm = 3.3459
	sim_grads_norm = 0.1340
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1924
	data_grads_norm = 2.2879
	new_data_grads_norm = 3.9859
	old_data_grads_norm = 2.8142
	sim_grads_norm = -0.0744
-- Starting training on experience 82 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4801
	data_grads_norm = 2.7177
	new_data_grads_norm = 4.2744
	old_data_grads_norm = 3.7755
	sim_grads_norm = 0.0485
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4291
	data_grads_norm = 2.6652
	new_data_grads_norm = 4.3514
	old_data_grads_norm = 3.4525
	sim_grads_norm = 0.0631
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0016
	data_grads_norm = 2.5315
	new_data_grads_norm = 4.0221
	old_data_grads_norm = 2.8413
	sim_grads_norm = -0.0063
-- Starting training on experience 83 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5294
	data_grads_norm = 3.3209
	new_data_grads_norm = 4.2818
	old_data_grads_norm = 4.1467
	sim_grads_norm = 0.0257
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7228
	data_grads_norm = 2.6431
	new_data_grads_norm = 3.5627
	old_data_grads_norm = 3.4080
	sim_grads_norm = 0.0729
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7184
	data_grads_norm = 2.7904
	new_data_grads_norm = 3.6047
	old_data_grads_norm = 3.6210
	sim_grads_norm = 0.0720
-- Starting training on experience 84 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0890
	data_grads_norm = 2.3874
	new_data_grads_norm = 3.1531
	old_data_grads_norm = 3.3861
	sim_grads_norm = 0.0634
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8134
	data_grads_norm = 2.0544
	new_data_grads_norm = 3.6532
	old_data_grads_norm = 2.6634
	sim_grads_norm = -0.0576
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3730
	data_grads_norm = 2.5484
	new_data_grads_norm = 3.8371
	old_data_grads_norm = 3.3926
	sim_grads_norm = 0.0203
-- Starting training on experience 85 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6140
	data_grads_norm = 3.3324
	new_data_grads_norm = 3.2742
	old_data_grads_norm = 5.3203
	sim_grads_norm = 0.1619
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7198
	data_grads_norm = 2.6574
	new_data_grads_norm = 2.9617
	old_data_grads_norm = 4.0206
	sim_grads_norm = -0.0183
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0481
	data_grads_norm = 2.3966
	new_data_grads_norm = 3.7580
	old_data_grads_norm = 3.3556
	sim_grads_norm = -0.1141
-- Starting training on experience 86 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3477
	data_grads_norm = 2.5920
	new_data_grads_norm = 3.8966
	old_data_grads_norm = 3.3075
	sim_grads_norm = -0.0349
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2874
	data_grads_norm = 2.5230
	new_data_grads_norm = 4.0621
	old_data_grads_norm = 3.0137
	sim_grads_norm = 0.0984
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5281
	data_grads_norm = 2.8094
	new_data_grads_norm = 3.7462
	old_data_grads_norm = 3.6494
	sim_grads_norm = -0.0437
-- Starting training on experience 87 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2048
	data_grads_norm = 2.2966
	new_data_grads_norm = 3.4032
	old_data_grads_norm = 3.6570
	sim_grads_norm = -0.1557
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5417
	data_grads_norm = 2.9658
	new_data_grads_norm = 3.4335
	old_data_grads_norm = 4.2068
	sim_grads_norm = 0.0422
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1142
	data_grads_norm = 2.4433
	new_data_grads_norm = 4.0276
	old_data_grads_norm = 3.4478
	sim_grads_norm = -0.0679
-- Starting training on experience 88 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3230
	data_grads_norm = 2.4319
	new_data_grads_norm = 3.4755
	old_data_grads_norm = 3.1808
	sim_grads_norm = 0.0440
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6649
	data_grads_norm = 2.9318
	new_data_grads_norm = 3.5427
	old_data_grads_norm = 3.6446
	sim_grads_norm = 0.2397
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3843
	data_grads_norm = 2.4718
	new_data_grads_norm = 3.3285
	old_data_grads_norm = 3.6519
	sim_grads_norm = -0.0435
-- Starting training on experience 89 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3193
	data_grads_norm = 2.4822
	new_data_grads_norm = 3.1949
	old_data_grads_norm = 4.1094
	sim_grads_norm = 0.0643
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3607
	data_grads_norm = 2.9743
	new_data_grads_norm = 3.1654
	old_data_grads_norm = 4.4335
	sim_grads_norm = 0.0459
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2694
	data_grads_norm = 2.8592
	new_data_grads_norm = 3.0956
	old_data_grads_norm = 3.6038
	sim_grads_norm = -0.0427
-- Starting training on experience 90 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5013
	data_grads_norm = 2.6401
	new_data_grads_norm = 4.5221
	old_data_grads_norm = 2.9553
	sim_grads_norm = -0.0183
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6117
	data_grads_norm = 3.0845
	new_data_grads_norm = 4.6980
	old_data_grads_norm = 3.0931
	sim_grads_norm = 0.0574
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9018
	data_grads_norm = 3.2773
	new_data_grads_norm = 4.2174
	old_data_grads_norm = 4.4661
	sim_grads_norm = 0.0398
-- Starting training on experience 91 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3751
	data_grads_norm = 2.4769
	new_data_grads_norm = 4.3862
	old_data_grads_norm = 2.5712
	sim_grads_norm = 0.1912
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1885
	data_grads_norm = 2.7988
	new_data_grads_norm = 3.9950
	old_data_grads_norm = 4.1710
	sim_grads_norm = 0.0213
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3882
	data_grads_norm = 2.9536
	new_data_grads_norm = 4.2433
	old_data_grads_norm = 3.7161
	sim_grads_norm = 0.0433
-- Starting training on experience 92 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4981
	data_grads_norm = 2.9406
	new_data_grads_norm = 4.4355
	old_data_grads_norm = 3.7466
	sim_grads_norm = -0.0229
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2571
	data_grads_norm = 3.1158
	new_data_grads_norm = 4.2292
	old_data_grads_norm = 3.5149
	sim_grads_norm = 0.1121
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4490
	data_grads_norm = 3.3964
	new_data_grads_norm = 4.5182
	old_data_grads_norm = 4.7495
	sim_grads_norm = -0.0996
-- Starting training on experience 93 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4944
	data_grads_norm = 3.1222
	new_data_grads_norm = 4.2844
	old_data_grads_norm = 3.0591
	sim_grads_norm = 0.4064
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1185
	data_grads_norm = 2.6130
	new_data_grads_norm = 4.1025
	old_data_grads_norm = 3.5371
	sim_grads_norm = 0.0504
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9177
	data_grads_norm = 2.7876
	new_data_grads_norm = 3.5743
	old_data_grads_norm = 4.2611
	sim_grads_norm = -0.0635
-- Starting training on experience 94 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4786
	data_grads_norm = 3.0198
	new_data_grads_norm = 3.8296
	old_data_grads_norm = 4.7089
	sim_grads_norm = 0.0091
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4744
	data_grads_norm = 3.3245
	new_data_grads_norm = 3.9045
	old_data_grads_norm = 3.8551
	sim_grads_norm = 0.0350
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6424
	data_grads_norm = 3.2536
	new_data_grads_norm = 3.9447
	old_data_grads_norm = 3.9072
	sim_grads_norm = 0.1556
-- Starting training on experience 95 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9334
	data_grads_norm = 2.5153
	new_data_grads_norm = 3.7540
	old_data_grads_norm = 3.4836
	sim_grads_norm = -0.0931
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2682
	data_grads_norm = 3.2285
	new_data_grads_norm = 4.1136
	old_data_grads_norm = 3.5656
	sim_grads_norm = 0.0766
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9274
	data_grads_norm = 2.7523
	new_data_grads_norm = 4.1339
	old_data_grads_norm = 4.1312
	sim_grads_norm = -0.0520
-- Starting training on experience 96 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3793
	data_grads_norm = 3.2531
	new_data_grads_norm = 5.4716
	old_data_grads_norm = 4.8777
	sim_grads_norm = -0.1015
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1357
	data_grads_norm = 3.1985
	new_data_grads_norm = 4.8290
	old_data_grads_norm = 4.1154
	sim_grads_norm = -0.0642
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8804
	data_grads_norm = 4.3568
	new_data_grads_norm = 5.3292
	old_data_grads_norm = 5.4738
	sim_grads_norm = 0.1343
-- Starting training on experience 97 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6720
	data_grads_norm = 4.1831
	new_data_grads_norm = 4.6170
	old_data_grads_norm = 6.0429
	sim_grads_norm = 0.0318
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8658
	data_grads_norm = 3.4482
	new_data_grads_norm = 4.7906
	old_data_grads_norm = 5.0336
	sim_grads_norm = 0.0247
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6175
	data_grads_norm = 3.2630
	new_data_grads_norm = 4.9477
	old_data_grads_norm = 4.5966
	sim_grads_norm = 0.0564
-- Starting training on experience 98 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0426
	data_grads_norm = 2.7888
	new_data_grads_norm = 4.0539
	old_data_grads_norm = 4.0083
	sim_grads_norm = 0.0612
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9690
	data_grads_norm = 2.5284
	new_data_grads_norm = 4.1990
	old_data_grads_norm = 2.7777
	sim_grads_norm = -0.0425
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4935
	data_grads_norm = 3.6032
	new_data_grads_norm = 4.4996
	old_data_grads_norm = 4.4970
	sim_grads_norm = 0.0180
-- Starting training on experience 99 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4628
	data_grads_norm = 2.6804
	new_data_grads_norm = 2.9287
	old_data_grads_norm = 3.6931
	sim_grads_norm = 0.0137
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3087
	data_grads_norm = 2.5417
	new_data_grads_norm = 3.1708
	old_data_grads_norm = 3.5326
	sim_grads_norm = 0.1089
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4693
	data_grads_norm = 2.5590
	new_data_grads_norm = 2.6508
	old_data_grads_norm = 4.6572
	sim_grads_norm = 0.0984
-- Starting training on experience 100 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2080
	data_grads_norm = 2.5045
	new_data_grads_norm = 3.9586
	old_data_grads_norm = 3.6381
	sim_grads_norm = 0.0101
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5729
	data_grads_norm = 3.3550
	new_data_grads_norm = 4.3475
	old_data_grads_norm = 4.9121
	sim_grads_norm = 0.0831
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2541
	data_grads_norm = 3.4742
	new_data_grads_norm = 5.3472
	old_data_grads_norm = 3.3794
	sim_grads_norm = -0.0745
-- Starting training on experience 101 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3357
	data_grads_norm = 2.6866
	new_data_grads_norm = 4.1672
	old_data_grads_norm = 3.6777
	sim_grads_norm = -0.0415
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4416
	data_grads_norm = 2.8984
	new_data_grads_norm = 4.0598
	old_data_grads_norm = 3.4260
	sim_grads_norm = 0.0448
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4764
	data_grads_norm = 3.3942
	new_data_grads_norm = 4.6096
	old_data_grads_norm = 5.1269
	sim_grads_norm = 0.0383
-- Starting training on experience 102 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3926
	data_grads_norm = 2.2684
	new_data_grads_norm = 3.3214
	old_data_grads_norm = 3.1403
	sim_grads_norm = -0.0259
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4317
	data_grads_norm = 2.2563
	new_data_grads_norm = 3.3061
	old_data_grads_norm = 3.3900
	sim_grads_norm = -0.0169
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3757
	data_grads_norm = 2.3263
	new_data_grads_norm = 3.4474
	old_data_grads_norm = 2.8325
	sim_grads_norm = -0.0491
-- Starting training on experience 103 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6258
	data_grads_norm = 2.4911
	new_data_grads_norm = 3.0967
	old_data_grads_norm = 3.3415
	sim_grads_norm = 0.1268
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2759
	data_grads_norm = 2.5121
	new_data_grads_norm = 3.1103
	old_data_grads_norm = 4.6021
	sim_grads_norm = -0.0542
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5520
	data_grads_norm = 2.8002
	new_data_grads_norm = 3.3559
	old_data_grads_norm = 4.3360
	sim_grads_norm = -0.0723
-- Starting training on experience 104 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4658
	data_grads_norm = 2.4721
	new_data_grads_norm = 4.3457
	old_data_grads_norm = 2.9949
	sim_grads_norm = 0.0179
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5666
	data_grads_norm = 2.8175
	new_data_grads_norm = 4.3495
	old_data_grads_norm = 3.1509
	sim_grads_norm = 0.0986
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7229
	data_grads_norm = 3.2129
	new_data_grads_norm = 4.0645
	old_data_grads_norm = 4.3223
	sim_grads_norm = 0.0502
-- Starting training on experience 105 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3841
	data_grads_norm = 3.1208
	new_data_grads_norm = 4.4378
	old_data_grads_norm = 4.1087
	sim_grads_norm = 0.1130
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2984
	data_grads_norm = 3.0118
	new_data_grads_norm = 4.4251
	old_data_grads_norm = 2.9654
	sim_grads_norm = 0.0730
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8252
	data_grads_norm = 3.3274
	new_data_grads_norm = 4.8273
	old_data_grads_norm = 3.9155
	sim_grads_norm = 0.1618
-- Starting training on experience 106 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6703
	data_grads_norm = 2.8278
	new_data_grads_norm = 3.4956
	old_data_grads_norm = 4.1512
	sim_grads_norm = -0.0059
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1253
	data_grads_norm = 2.5481
	new_data_grads_norm = 3.7344
	old_data_grads_norm = 3.8610
	sim_grads_norm = -0.1223
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2714
	data_grads_norm = 2.6484
	new_data_grads_norm = 3.6856
	old_data_grads_norm = 3.7584
	sim_grads_norm = -0.0580
-- Starting training on experience 107 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9397
	data_grads_norm = 3.3584
	new_data_grads_norm = 3.9843
	old_data_grads_norm = 4.3602
	sim_grads_norm = 0.1816
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9900
	data_grads_norm = 2.4637
	new_data_grads_norm = 3.7200
	old_data_grads_norm = 3.3945
	sim_grads_norm = -0.0318
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5463
	data_grads_norm = 2.8354
	new_data_grads_norm = 4.3532
	old_data_grads_norm = 3.6365
	sim_grads_norm = -0.0045
-- Starting training on experience 108 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3250
	data_grads_norm = 2.6955
	new_data_grads_norm = 4.7535
	old_data_grads_norm = 3.7883
	sim_grads_norm = -0.0085
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3106
	data_grads_norm = 2.9344
	new_data_grads_norm = 4.4768
	old_data_grads_norm = 4.0096
	sim_grads_norm = 0.0288
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5608
	data_grads_norm = 2.8906
	new_data_grads_norm = 4.7751
	old_data_grads_norm = 4.0850
	sim_grads_norm = -0.0366
-- Starting training on experience 109 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0213
	data_grads_norm = 3.3149
	new_data_grads_norm = 4.3855
	old_data_grads_norm = 3.9540
	sim_grads_norm = 0.0715
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3172
	data_grads_norm = 2.7650
	new_data_grads_norm = 3.9552
	old_data_grads_norm = 3.6051
	sim_grads_norm = 0.0550
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1612
	data_grads_norm = 2.9583
	new_data_grads_norm = 4.2548
	old_data_grads_norm = 3.7508
	sim_grads_norm = -0.0434
-- Starting training on experience 110 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6458
	data_grads_norm = 2.8562
	new_data_grads_norm = 3.9337
	old_data_grads_norm = 3.7699
	sim_grads_norm = 0.0796
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5816
	data_grads_norm = 3.3075
	new_data_grads_norm = 3.9110
	old_data_grads_norm = 4.2525
	sim_grads_norm = 0.0169
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8409
	data_grads_norm = 3.1286
	new_data_grads_norm = 4.1599
	old_data_grads_norm = 4.2969
	sim_grads_norm = 0.0129
-- Starting training on experience 111 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1523
	data_grads_norm = 2.7387
	new_data_grads_norm = 3.2773
	old_data_grads_norm = 4.0297
	sim_grads_norm = 0.0999
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0275
	data_grads_norm = 2.5009
	new_data_grads_norm = 3.2006
	old_data_grads_norm = 3.8859
	sim_grads_norm = -0.0272
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4735
	data_grads_norm = 3.0277
	new_data_grads_norm = 4.2589
	old_data_grads_norm = 3.9996
	sim_grads_norm = 0.0258
-- Starting training on experience 112 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2491
	data_grads_norm = 2.6136
	new_data_grads_norm = 3.7589
	old_data_grads_norm = 3.6310
	sim_grads_norm = -0.1258
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2541
	data_grads_norm = 2.6784
	new_data_grads_norm = 3.7604
	old_data_grads_norm = 3.1937
	sim_grads_norm = 0.0585
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2445
	data_grads_norm = 2.4377
	new_data_grads_norm = 3.8510
	old_data_grads_norm = 3.2377
	sim_grads_norm = -0.0111
-- Starting training on experience 113 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4812
	data_grads_norm = 2.9475
	new_data_grads_norm = 3.2616
	old_data_grads_norm = 4.5163
	sim_grads_norm = -0.0321
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2611
	data_grads_norm = 2.9436
	new_data_grads_norm = 3.4894
	old_data_grads_norm = 4.3657
	sim_grads_norm = 0.0588
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8652
	data_grads_norm = 2.3944
	new_data_grads_norm = 3.4939
	old_data_grads_norm = 2.9958
	sim_grads_norm = 0.0950
-- Starting training on experience 114 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0793
	data_grads_norm = 2.7062
	new_data_grads_norm = 4.1316
	old_data_grads_norm = 4.0187
	sim_grads_norm = -0.1370
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2848
	data_grads_norm = 2.9961
	new_data_grads_norm = 4.2843
	old_data_grads_norm = 3.7151
	sim_grads_norm = 0.0393
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0050
	data_grads_norm = 2.5881
	new_data_grads_norm = 4.0138
	old_data_grads_norm = 2.8055
	sim_grads_norm = -0.0081
-- Starting training on experience 115 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4776
	data_grads_norm = 2.5376
	new_data_grads_norm = 4.0977
	old_data_grads_norm = 2.9856
	sim_grads_norm = -0.0378
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2358
	data_grads_norm = 2.2279
	new_data_grads_norm = 4.1080
	old_data_grads_norm = 2.3518
	sim_grads_norm = -0.0769
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0801
	data_grads_norm = 3.2710
	new_data_grads_norm = 4.3037
	old_data_grads_norm = 4.1597
	sim_grads_norm = 0.0489
-- Starting training on experience 116 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2605
	data_grads_norm = 3.5412
	new_data_grads_norm = 5.5498
	old_data_grads_norm = 4.6757
	sim_grads_norm = -0.0534
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4522
	data_grads_norm = 3.1621
	new_data_grads_norm = 4.8118
	old_data_grads_norm = 4.2231
	sim_grads_norm = -0.0268
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5037
	data_grads_norm = 3.6976
	new_data_grads_norm = 5.3027
	old_data_grads_norm = 4.5413
	sim_grads_norm = -0.0591
-- Starting training on experience 117 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6141
	data_grads_norm = 3.4528
	new_data_grads_norm = 5.5936
	old_data_grads_norm = 4.8742
	sim_grads_norm = 0.0734
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9811
	data_grads_norm = 3.5489
	new_data_grads_norm = 4.5101
	old_data_grads_norm = 5.2969
	sim_grads_norm = 0.1296
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2648
	data_grads_norm = 3.1805
	new_data_grads_norm = 4.3729
	old_data_grads_norm = 3.4532
	sim_grads_norm = 0.0534
-- Starting training on experience 118 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8278
	data_grads_norm = 3.3015
	new_data_grads_norm = 5.3732
	old_data_grads_norm = 3.9026
	sim_grads_norm = -0.0306
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3504
	data_grads_norm = 2.9971
	new_data_grads_norm = 5.1072
	old_data_grads_norm = 3.1110
	sim_grads_norm = -0.0949
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7001
	data_grads_norm = 3.4975
	new_data_grads_norm = 5.1817
	old_data_grads_norm = 4.6984
	sim_grads_norm = 0.0160
-- Starting training on experience 119 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7877
	data_grads_norm = 3.1505
	new_data_grads_norm = 3.8342
	old_data_grads_norm = 5.1420
	sim_grads_norm = 0.0691
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6550
	data_grads_norm = 2.8323
	new_data_grads_norm = 3.6465
	old_data_grads_norm = 3.8060
	sim_grads_norm = -0.0805
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5564
	data_grads_norm = 2.5728
	new_data_grads_norm = 4.0266
	old_data_grads_norm = 3.0557
	sim_grads_norm = -0.0109
-- Starting training on experience 120 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2529
	data_grads_norm = 3.1428
	new_data_grads_norm = 4.3473
	old_data_grads_norm = 4.1594
	sim_grads_norm = -0.0248
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1181
	data_grads_norm = 2.9341
	new_data_grads_norm = 4.5965
	old_data_grads_norm = 3.8194
	sim_grads_norm = 0.1820
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2808
	data_grads_norm = 2.9780
	new_data_grads_norm = 4.0574
	old_data_grads_norm = 3.9732
	sim_grads_norm = 0.0383
-- Starting training on experience 121 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6392
	data_grads_norm = 2.6676
	new_data_grads_norm = 3.4751
	old_data_grads_norm = 3.6625
	sim_grads_norm = 0.0991
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4167
	data_grads_norm = 2.9153
	new_data_grads_norm = 3.5374
	old_data_grads_norm = 4.0538
	sim_grads_norm = 0.1495
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9228
	data_grads_norm = 2.4503
	new_data_grads_norm = 3.5529
	old_data_grads_norm = 3.6156
	sim_grads_norm = -0.0601
-- Starting training on experience 122 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9558
	data_grads_norm = 3.3475
	new_data_grads_norm = 4.3663
	old_data_grads_norm = 4.8878
	sim_grads_norm = -0.0001
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8356
	data_grads_norm = 2.6291
	new_data_grads_norm = 3.9550
	old_data_grads_norm = 3.1587
	sim_grads_norm = 0.0260
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2945
	data_grads_norm = 3.0357
	new_data_grads_norm = 4.2214
	old_data_grads_norm = 4.6110
	sim_grads_norm = -0.1114
-- Starting training on experience 123 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3993
	data_grads_norm = 2.8440
	new_data_grads_norm = 4.0187
	old_data_grads_norm = 4.4655
	sim_grads_norm = -0.0864
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7154
	data_grads_norm = 3.7746
	new_data_grads_norm = 4.6535
	old_data_grads_norm = 5.9192
	sim_grads_norm = 0.0841
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2367
	data_grads_norm = 2.9942
	new_data_grads_norm = 4.6137
	old_data_grads_norm = 4.0960
	sim_grads_norm = 0.0042
-- Starting training on experience 124 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5938
	data_grads_norm = 2.7242
	new_data_grads_norm = 4.0306
	old_data_grads_norm = 3.8263
	sim_grads_norm = -0.0058
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7535
	data_grads_norm = 2.8948
	new_data_grads_norm = 4.0707
	old_data_grads_norm = 3.8497
	sim_grads_norm = 0.0497
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3115
	data_grads_norm = 2.7415
	new_data_grads_norm = 3.9863
	old_data_grads_norm = 3.5603
	sim_grads_norm = 0.0769
-- Starting training on experience 125 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3954
	data_grads_norm = 3.3212
	new_data_grads_norm = 4.5632
	old_data_grads_norm = 4.2160
	sim_grads_norm = 0.1268
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5046
	data_grads_norm = 2.5571
	new_data_grads_norm = 4.0262
	old_data_grads_norm = 3.4373
	sim_grads_norm = 0.0042
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7032
	data_grads_norm = 2.8217
	new_data_grads_norm = 3.7772
	old_data_grads_norm = 4.1443
	sim_grads_norm = 0.0306
-- Starting training on experience 126 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4454
	data_grads_norm = 2.9834
	new_data_grads_norm = 3.7432
	old_data_grads_norm = 4.3928
	sim_grads_norm = 0.0663
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4413
	data_grads_norm = 2.7002
	new_data_grads_norm = 3.3426
	old_data_grads_norm = 3.6182
	sim_grads_norm = 0.0948
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0883
	data_grads_norm = 2.6854
	new_data_grads_norm = 3.5668
	old_data_grads_norm = 3.7907
	sim_grads_norm = -0.0938
-- Starting training on experience 127 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3960
	data_grads_norm = 2.8825
	new_data_grads_norm = 3.6996
	old_data_grads_norm = 4.0794
	sim_grads_norm = 0.0341
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0560
	data_grads_norm = 2.5971
	new_data_grads_norm = 4.1154
	old_data_grads_norm = 2.9308
	sim_grads_norm = -0.0207
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0222
	data_grads_norm = 2.5589
	new_data_grads_norm = 4.0578
	old_data_grads_norm = 2.9292
	sim_grads_norm = -0.0214
-- Starting training on experience 128 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2446
	data_grads_norm = 2.8084
	new_data_grads_norm = 4.0357
	old_data_grads_norm = 2.7432
	sim_grads_norm = 0.2197
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2276
	data_grads_norm = 2.4853
	new_data_grads_norm = 3.8624
	old_data_grads_norm = 4.1889
	sim_grads_norm = -0.0899
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4160
	data_grads_norm = 2.7115
	new_data_grads_norm = 4.8244
	old_data_grads_norm = 2.7494
	sim_grads_norm = 0.0105
-- Starting training on experience 129 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4037
	data_grads_norm = 3.1599
	new_data_grads_norm = 3.7659
	old_data_grads_norm = 4.7099
	sim_grads_norm = -0.0041
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6375
	data_grads_norm = 3.6718
	new_data_grads_norm = 3.7899
	old_data_grads_norm = 4.3035
	sim_grads_norm = 0.1405
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1581
	data_grads_norm = 3.0298
	new_data_grads_norm = 4.5230
	old_data_grads_norm = 3.4489
	sim_grads_norm = 0.0002
-- Starting training on experience 130 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1778
	data_grads_norm = 2.6391
	new_data_grads_norm = 4.2426
	old_data_grads_norm = 4.0238
	sim_grads_norm = -0.1255
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4663
	data_grads_norm = 2.9089
	new_data_grads_norm = 5.1547
	old_data_grads_norm = 2.9100
	sim_grads_norm = 0.1782
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6075
	data_grads_norm = 3.6791
	new_data_grads_norm = 4.6584
	old_data_grads_norm = 5.1524
	sim_grads_norm = -0.0039
-- Starting training on experience 131 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1638
	data_grads_norm = 2.7777
	new_data_grads_norm = 4.7760
	old_data_grads_norm = 3.2953
	sim_grads_norm = 0.0276
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6344
	data_grads_norm = 3.2939
	new_data_grads_norm = 4.8858
	old_data_grads_norm = 4.0455
	sim_grads_norm = 0.0595
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0861
	data_grads_norm = 2.7849
	new_data_grads_norm = 4.4695
	old_data_grads_norm = 4.1976
	sim_grads_norm = -0.0343
-- Starting training on experience 132 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6077
	data_grads_norm = 3.4621
	new_data_grads_norm = 4.0541
	old_data_grads_norm = 4.5172
	sim_grads_norm = -0.0242
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1928
	data_grads_norm = 2.8983
	new_data_grads_norm = 4.3755
	old_data_grads_norm = 3.7914
	sim_grads_norm = 0.0463
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2584
	data_grads_norm = 2.8908
	new_data_grads_norm = 4.7373
	old_data_grads_norm = 3.6097
	sim_grads_norm = -0.0692
-- Starting training on experience 133 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1420
	data_grads_norm = 3.1240
	new_data_grads_norm = 4.3914
	old_data_grads_norm = 4.4829
	sim_grads_norm = -0.0973
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2533
	data_grads_norm = 3.4769
	new_data_grads_norm = 5.3445
	old_data_grads_norm = 4.0576
	sim_grads_norm = 0.0902
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2831
	data_grads_norm = 2.8835
	new_data_grads_norm = 4.9713
	old_data_grads_norm = 3.7957
	sim_grads_norm = -0.0758
-- Starting training on experience 134 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5833
	data_grads_norm = 3.4493
	new_data_grads_norm = 5.0548
	old_data_grads_norm = 4.3561
	sim_grads_norm = -0.0737
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4378
	data_grads_norm = 3.7605
	new_data_grads_norm = 4.3414
	old_data_grads_norm = 4.8749
	sim_grads_norm = 0.0505
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9789
	data_grads_norm = 3.3385
	new_data_grads_norm = 4.2672
	old_data_grads_norm = 4.4429
	sim_grads_norm = 0.0136
-- Starting training on experience 135 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6108
	data_grads_norm = 3.4578
	new_data_grads_norm = 5.0989
	old_data_grads_norm = 3.4114
	sim_grads_norm = 0.0248
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6504
	data_grads_norm = 3.3254
	new_data_grads_norm = 5.1741
	old_data_grads_norm = 4.5166
	sim_grads_norm = 0.0002
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2016
	data_grads_norm = 4.1513
	new_data_grads_norm = 5.4217
	old_data_grads_norm = 4.9186
	sim_grads_norm = 0.2814
-- Starting training on experience 136 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6560
	data_grads_norm = 3.0127
	new_data_grads_norm = 4.4140
	old_data_grads_norm = 3.5718
	sim_grads_norm = 0.1558
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3357
	data_grads_norm = 2.5863
	new_data_grads_norm = 3.9579
	old_data_grads_norm = 4.2729
	sim_grads_norm = 0.0415
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4316
	data_grads_norm = 2.6743
	new_data_grads_norm = 3.7946
	old_data_grads_norm = 3.5594
	sim_grads_norm = 0.1575
-- Starting training on experience 137 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1042
	data_grads_norm = 3.4313
	new_data_grads_norm = 4.8944
	old_data_grads_norm = 5.2756
	sim_grads_norm = -0.0394
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1836
	data_grads_norm = 2.9816
	new_data_grads_norm = 4.1783
	old_data_grads_norm = 3.8027
	sim_grads_norm = 0.0786
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4011
	data_grads_norm = 3.3086
	new_data_grads_norm = 4.2640
	old_data_grads_norm = 4.4884
	sim_grads_norm = 0.0096
-- Starting training on experience 138 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8819
	data_grads_norm = 2.9689
	new_data_grads_norm = 3.8760
	old_data_grads_norm = 4.3202
	sim_grads_norm = 0.1124
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2332
	data_grads_norm = 2.4019
	new_data_grads_norm = 3.9044
	old_data_grads_norm = 3.4112
	sim_grads_norm = -0.0363
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5246
	data_grads_norm = 3.3279
	new_data_grads_norm = 4.2744
	old_data_grads_norm = 4.8384
	sim_grads_norm = -0.0422
-- Starting training on experience 139 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2334
	data_grads_norm = 2.7982
	new_data_grads_norm = 4.2576
	old_data_grads_norm = 3.1575
	sim_grads_norm = 0.0893
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6763
	data_grads_norm = 3.3861
	new_data_grads_norm = 4.6294
	old_data_grads_norm = 4.4877
	sim_grads_norm = 0.1241
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1725
	data_grads_norm = 2.7786
	new_data_grads_norm = 4.5937
	old_data_grads_norm = 2.8785
	sim_grads_norm = -0.0610
-- Starting training on experience 140 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9562
	data_grads_norm = 3.6228
	new_data_grads_norm = 4.6727
	old_data_grads_norm = 4.5577
	sim_grads_norm = 0.1635
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1260
	data_grads_norm = 2.5635
	new_data_grads_norm = 3.8275
	old_data_grads_norm = 3.2692
	sim_grads_norm = -0.0652
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5653
	data_grads_norm = 2.8741
	new_data_grads_norm = 3.9140
	old_data_grads_norm = 4.8015
	sim_grads_norm = -0.0768
-- Starting training on experience 141 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2305
	data_grads_norm = 3.0719
	new_data_grads_norm = 4.6499
	old_data_grads_norm = 4.2490
	sim_grads_norm = 0.0027
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8904
	data_grads_norm = 2.9228
	new_data_grads_norm = 4.3774
	old_data_grads_norm = 3.7565
	sim_grads_norm = -0.0086
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3325
	data_grads_norm = 2.9545
	new_data_grads_norm = 4.8191
	old_data_grads_norm = 3.5451
	sim_grads_norm = 0.0063
-- Starting training on experience 142 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1053
	data_grads_norm = 3.1585
	new_data_grads_norm = 4.2402
	old_data_grads_norm = 4.3999
	sim_grads_norm = 0.0652
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7128
	data_grads_norm = 2.7311
	new_data_grads_norm = 3.4795
	old_data_grads_norm = 4.3194
	sim_grads_norm = -0.0562
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2086
	data_grads_norm = 2.9180
	new_data_grads_norm = 3.8720
	old_data_grads_norm = 3.6898
	sim_grads_norm = 0.1536
-- Starting training on experience 143 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1150
	data_grads_norm = 2.5402
	new_data_grads_norm = 4.6464
	old_data_grads_norm = 4.7134
	sim_grads_norm = -0.0688
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6115
	data_grads_norm = 3.6656
	new_data_grads_norm = 5.3993
	old_data_grads_norm = 4.4806
	sim_grads_norm = 0.0865
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2830
	data_grads_norm = 2.6594
	new_data_grads_norm = 5.1304
	old_data_grads_norm = 3.8763
	sim_grads_norm = -0.0488
-- Starting training on experience 144 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3826
	data_grads_norm = 3.1180
	new_data_grads_norm = 4.6631
	old_data_grads_norm = 3.9639
	sim_grads_norm = -0.0391
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8856
	data_grads_norm = 3.5268
	new_data_grads_norm = 4.6613
	old_data_grads_norm = 3.7720
	sim_grads_norm = 0.1807
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9293
	data_grads_norm = 3.2996
	new_data_grads_norm = 4.1200
	old_data_grads_norm = 3.9805
	sim_grads_norm = 0.2173
-- Starting training on experience 145 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4528
	data_grads_norm = 3.0981
	new_data_grads_norm = 4.2902
	old_data_grads_norm = 4.5040
	sim_grads_norm = -0.0182
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0038
	data_grads_norm = 2.5037
	new_data_grads_norm = 3.9984
	old_data_grads_norm = 3.4743
	sim_grads_norm = 0.0221
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2521
	data_grads_norm = 2.7424
	new_data_grads_norm = 4.9487
	old_data_grads_norm = 3.3509
	sim_grads_norm = -0.0107
-- Starting training on experience 146 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3664
	data_grads_norm = 3.1661
	new_data_grads_norm = 3.8230
	old_data_grads_norm = 4.3637
	sim_grads_norm = 0.0899
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1702
	data_grads_norm = 2.7483
	new_data_grads_norm = 3.7855
	old_data_grads_norm = 4.0401
	sim_grads_norm = 0.0123
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3774
	data_grads_norm = 2.6961
	new_data_grads_norm = 3.3764
	old_data_grads_norm = 3.3006
	sim_grads_norm = 0.1433
-- Starting training on experience 147 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2548
	data_grads_norm = 2.4971
	new_data_grads_norm = 3.7444
	old_data_grads_norm = 3.1156
	sim_grads_norm = -0.0843
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9452
	data_grads_norm = 3.5650
	new_data_grads_norm = 4.3557
	old_data_grads_norm = 4.7488
	sim_grads_norm = -0.0143
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6230
	data_grads_norm = 2.8906
	new_data_grads_norm = 4.0675
	old_data_grads_norm = 3.3634
	sim_grads_norm = 0.1495
-- Starting training on experience 148 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9782
	data_grads_norm = 2.2827
	new_data_grads_norm = 3.0422
	old_data_grads_norm = 3.4714
	sim_grads_norm = -0.1716
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1980
	data_grads_norm = 2.9200
	new_data_grads_norm = 3.4492
	old_data_grads_norm = 4.9229
	sim_grads_norm = -0.0061
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1586
	data_grads_norm = 2.7711
	new_data_grads_norm = 3.3684
	old_data_grads_norm = 4.0898
	sim_grads_norm = 0.0419
-- Starting training on experience 149 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4725
	data_grads_norm = 2.9024
	new_data_grads_norm = 4.4734
	old_data_grads_norm = 2.8446
	sim_grads_norm = 0.0859
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2425
	data_grads_norm = 2.9968
	new_data_grads_norm = 4.4331
	old_data_grads_norm = 3.6999
	sim_grads_norm = 0.0080
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5911
	data_grads_norm = 3.3102
	new_data_grads_norm = 4.0782
	old_data_grads_norm = 4.4547
	sim_grads_norm = 0.1478
-- Starting training on experience 150 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3301
	data_grads_norm = 2.5401
	new_data_grads_norm = 3.5975
	old_data_grads_norm = 3.6109
	sim_grads_norm = 0.0535
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2478
	data_grads_norm = 2.4702
	new_data_grads_norm = 3.4272
	old_data_grads_norm = 3.2762
	sim_grads_norm = 0.0142
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8253
	data_grads_norm = 2.6718
	new_data_grads_norm = 3.5273
	old_data_grads_norm = 3.3752
	sim_grads_norm = 0.0726
-- Starting training on experience 151 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5247
	data_grads_norm = 3.0842
	new_data_grads_norm = 4.5655
	old_data_grads_norm = 3.9730
	sim_grads_norm = -0.0126
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0803
	data_grads_norm = 2.9649
	new_data_grads_norm = 4.5288
	old_data_grads_norm = 3.6480
	sim_grads_norm = 0.0332
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0612
	data_grads_norm = 2.5865
	new_data_grads_norm = 4.8882
	old_data_grads_norm = 3.1887
	sim_grads_norm = -0.0282
-- Starting training on experience 152 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9338
	data_grads_norm = 3.0566
	new_data_grads_norm = 4.8737
	old_data_grads_norm = 4.1392
	sim_grads_norm = -0.0436
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0636
	data_grads_norm = 3.9445
	new_data_grads_norm = 5.0346
	old_data_grads_norm = 4.9377
	sim_grads_norm = 0.1751
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2936
	data_grads_norm = 2.7814
	new_data_grads_norm = 3.9927
	old_data_grads_norm = 3.6535
	sim_grads_norm = 0.0290
-- Starting training on experience 153 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8666
	data_grads_norm = 2.2073
	new_data_grads_norm = 3.9353
	old_data_grads_norm = 2.6060
	sim_grads_norm = 0.0295
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4703
	data_grads_norm = 3.3411
	new_data_grads_norm = 4.6240
	old_data_grads_norm = 3.6023
	sim_grads_norm = 0.2328
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2347
	data_grads_norm = 2.8813
	new_data_grads_norm = 3.8051
	old_data_grads_norm = 4.4144
	sim_grads_norm = 0.0356
-- Starting training on experience 154 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9958
	data_grads_norm = 2.5325
	new_data_grads_norm = 3.5136
	old_data_grads_norm = 3.1306
	sim_grads_norm = 0.0982
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4591
	data_grads_norm = 1.8290
	new_data_grads_norm = 3.3204
	old_data_grads_norm = 2.6053
	sim_grads_norm = -0.1065
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9777
	data_grads_norm = 2.6885
	new_data_grads_norm = 3.4710
	old_data_grads_norm = 3.9778
	sim_grads_norm = -0.0868
-- Starting training on experience 155 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5073
	data_grads_norm = 2.9876
	new_data_grads_norm = 4.7678
	old_data_grads_norm = 4.3716
	sim_grads_norm = 0.0169
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6216
	data_grads_norm = 3.0966
	new_data_grads_norm = 4.2569
	old_data_grads_norm = 4.8253
	sim_grads_norm = -0.0436
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4198
	data_grads_norm = 2.8968
	new_data_grads_norm = 4.3366
	old_data_grads_norm = 3.0035
	sim_grads_norm = 0.0679
-- Starting training on experience 156 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3031
	data_grads_norm = 3.2495
	new_data_grads_norm = 3.9509
	old_data_grads_norm = 5.5977
	sim_grads_norm = 0.0173
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5889
	data_grads_norm = 3.2790
	new_data_grads_norm = 4.6655
	old_data_grads_norm = 4.0568
	sim_grads_norm = -0.0457
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4460
	data_grads_norm = 3.1226
	new_data_grads_norm = 4.7810
	old_data_grads_norm = 3.4739
	sim_grads_norm = 0.0379
-- Starting training on experience 157 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0819
	data_grads_norm = 2.7352
	new_data_grads_norm = 4.9377
	old_data_grads_norm = 3.8337
	sim_grads_norm = 0.0069
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1328
	data_grads_norm = 2.8798
	new_data_grads_norm = 4.7430
	old_data_grads_norm = 2.7088
	sim_grads_norm = 0.3165
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4589
	data_grads_norm = 2.9152
	new_data_grads_norm = 4.1169
	old_data_grads_norm = 4.1372
	sim_grads_norm = -0.0487
-- Starting training on experience 158 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7336
	data_grads_norm = 2.3654
	new_data_grads_norm = 3.7103
	old_data_grads_norm = 3.2262
	sim_grads_norm = -0.0234
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4037
	data_grads_norm = 3.6928
	new_data_grads_norm = 3.7732
	old_data_grads_norm = 5.3660
	sim_grads_norm = 0.1946
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4414
	data_grads_norm = 3.0313
	new_data_grads_norm = 3.5071
	old_data_grads_norm = 4.7167
	sim_grads_norm = 0.0127
-- Starting training on experience 159 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8667
	data_grads_norm = 3.0003
	new_data_grads_norm = 4.1541
	old_data_grads_norm = 3.3979
	sim_grads_norm = -0.0594
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0223
	data_grads_norm = 2.9467
	new_data_grads_norm = 4.2737
	old_data_grads_norm = 3.9305
	sim_grads_norm = 0.0122
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9438
	data_grads_norm = 3.3072
	new_data_grads_norm = 4.2942
	old_data_grads_norm = 4.6856
	sim_grads_norm = 0.0314
-- Starting training on experience 160 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2805
	data_grads_norm = 3.1754
	new_data_grads_norm = 4.2939
	old_data_grads_norm = 4.4834
	sim_grads_norm = 0.0073
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0971
	data_grads_norm = 2.9352
	new_data_grads_norm = 4.3924
	old_data_grads_norm = 4.0376
	sim_grads_norm = 0.0924
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4037
	data_grads_norm = 3.3741
	new_data_grads_norm = 4.9243
	old_data_grads_norm = 4.2572
	sim_grads_norm = 0.0205
-- Starting training on experience 161 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0556
	data_grads_norm = 2.8731
	new_data_grads_norm = 4.1754
	old_data_grads_norm = 3.6284
	sim_grads_norm = 0.1805
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9054
	data_grads_norm = 2.5768
	new_data_grads_norm = 4.0242
	old_data_grads_norm = 2.7100
	sim_grads_norm = 0.1138
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5461
	data_grads_norm = 2.4248
	new_data_grads_norm = 3.9552
	old_data_grads_norm = 3.8074
	sim_grads_norm = -0.0013
-- Starting training on experience 162 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1571
	data_grads_norm = 3.0829
	new_data_grads_norm = 4.7972
	old_data_grads_norm = 3.4969
	sim_grads_norm = -0.0028
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4531
	data_grads_norm = 3.5258
	new_data_grads_norm = 4.8912
	old_data_grads_norm = 4.2748
	sim_grads_norm = -0.0799
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7954
	data_grads_norm = 3.4173
	new_data_grads_norm = 4.9395
	old_data_grads_norm = 3.8038
	sim_grads_norm = 0.0628
-- Starting training on experience 163 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8656
	data_grads_norm = 3.9411
	new_data_grads_norm = 5.6101
	old_data_grads_norm = 6.4084
	sim_grads_norm = -0.0083
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8062
	data_grads_norm = 4.2845
	new_data_grads_norm = 6.0982
	old_data_grads_norm = 4.6405
	sim_grads_norm = 0.1893
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5111
	data_grads_norm = 3.7901
	new_data_grads_norm = 5.4862
	old_data_grads_norm = 4.9381
	sim_grads_norm = 0.1408
-- Starting training on experience 164 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9849
	data_grads_norm = 2.7418
	new_data_grads_norm = 3.9655
	old_data_grads_norm = 2.8722
	sim_grads_norm = 0.0222
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5160
	data_grads_norm = 3.2911
	new_data_grads_norm = 4.3684
	old_data_grads_norm = 4.2460
	sim_grads_norm = -0.0093
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5237
	data_grads_norm = 3.0052
	new_data_grads_norm = 3.7482
	old_data_grads_norm = 4.0191
	sim_grads_norm = 0.1188
-- Starting training on experience 165 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9964
	data_grads_norm = 3.0412
	new_data_grads_norm = 4.4830
	old_data_grads_norm = 4.2308
	sim_grads_norm = -0.0394
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4491
	data_grads_norm = 2.7075
	new_data_grads_norm = 4.2559
	old_data_grads_norm = 3.7756
	sim_grads_norm = 0.0079
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2274
	data_grads_norm = 2.3106
	new_data_grads_norm = 4.1375
	old_data_grads_norm = 2.5438
	sim_grads_norm = 0.0034
-- Starting training on experience 166 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6567
	data_grads_norm = 3.2341
	new_data_grads_norm = 3.8847
	old_data_grads_norm = 4.7652
	sim_grads_norm = 0.0284
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2696
	data_grads_norm = 2.8547
	new_data_grads_norm = 3.9266
	old_data_grads_norm = 3.5744
	sim_grads_norm = 0.0419
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8568
	data_grads_norm = 3.2638
	new_data_grads_norm = 3.8318
	old_data_grads_norm = 4.1956
	sim_grads_norm = 0.2410
-- Starting training on experience 167 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0579
	data_grads_norm = 3.2804
	new_data_grads_norm = 3.9535
	old_data_grads_norm = 5.2317
	sim_grads_norm = -0.0899
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3976
	data_grads_norm = 3.5203
	new_data_grads_norm = 4.1557
	old_data_grads_norm = 5.8807
	sim_grads_norm = 0.1240
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0952
	data_grads_norm = 2.5304
	new_data_grads_norm = 3.7204
	old_data_grads_norm = 3.3218
	sim_grads_norm = -0.0360
-- Starting training on experience 168 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2921
	data_grads_norm = 3.1418
	new_data_grads_norm = 4.2207
	old_data_grads_norm = 4.6426
	sim_grads_norm = -0.0353
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0785
	data_grads_norm = 3.9121
	new_data_grads_norm = 4.5383
	old_data_grads_norm = 5.3228
	sim_grads_norm = 0.1681
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8889
	data_grads_norm = 2.6910
	new_data_grads_norm = 3.8252
	old_data_grads_norm = 3.4331
	sim_grads_norm = -0.0113
-- Starting training on experience 169 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4449
	data_grads_norm = 2.7779
	new_data_grads_norm = 3.5216
	old_data_grads_norm = 3.7928
	sim_grads_norm = -0.0450
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4086
	data_grads_norm = 2.7010
	new_data_grads_norm = 4.1110
	old_data_grads_norm = 3.3504
	sim_grads_norm = -0.0500
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2171
	data_grads_norm = 2.8934
	new_data_grads_norm = 3.9960
	old_data_grads_norm = 3.2523
	sim_grads_norm = 0.1070
-- Starting training on experience 170 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6870
	data_grads_norm = 3.1376
	new_data_grads_norm = 4.6536
	old_data_grads_norm = 3.8031
	sim_grads_norm = 0.1043
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7302
	data_grads_norm = 3.3028
	new_data_grads_norm = 4.1530
	old_data_grads_norm = 4.5247
	sim_grads_norm = 0.0332
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6301
	data_grads_norm = 3.0387
	new_data_grads_norm = 3.9756
	old_data_grads_norm = 3.7851
	sim_grads_norm = 0.0831
-- Starting training on experience 171 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4158
	data_grads_norm = 2.7483
	new_data_grads_norm = 4.4659
	old_data_grads_norm = 3.1976
	sim_grads_norm = 0.1411
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1419
	data_grads_norm = 2.2913
	new_data_grads_norm = 4.1407
	old_data_grads_norm = 3.4196
	sim_grads_norm = -0.0295
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5952
	data_grads_norm = 3.5835
	new_data_grads_norm = 4.6599
	old_data_grads_norm = 5.1528
	sim_grads_norm = 0.0424
-- Starting training on experience 172 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2342
	data_grads_norm = 2.6784
	new_data_grads_norm = 3.6450
	old_data_grads_norm = 3.9130
	sim_grads_norm = -0.0355
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3548
	data_grads_norm = 2.7876
	new_data_grads_norm = 3.7477
	old_data_grads_norm = 3.8637
	sim_grads_norm = 0.0704
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1910
	data_grads_norm = 2.4379
	new_data_grads_norm = 3.9393
	old_data_grads_norm = 3.0980
	sim_grads_norm = 0.0951
-- Starting training on experience 173 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9203
	data_grads_norm = 3.1524
	new_data_grads_norm = 4.5490
	old_data_grads_norm = 4.1466
	sim_grads_norm = 0.0845
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8941
	data_grads_norm = 2.8260
	new_data_grads_norm = 4.3756
	old_data_grads_norm = 3.7424
	sim_grads_norm = 0.0789
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7783
	data_grads_norm = 3.0010
	new_data_grads_norm = 4.0389
	old_data_grads_norm = 4.0611
	sim_grads_norm = -0.0365
-- Starting training on experience 174 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1204
	data_grads_norm = 2.5398
	new_data_grads_norm = 3.6888
	old_data_grads_norm = 3.3191
	sim_grads_norm = 0.0340
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0985
	data_grads_norm = 2.3822
	new_data_grads_norm = 3.3324
	old_data_grads_norm = 3.2391
	sim_grads_norm = 0.0131
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4676
	data_grads_norm = 2.8415
	new_data_grads_norm = 3.8511
	old_data_grads_norm = 3.6554
	sim_grads_norm = -0.0001
-- Starting training on experience 175 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2469
	data_grads_norm = 2.7969
	new_data_grads_norm = 4.1980
	old_data_grads_norm = 2.6646
	sim_grads_norm = -0.0711
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1111
	data_grads_norm = 2.9132
	new_data_grads_norm = 3.9263
	old_data_grads_norm = 3.8942
	sim_grads_norm = -0.0032
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5553
	data_grads_norm = 2.9282
	new_data_grads_norm = 3.9644
	old_data_grads_norm = 3.8036
	sim_grads_norm = 0.0335
-- Starting training on experience 176 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3659
	data_grads_norm = 2.9401
	new_data_grads_norm = 4.0842
	old_data_grads_norm = 4.6702
	sim_grads_norm = -0.1204
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6784
	data_grads_norm = 3.3056
	new_data_grads_norm = 4.4610
	old_data_grads_norm = 4.5301
	sim_grads_norm = -0.0844
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7733
	data_grads_norm = 3.6344
	new_data_grads_norm = 4.7318
	old_data_grads_norm = 4.3358
	sim_grads_norm = 0.0959
-- Starting training on experience 177 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1365
	data_grads_norm = 2.9843
	new_data_grads_norm = 4.3027
	old_data_grads_norm = 3.7517
	sim_grads_norm = 0.0121
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0918
	data_grads_norm = 2.6495
	new_data_grads_norm = 3.9929
	old_data_grads_norm = 3.3684
	sim_grads_norm = -0.0471
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2341
	data_grads_norm = 3.0871
	new_data_grads_norm = 4.5559
	old_data_grads_norm = 3.7883
	sim_grads_norm = 0.1088
-- Starting training on experience 178 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4176
	data_grads_norm = 3.0098
	new_data_grads_norm = 4.3213
	old_data_grads_norm = 4.2339
	sim_grads_norm = 0.0430
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8958
	data_grads_norm = 3.1700
	new_data_grads_norm = 4.3599
	old_data_grads_norm = 4.9104
	sim_grads_norm = -0.0100
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9649
	data_grads_norm = 2.8597
	new_data_grads_norm = 3.8264
	old_data_grads_norm = 3.8433
	sim_grads_norm = 0.0273
-- Starting training on experience 179 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5821
	data_grads_norm = 3.6563
	new_data_grads_norm = 5.9458
	old_data_grads_norm = 4.5189
	sim_grads_norm = -0.0009
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7956
	data_grads_norm = 3.6137
	new_data_grads_norm = 5.4734
	old_data_grads_norm = 4.6847
	sim_grads_norm = 0.0969
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4865
	data_grads_norm = 3.4739
	new_data_grads_norm = 5.8951
	old_data_grads_norm = 4.0476
	sim_grads_norm = 0.0132
-- Starting training on experience 180 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3795
	data_grads_norm = 2.9530
	new_data_grads_norm = 4.0576
	old_data_grads_norm = 3.9475
	sim_grads_norm = 0.1336
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7682
	data_grads_norm = 3.7773
	new_data_grads_norm = 4.3138
	old_data_grads_norm = 5.3237
	sim_grads_norm = -0.0354
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6719
	data_grads_norm = 3.3395
	new_data_grads_norm = 4.7680
	old_data_grads_norm = 4.1828
	sim_grads_norm = 0.1049
-- Starting training on experience 181 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2299
	data_grads_norm = 3.1571
	new_data_grads_norm = 5.0370
	old_data_grads_norm = 4.8060
	sim_grads_norm = -0.0486
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0683
	data_grads_norm = 3.4224
	new_data_grads_norm = 5.4204
	old_data_grads_norm = 3.7392
	sim_grads_norm = 0.0980
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2117
	data_grads_norm = 3.0813
	new_data_grads_norm = 5.4892
	old_data_grads_norm = 3.5594
	sim_grads_norm = 0.0030
-- Starting training on experience 182 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8963
	data_grads_norm = 4.2516
	new_data_grads_norm = 4.5388
	old_data_grads_norm = 6.3231
	sim_grads_norm = 0.0354
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3860
	data_grads_norm = 3.2457
	new_data_grads_norm = 4.2456
	old_data_grads_norm = 4.4080
	sim_grads_norm = 0.0017
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3552
	data_grads_norm = 2.9969
	new_data_grads_norm = 4.2861
	old_data_grads_norm = 3.9658
	sim_grads_norm = 0.0017
-- Starting training on experience 183 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4381
	data_grads_norm = 3.5401
	new_data_grads_norm = 5.0289
	old_data_grads_norm = 4.6434
	sim_grads_norm = 0.1182
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8757
	data_grads_norm = 2.7730
	new_data_grads_norm = 4.2424
	old_data_grads_norm = 2.9957
	sim_grads_norm = -0.0153
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7742
	data_grads_norm = 2.7440
	new_data_grads_norm = 4.4174
	old_data_grads_norm = 4.0946
	sim_grads_norm = -0.0134
-- Starting training on experience 184 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9293
	data_grads_norm = 3.2890
	new_data_grads_norm = 4.8586
	old_data_grads_norm = 5.4860
	sim_grads_norm = -0.1226
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4758
	data_grads_norm = 3.7908
	new_data_grads_norm = 5.1538
	old_data_grads_norm = 4.6362
	sim_grads_norm = 0.0580
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3848
	data_grads_norm = 3.5505
	new_data_grads_norm = 5.2004
	old_data_grads_norm = 4.2260
	sim_grads_norm = 0.0288
-- Starting training on experience 185 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8079
	data_grads_norm = 3.9210
	new_data_grads_norm = 4.5818
	old_data_grads_norm = 5.3934
	sim_grads_norm = 0.0591
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3613
	data_grads_norm = 2.5540
	new_data_grads_norm = 4.0111
	old_data_grads_norm = 2.7954
	sim_grads_norm = -0.0026
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2316
	data_grads_norm = 3.4180
	new_data_grads_norm = 4.4861
	old_data_grads_norm = 4.8742
	sim_grads_norm = 0.0543
-- Starting training on experience 186 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2827
	data_grads_norm = 2.8474
	new_data_grads_norm = 4.7888
	old_data_grads_norm = 3.4286
	sim_grads_norm = 0.0774
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4275
	data_grads_norm = 3.4245
	new_data_grads_norm = 4.3630
	old_data_grads_norm = 4.7030
	sim_grads_norm = 0.0772
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1918
	data_grads_norm = 2.8140
	new_data_grads_norm = 4.1465
	old_data_grads_norm = 3.3965
	sim_grads_norm = 0.0656
-- Starting training on experience 187 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2148
	data_grads_norm = 2.7694
	new_data_grads_norm = 4.1841
	old_data_grads_norm = 3.8818
	sim_grads_norm = -0.0263
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9194
	data_grads_norm = 2.8261
	new_data_grads_norm = 4.0746
	old_data_grads_norm = 3.4729
	sim_grads_norm = 0.0876
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2526
	data_grads_norm = 3.4721
	new_data_grads_norm = 3.9926
	old_data_grads_norm = 5.3169
	sim_grads_norm = 0.0050
-- Starting training on experience 188 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6453
	data_grads_norm = 2.4452
	new_data_grads_norm = 4.5985
	old_data_grads_norm = 2.7696
	sim_grads_norm = 0.0145
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8882
	data_grads_norm = 3.0509
	new_data_grads_norm = 4.6641
	old_data_grads_norm = 3.6445
	sim_grads_norm = 0.0903
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5194
	data_grads_norm = 3.3859
	new_data_grads_norm = 4.4784
	old_data_grads_norm = 4.7926
	sim_grads_norm = 0.0441
-- Starting training on experience 189 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4511
	data_grads_norm = 3.0507
	new_data_grads_norm = 4.2612
	old_data_grads_norm = 3.6326
	sim_grads_norm = 0.0824
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0811
	data_grads_norm = 2.7470
	new_data_grads_norm = 3.6443
	old_data_grads_norm = 4.3876
	sim_grads_norm = -0.0452
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8305
	data_grads_norm = 3.5614
	new_data_grads_norm = 4.3096
	old_data_grads_norm = 5.5140
	sim_grads_norm = 0.0292
-- Starting training on experience 190 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1483
	data_grads_norm = 2.2422
	new_data_grads_norm = 4.0973
	old_data_grads_norm = 2.8060
	sim_grads_norm = -0.0132
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6692
	data_grads_norm = 2.8126
	new_data_grads_norm = 4.0719
	old_data_grads_norm = 3.8993
	sim_grads_norm = -0.0764
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7607
	data_grads_norm = 2.9938
	new_data_grads_norm = 4.0485
	old_data_grads_norm = 4.2962
	sim_grads_norm = 0.0045
-- Starting training on experience 191 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2713
	data_grads_norm = 2.7038
	new_data_grads_norm = 4.1760
	old_data_grads_norm = 3.1142
	sim_grads_norm = -0.0185
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2593
	data_grads_norm = 2.4737
	new_data_grads_norm = 3.9279
	old_data_grads_norm = 3.1810
	sim_grads_norm = 0.0085
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8063
	data_grads_norm = 3.7800
	new_data_grads_norm = 3.6236
	old_data_grads_norm = 5.2989
	sim_grads_norm = 0.0950
-- Starting training on experience 192 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1091
	data_grads_norm = 2.9736
	new_data_grads_norm = 3.9412
	old_data_grads_norm = 4.0731
	sim_grads_norm = -0.0217
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1381
	data_grads_norm = 3.2569
	new_data_grads_norm = 4.3825
	old_data_grads_norm = 4.4323
	sim_grads_norm = 0.0957
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8724
	data_grads_norm = 2.5526
	new_data_grads_norm = 3.7786
	old_data_grads_norm = 3.6459
	sim_grads_norm = -0.0364
-- Starting training on experience 193 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8305
	data_grads_norm = 2.7091
	new_data_grads_norm = 3.6381
	old_data_grads_norm = 2.9480
	sim_grads_norm = 0.0796
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1009
	data_grads_norm = 2.8729
	new_data_grads_norm = 3.6344
	old_data_grads_norm = 4.4218
	sim_grads_norm = -0.0995
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0133
	data_grads_norm = 2.6091
	new_data_grads_norm = 3.7679
	old_data_grads_norm = 2.7921
	sim_grads_norm = 0.1350
-- Starting training on experience 194 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2859
	data_grads_norm = 3.1700
	new_data_grads_norm = 4.4914
	old_data_grads_norm = 4.3819
	sim_grads_norm = 0.0274
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1888
	data_grads_norm = 3.5481
	new_data_grads_norm = 4.3179
	old_data_grads_norm = 5.3160
	sim_grads_norm = 0.0485
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7153
	data_grads_norm = 3.3215
	new_data_grads_norm = 4.2386
	old_data_grads_norm = 4.5945
	sim_grads_norm = -0.0109
-- Starting training on experience 195 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4480
	data_grads_norm = 3.0366
	new_data_grads_norm = 4.6513
	old_data_grads_norm = 3.8768
	sim_grads_norm = 0.0008
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1005
	data_grads_norm = 2.7361
	new_data_grads_norm = 4.3716
	old_data_grads_norm = 3.3359
	sim_grads_norm = -0.0097
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0780
	data_grads_norm = 2.6450
	new_data_grads_norm = 4.2081
	old_data_grads_norm = 3.7693
	sim_grads_norm = -0.0101
-- Starting training on experience 196 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4923
	data_grads_norm = 3.1301
	new_data_grads_norm = 4.0380
	old_data_grads_norm = 4.3918
	sim_grads_norm = 0.1558
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4337
	data_grads_norm = 3.0324
	new_data_grads_norm = 4.0367
	old_data_grads_norm = 4.1741
	sim_grads_norm = 0.0167
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2308
	data_grads_norm = 2.8233
	new_data_grads_norm = 4.1303
	old_data_grads_norm = 3.8991
	sim_grads_norm = -0.0151
-- Starting training on experience 197 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2041
	data_grads_norm = 2.5806
	new_data_grads_norm = 4.1284
	old_data_grads_norm = 3.2976
	sim_grads_norm = 0.0196
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3288
	data_grads_norm = 2.8037
	new_data_grads_norm = 4.6322
	old_data_grads_norm = 3.7427
	sim_grads_norm = -0.0250
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1611
	data_grads_norm = 2.5523
	new_data_grads_norm = 4.2838
	old_data_grads_norm = 3.5371
	sim_grads_norm = -0.1179
-- Starting training on experience 198 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3576
	data_grads_norm = 3.0140
	new_data_grads_norm = 4.5148
	old_data_grads_norm = 3.3743
	sim_grads_norm = 0.0412
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9935
	data_grads_norm = 2.8745
	new_data_grads_norm = 4.5635
	old_data_grads_norm = 3.6078
	sim_grads_norm = 0.0204
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1574
	data_grads_norm = 3.2061
	new_data_grads_norm = 4.3515
	old_data_grads_norm = 4.8021
	sim_grads_norm = 0.0951
-- Starting training on experience 199 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6153
	data_grads_norm = 3.3724
	new_data_grads_norm = 4.2742
	old_data_grads_norm = 4.8464
	sim_grads_norm = 0.0930
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2448
	data_grads_norm = 2.7180
	new_data_grads_norm = 3.7365
	old_data_grads_norm = 3.9892
	sim_grads_norm = 0.0468
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2370
	data_grads_norm = 2.8488
	new_data_grads_norm = 3.9783
	old_data_grads_norm = 4.1735
	sim_grads_norm = -0.0328
-- Starting training on experience 200 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7340
	data_grads_norm = 2.9367
	new_data_grads_norm = 4.2327
	old_data_grads_norm = 3.6116
	sim_grads_norm = 0.0376
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5471
	data_grads_norm = 2.8911
	new_data_grads_norm = 4.4530
	old_data_grads_norm = 3.3875
	sim_grads_norm = 0.1539
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2906
	data_grads_norm = 2.7752
	new_data_grads_norm = 4.2310
	old_data_grads_norm = 4.1096
	sim_grads_norm = 0.0273
-- Starting training on experience 201 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9031
	data_grads_norm = 2.9860
	new_data_grads_norm = 4.4080
	old_data_grads_norm = 4.3120
	sim_grads_norm = 0.0369
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0289
	data_grads_norm = 2.8418
	new_data_grads_norm = 4.3462
	old_data_grads_norm = 3.1544
	sim_grads_norm = 0.0344
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2805
	data_grads_norm = 2.8090
	new_data_grads_norm = 4.2741
	old_data_grads_norm = 3.9485
	sim_grads_norm = -0.0122
-- Starting training on experience 202 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1345
	data_grads_norm = 3.3889
	new_data_grads_norm = 4.6539
	old_data_grads_norm = 3.9376
	sim_grads_norm = 0.0579
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6301
	data_grads_norm = 3.8236
	new_data_grads_norm = 4.8318
	old_data_grads_norm = 5.3048
	sim_grads_norm = 0.0873
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9285
	data_grads_norm = 2.9520
	new_data_grads_norm = 4.6384
	old_data_grads_norm = 3.6842
	sim_grads_norm = 0.0013
-- Starting training on experience 203 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4891
	data_grads_norm = 3.1425
	new_data_grads_norm = 4.4531
	old_data_grads_norm = 4.0735
	sim_grads_norm = 0.0820
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0838
	data_grads_norm = 2.8433
	new_data_grads_norm = 4.3649
	old_data_grads_norm = 4.1857
	sim_grads_norm = 0.0860
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8568
	data_grads_norm = 2.4711
	new_data_grads_norm = 3.9374
	old_data_grads_norm = 3.1099
	sim_grads_norm = 0.0465
-- Starting training on experience 204 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9197
	data_grads_norm = 2.7883
	new_data_grads_norm = 4.4250
	old_data_grads_norm = 3.8365
	sim_grads_norm = -0.1007
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6921
	data_grads_norm = 3.2996
	new_data_grads_norm = 4.6401
	old_data_grads_norm = 4.3839
	sim_grads_norm = -0.0114
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1544
	data_grads_norm = 3.2067
	new_data_grads_norm = 5.2993
	old_data_grads_norm = 3.5046
	sim_grads_norm = 0.0474
-- Starting training on experience 205 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7247
	data_grads_norm = 3.8660
	new_data_grads_norm = 4.8485
	old_data_grads_norm = 5.1289
	sim_grads_norm = 0.0972
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5618
	data_grads_norm = 3.1635
	new_data_grads_norm = 4.5162
	old_data_grads_norm = 3.9818
	sim_grads_norm = 0.1114
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2409
	data_grads_norm = 2.9492
	new_data_grads_norm = 4.6181
	old_data_grads_norm = 3.4673
	sim_grads_norm = 0.0139
-- Starting training on experience 206 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3133
	data_grads_norm = 3.0578
	new_data_grads_norm = 4.4434
	old_data_grads_norm = 3.9053
	sim_grads_norm = 0.0103
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4512
	data_grads_norm = 3.1911
	new_data_grads_norm = 4.1194
	old_data_grads_norm = 4.0784
	sim_grads_norm = 0.0650
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4121
	data_grads_norm = 3.0244
	new_data_grads_norm = 4.3614
	old_data_grads_norm = 4.0353
	sim_grads_norm = -0.0121
-- Starting training on experience 207 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0479
	data_grads_norm = 2.6805
	new_data_grads_norm = 4.7132
	old_data_grads_norm = 3.5509
	sim_grads_norm = -0.0505
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1619
	data_grads_norm = 2.7400
	new_data_grads_norm = 5.1168
	old_data_grads_norm = 3.4733
	sim_grads_norm = -0.0308
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3691
	data_grads_norm = 3.2139
	new_data_grads_norm = 4.6170
	old_data_grads_norm = 4.0513
	sim_grads_norm = -0.0237
-- Starting training on experience 208 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5467
	data_grads_norm = 3.8138
	new_data_grads_norm = 4.3144
	old_data_grads_norm = 5.9538
	sim_grads_norm = 0.0653
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2565
	data_grads_norm = 2.8708
	new_data_grads_norm = 4.2019
	old_data_grads_norm = 3.5022
	sim_grads_norm = 0.1231
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9678
	data_grads_norm = 3.3845
	new_data_grads_norm = 4.0700
	old_data_grads_norm = 5.0692
	sim_grads_norm = -0.0890
-- Starting training on experience 209 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2337
	data_grads_norm = 3.0647
	new_data_grads_norm = 5.3309
	old_data_grads_norm = 3.6230
	sim_grads_norm = 0.0363
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0974
	data_grads_norm = 3.0085
	new_data_grads_norm = 5.8735
	old_data_grads_norm = 3.7867
	sim_grads_norm = 0.0428
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3373
	data_grads_norm = 3.6167
	new_data_grads_norm = 6.3549
	old_data_grads_norm = 4.2198
	sim_grads_norm = 0.1153
-- Starting training on experience 210 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8462
	data_grads_norm = 2.6507
	new_data_grads_norm = 4.1252
	old_data_grads_norm = 2.7589
	sim_grads_norm = 0.0611
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9959
	data_grads_norm = 3.0207
	new_data_grads_norm = 4.1830
	old_data_grads_norm = 3.7344
	sim_grads_norm = -0.0400
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9596
	data_grads_norm = 3.0752
	new_data_grads_norm = 4.2087
	old_data_grads_norm = 3.4024
	sim_grads_norm = 0.0635
-- Starting training on experience 211 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1402
	data_grads_norm = 3.2780
	new_data_grads_norm = 4.3309
	old_data_grads_norm = 4.0945
	sim_grads_norm = -0.0173
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4679
	data_grads_norm = 3.5538
	new_data_grads_norm = 4.4795
	old_data_grads_norm = 5.2909
	sim_grads_norm = 0.0582
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3225
	data_grads_norm = 3.7053
	new_data_grads_norm = 4.9707
	old_data_grads_norm = 4.9090
	sim_grads_norm = 0.0540
-- Starting training on experience 212 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2152
	data_grads_norm = 3.1321
	new_data_grads_norm = 5.6727
	old_data_grads_norm = 3.0382
	sim_grads_norm = 0.1037
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3475
	data_grads_norm = 3.3150
	new_data_grads_norm = 5.0860
	old_data_grads_norm = 3.6002
	sim_grads_norm = 0.0799
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3112
	data_grads_norm = 2.9706
	new_data_grads_norm = 4.9199
	old_data_grads_norm = 3.9341
	sim_grads_norm = -0.0584
-- Starting training on experience 213 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8330
	data_grads_norm = 3.0225
	new_data_grads_norm = 4.8072
	old_data_grads_norm = 3.3479
	sim_grads_norm = 0.0303
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2773
	data_grads_norm = 3.4649
	new_data_grads_norm = 4.4733
	old_data_grads_norm = 5.5729
	sim_grads_norm = -0.0633
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0419
	data_grads_norm = 2.8774
	new_data_grads_norm = 4.3095
	old_data_grads_norm = 3.6523
	sim_grads_norm = -0.0942
-- Starting training on experience 214 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8638
	data_grads_norm = 3.4843
	new_data_grads_norm = 4.5464
	old_data_grads_norm = 4.7194
	sim_grads_norm = 0.0582
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4679
	data_grads_norm = 3.0551
	new_data_grads_norm = 4.4933
	old_data_grads_norm = 4.0782
	sim_grads_norm = -0.0581
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5699
	data_grads_norm = 3.2699
	new_data_grads_norm = 4.3476
	old_data_grads_norm = 4.5265
	sim_grads_norm = 0.1107
-- Starting training on experience 215 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8034
	data_grads_norm = 2.9388
	new_data_grads_norm = 4.1389
	old_data_grads_norm = 4.1185
	sim_grads_norm = 0.0170
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5206
	data_grads_norm = 2.4464
	new_data_grads_norm = 4.0837
	old_data_grads_norm = 2.6156
	sim_grads_norm = 0.0626
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3719
	data_grads_norm = 3.2466
	new_data_grads_norm = 4.6137
	old_data_grads_norm = 4.2632
	sim_grads_norm = 0.0990
-- Starting training on experience 216 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8661
	data_grads_norm = 2.8940
	new_data_grads_norm = 4.1314
	old_data_grads_norm = 3.8442
	sim_grads_norm = 0.0249
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2178
	data_grads_norm = 3.6966
	new_data_grads_norm = 4.6608
	old_data_grads_norm = 5.0641
	sim_grads_norm = 0.0430
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2933
	data_grads_norm = 3.2024
	new_data_grads_norm = 4.3814
	old_data_grads_norm = 3.9637
	sim_grads_norm = -0.0265
-- Starting training on experience 217 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8421
	data_grads_norm = 2.8496
	new_data_grads_norm = 4.1376
	old_data_grads_norm = 3.4492
	sim_grads_norm = 0.1212
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2965
	data_grads_norm = 3.4733
	new_data_grads_norm = 4.1398
	old_data_grads_norm = 4.7683
	sim_grads_norm = 0.0850
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1116
	data_grads_norm = 2.9899
	new_data_grads_norm = 4.3059
	old_data_grads_norm = 4.1732
	sim_grads_norm = 0.0210
-- Starting training on experience 218 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7765
	data_grads_norm = 2.7207
	new_data_grads_norm = 3.6114
	old_data_grads_norm = 3.7802
	sim_grads_norm = 0.0107
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8843
	data_grads_norm = 3.1745
	new_data_grads_norm = 3.9081
	old_data_grads_norm = 5.5784
	sim_grads_norm = -0.0263
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5032
	data_grads_norm = 3.0016
	new_data_grads_norm = 3.8359
	old_data_grads_norm = 3.9923
	sim_grads_norm = 0.1547
-- Starting training on experience 219 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3270
	data_grads_norm = 3.0967
	new_data_grads_norm = 4.2075
	old_data_grads_norm = 4.8119
	sim_grads_norm = -0.1027
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2445
	data_grads_norm = 3.3787
	new_data_grads_norm = 4.4145
	old_data_grads_norm = 4.2758
	sim_grads_norm = 0.0813
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7200
	data_grads_norm = 2.5108
	new_data_grads_norm = 4.3961
	old_data_grads_norm = 3.4322
	sim_grads_norm = 0.0075
-- Starting training on experience 220 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2322
	data_grads_norm = 3.7548
	new_data_grads_norm = 5.6080
	old_data_grads_norm = 3.9009
	sim_grads_norm = -0.0469
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2284
	data_grads_norm = 3.2615
	new_data_grads_norm = 5.9469
	old_data_grads_norm = 2.9286
	sim_grads_norm = 0.0033
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5291
	data_grads_norm = 3.8465
	new_data_grads_norm = 5.8505
	old_data_grads_norm = 4.6694
	sim_grads_norm = 0.0159
-- Starting training on experience 221 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5789
	data_grads_norm = 3.4493
	new_data_grads_norm = 4.3387
	old_data_grads_norm = 5.2836
	sim_grads_norm = 0.0877
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9882
	data_grads_norm = 2.4418
	new_data_grads_norm = 4.1578
	old_data_grads_norm = 3.0415
	sim_grads_norm = -0.0632
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7278
	data_grads_norm = 2.3615
	new_data_grads_norm = 4.1122
	old_data_grads_norm = 2.5995
	sim_grads_norm = -0.0682
-- Starting training on experience 222 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6188
	data_grads_norm = 3.5427
	new_data_grads_norm = 5.0059
	old_data_grads_norm = 3.6582
	sim_grads_norm = 0.0293
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5086
	data_grads_norm = 3.6208
	new_data_grads_norm = 5.0167
	old_data_grads_norm = 5.6673
	sim_grads_norm = 0.0298
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4032
	data_grads_norm = 3.0730
	new_data_grads_norm = 4.5482
	old_data_grads_norm = 3.2936
	sim_grads_norm = 0.0547
-- Starting training on experience 223 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2542
	data_grads_norm = 3.2574
	new_data_grads_norm = 5.1287
	old_data_grads_norm = 3.9740
	sim_grads_norm = -0.0899
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0398
	data_grads_norm = 4.0152
	new_data_grads_norm = 5.0600
	old_data_grads_norm = 4.8932
	sim_grads_norm = 0.2634
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9398
	data_grads_norm = 3.0421
	new_data_grads_norm = 4.9729
	old_data_grads_norm = 3.5143
	sim_grads_norm = -0.0707
-- Starting training on experience 224 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5442
	data_grads_norm = 3.4908
	new_data_grads_norm = 5.1270
	old_data_grads_norm = 4.1903
	sim_grads_norm = 0.1302
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9664
	data_grads_norm = 3.0299
	new_data_grads_norm = 4.7846
	old_data_grads_norm = 5.6484
	sim_grads_norm = -0.0365
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3165
	data_grads_norm = 3.2849
	new_data_grads_norm = 4.5519
	old_data_grads_norm = 4.3101
	sim_grads_norm = -0.0063
-- Starting training on experience 225 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4779
	data_grads_norm = 3.5899
	new_data_grads_norm = 5.9412
	old_data_grads_norm = 3.7478
	sim_grads_norm = -0.0432
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3723
	data_grads_norm = 3.6973
	new_data_grads_norm = 5.7467
	old_data_grads_norm = 4.0397
	sim_grads_norm = 0.0055
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3214
	data_grads_norm = 3.7139
	new_data_grads_norm = 6.1772
	old_data_grads_norm = 3.7525
	sim_grads_norm = 0.0275
-- Starting training on experience 226 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2039
	data_grads_norm = 3.5392
	new_data_grads_norm = 5.7955
	old_data_grads_norm = 3.8252
	sim_grads_norm = -0.0175
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5470
	data_grads_norm = 4.0439
	new_data_grads_norm = 4.9827
	old_data_grads_norm = 5.2574
	sim_grads_norm = 0.0582
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1665
	data_grads_norm = 3.6278
	new_data_grads_norm = 5.2086
	old_data_grads_norm = 4.8673
	sim_grads_norm = -0.0578
-- Starting training on experience 227 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9979
	data_grads_norm = 3.1573
	new_data_grads_norm = 4.8930
	old_data_grads_norm = 4.1255
	sim_grads_norm = -0.0488
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3117
	data_grads_norm = 2.7917
	new_data_grads_norm = 4.7698
	old_data_grads_norm = 3.5573
	sim_grads_norm = -0.0779
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8936
	data_grads_norm = 3.1582
	new_data_grads_norm = 5.3666
	old_data_grads_norm = 3.0089
	sim_grads_norm = -0.0614
-- Starting training on experience 228 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4455
	data_grads_norm = 4.2590
	new_data_grads_norm = 5.6668
	old_data_grads_norm = 5.5577
	sim_grads_norm = 0.0413
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9759
	data_grads_norm = 3.3583
	new_data_grads_norm = 5.5854
	old_data_grads_norm = 3.4356
	sim_grads_norm = -0.0280
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1985
	data_grads_norm = 4.1341
	new_data_grads_norm = 5.5392
	old_data_grads_norm = 4.7694
	sim_grads_norm = 0.0296
-- Starting training on experience 229 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1564
	data_grads_norm = 3.2131
	new_data_grads_norm = 5.1930
	old_data_grads_norm = 3.5212
	sim_grads_norm = 0.0686
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9964
	data_grads_norm = 3.0746
	new_data_grads_norm = 4.8589
	old_data_grads_norm = 3.0423
	sim_grads_norm = 0.0763
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9879
	data_grads_norm = 3.1724
	new_data_grads_norm = 4.9106
	old_data_grads_norm = 4.3557
	sim_grads_norm = -0.0159
-- Starting training on experience 230 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7226
	data_grads_norm = 3.5882
	new_data_grads_norm = 5.2593
	old_data_grads_norm = 4.8892
	sim_grads_norm = 0.0196
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2810
	data_grads_norm = 3.1827
	new_data_grads_norm = 5.3061
	old_data_grads_norm = 3.5988
	sim_grads_norm = 0.1388
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7484
	data_grads_norm = 2.6611
	new_data_grads_norm = 4.8300
	old_data_grads_norm = 3.2244
	sim_grads_norm = -0.0758
-- Starting training on experience 231 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4113
	data_grads_norm = 3.6155
	new_data_grads_norm = 4.8501
	old_data_grads_norm = 4.5664
	sim_grads_norm = 0.1704
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0746
	data_grads_norm = 4.3311
	new_data_grads_norm = 5.9822
	old_data_grads_norm = 4.4882
	sim_grads_norm = -0.0779
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9323
	data_grads_norm = 3.3819
	new_data_grads_norm = 6.3832
	old_data_grads_norm = 4.2534
	sim_grads_norm = -0.0156
-- Starting training on experience 232 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2448
	data_grads_norm = 4.0280
	new_data_grads_norm = 5.5164
	old_data_grads_norm = 5.1341
	sim_grads_norm = 0.0841
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0262
	data_grads_norm = 3.1334
	new_data_grads_norm = 4.7765
	old_data_grads_norm = 3.2799
	sim_grads_norm = -0.0257
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1569
	data_grads_norm = 3.5709
	new_data_grads_norm = 5.3997
	old_data_grads_norm = 4.0468
	sim_grads_norm = 0.0261
-- Starting training on experience 233 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4502
	data_grads_norm = 3.3734
	new_data_grads_norm = 4.3361
	old_data_grads_norm = 5.1494
	sim_grads_norm = -0.0186
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1983
	data_grads_norm = 2.6706
	new_data_grads_norm = 4.1865
	old_data_grads_norm = 3.3394
	sim_grads_norm = 0.0090
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3542
	data_grads_norm = 3.2593
	new_data_grads_norm = 4.6652
	old_data_grads_norm = 3.6862
	sim_grads_norm = 0.1340
-- Starting training on experience 234 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0614
	data_grads_norm = 3.7802
	new_data_grads_norm = 5.4947
	old_data_grads_norm = 4.3794
	sim_grads_norm = -0.0260
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3734
	data_grads_norm = 3.6033
	new_data_grads_norm = 6.0919
	old_data_grads_norm = 3.9271
	sim_grads_norm = -0.0066
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1468
	data_grads_norm = 3.7491
	new_data_grads_norm = 6.4702
	old_data_grads_norm = 3.7640
	sim_grads_norm = 0.1006
-- Starting training on experience 235 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6504
	data_grads_norm = 2.9845
	new_data_grads_norm = 4.1893
	old_data_grads_norm = 4.3116
	sim_grads_norm = -0.0202
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4828
	data_grads_norm = 3.7788
	new_data_grads_norm = 4.4718
	old_data_grads_norm = 4.8131
	sim_grads_norm = 0.0840
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1102
	data_grads_norm = 2.9064
	new_data_grads_norm = 4.0050
	old_data_grads_norm = 3.9304
	sim_grads_norm = 0.0334
-- Starting training on experience 236 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3360
	data_grads_norm = 3.2005
	new_data_grads_norm = 4.3671
	old_data_grads_norm = 4.3651
	sim_grads_norm = -0.0417
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5983
	data_grads_norm = 2.8566
	new_data_grads_norm = 4.6306
	old_data_grads_norm = 4.0417
	sim_grads_norm = 0.0340
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1676
	data_grads_norm = 3.4437
	new_data_grads_norm = 4.6845
	old_data_grads_norm = 5.1933
	sim_grads_norm = 0.0046
-- Starting training on experience 237 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
-- >> End of training phase << --
-- >> Start of eval phase << --
-- Starting eval on experience 0 (Task 0) from test stream --
> Eval on experience 0 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp000 = 2.0174
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.4320
	mb_index = 1190
	time = 192.6303
-- Starting eval on experience 1 (Task 0) from test stream --
> Eval on experience 1 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp001 = 1.5128
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.6020
-- Starting eval on experience 2 (Task 0) from test stream --
> Eval on experience 2 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp002 = 2.7212
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.2020
-- Starting eval on experience 3 (Task 0) from test stream --
> Eval on experience 3 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp003 = 1.6834
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.5300
-- Starting eval on experience 4 (Task 0) from test stream --
> Eval on experience 4 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp004 = 3.0128
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.1260
-- >> End of eval phase << --
	CumulativeAccuracy/eval_phase/test_stream/Exp000 = 0.6900
	CumulativeAccuracy/eval_phase/test_stream/Exp001 = 0.6410
	CumulativeAccuracy/eval_phase/test_stream/Exp002 = 0.4913
	CumulativeAccuracy/eval_phase/test_stream/Exp003 = 0.4475
	CumulativeAccuracy/eval_phase/test_stream/Exp004 = 0.3784
	Loss_Stream/eval_phase/test_stream/Task000 = 2.1895
	Top1_Acc_Stream/eval_phase/test_stream/Task000 = 0.3784
-- >> Start of training phase << --
-- Starting training on experience 0 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1344
	data_grads_norm = 3.2382
	new_data_grads_norm = 4.7800
	old_data_grads_norm = 4.6125
	sim_grads_norm = 0.0720
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5784
	data_grads_norm = 3.8166
	new_data_grads_norm = 4.7802
	old_data_grads_norm = 5.9483
	sim_grads_norm = 0.1432
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2048
	data_grads_norm = 2.5458
	new_data_grads_norm = 4.0765
	old_data_grads_norm = 3.5495
	sim_grads_norm = -0.0648
-- Starting training on experience 1 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8229
	data_grads_norm = 2.5197
	new_data_grads_norm = 4.4074
	old_data_grads_norm = 2.9654
	sim_grads_norm = -0.0549
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0912
	data_grads_norm = 2.9018
	new_data_grads_norm = 5.3441
	old_data_grads_norm = 3.8262
	sim_grads_norm = 0.0249
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9888
	data_grads_norm = 2.7591
	new_data_grads_norm = 4.6949
	old_data_grads_norm = 3.5779
	sim_grads_norm = -0.0271
-- Starting training on experience 2 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3503
	data_grads_norm = 3.0045
	new_data_grads_norm = 5.5348
	old_data_grads_norm = 3.7035
	sim_grads_norm = -0.0135
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8819
	data_grads_norm = 3.1276
	new_data_grads_norm = 5.4497
	old_data_grads_norm = 3.5852
	sim_grads_norm = 0.0216
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0700
	data_grads_norm = 3.1437
	new_data_grads_norm = 5.2097
	old_data_grads_norm = 3.6922
	sim_grads_norm = 0.0366
-- Starting training on experience 3 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4046
	data_grads_norm = 3.1764
	new_data_grads_norm = 3.8288
	old_data_grads_norm = 4.7109
	sim_grads_norm = 0.0086
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5191
	data_grads_norm = 2.8012
	new_data_grads_norm = 4.1358
	old_data_grads_norm = 3.3072
	sim_grads_norm = 0.0500
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0789
	data_grads_norm = 2.6649
	new_data_grads_norm = 4.0124
	old_data_grads_norm = 3.5113
	sim_grads_norm = -0.0045
-- Starting training on experience 4 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7901
	data_grads_norm = 3.6369
	new_data_grads_norm = 5.2888
	old_data_grads_norm = 3.8922
	sim_grads_norm = 0.0393
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8424
	data_grads_norm = 3.8790
	new_data_grads_norm = 5.3236
	old_data_grads_norm = 5.1636
	sim_grads_norm = 0.0440
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5495
	data_grads_norm = 3.1975
	new_data_grads_norm = 4.8527
	old_data_grads_norm = 4.1910
	sim_grads_norm = 0.0413
-- Starting training on experience 5 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5211
	data_grads_norm = 3.7497
	new_data_grads_norm = 4.5810
	old_data_grads_norm = 5.1717
	sim_grads_norm = -0.0088
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3516
	data_grads_norm = 2.5463
	new_data_grads_norm = 3.9398
	old_data_grads_norm = 3.0468
	sim_grads_norm = 0.0305
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6401
	data_grads_norm = 2.1628
	new_data_grads_norm = 4.1657
	old_data_grads_norm = 2.6853
	sim_grads_norm = -0.0886
-- Starting training on experience 6 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4281
	data_grads_norm = 3.0952
	new_data_grads_norm = 4.6725
	old_data_grads_norm = 4.2051
	sim_grads_norm = 0.0310
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9056
	data_grads_norm = 2.8654
	new_data_grads_norm = 4.1385
	old_data_grads_norm = 4.1045
	sim_grads_norm = -0.0302
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1491
	data_grads_norm = 2.7868
	new_data_grads_norm = 4.2518
	old_data_grads_norm = 3.3195
	sim_grads_norm = -0.0370
-- Starting training on experience 7 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6391
	data_grads_norm = 3.3983
	new_data_grads_norm = 4.9278
	old_data_grads_norm = 3.6771
	sim_grads_norm = 0.0332
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3373
	data_grads_norm = 3.3339
	new_data_grads_norm = 5.1324
	old_data_grads_norm = 3.9372
	sim_grads_norm = -0.0818
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5586
	data_grads_norm = 3.6180
	new_data_grads_norm = 5.8328
	old_data_grads_norm = 3.7374
	sim_grads_norm = 0.0853
-- Starting training on experience 8 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0949
	data_grads_norm = 2.7596
	new_data_grads_norm = 4.1658
	old_data_grads_norm = 3.3093
	sim_grads_norm = -0.0492
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5209
	data_grads_norm = 3.2345
	new_data_grads_norm = 4.1815
	old_data_grads_norm = 5.9038
	sim_grads_norm = -0.0643
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3031
	data_grads_norm = 3.0724
	new_data_grads_norm = 4.0850
	old_data_grads_norm = 3.7532
	sim_grads_norm = -0.0351
-- Starting training on experience 9 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3607
	data_grads_norm = 2.6890
	new_data_grads_norm = 3.7335
	old_data_grads_norm = 3.9094
	sim_grads_norm = 0.0352
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5130
	data_grads_norm = 3.2550
	new_data_grads_norm = 3.9265
	old_data_grads_norm = 4.2388
	sim_grads_norm = 0.0261
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4461
	data_grads_norm = 3.2339
	new_data_grads_norm = 3.8041
	old_data_grads_norm = 4.7101
	sim_grads_norm = 0.0154
-- Starting training on experience 10 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2649
	data_grads_norm = 3.2401
	new_data_grads_norm = 4.1849
	old_data_grads_norm = 4.9415
	sim_grads_norm = 0.0311
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7388
	data_grads_norm = 3.2269
	new_data_grads_norm = 4.5899
	old_data_grads_norm = 4.3269
	sim_grads_norm = 0.0971
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0280
	data_grads_norm = 3.1246
	new_data_grads_norm = 4.5320
	old_data_grads_norm = 4.0977
	sim_grads_norm = -0.0736
-- Starting training on experience 11 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5030
	data_grads_norm = 2.7508
	new_data_grads_norm = 3.3625
	old_data_grads_norm = 3.6288
	sim_grads_norm = 0.0389
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9170
	data_grads_norm = 2.4044
	new_data_grads_norm = 3.1830
	old_data_grads_norm = 3.6875
	sim_grads_norm = 0.0113
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3040
	data_grads_norm = 2.7032
	new_data_grads_norm = 3.1853
	old_data_grads_norm = 4.0010
	sim_grads_norm = 0.0483
-- Starting training on experience 12 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8529
	data_grads_norm = 3.3234
	new_data_grads_norm = 4.5544
	old_data_grads_norm = 4.1047
	sim_grads_norm = 0.0697
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9207
	data_grads_norm = 2.8895
	new_data_grads_norm = 4.4089
	old_data_grads_norm = 3.0718
	sim_grads_norm = -0.0545
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2459
	data_grads_norm = 2.9942
	new_data_grads_norm = 4.5652
	old_data_grads_norm = 3.8557
	sim_grads_norm = -0.0122
-- Starting training on experience 13 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5348
	data_grads_norm = 3.1921
	new_data_grads_norm = 4.0690
	old_data_grads_norm = 4.5315
	sim_grads_norm = -0.0309
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3662
	data_grads_norm = 2.8985
	new_data_grads_norm = 4.1783
	old_data_grads_norm = 3.6532
	sim_grads_norm = 0.0218
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3187
	data_grads_norm = 2.7864
	new_data_grads_norm = 3.8275
	old_data_grads_norm = 3.8162
	sim_grads_norm = 0.0830
-- Starting training on experience 14 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3608
	data_grads_norm = 3.0305
	new_data_grads_norm = 4.3366
	old_data_grads_norm = 3.5550
	sim_grads_norm = -0.0292
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2162
	data_grads_norm = 3.5366
	new_data_grads_norm = 4.8285
	old_data_grads_norm = 3.9535
	sim_grads_norm = 0.2237
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2216
	data_grads_norm = 2.5176
	new_data_grads_norm = 3.7816
	old_data_grads_norm = 3.7668
	sim_grads_norm = -0.0133
-- Starting training on experience 15 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4463
	data_grads_norm = 2.8961
	new_data_grads_norm = 3.2964
	old_data_grads_norm = 4.1209
	sim_grads_norm = -0.0040
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8846
	data_grads_norm = 2.2904
	new_data_grads_norm = 3.4708
	old_data_grads_norm = 2.8152
	sim_grads_norm = -0.0264
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9715
	data_grads_norm = 2.4587
	new_data_grads_norm = 3.6531
	old_data_grads_norm = 3.1428
	sim_grads_norm = -0.0304
-- Starting training on experience 16 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2260
	data_grads_norm = 2.8749
	new_data_grads_norm = 4.1156
	old_data_grads_norm = 3.9238
	sim_grads_norm = 0.0089
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0726
	data_grads_norm = 3.2513
	new_data_grads_norm = 4.2130
	old_data_grads_norm = 5.2027
	sim_grads_norm = 0.1158
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8111
	data_grads_norm = 2.3724
	new_data_grads_norm = 3.7194
	old_data_grads_norm = 2.9160
	sim_grads_norm = -0.0078
-- Starting training on experience 17 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5725
	data_grads_norm = 3.0121
	new_data_grads_norm = 3.6850
	old_data_grads_norm = 4.4345
	sim_grads_norm = 0.0819
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4182
	data_grads_norm = 2.8527
	new_data_grads_norm = 3.2400
	old_data_grads_norm = 4.3168
	sim_grads_norm = 0.0486
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4381
	data_grads_norm = 2.6052
	new_data_grads_norm = 3.7404
	old_data_grads_norm = 3.6311
	sim_grads_norm = -0.0111
-- Starting training on experience 18 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9415
	data_grads_norm = 2.7539
	new_data_grads_norm = 3.7067
	old_data_grads_norm = 3.4889
	sim_grads_norm = 0.0302
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0521
	data_grads_norm = 2.6806
	new_data_grads_norm = 3.5903
	old_data_grads_norm = 3.1580
	sim_grads_norm = 0.0159
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2571
	data_grads_norm = 2.9472
	new_data_grads_norm = 4.0138
	old_data_grads_norm = 3.7948
	sim_grads_norm = -0.0285
-- Starting training on experience 19 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9981
	data_grads_norm = 2.6004
	new_data_grads_norm = 3.4365
	old_data_grads_norm = 3.4143
	sim_grads_norm = 0.0103
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7615
	data_grads_norm = 3.5702
	new_data_grads_norm = 3.8258
	old_data_grads_norm = 4.1666
	sim_grads_norm = 0.1113
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1811
	data_grads_norm = 3.2347
	new_data_grads_norm = 3.6274
	old_data_grads_norm = 4.0174
	sim_grads_norm = 0.0132
-- Starting training on experience 20 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4515
	data_grads_norm = 3.2208
	new_data_grads_norm = 4.4101
	old_data_grads_norm = 4.4151
	sim_grads_norm = 0.0377
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7107
	data_grads_norm = 3.2801
	new_data_grads_norm = 4.6246
	old_data_grads_norm = 4.4543
	sim_grads_norm = 0.1492
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4875
	data_grads_norm = 3.0892
	new_data_grads_norm = 4.2838
	old_data_grads_norm = 4.1311
	sim_grads_norm = 0.1250
-- Starting training on experience 21 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7379
	data_grads_norm = 2.6121
	new_data_grads_norm = 3.7294
	old_data_grads_norm = 3.6929
	sim_grads_norm = -0.0183
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0031
	data_grads_norm = 2.9085
	new_data_grads_norm = 3.7350
	old_data_grads_norm = 3.8525
	sim_grads_norm = 0.0343
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5821
	data_grads_norm = 2.6061
	new_data_grads_norm = 3.7620
	old_data_grads_norm = 3.6615
	sim_grads_norm = -0.1018
-- Starting training on experience 22 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3427
	data_grads_norm = 3.6330
	new_data_grads_norm = 5.1251
	old_data_grads_norm = 4.3740
	sim_grads_norm = 0.0545
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4184
	data_grads_norm = 3.0637
	new_data_grads_norm = 4.6038
	old_data_grads_norm = 4.2472
	sim_grads_norm = 0.0415
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3776
	data_grads_norm = 3.8386
	new_data_grads_norm = 4.3811
	old_data_grads_norm = 5.8230
	sim_grads_norm = 0.0401
-- Starting training on experience 23 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2158
	data_grads_norm = 3.7120
	new_data_grads_norm = 4.6587
	old_data_grads_norm = 5.3650
	sim_grads_norm = 0.0767
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9668
	data_grads_norm = 3.1287
	new_data_grads_norm = 3.8463
	old_data_grads_norm = 3.9858
	sim_grads_norm = -0.0393
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7644
	data_grads_norm = 3.0313
	new_data_grads_norm = 4.4028
	old_data_grads_norm = 4.7114
	sim_grads_norm = -0.0900
-- Starting training on experience 24 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2726
	data_grads_norm = 3.5651
	new_data_grads_norm = 4.6903
	old_data_grads_norm = 5.1465
	sim_grads_norm = -0.0286
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1458
	data_grads_norm = 2.7436
	new_data_grads_norm = 4.3043
	old_data_grads_norm = 4.0135
	sim_grads_norm = -0.0637
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6323
	data_grads_norm = 3.1257
	new_data_grads_norm = 4.3667
	old_data_grads_norm = 4.2996
	sim_grads_norm = 0.0977
-- Starting training on experience 25 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2684
	data_grads_norm = 2.8163
	new_data_grads_norm = 3.4831
	old_data_grads_norm = 4.1067
	sim_grads_norm = -0.0167
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2254
	data_grads_norm = 2.9706
	new_data_grads_norm = 3.5628
	old_data_grads_norm = 4.0726
	sim_grads_norm = 0.2045
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4464
	data_grads_norm = 3.1693
	new_data_grads_norm = 3.6051
	old_data_grads_norm = 4.9808
	sim_grads_norm = -0.0416
-- Starting training on experience 26 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6125
	data_grads_norm = 2.4323
	new_data_grads_norm = 3.0953
	old_data_grads_norm = 3.4978
	sim_grads_norm = 0.1007
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4640
	data_grads_norm = 2.3587
	new_data_grads_norm = 2.9110
	old_data_grads_norm = 4.8470
	sim_grads_norm = -0.0359
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5976
	data_grads_norm = 2.3082
	new_data_grads_norm = 3.0114
	old_data_grads_norm = 3.6523
	sim_grads_norm = -0.0109
-- Starting training on experience 27 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1880
	data_grads_norm = 3.4855
	new_data_grads_norm = 4.3102
	old_data_grads_norm = 5.2972
	sim_grads_norm = 0.0523
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6030
	data_grads_norm = 2.4026
	new_data_grads_norm = 3.8695
	old_data_grads_norm = 2.9245
	sim_grads_norm = 0.0012
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9842
	data_grads_norm = 2.8390
	new_data_grads_norm = 3.9056
	old_data_grads_norm = 4.2759
	sim_grads_norm = 0.0119
-- Starting training on experience 28 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8727
	data_grads_norm = 2.4841
	new_data_grads_norm = 2.6730
	old_data_grads_norm = 3.4946
	sim_grads_norm = 0.0944
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8605
	data_grads_norm = 2.4599
	new_data_grads_norm = 2.7594
	old_data_grads_norm = 3.1402
	sim_grads_norm = 0.1699
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7766
	data_grads_norm = 2.4171
	new_data_grads_norm = 2.8426
	old_data_grads_norm = 3.7498
	sim_grads_norm = -0.0190
-- Starting training on experience 29 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1203
	data_grads_norm = 3.3784
	new_data_grads_norm = 3.5311
	old_data_grads_norm = 4.5299
	sim_grads_norm = 0.0489
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4727
	data_grads_norm = 2.7624
	new_data_grads_norm = 3.2034
	old_data_grads_norm = 4.0743
	sim_grads_norm = -0.0783
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1838
	data_grads_norm = 2.8241
	new_data_grads_norm = 3.4154
	old_data_grads_norm = 3.7079
	sim_grads_norm = 0.1014
-- Starting training on experience 30 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9807
	data_grads_norm = 2.7270
	new_data_grads_norm = 3.2534
	old_data_grads_norm = 3.9952
	sim_grads_norm = 0.0805
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0312
	data_grads_norm = 2.9625
	new_data_grads_norm = 3.5020
	old_data_grads_norm = 4.0741
	sim_grads_norm = 0.0615
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4600
	data_grads_norm = 2.5083
	new_data_grads_norm = 3.4941
	old_data_grads_norm = 3.6198
	sim_grads_norm = 0.0426
-- Starting training on experience 31 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3839
	data_grads_norm = 2.3506
	new_data_grads_norm = 3.7129
	old_data_grads_norm = 3.1552
	sim_grads_norm = 0.0208
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6213
	data_grads_norm = 2.4535
	new_data_grads_norm = 3.1994
	old_data_grads_norm = 3.3113
	sim_grads_norm = -0.0313
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6849
	data_grads_norm = 2.2717
	new_data_grads_norm = 3.4676
	old_data_grads_norm = 3.3299
	sim_grads_norm = -0.0215
-- Starting training on experience 32 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7003
	data_grads_norm = 2.1585
	new_data_grads_norm = 3.2130
	old_data_grads_norm = 3.2223
	sim_grads_norm = 0.0627
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7757
	data_grads_norm = 2.6082
	new_data_grads_norm = 4.0331
	old_data_grads_norm = 3.5901
	sim_grads_norm = -0.0093
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6585
	data_grads_norm = 2.3705
	new_data_grads_norm = 3.9677
	old_data_grads_norm = 3.5567
	sim_grads_norm = -0.1073
-- Starting training on experience 33 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1054
	data_grads_norm = 3.0535
	new_data_grads_norm = 3.9380
	old_data_grads_norm = 4.9245
	sim_grads_norm = 0.0324
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7333
	data_grads_norm = 2.7720
	new_data_grads_norm = 3.3705
	old_data_grads_norm = 4.5512
	sim_grads_norm = -0.0144
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2578
	data_grads_norm = 2.8990
	new_data_grads_norm = 3.6531
	old_data_grads_norm = 3.6047
	sim_grads_norm = 0.0841
-- Starting training on experience 34 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6115
	data_grads_norm = 2.6600
	new_data_grads_norm = 3.0183
	old_data_grads_norm = 4.0377
	sim_grads_norm = 0.0536
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9841
	data_grads_norm = 2.8218
	new_data_grads_norm = 3.2167
	old_data_grads_norm = 4.8898
	sim_grads_norm = 0.0601
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6557
	data_grads_norm = 2.0096
	new_data_grads_norm = 3.1075
	old_data_grads_norm = 2.9709
	sim_grads_norm = -0.0511
-- Starting training on experience 35 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7476
	data_grads_norm = 2.8455
	new_data_grads_norm = 4.6030
	old_data_grads_norm = 3.4150
	sim_grads_norm = 0.0502
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1188
	data_grads_norm = 3.3087
	new_data_grads_norm = 3.7010
	old_data_grads_norm = 5.0880
	sim_grads_norm = -0.0059
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8801
	data_grads_norm = 2.8477
	new_data_grads_norm = 4.1021
	old_data_grads_norm = 4.5364
	sim_grads_norm = 0.1391
-- Starting training on experience 36 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7368
	data_grads_norm = 2.5421
	new_data_grads_norm = 2.4683
	old_data_grads_norm = 4.0234
	sim_grads_norm = -0.0094
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6846
	data_grads_norm = 2.1664
	new_data_grads_norm = 2.6775
	old_data_grads_norm = 3.1239
	sim_grads_norm = -0.0066
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8792
	data_grads_norm = 2.5024
	new_data_grads_norm = 2.6973
	old_data_grads_norm = 4.1603
	sim_grads_norm = -0.0206
-- Starting training on experience 37 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6767
	data_grads_norm = 2.8025
	new_data_grads_norm = 2.8673
	old_data_grads_norm = 4.1928
	sim_grads_norm = -0.0741
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7730
	data_grads_norm = 2.3439
	new_data_grads_norm = 3.1081
	old_data_grads_norm = 3.4268
	sim_grads_norm = 0.0320
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8400
	data_grads_norm = 2.3435
	new_data_grads_norm = 3.0890
	old_data_grads_norm = 3.2009
	sim_grads_norm = 0.0728
-- Starting training on experience 38 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9012
	data_grads_norm = 2.4103
	new_data_grads_norm = 3.4038
	old_data_grads_norm = 3.2242
	sim_grads_norm = 0.1448
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8079
	data_grads_norm = 2.7046
	new_data_grads_norm = 3.4923
	old_data_grads_norm = 4.3249
	sim_grads_norm = 0.0461
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9522
	data_grads_norm = 2.3050
	new_data_grads_norm = 3.3717
	old_data_grads_norm = 3.2757
	sim_grads_norm = -0.0446
-- Starting training on experience 39 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5300
	data_grads_norm = 2.2069
	new_data_grads_norm = 3.0933
	old_data_grads_norm = 2.7928
	sim_grads_norm = -0.0343
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8275
	data_grads_norm = 2.4258
	new_data_grads_norm = 3.3278
	old_data_grads_norm = 3.5015
	sim_grads_norm = -0.0107
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8629
	data_grads_norm = 2.4309
	new_data_grads_norm = 3.1346
	old_data_grads_norm = 3.7724
	sim_grads_norm = -0.0725
-- Starting training on experience 40 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7522
	data_grads_norm = 2.7126
	new_data_grads_norm = 3.0846
	old_data_grads_norm = 4.4799
	sim_grads_norm = -0.0209
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7125
	data_grads_norm = 2.9636
	new_data_grads_norm = 3.3563
	old_data_grads_norm = 4.7006
	sim_grads_norm = 0.0690
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7110
	data_grads_norm = 2.4765
	new_data_grads_norm = 2.8368
	old_data_grads_norm = 3.5926
	sim_grads_norm = 0.0985
-- Starting training on experience 41 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6281
	data_grads_norm = 2.3919
	new_data_grads_norm = 3.5096
	old_data_grads_norm = 3.1270
	sim_grads_norm = -0.0244
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6347
	data_grads_norm = 2.4457
	new_data_grads_norm = 3.5860
	old_data_grads_norm = 3.1538
	sim_grads_norm = 0.0333
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8862
	data_grads_norm = 2.7439
	new_data_grads_norm = 3.5508
	old_data_grads_norm = 3.7758
	sim_grads_norm = 0.0913
-- Starting training on experience 42 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5037
	data_grads_norm = 2.6117
	new_data_grads_norm = 3.3159
	old_data_grads_norm = 4.1238
	sim_grads_norm = 0.0368
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2815
	data_grads_norm = 1.9857
	new_data_grads_norm = 3.0186
	old_data_grads_norm = 2.8050
	sim_grads_norm = -0.0831
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7909
	data_grads_norm = 2.5367
	new_data_grads_norm = 3.1100
	old_data_grads_norm = 3.5972
	sim_grads_norm = -0.0170
-- Starting training on experience 43 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1283
	data_grads_norm = 1.9095
	new_data_grads_norm = 2.7560
	old_data_grads_norm = 2.3844
	sim_grads_norm = 0.1929
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2962
	data_grads_norm = 2.3998
	new_data_grads_norm = 2.9647
	old_data_grads_norm = 3.8271
	sim_grads_norm = -0.0226
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4970
	data_grads_norm = 2.5706
	new_data_grads_norm = 2.9301
	old_data_grads_norm = 4.0814
	sim_grads_norm = -0.0201
-- Starting training on experience 44 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9793
	data_grads_norm = 2.7603
	new_data_grads_norm = 3.1919
	old_data_grads_norm = 4.2387
	sim_grads_norm = 0.0078
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9853
	data_grads_norm = 2.6065
	new_data_grads_norm = 3.3292
	old_data_grads_norm = 3.5074
	sim_grads_norm = 0.0105
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7518
	data_grads_norm = 2.6100
	new_data_grads_norm = 3.4848
	old_data_grads_norm = 3.4369
	sim_grads_norm = -0.0310
-- Starting training on experience 45 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7687
	data_grads_norm = 2.2729
	new_data_grads_norm = 2.8942
	old_data_grads_norm = 2.8181
	sim_grads_norm = 0.0451
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6306
	data_grads_norm = 2.1318
	new_data_grads_norm = 2.8996
	old_data_grads_norm = 3.1080
	sim_grads_norm = -0.0597
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6902
	data_grads_norm = 2.5130
	new_data_grads_norm = 3.1225
	old_data_grads_norm = 3.9146
	sim_grads_norm = -0.0250
-- Starting training on experience 46 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5933
	data_grads_norm = 2.8110
	new_data_grads_norm = 2.9475
	old_data_grads_norm = 4.4230
	sim_grads_norm = 0.0028
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3952
	data_grads_norm = 3.0374
	new_data_grads_norm = 3.4877
	old_data_grads_norm = 4.2642
	sim_grads_norm = -0.0163
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8090
	data_grads_norm = 2.5573
	new_data_grads_norm = 3.0541
	old_data_grads_norm = 3.7984
	sim_grads_norm = 0.0724
-- Starting training on experience 47 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7730
	data_grads_norm = 2.4411
	new_data_grads_norm = 3.5979
	old_data_grads_norm = 3.1783
	sim_grads_norm = 0.0401
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9188
	data_grads_norm = 2.8447
	new_data_grads_norm = 3.8344
	old_data_grads_norm = 3.5821
	sim_grads_norm = 0.0785
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7205
	data_grads_norm = 2.6209
	new_data_grads_norm = 3.2119
	old_data_grads_norm = 3.6362
	sim_grads_norm = 0.0849
-- Starting training on experience 48 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8366
	data_grads_norm = 3.3477
	new_data_grads_norm = 3.3654
	old_data_grads_norm = 5.0071
	sim_grads_norm = -0.0801
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9128
	data_grads_norm = 2.6335
	new_data_grads_norm = 3.4873
	old_data_grads_norm = 3.4540
	sim_grads_norm = 0.1301
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7386
	data_grads_norm = 2.6477
	new_data_grads_norm = 3.8694
	old_data_grads_norm = 3.0016
	sim_grads_norm = 0.1782
-- Starting training on experience 49 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6920
	data_grads_norm = 2.7082
	new_data_grads_norm = 2.8835
	old_data_grads_norm = 4.2649
	sim_grads_norm = 0.0974
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5698
	data_grads_norm = 2.1189
	new_data_grads_norm = 2.9686
	old_data_grads_norm = 2.8963
	sim_grads_norm = -0.0088
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5735
	data_grads_norm = 2.4943
	new_data_grads_norm = 2.9532
	old_data_grads_norm = 3.6447
	sim_grads_norm = 0.0544
-- Starting training on experience 50 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5152
	data_grads_norm = 2.3848
	new_data_grads_norm = 3.0267
	old_data_grads_norm = 3.4628
	sim_grads_norm = 0.0522
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7853
	data_grads_norm = 2.6537
	new_data_grads_norm = 3.2611
	old_data_grads_norm = 3.2943
	sim_grads_norm = 0.1405
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2830
	data_grads_norm = 2.5253
	new_data_grads_norm = 3.1549
	old_data_grads_norm = 4.0900
	sim_grads_norm = -0.0351
-- Starting training on experience 51 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5678
	data_grads_norm = 2.4992
	new_data_grads_norm = 2.9975
	old_data_grads_norm = 4.5563
	sim_grads_norm = 0.0241
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3650
	data_grads_norm = 2.4639
	new_data_grads_norm = 2.9143
	old_data_grads_norm = 3.8009
	sim_grads_norm = -0.0685
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5886
	data_grads_norm = 3.3429
	new_data_grads_norm = 3.2636
	old_data_grads_norm = 4.9649
	sim_grads_norm = 0.0723
-- Starting training on experience 52 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0417
	data_grads_norm = 2.8776
	new_data_grads_norm = 3.5178
	old_data_grads_norm = 4.2071
	sim_grads_norm = 0.0349
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6815
	data_grads_norm = 2.7454
	new_data_grads_norm = 3.5920
	old_data_grads_norm = 3.5301
	sim_grads_norm = 0.1966
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8156
	data_grads_norm = 2.8444
	new_data_grads_norm = 3.4418
	old_data_grads_norm = 4.0486
	sim_grads_norm = 0.0085
-- Starting training on experience 53 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0024
	data_grads_norm = 2.4567
	new_data_grads_norm = 3.4283
	old_data_grads_norm = 3.2942
	sim_grads_norm = 0.0702
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8533
	data_grads_norm = 3.5002
	new_data_grads_norm = 3.6478
	old_data_grads_norm = 5.1373
	sim_grads_norm = 0.0340
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2404
	data_grads_norm = 2.4068
	new_data_grads_norm = 3.1417
	old_data_grads_norm = 3.1351
	sim_grads_norm = 0.0729
-- Starting training on experience 54 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3929
	data_grads_norm = 3.1477
	new_data_grads_norm = 3.5095
	old_data_grads_norm = 3.9001
	sim_grads_norm = 0.0223
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2757
	data_grads_norm = 2.7524
	new_data_grads_norm = 3.4795
	old_data_grads_norm = 3.7535
	sim_grads_norm = -0.0165
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1681
	data_grads_norm = 2.6336
	new_data_grads_norm = 3.3177
	old_data_grads_norm = 5.3462
	sim_grads_norm = -0.0366
-- Starting training on experience 55 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8596
	data_grads_norm = 2.1728
	new_data_grads_norm = 2.6332
	old_data_grads_norm = 3.1806
	sim_grads_norm = 0.1440
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7785
	data_grads_norm = 2.4243
	new_data_grads_norm = 2.8583
	old_data_grads_norm = 3.1647
	sim_grads_norm = 0.0098
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1771
	data_grads_norm = 2.0160
	new_data_grads_norm = 2.6559
	old_data_grads_norm = 3.4343
	sim_grads_norm = -0.0758
-- Starting training on experience 56 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8904
	data_grads_norm = 2.7814
	new_data_grads_norm = 3.5463
	old_data_grads_norm = 4.5150
	sim_grads_norm = 0.0221
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8718
	data_grads_norm = 2.8083
	new_data_grads_norm = 3.9627
	old_data_grads_norm = 3.8687
	sim_grads_norm = -0.0261
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4572
	data_grads_norm = 2.7845
	new_data_grads_norm = 3.6323
	old_data_grads_norm = 3.4772
	sim_grads_norm = 0.0809
-- Starting training on experience 57 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5542
	data_grads_norm = 2.6379
	new_data_grads_norm = 3.2293
	old_data_grads_norm = 4.0087
	sim_grads_norm = 0.1105
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4301
	data_grads_norm = 2.6841
	new_data_grads_norm = 3.1974
	old_data_grads_norm = 4.4892
	sim_grads_norm = 0.0088
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2748
	data_grads_norm = 2.2129
	new_data_grads_norm = 3.2250
	old_data_grads_norm = 2.6510
	sim_grads_norm = -0.0548
-- Starting training on experience 58 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2645
	data_grads_norm = 2.5266
	new_data_grads_norm = 3.7533
	old_data_grads_norm = 3.3591
	sim_grads_norm = -0.0117
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8680
	data_grads_norm = 3.0750
	new_data_grads_norm = 3.7509
	old_data_grads_norm = 4.2563
	sim_grads_norm = 0.0669
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5868
	data_grads_norm = 3.0089
	new_data_grads_norm = 3.7472
	old_data_grads_norm = 4.8570
	sim_grads_norm = -0.0316
-- Starting training on experience 59 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7072
	data_grads_norm = 3.0795
	new_data_grads_norm = 3.6226
	old_data_grads_norm = 4.6592
	sim_grads_norm = 0.2194
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1937
	data_grads_norm = 2.4298
	new_data_grads_norm = 3.2612
	old_data_grads_norm = 3.7760
	sim_grads_norm = -0.0001
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7322
	data_grads_norm = 2.7850
	new_data_grads_norm = 3.2681
	old_data_grads_norm = 5.3209
	sim_grads_norm = 0.0289
-- Starting training on experience 60 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3225
	data_grads_norm = 2.7627
	new_data_grads_norm = 2.8966
	old_data_grads_norm = 4.5006
	sim_grads_norm = 0.0161
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1678
	data_grads_norm = 2.5330
	new_data_grads_norm = 3.0211
	old_data_grads_norm = 4.0980
	sim_grads_norm = -0.0908
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7503
	data_grads_norm = 3.0476
	new_data_grads_norm = 3.8508
	old_data_grads_norm = 4.2597
	sim_grads_norm = 0.0913
-- Starting training on experience 61 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6041
	data_grads_norm = 2.9994
	new_data_grads_norm = 3.0545
	old_data_grads_norm = 4.8664
	sim_grads_norm = -0.0514
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3812
	data_grads_norm = 2.4961
	new_data_grads_norm = 3.2417
	old_data_grads_norm = 4.4197
	sim_grads_norm = -0.0038
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4884
	data_grads_norm = 3.6471
	new_data_grads_norm = 3.3359
	old_data_grads_norm = 6.6468
	sim_grads_norm = -0.0319
-- Starting training on experience 62 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6203
	data_grads_norm = 3.6007
	new_data_grads_norm = 3.6908
	old_data_grads_norm = 4.9871
	sim_grads_norm = 0.0658
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9446
	data_grads_norm = 3.3034
	new_data_grads_norm = 3.4574
	old_data_grads_norm = 5.6593
	sim_grads_norm = -0.0000
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8126
	data_grads_norm = 3.4491
	new_data_grads_norm = 3.2196
	old_data_grads_norm = 5.3258
	sim_grads_norm = 0.0120
-- Starting training on experience 63 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2297
	data_grads_norm = 2.8398
	new_data_grads_norm = 4.0093
	old_data_grads_norm = 4.0349
	sim_grads_norm = 0.0083
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5649
	data_grads_norm = 3.1343
	new_data_grads_norm = 3.9644
	old_data_grads_norm = 4.6405
	sim_grads_norm = -0.0034
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4358
	data_grads_norm = 2.9289
	new_data_grads_norm = 3.6761
	old_data_grads_norm = 4.1989
	sim_grads_norm = 0.0536
-- Starting training on experience 64 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7393
	data_grads_norm = 3.0447
	new_data_grads_norm = 3.5900
	old_data_grads_norm = 3.4937
	sim_grads_norm = 0.2865
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5115
	data_grads_norm = 2.4222
	new_data_grads_norm = 2.6848
	old_data_grads_norm = 3.5006
	sim_grads_norm = 0.0588
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6928
	data_grads_norm = 2.4847
	new_data_grads_norm = 2.6191
	old_data_grads_norm = 3.8577
	sim_grads_norm = -0.0239
-- Starting training on experience 65 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3571
	data_grads_norm = 2.3527
	new_data_grads_norm = 3.6758
	old_data_grads_norm = 3.2431
	sim_grads_norm = -0.0392
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4461
	data_grads_norm = 2.5627
	new_data_grads_norm = 3.4838
	old_data_grads_norm = 3.1669
	sim_grads_norm = 0.0775
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8047
	data_grads_norm = 3.0101
	new_data_grads_norm = 3.8756
	old_data_grads_norm = 3.8303
	sim_grads_norm = 0.0910
-- Starting training on experience 66 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5026
	data_grads_norm = 2.5790
	new_data_grads_norm = 3.3213
	old_data_grads_norm = 4.2393
	sim_grads_norm = 0.0034
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2499
	data_grads_norm = 2.4895
	new_data_grads_norm = 3.3637
	old_data_grads_norm = 3.6106
	sim_grads_norm = 0.1413
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3080
	data_grads_norm = 2.3337
	new_data_grads_norm = 3.1202
	old_data_grads_norm = 3.1890
	sim_grads_norm = 0.0237
-- Starting training on experience 67 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4224
	data_grads_norm = 2.4593
	new_data_grads_norm = 3.3658
	old_data_grads_norm = 3.4450
	sim_grads_norm = -0.0579
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4411
	data_grads_norm = 2.5898
	new_data_grads_norm = 3.3638
	old_data_grads_norm = 3.1908
	sim_grads_norm = 0.1779
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4965
	data_grads_norm = 2.5621
	new_data_grads_norm = 3.4419
	old_data_grads_norm = 4.0962
	sim_grads_norm = -0.0603
-- Starting training on experience 68 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9499
	data_grads_norm = 2.7012
	new_data_grads_norm = 3.2634
	old_data_grads_norm = 4.3181
	sim_grads_norm = 0.0459
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4327
	data_grads_norm = 2.9232
	new_data_grads_norm = 3.6872
	old_data_grads_norm = 4.4548
	sim_grads_norm = 0.0029
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7195
	data_grads_norm = 2.9495
	new_data_grads_norm = 3.4962
	old_data_grads_norm = 4.4683
	sim_grads_norm = 0.0001
-- Starting training on experience 69 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4684
	data_grads_norm = 2.5568
	new_data_grads_norm = 3.1980
	old_data_grads_norm = 3.8267
	sim_grads_norm = -0.0404
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0933
	data_grads_norm = 3.3682
	new_data_grads_norm = 3.8010
	old_data_grads_norm = 5.0991
	sim_grads_norm = 0.0765
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6365
	data_grads_norm = 2.7657
	new_data_grads_norm = 3.3256
	old_data_grads_norm = 3.7671
	sim_grads_norm = 0.0872
-- Starting training on experience 70 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7015
	data_grads_norm = 2.7959
	new_data_grads_norm = 3.7227
	old_data_grads_norm = 4.2474
	sim_grads_norm = -0.0381
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5916
	data_grads_norm = 2.3046
	new_data_grads_norm = 3.8084
	old_data_grads_norm = 3.0692
	sim_grads_norm = 0.0419
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7735
	data_grads_norm = 2.9629
	new_data_grads_norm = 3.6747
	old_data_grads_norm = 4.0820
	sim_grads_norm = 0.1608
-- Starting training on experience 71 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5427
	data_grads_norm = 2.8220
	new_data_grads_norm = 3.2861
	old_data_grads_norm = 4.3655
	sim_grads_norm = 0.0185
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3822
	data_grads_norm = 2.3933
	new_data_grads_norm = 2.8585
	old_data_grads_norm = 3.7884
	sim_grads_norm = 0.0632
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1065
	data_grads_norm = 2.4102
	new_data_grads_norm = 3.5421
	old_data_grads_norm = 3.0616
	sim_grads_norm = -0.0209
-- Starting training on experience 72 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4130
	data_grads_norm = 2.6599
	new_data_grads_norm = 3.0779
	old_data_grads_norm = 4.1043
	sim_grads_norm = 0.0156
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3883
	data_grads_norm = 2.6236
	new_data_grads_norm = 3.1838
	old_data_grads_norm = 3.8625
	sim_grads_norm = 0.0538
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4677
	data_grads_norm = 2.8205
	new_data_grads_norm = 3.1478
	old_data_grads_norm = 4.5825
	sim_grads_norm = 0.0049
-- Starting training on experience 73 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3538
	data_grads_norm = 2.9015
	new_data_grads_norm = 4.1414
	old_data_grads_norm = 4.0632
	sim_grads_norm = -0.0010
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3898
	data_grads_norm = 2.7101
	new_data_grads_norm = 4.3065
	old_data_grads_norm = 3.2878
	sim_grads_norm = -0.0507
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3440
	data_grads_norm = 3.1535
	new_data_grads_norm = 4.6028
	old_data_grads_norm = 4.0552
	sim_grads_norm = 0.0610
-- Starting training on experience 74 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2537
	data_grads_norm = 2.4807
	new_data_grads_norm = 3.3580
	old_data_grads_norm = 3.1031
	sim_grads_norm = 0.0212
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4171
	data_grads_norm = 2.3414
	new_data_grads_norm = 3.2892
	old_data_grads_norm = 3.0554
	sim_grads_norm = -0.0227
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4413
	data_grads_norm = 2.9887
	new_data_grads_norm = 3.6771
	old_data_grads_norm = 5.2065
	sim_grads_norm = 0.0011
-- Starting training on experience 75 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2057
	data_grads_norm = 2.5167
	new_data_grads_norm = 3.6426
	old_data_grads_norm = 3.7464
	sim_grads_norm = 0.0650
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3575
	data_grads_norm = 2.9155
	new_data_grads_norm = 3.9477
	old_data_grads_norm = 4.4191
	sim_grads_norm = -0.0618
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3754
	data_grads_norm = 2.5693
	new_data_grads_norm = 4.0700
	old_data_grads_norm = 2.8816
	sim_grads_norm = 0.0432
-- Starting training on experience 76 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1720
	data_grads_norm = 2.7805
	new_data_grads_norm = 3.2187
	old_data_grads_norm = 4.1203
	sim_grads_norm = 0.1193
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4182
	data_grads_norm = 3.1701
	new_data_grads_norm = 3.2426
	old_data_grads_norm = 4.2175
	sim_grads_norm = 0.0351
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3718
	data_grads_norm = 2.8097
	new_data_grads_norm = 3.3107
	old_data_grads_norm = 4.6160
	sim_grads_norm = 0.0468
-- Starting training on experience 77 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3845
	data_grads_norm = 3.2931
	new_data_grads_norm = 3.3251
	old_data_grads_norm = 4.5322
	sim_grads_norm = 0.1337
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3752
	data_grads_norm = 2.9320
	new_data_grads_norm = 3.0459
	old_data_grads_norm = 4.4076
	sim_grads_norm = -0.0389
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4508
	data_grads_norm = 2.5426
	new_data_grads_norm = 2.8858
	old_data_grads_norm = 3.7016
	sim_grads_norm = -0.0252
-- Starting training on experience 78 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8311
	data_grads_norm = 3.4029
	new_data_grads_norm = 3.8462
	old_data_grads_norm = 4.5743
	sim_grads_norm = 0.1620
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6968
	data_grads_norm = 2.5300
	new_data_grads_norm = 3.0726
	old_data_grads_norm = 3.5467
	sim_grads_norm = 0.0790
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3150
	data_grads_norm = 2.4392
	new_data_grads_norm = 3.0873
	old_data_grads_norm = 3.5852
	sim_grads_norm = 0.0090
-- Starting training on experience 79 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2821
	data_grads_norm = 2.9202
	new_data_grads_norm = 3.0174
	old_data_grads_norm = 4.1446
	sim_grads_norm = -0.0780
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4319
	data_grads_norm = 2.6203
	new_data_grads_norm = 3.3826
	old_data_grads_norm = 4.1522
	sim_grads_norm = -0.0960
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6201
	data_grads_norm = 3.0003
	new_data_grads_norm = 3.4488
	old_data_grads_norm = 4.9523
	sim_grads_norm = 0.0018
-- Starting training on experience 80 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7543
	data_grads_norm = 2.7748
	new_data_grads_norm = 3.2707
	old_data_grads_norm = 3.9038
	sim_grads_norm = 0.0125
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9433
	data_grads_norm = 3.0193
	new_data_grads_norm = 3.2453
	old_data_grads_norm = 5.0120
	sim_grads_norm = 0.0546
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7310
	data_grads_norm = 3.0718
	new_data_grads_norm = 3.2950
	old_data_grads_norm = 4.9278
	sim_grads_norm = 0.0167
-- Starting training on experience 81 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4186
	data_grads_norm = 2.5632
	new_data_grads_norm = 2.7651
	old_data_grads_norm = 4.1076
	sim_grads_norm = 0.0619
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3588
	data_grads_norm = 3.0584
	new_data_grads_norm = 2.7994
	old_data_grads_norm = 4.8053
	sim_grads_norm = 0.0357
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3588
	data_grads_norm = 2.4444
	new_data_grads_norm = 2.7652
	old_data_grads_norm = 4.1983
	sim_grads_norm = -0.0818
-- Starting training on experience 82 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8386
	data_grads_norm = 2.8275
	new_data_grads_norm = 2.8907
	old_data_grads_norm = 4.2392
	sim_grads_norm = 0.0430
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2590
	data_grads_norm = 2.6710
	new_data_grads_norm = 3.1577
	old_data_grads_norm = 4.7625
	sim_grads_norm = 0.0369
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5447
	data_grads_norm = 2.5896
	new_data_grads_norm = 3.1890
	old_data_grads_norm = 3.7239
	sim_grads_norm = 0.0285
-- Starting training on experience 83 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0863
	data_grads_norm = 2.3754
	new_data_grads_norm = 3.0874
	old_data_grads_norm = 3.8619
	sim_grads_norm = -0.0376
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2990
	data_grads_norm = 2.7377
	new_data_grads_norm = 3.0905
	old_data_grads_norm = 3.4979
	sim_grads_norm = -0.0153
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6808
	data_grads_norm = 2.6788
	new_data_grads_norm = 3.4099
	old_data_grads_norm = 3.6940
	sim_grads_norm = 0.0389
-- Starting training on experience 84 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1526
	data_grads_norm = 2.2951
	new_data_grads_norm = 3.2700
	old_data_grads_norm = 3.2654
	sim_grads_norm = -0.0421
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7419
	data_grads_norm = 3.4611
	new_data_grads_norm = 3.1931
	old_data_grads_norm = 5.1855
	sim_grads_norm = -0.0012
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4837
	data_grads_norm = 3.0169
	new_data_grads_norm = 3.3044
	old_data_grads_norm = 4.4861
	sim_grads_norm = 0.0599
-- Starting training on experience 85 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4600
	data_grads_norm = 2.2556
	new_data_grads_norm = 4.0140
	old_data_grads_norm = 2.6497
	sim_grads_norm = 0.0430
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4661
	data_grads_norm = 2.5668
	new_data_grads_norm = 3.8424
	old_data_grads_norm = 3.2715
	sim_grads_norm = -0.0274
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2359
	data_grads_norm = 3.6101
	new_data_grads_norm = 4.3459
	old_data_grads_norm = 4.9320
	sim_grads_norm = 0.1538
-- Starting training on experience 86 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0557
	data_grads_norm = 2.2243
	new_data_grads_norm = 2.8782
	old_data_grads_norm = 3.8416
	sim_grads_norm = -0.0004
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0077
	data_grads_norm = 3.1917
	new_data_grads_norm = 3.3726
	old_data_grads_norm = 4.9964
	sim_grads_norm = -0.0524
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8525
	data_grads_norm = 1.9844
	new_data_grads_norm = 3.1525
	old_data_grads_norm = 2.9139
	sim_grads_norm = -0.0295
-- Starting training on experience 87 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3681
	data_grads_norm = 3.0578
	new_data_grads_norm = 4.6018
	old_data_grads_norm = 3.6378
	sim_grads_norm = 0.0139
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1101
	data_grads_norm = 2.4054
	new_data_grads_norm = 3.7542
	old_data_grads_norm = 2.5552
	sim_grads_norm = 0.1127
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8559
	data_grads_norm = 3.8508
	new_data_grads_norm = 4.2795
	old_data_grads_norm = 5.9656
	sim_grads_norm = 0.0931
-- Starting training on experience 88 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2904
	data_grads_norm = 2.6298
	new_data_grads_norm = 3.3932
	old_data_grads_norm = 3.4865
	sim_grads_norm = 0.0963
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5412
	data_grads_norm = 2.7726
	new_data_grads_norm = 3.3174
	old_data_grads_norm = 4.3399
	sim_grads_norm = -0.0084
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1511
	data_grads_norm = 2.1740
	new_data_grads_norm = 3.1867
	old_data_grads_norm = 3.2417
	sim_grads_norm = -0.0361
-- Starting training on experience 89 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1632
	data_grads_norm = 2.5340
	new_data_grads_norm = 3.4165
	old_data_grads_norm = 3.7073
	sim_grads_norm = -0.0763
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5071
	data_grads_norm = 3.1849
	new_data_grads_norm = 4.1833
	old_data_grads_norm = 4.7481
	sim_grads_norm = 0.1126
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0941
	data_grads_norm = 3.3047
	new_data_grads_norm = 3.6550
	old_data_grads_norm = 4.4204
	sim_grads_norm = 0.0641
-- Starting training on experience 90 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8830
	data_grads_norm = 3.0678
	new_data_grads_norm = 4.1822
	old_data_grads_norm = 3.9978
	sim_grads_norm = 0.1351
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7814
	data_grads_norm = 3.1230
	new_data_grads_norm = 3.7541
	old_data_grads_norm = 4.8890
	sim_grads_norm = 0.0640
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5663
	data_grads_norm = 3.2298
	new_data_grads_norm = 4.4210
	old_data_grads_norm = 4.1053
	sim_grads_norm = 0.1283
-- Starting training on experience 91 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0691
	data_grads_norm = 2.7162
	new_data_grads_norm = 3.7386
	old_data_grads_norm = 4.0116
	sim_grads_norm = -0.0303
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9899
	data_grads_norm = 2.8317
	new_data_grads_norm = 4.1341
	old_data_grads_norm = 4.8009
	sim_grads_norm = -0.0711
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0984
	data_grads_norm = 3.1798
	new_data_grads_norm = 4.4301
	old_data_grads_norm = 4.3395
	sim_grads_norm = -0.0911
-- Starting training on experience 92 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2280
	data_grads_norm = 3.0696
	new_data_grads_norm = 3.9319
	old_data_grads_norm = 4.4774
	sim_grads_norm = 0.0132
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9364
	data_grads_norm = 3.0796
	new_data_grads_norm = 4.5069
	old_data_grads_norm = 4.2076
	sim_grads_norm = -0.0165
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5060
	data_grads_norm = 3.0276
	new_data_grads_norm = 4.0788
	old_data_grads_norm = 4.2809
	sim_grads_norm = 0.0143
-- Starting training on experience 93 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5554
	data_grads_norm = 3.4324
	new_data_grads_norm = 3.7664
	old_data_grads_norm = 4.5103
	sim_grads_norm = 0.0885
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2890
	data_grads_norm = 2.7679
	new_data_grads_norm = 3.7883
	old_data_grads_norm = 4.0181
	sim_grads_norm = -0.0357
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1993
	data_grads_norm = 2.5449
	new_data_grads_norm = 3.7606
	old_data_grads_norm = 3.8116
	sim_grads_norm = -0.0518
-- Starting training on experience 94 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2749
	data_grads_norm = 2.5355
	new_data_grads_norm = 3.1103
	old_data_grads_norm = 3.0191
	sim_grads_norm = 0.1356
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4494
	data_grads_norm = 2.4133
	new_data_grads_norm = 3.1119
	old_data_grads_norm = 3.9805
	sim_grads_norm = -0.0418
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2500
	data_grads_norm = 2.3441
	new_data_grads_norm = 2.9984
	old_data_grads_norm = 3.4116
	sim_grads_norm = -0.0156
-- Starting training on experience 95 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8377
	data_grads_norm = 2.8885
	new_data_grads_norm = 3.9514
	old_data_grads_norm = 3.9671
	sim_grads_norm = -0.0345
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8518
	data_grads_norm = 2.6792
	new_data_grads_norm = 4.2397
	old_data_grads_norm = 3.4901
	sim_grads_norm = 0.0341
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5754
	data_grads_norm = 3.2403
	new_data_grads_norm = 4.1060
	old_data_grads_norm = 4.6753
	sim_grads_norm = 0.0431
-- Starting training on experience 96 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0916
	data_grads_norm = 2.2622
	new_data_grads_norm = 3.1316
	old_data_grads_norm = 3.2340
	sim_grads_norm = 0.0683
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3787
	data_grads_norm = 2.5515
	new_data_grads_norm = 3.0234
	old_data_grads_norm = 3.8177
	sim_grads_norm = -0.0413
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2097
	data_grads_norm = 2.9405
	new_data_grads_norm = 3.4329
	old_data_grads_norm = 4.5809
	sim_grads_norm = -0.0253
-- Starting training on experience 97 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1975
	data_grads_norm = 2.5484
	new_data_grads_norm = 3.3114
	old_data_grads_norm = 3.8541
	sim_grads_norm = 0.0047
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1575
	data_grads_norm = 2.3147
	new_data_grads_norm = 3.3647
	old_data_grads_norm = 3.2090
	sim_grads_norm = -0.0140
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8109
	data_grads_norm = 2.6772
	new_data_grads_norm = 3.4655
	old_data_grads_norm = 3.5551
	sim_grads_norm = 0.0785
-- Starting training on experience 98 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3818
	data_grads_norm = 2.4269
	new_data_grads_norm = 3.7452
	old_data_grads_norm = 3.0881
	sim_grads_norm = -0.0000
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5717
	data_grads_norm = 2.8782
	new_data_grads_norm = 3.5310
	old_data_grads_norm = 3.8158
	sim_grads_norm = 0.0572
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3481
	data_grads_norm = 2.7756
	new_data_grads_norm = 3.4756
	old_data_grads_norm = 4.1081
	sim_grads_norm = -0.0051
-- Starting training on experience 99 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1679
	data_grads_norm = 2.8543
	new_data_grads_norm = 3.6955
	old_data_grads_norm = 4.0144
	sim_grads_norm = 0.0038
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4713
	data_grads_norm = 2.5153
	new_data_grads_norm = 3.7430
	old_data_grads_norm = 3.3021
	sim_grads_norm = -0.0103
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5000
	data_grads_norm = 3.0914
	new_data_grads_norm = 3.4631
	old_data_grads_norm = 5.4173
	sim_grads_norm = -0.0357
-- Starting training on experience 100 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5254
	data_grads_norm = 3.1114
	new_data_grads_norm = 3.9963
	old_data_grads_norm = 3.6988
	sim_grads_norm = 0.2192
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4289
	data_grads_norm = 2.9423
	new_data_grads_norm = 4.1128
	old_data_grads_norm = 3.2402
	sim_grads_norm = 0.1843
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6410
	data_grads_norm = 3.6787
	new_data_grads_norm = 4.3565
	old_data_grads_norm = 4.9952
	sim_grads_norm = -0.0570
-- Starting training on experience 101 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1211
	data_grads_norm = 2.4485
	new_data_grads_norm = 3.2688
	old_data_grads_norm = 3.7201
	sim_grads_norm = -0.0038
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9048
	data_grads_norm = 2.8577
	new_data_grads_norm = 3.4720
	old_data_grads_norm = 4.5127
	sim_grads_norm = 0.1133
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2992
	data_grads_norm = 2.5431
	new_data_grads_norm = 3.2049
	old_data_grads_norm = 3.9579
	sim_grads_norm = -0.0275
-- Starting training on experience 102 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4022
	data_grads_norm = 3.0918
	new_data_grads_norm = 3.5105
	old_data_grads_norm = 4.9595
	sim_grads_norm = -0.0014
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9735
	data_grads_norm = 3.5363
	new_data_grads_norm = 3.4193
	old_data_grads_norm = 6.3588
	sim_grads_norm = -0.0206
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4039
	data_grads_norm = 2.9025
	new_data_grads_norm = 3.3762
	old_data_grads_norm = 4.3754
	sim_grads_norm = 0.0274
-- Starting training on experience 103 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4790
	data_grads_norm = 2.3530
	new_data_grads_norm = 3.0125
	old_data_grads_norm = 3.6722
	sim_grads_norm = 0.0070
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2838
	data_grads_norm = 3.0334
	new_data_grads_norm = 3.2918
	old_data_grads_norm = 5.0915
	sim_grads_norm = -0.0368
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1512
	data_grads_norm = 2.5299
	new_data_grads_norm = 3.2925
	old_data_grads_norm = 3.1448
	sim_grads_norm = 0.1241
-- Starting training on experience 104 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9676
	data_grads_norm = 2.6609
	new_data_grads_norm = 3.1133
	old_data_grads_norm = 3.9284
	sim_grads_norm = 0.0944
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1886
	data_grads_norm = 2.3978
	new_data_grads_norm = 3.2212
	old_data_grads_norm = 3.9145
	sim_grads_norm = -0.1021
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7214
	data_grads_norm = 3.1021
	new_data_grads_norm = 3.3265
	old_data_grads_norm = 4.8851
	sim_grads_norm = 0.0120
-- Starting training on experience 105 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2396
	data_grads_norm = 2.6003
	new_data_grads_norm = 3.6912
	old_data_grads_norm = 3.4404
	sim_grads_norm = 0.0739
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1820
	data_grads_norm = 2.4262
	new_data_grads_norm = 3.5486
	old_data_grads_norm = 3.5288
	sim_grads_norm = -0.0115
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4345
	data_grads_norm = 2.7236
	new_data_grads_norm = 4.1478
	old_data_grads_norm = 4.1006
	sim_grads_norm = 0.0566
-- Starting training on experience 106 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3817
	data_grads_norm = 3.3798
	new_data_grads_norm = 4.4245
	old_data_grads_norm = 4.5425
	sim_grads_norm = 0.0395
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4709
	data_grads_norm = 3.1471
	new_data_grads_norm = 4.3838
	old_data_grads_norm = 3.9780
	sim_grads_norm = 0.0243
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2962
	data_grads_norm = 3.4109
	new_data_grads_norm = 4.0190
	old_data_grads_norm = 5.2970
	sim_grads_norm = -0.0799
-- Starting training on experience 107 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5392
	data_grads_norm = 2.4343
	new_data_grads_norm = 3.4102
	old_data_grads_norm = 3.0336
	sim_grads_norm = 0.0639
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3035
	data_grads_norm = 2.2788
	new_data_grads_norm = 3.1003
	old_data_grads_norm = 3.2461
	sim_grads_norm = 0.0561
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5360
	data_grads_norm = 2.9668
	new_data_grads_norm = 3.1872
	old_data_grads_norm = 4.5262
	sim_grads_norm = 0.0087
-- Starting training on experience 108 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2788
	data_grads_norm = 2.9611
	new_data_grads_norm = 4.0343
	old_data_grads_norm = 3.8357
	sim_grads_norm = -0.0584
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5280
	data_grads_norm = 2.6761
	new_data_grads_norm = 4.0507
	old_data_grads_norm = 3.2715
	sim_grads_norm = 0.2066
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2073
	data_grads_norm = 2.7285
	new_data_grads_norm = 3.8689
	old_data_grads_norm = 4.2679
	sim_grads_norm = -0.0904
-- Starting training on experience 109 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5207
	data_grads_norm = 2.8078
	new_data_grads_norm = 3.8147
	old_data_grads_norm = 3.9955
	sim_grads_norm = -0.0336
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1076
	data_grads_norm = 2.5556
	new_data_grads_norm = 3.8689
	old_data_grads_norm = 2.6134
	sim_grads_norm = 0.0525
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4548
	data_grads_norm = 3.0819
	new_data_grads_norm = 3.8956
	old_data_grads_norm = 4.1952
	sim_grads_norm = 0.0754
-- Starting training on experience 110 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3827
	data_grads_norm = 2.5036
	new_data_grads_norm = 3.7660
	old_data_grads_norm = 3.3585
	sim_grads_norm = -0.0066
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7196
	data_grads_norm = 3.3540
	new_data_grads_norm = 3.7682
	old_data_grads_norm = 5.3350
	sim_grads_norm = 0.0515
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4093
	data_grads_norm = 3.0854
	new_data_grads_norm = 3.6876
	old_data_grads_norm = 4.2203
	sim_grads_norm = 0.0210
-- Starting training on experience 111 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7360
	data_grads_norm = 3.3192
	new_data_grads_norm = 4.1996
	old_data_grads_norm = 3.7508
	sim_grads_norm = 0.2995
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1448
	data_grads_norm = 2.5582
	new_data_grads_norm = 3.6185
	old_data_grads_norm = 3.5999
	sim_grads_norm = -0.0223
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4473
	data_grads_norm = 3.3153
	new_data_grads_norm = 4.0162
	old_data_grads_norm = 4.8762
	sim_grads_norm = -0.0177
-- Starting training on experience 112 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0762
	data_grads_norm = 3.0212
	new_data_grads_norm = 3.7029
	old_data_grads_norm = 4.4339
	sim_grads_norm = 0.0083
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0635
	data_grads_norm = 2.8254
	new_data_grads_norm = 4.0743
	old_data_grads_norm = 4.0594
	sim_grads_norm = -0.0154
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2240
	data_grads_norm = 3.2026
	new_data_grads_norm = 3.6929
	old_data_grads_norm = 4.7584
	sim_grads_norm = 0.0158
-- Starting training on experience 113 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1730
	data_grads_norm = 3.2696
	new_data_grads_norm = 3.7239
	old_data_grads_norm = 4.3712
	sim_grads_norm = 0.0722
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0277
	data_grads_norm = 2.7294
	new_data_grads_norm = 3.4308
	old_data_grads_norm = 4.7015
	sim_grads_norm = 0.0090
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1107
	data_grads_norm = 2.8319
	new_data_grads_norm = 3.6328
	old_data_grads_norm = 4.9181
	sim_grads_norm = -0.0412
-- Starting training on experience 114 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1012
	data_grads_norm = 2.5987
	new_data_grads_norm = 3.4093
	old_data_grads_norm = 4.5497
	sim_grads_norm = 0.0229
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9751
	data_grads_norm = 2.5273
	new_data_grads_norm = 3.4940
	old_data_grads_norm = 4.0027
	sim_grads_norm = 0.1306
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1934
	data_grads_norm = 2.9183
	new_data_grads_norm = 3.4549
	old_data_grads_norm = 3.9763
	sim_grads_norm = 0.0563
-- Starting training on experience 115 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0176
	data_grads_norm = 2.4552
	new_data_grads_norm = 3.4232
	old_data_grads_norm = 3.3388
	sim_grads_norm = 0.0618
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9930
	data_grads_norm = 2.3014
	new_data_grads_norm = 3.1388
	old_data_grads_norm = 4.7290
	sim_grads_norm = -0.0208
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3523
	data_grads_norm = 2.9011
	new_data_grads_norm = 3.3219
	old_data_grads_norm = 3.7221
	sim_grads_norm = 0.0942
-- Starting training on experience 116 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9364
	data_grads_norm = 2.7842
	new_data_grads_norm = 4.0186
	old_data_grads_norm = 3.7577
	sim_grads_norm = 0.0524
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0695
	data_grads_norm = 2.8530
	new_data_grads_norm = 3.9938
	old_data_grads_norm = 4.0316
	sim_grads_norm = 0.0451
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9071
	data_grads_norm = 2.8654
	new_data_grads_norm = 3.8519
	old_data_grads_norm = 3.8097
	sim_grads_norm = -0.0410
-- Starting training on experience 117 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2750
	data_grads_norm = 2.9233
	new_data_grads_norm = 4.0631
	old_data_grads_norm = 4.0247
	sim_grads_norm = 0.0306
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2344
	data_grads_norm = 2.9973
	new_data_grads_norm = 4.2910
	old_data_grads_norm = 4.6778
	sim_grads_norm = -0.0750
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9676
	data_grads_norm = 2.8988
	new_data_grads_norm = 4.3698
	old_data_grads_norm = 3.4962
	sim_grads_norm = -0.0709
-- Starting training on experience 118 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5449
	data_grads_norm = 2.9904
	new_data_grads_norm = 3.8732
	old_data_grads_norm = 4.5158
	sim_grads_norm = 0.0142
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4263
	data_grads_norm = 3.1857
	new_data_grads_norm = 4.0445
	old_data_grads_norm = 5.0494
	sim_grads_norm = 0.0243
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0836
	data_grads_norm = 2.2563
	new_data_grads_norm = 3.6991
	old_data_grads_norm = 2.7690
	sim_grads_norm = -0.0234
-- Starting training on experience 119 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4340
	data_grads_norm = 2.9306
	new_data_grads_norm = 3.2136
	old_data_grads_norm = 4.8525
	sim_grads_norm = -0.0102
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1537
	data_grads_norm = 3.2030
	new_data_grads_norm = 3.4356
	old_data_grads_norm = 4.7929
	sim_grads_norm = 0.0530
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7351
	data_grads_norm = 2.3067
	new_data_grads_norm = 3.7474
	old_data_grads_norm = 3.0683
	sim_grads_norm = -0.0581
-- Starting training on experience 120 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4937
	data_grads_norm = 3.6022
	new_data_grads_norm = 4.8277
	old_data_grads_norm = 5.8562
	sim_grads_norm = 0.0018
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1662
	data_grads_norm = 4.0774
	new_data_grads_norm = 4.9378
	old_data_grads_norm = 5.8668
	sim_grads_norm = -0.0164
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3417
	data_grads_norm = 3.1272
	new_data_grads_norm = 4.4053
	old_data_grads_norm = 4.0627
	sim_grads_norm = -0.0111
-- Starting training on experience 121 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4619
	data_grads_norm = 3.3234
	new_data_grads_norm = 4.5358
	old_data_grads_norm = 4.8174
	sim_grads_norm = -0.0387
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4686
	data_grads_norm = 3.6000
	new_data_grads_norm = 4.6670
	old_data_grads_norm = 4.7457
	sim_grads_norm = 0.1555
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2006
	data_grads_norm = 2.9191
	new_data_grads_norm = 4.1046
	old_data_grads_norm = 3.7056
	sim_grads_norm = 0.0139
-- Starting training on experience 122 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4769
	data_grads_norm = 2.6699
	new_data_grads_norm = 4.0964
	old_data_grads_norm = 3.6665
	sim_grads_norm = -0.0270
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9339
	data_grads_norm = 2.4857
	new_data_grads_norm = 3.8649
	old_data_grads_norm = 4.1398
	sim_grads_norm = -0.0931
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9626
	data_grads_norm = 3.2985
	new_data_grads_norm = 4.4172
	old_data_grads_norm = 4.3559
	sim_grads_norm = -0.0564
-- Starting training on experience 123 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1524
	data_grads_norm = 2.9860
	new_data_grads_norm = 3.3978
	old_data_grads_norm = 3.8312
	sim_grads_norm = 0.0865
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5275
	data_grads_norm = 2.4915
	new_data_grads_norm = 3.3876
	old_data_grads_norm = 3.4876
	sim_grads_norm = 0.0604
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6142
	data_grads_norm = 2.7099
	new_data_grads_norm = 3.5035
	old_data_grads_norm = 3.9056
	sim_grads_norm = 0.0705
-- Starting training on experience 124 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2602
	data_grads_norm = 2.3372
	new_data_grads_norm = 3.2979
	old_data_grads_norm = 2.9039
	sim_grads_norm = 0.1328
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2179
	data_grads_norm = 2.6301
	new_data_grads_norm = 3.2910
	old_data_grads_norm = 4.2662
	sim_grads_norm = -0.0327
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3318
	data_grads_norm = 3.1144
	new_data_grads_norm = 3.8041
	old_data_grads_norm = 4.6509
	sim_grads_norm = 0.0577
-- Starting training on experience 125 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5287
	data_grads_norm = 2.9844
	new_data_grads_norm = 4.4406
	old_data_grads_norm = 3.6333
	sim_grads_norm = 0.0222
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4670
	data_grads_norm = 3.0657
	new_data_grads_norm = 4.6968
	old_data_grads_norm = 3.3465
	sim_grads_norm = 0.1000
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9218
	data_grads_norm = 2.2713
	new_data_grads_norm = 4.2475
	old_data_grads_norm = 2.6186
	sim_grads_norm = -0.0565
-- Starting training on experience 126 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2066
	data_grads_norm = 3.1189
	new_data_grads_norm = 3.9641
	old_data_grads_norm = 5.2157
	sim_grads_norm = 0.0118
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2275
	data_grads_norm = 2.7185
	new_data_grads_norm = 3.6090
	old_data_grads_norm = 3.8058
	sim_grads_norm = 0.0525
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1313
	data_grads_norm = 2.7122
	new_data_grads_norm = 3.3971
	old_data_grads_norm = 4.0592
	sim_grads_norm = 0.1261
-- Starting training on experience 127 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1789
	data_grads_norm = 2.7643
	new_data_grads_norm = 3.5482
	old_data_grads_norm = 4.3577
	sim_grads_norm = -0.0273
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3731
	data_grads_norm = 3.3107
	new_data_grads_norm = 3.8102
	old_data_grads_norm = 5.5742
	sim_grads_norm = 0.0427
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5566
	data_grads_norm = 3.1592
	new_data_grads_norm = 3.6815
	old_data_grads_norm = 5.1711
	sim_grads_norm = -0.0110
-- Starting training on experience 128 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6757
	data_grads_norm = 3.4478
	new_data_grads_norm = 4.7761
	old_data_grads_norm = 4.9181
	sim_grads_norm = 0.0138
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3592
	data_grads_norm = 2.9679
	new_data_grads_norm = 4.8024
	old_data_grads_norm = 3.0960
	sim_grads_norm = 0.1289
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5883
	data_grads_norm = 2.9101
	new_data_grads_norm = 5.0002
	old_data_grads_norm = 3.3518
	sim_grads_norm = 0.0989
-- Starting training on experience 129 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3767
	data_grads_norm = 3.1632
	new_data_grads_norm = 3.6646
	old_data_grads_norm = 4.0874
	sim_grads_norm = 0.1028
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9934
	data_grads_norm = 2.7516
	new_data_grads_norm = 3.6754
	old_data_grads_norm = 3.7794
	sim_grads_norm = 0.0642
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7782
	data_grads_norm = 2.7516
	new_data_grads_norm = 3.7990
	old_data_grads_norm = 4.2399
	sim_grads_norm = -0.0465
-- Starting training on experience 130 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2141
	data_grads_norm = 2.8532
	new_data_grads_norm = 3.8055
	old_data_grads_norm = 3.4865
	sim_grads_norm = 0.1937
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1469
	data_grads_norm = 3.1512
	new_data_grads_norm = 3.6836
	old_data_grads_norm = 4.4868
	sim_grads_norm = 0.0019
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2590
	data_grads_norm = 2.8301
	new_data_grads_norm = 3.6431
	old_data_grads_norm = 4.1842
	sim_grads_norm = 0.0712
-- Starting training on experience 131 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8394
	data_grads_norm = 3.6200
	new_data_grads_norm = 4.2186
	old_data_grads_norm = 4.5745
	sim_grads_norm = 0.2144
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2127
	data_grads_norm = 2.6562
	new_data_grads_norm = 3.9113
	old_data_grads_norm = 3.5828
	sim_grads_norm = 0.0588
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1015
	data_grads_norm = 2.7263
	new_data_grads_norm = 3.6860
	old_data_grads_norm = 4.1151
	sim_grads_norm = -0.0528
-- Starting training on experience 132 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7779
	data_grads_norm = 3.8365
	new_data_grads_norm = 4.5378
	old_data_grads_norm = 5.7169
	sim_grads_norm = 0.1203
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0568
	data_grads_norm = 2.7378
	new_data_grads_norm = 4.1517
	old_data_grads_norm = 3.6582
	sim_grads_norm = -0.0460
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3324
	data_grads_norm = 2.7024
	new_data_grads_norm = 4.1965
	old_data_grads_norm = 4.0489
	sim_grads_norm = -0.0465
-- Starting training on experience 133 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1996
	data_grads_norm = 2.6156
	new_data_grads_norm = 3.6281
	old_data_grads_norm = 3.9475
	sim_grads_norm = -0.0574
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6890
	data_grads_norm = 2.6270
	new_data_grads_norm = 3.5880
	old_data_grads_norm = 3.9044
	sim_grads_norm = -0.0148
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4694
	data_grads_norm = 3.4815
	new_data_grads_norm = 4.3988
	old_data_grads_norm = 4.9712
	sim_grads_norm = 0.0947
-- Starting training on experience 134 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9091
	data_grads_norm = 2.5458
	new_data_grads_norm = 3.4718
	old_data_grads_norm = 3.4087
	sim_grads_norm = 0.0474
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8527
	data_grads_norm = 2.7431
	new_data_grads_norm = 3.6234
	old_data_grads_norm = 3.9885
	sim_grads_norm = -0.0449
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8392
	data_grads_norm = 2.2576
	new_data_grads_norm = 3.5637
	old_data_grads_norm = 2.9202
	sim_grads_norm = -0.0754
-- Starting training on experience 135 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1202
	data_grads_norm = 2.8930
	new_data_grads_norm = 3.6022
	old_data_grads_norm = 3.7526
	sim_grads_norm = 0.2293
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0518
	data_grads_norm = 2.9574
	new_data_grads_norm = 3.6907
	old_data_grads_norm = 3.8317
	sim_grads_norm = -0.0598
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7448
	data_grads_norm = 2.3501
	new_data_grads_norm = 3.7042
	old_data_grads_norm = 3.1611
	sim_grads_norm = -0.0634
-- Starting training on experience 136 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0377
	data_grads_norm = 3.0201
	new_data_grads_norm = 4.9480
	old_data_grads_norm = 3.8611
	sim_grads_norm = 0.1213
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1413
	data_grads_norm = 2.8777
	new_data_grads_norm = 4.5414
	old_data_grads_norm = 3.4537
	sim_grads_norm = -0.0234
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8874
	data_grads_norm = 2.9106
	new_data_grads_norm = 4.7755
	old_data_grads_norm = 3.9587
	sim_grads_norm = -0.0558
-- Starting training on experience 137 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4885
	data_grads_norm = 3.8270
	new_data_grads_norm = 4.2671
	old_data_grads_norm = 5.6480
	sim_grads_norm = 0.0998
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1698
	data_grads_norm = 3.1377
	new_data_grads_norm = 4.0684
	old_data_grads_norm = 4.5232
	sim_grads_norm = 0.0318
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0595
	data_grads_norm = 2.6748
	new_data_grads_norm = 3.8765
	old_data_grads_norm = 3.5022
	sim_grads_norm = -0.0264
-- Starting training on experience 138 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6542
	data_grads_norm = 3.2032
	new_data_grads_norm = 3.8392
	old_data_grads_norm = 4.9350
	sim_grads_norm = 0.0487
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5178
	data_grads_norm = 2.9046
	new_data_grads_norm = 3.9751
	old_data_grads_norm = 4.3287
	sim_grads_norm = -0.0202
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3519
	data_grads_norm = 3.1534
	new_data_grads_norm = 3.6821
	old_data_grads_norm = 5.0794
	sim_grads_norm = 0.0143
-- Starting training on experience 139 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5719
	data_grads_norm = 3.0680
	new_data_grads_norm = 3.7869
	old_data_grads_norm = 4.0650
	sim_grads_norm = 0.1740
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1254
	data_grads_norm = 2.6980
	new_data_grads_norm = 3.8246
	old_data_grads_norm = 3.6811
	sim_grads_norm = -0.0138
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3059
	data_grads_norm = 3.0531
	new_data_grads_norm = 3.9365
	old_data_grads_norm = 4.6007
	sim_grads_norm = -0.0131
-- Starting training on experience 140 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1273
	data_grads_norm = 2.5455
	new_data_grads_norm = 3.8200
	old_data_grads_norm = 3.0444
	sim_grads_norm = 0.0478
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2567
	data_grads_norm = 3.0495
	new_data_grads_norm = 4.0068
	old_data_grads_norm = 4.2148
	sim_grads_norm = 0.0232
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3685
	data_grads_norm = 3.4949
	new_data_grads_norm = 4.4185
	old_data_grads_norm = 5.1329
	sim_grads_norm = 0.0517
-- Starting training on experience 141 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4474
	data_grads_norm = 3.0964
	new_data_grads_norm = 4.9503
	old_data_grads_norm = 3.1216
	sim_grads_norm = 0.0422
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9088
	data_grads_norm = 2.7622
	new_data_grads_norm = 4.5376
	old_data_grads_norm = 3.6635
	sim_grads_norm = -0.0492
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1041
	data_grads_norm = 3.0240
	new_data_grads_norm = 4.7200
	old_data_grads_norm = 3.7001
	sim_grads_norm = 0.0818
-- Starting training on experience 142 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4623
	data_grads_norm = 3.6791
	new_data_grads_norm = 4.0361
	old_data_grads_norm = 5.2843
	sim_grads_norm = 0.0479
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8811
	data_grads_norm = 4.0092
	new_data_grads_norm = 4.2050
	old_data_grads_norm = 6.5093
	sim_grads_norm = 0.1458
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4533
	data_grads_norm = 3.1753
	new_data_grads_norm = 3.9202
	old_data_grads_norm = 4.7025
	sim_grads_norm = -0.0025
-- Starting training on experience 143 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8687
	data_grads_norm = 2.6536
	new_data_grads_norm = 3.5669
	old_data_grads_norm = 3.6151
	sim_grads_norm = 0.0349
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2758
	data_grads_norm = 3.9656
	new_data_grads_norm = 3.3835
	old_data_grads_norm = 5.7858
	sim_grads_norm = 0.0721
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9954
	data_grads_norm = 2.7866
	new_data_grads_norm = 3.3602
	old_data_grads_norm = 4.2828
	sim_grads_norm = -0.0329
-- Starting training on experience 144 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2016
	data_grads_norm = 2.9095
	new_data_grads_norm = 4.0563
	old_data_grads_norm = 4.1229
	sim_grads_norm = -0.0111
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8060
	data_grads_norm = 3.9176
	new_data_grads_norm = 5.1771
	old_data_grads_norm = 5.7215
	sim_grads_norm = 0.0860
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6047
	data_grads_norm = 3.4401
	new_data_grads_norm = 4.5749
	old_data_grads_norm = 5.1701
	sim_grads_norm = 0.0343
-- Starting training on experience 145 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3649
	data_grads_norm = 2.7089
	new_data_grads_norm = 3.8682
	old_data_grads_norm = 3.4255
	sim_grads_norm = 0.1259
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3060
	data_grads_norm = 2.8948
	new_data_grads_norm = 3.4942
	old_data_grads_norm = 4.1803
	sim_grads_norm = 0.0137
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5339
	data_grads_norm = 3.1380
	new_data_grads_norm = 3.6343
	old_data_grads_norm = 4.9041
	sim_grads_norm = 0.0154
-- Starting training on experience 146 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0342
	data_grads_norm = 2.3292
	new_data_grads_norm = 3.0354
	old_data_grads_norm = 3.5308
	sim_grads_norm = 0.0487
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3038
	data_grads_norm = 2.1837
	new_data_grads_norm = 3.0369
	old_data_grads_norm = 3.0655
	sim_grads_norm = 0.1267
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9661
	data_grads_norm = 2.2546
	new_data_grads_norm = 3.0452
	old_data_grads_norm = 3.2965
	sim_grads_norm = -0.0670
-- Starting training on experience 147 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0542
	data_grads_norm = 2.7950
	new_data_grads_norm = 3.6273
	old_data_grads_norm = 4.1610
	sim_grads_norm = 0.0292
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0963
	data_grads_norm = 2.6982
	new_data_grads_norm = 3.3100
	old_data_grads_norm = 4.1700
	sim_grads_norm = 0.0306
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1252
	data_grads_norm = 2.8763
	new_data_grads_norm = 3.3524
	old_data_grads_norm = 4.3824
	sim_grads_norm = -0.0350
-- Starting training on experience 148 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1975
	data_grads_norm = 3.1830
	new_data_grads_norm = 4.2613
	old_data_grads_norm = 4.2909
	sim_grads_norm = 0.0629
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9167
	data_grads_norm = 2.5003
	new_data_grads_norm = 3.4387
	old_data_grads_norm = 3.3253
	sim_grads_norm = 0.0453
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3292
	data_grads_norm = 2.8805
	new_data_grads_norm = 3.6560
	old_data_grads_norm = 4.2119
	sim_grads_norm = 0.0624
-- Starting training on experience 149 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2597
	data_grads_norm = 3.0717
	new_data_grads_norm = 3.8565
	old_data_grads_norm = 3.9574
	sim_grads_norm = 0.0474
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0802
	data_grads_norm = 3.0062
	new_data_grads_norm = 3.9250
	old_data_grads_norm = 4.5828
	sim_grads_norm = 0.0117
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1731
	data_grads_norm = 3.0653
	new_data_grads_norm = 4.2387
	old_data_grads_norm = 4.2137
	sim_grads_norm = -0.0367
-- Starting training on experience 150 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0216
	data_grads_norm = 2.8349
	new_data_grads_norm = 3.9824
	old_data_grads_norm = 4.1961
	sim_grads_norm = 0.0213
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2637
	data_grads_norm = 3.3814
	new_data_grads_norm = 4.1925
	old_data_grads_norm = 4.4465
	sim_grads_norm = 0.0706
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7431
	data_grads_norm = 2.6534
	new_data_grads_norm = 3.5807
	old_data_grads_norm = 3.5567
	sim_grads_norm = -0.0052
-- Starting training on experience 151 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8238
	data_grads_norm = 2.9880
	new_data_grads_norm = 3.9010
	old_data_grads_norm = 4.0541
	sim_grads_norm = 0.0363
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3963
	data_grads_norm = 2.8423
	new_data_grads_norm = 4.0077
	old_data_grads_norm = 3.6703
	sim_grads_norm = 0.0231
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3758
	data_grads_norm = 3.0400
	new_data_grads_norm = 3.8950
	old_data_grads_norm = 4.3428
	sim_grads_norm = 0.0146
-- Starting training on experience 152 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9618
	data_grads_norm = 3.2082
	new_data_grads_norm = 4.0838
	old_data_grads_norm = 5.0174
	sim_grads_norm = -0.0065
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4538
	data_grads_norm = 3.0412
	new_data_grads_norm = 4.0059
	old_data_grads_norm = 4.8728
	sim_grads_norm = -0.0205
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0751
	data_grads_norm = 3.1114
	new_data_grads_norm = 4.7195
	old_data_grads_norm = 4.4457
	sim_grads_norm = 0.0048
-- Starting training on experience 153 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2776
	data_grads_norm = 3.5367
	new_data_grads_norm = 5.1953
	old_data_grads_norm = 3.5746
	sim_grads_norm = -0.0013
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6246
	data_grads_norm = 3.4157
	new_data_grads_norm = 5.1060
	old_data_grads_norm = 4.5151
	sim_grads_norm = -0.0184
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3857
	data_grads_norm = 3.5871
	new_data_grads_norm = 5.1301
	old_data_grads_norm = 4.2252
	sim_grads_norm = 0.1246
-- Starting training on experience 154 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2440
	data_grads_norm = 2.4818
	new_data_grads_norm = 3.6936
	old_data_grads_norm = 3.3162
	sim_grads_norm = 0.0289
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6548
	data_grads_norm = 2.8267
	new_data_grads_norm = 3.5702
	old_data_grads_norm = 4.0686
	sim_grads_norm = 0.0395
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2561
	data_grads_norm = 2.7237
	new_data_grads_norm = 3.2993
	old_data_grads_norm = 3.5657
	sim_grads_norm = 0.0516
-- Starting training on experience 155 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5269
	data_grads_norm = 3.0659
	new_data_grads_norm = 3.9773
	old_data_grads_norm = 4.2121
	sim_grads_norm = 0.0464
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3682
	data_grads_norm = 3.2615
	new_data_grads_norm = 3.9384
	old_data_grads_norm = 4.4929
	sim_grads_norm = 0.0256
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2096
	data_grads_norm = 2.6413
	new_data_grads_norm = 3.7087
	old_data_grads_norm = 3.9381
	sim_grads_norm = -0.0847
-- Starting training on experience 156 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2242
	data_grads_norm = 2.5352
	new_data_grads_norm = 3.7756
	old_data_grads_norm = 3.5884
	sim_grads_norm = -0.0217
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8816
	data_grads_norm = 2.4413
	new_data_grads_norm = 4.1485
	old_data_grads_norm = 3.3210
	sim_grads_norm = 0.0342
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7774
	data_grads_norm = 3.0883
	new_data_grads_norm = 4.5189
	old_data_grads_norm = 3.6594
	sim_grads_norm = 0.0866
-- Starting training on experience 157 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3350
	data_grads_norm = 2.9989
	new_data_grads_norm = 3.8479
	old_data_grads_norm = 3.6556
	sim_grads_norm = 0.0845
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2817
	data_grads_norm = 3.1962
	new_data_grads_norm = 3.9129
	old_data_grads_norm = 4.3685
	sim_grads_norm = -0.0303
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0887
	data_grads_norm = 3.3088
	new_data_grads_norm = 4.1578
	old_data_grads_norm = 4.9079
	sim_grads_norm = -0.0241
-- Starting training on experience 158 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7312
	data_grads_norm = 3.3647
	new_data_grads_norm = 4.2882
	old_data_grads_norm = 3.8408
	sim_grads_norm = 0.1631
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5428
	data_grads_norm = 3.1133
	new_data_grads_norm = 4.5499
	old_data_grads_norm = 4.0988
	sim_grads_norm = -0.0303
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7656
	data_grads_norm = 3.2016
	new_data_grads_norm = 4.5759
	old_data_grads_norm = 3.9628
	sim_grads_norm = 0.0497
-- Starting training on experience 159 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2041
	data_grads_norm = 2.9534
	new_data_grads_norm = 3.4733
	old_data_grads_norm = 5.0401
	sim_grads_norm = -0.0001
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4535
	data_grads_norm = 3.0546
	new_data_grads_norm = 4.0523
	old_data_grads_norm = 4.3732
	sim_grads_norm = 0.0057
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3031
	data_grads_norm = 2.8333
	new_data_grads_norm = 3.9010
	old_data_grads_norm = 3.9362
	sim_grads_norm = 0.0380
-- Starting training on experience 160 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2335
	data_grads_norm = 3.1067
	new_data_grads_norm = 4.2863
	old_data_grads_norm = 4.3791
	sim_grads_norm = 0.0715
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0457
	data_grads_norm = 2.9925
	new_data_grads_norm = 4.1672
	old_data_grads_norm = 4.4158
	sim_grads_norm = 0.0734
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9619
	data_grads_norm = 2.9334
	new_data_grads_norm = 3.9859
	old_data_grads_norm = 4.4610
	sim_grads_norm = 0.0790
-- Starting training on experience 161 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2857
	data_grads_norm = 3.0642
	new_data_grads_norm = 4.8291
	old_data_grads_norm = 3.8661
	sim_grads_norm = 0.0662
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1758
	data_grads_norm = 3.2996
	new_data_grads_norm = 5.2690
	old_data_grads_norm = 3.5694
	sim_grads_norm = 0.0108
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9974
	data_grads_norm = 2.7733
	new_data_grads_norm = 4.8393
	old_data_grads_norm = 3.2530
	sim_grads_norm = -0.0491
-- Starting training on experience 162 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4020
	data_grads_norm = 3.1369
	new_data_grads_norm = 4.0819
	old_data_grads_norm = 4.1332
	sim_grads_norm = 0.0848
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1306
	data_grads_norm = 2.6339
	new_data_grads_norm = 4.6742
	old_data_grads_norm = 3.9016
	sim_grads_norm = -0.0548
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4923
	data_grads_norm = 3.4248
	new_data_grads_norm = 4.4784
	old_data_grads_norm = 4.6392
	sim_grads_norm = 0.0428
-- Starting training on experience 163 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0419
	data_grads_norm = 3.0855
	new_data_grads_norm = 4.3333
	old_data_grads_norm = 3.4187
	sim_grads_norm = 0.1575
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3609
	data_grads_norm = 3.6248
	new_data_grads_norm = 4.3199
	old_data_grads_norm = 5.4931
	sim_grads_norm = 0.0138
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2610
	data_grads_norm = 3.6765
	new_data_grads_norm = 4.2135
	old_data_grads_norm = 5.1531
	sim_grads_norm = -0.0269
-- Starting training on experience 164 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4776
	data_grads_norm = 4.1019
	new_data_grads_norm = 5.0417
	old_data_grads_norm = 4.6619
	sim_grads_norm = 0.0418
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2496
	data_grads_norm = 3.2266
	new_data_grads_norm = 5.0535
	old_data_grads_norm = 4.4364
	sim_grads_norm = -0.0661
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8905
	data_grads_norm = 3.3989
	new_data_grads_norm = 5.2330
	old_data_grads_norm = 4.4105
	sim_grads_norm = -0.0031
-- Starting training on experience 165 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2837
	data_grads_norm = 3.1689
	new_data_grads_norm = 5.0660
	old_data_grads_norm = 4.9918
	sim_grads_norm = -0.0072
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4526
	data_grads_norm = 3.0535
	new_data_grads_norm = 4.9862
	old_data_grads_norm = 4.0711
	sim_grads_norm = -0.0576
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8963
	data_grads_norm = 2.9302
	new_data_grads_norm = 4.5860
	old_data_grads_norm = 4.5104
	sim_grads_norm = 0.0733
-- Starting training on experience 166 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4513
	data_grads_norm = 3.1605
	new_data_grads_norm = 3.8737
	old_data_grads_norm = 4.4726
	sim_grads_norm = 0.0198
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5428
	data_grads_norm = 3.1280
	new_data_grads_norm = 3.7212
	old_data_grads_norm = 4.6249
	sim_grads_norm = 0.0166
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3254
	data_grads_norm = 2.7198
	new_data_grads_norm = 3.6247
	old_data_grads_norm = 3.9919
	sim_grads_norm = -0.0558
-- Starting training on experience 167 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4638
	data_grads_norm = 3.0151
	new_data_grads_norm = 3.5920
	old_data_grads_norm = 4.6986
	sim_grads_norm = 0.0345
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2241
	data_grads_norm = 2.9925
	new_data_grads_norm = 3.8126
	old_data_grads_norm = 4.5619
	sim_grads_norm = -0.0083
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3338
	data_grads_norm = 2.7470
	new_data_grads_norm = 3.9871
	old_data_grads_norm = 5.1790
	sim_grads_norm = -0.0253
-- Starting training on experience 168 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2474
	data_grads_norm = 3.2577
	new_data_grads_norm = 4.2330
	old_data_grads_norm = 4.6968
	sim_grads_norm = 0.0270
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3733
	data_grads_norm = 3.0784
	new_data_grads_norm = 4.3476
	old_data_grads_norm = 4.2225
	sim_grads_norm = 0.0255
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5451
	data_grads_norm = 3.3969
	new_data_grads_norm = 4.1333
	old_data_grads_norm = 4.9273
	sim_grads_norm = 0.0011
-- Starting training on experience 169 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6792
	data_grads_norm = 3.1225
	new_data_grads_norm = 4.7005
	old_data_grads_norm = 4.3778
	sim_grads_norm = 0.0441
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1903
	data_grads_norm = 3.4025
	new_data_grads_norm = 4.3346
	old_data_grads_norm = 4.8706
	sim_grads_norm = -0.0016
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7478
	data_grads_norm = 3.2250
	new_data_grads_norm = 4.2107
	old_data_grads_norm = 4.6949
	sim_grads_norm = 0.0263
-- Starting training on experience 170 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3423
	data_grads_norm = 2.8481
	new_data_grads_norm = 3.4350
	old_data_grads_norm = 4.0299
	sim_grads_norm = 0.1470
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4560
	data_grads_norm = 2.7436
	new_data_grads_norm = 3.9244
	old_data_grads_norm = 3.4407
	sim_grads_norm = 0.0164
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1191
	data_grads_norm = 2.5654
	new_data_grads_norm = 3.4458
	old_data_grads_norm = 3.8169
	sim_grads_norm = -0.0149
-- Starting training on experience 171 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9310
	data_grads_norm = 2.7590
	new_data_grads_norm = 3.9384
	old_data_grads_norm = 4.1580
	sim_grads_norm = 0.0023
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1051
	data_grads_norm = 2.7840
	new_data_grads_norm = 3.5872
	old_data_grads_norm = 4.4783
	sim_grads_norm = -0.1032
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2908
	data_grads_norm = 2.8183
	new_data_grads_norm = 4.0619
	old_data_grads_norm = 3.5639
	sim_grads_norm = 0.0873
-- Starting training on experience 172 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5635
	data_grads_norm = 2.7301
	new_data_grads_norm = 3.6533
	old_data_grads_norm = 3.6876
	sim_grads_norm = 0.1273
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8947
	data_grads_norm = 3.2339
	new_data_grads_norm = 3.6302
	old_data_grads_norm = 4.8583
	sim_grads_norm = 0.0570
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4895
	data_grads_norm = 2.6547
	new_data_grads_norm = 3.6098
	old_data_grads_norm = 3.5453
	sim_grads_norm = -0.0177
-- Starting training on experience 173 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5387
	data_grads_norm = 2.8025
	new_data_grads_norm = 4.4146
	old_data_grads_norm = 3.4858
	sim_grads_norm = 0.0109
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7674
	data_grads_norm = 3.7156
	new_data_grads_norm = 4.6345
	old_data_grads_norm = 4.9793
	sim_grads_norm = -0.0122
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3181
	data_grads_norm = 3.2209
	new_data_grads_norm = 4.6835
	old_data_grads_norm = 4.1374
	sim_grads_norm = -0.0275
-- Starting training on experience 174 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1725
	data_grads_norm = 2.7095
	new_data_grads_norm = 3.8907
	old_data_grads_norm = 3.7666
	sim_grads_norm = -0.0150
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3421
	data_grads_norm = 3.0964
	new_data_grads_norm = 4.2290
	old_data_grads_norm = 4.7224
	sim_grads_norm = -0.0091
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9946
	data_grads_norm = 3.0859
	new_data_grads_norm = 4.0907
	old_data_grads_norm = 5.4165
	sim_grads_norm = 0.0388
-- Starting training on experience 175 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1848
	data_grads_norm = 3.2513
	new_data_grads_norm = 4.1773
	old_data_grads_norm = 4.1903
	sim_grads_norm = -0.0261
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0581
	data_grads_norm = 2.6758
	new_data_grads_norm = 4.1339
	old_data_grads_norm = 2.9200
	sim_grads_norm = 0.0566
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2419
	data_grads_norm = 3.5151
	new_data_grads_norm = 4.3069
	old_data_grads_norm = 5.6751
	sim_grads_norm = -0.0347
-- Starting training on experience 176 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4306
	data_grads_norm = 4.0349
	new_data_grads_norm = 4.2861
	old_data_grads_norm = 6.2634
	sim_grads_norm = -0.0295
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3746
	data_grads_norm = 3.5196
	new_data_grads_norm = 4.6897
	old_data_grads_norm = 3.9960
	sim_grads_norm = 0.1994
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0932
	data_grads_norm = 3.0183
	new_data_grads_norm = 4.1249
	old_data_grads_norm = 4.4413
	sim_grads_norm = 0.0380
-- Starting training on experience 177 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8489
	data_grads_norm = 2.7849
	new_data_grads_norm = 4.5324
	old_data_grads_norm = 4.2762
	sim_grads_norm = -0.0656
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5094
	data_grads_norm = 3.9811
	new_data_grads_norm = 4.3409
	old_data_grads_norm = 6.0128
	sim_grads_norm = 0.0816
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6146
	data_grads_norm = 3.5470
	new_data_grads_norm = 4.6702
	old_data_grads_norm = 5.0171
	sim_grads_norm = 0.0120
-- Starting training on experience 178 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6405
	data_grads_norm = 3.3328
	new_data_grads_norm = 4.9791
	old_data_grads_norm = 4.2329
	sim_grads_norm = 0.0581
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7313
	data_grads_norm = 3.3107
	new_data_grads_norm = 4.1645
	old_data_grads_norm = 5.1324
	sim_grads_norm = 0.0095
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3923
	data_grads_norm = 3.6390
	new_data_grads_norm = 4.5401
	old_data_grads_norm = 5.1241
	sim_grads_norm = 0.1132
-- Starting training on experience 179 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8598
	data_grads_norm = 2.6506
	new_data_grads_norm = 3.7851
	old_data_grads_norm = 3.5737
	sim_grads_norm = -0.0648
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1939
	data_grads_norm = 3.5386
	new_data_grads_norm = 4.0791
	old_data_grads_norm = 5.1787
	sim_grads_norm = 0.0730
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8506
	data_grads_norm = 2.6803
	new_data_grads_norm = 3.6037
	old_data_grads_norm = 3.6172
	sim_grads_norm = 0.0791
-- Starting training on experience 180 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5994
	data_grads_norm = 3.2606
	new_data_grads_norm = 3.8690
	old_data_grads_norm = 5.2127
	sim_grads_norm = 0.0796
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7563
	data_grads_norm = 3.2870
	new_data_grads_norm = 4.3442
	old_data_grads_norm = 3.9499
	sim_grads_norm = 0.0208
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0025
	data_grads_norm = 2.5087
	new_data_grads_norm = 3.7357
	old_data_grads_norm = 3.2695
	sim_grads_norm = 0.0503
-- Starting training on experience 181 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2203
	data_grads_norm = 3.4095
	new_data_grads_norm = 3.9903
	old_data_grads_norm = 4.7510
	sim_grads_norm = 0.0808
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2808
	data_grads_norm = 3.1127
	new_data_grads_norm = 3.7259
	old_data_grads_norm = 4.8211
	sim_grads_norm = 0.0909
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0971
	data_grads_norm = 2.7575
	new_data_grads_norm = 3.9351
	old_data_grads_norm = 4.5449
	sim_grads_norm = -0.0399
-- Starting training on experience 182 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4171
	data_grads_norm = 2.9958
	new_data_grads_norm = 3.3662
	old_data_grads_norm = 4.9273
	sim_grads_norm = 0.0620
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5614
	data_grads_norm = 2.9712
	new_data_grads_norm = 4.6113
	old_data_grads_norm = 4.0331
	sim_grads_norm = 0.0089
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4093
	data_grads_norm = 3.0499
	new_data_grads_norm = 4.3499
	old_data_grads_norm = 4.0204
	sim_grads_norm = 0.0961
-- Starting training on experience 183 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2930
	data_grads_norm = 2.7114
	new_data_grads_norm = 3.6797
	old_data_grads_norm = 3.5481
	sim_grads_norm = 0.0071
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0144
	data_grads_norm = 3.0505
	new_data_grads_norm = 4.2467
	old_data_grads_norm = 4.3953
	sim_grads_norm = -0.0897
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6649
	data_grads_norm = 3.3275
	new_data_grads_norm = 4.4414
	old_data_grads_norm = 3.5473
	sim_grads_norm = 0.3210
-- Starting training on experience 184 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2128
	data_grads_norm = 3.1310
	new_data_grads_norm = 4.2035
	old_data_grads_norm = 4.8829
	sim_grads_norm = -0.0503
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5515
	data_grads_norm = 2.9239
	new_data_grads_norm = 4.3524
	old_data_grads_norm = 3.7457
	sim_grads_norm = -0.0101
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1703
	data_grads_norm = 3.1307
	new_data_grads_norm = 4.1385
	old_data_grads_norm = 4.3076
	sim_grads_norm = 0.0274
-- Starting training on experience 185 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1080
	data_grads_norm = 2.7961
	new_data_grads_norm = 4.4441
	old_data_grads_norm = 3.6269
	sim_grads_norm = 0.0341
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3581
	data_grads_norm = 3.8559
	new_data_grads_norm = 4.8164
	old_data_grads_norm = 4.8865
	sim_grads_norm = 0.0323
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9386
	data_grads_norm = 2.5736
	new_data_grads_norm = 4.7454
	old_data_grads_norm = 3.1778
	sim_grads_norm = -0.0230
-- Starting training on experience 186 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9687
	data_grads_norm = 2.3540
	new_data_grads_norm = 3.2566
	old_data_grads_norm = 3.7830
	sim_grads_norm = -0.0026
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3425
	data_grads_norm = 2.7052
	new_data_grads_norm = 3.0587
	old_data_grads_norm = 3.6528
	sim_grads_norm = 0.2377
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6500
	data_grads_norm = 2.2509
	new_data_grads_norm = 3.0574
	old_data_grads_norm = 4.2319
	sim_grads_norm = -0.0560
-- Starting training on experience 187 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2838
	data_grads_norm = 2.6699
	new_data_grads_norm = 4.0469
	old_data_grads_norm = 3.5000
	sim_grads_norm = -0.0065
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4122
	data_grads_norm = 2.9700
	new_data_grads_norm = 3.7097
	old_data_grads_norm = 4.4108
	sim_grads_norm = -0.0260
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4173
	data_grads_norm = 3.4004
	new_data_grads_norm = 4.3170
	old_data_grads_norm = 5.1908
	sim_grads_norm = 0.0004
-- Starting training on experience 188 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1255
	data_grads_norm = 3.2372
	new_data_grads_norm = 4.4047
	old_data_grads_norm = 3.8659
	sim_grads_norm = 0.0716
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3060
	data_grads_norm = 3.7328
	new_data_grads_norm = 4.1181
	old_data_grads_norm = 6.0328
	sim_grads_norm = -0.0039
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8072
	data_grads_norm = 2.9144
	new_data_grads_norm = 3.8432
	old_data_grads_norm = 3.9872
	sim_grads_norm = -0.0562
-- Starting training on experience 189 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9116
	data_grads_norm = 2.7066
	new_data_grads_norm = 3.6418
	old_data_grads_norm = 4.0179
	sim_grads_norm = -0.1254
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9127
	data_grads_norm = 2.7951
	new_data_grads_norm = 3.4658
	old_data_grads_norm = 3.5265
	sim_grads_norm = 0.0897
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1977
	data_grads_norm = 3.4789
	new_data_grads_norm = 4.2288
	old_data_grads_norm = 5.1767
	sim_grads_norm = 0.0598
-- Starting training on experience 190 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6571
	data_grads_norm = 2.4370
	new_data_grads_norm = 3.7091
	old_data_grads_norm = 4.1412
	sim_grads_norm = -0.0465
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9049
	data_grads_norm = 2.9276
	new_data_grads_norm = 4.0520
	old_data_grads_norm = 4.0001
	sim_grads_norm = 0.0312
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0948
	data_grads_norm = 3.0552
	new_data_grads_norm = 4.0754
	old_data_grads_norm = 4.5838
	sim_grads_norm = -0.0114
-- Starting training on experience 191 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3646
	data_grads_norm = 2.8525
	new_data_grads_norm = 4.2008
	old_data_grads_norm = 3.6068
	sim_grads_norm = 0.1159
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6069
	data_grads_norm = 2.9824
	new_data_grads_norm = 4.2263
	old_data_grads_norm = 4.3848
	sim_grads_norm = -0.0227
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4347
	data_grads_norm = 3.1148
	new_data_grads_norm = 4.7788
	old_data_grads_norm = 4.0299
	sim_grads_norm = -0.0543
-- Starting training on experience 192 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8876
	data_grads_norm = 2.6517
	new_data_grads_norm = 4.1076
	old_data_grads_norm = 3.2503
	sim_grads_norm = -0.0390
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9166
	data_grads_norm = 3.6789
	new_data_grads_norm = 4.2074
	old_data_grads_norm = 5.1698
	sim_grads_norm = 0.0889
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5756
	data_grads_norm = 3.0446
	new_data_grads_norm = 3.9959
	old_data_grads_norm = 4.5695
	sim_grads_norm = -0.0243
-- Starting training on experience 193 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3672
	data_grads_norm = 3.2766
	new_data_grads_norm = 4.8817
	old_data_grads_norm = 4.1699
	sim_grads_norm = 0.0021
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0818
	data_grads_norm = 2.9803
	new_data_grads_norm = 4.9552
	old_data_grads_norm = 3.5425
	sim_grads_norm = -0.0427
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3646
	data_grads_norm = 3.4405
	new_data_grads_norm = 5.0836
	old_data_grads_norm = 4.7404
	sim_grads_norm = 0.0469
-- Starting training on experience 194 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2953
	data_grads_norm = 3.1786
	new_data_grads_norm = 4.8788
	old_data_grads_norm = 4.1956
	sim_grads_norm = -0.0193
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4097
	data_grads_norm = 2.8614
	new_data_grads_norm = 4.3585
	old_data_grads_norm = 3.3059
	sim_grads_norm = 0.0825
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6340
	data_grads_norm = 3.5076
	new_data_grads_norm = 4.6962
	old_data_grads_norm = 4.2538
	sim_grads_norm = 0.1336
-- Starting training on experience 195 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3997
	data_grads_norm = 3.0844
	new_data_grads_norm = 3.6079
	old_data_grads_norm = 3.9726
	sim_grads_norm = -0.0104
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8839
	data_grads_norm = 3.0059
	new_data_grads_norm = 3.6886
	old_data_grads_norm = 4.2337
	sim_grads_norm = 0.0436
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2532
	data_grads_norm = 3.6933
	new_data_grads_norm = 3.9683
	old_data_grads_norm = 5.1553
	sim_grads_norm = 0.0341
-- Starting training on experience 196 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1710
	data_grads_norm = 2.7931
	new_data_grads_norm = 4.1118
	old_data_grads_norm = 3.5534
	sim_grads_norm = 0.0464
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0269
	data_grads_norm = 2.5825
	new_data_grads_norm = 4.5944
	old_data_grads_norm = 3.6856
	sim_grads_norm = -0.0445
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2159
	data_grads_norm = 2.9930
	new_data_grads_norm = 4.5655
	old_data_grads_norm = 3.4925
	sim_grads_norm = 0.0748
-- Starting training on experience 197 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6971
	data_grads_norm = 3.3642
	new_data_grads_norm = 4.9081
	old_data_grads_norm = 4.9432
	sim_grads_norm = -0.0587
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1519
	data_grads_norm = 3.2190
	new_data_grads_norm = 4.8879
	old_data_grads_norm = 3.9671
	sim_grads_norm = 0.0643
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3952
	data_grads_norm = 3.4030
	new_data_grads_norm = 4.7342
	old_data_grads_norm = 4.0587
	sim_grads_norm = 0.1011
-- Starting training on experience 198 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2512
	data_grads_norm = 2.7812
	new_data_grads_norm = 3.4972
	old_data_grads_norm = 4.1487
	sim_grads_norm = 0.0410
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3989
	data_grads_norm = 2.7892
	new_data_grads_norm = 3.5307
	old_data_grads_norm = 4.3601
	sim_grads_norm = -0.0052
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0620
	data_grads_norm = 2.9017
	new_data_grads_norm = 3.8277
	old_data_grads_norm = 4.2059
	sim_grads_norm = 0.0036
-- Starting training on experience 199 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4330
	data_grads_norm = 2.7703
	new_data_grads_norm = 3.4384
	old_data_grads_norm = 3.7050
	sim_grads_norm = -0.0257
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5459
	data_grads_norm = 3.1602
	new_data_grads_norm = 3.6802
	old_data_grads_norm = 4.5333
	sim_grads_norm = 0.0039
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4092
	data_grads_norm = 2.9674
	new_data_grads_norm = 3.3693
	old_data_grads_norm = 4.4598
	sim_grads_norm = 0.0449
-- Starting training on experience 200 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2976
	data_grads_norm = 2.8760
	new_data_grads_norm = 4.2592
	old_data_grads_norm = 3.8147
	sim_grads_norm = 0.0046
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4670
	data_grads_norm = 3.0361
	new_data_grads_norm = 4.1715
	old_data_grads_norm = 4.4184
	sim_grads_norm = -0.0151
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5014
	data_grads_norm = 3.1262
	new_data_grads_norm = 4.7098
	old_data_grads_norm = 3.7661
	sim_grads_norm = -0.0373
-- Starting training on experience 201 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1966
	data_grads_norm = 2.7355
	new_data_grads_norm = 4.2019
	old_data_grads_norm = 3.4330
	sim_grads_norm = 0.0857
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9521
	data_grads_norm = 3.0120
	new_data_grads_norm = 3.8628
	old_data_grads_norm = 4.8872
	sim_grads_norm = -0.0014
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3744
	data_grads_norm = 3.5813
	new_data_grads_norm = 4.4867
	old_data_grads_norm = 5.2258
	sim_grads_norm = 0.0587
-- Starting training on experience 202 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7738
	data_grads_norm = 3.2174
	new_data_grads_norm = 4.6518
	old_data_grads_norm = 4.8168
	sim_grads_norm = -0.0120
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2886
	data_grads_norm = 3.4269
	new_data_grads_norm = 4.8358
	old_data_grads_norm = 4.4648
	sim_grads_norm = -0.0412
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3060
	data_grads_norm = 3.7006
	new_data_grads_norm = 5.0353
	old_data_grads_norm = 5.5613
	sim_grads_norm = 0.0142
-- Starting training on experience 203 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9861
	data_grads_norm = 3.7135
	new_data_grads_norm = 5.1746
	old_data_grads_norm = 4.5529
	sim_grads_norm = 0.1764
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8145
	data_grads_norm = 3.3981
	new_data_grads_norm = 4.7544
	old_data_grads_norm = 4.6332
	sim_grads_norm = 0.0356
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3734
	data_grads_norm = 3.4963
	new_data_grads_norm = 4.4746
	old_data_grads_norm = 5.0973
	sim_grads_norm = -0.0252
-- Starting training on experience 204 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6817
	data_grads_norm = 3.4799
	new_data_grads_norm = 4.2671
	old_data_grads_norm = 5.1871
	sim_grads_norm = 0.0608
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7045
	data_grads_norm = 3.0482
	new_data_grads_norm = 4.2202
	old_data_grads_norm = 4.6092
	sim_grads_norm = -0.0198
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2337
	data_grads_norm = 2.7988
	new_data_grads_norm = 4.4453
	old_data_grads_norm = 3.8695
	sim_grads_norm = -0.0494
-- Starting training on experience 205 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5032
	data_grads_norm = 3.0217
	new_data_grads_norm = 3.7374
	old_data_grads_norm = 4.6960
	sim_grads_norm = -0.0185
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0100
	data_grads_norm = 2.9490
	new_data_grads_norm = 3.4879
	old_data_grads_norm = 4.4414
	sim_grads_norm = 0.0609
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9423
	data_grads_norm = 2.5844
	new_data_grads_norm = 3.3192
	old_data_grads_norm = 3.6537
	sim_grads_norm = 0.0520
-- Starting training on experience 206 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1928
	data_grads_norm = 2.8844
	new_data_grads_norm = 3.9333
	old_data_grads_norm = 4.1053
	sim_grads_norm = -0.0084
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7642
	data_grads_norm = 2.6287
	new_data_grads_norm = 3.6674
	old_data_grads_norm = 3.7889
	sim_grads_norm = 0.1370
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8178
	data_grads_norm = 2.9092
	new_data_grads_norm = 3.6093
	old_data_grads_norm = 4.7956
	sim_grads_norm = 0.0124
-- Starting training on experience 207 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6933
	data_grads_norm = 2.3097
	new_data_grads_norm = 3.2634
	old_data_grads_norm = 3.7624
	sim_grads_norm = -0.0582
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1388
	data_grads_norm = 2.6375
	new_data_grads_norm = 3.8886
	old_data_grads_norm = 3.3000
	sim_grads_norm = -0.0646
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6993
	data_grads_norm = 2.4251
	new_data_grads_norm = 3.4148
	old_data_grads_norm = 3.8328
	sim_grads_norm = -0.0357
-- Starting training on experience 208 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6680
	data_grads_norm = 3.3168
	new_data_grads_norm = 3.9048
	old_data_grads_norm = 5.2480
	sim_grads_norm = 0.0464
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7001
	data_grads_norm = 3.5791
	new_data_grads_norm = 3.9211
	old_data_grads_norm = 5.2324
	sim_grads_norm = 0.1592
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4472
	data_grads_norm = 2.8450
	new_data_grads_norm = 3.8652
	old_data_grads_norm = 3.4215
	sim_grads_norm = 0.0886
-- Starting training on experience 209 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4455
	data_grads_norm = 3.0198
	new_data_grads_norm = 4.3590
	old_data_grads_norm = 3.5110
	sim_grads_norm = 0.0275
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5204
	data_grads_norm = 3.1315
	new_data_grads_norm = 4.3386
	old_data_grads_norm = 4.3227
	sim_grads_norm = 0.0607
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4499
	data_grads_norm = 3.2203
	new_data_grads_norm = 4.0664
	old_data_grads_norm = 4.8560
	sim_grads_norm = -0.0681
-- Starting training on experience 210 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0153
	data_grads_norm = 3.3017
	new_data_grads_norm = 3.8457
	old_data_grads_norm = 5.3168
	sim_grads_norm = -0.0248
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3015
	data_grads_norm = 3.0708
	new_data_grads_norm = 4.1215
	old_data_grads_norm = 4.0148
	sim_grads_norm = 0.0819
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7835
	data_grads_norm = 2.6088
	new_data_grads_norm = 3.3453
	old_data_grads_norm = 3.7118
	sim_grads_norm = 0.0101
-- Starting training on experience 211 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2236
	data_grads_norm = 2.8930
	new_data_grads_norm = 3.5685
	old_data_grads_norm = 4.1682
	sim_grads_norm = 0.0615
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9989
	data_grads_norm = 2.9224
	new_data_grads_norm = 3.5789
	old_data_grads_norm = 4.7687
	sim_grads_norm = -0.0698
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9830
	data_grads_norm = 2.6841
	new_data_grads_norm = 4.1483
	old_data_grads_norm = 3.2750
	sim_grads_norm = -0.0051
-- Starting training on experience 212 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1143
	data_grads_norm = 2.7495
	new_data_grads_norm = 3.3692
	old_data_grads_norm = 3.9177
	sim_grads_norm = -0.0284
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7841
	data_grads_norm = 2.6692
	new_data_grads_norm = 3.8835
	old_data_grads_norm = 3.3225
	sim_grads_norm = -0.0240
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1064
	data_grads_norm = 2.5894
	new_data_grads_norm = 3.5216
	old_data_grads_norm = 4.2289
	sim_grads_norm = -0.0019
-- Starting training on experience 213 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1804
	data_grads_norm = 2.9395
	new_data_grads_norm = 4.3453
	old_data_grads_norm = 4.1705
	sim_grads_norm = 0.0107
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9427
	data_grads_norm = 2.7248
	new_data_grads_norm = 4.0944
	old_data_grads_norm = 3.4222
	sim_grads_norm = -0.0309
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8730
	data_grads_norm = 3.0522
	new_data_grads_norm = 4.7894
	old_data_grads_norm = 3.9384
	sim_grads_norm = -0.0250
-- Starting training on experience 214 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0488
	data_grads_norm = 3.2069
	new_data_grads_norm = 4.1039
	old_data_grads_norm = 5.7205
	sim_grads_norm = 0.0165
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3452
	data_grads_norm = 3.0905
	new_data_grads_norm = 4.3820
	old_data_grads_norm = 3.7570
	sim_grads_norm = 0.0491
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2294
	data_grads_norm = 3.0218
	new_data_grads_norm = 4.2089
	old_data_grads_norm = 4.2265
	sim_grads_norm = 0.0433
-- Starting training on experience 215 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9971
	data_grads_norm = 2.5142
	new_data_grads_norm = 3.8094
	old_data_grads_norm = 3.2842
	sim_grads_norm = 0.0109
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0712
	data_grads_norm = 2.7517
	new_data_grads_norm = 3.7598
	old_data_grads_norm = 3.9973
	sim_grads_norm = -0.0097
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8767
	data_grads_norm = 2.7761
	new_data_grads_norm = 4.0742
	old_data_grads_norm = 3.3428
	sim_grads_norm = 0.1677
-- Starting training on experience 216 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9792
	data_grads_norm = 2.9347
	new_data_grads_norm = 4.4176
	old_data_grads_norm = 3.8103
	sim_grads_norm = -0.0182
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1756
	data_grads_norm = 2.9322
	new_data_grads_norm = 4.8005
	old_data_grads_norm = 4.2127
	sim_grads_norm = 0.0044
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2711
	data_grads_norm = 3.6698
	new_data_grads_norm = 5.1505
	old_data_grads_norm = 5.3639
	sim_grads_norm = -0.1064
-- Starting training on experience 217 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0970
	data_grads_norm = 3.0352
	new_data_grads_norm = 4.3927
	old_data_grads_norm = 3.6493
	sim_grads_norm = 0.0870
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0796
	data_grads_norm = 3.2780
	new_data_grads_norm = 4.1172
	old_data_grads_norm = 4.8453
	sim_grads_norm = 0.0346
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8779
	data_grads_norm = 2.8542
	new_data_grads_norm = 3.5342
	old_data_grads_norm = 4.0298
	sim_grads_norm = 0.0829
-- Starting training on experience 218 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9795
	data_grads_norm = 3.0604
	new_data_grads_norm = 5.0247
	old_data_grads_norm = 3.4205
	sim_grads_norm = 0.0932
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0163
	data_grads_norm = 3.1783
	new_data_grads_norm = 5.0065
	old_data_grads_norm = 3.7059
	sim_grads_norm = 0.0336
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9200
	data_grads_norm = 3.2124
	new_data_grads_norm = 4.9826
	old_data_grads_norm = 4.2550
	sim_grads_norm = 0.0263
-- Starting training on experience 219 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4568
	data_grads_norm = 3.0729
	new_data_grads_norm = 4.1458
	old_data_grads_norm = 4.5678
	sim_grads_norm = 0.0314
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4047
	data_grads_norm = 2.8374
	new_data_grads_norm = 4.1266
	old_data_grads_norm = 3.7761
	sim_grads_norm = -0.0423
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7747
	data_grads_norm = 3.7241
	new_data_grads_norm = 4.5028
	old_data_grads_norm = 5.4537
	sim_grads_norm = -0.0092
-- Starting training on experience 220 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1716
	data_grads_norm = 3.1959
	new_data_grads_norm = 4.0456
	old_data_grads_norm = 4.1431
	sim_grads_norm = 0.1398
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2766
	data_grads_norm = 3.4712
	new_data_grads_norm = 3.6427
	old_data_grads_norm = 5.6306
	sim_grads_norm = 0.0749
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6544
	data_grads_norm = 2.6320
	new_data_grads_norm = 3.5657
	old_data_grads_norm = 3.6228
	sim_grads_norm = -0.0776
-- Starting training on experience 221 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0008
	data_grads_norm = 2.6780
	new_data_grads_norm = 3.7123
	old_data_grads_norm = 4.0273
	sim_grads_norm = -0.0835
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8710
	data_grads_norm = 2.6654
	new_data_grads_norm = 3.6307
	old_data_grads_norm = 4.0453
	sim_grads_norm = -0.0449
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1360
	data_grads_norm = 3.0822
	new_data_grads_norm = 4.0231
	old_data_grads_norm = 4.5490
	sim_grads_norm = -0.0109
-- Starting training on experience 222 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6046
	data_grads_norm = 2.8745
	new_data_grads_norm = 4.4148
	old_data_grads_norm = 4.9001
	sim_grads_norm = 0.0356
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5326
	data_grads_norm = 3.0417
	new_data_grads_norm = 4.6391
	old_data_grads_norm = 3.9457
	sim_grads_norm = 0.0260
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9515
	data_grads_norm = 3.2174
	new_data_grads_norm = 4.4350
	old_data_grads_norm = 4.6175
	sim_grads_norm = 0.0160
-- Starting training on experience 223 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5828
	data_grads_norm = 3.4798
	new_data_grads_norm = 4.0948
	old_data_grads_norm = 5.4090
	sim_grads_norm = 0.0714
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9224
	data_grads_norm = 3.1358
	new_data_grads_norm = 4.0346
	old_data_grads_norm = 4.4263
	sim_grads_norm = 0.0370
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1709
	data_grads_norm = 3.3616
	new_data_grads_norm = 4.1754
	old_data_grads_norm = 5.3118
	sim_grads_norm = 0.0564
-- Starting training on experience 224 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9658
	data_grads_norm = 3.1290
	new_data_grads_norm = 5.3438
	old_data_grads_norm = 3.4498
	sim_grads_norm = 0.0506
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5380
	data_grads_norm = 2.9339
	new_data_grads_norm = 5.1875
	old_data_grads_norm = 3.9520
	sim_grads_norm = -0.0528
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1744
	data_grads_norm = 4.0073
	new_data_grads_norm = 4.8883
	old_data_grads_norm = 5.9428
	sim_grads_norm = -0.0062
-- Starting training on experience 225 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2279
	data_grads_norm = 3.3373
	new_data_grads_norm = 3.7877
	old_data_grads_norm = 5.3296
	sim_grads_norm = 0.0486
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1385
	data_grads_norm = 3.5475
	new_data_grads_norm = 3.7546
	old_data_grads_norm = 4.8996
	sim_grads_norm = -0.0171
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3191
	data_grads_norm = 2.8358
	new_data_grads_norm = 4.0918
	old_data_grads_norm = 4.0569
	sim_grads_norm = -0.0567
-- Starting training on experience 226 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8390
	data_grads_norm = 2.7584
	new_data_grads_norm = 4.6637
	old_data_grads_norm = 3.5946
	sim_grads_norm = 0.0129
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4443
	data_grads_norm = 3.6850
	new_data_grads_norm = 4.5994
	old_data_grads_norm = 4.8642
	sim_grads_norm = 0.1472
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1107
	data_grads_norm = 3.0585
	new_data_grads_norm = 3.7954
	old_data_grads_norm = 4.8026
	sim_grads_norm = 0.0025
-- Starting training on experience 227 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9718
	data_grads_norm = 3.0955
	new_data_grads_norm = 3.9279
	old_data_grads_norm = 4.3208
	sim_grads_norm = 0.0455
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2763
	data_grads_norm = 3.1158
	new_data_grads_norm = 4.3404
	old_data_grads_norm = 4.3417
	sim_grads_norm = 0.0233
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1188
	data_grads_norm = 2.7569
	new_data_grads_norm = 4.1169
	old_data_grads_norm = 3.6162
	sim_grads_norm = -0.0153
-- Starting training on experience 228 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2983
	data_grads_norm = 2.7671
	new_data_grads_norm = 4.0394
	old_data_grads_norm = 2.8665
	sim_grads_norm = 0.1142
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2090
	data_grads_norm = 2.6614
	new_data_grads_norm = 3.8073
	old_data_grads_norm = 3.6595
	sim_grads_norm = -0.0043
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1698
	data_grads_norm = 3.0384
	new_data_grads_norm = 4.6343
	old_data_grads_norm = 4.1386
	sim_grads_norm = 0.0643
-- Starting training on experience 229 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3043
	data_grads_norm = 3.1395
	new_data_grads_norm = 5.3787
	old_data_grads_norm = 3.4886
	sim_grads_norm = -0.0764
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0364
	data_grads_norm = 3.1003
	new_data_grads_norm = 5.1974
	old_data_grads_norm = 3.4055
	sim_grads_norm = -0.0776
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3311
	data_grads_norm = 3.2237
	new_data_grads_norm = 5.2767
	old_data_grads_norm = 3.7196
	sim_grads_norm = -0.0054
-- Starting training on experience 230 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3613
	data_grads_norm = 3.3888
	new_data_grads_norm = 5.0719
	old_data_grads_norm = 4.1743
	sim_grads_norm = 0.0120
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1576
	data_grads_norm = 3.3119
	new_data_grads_norm = 4.9528
	old_data_grads_norm = 3.8453
	sim_grads_norm = 0.0602
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3129
	data_grads_norm = 3.3815
	new_data_grads_norm = 5.2362
	old_data_grads_norm = 3.7251
	sim_grads_norm = 0.1247
-- Starting training on experience 231 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2140
	data_grads_norm = 3.1885
	new_data_grads_norm = 5.2362
	old_data_grads_norm = 3.7754
	sim_grads_norm = -0.0004
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0136
	data_grads_norm = 3.4326
	new_data_grads_norm = 5.0869
	old_data_grads_norm = 4.2836
	sim_grads_norm = -0.0417
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8356
	data_grads_norm = 2.6884
	new_data_grads_norm = 5.1475
	old_data_grads_norm = 3.3270
	sim_grads_norm = -0.0868
-- Starting training on experience 232 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1642
	data_grads_norm = 3.9996
	new_data_grads_norm = 4.4598
	old_data_grads_norm = 5.4532
	sim_grads_norm = 0.0099
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4015
	data_grads_norm = 3.3334
	new_data_grads_norm = 3.9108
	old_data_grads_norm = 5.0344
	sim_grads_norm = 0.0348
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0744
	data_grads_norm = 3.0367
	new_data_grads_norm = 3.7841
	old_data_grads_norm = 4.2123
	sim_grads_norm = 0.0682
-- Starting training on experience 233 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4074
	data_grads_norm = 3.2943
	new_data_grads_norm = 4.5014
	old_data_grads_norm = 4.0798
	sim_grads_norm = 0.0447
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3972
	data_grads_norm = 3.2498
	new_data_grads_norm = 4.0844
	old_data_grads_norm = 5.1654
	sim_grads_norm = -0.0383
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6786
	data_grads_norm = 3.0891
	new_data_grads_norm = 4.5294
	old_data_grads_norm = 3.7626
	sim_grads_norm = 0.0631
-- Starting training on experience 234 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8963
	data_grads_norm = 3.3429
	new_data_grads_norm = 3.7640
	old_data_grads_norm = 5.0509
	sim_grads_norm = 0.0480
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6439
	data_grads_norm = 3.2324
	new_data_grads_norm = 3.9465
	old_data_grads_norm = 5.0004
	sim_grads_norm = 0.0265
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6128
	data_grads_norm = 2.3707
	new_data_grads_norm = 4.2558
	old_data_grads_norm = 3.3090
	sim_grads_norm = -0.0266
-- Starting training on experience 235 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5141
	data_grads_norm = 4.0357
	new_data_grads_norm = 4.8884
	old_data_grads_norm = 5.8544
	sim_grads_norm = 0.0135
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8647
	data_grads_norm = 3.2421
	new_data_grads_norm = 4.7469
	old_data_grads_norm = 3.9786
	sim_grads_norm = 0.1005
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9931
	data_grads_norm = 3.1816
	new_data_grads_norm = 5.2321
	old_data_grads_norm = 5.0100
	sim_grads_norm = -0.0491
-- Starting training on experience 236 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7426
	data_grads_norm = 3.6829
	new_data_grads_norm = 4.8705
	old_data_grads_norm = 5.1336
	sim_grads_norm = 0.0698
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3989
	data_grads_norm = 3.0476
	new_data_grads_norm = 4.6992
	old_data_grads_norm = 4.6947
	sim_grads_norm = -0.0217
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3987
	data_grads_norm = 2.9396
	new_data_grads_norm = 4.4778
	old_data_grads_norm = 3.5782
	sim_grads_norm = 0.0317
-- Starting training on experience 237 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
-- >> End of training phase << --
-- >> Start of eval phase << --
-- Starting eval on experience 0 (Task 0) from test stream --
> Eval on experience 0 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp000 = 2.0612
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.4000
	mb_index = 1428
	time = 247.6332
-- Starting eval on experience 1 (Task 0) from test stream --
> Eval on experience 1 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp001 = 1.6555
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.5700
-- Starting eval on experience 2 (Task 0) from test stream --
> Eval on experience 2 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp002 = 2.3687
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.3540
-- Starting eval on experience 3 (Task 0) from test stream --
> Eval on experience 3 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp003 = 2.1944
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.3900
-- Starting eval on experience 4 (Task 0) from test stream --
> Eval on experience 4 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp004 = 2.5330
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.3080
-- Starting eval on experience 5 (Task 0) from test stream --
> Eval on experience 5 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp005 = 2.6756
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.2340
-- >> End of eval phase << --
	CumulativeAccuracy/eval_phase/test_stream/Exp000 = 0.6880
	CumulativeAccuracy/eval_phase/test_stream/Exp001 = 0.6320
	CumulativeAccuracy/eval_phase/test_stream/Exp002 = 0.5220
	CumulativeAccuracy/eval_phase/test_stream/Exp003 = 0.4860
	CumulativeAccuracy/eval_phase/test_stream/Exp004 = 0.4192
	CumulativeAccuracy/eval_phase/test_stream/Exp005 = 0.3760
	Loss_Stream/eval_phase/test_stream/Task000 = 2.2481
	Top1_Acc_Stream/eval_phase/test_stream/Task000 = 0.3760
-- >> Start of training phase << --
-- Starting training on experience 0 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9242
	data_grads_norm = 2.5630
	new_data_grads_norm = 4.7069
	old_data_grads_norm = 3.1767
	sim_grads_norm = -0.0692
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2787
	data_grads_norm = 3.2691
	new_data_grads_norm = 4.7589
	old_data_grads_norm = 4.6860
	sim_grads_norm = -0.0087
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8279
	data_grads_norm = 3.5984
	new_data_grads_norm = 5.1639
	old_data_grads_norm = 4.7743
	sim_grads_norm = 0.0759
-- Starting training on experience 1 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3040
	data_grads_norm = 3.1623
	new_data_grads_norm = 5.0472
	old_data_grads_norm = 4.2066
	sim_grads_norm = 0.0363
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0332
	data_grads_norm = 4.1322
	new_data_grads_norm = 5.6527
	old_data_grads_norm = 5.6668
	sim_grads_norm = 0.0673
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6731
	data_grads_norm = 3.6554
	new_data_grads_norm = 5.2106
	old_data_grads_norm = 4.8385
	sim_grads_norm = 0.0219
-- Starting training on experience 2 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3983
	data_grads_norm = 3.2917
	new_data_grads_norm = 4.5302
	old_data_grads_norm = 4.0013
	sim_grads_norm = 0.0651
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8167
	data_grads_norm = 3.9370
	new_data_grads_norm = 4.3256
	old_data_grads_norm = 5.5438
	sim_grads_norm = 0.0358
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6551
	data_grads_norm = 3.4014
	new_data_grads_norm = 4.0789
	old_data_grads_norm = 4.5472
	sim_grads_norm = 0.0097
-- Starting training on experience 3 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3808
	data_grads_norm = 3.1700
	new_data_grads_norm = 4.9649
	old_data_grads_norm = 3.8649
	sim_grads_norm = -0.0090
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3020
	data_grads_norm = 3.0661
	new_data_grads_norm = 4.7860
	old_data_grads_norm = 4.7158
	sim_grads_norm = -0.0154
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7221
	data_grads_norm = 3.5063
	new_data_grads_norm = 4.7102
	old_data_grads_norm = 5.1037
	sim_grads_norm = 0.0583
-- Starting training on experience 4 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3670
	data_grads_norm = 3.1507
	new_data_grads_norm = 4.5942
	old_data_grads_norm = 4.1707
	sim_grads_norm = -0.0428
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5385
	data_grads_norm = 3.2204
	new_data_grads_norm = 4.7182
	old_data_grads_norm = 4.2162
	sim_grads_norm = 0.0075
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4005
	data_grads_norm = 3.3204
	new_data_grads_norm = 4.5469
	old_data_grads_norm = 4.6793
	sim_grads_norm = 0.0028
-- Starting training on experience 5 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6162
	data_grads_norm = 3.8505
	new_data_grads_norm = 5.8577
	old_data_grads_norm = 4.7419
	sim_grads_norm = 0.0356
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3722
	data_grads_norm = 3.0529
	new_data_grads_norm = 5.1795
	old_data_grads_norm = 2.7229
	sim_grads_norm = -0.0024
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0738
	data_grads_norm = 3.6947
	new_data_grads_norm = 5.3421
	old_data_grads_norm = 4.4724
	sim_grads_norm = 0.0419
-- Starting training on experience 6 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8107
	data_grads_norm = 3.4827
	new_data_grads_norm = 4.5744
	old_data_grads_norm = 4.5298
	sim_grads_norm = -0.0059
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7903
	data_grads_norm = 3.7275
	new_data_grads_norm = 5.4906
	old_data_grads_norm = 4.0195
	sim_grads_norm = 0.0020
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7307
	data_grads_norm = 3.5690
	new_data_grads_norm = 4.7126
	old_data_grads_norm = 4.7552
	sim_grads_norm = -0.0380
-- Starting training on experience 7 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0619
	data_grads_norm = 4.0233
	new_data_grads_norm = 5.0414
	old_data_grads_norm = 5.5997
	sim_grads_norm = 0.0236
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9629
	data_grads_norm = 3.3943
	new_data_grads_norm = 4.6023
	old_data_grads_norm = 4.0062
	sim_grads_norm = 0.1142
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5306
	data_grads_norm = 3.2755
	new_data_grads_norm = 4.4537
	old_data_grads_norm = 3.3316
	sim_grads_norm = 0.0625
-- Starting training on experience 8 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7148
	data_grads_norm = 3.2249
	new_data_grads_norm = 4.5250
	old_data_grads_norm = 3.8471
	sim_grads_norm = -0.0031
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5390
	data_grads_norm = 3.6922
	new_data_grads_norm = 4.4315
	old_data_grads_norm = 5.6730
	sim_grads_norm = -0.0103
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7733
	data_grads_norm = 3.1224
	new_data_grads_norm = 4.7830
	old_data_grads_norm = 3.0591
	sim_grads_norm = 0.0512
-- Starting training on experience 9 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1035
	data_grads_norm = 3.6522
	new_data_grads_norm = 4.5780
	old_data_grads_norm = 4.6568
	sim_grads_norm = 0.0138
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6016
	data_grads_norm = 3.1273
	new_data_grads_norm = 4.5677
	old_data_grads_norm = 3.9275
	sim_grads_norm = 0.0307
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4950
	data_grads_norm = 3.0463
	new_data_grads_norm = 4.9166
	old_data_grads_norm = 3.7041
	sim_grads_norm = -0.0702
-- Starting training on experience 10 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6511
	data_grads_norm = 3.1903
	new_data_grads_norm = 4.0915
	old_data_grads_norm = 4.4894
	sim_grads_norm = 0.0706
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2134
	data_grads_norm = 2.7050
	new_data_grads_norm = 3.8746
	old_data_grads_norm = 3.8095
	sim_grads_norm = -0.0254
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7562
	data_grads_norm = 3.6367
	new_data_grads_norm = 4.4145
	old_data_grads_norm = 6.1734
	sim_grads_norm = 0.0640
-- Starting training on experience 11 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1979
	data_grads_norm = 3.0728
	new_data_grads_norm = 4.5423
	old_data_grads_norm = 3.6593
	sim_grads_norm = -0.0402
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1675
	data_grads_norm = 3.0400
	new_data_grads_norm = 5.0265
	old_data_grads_norm = 4.3468
	sim_grads_norm = -0.0272
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3270
	data_grads_norm = 3.4755
	new_data_grads_norm = 5.3405
	old_data_grads_norm = 4.3225
	sim_grads_norm = -0.0314
-- Starting training on experience 12 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7519
	data_grads_norm = 5.5122
	new_data_grads_norm = 5.0028
	old_data_grads_norm = 8.2939
	sim_grads_norm = 0.0581
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4887
	data_grads_norm = 4.0020
	new_data_grads_norm = 4.8236
	old_data_grads_norm = 4.4525
	sim_grads_norm = -0.0566
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7756
	data_grads_norm = 4.0755
	new_data_grads_norm = 5.3325
	old_data_grads_norm = 5.4648
	sim_grads_norm = -0.0196
-- Starting training on experience 13 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0311
	data_grads_norm = 4.2460
	new_data_grads_norm = 5.7635
	old_data_grads_norm = 5.1922
	sim_grads_norm = 0.0857
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3442
	data_grads_norm = 3.0846
	new_data_grads_norm = 4.8570
	old_data_grads_norm = 3.6400
	sim_grads_norm = 0.0133
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2975
	data_grads_norm = 3.2562
	new_data_grads_norm = 4.8899
	old_data_grads_norm = 4.3051
	sim_grads_norm = -0.0483
-- Starting training on experience 14 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0507
	data_grads_norm = 3.8435
	new_data_grads_norm = 5.4193
	old_data_grads_norm = 4.3234
	sim_grads_norm = 0.0157
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1400
	data_grads_norm = 2.9649
	new_data_grads_norm = 4.3129
	old_data_grads_norm = 4.1899
	sim_grads_norm = 0.0029
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0299
	data_grads_norm = 3.9318
	new_data_grads_norm = 5.6561
	old_data_grads_norm = 5.0593
	sim_grads_norm = 0.0272
-- Starting training on experience 15 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0234
	data_grads_norm = 4.3657
	new_data_grads_norm = 5.7152
	old_data_grads_norm = 5.8078
	sim_grads_norm = 0.0208
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1330
	data_grads_norm = 4.3649
	new_data_grads_norm = 5.6485
	old_data_grads_norm = 4.5692
	sim_grads_norm = 0.0745
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5891
	data_grads_norm = 3.4381
	new_data_grads_norm = 5.2528
	old_data_grads_norm = 4.0674
	sim_grads_norm = -0.0438
-- Starting training on experience 16 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7572
	data_grads_norm = 3.5132
	new_data_grads_norm = 5.4870
	old_data_grads_norm = 3.7044
	sim_grads_norm = 0.0342
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5242
	data_grads_norm = 3.1993
	new_data_grads_norm = 5.3204
	old_data_grads_norm = 3.7979
	sim_grads_norm = 0.0251
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4264
	data_grads_norm = 4.4799
	new_data_grads_norm = 5.4360
	old_data_grads_norm = 5.4947
	sim_grads_norm = 0.1816
-- Starting training on experience 17 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1280
	data_grads_norm = 2.9213
	new_data_grads_norm = 4.2527
	old_data_grads_norm = 3.5707
	sim_grads_norm = 0.0500
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0759
	data_grads_norm = 3.9767
	new_data_grads_norm = 4.1492
	old_data_grads_norm = 6.1048
	sim_grads_norm = -0.0014
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3513
	data_grads_norm = 3.1345
	new_data_grads_norm = 4.7992
	old_data_grads_norm = 3.7169
	sim_grads_norm = -0.0431
-- Starting training on experience 18 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4606
	data_grads_norm = 3.1303
	new_data_grads_norm = 4.8522
	old_data_grads_norm = 3.8597
	sim_grads_norm = 0.0389
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6592
	data_grads_norm = 3.1700
	new_data_grads_norm = 4.7440
	old_data_grads_norm = 3.6081
	sim_grads_norm = 0.0987
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8282
	data_grads_norm = 3.1500
	new_data_grads_norm = 4.4060
	old_data_grads_norm = 3.8379
	sim_grads_norm = 0.0219
-- Starting training on experience 19 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7912
	data_grads_norm = 3.3698
	new_data_grads_norm = 5.0839
	old_data_grads_norm = 4.3272
	sim_grads_norm = 0.0118
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3621
	data_grads_norm = 3.1052
	new_data_grads_norm = 4.7959
	old_data_grads_norm = 3.3536
	sim_grads_norm = 0.0476
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4591
	data_grads_norm = 3.2793
	new_data_grads_norm = 5.1914
	old_data_grads_norm = 3.4493
	sim_grads_norm = 0.0636
-- Starting training on experience 20 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8717
	data_grads_norm = 3.7015
	new_data_grads_norm = 4.9331
	old_data_grads_norm = 4.7359
	sim_grads_norm = -0.0141
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4794
	data_grads_norm = 3.9629
	new_data_grads_norm = 4.7303
	old_data_grads_norm = 5.2085
	sim_grads_norm = 0.0342
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0990
	data_grads_norm = 3.8535
	new_data_grads_norm = 4.8058
	old_data_grads_norm = 5.7577
	sim_grads_norm = 0.0132
-- Starting training on experience 21 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2860
	data_grads_norm = 3.1556
	new_data_grads_norm = 4.6575
	old_data_grads_norm = 3.7101
	sim_grads_norm = -0.0081
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2892
	data_grads_norm = 3.1935
	new_data_grads_norm = 5.2632
	old_data_grads_norm = 3.5580
	sim_grads_norm = -0.0279
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8457
	data_grads_norm = 3.6583
	new_data_grads_norm = 5.4550
	old_data_grads_norm = 4.3516
	sim_grads_norm = 0.0619
-- Starting training on experience 22 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4227
	data_grads_norm = 3.0134
	new_data_grads_norm = 3.9307
	old_data_grads_norm = 3.6598
	sim_grads_norm = 0.0639
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4044
	data_grads_norm = 3.0349
	new_data_grads_norm = 4.0842
	old_data_grads_norm = 4.2820
	sim_grads_norm = 0.0253
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2899
	data_grads_norm = 2.9790
	new_data_grads_norm = 4.0959
	old_data_grads_norm = 4.3047
	sim_grads_norm = -0.0294
-- Starting training on experience 23 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4312
	data_grads_norm = 2.9500
	new_data_grads_norm = 3.4002
	old_data_grads_norm = 3.7155
	sim_grads_norm = 0.1286
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8873
	data_grads_norm = 2.3645
	new_data_grads_norm = 3.5246
	old_data_grads_norm = 3.2166
	sim_grads_norm = 0.0157
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4894
	data_grads_norm = 3.2008
	new_data_grads_norm = 3.3666
	old_data_grads_norm = 5.0401
	sim_grads_norm = 0.1418
-- Starting training on experience 24 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8651
	data_grads_norm = 2.8077
	new_data_grads_norm = 3.5501
	old_data_grads_norm = 4.1916
	sim_grads_norm = -0.0669
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7343
	data_grads_norm = 2.4973
	new_data_grads_norm = 3.7186
	old_data_grads_norm = 2.7642
	sim_grads_norm = -0.0272
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2862
	data_grads_norm = 3.5131
	new_data_grads_norm = 3.9777
	old_data_grads_norm = 4.5584
	sim_grads_norm = 0.0093
-- Starting training on experience 25 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7707
	data_grads_norm = 2.7996
	new_data_grads_norm = 4.0326
	old_data_grads_norm = 3.9200
	sim_grads_norm = 0.0373
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0962
	data_grads_norm = 2.9171
	new_data_grads_norm = 4.1515
	old_data_grads_norm = 3.7158
	sim_grads_norm = -0.0214
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0089
	data_grads_norm = 3.2909
	new_data_grads_norm = 4.2718
	old_data_grads_norm = 4.8809
	sim_grads_norm = 0.0441
-- Starting training on experience 26 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7923
	data_grads_norm = 2.9112
	new_data_grads_norm = 4.4621
	old_data_grads_norm = 4.5209
	sim_grads_norm = 0.0122
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6246
	data_grads_norm = 2.6986
	new_data_grads_norm = 4.6884
	old_data_grads_norm = 4.0559
	sim_grads_norm = 0.0457
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9534
	data_grads_norm = 2.9514
	new_data_grads_norm = 5.2210
	old_data_grads_norm = 3.4312
	sim_grads_norm = 0.0950
-- Starting training on experience 27 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2959
	data_grads_norm = 3.6161
	new_data_grads_norm = 4.4930
	old_data_grads_norm = 5.0127
	sim_grads_norm = 0.0813
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9672
	data_grads_norm = 3.2912
	new_data_grads_norm = 4.8339
	old_data_grads_norm = 3.6289
	sim_grads_norm = 0.0855
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9980
	data_grads_norm = 3.3396
	new_data_grads_norm = 4.8990
	old_data_grads_norm = 3.7778
	sim_grads_norm = 0.0709
-- Starting training on experience 28 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9295
	data_grads_norm = 2.9093
	new_data_grads_norm = 5.2317
	old_data_grads_norm = 3.5605
	sim_grads_norm = -0.0030
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7182
	data_grads_norm = 2.9038
	new_data_grads_norm = 5.1605
	old_data_grads_norm = 3.2720
	sim_grads_norm = -0.0275
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4089
	data_grads_norm = 3.4575
	new_data_grads_norm = 4.9959
	old_data_grads_norm = 4.0836
	sim_grads_norm = 0.0867
-- Starting training on experience 29 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2192
	data_grads_norm = 3.3209
	new_data_grads_norm = 4.6867
	old_data_grads_norm = 4.4127
	sim_grads_norm = 0.1224
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8621
	data_grads_norm = 3.1140
	new_data_grads_norm = 4.1196
	old_data_grads_norm = 3.2553
	sim_grads_norm = 0.1603
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6131
	data_grads_norm = 2.9400
	new_data_grads_norm = 4.5225
	old_data_grads_norm = 4.4490
	sim_grads_norm = -0.0688
-- Starting training on experience 30 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8611
	data_grads_norm = 3.5004
	new_data_grads_norm = 4.2469
	old_data_grads_norm = 5.4470
	sim_grads_norm = 0.0078
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8342
	data_grads_norm = 3.2023
	new_data_grads_norm = 4.5747
	old_data_grads_norm = 4.5190
	sim_grads_norm = -0.0032
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7064
	data_grads_norm = 3.7301
	new_data_grads_norm = 4.7310
	old_data_grads_norm = 5.0367
	sim_grads_norm = 0.0511
-- Starting training on experience 31 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8917
	data_grads_norm = 2.9402
	new_data_grads_norm = 4.1420
	old_data_grads_norm = 3.6956
	sim_grads_norm = 0.0623
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4726
	data_grads_norm = 2.8716
	new_data_grads_norm = 4.3204
	old_data_grads_norm = 4.7718
	sim_grads_norm = -0.0045
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4397
	data_grads_norm = 2.5682
	new_data_grads_norm = 3.8650
	old_data_grads_norm = 3.3385
	sim_grads_norm = 0.1018
-- Starting training on experience 32 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5947
	data_grads_norm = 3.0057
	new_data_grads_norm = 4.0319
	old_data_grads_norm = 4.1599
	sim_grads_norm = 0.0752
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6361
	data_grads_norm = 3.0882
	new_data_grads_norm = 3.9137
	old_data_grads_norm = 4.0315
	sim_grads_norm = 0.0458
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9963
	data_grads_norm = 3.5524
	new_data_grads_norm = 4.1556
	old_data_grads_norm = 5.0308
	sim_grads_norm = 0.0078
-- Starting training on experience 33 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4976
	data_grads_norm = 2.5161
	new_data_grads_norm = 3.5404
	old_data_grads_norm = 3.5630
	sim_grads_norm = 0.0009
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8255
	data_grads_norm = 3.0841
	new_data_grads_norm = 3.5386
	old_data_grads_norm = 4.5285
	sim_grads_norm = -0.0305
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8581
	data_grads_norm = 2.6386
	new_data_grads_norm = 3.4017
	old_data_grads_norm = 4.3106
	sim_grads_norm = -0.0432
-- Starting training on experience 34 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5320
	data_grads_norm = 2.5486
	new_data_grads_norm = 3.7475
	old_data_grads_norm = 3.2937
	sim_grads_norm = -0.0002
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5721
	data_grads_norm = 2.6478
	new_data_grads_norm = 3.5801
	old_data_grads_norm = 3.7396
	sim_grads_norm = 0.0898
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6260
	data_grads_norm = 2.5029
	new_data_grads_norm = 3.8424
	old_data_grads_norm = 2.8971
	sim_grads_norm = 0.0987
-- Starting training on experience 35 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7730
	data_grads_norm = 2.8001
	new_data_grads_norm = 3.5741
	old_data_grads_norm = 3.9510
	sim_grads_norm = 0.0099
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7831
	data_grads_norm = 2.8971
	new_data_grads_norm = 4.0751
	old_data_grads_norm = 3.2895
	sim_grads_norm = 0.1642
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9417
	data_grads_norm = 3.2299
	new_data_grads_norm = 4.0349
	old_data_grads_norm = 4.3960
	sim_grads_norm = 0.0872
-- Starting training on experience 36 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3803
	data_grads_norm = 2.7875
	new_data_grads_norm = 3.9586
	old_data_grads_norm = 4.0388
	sim_grads_norm = -0.0107
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6460
	data_grads_norm = 2.5894
	new_data_grads_norm = 3.8725
	old_data_grads_norm = 2.9583
	sim_grads_norm = 0.0726
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8169
	data_grads_norm = 3.2732
	new_data_grads_norm = 3.5029
	old_data_grads_norm = 5.3002
	sim_grads_norm = 0.0842
-- Starting training on experience 37 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5351
	data_grads_norm = 2.8997
	new_data_grads_norm = 3.8467
	old_data_grads_norm = 3.9117
	sim_grads_norm = -0.0069
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8666
	data_grads_norm = 2.9720
	new_data_grads_norm = 3.9169
	old_data_grads_norm = 3.0685
	sim_grads_norm = -0.0089
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0509
	data_grads_norm = 3.6696
	new_data_grads_norm = 3.9493
	old_data_grads_norm = 5.2666
	sim_grads_norm = -0.0326
-- Starting training on experience 38 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8419
	data_grads_norm = 3.0516
	new_data_grads_norm = 3.9935
	old_data_grads_norm = 4.2543
	sim_grads_norm = -0.0708
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5262
	data_grads_norm = 3.3044
	new_data_grads_norm = 3.9805
	old_data_grads_norm = 4.0980
	sim_grads_norm = 0.0653
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1234
	data_grads_norm = 3.1127
	new_data_grads_norm = 3.5551
	old_data_grads_norm = 4.1161
	sim_grads_norm = 0.1024
-- Starting training on experience 39 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4590
	data_grads_norm = 2.8779
	new_data_grads_norm = 3.8787
	old_data_grads_norm = 4.2757
	sim_grads_norm = -0.0186
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4799
	data_grads_norm = 2.6093
	new_data_grads_norm = 3.8504
	old_data_grads_norm = 3.5057
	sim_grads_norm = -0.0033
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5205
	data_grads_norm = 3.1165
	new_data_grads_norm = 4.0720
	old_data_grads_norm = 3.7650
	sim_grads_norm = 0.0696
-- Starting training on experience 40 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7487
	data_grads_norm = 3.2580
	new_data_grads_norm = 4.5933
	old_data_grads_norm = 4.0008
	sim_grads_norm = 0.1420
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1527
	data_grads_norm = 3.5571
	new_data_grads_norm = 4.5445
	old_data_grads_norm = 4.3447
	sim_grads_norm = 0.1112
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9435
	data_grads_norm = 4.0989
	new_data_grads_norm = 4.9840
	old_data_grads_norm = 5.0174
	sim_grads_norm = 0.0096
-- Starting training on experience 41 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7778
	data_grads_norm = 3.5485
	new_data_grads_norm = 4.1967
	old_data_grads_norm = 4.6889
	sim_grads_norm = -0.0182
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9844
	data_grads_norm = 3.7906
	new_data_grads_norm = 4.5825
	old_data_grads_norm = 4.4042
	sim_grads_norm = 0.2561
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2433
	data_grads_norm = 2.9641
	new_data_grads_norm = 4.0247
	old_data_grads_norm = 3.7718
	sim_grads_norm = -0.0206
-- Starting training on experience 42 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9701
	data_grads_norm = 3.2920
	new_data_grads_norm = 4.0165
	old_data_grads_norm = 4.3044
	sim_grads_norm = 0.0889
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6859
	data_grads_norm = 2.8293
	new_data_grads_norm = 3.6225
	old_data_grads_norm = 4.2326
	sim_grads_norm = -0.0290
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7352
	data_grads_norm = 2.9596
	new_data_grads_norm = 4.2785
	old_data_grads_norm = 4.1037
	sim_grads_norm = 0.0083
-- Starting training on experience 43 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0833
	data_grads_norm = 3.1153
	new_data_grads_norm = 4.2949
	old_data_grads_norm = 4.2362
	sim_grads_norm = 0.0041
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6153
	data_grads_norm = 3.0056
	new_data_grads_norm = 4.0417
	old_data_grads_norm = 4.7406
	sim_grads_norm = 0.0206
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3608
	data_grads_norm = 3.8144
	new_data_grads_norm = 5.2301
	old_data_grads_norm = 5.3214
	sim_grads_norm = 0.2346
-- Starting training on experience 44 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7625
	data_grads_norm = 3.0192
	new_data_grads_norm = 4.0800
	old_data_grads_norm = 4.8205
	sim_grads_norm = -0.0426
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9316
	data_grads_norm = 3.0319
	new_data_grads_norm = 3.8226
	old_data_grads_norm = 5.0210
	sim_grads_norm = 0.0021
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1946
	data_grads_norm = 3.5339
	new_data_grads_norm = 3.7810
	old_data_grads_norm = 5.4561
	sim_grads_norm = 0.0704
-- Starting training on experience 45 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2500
	data_grads_norm = 2.5505
	new_data_grads_norm = 4.0921
	old_data_grads_norm = 3.3240
	sim_grads_norm = -0.0283
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4689
	data_grads_norm = 2.9305
	new_data_grads_norm = 3.9145
	old_data_grads_norm = 3.8842
	sim_grads_norm = -0.0051
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4697
	data_grads_norm = 2.4789
	new_data_grads_norm = 3.7845
	old_data_grads_norm = 3.3650
	sim_grads_norm = -0.1024
-- Starting training on experience 46 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2519
	data_grads_norm = 2.6554
	new_data_grads_norm = 3.5494
	old_data_grads_norm = 3.3703
	sim_grads_norm = 0.1264
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3306
	data_grads_norm = 2.6688
	new_data_grads_norm = 3.9471
	old_data_grads_norm = 3.2210
	sim_grads_norm = 0.0529
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9040
	data_grads_norm = 2.3516
	new_data_grads_norm = 3.8782
	old_data_grads_norm = 3.1162
	sim_grads_norm = -0.0134
-- Starting training on experience 47 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2776
	data_grads_norm = 2.6946
	new_data_grads_norm = 3.5530
	old_data_grads_norm = 3.6747
	sim_grads_norm = 0.1442
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7500
	data_grads_norm = 2.9357
	new_data_grads_norm = 3.3784
	old_data_grads_norm = 5.0615
	sim_grads_norm = 0.0554
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1018
	data_grads_norm = 2.1386
	new_data_grads_norm = 3.1373
	old_data_grads_norm = 2.8172
	sim_grads_norm = 0.0558
-- Starting training on experience 48 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6753
	data_grads_norm = 2.6577
	new_data_grads_norm = 3.2880
	old_data_grads_norm = 3.8942
	sim_grads_norm = 0.0098
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2123
	data_grads_norm = 2.2946
	new_data_grads_norm = 3.1705
	old_data_grads_norm = 3.4182
	sim_grads_norm = -0.1073
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0734
	data_grads_norm = 2.2050
	new_data_grads_norm = 3.6958
	old_data_grads_norm = 1.9756
	sim_grads_norm = 0.2421
-- Starting training on experience 49 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4003
	data_grads_norm = 2.9893
	new_data_grads_norm = 4.0456
	old_data_grads_norm = 4.5335
	sim_grads_norm = 0.0083
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4646
	data_grads_norm = 2.5830
	new_data_grads_norm = 3.5208
	old_data_grads_norm = 3.3363
	sim_grads_norm = -0.0826
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5818
	data_grads_norm = 3.2286
	new_data_grads_norm = 3.9087
	old_data_grads_norm = 4.8768
	sim_grads_norm = -0.0062
-- Starting training on experience 50 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5487
	data_grads_norm = 2.9412
	new_data_grads_norm = 4.2582
	old_data_grads_norm = 3.6645
	sim_grads_norm = 0.0158
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5976
	data_grads_norm = 2.7547
	new_data_grads_norm = 4.2036
	old_data_grads_norm = 3.2941
	sim_grads_norm = 0.0901
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5864
	data_grads_norm = 2.9006
	new_data_grads_norm = 4.4360
	old_data_grads_norm = 3.7967
	sim_grads_norm = 0.0121
-- Starting training on experience 51 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8175
	data_grads_norm = 2.9915
	new_data_grads_norm = 4.1027
	old_data_grads_norm = 4.3279
	sim_grads_norm = 0.0455
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4907
	data_grads_norm = 3.0127
	new_data_grads_norm = 4.2218
	old_data_grads_norm = 3.4943
	sim_grads_norm = 0.0397
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7944
	data_grads_norm = 3.5022
	new_data_grads_norm = 4.2799
	old_data_grads_norm = 4.6852
	sim_grads_norm = -0.0024
-- Starting training on experience 52 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3707
	data_grads_norm = 3.1305
	new_data_grads_norm = 3.7655
	old_data_grads_norm = 5.2768
	sim_grads_norm = 0.0058
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7357
	data_grads_norm = 3.2295
	new_data_grads_norm = 3.7958
	old_data_grads_norm = 4.5622
	sim_grads_norm = 0.0665
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8146
	data_grads_norm = 3.2901
	new_data_grads_norm = 4.1654
	old_data_grads_norm = 4.2934
	sim_grads_norm = 0.1523
-- Starting training on experience 53 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2460
	data_grads_norm = 2.8855
	new_data_grads_norm = 4.1623
	old_data_grads_norm = 3.7994
	sim_grads_norm = -0.0268
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4827
	data_grads_norm = 3.2521
	new_data_grads_norm = 4.2668
	old_data_grads_norm = 3.5272
	sim_grads_norm = 0.2193
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2788
	data_grads_norm = 3.1861
	new_data_grads_norm = 4.1277
	old_data_grads_norm = 4.6376
	sim_grads_norm = 0.0855
-- Starting training on experience 54 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4837
	data_grads_norm = 3.2451
	new_data_grads_norm = 4.3564
	old_data_grads_norm = 4.5963
	sim_grads_norm = 0.1105
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2484
	data_grads_norm = 2.8303
	new_data_grads_norm = 3.9336
	old_data_grads_norm = 4.2843
	sim_grads_norm = -0.0355
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8364
	data_grads_norm = 3.4396
	new_data_grads_norm = 4.3082
	old_data_grads_norm = 4.7073
	sim_grads_norm = 0.0274
-- Starting training on experience 55 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7863
	data_grads_norm = 2.7001
	new_data_grads_norm = 3.3353
	old_data_grads_norm = 4.0487
	sim_grads_norm = 0.0522
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2327
	data_grads_norm = 2.4065
	new_data_grads_norm = 4.1242
	old_data_grads_norm = 3.1746
	sim_grads_norm = -0.0252
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8868
	data_grads_norm = 3.0426
	new_data_grads_norm = 4.1830
	old_data_grads_norm = 4.3645
	sim_grads_norm = -0.0257
-- Starting training on experience 56 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6563
	data_grads_norm = 2.6162
	new_data_grads_norm = 4.3050
	old_data_grads_norm = 3.3907
	sim_grads_norm = 0.0487
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7494
	data_grads_norm = 2.8912
	new_data_grads_norm = 3.7829
	old_data_grads_norm = 3.7277
	sim_grads_norm = 0.0718
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9930
	data_grads_norm = 3.3400
	new_data_grads_norm = 3.8354
	old_data_grads_norm = 5.1816
	sim_grads_norm = -0.0082
-- Starting training on experience 57 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2867
	data_grads_norm = 3.2531
	new_data_grads_norm = 4.1048
	old_data_grads_norm = 4.7263
	sim_grads_norm = -0.0231
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5500
	data_grads_norm = 2.8912
	new_data_grads_norm = 4.4087
	old_data_grads_norm = 3.5870
	sim_grads_norm = -0.0076
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0529
	data_grads_norm = 3.8725
	new_data_grads_norm = 4.8157
	old_data_grads_norm = 5.2075
	sim_grads_norm = 0.0221
-- Starting training on experience 58 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2749
	data_grads_norm = 2.9564
	new_data_grads_norm = 3.6241
	old_data_grads_norm = 4.0844
	sim_grads_norm = 0.0897
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2504
	data_grads_norm = 3.2463
	new_data_grads_norm = 3.5152
	old_data_grads_norm = 4.4656
	sim_grads_norm = 0.0259
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6693
	data_grads_norm = 3.1129
	new_data_grads_norm = 3.5844
	old_data_grads_norm = 4.1493
	sim_grads_norm = 0.0886
-- Starting training on experience 59 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0483
	data_grads_norm = 2.4177
	new_data_grads_norm = 3.7065
	old_data_grads_norm = 3.2557
	sim_grads_norm = -0.0082
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3945
	data_grads_norm = 2.9407
	new_data_grads_norm = 3.6929
	old_data_grads_norm = 4.2514
	sim_grads_norm = 0.1150
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2586
	data_grads_norm = 2.5840
	new_data_grads_norm = 3.3776
	old_data_grads_norm = 3.3833
	sim_grads_norm = 0.0460
-- Starting training on experience 60 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2655
	data_grads_norm = 3.0268
	new_data_grads_norm = 4.1816
	old_data_grads_norm = 4.0429
	sim_grads_norm = 0.0209
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3934
	data_grads_norm = 2.7903
	new_data_grads_norm = 3.7102
	old_data_grads_norm = 4.0670
	sim_grads_norm = 0.0313
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2238
	data_grads_norm = 3.3159
	new_data_grads_norm = 3.7127
	old_data_grads_norm = 4.9387
	sim_grads_norm = -0.0209
-- Starting training on experience 61 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3392
	data_grads_norm = 2.7606
	new_data_grads_norm = 4.7667
	old_data_grads_norm = 3.2366
	sim_grads_norm = 0.0980
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3373
	data_grads_norm = 2.8877
	new_data_grads_norm = 4.5337
	old_data_grads_norm = 3.9281
	sim_grads_norm = 0.0094
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4599
	data_grads_norm = 2.8623
	new_data_grads_norm = 4.3767
	old_data_grads_norm = 3.8464
	sim_grads_norm = 0.0396
-- Starting training on experience 62 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2910
	data_grads_norm = 3.4023
	new_data_grads_norm = 3.9946
	old_data_grads_norm = 4.2423
	sim_grads_norm = -0.0198
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4069
	data_grads_norm = 3.6169
	new_data_grads_norm = 4.7935
	old_data_grads_norm = 4.8569
	sim_grads_norm = 0.0286
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2949
	data_grads_norm = 3.3941
	new_data_grads_norm = 4.4434
	old_data_grads_norm = 4.5760
	sim_grads_norm = 0.0214
-- Starting training on experience 63 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1038
	data_grads_norm = 2.6367
	new_data_grads_norm = 3.7025
	old_data_grads_norm = 3.3822
	sim_grads_norm = 0.0135
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8568
	data_grads_norm = 2.8667
	new_data_grads_norm = 3.9120
	old_data_grads_norm = 4.1399
	sim_grads_norm = 0.0161
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2710
	data_grads_norm = 2.9295
	new_data_grads_norm = 3.6261
	old_data_grads_norm = 4.5579
	sim_grads_norm = -0.0391
-- Starting training on experience 64 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5174
	data_grads_norm = 3.4084
	new_data_grads_norm = 4.5566
	old_data_grads_norm = 4.6065
	sim_grads_norm = 0.0620
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6693
	data_grads_norm = 3.1042
	new_data_grads_norm = 4.5813
	old_data_grads_norm = 4.3655
	sim_grads_norm = 0.0477
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7043
	data_grads_norm = 2.8818
	new_data_grads_norm = 4.4405
	old_data_grads_norm = 3.1219
	sim_grads_norm = 0.1208
-- Starting training on experience 65 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0611
	data_grads_norm = 2.9133
	new_data_grads_norm = 3.5413
	old_data_grads_norm = 3.1474
	sim_grads_norm = -0.0264
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8415
	data_grads_norm = 3.9185
	new_data_grads_norm = 3.6878
	old_data_grads_norm = 5.1983
	sim_grads_norm = -0.0360
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7876
	data_grads_norm = 2.3910
	new_data_grads_norm = 3.6891
	old_data_grads_norm = 2.8633
	sim_grads_norm = -0.0621
-- Starting training on experience 66 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5200
	data_grads_norm = 2.8895
	new_data_grads_norm = 3.9738
	old_data_grads_norm = 4.2132
	sim_grads_norm = 0.1040
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9616
	data_grads_norm = 3.9455
	new_data_grads_norm = 3.6329
	old_data_grads_norm = 5.6278
	sim_grads_norm = 0.1280
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6406
	data_grads_norm = 2.8668
	new_data_grads_norm = 3.3805
	old_data_grads_norm = 3.9297
	sim_grads_norm = -0.0461
-- Starting training on experience 67 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6955
	data_grads_norm = 3.4013
	new_data_grads_norm = 3.9812
	old_data_grads_norm = 5.5040
	sim_grads_norm = 0.0079
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4133
	data_grads_norm = 2.9888
	new_data_grads_norm = 4.0463
	old_data_grads_norm = 3.8867
	sim_grads_norm = 0.0746
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5029
	data_grads_norm = 3.1425
	new_data_grads_norm = 3.9227
	old_data_grads_norm = 4.1148
	sim_grads_norm = 0.1850
-- Starting training on experience 68 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3117
	data_grads_norm = 3.1323
	new_data_grads_norm = 3.9082
	old_data_grads_norm = 4.6117
	sim_grads_norm = 0.0519
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2672
	data_grads_norm = 3.0054
	new_data_grads_norm = 4.0898
	old_data_grads_norm = 4.5195
	sim_grads_norm = -0.0155
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3221
	data_grads_norm = 2.8644
	new_data_grads_norm = 4.2587
	old_data_grads_norm = 3.8382
	sim_grads_norm = 0.0185
-- Starting training on experience 69 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1095
	data_grads_norm = 3.3579
	new_data_grads_norm = 4.2008
	old_data_grads_norm = 3.9755
	sim_grads_norm = 0.0277
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4157
	data_grads_norm = 3.0827
	new_data_grads_norm = 4.9108
	old_data_grads_norm = 3.4463
	sim_grads_norm = 0.1022
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3712
	data_grads_norm = 3.0953
	new_data_grads_norm = 4.5740
	old_data_grads_norm = 3.6503
	sim_grads_norm = -0.0198
-- Starting training on experience 70 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8184
	data_grads_norm = 3.2205
	new_data_grads_norm = 4.6766
	old_data_grads_norm = 4.1415
	sim_grads_norm = -0.0438
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7497
	data_grads_norm = 3.4684
	new_data_grads_norm = 4.6467
	old_data_grads_norm = 4.2614
	sim_grads_norm = 0.0413
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1007
	data_grads_norm = 3.7381
	new_data_grads_norm = 4.5895
	old_data_grads_norm = 4.8275
	sim_grads_norm = 0.0687
-- Starting training on experience 71 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1304
	data_grads_norm = 2.6596
	new_data_grads_norm = 4.5628
	old_data_grads_norm = 3.0538
	sim_grads_norm = -0.0100
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4347
	data_grads_norm = 3.0121
	new_data_grads_norm = 4.6796
	old_data_grads_norm = 4.1541
	sim_grads_norm = -0.0523
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5409
	data_grads_norm = 3.0939
	new_data_grads_norm = 4.8889
	old_data_grads_norm = 4.4367
	sim_grads_norm = -0.0660
-- Starting training on experience 72 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6765
	data_grads_norm = 3.3977
	new_data_grads_norm = 4.5799
	old_data_grads_norm = 3.9469
	sim_grads_norm = -0.0146
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5114
	data_grads_norm = 3.0151
	new_data_grads_norm = 4.6846
	old_data_grads_norm = 3.5410
	sim_grads_norm = 0.0012
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9272
	data_grads_norm = 3.7634
	new_data_grads_norm = 4.6811
	old_data_grads_norm = 4.5235
	sim_grads_norm = 0.1170
-- Starting training on experience 73 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0366
	data_grads_norm = 2.3915
	new_data_grads_norm = 3.6417
	old_data_grads_norm = 3.4471
	sim_grads_norm = -0.0484
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4393
	data_grads_norm = 2.8281
	new_data_grads_norm = 4.1790
	old_data_grads_norm = 4.0158
	sim_grads_norm = -0.0295
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7023
	data_grads_norm = 3.1234
	new_data_grads_norm = 4.0395
	old_data_grads_norm = 4.7386
	sim_grads_norm = -0.0123
-- Starting training on experience 74 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3860
	data_grads_norm = 3.0192
	new_data_grads_norm = 4.1383
	old_data_grads_norm = 4.2781
	sim_grads_norm = -0.0069
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2549
	data_grads_norm = 2.8148
	new_data_grads_norm = 4.0285
	old_data_grads_norm = 3.3930
	sim_grads_norm = -0.0268
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1805
	data_grads_norm = 2.5939
	new_data_grads_norm = 3.9698
	old_data_grads_norm = 2.5962
	sim_grads_norm = 0.0362
-- Starting training on experience 75 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5043
	data_grads_norm = 3.0484
	new_data_grads_norm = 4.4048
	old_data_grads_norm = 4.7801
	sim_grads_norm = 0.0795
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1856
	data_grads_norm = 2.7057
	new_data_grads_norm = 3.7707
	old_data_grads_norm = 3.3403
	sim_grads_norm = 0.0759
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7761
	data_grads_norm = 3.6945
	new_data_grads_norm = 3.8397
	old_data_grads_norm = 6.6069
	sim_grads_norm = 0.0370
-- Starting training on experience 76 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2903
	data_grads_norm = 3.1475
	new_data_grads_norm = 4.9384
	old_data_grads_norm = 4.3510
	sim_grads_norm = 0.0718
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7159
	data_grads_norm = 3.3203
	new_data_grads_norm = 3.9933
	old_data_grads_norm = 4.3667
	sim_grads_norm = 0.1487
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2808
	data_grads_norm = 3.1410
	new_data_grads_norm = 3.5163
	old_data_grads_norm = 4.4912
	sim_grads_norm = 0.0858
-- Starting training on experience 77 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4846
	data_grads_norm = 3.6072
	new_data_grads_norm = 4.4505
	old_data_grads_norm = 5.2855
	sim_grads_norm = 0.0679
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2448
	data_grads_norm = 3.2385
	new_data_grads_norm = 4.4874
	old_data_grads_norm = 4.7025
	sim_grads_norm = -0.0217
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5255
	data_grads_norm = 2.8401
	new_data_grads_norm = 4.4117
	old_data_grads_norm = 3.3393
	sim_grads_norm = 0.0154
-- Starting training on experience 78 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3179
	data_grads_norm = 3.2711
	new_data_grads_norm = 4.6533
	old_data_grads_norm = 3.6953
	sim_grads_norm = 0.0092
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0234
	data_grads_norm = 3.7978
	new_data_grads_norm = 4.7586
	old_data_grads_norm = 5.4103
	sim_grads_norm = 0.1097
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2589
	data_grads_norm = 2.9223
	new_data_grads_norm = 4.3096
	old_data_grads_norm = 4.4051
	sim_grads_norm = -0.0266
-- Starting training on experience 79 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6339
	data_grads_norm = 3.7067
	new_data_grads_norm = 3.9755
	old_data_grads_norm = 6.1250
	sim_grads_norm = -0.0257
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2327
	data_grads_norm = 2.7314
	new_data_grads_norm = 4.0390
	old_data_grads_norm = 4.3113
	sim_grads_norm = -0.0266
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3448
	data_grads_norm = 2.8004
	new_data_grads_norm = 4.2128
	old_data_grads_norm = 4.1138
	sim_grads_norm = -0.0680
-- Starting training on experience 80 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2608
	data_grads_norm = 2.9070
	new_data_grads_norm = 4.3281
	old_data_grads_norm = 4.1713
	sim_grads_norm = 0.0553
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9388
	data_grads_norm = 3.3305
	new_data_grads_norm = 4.1427
	old_data_grads_norm = 4.9670
	sim_grads_norm = -0.0295
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4803
	data_grads_norm = 2.9469
	new_data_grads_norm = 3.9594
	old_data_grads_norm = 3.7734
	sim_grads_norm = 0.0980
-- Starting training on experience 81 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8151
	data_grads_norm = 3.6206
	new_data_grads_norm = 4.4917
	old_data_grads_norm = 4.4958
	sim_grads_norm = 0.1060
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9601
	data_grads_norm = 2.5646
	new_data_grads_norm = 4.3903
	old_data_grads_norm = 2.5891
	sim_grads_norm = 0.0646
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4857
	data_grads_norm = 3.1114
	new_data_grads_norm = 3.9052
	old_data_grads_norm = 4.5062
	sim_grads_norm = 0.0437
-- Starting training on experience 82 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7853
	data_grads_norm = 3.2770
	new_data_grads_norm = 4.6145
	old_data_grads_norm = 4.5850
	sim_grads_norm = 0.1011
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6389
	data_grads_norm = 3.2550
	new_data_grads_norm = 3.8802
	old_data_grads_norm = 4.9042
	sim_grads_norm = 0.0077
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6751
	data_grads_norm = 3.2604
	new_data_grads_norm = 4.5387
	old_data_grads_norm = 4.7105
	sim_grads_norm = 0.0415
-- Starting training on experience 83 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5888
	data_grads_norm = 2.8568
	new_data_grads_norm = 4.3722
	old_data_grads_norm = 3.7308
	sim_grads_norm = 0.0753
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4310
	data_grads_norm = 3.0192
	new_data_grads_norm = 4.1611
	old_data_grads_norm = 3.5233
	sim_grads_norm = 0.1716
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6420
	data_grads_norm = 2.5526
	new_data_grads_norm = 3.5087
	old_data_grads_norm = 3.6700
	sim_grads_norm = -0.0503
-- Starting training on experience 84 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3188
	data_grads_norm = 3.5078
	new_data_grads_norm = 4.1202
	old_data_grads_norm = 4.4827
	sim_grads_norm = 0.0896
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3919
	data_grads_norm = 3.7306
	new_data_grads_norm = 4.5747
	old_data_grads_norm = 4.7721
	sim_grads_norm = 0.0213
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4248
	data_grads_norm = 4.1065
	new_data_grads_norm = 4.7656
	old_data_grads_norm = 5.9355
	sim_grads_norm = -0.0065
-- Starting training on experience 85 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4184
	data_grads_norm = 3.4943
	new_data_grads_norm = 4.0220
	old_data_grads_norm = 5.9234
	sim_grads_norm = 0.0224
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5185
	data_grads_norm = 2.8792
	new_data_grads_norm = 3.9738
	old_data_grads_norm = 4.0201
	sim_grads_norm = -0.0711
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6475
	data_grads_norm = 3.3177
	new_data_grads_norm = 3.9062
	old_data_grads_norm = 4.5797
	sim_grads_norm = 0.1956
-- Starting training on experience 86 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0004
	data_grads_norm = 2.8304
	new_data_grads_norm = 4.5486
	old_data_grads_norm = 3.5625
	sim_grads_norm = -0.0319
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4950
	data_grads_norm = 3.0123
	new_data_grads_norm = 4.1864
	old_data_grads_norm = 4.6137
	sim_grads_norm = 0.0797
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5574
	data_grads_norm = 3.1284
	new_data_grads_norm = 4.2600
	old_data_grads_norm = 4.0705
	sim_grads_norm = 0.0767
-- Starting training on experience 87 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4839
	data_grads_norm = 2.8503
	new_data_grads_norm = 3.7628
	old_data_grads_norm = 3.8831
	sim_grads_norm = 0.0382
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3535
	data_grads_norm = 3.3930
	new_data_grads_norm = 3.5877
	old_data_grads_norm = 5.0165
	sim_grads_norm = 0.0317
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5445
	data_grads_norm = 3.2760
	new_data_grads_norm = 3.8698
	old_data_grads_norm = 5.5214
	sim_grads_norm = -0.0396
-- Starting training on experience 88 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3894
	data_grads_norm = 3.6451
	new_data_grads_norm = 4.6560
	old_data_grads_norm = 4.4961
	sim_grads_norm = 0.1226
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2564
	data_grads_norm = 3.2715
	new_data_grads_norm = 5.4115
	old_data_grads_norm = 3.4570
	sim_grads_norm = 0.0100
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4149
	data_grads_norm = 3.1477
	new_data_grads_norm = 4.8025
	old_data_grads_norm = 2.8869
	sim_grads_norm = 0.1326
-- Starting training on experience 89 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9950
	data_grads_norm = 3.1440
	new_data_grads_norm = 4.6182
	old_data_grads_norm = 3.8477
	sim_grads_norm = -0.0163
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0814
	data_grads_norm = 3.5605
	new_data_grads_norm = 4.4824
	old_data_grads_norm = 4.5203
	sim_grads_norm = -0.0366
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9029
	data_grads_norm = 2.9455
	new_data_grads_norm = 4.2544
	old_data_grads_norm = 2.9072
	sim_grads_norm = 0.0545
-- Starting training on experience 90 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8932
	data_grads_norm = 3.5045
	new_data_grads_norm = 4.3278
	old_data_grads_norm = 4.9566
	sim_grads_norm = -0.0111
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7236
	data_grads_norm = 3.1591
	new_data_grads_norm = 4.1023
	old_data_grads_norm = 4.2120
	sim_grads_norm = 0.0174
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5427
	data_grads_norm = 2.8746
	new_data_grads_norm = 4.4372
	old_data_grads_norm = 4.1144
	sim_grads_norm = -0.0402
-- Starting training on experience 91 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7788
	data_grads_norm = 3.3629
	new_data_grads_norm = 4.4955
	old_data_grads_norm = 4.0944
	sim_grads_norm = 0.1203
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2300
	data_grads_norm = 3.2172
	new_data_grads_norm = 5.0249
	old_data_grads_norm = 4.4465
	sim_grads_norm = 0.0018
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4095
	data_grads_norm = 3.4449
	new_data_grads_norm = 4.3268
	old_data_grads_norm = 4.8698
	sim_grads_norm = 0.0701
-- Starting training on experience 92 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3638
	data_grads_norm = 2.9391
	new_data_grads_norm = 4.6223
	old_data_grads_norm = 3.5854
	sim_grads_norm = -0.0191
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4641
	data_grads_norm = 2.8193
	new_data_grads_norm = 4.5764
	old_data_grads_norm = 3.5116
	sim_grads_norm = -0.0605
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5742
	data_grads_norm = 3.2762
	new_data_grads_norm = 4.7911
	old_data_grads_norm = 3.3412
	sim_grads_norm = 0.2057
-- Starting training on experience 93 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1900
	data_grads_norm = 3.1498
	new_data_grads_norm = 4.6149
	old_data_grads_norm = 3.6768
	sim_grads_norm = -0.0263
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2388
	data_grads_norm = 3.2456
	new_data_grads_norm = 4.5419
	old_data_grads_norm = 4.6642
	sim_grads_norm = 0.0089
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0944
	data_grads_norm = 3.1662
	new_data_grads_norm = 4.7894
	old_data_grads_norm = 3.3705
	sim_grads_norm = 0.1360
-- Starting training on experience 94 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8661
	data_grads_norm = 3.0692
	new_data_grads_norm = 4.6357
	old_data_grads_norm = 4.0761
	sim_grads_norm = -0.0147
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1893
	data_grads_norm = 3.1636
	new_data_grads_norm = 4.3599
	old_data_grads_norm = 4.3734
	sim_grads_norm = -0.0555
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2262
	data_grads_norm = 3.2809
	new_data_grads_norm = 4.7246
	old_data_grads_norm = 4.1659
	sim_grads_norm = -0.0176
-- Starting training on experience 95 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6335
	data_grads_norm = 3.6982
	new_data_grads_norm = 4.6653
	old_data_grads_norm = 4.7617
	sim_grads_norm = 0.0318
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6895
	data_grads_norm = 3.5778
	new_data_grads_norm = 4.3622
	old_data_grads_norm = 5.2401
	sim_grads_norm = 0.0137
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0330
	data_grads_norm = 3.4232
	new_data_grads_norm = 4.7109
	old_data_grads_norm = 4.7983
	sim_grads_norm = 0.1635
-- Starting training on experience 96 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3084
	data_grads_norm = 3.2617
	new_data_grads_norm = 4.5386
	old_data_grads_norm = 4.2640
	sim_grads_norm = -0.0537
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4114
	data_grads_norm = 3.5417
	new_data_grads_norm = 4.3718
	old_data_grads_norm = 5.2766
	sim_grads_norm = 0.0412
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5200
	data_grads_norm = 3.3395
	new_data_grads_norm = 4.6294
	old_data_grads_norm = 4.5131
	sim_grads_norm = 0.0059
-- Starting training on experience 97 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1493
	data_grads_norm = 3.0321
	new_data_grads_norm = 4.5900
	old_data_grads_norm = 3.8553
	sim_grads_norm = 0.0278
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0193
	data_grads_norm = 3.6241
	new_data_grads_norm = 5.1650
	old_data_grads_norm = 5.6331
	sim_grads_norm = 0.0069
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3119
	data_grads_norm = 3.3355
	new_data_grads_norm = 4.9544
	old_data_grads_norm = 3.7880
	sim_grads_norm = 0.0106
-- Starting training on experience 98 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2995
	data_grads_norm = 2.9518
	new_data_grads_norm = 4.1596
	old_data_grads_norm = 3.5569
	sim_grads_norm = 0.1897
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3391
	data_grads_norm = 2.6251
	new_data_grads_norm = 4.0258
	old_data_grads_norm = 3.3828
	sim_grads_norm = -0.0003
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0386
	data_grads_norm = 2.7997
	new_data_grads_norm = 4.0346
	old_data_grads_norm = 5.0603
	sim_grads_norm = -0.0394
-- Starting training on experience 99 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3695
	data_grads_norm = 3.7810
	new_data_grads_norm = 4.0971
	old_data_grads_norm = 5.5138
	sim_grads_norm = 0.0080
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4735
	data_grads_norm = 3.1949
	new_data_grads_norm = 3.8959
	old_data_grads_norm = 5.0685
	sim_grads_norm = 0.0487
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0535
	data_grads_norm = 2.9569
	new_data_grads_norm = 3.7714
	old_data_grads_norm = 4.3746
	sim_grads_norm = -0.0093
-- Starting training on experience 100 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2081
	data_grads_norm = 3.1243
	new_data_grads_norm = 4.0887
	old_data_grads_norm = 4.6074
	sim_grads_norm = -0.0231
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7999
	data_grads_norm = 2.5679
	new_data_grads_norm = 3.8705
	old_data_grads_norm = 3.5621
	sim_grads_norm = -0.0069
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3294
	data_grads_norm = 3.2522
	new_data_grads_norm = 4.7514
	old_data_grads_norm = 4.8535
	sim_grads_norm = 0.0285
-- Starting training on experience 101 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2656
	data_grads_norm = 3.6139
	new_data_grads_norm = 4.5572
	old_data_grads_norm = 4.9693
	sim_grads_norm = -0.0128
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5341
	data_grads_norm = 3.1999
	new_data_grads_norm = 4.5923
	old_data_grads_norm = 4.2072
	sim_grads_norm = 0.0100
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4031
	data_grads_norm = 3.5450
	new_data_grads_norm = 5.2407
	old_data_grads_norm = 4.6601
	sim_grads_norm = -0.0584
-- Starting training on experience 102 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4491
	data_grads_norm = 3.1622
	new_data_grads_norm = 5.1518
	old_data_grads_norm = 4.0734
	sim_grads_norm = 0.0167
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8451
	data_grads_norm = 3.6858
	new_data_grads_norm = 5.5745
	old_data_grads_norm = 5.1757
	sim_grads_norm = -0.0411
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8068
	data_grads_norm = 3.6453
	new_data_grads_norm = 5.2282
	old_data_grads_norm = 5.0693
	sim_grads_norm = 0.0650
-- Starting training on experience 103 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5920
	data_grads_norm = 3.3372
	new_data_grads_norm = 4.8078
	old_data_grads_norm = 3.9213
	sim_grads_norm = 0.0793
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8013
	data_grads_norm = 3.4815
	new_data_grads_norm = 4.2176
	old_data_grads_norm = 5.1057
	sim_grads_norm = 0.0005
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1382
	data_grads_norm = 2.6924
	new_data_grads_norm = 3.8623
	old_data_grads_norm = 3.5290
	sim_grads_norm = 0.1005
-- Starting training on experience 104 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3595
	data_grads_norm = 2.9214
	new_data_grads_norm = 4.0484
	old_data_grads_norm = 3.5849
	sim_grads_norm = 0.0755
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1676
	data_grads_norm = 2.6017
	new_data_grads_norm = 3.9170
	old_data_grads_norm = 3.7816
	sim_grads_norm = -0.0171
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9575
	data_grads_norm = 2.5790
	new_data_grads_norm = 4.0929
	old_data_grads_norm = 3.4894
	sim_grads_norm = 0.0102
-- Starting training on experience 105 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9241
	data_grads_norm = 2.5096
	new_data_grads_norm = 3.7513
	old_data_grads_norm = 4.0143
	sim_grads_norm = -0.0057
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3700
	data_grads_norm = 2.5591
	new_data_grads_norm = 4.4519
	old_data_grads_norm = 3.4141
	sim_grads_norm = -0.0328
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9507
	data_grads_norm = 3.5760
	new_data_grads_norm = 4.5026
	old_data_grads_norm = 4.6339
	sim_grads_norm = 0.1191
-- Starting training on experience 106 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2026
	data_grads_norm = 2.7854
	new_data_grads_norm = 4.0002
	old_data_grads_norm = 3.7358
	sim_grads_norm = -0.0607
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1817
	data_grads_norm = 3.5337
	new_data_grads_norm = 4.6035
	old_data_grads_norm = 4.1302
	sim_grads_norm = 0.0393
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0813
	data_grads_norm = 2.5176
	new_data_grads_norm = 3.8862
	old_data_grads_norm = 3.5213
	sim_grads_norm = -0.0103
-- Starting training on experience 107 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2780
	data_grads_norm = 3.2071
	new_data_grads_norm = 5.0777
	old_data_grads_norm = 3.9675
	sim_grads_norm = 0.0414
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1048
	data_grads_norm = 2.9974
	new_data_grads_norm = 4.8757
	old_data_grads_norm = 3.6546
	sim_grads_norm = 0.0463
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2670
	data_grads_norm = 3.1273
	new_data_grads_norm = 4.5523
	old_data_grads_norm = 3.8312
	sim_grads_norm = 0.0955
-- Starting training on experience 108 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1377
	data_grads_norm = 3.3424
	new_data_grads_norm = 5.2838
	old_data_grads_norm = 3.6794
	sim_grads_norm = -0.0105
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4223
	data_grads_norm = 3.7287
	new_data_grads_norm = 4.4300
	old_data_grads_norm = 5.6895
	sim_grads_norm = 0.1004
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6774
	data_grads_norm = 3.8035
	new_data_grads_norm = 4.8081
	old_data_grads_norm = 5.6772
	sim_grads_norm = 0.0380
-- Starting training on experience 109 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3933
	data_grads_norm = 3.4446
	new_data_grads_norm = 5.8393
	old_data_grads_norm = 3.8309
	sim_grads_norm = 0.0732
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6974
	data_grads_norm = 3.6805
	new_data_grads_norm = 4.9134
	old_data_grads_norm = 5.3811
	sim_grads_norm = 0.1207
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3196
	data_grads_norm = 3.4340
	new_data_grads_norm = 4.8457
	old_data_grads_norm = 4.7114
	sim_grads_norm = 0.0341
-- Starting training on experience 110 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6089
	data_grads_norm = 2.4681
	new_data_grads_norm = 3.6195
	old_data_grads_norm = 3.4282
	sim_grads_norm = -0.0202
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0121
	data_grads_norm = 2.9518
	new_data_grads_norm = 3.7353
	old_data_grads_norm = 4.5403
	sim_grads_norm = 0.0115
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4088
	data_grads_norm = 3.2245
	new_data_grads_norm = 3.8787
	old_data_grads_norm = 5.4201
	sim_grads_norm = -0.0076
-- Starting training on experience 111 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5449
	data_grads_norm = 3.3464
	new_data_grads_norm = 3.8466
	old_data_grads_norm = 4.6427
	sim_grads_norm = 0.1413
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0672
	data_grads_norm = 2.6676
	new_data_grads_norm = 3.8840
	old_data_grads_norm = 3.3800
	sim_grads_norm = 0.0283
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1530
	data_grads_norm = 2.9982
	new_data_grads_norm = 4.1042
	old_data_grads_norm = 3.5962
	sim_grads_norm = 0.2167
-- Starting training on experience 112 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5109
	data_grads_norm = 3.5190
	new_data_grads_norm = 4.5171
	old_data_grads_norm = 5.2865
	sim_grads_norm = -0.0255
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2757
	data_grads_norm = 3.2870
	new_data_grads_norm = 4.5047
	old_data_grads_norm = 4.2559
	sim_grads_norm = -0.0649
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6864
	data_grads_norm = 3.3457
	new_data_grads_norm = 4.6130
	old_data_grads_norm = 4.0610
	sim_grads_norm = 0.0696
-- Starting training on experience 113 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5742
	data_grads_norm = 3.7436
	new_data_grads_norm = 4.2652
	old_data_grads_norm = 5.7748
	sim_grads_norm = 0.0591
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3340
	data_grads_norm = 3.1401
	new_data_grads_norm = 4.2979
	old_data_grads_norm = 4.2193
	sim_grads_norm = -0.0097
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3353
	data_grads_norm = 3.3525
	new_data_grads_norm = 3.9362
	old_data_grads_norm = 4.8241
	sim_grads_norm = 0.0733
-- Starting training on experience 114 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3740
	data_grads_norm = 2.7756
	new_data_grads_norm = 3.5989
	old_data_grads_norm = 3.8750
	sim_grads_norm = -0.0205
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0127
	data_grads_norm = 2.6270
	new_data_grads_norm = 3.5658
	old_data_grads_norm = 3.2873
	sim_grads_norm = 0.0660
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2040
	data_grads_norm = 2.9710
	new_data_grads_norm = 3.5205
	old_data_grads_norm = 4.4759
	sim_grads_norm = 0.0553
-- Starting training on experience 115 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1533
	data_grads_norm = 2.5705
	new_data_grads_norm = 2.6943
	old_data_grads_norm = 3.9016
	sim_grads_norm = 0.0365
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9055
	data_grads_norm = 2.5138
	new_data_grads_norm = 2.6970
	old_data_grads_norm = 3.9374
	sim_grads_norm = -0.0364
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1957
	data_grads_norm = 2.5655
	new_data_grads_norm = 2.9279
	old_data_grads_norm = 3.4221
	sim_grads_norm = 0.0969
-- Starting training on experience 116 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0642
	data_grads_norm = 3.1208
	new_data_grads_norm = 3.9379
	old_data_grads_norm = 4.5551
	sim_grads_norm = 0.0878
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1060
	data_grads_norm = 2.7803
	new_data_grads_norm = 4.0245
	old_data_grads_norm = 4.0610
	sim_grads_norm = -0.0916
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2131
	data_grads_norm = 2.9060
	new_data_grads_norm = 4.4063
	old_data_grads_norm = 4.1758
	sim_grads_norm = -0.1107
-- Starting training on experience 117 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0307
	data_grads_norm = 3.3107
	new_data_grads_norm = 4.6870
	old_data_grads_norm = 4.7197
	sim_grads_norm = -0.0656
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2746
	data_grads_norm = 3.3057
	new_data_grads_norm = 4.7329
	old_data_grads_norm = 4.3690
	sim_grads_norm = 0.0134
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5276
	data_grads_norm = 3.6591
	new_data_grads_norm = 5.0811
	old_data_grads_norm = 4.9239
	sim_grads_norm = 0.1338
-- Starting training on experience 118 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1807
	data_grads_norm = 2.7118
	new_data_grads_norm = 3.3277
	old_data_grads_norm = 4.1362
	sim_grads_norm = 0.0341
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8864
	data_grads_norm = 2.4227
	new_data_grads_norm = 3.3630
	old_data_grads_norm = 2.7924
	sim_grads_norm = 0.0120
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6620
	data_grads_norm = 3.0910
	new_data_grads_norm = 3.4856
	old_data_grads_norm = 4.3919
	sim_grads_norm = 0.1245
-- Starting training on experience 119 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1523
	data_grads_norm = 2.7851
	new_data_grads_norm = 3.8456
	old_data_grads_norm = 4.2292
	sim_grads_norm = -0.0467
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5683
	data_grads_norm = 3.2654
	new_data_grads_norm = 4.0988
	old_data_grads_norm = 4.7136
	sim_grads_norm = 0.0389
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1721
	data_grads_norm = 2.8917
	new_data_grads_norm = 3.6732
	old_data_grads_norm = 4.0117
	sim_grads_norm = 0.1335
-- Starting training on experience 120 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2350
	data_grads_norm = 2.8331
	new_data_grads_norm = 4.0632
	old_data_grads_norm = 4.1491
	sim_grads_norm = -0.1301
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2182
	data_grads_norm = 3.0394
	new_data_grads_norm = 4.3524
	old_data_grads_norm = 4.1995
	sim_grads_norm = -0.0817
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3976
	data_grads_norm = 3.3894
	new_data_grads_norm = 4.4566
	old_data_grads_norm = 3.8799
	sim_grads_norm = 0.1181
-- Starting training on experience 121 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6011
	data_grads_norm = 2.6812
	new_data_grads_norm = 4.0511
	old_data_grads_norm = 3.7889
	sim_grads_norm = -0.0130
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8699
	data_grads_norm = 3.2313
	new_data_grads_norm = 4.5309
	old_data_grads_norm = 3.7056
	sim_grads_norm = -0.0324
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7908
	data_grads_norm = 2.8859
	new_data_grads_norm = 4.5387
	old_data_grads_norm = 4.0795
	sim_grads_norm = 0.0544
-- Starting training on experience 122 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8089
	data_grads_norm = 3.0885
	new_data_grads_norm = 3.6272
	old_data_grads_norm = 4.1005
	sim_grads_norm = 0.0067
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0858
	data_grads_norm = 3.0624
	new_data_grads_norm = 3.5744
	old_data_grads_norm = 4.5062
	sim_grads_norm = 0.1161
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1063
	data_grads_norm = 2.8660
	new_data_grads_norm = 3.2977
	old_data_grads_norm = 4.6403
	sim_grads_norm = -0.0670
-- Starting training on experience 123 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3378
	data_grads_norm = 3.0983
	new_data_grads_norm = 3.5356
	old_data_grads_norm = 5.0264
	sim_grads_norm = -0.0130
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0848
	data_grads_norm = 2.8281
	new_data_grads_norm = 3.5735
	old_data_grads_norm = 4.1641
	sim_grads_norm = 0.0174
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3897
	data_grads_norm = 3.0051
	new_data_grads_norm = 3.9629
	old_data_grads_norm = 4.3409
	sim_grads_norm = -0.1364
-- Starting training on experience 124 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1704
	data_grads_norm = 2.8784
	new_data_grads_norm = 3.7307
	old_data_grads_norm = 3.8818
	sim_grads_norm = 0.0931
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1915
	data_grads_norm = 3.2172
	new_data_grads_norm = 4.1972
	old_data_grads_norm = 3.9479
	sim_grads_norm = 0.0737
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1073
	data_grads_norm = 2.9699
	new_data_grads_norm = 3.9525
	old_data_grads_norm = 3.7547
	sim_grads_norm = 0.0829
-- Starting training on experience 125 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3853
	data_grads_norm = 3.2346
	new_data_grads_norm = 4.8060
	old_data_grads_norm = 3.7450
	sim_grads_norm = 0.0502
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3080
	data_grads_norm = 3.5088
	new_data_grads_norm = 5.2581
	old_data_grads_norm = 3.9483
	sim_grads_norm = 0.0163
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1449
	data_grads_norm = 3.2277
	new_data_grads_norm = 5.3890
	old_data_grads_norm = 3.7325
	sim_grads_norm = 0.0555
-- Starting training on experience 126 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1730
	data_grads_norm = 2.8181
	new_data_grads_norm = 3.8740
	old_data_grads_norm = 3.5954
	sim_grads_norm = 0.0406
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7169
	data_grads_norm = 2.4709
	new_data_grads_norm = 4.0449
	old_data_grads_norm = 3.4282
	sim_grads_norm = -0.0441
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8412
	data_grads_norm = 3.0746
	new_data_grads_norm = 4.2380
	old_data_grads_norm = 4.3140
	sim_grads_norm = 0.0688
-- Starting training on experience 127 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8011
	data_grads_norm = 3.1349
	new_data_grads_norm = 4.7439
	old_data_grads_norm = 4.0750
	sim_grads_norm = 0.0031
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1486
	data_grads_norm = 3.1419
	new_data_grads_norm = 4.1289
	old_data_grads_norm = 4.1501
	sim_grads_norm = 0.0556
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0607
	data_grads_norm = 3.6923
	new_data_grads_norm = 5.1019
	old_data_grads_norm = 4.7777
	sim_grads_norm = 0.0131
-- Starting training on experience 128 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5682
	data_grads_norm = 2.5393
	new_data_grads_norm = 4.0849
	old_data_grads_norm = 3.2020
	sim_grads_norm = 0.0221
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9747
	data_grads_norm = 2.7885
	new_data_grads_norm = 4.2700
	old_data_grads_norm = 3.3890
	sim_grads_norm = -0.0069
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8060
	data_grads_norm = 2.7214
	new_data_grads_norm = 4.0932
	old_data_grads_norm = 3.6740
	sim_grads_norm = 0.0142
-- Starting training on experience 129 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2837
	data_grads_norm = 3.1554
	new_data_grads_norm = 5.3933
	old_data_grads_norm = 3.9136
	sim_grads_norm = -0.0531
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3700
	data_grads_norm = 3.3156
	new_data_grads_norm = 5.3481
	old_data_grads_norm = 4.1492
	sim_grads_norm = 0.0146
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8306
	data_grads_norm = 3.6162
	new_data_grads_norm = 5.2844
	old_data_grads_norm = 4.8174
	sim_grads_norm = 0.1348
-- Starting training on experience 130 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5380
	data_grads_norm = 2.9848
	new_data_grads_norm = 4.5470
	old_data_grads_norm = 4.3398
	sim_grads_norm = -0.0072
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2305
	data_grads_norm = 3.0954
	new_data_grads_norm = 4.7927
	old_data_grads_norm = 4.8182
	sim_grads_norm = 0.0021
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2646
	data_grads_norm = 3.4372
	new_data_grads_norm = 5.2551
	old_data_grads_norm = 3.8341
	sim_grads_norm = 0.0840
-- Starting training on experience 131 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1334
	data_grads_norm = 3.3538
	new_data_grads_norm = 4.1210
	old_data_grads_norm = 5.1152
	sim_grads_norm = 0.0218
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6964
	data_grads_norm = 2.7661
	new_data_grads_norm = 3.7354
	old_data_grads_norm = 3.6910
	sim_grads_norm = 0.0546
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4995
	data_grads_norm = 2.5569
	new_data_grads_norm = 3.9430
	old_data_grads_norm = 3.4151
	sim_grads_norm = 0.0214
-- Starting training on experience 132 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8951
	data_grads_norm = 3.1801
	new_data_grads_norm = 4.5761
	old_data_grads_norm = 3.5026
	sim_grads_norm = 0.1092
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0385
	data_grads_norm = 3.0209
	new_data_grads_norm = 4.7618
	old_data_grads_norm = 3.9638
	sim_grads_norm = -0.0683
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1586
	data_grads_norm = 3.1315
	new_data_grads_norm = 4.7903
	old_data_grads_norm = 3.9480
	sim_grads_norm = -0.0724
-- Starting training on experience 133 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2135
	data_grads_norm = 3.1581
	new_data_grads_norm = 4.4247
	old_data_grads_norm = 4.1031
	sim_grads_norm = 0.0618
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0183
	data_grads_norm = 2.7898
	new_data_grads_norm = 4.0342
	old_data_grads_norm = 3.5255
	sim_grads_norm = 0.0541
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9790
	data_grads_norm = 2.6245
	new_data_grads_norm = 4.3991
	old_data_grads_norm = 3.9010
	sim_grads_norm = 0.0552
-- Starting training on experience 134 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0863
	data_grads_norm = 2.8195
	new_data_grads_norm = 4.2850
	old_data_grads_norm = 3.4760
	sim_grads_norm = 0.0219
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5899
	data_grads_norm = 3.6463
	new_data_grads_norm = 4.7560
	old_data_grads_norm = 5.5341
	sim_grads_norm = 0.1179
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1069
	data_grads_norm = 3.5346
	new_data_grads_norm = 4.4001
	old_data_grads_norm = 4.9745
	sim_grads_norm = 0.0287
-- Starting training on experience 135 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6464
	data_grads_norm = 2.8202
	new_data_grads_norm = 4.3198
	old_data_grads_norm = 3.9501
	sim_grads_norm = 0.0093
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0082
	data_grads_norm = 3.6432
	new_data_grads_norm = 4.7159
	old_data_grads_norm = 5.2780
	sim_grads_norm = 0.0554
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9346
	data_grads_norm = 3.1132
	new_data_grads_norm = 4.3505
	old_data_grads_norm = 4.0576
	sim_grads_norm = 0.0724
-- Starting training on experience 136 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3401
	data_grads_norm = 3.7560
	new_data_grads_norm = 5.8360
	old_data_grads_norm = 4.2169
	sim_grads_norm = 0.1334
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4210
	data_grads_norm = 3.1924
	new_data_grads_norm = 4.9091
	old_data_grads_norm = 4.2050
	sim_grads_norm = -0.0532
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9801
	data_grads_norm = 3.8403
	new_data_grads_norm = 6.1439
	old_data_grads_norm = 4.5396
	sim_grads_norm = 0.0263
-- Starting training on experience 137 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2531
	data_grads_norm = 3.2109
	new_data_grads_norm = 3.9651
	old_data_grads_norm = 4.7330
	sim_grads_norm = 0.0215
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0799
	data_grads_norm = 2.7041
	new_data_grads_norm = 4.2769
	old_data_grads_norm = 3.5569
	sim_grads_norm = 0.0043
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0761
	data_grads_norm = 2.8539
	new_data_grads_norm = 3.8982
	old_data_grads_norm = 4.5449
	sim_grads_norm = -0.0485
-- Starting training on experience 138 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6492
	data_grads_norm = 3.9164
	new_data_grads_norm = 4.3428
	old_data_grads_norm = 6.1948
	sim_grads_norm = 0.0403
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1237
	data_grads_norm = 2.9323
	new_data_grads_norm = 4.3276
	old_data_grads_norm = 3.7363
	sim_grads_norm = -0.0184
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2410
	data_grads_norm = 3.5388
	new_data_grads_norm = 4.3282
	old_data_grads_norm = 5.1979
	sim_grads_norm = 0.0276
-- Starting training on experience 139 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2354
	data_grads_norm = 3.5389
	new_data_grads_norm = 4.9521
	old_data_grads_norm = 4.8011
	sim_grads_norm = -0.0026
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2616
	data_grads_norm = 3.4326
	new_data_grads_norm = 4.6102
	old_data_grads_norm = 4.0070
	sim_grads_norm = 0.1088
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4177
	data_grads_norm = 4.0349
	new_data_grads_norm = 4.5503
	old_data_grads_norm = 5.8339
	sim_grads_norm = 0.1883
-- Starting training on experience 140 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3034
	data_grads_norm = 3.0250
	new_data_grads_norm = 4.1367
	old_data_grads_norm = 4.4997
	sim_grads_norm = 0.0597
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3108
	data_grads_norm = 3.1219
	new_data_grads_norm = 4.1742
	old_data_grads_norm = 4.7849
	sim_grads_norm = -0.0270
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9138
	data_grads_norm = 2.8064
	new_data_grads_norm = 4.2709
	old_data_grads_norm = 3.8279
	sim_grads_norm = -0.1233
-- Starting training on experience 141 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6278
	data_grads_norm = 2.9600
	new_data_grads_norm = 4.1533
	old_data_grads_norm = 3.8780
	sim_grads_norm = -0.0028
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7035
	data_grads_norm = 2.9550
	new_data_grads_norm = 4.4488
	old_data_grads_norm = 3.6697
	sim_grads_norm = 0.0070
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7888
	data_grads_norm = 3.2176
	new_data_grads_norm = 4.5365
	old_data_grads_norm = 3.7619
	sim_grads_norm = 0.0602
-- Starting training on experience 142 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0941
	data_grads_norm = 2.9253
	new_data_grads_norm = 4.3104
	old_data_grads_norm = 4.6913
	sim_grads_norm = 0.0748
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1402
	data_grads_norm = 3.0167
	new_data_grads_norm = 3.7776
	old_data_grads_norm = 3.9913
	sim_grads_norm = 0.1405
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2785
	data_grads_norm = 3.4523
	new_data_grads_norm = 3.8989
	old_data_grads_norm = 5.2111
	sim_grads_norm = -0.0193
-- Starting training on experience 143 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1595
	data_grads_norm = 3.0301
	new_data_grads_norm = 4.2999
	old_data_grads_norm = 3.6125
	sim_grads_norm = 0.0555
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9779
	data_grads_norm = 2.8440
	new_data_grads_norm = 4.0071
	old_data_grads_norm = 3.5746
	sim_grads_norm = -0.0259
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1249
	data_grads_norm = 3.0230
	new_data_grads_norm = 4.3243
	old_data_grads_norm = 3.4841
	sim_grads_norm = 0.0142
-- Starting training on experience 144 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1725
	data_grads_norm = 3.4538
	new_data_grads_norm = 4.6684
	old_data_grads_norm = 4.3895
	sim_grads_norm = 0.0472
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8974
	data_grads_norm = 3.7380
	new_data_grads_norm = 4.7252
	old_data_grads_norm = 5.1660
	sim_grads_norm = 0.1087
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5796
	data_grads_norm = 2.6546
	new_data_grads_norm = 4.2038
	old_data_grads_norm = 3.0222
	sim_grads_norm = -0.0026
-- Starting training on experience 145 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4379
	data_grads_norm = 3.1599
	new_data_grads_norm = 4.7224
	old_data_grads_norm = 4.0264
	sim_grads_norm = -0.0965
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7229
	data_grads_norm = 3.6354
	new_data_grads_norm = 4.2986
	old_data_grads_norm = 5.6661
	sim_grads_norm = -0.0090
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4536
	data_grads_norm = 3.3021
	new_data_grads_norm = 5.1128
	old_data_grads_norm = 4.1932
	sim_grads_norm = -0.0335
-- Starting training on experience 146 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7837
	data_grads_norm = 3.0901
	new_data_grads_norm = 4.4521
	old_data_grads_norm = 3.6350
	sim_grads_norm = 0.0785
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1616
	data_grads_norm = 3.1731
	new_data_grads_norm = 4.6826
	old_data_grads_norm = 3.9815
	sim_grads_norm = -0.0380
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4561
	data_grads_norm = 3.6650
	new_data_grads_norm = 4.7578
	old_data_grads_norm = 4.9851
	sim_grads_norm = 0.1171
-- Starting training on experience 147 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1906
	data_grads_norm = 2.8522
	new_data_grads_norm = 3.6409
	old_data_grads_norm = 4.7007
	sim_grads_norm = -0.0091
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3830
	data_grads_norm = 3.0452
	new_data_grads_norm = 3.5872
	old_data_grads_norm = 4.1752
	sim_grads_norm = 0.0999
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1631
	data_grads_norm = 2.5613
	new_data_grads_norm = 3.2742
	old_data_grads_norm = 4.1343
	sim_grads_norm = -0.0550
-- Starting training on experience 148 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0558
	data_grads_norm = 3.4191
	new_data_grads_norm = 5.4773
	old_data_grads_norm = 3.3514
	sim_grads_norm = 0.1683
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0048
	data_grads_norm = 3.4164
	new_data_grads_norm = 5.2024
	old_data_grads_norm = 4.6027
	sim_grads_norm = -0.0445
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1541
	data_grads_norm = 3.1430
	new_data_grads_norm = 5.0464
	old_data_grads_norm = 3.8976
	sim_grads_norm = 0.0241
-- Starting training on experience 149 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4010
	data_grads_norm = 3.1705
	new_data_grads_norm = 4.7546
	old_data_grads_norm = 3.6147
	sim_grads_norm = 0.0505
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9026
	data_grads_norm = 3.2818
	new_data_grads_norm = 4.3967
	old_data_grads_norm = 4.3709
	sim_grads_norm = 0.0112
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6632
	data_grads_norm = 3.1656
	new_data_grads_norm = 4.1928
	old_data_grads_norm = 4.4445
	sim_grads_norm = 0.0483
-- Starting training on experience 150 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2400
	data_grads_norm = 3.7236
	new_data_grads_norm = 4.5087
	old_data_grads_norm = 5.1716
	sim_grads_norm = 0.0404
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1580
	data_grads_norm = 3.2941
	new_data_grads_norm = 4.6098
	old_data_grads_norm = 4.4523
	sim_grads_norm = 0.0140
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2225
	data_grads_norm = 3.4661
	new_data_grads_norm = 5.0607
	old_data_grads_norm = 3.9825
	sim_grads_norm = 0.0210
-- Starting training on experience 151 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9982
	data_grads_norm = 2.8621
	new_data_grads_norm = 4.1249
	old_data_grads_norm = 3.4337
	sim_grads_norm = 0.0111
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9622
	data_grads_norm = 2.7284
	new_data_grads_norm = 4.4115
	old_data_grads_norm = 3.6558
	sim_grads_norm = 0.0407
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2004
	data_grads_norm = 3.3225
	new_data_grads_norm = 4.3543
	old_data_grads_norm = 4.5846
	sim_grads_norm = 0.0816
-- Starting training on experience 152 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0782
	data_grads_norm = 2.7550
	new_data_grads_norm = 4.3124
	old_data_grads_norm = 3.9696
	sim_grads_norm = -0.0921
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8166
	data_grads_norm = 3.5734
	new_data_grads_norm = 4.9845
	old_data_grads_norm = 4.5483
	sim_grads_norm = -0.0426
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8078
	data_grads_norm = 3.6153
	new_data_grads_norm = 4.5593
	old_data_grads_norm = 4.8208
	sim_grads_norm = 0.0120
-- Starting training on experience 153 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7819
	data_grads_norm = 3.0261
	new_data_grads_norm = 4.6023
	old_data_grads_norm = 3.8597
	sim_grads_norm = 0.0022
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6937
	data_grads_norm = 3.3110
	new_data_grads_norm = 3.7680
	old_data_grads_norm = 4.9955
	sim_grads_norm = 0.0696
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2127
	data_grads_norm = 2.5349
	new_data_grads_norm = 3.9013
	old_data_grads_norm = 3.4121
	sim_grads_norm = -0.0326
-- Starting training on experience 154 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6298
	data_grads_norm = 3.8672
	new_data_grads_norm = 6.0073
	old_data_grads_norm = 4.9178
	sim_grads_norm = -0.0349
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0030
	data_grads_norm = 3.9379
	new_data_grads_norm = 6.3873
	old_data_grads_norm = 4.5700
	sim_grads_norm = -0.0440
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9099
	data_grads_norm = 3.9426
	new_data_grads_norm = 6.1298
	old_data_grads_norm = 4.5834
	sim_grads_norm = 0.0538
-- Starting training on experience 155 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2955
	data_grads_norm = 3.3454
	new_data_grads_norm = 4.7299
	old_data_grads_norm = 4.6861
	sim_grads_norm = -0.0168
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8193
	data_grads_norm = 2.6320
	new_data_grads_norm = 4.4810
	old_data_grads_norm = 3.5984
	sim_grads_norm = 0.0329
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1240
	data_grads_norm = 3.5045
	new_data_grads_norm = 4.6034
	old_data_grads_norm = 4.9042
	sim_grads_norm = -0.0546
-- Starting training on experience 156 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8239
	data_grads_norm = 3.0573
	new_data_grads_norm = 4.8800
	old_data_grads_norm = 3.5340
	sim_grads_norm = 0.0073
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2990
	data_grads_norm = 4.0774
	new_data_grads_norm = 4.8979
	old_data_grads_norm = 6.7035
	sim_grads_norm = 0.0005
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0795
	data_grads_norm = 3.6837
	new_data_grads_norm = 5.6404
	old_data_grads_norm = 4.3300
	sim_grads_norm = 0.1046
-- Starting training on experience 157 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2765
	data_grads_norm = 3.7019
	new_data_grads_norm = 5.3941
	old_data_grads_norm = 4.3719
	sim_grads_norm = 0.1002
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0109
	data_grads_norm = 3.2818
	new_data_grads_norm = 4.8508
	old_data_grads_norm = 3.9243
	sim_grads_norm = 0.0855
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1933
	data_grads_norm = 3.4379
	new_data_grads_norm = 4.9004
	old_data_grads_norm = 4.7636
	sim_grads_norm = 0.0584
-- Starting training on experience 158 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0699
	data_grads_norm = 2.5409
	new_data_grads_norm = 4.0348
	old_data_grads_norm = 3.4697
	sim_grads_norm = -0.0457
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0942
	data_grads_norm = 3.0962
	new_data_grads_norm = 4.3447
	old_data_grads_norm = 4.8618
	sim_grads_norm = -0.0020
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1153
	data_grads_norm = 3.1482
	new_data_grads_norm = 4.0010
	old_data_grads_norm = 4.7077
	sim_grads_norm = -0.0016
-- Starting training on experience 159 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2224
	data_grads_norm = 4.0304
	new_data_grads_norm = 6.1529
	old_data_grads_norm = 3.3231
	sim_grads_norm = 0.0747
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4272
	data_grads_norm = 4.7177
	new_data_grads_norm = 6.8721
	old_data_grads_norm = 5.8059
	sim_grads_norm = 0.0274
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2605
	data_grads_norm = 3.8961
	new_data_grads_norm = 5.7035
	old_data_grads_norm = 4.5267
	sim_grads_norm = 0.0406
-- Starting training on experience 160 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1231
	data_grads_norm = 3.2417
	new_data_grads_norm = 4.8769
	old_data_grads_norm = 4.0083
	sim_grads_norm = -0.0428
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3875
	data_grads_norm = 3.5791
	new_data_grads_norm = 4.9540
	old_data_grads_norm = 5.9314
	sim_grads_norm = 0.0776
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2906
	data_grads_norm = 3.5517
	new_data_grads_norm = 4.8813
	old_data_grads_norm = 5.3391
	sim_grads_norm = 0.0469
-- Starting training on experience 161 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1851
	data_grads_norm = 3.8201
	new_data_grads_norm = 4.6587
	old_data_grads_norm = 4.9463
	sim_grads_norm = 0.2081
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5462
	data_grads_norm = 2.8929
	new_data_grads_norm = 3.8633
	old_data_grads_norm = 4.8186
	sim_grads_norm = 0.0532
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3097
	data_grads_norm = 3.3834
	new_data_grads_norm = 4.5463
	old_data_grads_norm = 5.0583
	sim_grads_norm = 0.0072
-- Starting training on experience 162 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4719
	data_grads_norm = 2.9196
	new_data_grads_norm = 4.2362
	old_data_grads_norm = 4.1045
	sim_grads_norm = -0.0738
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9784
	data_grads_norm = 4.1766
	new_data_grads_norm = 4.7025
	old_data_grads_norm = 5.5878
	sim_grads_norm = -0.0737
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5569
	data_grads_norm = 3.9560
	new_data_grads_norm = 4.7992
	old_data_grads_norm = 5.8816
	sim_grads_norm = 0.1146
-- Starting training on experience 163 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2254
	data_grads_norm = 3.1603
	new_data_grads_norm = 4.8079
	old_data_grads_norm = 4.0060
	sim_grads_norm = -0.0310
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6604
	data_grads_norm = 3.5018
	new_data_grads_norm = 4.9047
	old_data_grads_norm = 4.2377
	sim_grads_norm = 0.0629
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5141
	data_grads_norm = 3.3817
	new_data_grads_norm = 4.7166
	old_data_grads_norm = 4.3704
	sim_grads_norm = 0.0810
-- Starting training on experience 164 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1989
	data_grads_norm = 3.1464
	new_data_grads_norm = 4.1497
	old_data_grads_norm = 4.4316
	sim_grads_norm = 0.0162
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4186
	data_grads_norm = 3.1640
	new_data_grads_norm = 3.8108
	old_data_grads_norm = 3.7898
	sim_grads_norm = 0.1177
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1729
	data_grads_norm = 2.9117
	new_data_grads_norm = 4.2621
	old_data_grads_norm = 4.2362
	sim_grads_norm = -0.0425
-- Starting training on experience 165 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7563
	data_grads_norm = 3.8166
	new_data_grads_norm = 4.9576
	old_data_grads_norm = 5.0369
	sim_grads_norm = 0.0005
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4618
	data_grads_norm = 3.6534
	new_data_grads_norm = 5.0404
	old_data_grads_norm = 4.4526
	sim_grads_norm = 0.0518
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3736
	data_grads_norm = 3.2582
	new_data_grads_norm = 5.0176
	old_data_grads_norm = 4.2364
	sim_grads_norm = -0.0419
-- Starting training on experience 166 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8624
	data_grads_norm = 3.3060
	new_data_grads_norm = 4.5111
	old_data_grads_norm = 3.7504
	sim_grads_norm = 0.0269
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0638
	data_grads_norm = 3.3648
	new_data_grads_norm = 4.3545
	old_data_grads_norm = 5.2544
	sim_grads_norm = -0.0099
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9564
	data_grads_norm = 3.0359
	new_data_grads_norm = 4.4511
	old_data_grads_norm = 4.3597
	sim_grads_norm = -0.0488
-- Starting training on experience 167 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1392
	data_grads_norm = 2.9717
	new_data_grads_norm = 4.4495
	old_data_grads_norm = 3.7549
	sim_grads_norm = -0.0592
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4502
	data_grads_norm = 3.9242
	new_data_grads_norm = 4.6741
	old_data_grads_norm = 5.8064
	sim_grads_norm = 0.0492
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5921
	data_grads_norm = 3.7377
	new_data_grads_norm = 4.8476
	old_data_grads_norm = 4.0746
	sim_grads_norm = 0.0061
-- Starting training on experience 168 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3776
	data_grads_norm = 3.2399
	new_data_grads_norm = 4.4482
	old_data_grads_norm = 4.8651
	sim_grads_norm = 0.0550
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3901
	data_grads_norm = 3.3460
	new_data_grads_norm = 4.3872
	old_data_grads_norm = 5.0720
	sim_grads_norm = 0.0052
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9067
	data_grads_norm = 3.1837
	new_data_grads_norm = 5.0229
	old_data_grads_norm = 3.6178
	sim_grads_norm = 0.0281
-- Starting training on experience 169 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2660
	data_grads_norm = 3.3882
	new_data_grads_norm = 4.8055
	old_data_grads_norm = 4.3778
	sim_grads_norm = -0.0194
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0278
	data_grads_norm = 3.7240
	new_data_grads_norm = 4.4325
	old_data_grads_norm = 5.0992
	sim_grads_norm = 0.0704
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3391
	data_grads_norm = 3.4520
	new_data_grads_norm = 3.6241
	old_data_grads_norm = 5.6525
	sim_grads_norm = -0.0355
-- Starting training on experience 170 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4501
	data_grads_norm = 3.0104
	new_data_grads_norm = 4.7494
	old_data_grads_norm = 3.6302
	sim_grads_norm = -0.0870
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5404
	data_grads_norm = 3.5307
	new_data_grads_norm = 4.8953
	old_data_grads_norm = 4.9121
	sim_grads_norm = -0.0359
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0957
	data_grads_norm = 3.3428
	new_data_grads_norm = 5.3034
	old_data_grads_norm = 4.7768
	sim_grads_norm = -0.0180
-- Starting training on experience 171 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9737
	data_grads_norm = 3.1161
	new_data_grads_norm = 5.1359
	old_data_grads_norm = 3.9901
	sim_grads_norm = 0.0034
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6296
	data_grads_norm = 3.9794
	new_data_grads_norm = 6.0150
	old_data_grads_norm = 4.7600
	sim_grads_norm = 0.0058
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3244
	data_grads_norm = 3.8133
	new_data_grads_norm = 5.4947
	old_data_grads_norm = 3.7387
	sim_grads_norm = 0.1751
-- Starting training on experience 172 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5367
	data_grads_norm = 3.0620
	new_data_grads_norm = 5.6833
	old_data_grads_norm = 3.1223
	sim_grads_norm = -0.0739
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2716
	data_grads_norm = 3.9686
	new_data_grads_norm = 6.0380
	old_data_grads_norm = 4.9257
	sim_grads_norm = 0.1001
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8225
	data_grads_norm = 3.3853
	new_data_grads_norm = 5.3774
	old_data_grads_norm = 3.9732
	sim_grads_norm = 0.0049
-- Starting training on experience 173 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4723
	data_grads_norm = 3.3155
	new_data_grads_norm = 4.9931
	old_data_grads_norm = 4.0962
	sim_grads_norm = 0.0546
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6942
	data_grads_norm = 3.6747
	new_data_grads_norm = 4.9388
	old_data_grads_norm = 4.4576
	sim_grads_norm = 0.0185
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1402
	data_grads_norm = 3.2904
	new_data_grads_norm = 4.9141
	old_data_grads_norm = 4.3328
	sim_grads_norm = 0.0202
-- Starting training on experience 174 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7521
	data_grads_norm = 3.7794
	new_data_grads_norm = 5.4198
	old_data_grads_norm = 4.6821
	sim_grads_norm = -0.0290
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6505
	data_grads_norm = 3.3297
	new_data_grads_norm = 5.2635
	old_data_grads_norm = 3.7561
	sim_grads_norm = 0.0450
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1851
	data_grads_norm = 3.2898
	new_data_grads_norm = 5.4972
	old_data_grads_norm = 3.4603
	sim_grads_norm = 0.0048
-- Starting training on experience 175 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8065
	data_grads_norm = 3.0433
	new_data_grads_norm = 5.2933
	old_data_grads_norm = 3.3319
	sim_grads_norm = -0.0236
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4822
	data_grads_norm = 3.3804
	new_data_grads_norm = 5.0762
	old_data_grads_norm = 4.8345
	sim_grads_norm = -0.0380
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7348
	data_grads_norm = 3.1023
	new_data_grads_norm = 4.5541
	old_data_grads_norm = 4.0647
	sim_grads_norm = 0.0878
-- Starting training on experience 176 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2518
	data_grads_norm = 3.1572
	new_data_grads_norm = 4.2637
	old_data_grads_norm = 4.3017
	sim_grads_norm = -0.0293
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7167
	data_grads_norm = 2.8725
	new_data_grads_norm = 4.1031
	old_data_grads_norm = 3.8594
	sim_grads_norm = -0.0654
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8104
	data_grads_norm = 3.4705
	new_data_grads_norm = 4.6664
	old_data_grads_norm = 5.5009
	sim_grads_norm = 0.0233
-- Starting training on experience 177 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1248
	data_grads_norm = 2.8154
	new_data_grads_norm = 4.3965
	old_data_grads_norm = 3.1313
	sim_grads_norm = 0.0488
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1710
	data_grads_norm = 3.3818
	new_data_grads_norm = 3.8851
	old_data_grads_norm = 5.1723
	sim_grads_norm = 0.0410
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5598
	data_grads_norm = 2.6424
	new_data_grads_norm = 4.0794
	old_data_grads_norm = 3.6186
	sim_grads_norm = -0.0649
-- Starting training on experience 178 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7153
	data_grads_norm = 4.3778
	new_data_grads_norm = 6.3970
	old_data_grads_norm = 5.1686
	sim_grads_norm = 0.0752
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4996
	data_grads_norm = 3.7175
	new_data_grads_norm = 5.4853
	old_data_grads_norm = 5.0763
	sim_grads_norm = -0.0777
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9367
	data_grads_norm = 3.2528
	new_data_grads_norm = 6.4335
	old_data_grads_norm = 3.7407
	sim_grads_norm = 0.0462
-- Starting training on experience 179 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9124
	data_grads_norm = 3.3553
	new_data_grads_norm = 4.7852
	old_data_grads_norm = 3.8086
	sim_grads_norm = -0.0318
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9512
	data_grads_norm = 3.2800
	new_data_grads_norm = 5.0168
	old_data_grads_norm = 3.6078
	sim_grads_norm = 0.1020
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2384
	data_grads_norm = 3.4007
	new_data_grads_norm = 5.0247
	old_data_grads_norm = 4.2531
	sim_grads_norm = -0.0147
-- Starting training on experience 180 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8383
	data_grads_norm = 4.5405
	new_data_grads_norm = 4.5550
	old_data_grads_norm = 6.8920
	sim_grads_norm = 0.0870
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9502
	data_grads_norm = 3.0894
	new_data_grads_norm = 4.7835
	old_data_grads_norm = 4.9240
	sim_grads_norm = 0.1515
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9080
	data_grads_norm = 2.9308
	new_data_grads_norm = 4.3176
	old_data_grads_norm = 3.8806
	sim_grads_norm = -0.0092
-- Starting training on experience 181 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4953
	data_grads_norm = 3.1144
	new_data_grads_norm = 4.9596
	old_data_grads_norm = 4.5436
	sim_grads_norm = -0.0368
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5992
	data_grads_norm = 3.3876
	new_data_grads_norm = 4.6179
	old_data_grads_norm = 4.4541
	sim_grads_norm = 0.0861
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4855
	data_grads_norm = 3.0599
	new_data_grads_norm = 4.6424
	old_data_grads_norm = 3.4593
	sim_grads_norm = 0.0634
-- Starting training on experience 182 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2483
	data_grads_norm = 3.1280
	new_data_grads_norm = 4.8067
	old_data_grads_norm = 3.3069
	sim_grads_norm = 0.0927
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9874
	data_grads_norm = 3.5667
	new_data_grads_norm = 4.7895
	old_data_grads_norm = 5.0845
	sim_grads_norm = 0.0236
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6942
	data_grads_norm = 4.0467
	new_data_grads_norm = 5.3495
	old_data_grads_norm = 5.2320
	sim_grads_norm = 0.1032
-- Starting training on experience 183 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1614
	data_grads_norm = 2.9545
	new_data_grads_norm = 4.2848
	old_data_grads_norm = 4.2055
	sim_grads_norm = -0.0295
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5087
	data_grads_norm = 3.5640
	new_data_grads_norm = 5.2451
	old_data_grads_norm = 4.0092
	sim_grads_norm = 0.0462
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6133
	data_grads_norm = 3.7195
	new_data_grads_norm = 5.6559
	old_data_grads_norm = 4.5283
	sim_grads_norm = 0.0597
-- Starting training on experience 184 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4531
	data_grads_norm = 3.1720
	new_data_grads_norm = 4.7580
	old_data_grads_norm = 4.3732
	sim_grads_norm = 0.0461
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7297
	data_grads_norm = 3.8304
	new_data_grads_norm = 4.8496
	old_data_grads_norm = 4.9930
	sim_grads_norm = 0.1797
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7828
	data_grads_norm = 3.3880
	new_data_grads_norm = 4.1344
	old_data_grads_norm = 5.2679
	sim_grads_norm = 0.0801
-- Starting training on experience 185 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9914
	data_grads_norm = 2.7315
	new_data_grads_norm = 3.8716
	old_data_grads_norm = 4.3253
	sim_grads_norm = -0.0149
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9915
	data_grads_norm = 2.5862
	new_data_grads_norm = 3.6222
	old_data_grads_norm = 4.0616
	sim_grads_norm = -0.1024
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6458
	data_grads_norm = 2.5405
	new_data_grads_norm = 3.6850
	old_data_grads_norm = 3.2485
	sim_grads_norm = -0.0259
-- Starting training on experience 186 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8925
	data_grads_norm = 2.8961
	new_data_grads_norm = 3.4846
	old_data_grads_norm = 4.5806
	sim_grads_norm = -0.0347
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2236
	data_grads_norm = 3.5515
	new_data_grads_norm = 3.8483
	old_data_grads_norm = 4.9815
	sim_grads_norm = 0.1383
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6086
	data_grads_norm = 2.7813
	new_data_grads_norm = 3.8039
	old_data_grads_norm = 4.1215
	sim_grads_norm = 0.0101
-- Starting training on experience 187 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5103
	data_grads_norm = 3.3902
	new_data_grads_norm = 4.9507
	old_data_grads_norm = 4.4096
	sim_grads_norm = 0.0823
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3286
	data_grads_norm = 3.1081
	new_data_grads_norm = 4.6449
	old_data_grads_norm = 3.6990
	sim_grads_norm = 0.0366
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4967
	data_grads_norm = 3.3651
	new_data_grads_norm = 5.1616
	old_data_grads_norm = 3.9244
	sim_grads_norm = 0.0242
-- Starting training on experience 188 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0136
	data_grads_norm = 3.2054
	new_data_grads_norm = 3.7184
	old_data_grads_norm = 5.9870
	sim_grads_norm = -0.0789
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0295
	data_grads_norm = 3.1842
	new_data_grads_norm = 5.2274
	old_data_grads_norm = 3.1399
	sim_grads_norm = 0.1273
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4203
	data_grads_norm = 3.3498
	new_data_grads_norm = 4.7671
	old_data_grads_norm = 4.2466
	sim_grads_norm = -0.0429
-- Starting training on experience 189 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2708
	data_grads_norm = 3.5026
	new_data_grads_norm = 5.0509
	old_data_grads_norm = 4.3328
	sim_grads_norm = 0.0035
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4712
	data_grads_norm = 3.7793
	new_data_grads_norm = 5.3169
	old_data_grads_norm = 4.9151
	sim_grads_norm = 0.0551
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5865
	data_grads_norm = 3.6268
	new_data_grads_norm = 5.2599
	old_data_grads_norm = 5.2647
	sim_grads_norm = 0.0303
-- Starting training on experience 190 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8191
	data_grads_norm = 3.7834
	new_data_grads_norm = 5.3655
	old_data_grads_norm = 4.6497
	sim_grads_norm = 0.0074
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4889
	data_grads_norm = 3.4519
	new_data_grads_norm = 4.8561
	old_data_grads_norm = 4.4057
	sim_grads_norm = 0.0197
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3730
	data_grads_norm = 3.3397
	new_data_grads_norm = 5.3553
	old_data_grads_norm = 3.1646
	sim_grads_norm = 0.0124
-- Starting training on experience 191 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4413
	data_grads_norm = 3.1014
	new_data_grads_norm = 4.1604
	old_data_grads_norm = 4.1393
	sim_grads_norm = 0.0388
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4310
	data_grads_norm = 3.4854
	new_data_grads_norm = 4.5558
	old_data_grads_norm = 4.6747
	sim_grads_norm = 0.0680
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3642
	data_grads_norm = 2.9981
	new_data_grads_norm = 4.0806
	old_data_grads_norm = 3.8131
	sim_grads_norm = 0.1004
-- Starting training on experience 192 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1129
	data_grads_norm = 3.4834
	new_data_grads_norm = 4.6071
	old_data_grads_norm = 5.4953
	sim_grads_norm = -0.0011
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8195
	data_grads_norm = 3.2176
	new_data_grads_norm = 4.7580
	old_data_grads_norm = 3.8227
	sim_grads_norm = 0.0640
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8742
	data_grads_norm = 3.1528
	new_data_grads_norm = 4.6469
	old_data_grads_norm = 4.4058
	sim_grads_norm = -0.0569
-- Starting training on experience 193 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4919
	data_grads_norm = 2.9960
	new_data_grads_norm = 4.6699
	old_data_grads_norm = 3.7859
	sim_grads_norm = -0.0344
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3545
	data_grads_norm = 3.4118
	new_data_grads_norm = 5.6066
	old_data_grads_norm = 3.3928
	sim_grads_norm = 0.0733
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5177
	data_grads_norm = 3.8222
	new_data_grads_norm = 5.1828
	old_data_grads_norm = 4.9099
	sim_grads_norm = 0.0536
-- Starting training on experience 194 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9375
	data_grads_norm = 3.2009
	new_data_grads_norm = 5.0531
	old_data_grads_norm = 3.4795
	sim_grads_norm = 0.0178
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2879
	data_grads_norm = 3.8026
	new_data_grads_norm = 5.3099
	old_data_grads_norm = 4.4419
	sim_grads_norm = 0.0138
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9293
	data_grads_norm = 3.0252
	new_data_grads_norm = 5.1589
	old_data_grads_norm = 3.4947
	sim_grads_norm = 0.0841
-- Starting training on experience 195 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3609
	data_grads_norm = 3.0170
	new_data_grads_norm = 4.5981
	old_data_grads_norm = 3.8499
	sim_grads_norm = -0.0524
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3917
	data_grads_norm = 2.9341
	new_data_grads_norm = 4.4715
	old_data_grads_norm = 3.6704
	sim_grads_norm = 0.0373
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8830
	data_grads_norm = 2.7361
	new_data_grads_norm = 4.9409
	old_data_grads_norm = 3.1143
	sim_grads_norm = -0.0001
-- Starting training on experience 196 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6799
	data_grads_norm = 3.2698
	new_data_grads_norm = 5.1032
	old_data_grads_norm = 4.2825
	sim_grads_norm = -0.0018
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8279
	data_grads_norm = 3.9402
	new_data_grads_norm = 5.3550
	old_data_grads_norm = 5.5781
	sim_grads_norm = 0.0859
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8147
	data_grads_norm = 3.3645
	new_data_grads_norm = 4.7097
	old_data_grads_norm = 4.5599
	sim_grads_norm = 0.0167
-- Starting training on experience 197 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3687
	data_grads_norm = 3.0693
	new_data_grads_norm = 4.2457
	old_data_grads_norm = 4.7826
	sim_grads_norm = 0.0399
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3907
	data_grads_norm = 3.3540
	new_data_grads_norm = 5.2034
	old_data_grads_norm = 4.8522
	sim_grads_norm = 0.0325
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0999
	data_grads_norm = 2.8036
	new_data_grads_norm = 4.5005
	old_data_grads_norm = 3.9649
	sim_grads_norm = 0.0314
-- Starting training on experience 198 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2258
	data_grads_norm = 3.4529
	new_data_grads_norm = 5.1010
	old_data_grads_norm = 4.4448
	sim_grads_norm = 0.0366
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2946
	data_grads_norm = 3.7830
	new_data_grads_norm = 5.6273
	old_data_grads_norm = 4.8150
	sim_grads_norm = 0.0574
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7152
	data_grads_norm = 3.7761
	new_data_grads_norm = 5.2234
	old_data_grads_norm = 4.4638
	sim_grads_norm = 0.0191
-- Starting training on experience 199 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2706
	data_grads_norm = 3.4893
	new_data_grads_norm = 4.7621
	old_data_grads_norm = 4.3225
	sim_grads_norm = 0.0564
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9255
	data_grads_norm = 3.2630
	new_data_grads_norm = 4.6748
	old_data_grads_norm = 4.2388
	sim_grads_norm = 0.0639
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8711
	data_grads_norm = 3.2027
	new_data_grads_norm = 4.4898
	old_data_grads_norm = 4.3921
	sim_grads_norm = 0.0468
-- Starting training on experience 200 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9915
	data_grads_norm = 3.2736
	new_data_grads_norm = 4.8434
	old_data_grads_norm = 4.5640
	sim_grads_norm = -0.0760
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2280
	data_grads_norm = 3.3578
	new_data_grads_norm = 4.9206
	old_data_grads_norm = 4.1060
	sim_grads_norm = 0.0999
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3442
	data_grads_norm = 4.0909
	new_data_grads_norm = 5.3628
	old_data_grads_norm = 5.2064
	sim_grads_norm = 0.0130
-- Starting training on experience 201 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4498
	data_grads_norm = 3.3357
	new_data_grads_norm = 3.8570
	old_data_grads_norm = 5.2864
	sim_grads_norm = -0.0126
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4478
	data_grads_norm = 3.5196
	new_data_grads_norm = 4.1817
	old_data_grads_norm = 5.7186
	sim_grads_norm = 0.0396
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8064
	data_grads_norm = 3.0313
	new_data_grads_norm = 4.1730
	old_data_grads_norm = 3.6318
	sim_grads_norm = 0.0414
-- Starting training on experience 202 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2976
	data_grads_norm = 2.6157
	new_data_grads_norm = 4.3949
	old_data_grads_norm = 4.1698
	sim_grads_norm = -0.0506
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5985
	data_grads_norm = 2.6408
	new_data_grads_norm = 4.3602
	old_data_grads_norm = 4.0241
	sim_grads_norm = -0.0008
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7077
	data_grads_norm = 3.1667
	new_data_grads_norm = 4.1265
	old_data_grads_norm = 4.5637
	sim_grads_norm = 0.0671
-- Starting training on experience 203 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1308
	data_grads_norm = 3.3969
	new_data_grads_norm = 4.3669
	old_data_grads_norm = 4.4615
	sim_grads_norm = 0.0573
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3015
	data_grads_norm = 3.3651
	new_data_grads_norm = 4.6352
	old_data_grads_norm = 4.0985
	sim_grads_norm = -0.0689
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1138
	data_grads_norm = 3.4435
	new_data_grads_norm = 4.8689
	old_data_grads_norm = 3.8474
	sim_grads_norm = 0.0754
-- Starting training on experience 204 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7642
	data_grads_norm = 3.0584
	new_data_grads_norm = 4.7011
	old_data_grads_norm = 3.7313
	sim_grads_norm = -0.0697
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0720
	data_grads_norm = 3.1390
	new_data_grads_norm = 4.7216
	old_data_grads_norm = 4.5930
	sim_grads_norm = -0.0201
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2573
	data_grads_norm = 3.6469
	new_data_grads_norm = 4.9380
	old_data_grads_norm = 4.2468
	sim_grads_norm = 0.0760
-- Starting training on experience 205 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2094
	data_grads_norm = 3.0453
	new_data_grads_norm = 4.0996
	old_data_grads_norm = 4.8124
	sim_grads_norm = -0.0310
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2845
	data_grads_norm = 3.6596
	new_data_grads_norm = 4.5841
	old_data_grads_norm = 4.4624
	sim_grads_norm = 0.0958
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6031
	data_grads_norm = 3.8149
	new_data_grads_norm = 5.1235
	old_data_grads_norm = 4.7688
	sim_grads_norm = 0.0698
-- Starting training on experience 206 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9573
	data_grads_norm = 3.3849
	new_data_grads_norm = 4.4296
	old_data_grads_norm = 4.9049
	sim_grads_norm = -0.0295
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8358
	data_grads_norm = 3.1122
	new_data_grads_norm = 4.7575
	old_data_grads_norm = 3.8210
	sim_grads_norm = -0.0290
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0990
	data_grads_norm = 3.6403
	new_data_grads_norm = 5.4392
	old_data_grads_norm = 3.8539
	sim_grads_norm = 0.1041
-- Starting training on experience 207 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4847
	data_grads_norm = 3.4228
	new_data_grads_norm = 5.7130
	old_data_grads_norm = 3.4381
	sim_grads_norm = -0.0234
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5001
	data_grads_norm = 3.3502
	new_data_grads_norm = 5.7022
	old_data_grads_norm = 3.9294
	sim_grads_norm = -0.0302
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8300
	data_grads_norm = 3.8324
	new_data_grads_norm = 5.8557
	old_data_grads_norm = 4.6302
	sim_grads_norm = 0.0182
-- Starting training on experience 208 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9777
	data_grads_norm = 2.8524
	new_data_grads_norm = 4.7688
	old_data_grads_norm = 3.5562
	sim_grads_norm = -0.0579
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3180
	data_grads_norm = 3.2050
	new_data_grads_norm = 4.9811
	old_data_grads_norm = 4.3196
	sim_grads_norm = -0.0177
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4257
	data_grads_norm = 3.5394
	new_data_grads_norm = 4.8001
	old_data_grads_norm = 5.5839
	sim_grads_norm = 0.0426
-- Starting training on experience 209 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5878
	data_grads_norm = 3.4703
	new_data_grads_norm = 5.2541
	old_data_grads_norm = 4.2897
	sim_grads_norm = 0.1299
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4307
	data_grads_norm = 3.2617
	new_data_grads_norm = 4.9306
	old_data_grads_norm = 3.9174
	sim_grads_norm = -0.0687
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5616
	data_grads_norm = 3.2621
	new_data_grads_norm = 4.7357
	old_data_grads_norm = 3.7513
	sim_grads_norm = 0.0693
-- Starting training on experience 210 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0805
	data_grads_norm = 3.5405
	new_data_grads_norm = 5.3416
	old_data_grads_norm = 5.0521
	sim_grads_norm = 0.0065
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1813
	data_grads_norm = 3.1150
	new_data_grads_norm = 5.0195
	old_data_grads_norm = 3.5381
	sim_grads_norm = -0.0052
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4426
	data_grads_norm = 3.6056
	new_data_grads_norm = 5.2296
	old_data_grads_norm = 4.0709
	sim_grads_norm = 0.0482
-- Starting training on experience 211 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3428
	data_grads_norm = 3.0273
	new_data_grads_norm = 4.1878
	old_data_grads_norm = 5.1571
	sim_grads_norm = 0.0200
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3361
	data_grads_norm = 2.8999
	new_data_grads_norm = 4.1089
	old_data_grads_norm = 3.6003
	sim_grads_norm = 0.0371
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3070
	data_grads_norm = 3.1914
	new_data_grads_norm = 4.2799
	old_data_grads_norm = 4.7975
	sim_grads_norm = -0.0234
-- Starting training on experience 212 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4318
	data_grads_norm = 3.0870
	new_data_grads_norm = 4.8737
	old_data_grads_norm = 3.5184
	sim_grads_norm = 0.0912
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4686
	data_grads_norm = 3.3653
	new_data_grads_norm = 4.2688
	old_data_grads_norm = 4.1781
	sim_grads_norm = 0.0399
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4077
	data_grads_norm = 3.4436
	new_data_grads_norm = 4.8818
	old_data_grads_norm = 4.8567
	sim_grads_norm = 0.0193
-- Starting training on experience 213 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8298
	data_grads_norm = 3.1535
	new_data_grads_norm = 4.9541
	old_data_grads_norm = 3.7573
	sim_grads_norm = -0.0058
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7318
	data_grads_norm = 3.9281
	new_data_grads_norm = 5.0988
	old_data_grads_norm = 5.3709
	sim_grads_norm = -0.0174
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5257
	data_grads_norm = 3.5350
	new_data_grads_norm = 5.2048
	old_data_grads_norm = 4.7136
	sim_grads_norm = -0.0610
-- Starting training on experience 214 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3049
	data_grads_norm = 3.9496
	new_data_grads_norm = 5.6912
	old_data_grads_norm = 5.1644
	sim_grads_norm = 0.0251
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1317
	data_grads_norm = 4.2493
	new_data_grads_norm = 5.6747
	old_data_grads_norm = 5.5388
	sim_grads_norm = 0.1259
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5816
	data_grads_norm = 3.0154
	new_data_grads_norm = 4.6935
	old_data_grads_norm = 3.6354
	sim_grads_norm = -0.0105
-- Starting training on experience 215 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0218
	data_grads_norm = 2.9574
	new_data_grads_norm = 4.3768
	old_data_grads_norm = 3.8592
	sim_grads_norm = 0.0047
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0011
	data_grads_norm = 3.5673
	new_data_grads_norm = 5.1400
	old_data_grads_norm = 4.1748
	sim_grads_norm = 0.0277
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8907
	data_grads_norm = 3.2139
	new_data_grads_norm = 4.8608
	old_data_grads_norm = 3.8902
	sim_grads_norm = -0.0553
-- Starting training on experience 216 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1186
	data_grads_norm = 3.9058
	new_data_grads_norm = 4.9513
	old_data_grads_norm = 5.7243
	sim_grads_norm = 0.0549
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0527
	data_grads_norm = 3.9511
	new_data_grads_norm = 4.9102
	old_data_grads_norm = 6.1520
	sim_grads_norm = 0.0673
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2052
	data_grads_norm = 3.7299
	new_data_grads_norm = 5.9660
	old_data_grads_norm = 4.5095
	sim_grads_norm = -0.0539
-- Starting training on experience 217 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9745
	data_grads_norm = 3.4757
	new_data_grads_norm = 4.7595
	old_data_grads_norm = 4.9640
	sim_grads_norm = -0.0372
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9786
	data_grads_norm = 3.0550
	new_data_grads_norm = 4.4842
	old_data_grads_norm = 3.5614
	sim_grads_norm = 0.0440
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7941
	data_grads_norm = 2.4464
	new_data_grads_norm = 4.1169
	old_data_grads_norm = 2.7084
	sim_grads_norm = 0.0398
-- Starting training on experience 218 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0820
	data_grads_norm = 2.8472
	new_data_grads_norm = 4.2151
	old_data_grads_norm = 3.4260
	sim_grads_norm = 0.1072
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1715
	data_grads_norm = 3.3323
	new_data_grads_norm = 4.5552
	old_data_grads_norm = 4.7342
	sim_grads_norm = -0.0313
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1543
	data_grads_norm = 3.2488
	new_data_grads_norm = 4.4984
	old_data_grads_norm = 4.1919
	sim_grads_norm = 0.0960
-- Starting training on experience 219 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2088
	data_grads_norm = 3.6538
	new_data_grads_norm = 4.2855
	old_data_grads_norm = 5.3528
	sim_grads_norm = -0.0323
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2385
	data_grads_norm = 3.2882
	new_data_grads_norm = 3.8973
	old_data_grads_norm = 5.2671
	sim_grads_norm = 0.0293
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3802
	data_grads_norm = 2.9526
	new_data_grads_norm = 4.4171
	old_data_grads_norm = 3.8913
	sim_grads_norm = -0.0436
-- Starting training on experience 220 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8396
	data_grads_norm = 3.1527
	new_data_grads_norm = 4.7699
	old_data_grads_norm = 4.0076
	sim_grads_norm = 0.0106
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6381
	data_grads_norm = 3.0444
	new_data_grads_norm = 5.0473
	old_data_grads_norm = 3.7743
	sim_grads_norm = -0.0002
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0051
	data_grads_norm = 3.6491
	new_data_grads_norm = 4.9851
	old_data_grads_norm = 4.5715
	sim_grads_norm = 0.0242
-- Starting training on experience 221 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9168
	data_grads_norm = 2.8640
	new_data_grads_norm = 4.2314
	old_data_grads_norm = 3.6062
	sim_grads_norm = -0.0458
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3294
	data_grads_norm = 3.3888
	new_data_grads_norm = 4.5085
	old_data_grads_norm = 5.0699
	sim_grads_norm = -0.0145
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0357
	data_grads_norm = 3.0262
	new_data_grads_norm = 4.4007
	old_data_grads_norm = 4.0543
	sim_grads_norm = -0.0818
-- Starting training on experience 222 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8290
	data_grads_norm = 3.0567
	new_data_grads_norm = 5.1209
	old_data_grads_norm = 3.2926
	sim_grads_norm = -0.0220
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0869
	data_grads_norm = 3.6629
	new_data_grads_norm = 5.4874
	old_data_grads_norm = 5.4079
	sim_grads_norm = -0.0068
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2238
	data_grads_norm = 3.5315
	new_data_grads_norm = 5.5626
	old_data_grads_norm = 4.0789
	sim_grads_norm = 0.0729
-- Starting training on experience 223 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1738
	data_grads_norm = 3.0769
	new_data_grads_norm = 4.4329
	old_data_grads_norm = 4.0631
	sim_grads_norm = 0.0229
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6503
	data_grads_norm = 3.2386
	new_data_grads_norm = 4.3951
	old_data_grads_norm = 4.9172
	sim_grads_norm = -0.0723
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2438
	data_grads_norm = 3.3179
	new_data_grads_norm = 4.6185
	old_data_grads_norm = 3.2700
	sim_grads_norm = 0.0837
-- Starting training on experience 224 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8994
	data_grads_norm = 3.0773
	new_data_grads_norm = 5.0190
	old_data_grads_norm = 3.6829
	sim_grads_norm = 0.0425
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5753
	data_grads_norm = 3.6131
	new_data_grads_norm = 5.4415
	old_data_grads_norm = 4.5913
	sim_grads_norm = 0.0516
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9567
	data_grads_norm = 2.6513
	new_data_grads_norm = 4.7200
	old_data_grads_norm = 2.9833
	sim_grads_norm = -0.0048
-- Starting training on experience 225 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2172
	data_grads_norm = 3.3405
	new_data_grads_norm = 5.0856
	old_data_grads_norm = 4.1774
	sim_grads_norm = -0.0431
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1468
	data_grads_norm = 3.4780
	new_data_grads_norm = 5.0799
	old_data_grads_norm = 4.9991
	sim_grads_norm = 0.0144
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7815
	data_grads_norm = 3.6549
	new_data_grads_norm = 5.1329
	old_data_grads_norm = 4.6339
	sim_grads_norm = 0.0846
-- Starting training on experience 226 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9150
	data_grads_norm = 3.0434
	new_data_grads_norm = 4.5880
	old_data_grads_norm = 4.0024
	sim_grads_norm = 0.0698
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6430
	data_grads_norm = 3.0139
	new_data_grads_norm = 4.4018
	old_data_grads_norm = 3.9336
	sim_grads_norm = 0.0304
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2087
	data_grads_norm = 3.4052
	new_data_grads_norm = 4.8222
	old_data_grads_norm = 4.4768
	sim_grads_norm = 0.0468
-- Starting training on experience 227 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5746
	data_grads_norm = 2.9405
	new_data_grads_norm = 5.0332
	old_data_grads_norm = 3.3719
	sim_grads_norm = 0.0196
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1674
	data_grads_norm = 3.5542
	new_data_grads_norm = 5.2303
	old_data_grads_norm = 4.3655
	sim_grads_norm = 0.0125
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3195
	data_grads_norm = 3.5806
	new_data_grads_norm = 5.2848
	old_data_grads_norm = 4.5130
	sim_grads_norm = 0.0190
-- Starting training on experience 228 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0106
	data_grads_norm = 3.7909
	new_data_grads_norm = 4.8757
	old_data_grads_norm = 4.7976
	sim_grads_norm = 0.0760
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9213
	data_grads_norm = 3.3080
	new_data_grads_norm = 4.3391
	old_data_grads_norm = 4.5978
	sim_grads_norm = -0.0715
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6127
	data_grads_norm = 2.8411
	new_data_grads_norm = 3.9987
	old_data_grads_norm = 3.7229
	sim_grads_norm = 0.0462
-- Starting training on experience 229 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1284
	data_grads_norm = 3.5252
	new_data_grads_norm = 5.4473
	old_data_grads_norm = 4.7667
	sim_grads_norm = -0.0493
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1351
	data_grads_norm = 3.6062
	new_data_grads_norm = 5.2113
	old_data_grads_norm = 4.9517
	sim_grads_norm = 0.0939
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3442
	data_grads_norm = 3.3121
	new_data_grads_norm = 5.2470
	old_data_grads_norm = 4.4716
	sim_grads_norm = 0.0110
-- Starting training on experience 230 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5583
	data_grads_norm = 3.9054
	new_data_grads_norm = 4.9903
	old_data_grads_norm = 5.4190
	sim_grads_norm = -0.0245
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0417
	data_grads_norm = 3.0593
	new_data_grads_norm = 4.8644
	old_data_grads_norm = 4.2180
	sim_grads_norm = -0.0589
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0610
	data_grads_norm = 3.4430
	new_data_grads_norm = 4.9673
	old_data_grads_norm = 4.1910
	sim_grads_norm = 0.0877
-- Starting training on experience 231 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1000
	data_grads_norm = 3.2753
	new_data_grads_norm = 4.7677
	old_data_grads_norm = 4.2021
	sim_grads_norm = 0.0634
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0706
	data_grads_norm = 3.2248
	new_data_grads_norm = 5.3441
	old_data_grads_norm = 3.0476
	sim_grads_norm = 0.0078
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4084
	data_grads_norm = 3.4312
	new_data_grads_norm = 5.3657
	old_data_grads_norm = 5.2112
	sim_grads_norm = 0.0174
-- Starting training on experience 232 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7464
	data_grads_norm = 3.2930
	new_data_grads_norm = 4.6496
	old_data_grads_norm = 4.6980
	sim_grads_norm = -0.0481
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0412
	data_grads_norm = 3.6357
	new_data_grads_norm = 4.7745
	old_data_grads_norm = 4.5427
	sim_grads_norm = 0.0944
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0450
	data_grads_norm = 3.6175
	new_data_grads_norm = 5.1107
	old_data_grads_norm = 5.0672
	sim_grads_norm = 0.0320
-- Starting training on experience 233 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4193
	data_grads_norm = 3.9219
	new_data_grads_norm = 6.1303
	old_data_grads_norm = 4.4302
	sim_grads_norm = 0.0819
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4768
	data_grads_norm = 3.7403
	new_data_grads_norm = 5.9045
	old_data_grads_norm = 5.1529
	sim_grads_norm = -0.0908
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4104
	data_grads_norm = 4.1123
	new_data_grads_norm = 6.7465
	old_data_grads_norm = 4.7621
	sim_grads_norm = -0.0458
-- Starting training on experience 234 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5792
	data_grads_norm = 2.8217
	new_data_grads_norm = 5.1242
	old_data_grads_norm = 3.5799
	sim_grads_norm = 0.0102
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0530
	data_grads_norm = 3.9045
	new_data_grads_norm = 5.5713
	old_data_grads_norm = 5.0840
	sim_grads_norm = 0.0346
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1683
	data_grads_norm = 3.4668
	new_data_grads_norm = 5.3456
	old_data_grads_norm = 5.1034
	sim_grads_norm = -0.0143
-- Starting training on experience 235 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7841
	data_grads_norm = 3.3008
	new_data_grads_norm = 5.6980
	old_data_grads_norm = 3.4403
	sim_grads_norm = -0.0079
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7814
	data_grads_norm = 3.6133
	new_data_grads_norm = 5.7882
	old_data_grads_norm = 3.7894
	sim_grads_norm = 0.0191
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2721
	data_grads_norm = 4.0124
	new_data_grads_norm = 5.2436
	old_data_grads_norm = 4.7598
	sim_grads_norm = 0.1363
-- Starting training on experience 236 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1176
	data_grads_norm = 3.2682
	new_data_grads_norm = 4.7895
	old_data_grads_norm = 3.7569
	sim_grads_norm = 0.0503
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7828
	data_grads_norm = 3.4367
	new_data_grads_norm = 4.6634
	old_data_grads_norm = 4.5417
	sim_grads_norm = 0.0414
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0997
	data_grads_norm = 4.1053
	new_data_grads_norm = 4.9193
	old_data_grads_norm = 4.9953
	sim_grads_norm = 0.0538
-- Starting training on experience 237 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
-- >> End of training phase << --
-- >> Start of eval phase << --
-- Starting eval on experience 0 (Task 0) from test stream --
> Eval on experience 0 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp000 = 2.6490
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.3160
	mb_index = 1666
	time = 308.1249
-- Starting eval on experience 1 (Task 0) from test stream --
> Eval on experience 1 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp001 = 1.7400
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.5400
-- Starting eval on experience 2 (Task 0) from test stream --
> Eval on experience 2 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp002 = 2.3544
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.3720
-- Starting eval on experience 3 (Task 0) from test stream --
> Eval on experience 3 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp003 = 1.8925
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.5080
-- Starting eval on experience 4 (Task 0) from test stream --
> Eval on experience 4 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp004 = 2.4578
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.3460
-- Starting eval on experience 5 (Task 0) from test stream --
> Eval on experience 5 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp005 = 2.8591
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.1760
-- Starting eval on experience 6 (Task 0) from test stream --
> Eval on experience 6 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp006 = 2.1948
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp006 = 0.3940
-- >> End of eval phase << --
	CumulativeAccuracy/eval_phase/test_stream/Exp000 = 0.7100
	CumulativeAccuracy/eval_phase/test_stream/Exp001 = 0.6450
	CumulativeAccuracy/eval_phase/test_stream/Exp002 = 0.5513
	CumulativeAccuracy/eval_phase/test_stream/Exp003 = 0.5165
	CumulativeAccuracy/eval_phase/test_stream/Exp004 = 0.4596
	CumulativeAccuracy/eval_phase/test_stream/Exp005 = 0.4097
	CumulativeAccuracy/eval_phase/test_stream/Exp006 = 0.3789
	Loss_Stream/eval_phase/test_stream/Task000 = 2.3068
	Top1_Acc_Stream/eval_phase/test_stream/Task000 = 0.3789
-- >> Start of training phase << --
-- Starting training on experience 0 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8966
	data_grads_norm = 4.5779
	new_data_grads_norm = 5.8758
	old_data_grads_norm = 5.9095
	sim_grads_norm = 0.0311
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2304
	data_grads_norm = 3.8630
	new_data_grads_norm = 5.4681
	old_data_grads_norm = 5.3191
	sim_grads_norm = 0.0005
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6985
	data_grads_norm = 3.5380
	new_data_grads_norm = 5.7168
	old_data_grads_norm = 4.3359
	sim_grads_norm = -0.0584
-- Starting training on experience 1 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9094
	data_grads_norm = 4.1286
	new_data_grads_norm = 6.0623
	old_data_grads_norm = 4.6809
	sim_grads_norm = 0.0007
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7973
	data_grads_norm = 4.0862
	new_data_grads_norm = 5.5761
	old_data_grads_norm = 4.6034
	sim_grads_norm = 0.0430
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2471
	data_grads_norm = 4.0204
	new_data_grads_norm = 5.6209
	old_data_grads_norm = 5.8913
	sim_grads_norm = 0.0428
-- Starting training on experience 2 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7712
	data_grads_norm = 3.2985
	new_data_grads_norm = 4.8314
	old_data_grads_norm = 3.8682
	sim_grads_norm = 0.1148
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5945
	data_grads_norm = 3.4250
	new_data_grads_norm = 5.0760
	old_data_grads_norm = 4.0981
	sim_grads_norm = -0.0013
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1111
	data_grads_norm = 4.1210
	new_data_grads_norm = 5.9465
	old_data_grads_norm = 6.1392
	sim_grads_norm = -0.0182
-- Starting training on experience 3 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1087
	data_grads_norm = 3.7815
	new_data_grads_norm = 5.2492
	old_data_grads_norm = 4.7296
	sim_grads_norm = 0.0198
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6558
	data_grads_norm = 3.2231
	new_data_grads_norm = 5.1829
	old_data_grads_norm = 3.2125
	sim_grads_norm = -0.0089
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9459
	data_grads_norm = 3.4580
	new_data_grads_norm = 5.4285
	old_data_grads_norm = 4.5038
	sim_grads_norm = -0.0082
-- Starting training on experience 4 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0583
	data_grads_norm = 3.6466
	new_data_grads_norm = 5.5605
	old_data_grads_norm = 4.3321
	sim_grads_norm = 0.0207
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3082
	data_grads_norm = 3.9373
	new_data_grads_norm = 5.1683
	old_data_grads_norm = 5.2250
	sim_grads_norm = 0.0339
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8144
	data_grads_norm = 3.7569
	new_data_grads_norm = 4.9623
	old_data_grads_norm = 4.2817
	sim_grads_norm = 0.0299
-- Starting training on experience 5 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0953
	data_grads_norm = 2.9614
	new_data_grads_norm = 5.2769
	old_data_grads_norm = 2.9309
	sim_grads_norm = 0.0205
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8935
	data_grads_norm = 3.4867
	new_data_grads_norm = 4.7156
	old_data_grads_norm = 4.6629
	sim_grads_norm = 0.0046
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7820
	data_grads_norm = 3.7304
	new_data_grads_norm = 5.0818
	old_data_grads_norm = 4.7761
	sim_grads_norm = 0.0084
-- Starting training on experience 6 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3520
	data_grads_norm = 2.8965
	new_data_grads_norm = 4.3899
	old_data_grads_norm = 3.7579
	sim_grads_norm = -0.0518
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5006
	data_grads_norm = 3.5147
	new_data_grads_norm = 4.8752
	old_data_grads_norm = 3.4790
	sim_grads_norm = 0.0567
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4073
	data_grads_norm = 3.3164
	new_data_grads_norm = 4.7041
	old_data_grads_norm = 4.7991
	sim_grads_norm = -0.0274
-- Starting training on experience 7 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7755
	data_grads_norm = 3.8122
	new_data_grads_norm = 5.8239
	old_data_grads_norm = 4.0182
	sim_grads_norm = 0.0299
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8913
	data_grads_norm = 3.6305
	new_data_grads_norm = 5.2618
	old_data_grads_norm = 3.9531
	sim_grads_norm = 0.0928
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7236
	data_grads_norm = 3.6970
	new_data_grads_norm = 5.0214
	old_data_grads_norm = 4.0309
	sim_grads_norm = -0.0244
-- Starting training on experience 8 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0339
	data_grads_norm = 3.9177
	new_data_grads_norm = 5.5726
	old_data_grads_norm = 4.3104
	sim_grads_norm = 0.1038
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9761
	data_grads_norm = 3.7579
	new_data_grads_norm = 4.7994
	old_data_grads_norm = 5.0272
	sim_grads_norm = 0.0570
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0287
	data_grads_norm = 3.6467
	new_data_grads_norm = 4.9730
	old_data_grads_norm = 4.6046
	sim_grads_norm = -0.0137
-- Starting training on experience 9 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0901
	data_grads_norm = 3.4246
	new_data_grads_norm = 5.5244
	old_data_grads_norm = 4.1099
	sim_grads_norm = 0.0076
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2200
	data_grads_norm = 3.9617
	new_data_grads_norm = 5.4504
	old_data_grads_norm = 4.8794
	sim_grads_norm = 0.0125
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6060
	data_grads_norm = 3.6904
	new_data_grads_norm = 5.5521
	old_data_grads_norm = 4.5717
	sim_grads_norm = 0.0142
-- Starting training on experience 10 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8071
	data_grads_norm = 4.3074
	new_data_grads_norm = 5.2418
	old_data_grads_norm = 5.5759
	sim_grads_norm = 0.0063
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5922
	data_grads_norm = 3.8100
	new_data_grads_norm = 5.6784
	old_data_grads_norm = 4.0913
	sim_grads_norm = 0.0720
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8306
	data_grads_norm = 3.6653
	new_data_grads_norm = 5.3865
	old_data_grads_norm = 4.4609
	sim_grads_norm = -0.0082
-- Starting training on experience 11 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3240
	data_grads_norm = 3.7126
	new_data_grads_norm = 5.2484
	old_data_grads_norm = 4.9145
	sim_grads_norm = -0.0101
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1730
	data_grads_norm = 3.9503
	new_data_grads_norm = 5.5507
	old_data_grads_norm = 5.3142
	sim_grads_norm = 0.1157
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4278
	data_grads_norm = 3.8013
	new_data_grads_norm = 4.8908
	old_data_grads_norm = 5.2857
	sim_grads_norm = 0.0899
-- Starting training on experience 12 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1237
	data_grads_norm = 3.8073
	new_data_grads_norm = 5.9481
	old_data_grads_norm = 3.9466
	sim_grads_norm = 0.0190
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9734
	data_grads_norm = 3.7748
	new_data_grads_norm = 6.2091
	old_data_grads_norm = 3.3747
	sim_grads_norm = 0.0522
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4619
	data_grads_norm = 3.9523
	new_data_grads_norm = 5.8504
	old_data_grads_norm = 4.6841
	sim_grads_norm = 0.0433
-- Starting training on experience 13 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8974
	data_grads_norm = 3.5352
	new_data_grads_norm = 4.8339
	old_data_grads_norm = 4.7379
	sim_grads_norm = 0.0924
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8232
	data_grads_norm = 3.4292
	new_data_grads_norm = 4.8933
	old_data_grads_norm = 4.2319
	sim_grads_norm = 0.1192
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3868
	data_grads_norm = 3.1203
	new_data_grads_norm = 4.3654
	old_data_grads_norm = 4.0481
	sim_grads_norm = 0.0209
-- Starting training on experience 14 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5466
	data_grads_norm = 4.3358
	new_data_grads_norm = 5.8863
	old_data_grads_norm = 4.2876
	sim_grads_norm = 0.0145
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1963
	data_grads_norm = 3.7162
	new_data_grads_norm = 5.4091
	old_data_grads_norm = 4.2402
	sim_grads_norm = 0.0107
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5377
	data_grads_norm = 3.6403
	new_data_grads_norm = 5.4156
	old_data_grads_norm = 3.4802
	sim_grads_norm = -0.0273
-- Starting training on experience 15 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4414
	data_grads_norm = 3.1560
	new_data_grads_norm = 4.5940
	old_data_grads_norm = 4.1214
	sim_grads_norm = -0.0246
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0778
	data_grads_norm = 3.7295
	new_data_grads_norm = 5.1743
	old_data_grads_norm = 4.9471
	sim_grads_norm = 0.0745
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2389
	data_grads_norm = 3.1855
	new_data_grads_norm = 4.9226
	old_data_grads_norm = 3.8660
	sim_grads_norm = 0.0111
-- Starting training on experience 16 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8604
	data_grads_norm = 3.8779
	new_data_grads_norm = 5.2523
	old_data_grads_norm = 5.2534
	sim_grads_norm = 0.0040
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8747
	data_grads_norm = 3.6546
	new_data_grads_norm = 5.6323
	old_data_grads_norm = 3.6118
	sim_grads_norm = 0.1365
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0619
	data_grads_norm = 2.8141
	new_data_grads_norm = 4.6073
	old_data_grads_norm = 3.5794
	sim_grads_norm = -0.0476
-- Starting training on experience 17 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8217
	data_grads_norm = 3.7658
	new_data_grads_norm = 5.1718
	old_data_grads_norm = 4.2914
	sim_grads_norm = 0.1258
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6412
	data_grads_norm = 3.6891
	new_data_grads_norm = 4.9435
	old_data_grads_norm = 4.6981
	sim_grads_norm = 0.0702
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6952
	data_grads_norm = 3.6528
	new_data_grads_norm = 5.2315
	old_data_grads_norm = 3.9560
	sim_grads_norm = 0.0084
-- Starting training on experience 18 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4030
	data_grads_norm = 3.6446
	new_data_grads_norm = 5.3512
	old_data_grads_norm = 4.8927
	sim_grads_norm = -0.0092
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6219
	data_grads_norm = 3.3759
	new_data_grads_norm = 5.4326
	old_data_grads_norm = 4.1710
	sim_grads_norm = -0.1047
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5480
	data_grads_norm = 3.3230
	new_data_grads_norm = 5.2048
	old_data_grads_norm = 3.7725
	sim_grads_norm = 0.0059
-- Starting training on experience 19 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3142
	data_grads_norm = 3.0473
	new_data_grads_norm = 4.0583
	old_data_grads_norm = 4.1991
	sim_grads_norm = -0.0176
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1506
	data_grads_norm = 3.0556
	new_data_grads_norm = 4.0019
	old_data_grads_norm = 4.3806
	sim_grads_norm = -0.0075
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3564
	data_grads_norm = 3.4308
	new_data_grads_norm = 4.6864
	old_data_grads_norm = 4.7666
	sim_grads_norm = 0.0010
-- Starting training on experience 20 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7516
	data_grads_norm = 3.6550
	new_data_grads_norm = 5.1988
	old_data_grads_norm = 4.5417
	sim_grads_norm = -0.0064
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0438
	data_grads_norm = 3.6217
	new_data_grads_norm = 5.1910
	old_data_grads_norm = 4.7887
	sim_grads_norm = 0.0134
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9393
	data_grads_norm = 3.5861
	new_data_grads_norm = 5.4941
	old_data_grads_norm = 3.9026
	sim_grads_norm = 0.0361
-- Starting training on experience 21 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4956
	data_grads_norm = 3.3520
	new_data_grads_norm = 4.5926
	old_data_grads_norm = 4.3673
	sim_grads_norm = -0.0517
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3170
	data_grads_norm = 3.7472
	new_data_grads_norm = 4.6965
	old_data_grads_norm = 5.4670
	sim_grads_norm = 0.0448
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3771
	data_grads_norm = 3.4589
	new_data_grads_norm = 4.9319
	old_data_grads_norm = 4.3115
	sim_grads_norm = 0.0209
-- Starting training on experience 22 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1425
	data_grads_norm = 3.2238
	new_data_grads_norm = 3.7560
	old_data_grads_norm = 4.8514
	sim_grads_norm = -0.0156
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8266
	data_grads_norm = 3.1736
	new_data_grads_norm = 4.0243
	old_data_grads_norm = 4.4786
	sim_grads_norm = -0.0067
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1472
	data_grads_norm = 3.3109
	new_data_grads_norm = 4.2662
	old_data_grads_norm = 5.0012
	sim_grads_norm = 0.0013
-- Starting training on experience 23 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0932
	data_grads_norm = 2.8850
	new_data_grads_norm = 4.5376
	old_data_grads_norm = 4.2699
	sim_grads_norm = -0.0527
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8981
	data_grads_norm = 2.9466
	new_data_grads_norm = 5.7784
	old_data_grads_norm = 2.4612
	sim_grads_norm = -0.0184
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1871
	data_grads_norm = 3.4886
	new_data_grads_norm = 5.5329
	old_data_grads_norm = 4.3121
	sim_grads_norm = 0.0045
-- Starting training on experience 24 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3608
	data_grads_norm = 4.4990
	new_data_grads_norm = 6.0824
	old_data_grads_norm = 5.9751
	sim_grads_norm = 0.0744
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0259
	data_grads_norm = 3.8708
	new_data_grads_norm = 5.1867
	old_data_grads_norm = 4.9359
	sim_grads_norm = 0.0782
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1391
	data_grads_norm = 3.2445
	new_data_grads_norm = 5.3582
	old_data_grads_norm = 3.2292
	sim_grads_norm = -0.0065
-- Starting training on experience 25 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1529
	data_grads_norm = 3.0392
	new_data_grads_norm = 4.6963
	old_data_grads_norm = 3.5221
	sim_grads_norm = 0.1837
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2746
	data_grads_norm = 3.4505
	new_data_grads_norm = 4.4671
	old_data_grads_norm = 5.3997
	sim_grads_norm = 0.1424
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8772
	data_grads_norm = 3.2851
	new_data_grads_norm = 3.9969
	old_data_grads_norm = 5.2687
	sim_grads_norm = -0.0427
-- Starting training on experience 26 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2277
	data_grads_norm = 3.4724
	new_data_grads_norm = 5.3838
	old_data_grads_norm = 2.8580
	sim_grads_norm = 0.1158
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1334
	data_grads_norm = 3.6942
	new_data_grads_norm = 5.3572
	old_data_grads_norm = 4.2459
	sim_grads_norm = 0.0155
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7254
	data_grads_norm = 3.2579
	new_data_grads_norm = 5.3260
	old_data_grads_norm = 4.2739
	sim_grads_norm = 0.0337
-- Starting training on experience 27 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6172
	data_grads_norm = 3.0792
	new_data_grads_norm = 4.6611
	old_data_grads_norm = 2.9938
	sim_grads_norm = 0.1043
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5535
	data_grads_norm = 3.1194
	new_data_grads_norm = 4.4780
	old_data_grads_norm = 3.5987
	sim_grads_norm = 0.1897
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5986
	data_grads_norm = 3.0949
	new_data_grads_norm = 4.2503
	old_data_grads_norm = 3.9322
	sim_grads_norm = 0.0340
-- Starting training on experience 28 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9854
	data_grads_norm = 3.6282
	new_data_grads_norm = 4.9460
	old_data_grads_norm = 4.7444
	sim_grads_norm = 0.0420
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5296
	data_grads_norm = 2.9870
	new_data_grads_norm = 4.8019
	old_data_grads_norm = 3.9854
	sim_grads_norm = -0.0245
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5405
	data_grads_norm = 2.9107
	new_data_grads_norm = 4.5423
	old_data_grads_norm = 3.5582
	sim_grads_norm = -0.0751
-- Starting training on experience 29 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6771
	data_grads_norm = 3.6373
	new_data_grads_norm = 5.5638
	old_data_grads_norm = 4.2178
	sim_grads_norm = -0.0605
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6973
	data_grads_norm = 3.5616
	new_data_grads_norm = 5.2158
	old_data_grads_norm = 3.7553
	sim_grads_norm = -0.0498
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8615
	data_grads_norm = 3.4834
	new_data_grads_norm = 5.3856
	old_data_grads_norm = 4.0375
	sim_grads_norm = -0.0265
-- Starting training on experience 30 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5245
	data_grads_norm = 3.3082
	new_data_grads_norm = 4.7613
	old_data_grads_norm = 3.7963
	sim_grads_norm = 0.0523
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7924
	data_grads_norm = 3.4335
	new_data_grads_norm = 4.3150
	old_data_grads_norm = 4.9329
	sim_grads_norm = -0.0414
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3303
	data_grads_norm = 3.9226
	new_data_grads_norm = 4.3219
	old_data_grads_norm = 4.8736
	sim_grads_norm = 0.0966
-- Starting training on experience 31 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9241
	data_grads_norm = 3.2481
	new_data_grads_norm = 4.3663
	old_data_grads_norm = 3.7307
	sim_grads_norm = 0.1457
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8949
	data_grads_norm = 3.6631
	new_data_grads_norm = 4.2951
	old_data_grads_norm = 5.0000
	sim_grads_norm = -0.0430
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9278
	data_grads_norm = 3.5168
	new_data_grads_norm = 4.4173
	old_data_grads_norm = 4.7393
	sim_grads_norm = 0.0025
-- Starting training on experience 32 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7788
	data_grads_norm = 3.3301
	new_data_grads_norm = 4.6219
	old_data_grads_norm = 4.4413
	sim_grads_norm = 0.0375
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4671
	data_grads_norm = 4.2779
	new_data_grads_norm = 4.7776
	old_data_grads_norm = 6.2543
	sim_grads_norm = -0.0060
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8963
	data_grads_norm = 3.2355
	new_data_grads_norm = 4.3174
	old_data_grads_norm = 4.5306
	sim_grads_norm = 0.0224
-- Starting training on experience 33 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3173
	data_grads_norm = 3.1947
	new_data_grads_norm = 3.8811
	old_data_grads_norm = 4.6380
	sim_grads_norm = 0.0979
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5400
	data_grads_norm = 2.9262
	new_data_grads_norm = 4.6103
	old_data_grads_norm = 4.1922
	sim_grads_norm = -0.0317
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8888
	data_grads_norm = 3.6113
	new_data_grads_norm = 3.8795
	old_data_grads_norm = 5.3602
	sim_grads_norm = 0.0686
-- Starting training on experience 34 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7839
	data_grads_norm = 3.1412
	new_data_grads_norm = 4.3210
	old_data_grads_norm = 4.2595
	sim_grads_norm = -0.0100
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3771
	data_grads_norm = 3.1266
	new_data_grads_norm = 4.8531
	old_data_grads_norm = 4.6016
	sim_grads_norm = -0.0769
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8065
	data_grads_norm = 3.5146
	new_data_grads_norm = 4.6530
	old_data_grads_norm = 4.5302
	sim_grads_norm = -0.0328
-- Starting training on experience 35 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7872
	data_grads_norm = 3.6018
	new_data_grads_norm = 4.8607
	old_data_grads_norm = 4.3214
	sim_grads_norm = 0.0727
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5084
	data_grads_norm = 3.2310
	new_data_grads_norm = 4.5270
	old_data_grads_norm = 4.1708
	sim_grads_norm = 0.0422
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9516
	data_grads_norm = 3.6683
	new_data_grads_norm = 4.3548
	old_data_grads_norm = 5.3424
	sim_grads_norm = 0.0016
-- Starting training on experience 36 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4737
	data_grads_norm = 3.1171
	new_data_grads_norm = 4.0313
	old_data_grads_norm = 4.8699
	sim_grads_norm = -0.0467
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2358
	data_grads_norm = 2.7282
	new_data_grads_norm = 4.3587
	old_data_grads_norm = 3.7057
	sim_grads_norm = -0.0536
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6775
	data_grads_norm = 3.2783
	new_data_grads_norm = 4.4576
	old_data_grads_norm = 4.2114
	sim_grads_norm = 0.1662
-- Starting training on experience 37 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4405
	data_grads_norm = 3.0389
	new_data_grads_norm = 5.4906
	old_data_grads_norm = 3.8277
	sim_grads_norm = 0.0187
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7456
	data_grads_norm = 3.3625
	new_data_grads_norm = 5.0260
	old_data_grads_norm = 4.9323
	sim_grads_norm = -0.0021
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0402
	data_grads_norm = 4.1330
	new_data_grads_norm = 6.1092
	old_data_grads_norm = 4.9971
	sim_grads_norm = -0.0213
-- Starting training on experience 38 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1526
	data_grads_norm = 3.5004
	new_data_grads_norm = 4.7043
	old_data_grads_norm = 4.8845
	sim_grads_norm = 0.1028
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0177
	data_grads_norm = 3.3146
	new_data_grads_norm = 4.4063
	old_data_grads_norm = 4.2276
	sim_grads_norm = 0.0676
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6694
	data_grads_norm = 3.1247
	new_data_grads_norm = 4.3912
	old_data_grads_norm = 3.4891
	sim_grads_norm = 0.0257
-- Starting training on experience 39 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4551
	data_grads_norm = 3.6074
	new_data_grads_norm = 5.1518
	old_data_grads_norm = 4.8787
	sim_grads_norm = -0.0459
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5585
	data_grads_norm = 3.5678
	new_data_grads_norm = 5.3202
	old_data_grads_norm = 4.8510
	sim_grads_norm = -0.0001
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3203
	data_grads_norm = 3.0374
	new_data_grads_norm = 4.9189
	old_data_grads_norm = 3.2574
	sim_grads_norm = 0.0283
-- Starting training on experience 40 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6828
	data_grads_norm = 3.6969
	new_data_grads_norm = 5.0893
	old_data_grads_norm = 6.4905
	sim_grads_norm = 0.0152
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7917
	data_grads_norm = 3.5076
	new_data_grads_norm = 5.3784
	old_data_grads_norm = 4.8742
	sim_grads_norm = 0.0152
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8316
	data_grads_norm = 3.4328
	new_data_grads_norm = 5.4814
	old_data_grads_norm = 4.4502
	sim_grads_norm = -0.0243
-- Starting training on experience 41 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8847
	data_grads_norm = 3.5445
	new_data_grads_norm = 4.7300
	old_data_grads_norm = 4.5713
	sim_grads_norm = 0.0085
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2174
	data_grads_norm = 2.8803
	new_data_grads_norm = 4.5922
	old_data_grads_norm = 3.5707
	sim_grads_norm = -0.0464
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0642
	data_grads_norm = 3.3818
	new_data_grads_norm = 4.1184
	old_data_grads_norm = 4.3587
	sim_grads_norm = 0.0889
-- Starting training on experience 42 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7460
	data_grads_norm = 3.7395
	new_data_grads_norm = 4.8521
	old_data_grads_norm = 4.8585
	sim_grads_norm = 0.0426
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0911
	data_grads_norm = 3.6468
	new_data_grads_norm = 5.1388
	old_data_grads_norm = 4.2726
	sim_grads_norm = 0.0781
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7375
	data_grads_norm = 3.3386
	new_data_grads_norm = 4.6670
	old_data_grads_norm = 5.0420
	sim_grads_norm = -0.1045
-- Starting training on experience 43 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0091
	data_grads_norm = 3.1104
	new_data_grads_norm = 4.0344
	old_data_grads_norm = 4.2188
	sim_grads_norm = -0.0257
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0862
	data_grads_norm = 2.3495
	new_data_grads_norm = 3.7295
	old_data_grads_norm = 3.5023
	sim_grads_norm = -0.0213
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2095
	data_grads_norm = 2.6814
	new_data_grads_norm = 4.1058
	old_data_grads_norm = 3.8928
	sim_grads_norm = 0.0336
-- Starting training on experience 44 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6282
	data_grads_norm = 2.9370
	new_data_grads_norm = 3.8753
	old_data_grads_norm = 3.8907
	sim_grads_norm = -0.0217
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4232
	data_grads_norm = 3.0212
	new_data_grads_norm = 5.0041
	old_data_grads_norm = 3.2200
	sim_grads_norm = 0.0483
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8028
	data_grads_norm = 2.9973
	new_data_grads_norm = 3.7283
	old_data_grads_norm = 3.4846
	sim_grads_norm = -0.0174
-- Starting training on experience 45 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6831
	data_grads_norm = 3.6060
	new_data_grads_norm = 5.4444
	old_data_grads_norm = 4.8014
	sim_grads_norm = -0.0059
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0837
	data_grads_norm = 4.1354
	new_data_grads_norm = 5.6300
	old_data_grads_norm = 4.9606
	sim_grads_norm = 0.1388
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5981
	data_grads_norm = 3.3920
	new_data_grads_norm = 5.1172
	old_data_grads_norm = 4.1332
	sim_grads_norm = -0.0330
-- Starting training on experience 46 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6389
	data_grads_norm = 3.8645
	new_data_grads_norm = 5.4627
	old_data_grads_norm = 4.4703
	sim_grads_norm = -0.0428
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9452
	data_grads_norm = 3.6655
	new_data_grads_norm = 5.3532
	old_data_grads_norm = 4.0160
	sim_grads_norm = 0.1299
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5054
	data_grads_norm = 3.7128
	new_data_grads_norm = 5.4128
	old_data_grads_norm = 4.9912
	sim_grads_norm = 0.0140
-- Starting training on experience 47 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8428
	data_grads_norm = 3.2976
	new_data_grads_norm = 4.0660
	old_data_grads_norm = 4.4816
	sim_grads_norm = 0.0189
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5721
	data_grads_norm = 3.7000
	new_data_grads_norm = 4.3302
	old_data_grads_norm = 5.1384
	sim_grads_norm = 0.0292
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3846
	data_grads_norm = 2.8995
	new_data_grads_norm = 4.7404
	old_data_grads_norm = 3.7521
	sim_grads_norm = -0.0380
-- Starting training on experience 48 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6517
	data_grads_norm = 3.2447
	new_data_grads_norm = 4.8943
	old_data_grads_norm = 4.0523
	sim_grads_norm = -0.0212
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4694
	data_grads_norm = 3.3235
	new_data_grads_norm = 4.5245
	old_data_grads_norm = 4.6820
	sim_grads_norm = -0.0264
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9064
	data_grads_norm = 3.8551
	new_data_grads_norm = 4.9215
	old_data_grads_norm = 5.5812
	sim_grads_norm = 0.0250
-- Starting training on experience 49 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4562
	data_grads_norm = 2.7783
	new_data_grads_norm = 4.3190
	old_data_grads_norm = 3.5377
	sim_grads_norm = -0.0782
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6268
	data_grads_norm = 2.9551
	new_data_grads_norm = 4.5001
	old_data_grads_norm = 3.3726
	sim_grads_norm = 0.0804
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8903
	data_grads_norm = 3.5112
	new_data_grads_norm = 4.3425
	old_data_grads_norm = 5.2290
	sim_grads_norm = 0.1021
-- Starting training on experience 50 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4782
	data_grads_norm = 3.3860
	new_data_grads_norm = 5.0175
	old_data_grads_norm = 3.8683
	sim_grads_norm = 0.0502
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0981
	data_grads_norm = 3.7020
	new_data_grads_norm = 4.8271
	old_data_grads_norm = 4.6688
	sim_grads_norm = 0.0448
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6927
	data_grads_norm = 3.5327
	new_data_grads_norm = 4.9788
	old_data_grads_norm = 3.9627
	sim_grads_norm = 0.1629
-- Starting training on experience 51 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6097
	data_grads_norm = 3.3653
	new_data_grads_norm = 4.0510
	old_data_grads_norm = 4.9369
	sim_grads_norm = 0.0199
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4967
	data_grads_norm = 3.0136
	new_data_grads_norm = 4.1961
	old_data_grads_norm = 3.8410
	sim_grads_norm = -0.0293
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5955
	data_grads_norm = 3.0867
	new_data_grads_norm = 3.9536
	old_data_grads_norm = 4.1779
	sim_grads_norm = 0.1087
-- Starting training on experience 52 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7608
	data_grads_norm = 3.1619
	new_data_grads_norm = 4.5781
	old_data_grads_norm = 3.7162
	sim_grads_norm = 0.0202
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2379
	data_grads_norm = 3.0342
	new_data_grads_norm = 4.6886
	old_data_grads_norm = 3.8019
	sim_grads_norm = -0.0549
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3500
	data_grads_norm = 2.8614
	new_data_grads_norm = 4.6188
	old_data_grads_norm = 3.8390
	sim_grads_norm = 0.0267
-- Starting training on experience 53 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9203
	data_grads_norm = 3.8280
	new_data_grads_norm = 4.8188
	old_data_grads_norm = 5.3344
	sim_grads_norm = 0.0348
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5682
	data_grads_norm = 4.0380
	new_data_grads_norm = 6.4170
	old_data_grads_norm = 4.7468
	sim_grads_norm = 0.1137
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6266
	data_grads_norm = 3.1093
	new_data_grads_norm = 5.7765
	old_data_grads_norm = 3.1028
	sim_grads_norm = -0.0136
-- Starting training on experience 54 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9188
	data_grads_norm = 3.5434
	new_data_grads_norm = 4.0582
	old_data_grads_norm = 5.0989
	sim_grads_norm = 0.0740
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6160
	data_grads_norm = 2.9110
	new_data_grads_norm = 3.6896
	old_data_grads_norm = 4.5050
	sim_grads_norm = -0.0129
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1234
	data_grads_norm = 3.4120
	new_data_grads_norm = 4.0425
	old_data_grads_norm = 4.8429
	sim_grads_norm = 0.1763
-- Starting training on experience 55 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4396
	data_grads_norm = 3.1169
	new_data_grads_norm = 4.1498
	old_data_grads_norm = 4.1443
	sim_grads_norm = -0.0256
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5966
	data_grads_norm = 4.3792
	new_data_grads_norm = 5.5601
	old_data_grads_norm = 5.7796
	sim_grads_norm = 0.0725
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5202
	data_grads_norm = 3.5797
	new_data_grads_norm = 5.2119
	old_data_grads_norm = 4.5013
	sim_grads_norm = -0.0657
-- Starting training on experience 56 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5562
	data_grads_norm = 2.7506
	new_data_grads_norm = 3.9003
	old_data_grads_norm = 3.3668
	sim_grads_norm = 0.0476
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6307
	data_grads_norm = 2.8602
	new_data_grads_norm = 3.8231
	old_data_grads_norm = 4.1866
	sim_grads_norm = -0.0658
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4742
	data_grads_norm = 2.6760
	new_data_grads_norm = 3.8275
	old_data_grads_norm = 3.3078
	sim_grads_norm = 0.0738
-- Starting training on experience 57 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5143
	data_grads_norm = 3.3300
	new_data_grads_norm = 3.6619
	old_data_grads_norm = 5.2569
	sim_grads_norm = -0.0550
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8188
	data_grads_norm = 3.5428
	new_data_grads_norm = 3.8886
	old_data_grads_norm = 4.2626
	sim_grads_norm = 0.1884
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7925
	data_grads_norm = 3.1047
	new_data_grads_norm = 3.5187
	old_data_grads_norm = 4.4686
	sim_grads_norm = -0.0390
-- Starting training on experience 58 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3559
	data_grads_norm = 3.0265
	new_data_grads_norm = 3.8553
	old_data_grads_norm = 4.3477
	sim_grads_norm = -0.0513
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7153
	data_grads_norm = 3.3235
	new_data_grads_norm = 4.5540
	old_data_grads_norm = 4.6538
	sim_grads_norm = 0.0092
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5547
	data_grads_norm = 2.9904
	new_data_grads_norm = 4.7019
	old_data_grads_norm = 3.7044
	sim_grads_norm = -0.0515
-- Starting training on experience 59 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3784
	data_grads_norm = 2.8168
	new_data_grads_norm = 4.0025
	old_data_grads_norm = 3.9978
	sim_grads_norm = -0.0443
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0915
	data_grads_norm = 3.7621
	new_data_grads_norm = 4.8511
	old_data_grads_norm = 5.2503
	sim_grads_norm = -0.0028
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5538
	data_grads_norm = 3.0703
	new_data_grads_norm = 4.3019
	old_data_grads_norm = 3.9246
	sim_grads_norm = -0.0341
-- Starting training on experience 60 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4273
	data_grads_norm = 3.2568
	new_data_grads_norm = 4.3048
	old_data_grads_norm = 4.2455
	sim_grads_norm = 0.0091
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4566
	data_grads_norm = 3.8231
	new_data_grads_norm = 5.0063
	old_data_grads_norm = 5.4080
	sim_grads_norm = 0.0211
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8808
	data_grads_norm = 3.3260
	new_data_grads_norm = 4.6353
	old_data_grads_norm = 3.9554
	sim_grads_norm = 0.1426
-- Starting training on experience 61 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5152
	data_grads_norm = 3.3521
	new_data_grads_norm = 3.6683
	old_data_grads_norm = 5.1104
	sim_grads_norm = 0.0037
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8411
	data_grads_norm = 3.1715
	new_data_grads_norm = 3.7907
	old_data_grads_norm = 4.6692
	sim_grads_norm = 0.0528
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7521
	data_grads_norm = 2.8879
	new_data_grads_norm = 3.6802
	old_data_grads_norm = 3.9735
	sim_grads_norm = 0.0981
-- Starting training on experience 62 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6269
	data_grads_norm = 3.2421
	new_data_grads_norm = 4.1572
	old_data_grads_norm = 4.5468
	sim_grads_norm = 0.0557
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2013
	data_grads_norm = 2.7191
	new_data_grads_norm = 3.8880
	old_data_grads_norm = 3.2564
	sim_grads_norm = 0.0682
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9849
	data_grads_norm = 3.0785
	new_data_grads_norm = 4.3288
	old_data_grads_norm = 3.7102
	sim_grads_norm = 0.0719
-- Starting training on experience 63 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7701
	data_grads_norm = 3.7115
	new_data_grads_norm = 5.3661
	old_data_grads_norm = 4.5966
	sim_grads_norm = -0.0271
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8165
	data_grads_norm = 3.2613
	new_data_grads_norm = 4.8775
	old_data_grads_norm = 4.3073
	sim_grads_norm = -0.0836
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7341
	data_grads_norm = 3.5656
	new_data_grads_norm = 4.9256
	old_data_grads_norm = 4.2228
	sim_grads_norm = 0.0590
-- Starting training on experience 64 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6313
	data_grads_norm = 2.9625
	new_data_grads_norm = 3.6803
	old_data_grads_norm = 4.0469
	sim_grads_norm = 0.0102
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4308
	data_grads_norm = 2.9218
	new_data_grads_norm = 3.9873
	old_data_grads_norm = 3.6348
	sim_grads_norm = -0.0157
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3481
	data_grads_norm = 2.7953
	new_data_grads_norm = 3.9095
	old_data_grads_norm = 3.0281
	sim_grads_norm = 0.0165
-- Starting training on experience 65 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0496
	data_grads_norm = 3.0452
	new_data_grads_norm = 4.1684
	old_data_grads_norm = 3.6666
	sim_grads_norm = -0.0147
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5989
	data_grads_norm = 3.7166
	new_data_grads_norm = 4.4968
	old_data_grads_norm = 5.4992
	sim_grads_norm = 0.0063
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7019
	data_grads_norm = 3.3489
	new_data_grads_norm = 4.6309
	old_data_grads_norm = 4.7337
	sim_grads_norm = 0.0005
-- Starting training on experience 66 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7227
	data_grads_norm = 3.3013
	new_data_grads_norm = 4.5171
	old_data_grads_norm = 4.6976
	sim_grads_norm = 0.0005
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7082
	data_grads_norm = 3.0771
	new_data_grads_norm = 4.4847
	old_data_grads_norm = 3.8270
	sim_grads_norm = -0.0017
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3078
	data_grads_norm = 2.9398
	new_data_grads_norm = 4.3153
	old_data_grads_norm = 4.1062
	sim_grads_norm = -0.0493
-- Starting training on experience 67 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8291
	data_grads_norm = 2.9605
	new_data_grads_norm = 3.9798
	old_data_grads_norm = 4.3048
	sim_grads_norm = -0.0678
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8868
	data_grads_norm = 3.1557
	new_data_grads_norm = 3.8473
	old_data_grads_norm = 4.3012
	sim_grads_norm = 0.0440
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7943
	data_grads_norm = 3.1940
	new_data_grads_norm = 4.7781
	old_data_grads_norm = 4.3133
	sim_grads_norm = 0.0092
-- Starting training on experience 68 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1098
	data_grads_norm = 3.1985
	new_data_grads_norm = 4.3589
	old_data_grads_norm = 4.5172
	sim_grads_norm = 0.0079
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4457
	data_grads_norm = 2.6155
	new_data_grads_norm = 4.1815
	old_data_grads_norm = 2.9129
	sim_grads_norm = -0.0092
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4335
	data_grads_norm = 2.9190
	new_data_grads_norm = 4.4131
	old_data_grads_norm = 4.2163
	sim_grads_norm = -0.0217
-- Starting training on experience 69 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0446
	data_grads_norm = 3.2876
	new_data_grads_norm = 4.4777
	old_data_grads_norm = 4.3130
	sim_grads_norm = -0.0507
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5631
	data_grads_norm = 3.1403
	new_data_grads_norm = 4.5347
	old_data_grads_norm = 4.2829
	sim_grads_norm = -0.0459
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9082
	data_grads_norm = 3.2173
	new_data_grads_norm = 4.5648
	old_data_grads_norm = 5.2147
	sim_grads_norm = -0.0620
-- Starting training on experience 70 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8761
	data_grads_norm = 3.4292
	new_data_grads_norm = 5.2338
	old_data_grads_norm = 4.2237
	sim_grads_norm = 0.0262
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4541
	data_grads_norm = 3.3253
	new_data_grads_norm = 5.1985
	old_data_grads_norm = 3.8310
	sim_grads_norm = 0.0375
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8717
	data_grads_norm = 3.8389
	new_data_grads_norm = 4.8130
	old_data_grads_norm = 5.2152
	sim_grads_norm = 0.0283
-- Starting training on experience 71 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7855
	data_grads_norm = 3.2833
	new_data_grads_norm = 4.9754
	old_data_grads_norm = 5.3091
	sim_grads_norm = -0.0197
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6900
	data_grads_norm = 3.2427
	new_data_grads_norm = 4.6400
	old_data_grads_norm = 3.5824
	sim_grads_norm = 0.1533
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7077
	data_grads_norm = 3.5567
	new_data_grads_norm = 4.6720
	old_data_grads_norm = 4.9243
	sim_grads_norm = 0.0765
-- Starting training on experience 72 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4186
	data_grads_norm = 3.7181
	new_data_grads_norm = 4.5135
	old_data_grads_norm = 4.8428
	sim_grads_norm = 0.0461
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4995
	data_grads_norm = 3.6671
	new_data_grads_norm = 4.7621
	old_data_grads_norm = 4.2442
	sim_grads_norm = 0.0907
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0391
	data_grads_norm = 3.4385
	new_data_grads_norm = 5.1098
	old_data_grads_norm = 4.1356
	sim_grads_norm = -0.0466
-- Starting training on experience 73 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8759
	data_grads_norm = 3.2174
	new_data_grads_norm = 4.1971
	old_data_grads_norm = 4.1247
	sim_grads_norm = 0.1301
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7386
	data_grads_norm = 3.3104
	new_data_grads_norm = 4.3859
	old_data_grads_norm = 4.4516
	sim_grads_norm = 0.1594
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8631
	data_grads_norm = 3.1759
	new_data_grads_norm = 4.1598
	old_data_grads_norm = 4.5219
	sim_grads_norm = 0.0289
-- Starting training on experience 74 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6458
	data_grads_norm = 3.1814
	new_data_grads_norm = 3.9931
	old_data_grads_norm = 4.8371
	sim_grads_norm = 0.0030
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0877
	data_grads_norm = 3.2215
	new_data_grads_norm = 4.1671
	old_data_grads_norm = 4.8936
	sim_grads_norm = -0.0177
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6198
	data_grads_norm = 3.8824
	new_data_grads_norm = 4.7236
	old_data_grads_norm = 5.1866
	sim_grads_norm = 0.0597
-- Starting training on experience 75 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3968
	data_grads_norm = 3.1990
	new_data_grads_norm = 5.0509
	old_data_grads_norm = 3.3464
	sim_grads_norm = 0.0384
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4419
	data_grads_norm = 3.1820
	new_data_grads_norm = 4.5710
	old_data_grads_norm = 3.7532
	sim_grads_norm = 0.0678
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7508
	data_grads_norm = 3.3067
	new_data_grads_norm = 4.2338
	old_data_grads_norm = 4.8867
	sim_grads_norm = -0.0209
-- Starting training on experience 76 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9497
	data_grads_norm = 3.1870
	new_data_grads_norm = 4.1193
	old_data_grads_norm = 4.3406
	sim_grads_norm = 0.0078
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2678
	data_grads_norm = 3.2224
	new_data_grads_norm = 4.1249
	old_data_grads_norm = 4.8200
	sim_grads_norm = -0.0440
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5021
	data_grads_norm = 3.2882
	new_data_grads_norm = 4.7098
	old_data_grads_norm = 4.0449
	sim_grads_norm = 0.0867
-- Starting training on experience 77 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3028
	data_grads_norm = 3.0446
	new_data_grads_norm = 4.2208
	old_data_grads_norm = 3.9626
	sim_grads_norm = 0.0030
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3551
	data_grads_norm = 2.7125
	new_data_grads_norm = 4.1709
	old_data_grads_norm = 3.5637
	sim_grads_norm = -0.0513
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5977
	data_grads_norm = 2.9815
	new_data_grads_norm = 4.2171
	old_data_grads_norm = 3.7127
	sim_grads_norm = -0.0117
-- Starting training on experience 78 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7190
	data_grads_norm = 3.6453
	new_data_grads_norm = 4.9973
	old_data_grads_norm = 4.9771
	sim_grads_norm = 0.0368
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1116
	data_grads_norm = 2.6603
	new_data_grads_norm = 4.1570
	old_data_grads_norm = 3.4616
	sim_grads_norm = -0.0339
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3296
	data_grads_norm = 3.2636
	new_data_grads_norm = 4.7127
	old_data_grads_norm = 4.2871
	sim_grads_norm = 0.0243
-- Starting training on experience 79 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6665
	data_grads_norm = 3.0384
	new_data_grads_norm = 4.0554
	old_data_grads_norm = 4.4950
	sim_grads_norm = 0.0391
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5765
	data_grads_norm = 3.2550
	new_data_grads_norm = 3.8777
	old_data_grads_norm = 4.7978
	sim_grads_norm = 0.0643
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4589
	data_grads_norm = 2.9732
	new_data_grads_norm = 3.9859
	old_data_grads_norm = 4.1215
	sim_grads_norm = 0.0553
-- Starting training on experience 80 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9137
	data_grads_norm = 3.2546
	new_data_grads_norm = 4.8847
	old_data_grads_norm = 4.3368
	sim_grads_norm = -0.0675
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1361
	data_grads_norm = 3.2197
	new_data_grads_norm = 4.8876
	old_data_grads_norm = 4.2377
	sim_grads_norm = 0.0404
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1386
	data_grads_norm = 3.6780
	new_data_grads_norm = 5.0262
	old_data_grads_norm = 4.6275
	sim_grads_norm = 0.0206
-- Starting training on experience 81 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7165
	data_grads_norm = 3.6035
	new_data_grads_norm = 4.3762
	old_data_grads_norm = 5.6226
	sim_grads_norm = 0.0869
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7862
	data_grads_norm = 3.6191
	new_data_grads_norm = 4.6681
	old_data_grads_norm = 4.6954
	sim_grads_norm = 0.0026
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9961
	data_grads_norm = 3.6229
	new_data_grads_norm = 4.9143
	old_data_grads_norm = 4.5765
	sim_grads_norm = -0.0057
-- Starting training on experience 82 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1752
	data_grads_norm = 3.3732
	new_data_grads_norm = 4.7966
	old_data_grads_norm = 4.6994
	sim_grads_norm = 0.0530
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2725
	data_grads_norm = 3.2453
	new_data_grads_norm = 4.4275
	old_data_grads_norm = 4.6138
	sim_grads_norm = 0.0154
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1922
	data_grads_norm = 3.3661
	new_data_grads_norm = 5.0373
	old_data_grads_norm = 4.5537
	sim_grads_norm = -0.0116
-- Starting training on experience 83 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7606
	data_grads_norm = 3.0774
	new_data_grads_norm = 3.9794
	old_data_grads_norm = 4.6948
	sim_grads_norm = 0.0200
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5574
	data_grads_norm = 3.1694
	new_data_grads_norm = 4.3658
	old_data_grads_norm = 4.0199
	sim_grads_norm = 0.1111
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4093
	data_grads_norm = 3.1519
	new_data_grads_norm = 4.0301
	old_data_grads_norm = 4.5593
	sim_grads_norm = 0.0317
-- Starting training on experience 84 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1624
	data_grads_norm = 3.5096
	new_data_grads_norm = 3.9630
	old_data_grads_norm = 5.6127
	sim_grads_norm = 0.0230
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4050
	data_grads_norm = 3.1298
	new_data_grads_norm = 4.0884
	old_data_grads_norm = 4.4388
	sim_grads_norm = 0.0258
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1808
	data_grads_norm = 2.9762
	new_data_grads_norm = 4.0941
	old_data_grads_norm = 4.2552
	sim_grads_norm = 0.0507
-- Starting training on experience 85 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3063
	data_grads_norm = 3.1460
	new_data_grads_norm = 4.8295
	old_data_grads_norm = 4.0297
	sim_grads_norm = 0.0364
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0597
	data_grads_norm = 4.0057
	new_data_grads_norm = 5.7362
	old_data_grads_norm = 4.9256
	sim_grads_norm = 0.0333
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2302
	data_grads_norm = 3.7968
	new_data_grads_norm = 5.4691
	old_data_grads_norm = 5.1679
	sim_grads_norm = -0.0067
-- Starting training on experience 86 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6250
	data_grads_norm = 2.9039
	new_data_grads_norm = 4.4329
	old_data_grads_norm = 3.8854
	sim_grads_norm = -0.0188
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6039
	data_grads_norm = 3.5283
	new_data_grads_norm = 4.7552
	old_data_grads_norm = 4.4091
	sim_grads_norm = 0.0089
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7851
	data_grads_norm = 3.3866
	new_data_grads_norm = 4.7504
	old_data_grads_norm = 4.5063
	sim_grads_norm = -0.0406
-- Starting training on experience 87 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2182
	data_grads_norm = 2.8027
	new_data_grads_norm = 3.9991
	old_data_grads_norm = 3.7828
	sim_grads_norm = 0.0047
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5558
	data_grads_norm = 3.1713
	new_data_grads_norm = 4.0350
	old_data_grads_norm = 4.7071
	sim_grads_norm = -0.0190
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0298
	data_grads_norm = 2.7169
	new_data_grads_norm = 4.5204
	old_data_grads_norm = 3.2738
	sim_grads_norm = 0.0709
-- Starting training on experience 88 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7516
	data_grads_norm = 3.7355
	new_data_grads_norm = 4.2588
	old_data_grads_norm = 5.7447
	sim_grads_norm = 0.0296
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6975
	data_grads_norm = 3.0126
	new_data_grads_norm = 4.6165
	old_data_grads_norm = 3.9241
	sim_grads_norm = -0.0180
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7998
	data_grads_norm = 3.1739
	new_data_grads_norm = 4.1807
	old_data_grads_norm = 4.4044
	sim_grads_norm = 0.0817
-- Starting training on experience 89 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3086
	data_grads_norm = 3.1210
	new_data_grads_norm = 4.2515
	old_data_grads_norm = 4.4457
	sim_grads_norm = -0.0034
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2261
	data_grads_norm = 3.7136
	new_data_grads_norm = 4.2118
	old_data_grads_norm = 6.7162
	sim_grads_norm = -0.0202
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5386
	data_grads_norm = 3.2312
	new_data_grads_norm = 4.0034
	old_data_grads_norm = 5.2118
	sim_grads_norm = 0.0427
-- Starting training on experience 90 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1352
	data_grads_norm = 3.3801
	new_data_grads_norm = 4.1807
	old_data_grads_norm = 4.7218
	sim_grads_norm = 0.1217
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3313
	data_grads_norm = 3.5562
	new_data_grads_norm = 4.1705
	old_data_grads_norm = 5.1238
	sim_grads_norm = 0.0185
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0562
	data_grads_norm = 2.7163
	new_data_grads_norm = 3.9977
	old_data_grads_norm = 4.1979
	sim_grads_norm = -0.0278
-- Starting training on experience 91 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1188
	data_grads_norm = 3.4674
	new_data_grads_norm = 4.5483
	old_data_grads_norm = 4.7508
	sim_grads_norm = -0.0283
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7350
	data_grads_norm = 3.8363
	new_data_grads_norm = 4.9707
	old_data_grads_norm = 4.8818
	sim_grads_norm = 0.1975
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7740
	data_grads_norm = 3.3468
	new_data_grads_norm = 4.2759
	old_data_grads_norm = 4.8240
	sim_grads_norm = 0.0262
-- Starting training on experience 92 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7507
	data_grads_norm = 3.0872
	new_data_grads_norm = 4.0672
	old_data_grads_norm = 3.8304
	sim_grads_norm = 0.1598
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8051
	data_grads_norm = 3.3196
	new_data_grads_norm = 4.6897
	old_data_grads_norm = 4.4448
	sim_grads_norm = 0.0539
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5616
	data_grads_norm = 3.3103
	new_data_grads_norm = 4.6094
	old_data_grads_norm = 4.3462
	sim_grads_norm = 0.0665
-- Starting training on experience 93 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9192
	data_grads_norm = 2.7405
	new_data_grads_norm = 3.3696
	old_data_grads_norm = 4.0248
	sim_grads_norm = -0.0552
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5544
	data_grads_norm = 3.0672
	new_data_grads_norm = 3.7095
	old_data_grads_norm = 4.7963
	sim_grads_norm = -0.0111
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3648
	data_grads_norm = 2.9279
	new_data_grads_norm = 3.9657
	old_data_grads_norm = 4.6389
	sim_grads_norm = -0.0196
-- Starting training on experience 94 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3454
	data_grads_norm = 3.1505
	new_data_grads_norm = 4.2975
	old_data_grads_norm = 4.1115
	sim_grads_norm = -0.0018
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4875
	data_grads_norm = 3.2811
	new_data_grads_norm = 4.0397
	old_data_grads_norm = 4.5156
	sim_grads_norm = 0.1086
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1868
	data_grads_norm = 3.3118
	new_data_grads_norm = 4.3922
	old_data_grads_norm = 4.1677
	sim_grads_norm = -0.0760
-- Starting training on experience 95 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4904
	data_grads_norm = 3.2259
	new_data_grads_norm = 4.1090
	old_data_grads_norm = 4.4917
	sim_grads_norm = 0.0177
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6948
	data_grads_norm = 3.6814
	new_data_grads_norm = 4.4392
	old_data_grads_norm = 4.7791
	sim_grads_norm = 0.1483
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2341
	data_grads_norm = 3.0157
	new_data_grads_norm = 3.8807
	old_data_grads_norm = 4.3578
	sim_grads_norm = -0.0404
-- Starting training on experience 96 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4502
	data_grads_norm = 2.8847
	new_data_grads_norm = 4.2906
	old_data_grads_norm = 4.1906
	sim_grads_norm = 0.0183
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5135
	data_grads_norm = 2.8526
	new_data_grads_norm = 4.1254
	old_data_grads_norm = 4.0959
	sim_grads_norm = -0.0225
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4842
	data_grads_norm = 3.0767
	new_data_grads_norm = 4.4851
	old_data_grads_norm = 3.7988
	sim_grads_norm = 0.0104
-- Starting training on experience 97 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9442
	data_grads_norm = 2.9159
	new_data_grads_norm = 4.5938
	old_data_grads_norm = 3.9478
	sim_grads_norm = -0.0058
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3021
	data_grads_norm = 3.3085
	new_data_grads_norm = 4.3947
	old_data_grads_norm = 4.5214
	sim_grads_norm = -0.0102
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5448
	data_grads_norm = 3.3518
	new_data_grads_norm = 5.1351
	old_data_grads_norm = 4.2156
	sim_grads_norm = -0.0016
-- Starting training on experience 98 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2789
	data_grads_norm = 3.2152
	new_data_grads_norm = 4.6092
	old_data_grads_norm = 3.8024
	sim_grads_norm = 0.0087
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7460
	data_grads_norm = 3.6584
	new_data_grads_norm = 4.3570
	old_data_grads_norm = 4.5221
	sim_grads_norm = 0.1019
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0735
	data_grads_norm = 3.3108
	new_data_grads_norm = 4.4819
	old_data_grads_norm = 4.6826
	sim_grads_norm = -0.0235
-- Starting training on experience 99 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1364
	data_grads_norm = 3.0087
	new_data_grads_norm = 4.1829
	old_data_grads_norm = 4.5116
	sim_grads_norm = -0.0808
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0994
	data_grads_norm = 3.5873
	new_data_grads_norm = 4.4621
	old_data_grads_norm = 5.2068
	sim_grads_norm = -0.0257
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5661
	data_grads_norm = 3.2906
	new_data_grads_norm = 4.5094
	old_data_grads_norm = 4.8618
	sim_grads_norm = -0.0558
-- Starting training on experience 100 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2330
	data_grads_norm = 3.1572
	new_data_grads_norm = 4.6003
	old_data_grads_norm = 4.1584
	sim_grads_norm = 0.0166
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0893
	data_grads_norm = 3.0934
	new_data_grads_norm = 4.3267
	old_data_grads_norm = 4.1914
	sim_grads_norm = -0.0544
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2114
	data_grads_norm = 3.2206
	new_data_grads_norm = 4.4252
	old_data_grads_norm = 4.3526
	sim_grads_norm = -0.0605
-- Starting training on experience 101 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1635
	data_grads_norm = 3.0689
	new_data_grads_norm = 4.5232
	old_data_grads_norm = 3.9587
	sim_grads_norm = 0.0566
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1275
	data_grads_norm = 2.7851
	new_data_grads_norm = 4.3957
	old_data_grads_norm = 3.3568
	sim_grads_norm = -0.0257
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5313
	data_grads_norm = 3.2000
	new_data_grads_norm = 4.5568
	old_data_grads_norm = 3.9741
	sim_grads_norm = 0.0489
-- Starting training on experience 102 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7476
	data_grads_norm = 3.4166
	new_data_grads_norm = 4.3907
	old_data_grads_norm = 5.1401
	sim_grads_norm = -0.0113
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7543
	data_grads_norm = 3.2301
	new_data_grads_norm = 4.7863
	old_data_grads_norm = 5.0445
	sim_grads_norm = 0.0243
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4434
	data_grads_norm = 2.7957
	new_data_grads_norm = 4.4719
	old_data_grads_norm = 3.4011
	sim_grads_norm = -0.0547
-- Starting training on experience 103 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6489
	data_grads_norm = 2.9034
	new_data_grads_norm = 4.1637
	old_data_grads_norm = 3.8077
	sim_grads_norm = 0.0060
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5648
	data_grads_norm = 2.7991
	new_data_grads_norm = 3.9954
	old_data_grads_norm = 4.1459
	sim_grads_norm = 0.0361
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3152
	data_grads_norm = 3.4222
	new_data_grads_norm = 4.3894
	old_data_grads_norm = 6.1323
	sim_grads_norm = -0.0138
-- Starting training on experience 104 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4947
	data_grads_norm = 3.0834
	new_data_grads_norm = 4.2146
	old_data_grads_norm = 4.5599
	sim_grads_norm = -0.0980
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5080
	data_grads_norm = 3.1526
	new_data_grads_norm = 4.5623
	old_data_grads_norm = 3.4350
	sim_grads_norm = 0.1298
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3656
	data_grads_norm = 3.0980
	new_data_grads_norm = 4.0446
	old_data_grads_norm = 4.6460
	sim_grads_norm = 0.0464
-- Starting training on experience 105 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0252
	data_grads_norm = 3.6089
	new_data_grads_norm = 4.7116
	old_data_grads_norm = 4.5897
	sim_grads_norm = 0.1911
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6199
	data_grads_norm = 3.8923
	new_data_grads_norm = 4.5018
	old_data_grads_norm = 4.9910
	sim_grads_norm = 0.0261
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7223
	data_grads_norm = 3.4517
	new_data_grads_norm = 4.9865
	old_data_grads_norm = 4.4061
	sim_grads_norm = 0.0687
-- Starting training on experience 106 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4892
	data_grads_norm = 3.3832
	new_data_grads_norm = 5.0313
	old_data_grads_norm = 4.0864
	sim_grads_norm = -0.0267
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3322
	data_grads_norm = 3.1817
	new_data_grads_norm = 5.2703
	old_data_grads_norm = 4.7258
	sim_grads_norm = -0.0354
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1084
	data_grads_norm = 3.3873
	new_data_grads_norm = 5.6434
	old_data_grads_norm = 3.6820
	sim_grads_norm = -0.0485
-- Starting training on experience 107 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4045
	data_grads_norm = 4.2291
	new_data_grads_norm = 6.3068
	old_data_grads_norm = 4.5781
	sim_grads_norm = 0.0439
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7647
	data_grads_norm = 4.2174
	new_data_grads_norm = 5.4039
	old_data_grads_norm = 5.5669
	sim_grads_norm = -0.0349
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7615
	data_grads_norm = 3.7709
	new_data_grads_norm = 5.4167
	old_data_grads_norm = 3.8117
	sim_grads_norm = 0.0382
-- Starting training on experience 108 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6440
	data_grads_norm = 3.5127
	new_data_grads_norm = 5.4313
	old_data_grads_norm = 3.7106
	sim_grads_norm = 0.1171
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0363
	data_grads_norm = 4.3307
	new_data_grads_norm = 5.8963
	old_data_grads_norm = 6.0432
	sim_grads_norm = -0.0450
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8759
	data_grads_norm = 4.2430
	new_data_grads_norm = 6.6017
	old_data_grads_norm = 4.1476
	sim_grads_norm = 0.1567
-- Starting training on experience 109 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4235
	data_grads_norm = 3.3512
	new_data_grads_norm = 4.4470
	old_data_grads_norm = 4.9300
	sim_grads_norm = -0.0570
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3191
	data_grads_norm = 2.9415
	new_data_grads_norm = 4.4531
	old_data_grads_norm = 3.9505
	sim_grads_norm = -0.0178
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4903
	data_grads_norm = 3.2483
	new_data_grads_norm = 4.6901
	old_data_grads_norm = 4.6763
	sim_grads_norm = 0.0266
-- Starting training on experience 110 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3726
	data_grads_norm = 3.3531
	new_data_grads_norm = 4.4613
	old_data_grads_norm = 4.3521
	sim_grads_norm = 0.0871
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5568
	data_grads_norm = 3.1209
	new_data_grads_norm = 4.0806
	old_data_grads_norm = 4.4338
	sim_grads_norm = -0.0382
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2084
	data_grads_norm = 2.7504
	new_data_grads_norm = 4.0516
	old_data_grads_norm = 3.9218
	sim_grads_norm = 0.0170
-- Starting training on experience 111 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3919
	data_grads_norm = 3.9459
	new_data_grads_norm = 4.8869
	old_data_grads_norm = 4.9885
	sim_grads_norm = 0.0864
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3282
	data_grads_norm = 3.4620
	new_data_grads_norm = 5.1268
	old_data_grads_norm = 4.3066
	sim_grads_norm = 0.0145
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2539
	data_grads_norm = 3.5212
	new_data_grads_norm = 4.7783
	old_data_grads_norm = 4.6865
	sim_grads_norm = 0.0264
-- Starting training on experience 112 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1412
	data_grads_norm = 3.2911
	new_data_grads_norm = 4.5944
	old_data_grads_norm = 4.1375
	sim_grads_norm = 0.0693
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7739
	data_grads_norm = 3.0726
	new_data_grads_norm = 4.7162
	old_data_grads_norm = 3.7433
	sim_grads_norm = -0.0259
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0835
	data_grads_norm = 3.5785
	new_data_grads_norm = 4.7983
	old_data_grads_norm = 5.1277
	sim_grads_norm = 0.0806
-- Starting training on experience 113 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1733
	data_grads_norm = 3.1369
	new_data_grads_norm = 4.0452
	old_data_grads_norm = 4.1675
	sim_grads_norm = -0.0294
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4266
	data_grads_norm = 3.6700
	new_data_grads_norm = 4.2275
	old_data_grads_norm = 5.0916
	sim_grads_norm = 0.0660
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1247
	data_grads_norm = 3.4419
	new_data_grads_norm = 4.1490
	old_data_grads_norm = 4.6253
	sim_grads_norm = -0.0132
-- Starting training on experience 114 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8889
	data_grads_norm = 3.3426
	new_data_grads_norm = 3.4585
	old_data_grads_norm = 5.3775
	sim_grads_norm = -0.0453
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8039
	data_grads_norm = 3.3668
	new_data_grads_norm = 3.5083
	old_data_grads_norm = 5.1570
	sim_grads_norm = 0.0003
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6866
	data_grads_norm = 3.2074
	new_data_grads_norm = 3.8492
	old_data_grads_norm = 4.2131
	sim_grads_norm = -0.0077
-- Starting training on experience 115 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0701
	data_grads_norm = 4.6383
	new_data_grads_norm = 4.9129
	old_data_grads_norm = 4.8834
	sim_grads_norm = -0.0309
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4614
	data_grads_norm = 3.7636
	new_data_grads_norm = 4.9531
	old_data_grads_norm = 5.3045
	sim_grads_norm = -0.0055
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8913
	data_grads_norm = 3.0727
	new_data_grads_norm = 4.9741
	old_data_grads_norm = 4.6321
	sim_grads_norm = -0.0877
-- Starting training on experience 116 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7875
	data_grads_norm = 3.5242
	new_data_grads_norm = 5.1584
	old_data_grads_norm = 4.2329
	sim_grads_norm = 0.0206
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4050
	data_grads_norm = 3.8668
	new_data_grads_norm = 5.1622
	old_data_grads_norm = 5.0896
	sim_grads_norm = -0.0155
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5550
	data_grads_norm = 3.3720
	new_data_grads_norm = 4.6486
	old_data_grads_norm = 4.6827
	sim_grads_norm = 0.1703
-- Starting training on experience 117 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7518
	data_grads_norm = 3.7758
	new_data_grads_norm = 5.0687
	old_data_grads_norm = 5.0253
	sim_grads_norm = 0.0582
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2913
	data_grads_norm = 3.5403
	new_data_grads_norm = 4.8501
	old_data_grads_norm = 4.3543
	sim_grads_norm = 0.0845
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2379
	data_grads_norm = 3.2750
	new_data_grads_norm = 4.7387
	old_data_grads_norm = 4.7402
	sim_grads_norm = -0.0259
-- Starting training on experience 118 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5573
	data_grads_norm = 3.6359
	new_data_grads_norm = 4.7726
	old_data_grads_norm = 4.6017
	sim_grads_norm = 0.1391
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9982
	data_grads_norm = 3.0988
	new_data_grads_norm = 4.6957
	old_data_grads_norm = 4.7335
	sim_grads_norm = -0.0748
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0770
	data_grads_norm = 3.1104
	new_data_grads_norm = 4.8777
	old_data_grads_norm = 4.3438
	sim_grads_norm = -0.0109
-- Starting training on experience 119 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4694
	data_grads_norm = 3.2336
	new_data_grads_norm = 4.3937
	old_data_grads_norm = 4.8042
	sim_grads_norm = 0.0208
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4296
	data_grads_norm = 3.5094
	new_data_grads_norm = 4.8508
	old_data_grads_norm = 4.8191
	sim_grads_norm = -0.0198
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1249
	data_grads_norm = 3.3462
	new_data_grads_norm = 4.5601
	old_data_grads_norm = 4.8493
	sim_grads_norm = 0.0269
-- Starting training on experience 120 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9425
	data_grads_norm = 2.8838
	new_data_grads_norm = 4.6070
	old_data_grads_norm = 3.5837
	sim_grads_norm = 0.0153
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2988
	data_grads_norm = 3.7675
	new_data_grads_norm = 4.2190
	old_data_grads_norm = 5.4619
	sim_grads_norm = 0.2272
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0257
	data_grads_norm = 3.0883
	new_data_grads_norm = 4.0607
	old_data_grads_norm = 4.9379
	sim_grads_norm = -0.0516
-- Starting training on experience 121 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6086
	data_grads_norm = 3.0292
	new_data_grads_norm = 4.0828
	old_data_grads_norm = 4.2134
	sim_grads_norm = 0.0210
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9701
	data_grads_norm = 3.3610
	new_data_grads_norm = 4.3655
	old_data_grads_norm = 5.0561
	sim_grads_norm = 0.0218
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3107
	data_grads_norm = 2.8937
	new_data_grads_norm = 4.0791
	old_data_grads_norm = 4.8018
	sim_grads_norm = -0.0412
-- Starting training on experience 122 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2789
	data_grads_norm = 3.2493
	new_data_grads_norm = 4.6846
	old_data_grads_norm = 3.8126
	sim_grads_norm = 0.0318
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7907
	data_grads_norm = 3.9592
	new_data_grads_norm = 4.4195
	old_data_grads_norm = 5.9204
	sim_grads_norm = 0.0305
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2645
	data_grads_norm = 3.5601
	new_data_grads_norm = 4.7110
	old_data_grads_norm = 4.6959
	sim_grads_norm = -0.0472
-- Starting training on experience 123 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6520
	data_grads_norm = 3.9722
	new_data_grads_norm = 5.8502
	old_data_grads_norm = 4.3827
	sim_grads_norm = 0.1747
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0081
	data_grads_norm = 3.8807
	new_data_grads_norm = 4.8354
	old_data_grads_norm = 5.1035
	sim_grads_norm = 0.0286
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0800
	data_grads_norm = 3.6539
	new_data_grads_norm = 4.8470
	old_data_grads_norm = 5.2782
	sim_grads_norm = -0.0337
-- Starting training on experience 124 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3144
	data_grads_norm = 2.9970
	new_data_grads_norm = 3.9338
	old_data_grads_norm = 4.1560
	sim_grads_norm = 0.0086
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1331
	data_grads_norm = 2.9510
	new_data_grads_norm = 4.3835
	old_data_grads_norm = 4.6301
	sim_grads_norm = -0.0655
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3650
	data_grads_norm = 3.2769
	new_data_grads_norm = 4.3176
	old_data_grads_norm = 4.7181
	sim_grads_norm = 0.0884
-- Starting training on experience 125 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9950
	data_grads_norm = 4.3680
	new_data_grads_norm = 5.2398
	old_data_grads_norm = 5.9631
	sim_grads_norm = 0.1195
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3488
	data_grads_norm = 3.4885
	new_data_grads_norm = 4.9262
	old_data_grads_norm = 4.3958
	sim_grads_norm = 0.0242
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1421
	data_grads_norm = 3.5247
	new_data_grads_norm = 4.6027
	old_data_grads_norm = 4.6882
	sim_grads_norm = -0.0221
-- Starting training on experience 126 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8167
	data_grads_norm = 2.9044
	new_data_grads_norm = 3.6070
	old_data_grads_norm = 4.1211
	sim_grads_norm = 0.0066
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1526
	data_grads_norm = 2.9195
	new_data_grads_norm = 3.6937
	old_data_grads_norm = 4.1634
	sim_grads_norm = 0.0506
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8347
	data_grads_norm = 2.8849
	new_data_grads_norm = 3.4072
	old_data_grads_norm = 4.5083
	sim_grads_norm = -0.0127
-- Starting training on experience 127 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3320
	data_grads_norm = 3.2668
	new_data_grads_norm = 5.4267
	old_data_grads_norm = 3.9413
	sim_grads_norm = 0.0992
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0467
	data_grads_norm = 3.1170
	new_data_grads_norm = 4.9184
	old_data_grads_norm = 3.7837
	sim_grads_norm = 0.0120
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1362
	data_grads_norm = 2.9458
	new_data_grads_norm = 5.2034
	old_data_grads_norm = 3.2578
	sim_grads_norm = -0.1175
-- Starting training on experience 128 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0460
	data_grads_norm = 3.2309
	new_data_grads_norm = 4.2332
	old_data_grads_norm = 4.4518
	sim_grads_norm = -0.0074
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9449
	data_grads_norm = 2.9044
	new_data_grads_norm = 4.4709
	old_data_grads_norm = 3.8170
	sim_grads_norm = 0.0261
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2152
	data_grads_norm = 2.9626
	new_data_grads_norm = 3.9480
	old_data_grads_norm = 4.5421
	sim_grads_norm = -0.0090
-- Starting training on experience 129 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1496
	data_grads_norm = 3.6114
	new_data_grads_norm = 5.4349
	old_data_grads_norm = 5.0055
	sim_grads_norm = -0.0516
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5078
	data_grads_norm = 3.6325
	new_data_grads_norm = 5.8711
	old_data_grads_norm = 4.3971
	sim_grads_norm = 0.0500
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4671
	data_grads_norm = 3.5196
	new_data_grads_norm = 5.6285
	old_data_grads_norm = 4.8983
	sim_grads_norm = -0.0440
-- Starting training on experience 130 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2345
	data_grads_norm = 3.4838
	new_data_grads_norm = 4.3763
	old_data_grads_norm = 4.8910
	sim_grads_norm = -0.0255
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5949
	data_grads_norm = 3.4581
	new_data_grads_norm = 4.6294
	old_data_grads_norm = 4.4118
	sim_grads_norm = -0.0068
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5789
	data_grads_norm = 3.4139
	new_data_grads_norm = 4.9045
	old_data_grads_norm = 4.3132
	sim_grads_norm = 0.0118
-- Starting training on experience 131 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9701
	data_grads_norm = 4.4872
	new_data_grads_norm = 5.6043
	old_data_grads_norm = 6.0522
	sim_grads_norm = 0.0923
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5636
	data_grads_norm = 3.7122
	new_data_grads_norm = 4.9120
	old_data_grads_norm = 5.1413
	sim_grads_norm = 0.1423
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2748
	data_grads_norm = 3.2620
	new_data_grads_norm = 4.8925
	old_data_grads_norm = 3.7539
	sim_grads_norm = -0.0441
-- Starting training on experience 132 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4104
	data_grads_norm = 3.7843
	new_data_grads_norm = 5.6501
	old_data_grads_norm = 3.7935
	sim_grads_norm = 0.0600
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4189
	data_grads_norm = 3.6761
	new_data_grads_norm = 5.0054
	old_data_grads_norm = 5.1411
	sim_grads_norm = -0.0294
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4306
	data_grads_norm = 3.7467
	new_data_grads_norm = 5.1112
	old_data_grads_norm = 4.9321
	sim_grads_norm = -0.0647
-- Starting training on experience 133 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1379
	data_grads_norm = 3.1901
	new_data_grads_norm = 4.5185
	old_data_grads_norm = 3.4390
	sim_grads_norm = 0.1337
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3673
	data_grads_norm = 3.5454
	new_data_grads_norm = 4.7744
	old_data_grads_norm = 5.4608
	sim_grads_norm = -0.0370
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6340
	data_grads_norm = 2.5360
	new_data_grads_norm = 5.0590
	old_data_grads_norm = 3.6404
	sim_grads_norm = -0.0448
-- Starting training on experience 134 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9880
	data_grads_norm = 3.3845
	new_data_grads_norm = 4.1880
	old_data_grads_norm = 5.1145
	sim_grads_norm = 0.0471
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9085
	data_grads_norm = 3.1807
	new_data_grads_norm = 4.0571
	old_data_grads_norm = 3.8781
	sim_grads_norm = 0.0180
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2454
	data_grads_norm = 2.9872
	new_data_grads_norm = 3.6944
	old_data_grads_norm = 4.4710
	sim_grads_norm = -0.0367
-- Starting training on experience 135 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2602
	data_grads_norm = 3.3200
	new_data_grads_norm = 5.0024
	old_data_grads_norm = 4.2285
	sim_grads_norm = -0.0395
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3988
	data_grads_norm = 3.8350
	new_data_grads_norm = 5.3449
	old_data_grads_norm = 5.0855
	sim_grads_norm = 0.0819
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9339
	data_grads_norm = 3.4602
	new_data_grads_norm = 4.9325
	old_data_grads_norm = 3.7887
	sim_grads_norm = 0.1274
-- Starting training on experience 136 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5172
	data_grads_norm = 3.5585
	new_data_grads_norm = 5.4066
	old_data_grads_norm = 4.6344
	sim_grads_norm = -0.0096
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6030
	data_grads_norm = 3.8035
	new_data_grads_norm = 5.6368
	old_data_grads_norm = 5.1233
	sim_grads_norm = -0.0386
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6172
	data_grads_norm = 3.8813
	new_data_grads_norm = 5.8125
	old_data_grads_norm = 4.6833
	sim_grads_norm = -0.0359
-- Starting training on experience 137 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6196
	data_grads_norm = 3.4590
	new_data_grads_norm = 4.6949
	old_data_grads_norm = 4.6254
	sim_grads_norm = -0.0167
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7863
	data_grads_norm = 3.6906
	new_data_grads_norm = 5.1684
	old_data_grads_norm = 4.3376
	sim_grads_norm = 0.0163
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2279
	data_grads_norm = 3.0634
	new_data_grads_norm = 4.6561
	old_data_grads_norm = 3.3855
	sim_grads_norm = -0.0032
-- Starting training on experience 138 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8774
	data_grads_norm = 3.8177
	new_data_grads_norm = 5.3954
	old_data_grads_norm = 4.9498
	sim_grads_norm = 0.0144
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9284
	data_grads_norm = 4.2133
	new_data_grads_norm = 4.9256
	old_data_grads_norm = 5.6273
	sim_grads_norm = 0.0891
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6171
	data_grads_norm = 3.3323
	new_data_grads_norm = 4.7745
	old_data_grads_norm = 4.4154
	sim_grads_norm = 0.0056
-- Starting training on experience 139 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2050
	data_grads_norm = 3.6261
	new_data_grads_norm = 5.2958
	old_data_grads_norm = 3.8463
	sim_grads_norm = 0.0027
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1576
	data_grads_norm = 3.2237
	new_data_grads_norm = 4.7883
	old_data_grads_norm = 3.7973
	sim_grads_norm = 0.0189
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2614
	data_grads_norm = 3.6416
	new_data_grads_norm = 4.7697
	old_data_grads_norm = 4.9057
	sim_grads_norm = -0.0118
-- Starting training on experience 140 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5287
	data_grads_norm = 3.1141
	new_data_grads_norm = 4.8976
	old_data_grads_norm = 4.0662
	sim_grads_norm = 0.0018
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6373
	data_grads_norm = 2.9993
	new_data_grads_norm = 4.5805
	old_data_grads_norm = 3.8714
	sim_grads_norm = -0.0340
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8160
	data_grads_norm = 3.8173
	new_data_grads_norm = 4.6461
	old_data_grads_norm = 5.4911
	sim_grads_norm = 0.0557
-- Starting training on experience 141 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9722
	data_grads_norm = 3.2467
	new_data_grads_norm = 5.6365
	old_data_grads_norm = 3.9381
	sim_grads_norm = 0.0272
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8235
	data_grads_norm = 3.4027
	new_data_grads_norm = 5.6730
	old_data_grads_norm = 4.1641
	sim_grads_norm = 0.0206
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1406
	data_grads_norm = 3.4638
	new_data_grads_norm = 5.3234
	old_data_grads_norm = 4.2569
	sim_grads_norm = 0.1136
-- Starting training on experience 142 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6106
	data_grads_norm = 3.4050
	new_data_grads_norm = 5.4030
	old_data_grads_norm = 3.9837
	sim_grads_norm = 0.0184
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3504
	data_grads_norm = 3.2086
	new_data_grads_norm = 5.3735
	old_data_grads_norm = 3.5536
	sim_grads_norm = -0.0283
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8394
	data_grads_norm = 4.3762
	new_data_grads_norm = 6.7022
	old_data_grads_norm = 5.1993
	sim_grads_norm = 0.0602
-- Starting training on experience 143 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1419
	data_grads_norm = 3.7773
	new_data_grads_norm = 6.0360
	old_data_grads_norm = 4.8716
	sim_grads_norm = 0.0608
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9116
	data_grads_norm = 3.1088
	new_data_grads_norm = 5.6760
	old_data_grads_norm = 3.8702
	sim_grads_norm = -0.0595
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1405
	data_grads_norm = 3.8057
	new_data_grads_norm = 5.3353
	old_data_grads_norm = 4.4352
	sim_grads_norm = 0.0319
-- Starting training on experience 144 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1102
	data_grads_norm = 3.1263
	new_data_grads_norm = 4.1401
	old_data_grads_norm = 4.2761
	sim_grads_norm = 0.0387
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2752
	data_grads_norm = 2.9239
	new_data_grads_norm = 4.0128
	old_data_grads_norm = 4.6339
	sim_grads_norm = 0.0138
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3345
	data_grads_norm = 3.6530
	new_data_grads_norm = 3.8443
	old_data_grads_norm = 5.8675
	sim_grads_norm = 0.0005
-- Starting training on experience 145 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5950
	data_grads_norm = 2.6281
	new_data_grads_norm = 3.9575
	old_data_grads_norm = 3.5821
	sim_grads_norm = -0.0174
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4329
	data_grads_norm = 3.7636
	new_data_grads_norm = 4.5163
	old_data_grads_norm = 5.8031
	sim_grads_norm = 0.0366
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0408
	data_grads_norm = 3.2599
	new_data_grads_norm = 4.1083
	old_data_grads_norm = 5.0798
	sim_grads_norm = 0.0228
-- Starting training on experience 146 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7437
	data_grads_norm = 3.2599
	new_data_grads_norm = 3.7389
	old_data_grads_norm = 4.6901
	sim_grads_norm = -0.0534
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7886
	data_grads_norm = 3.2365
	new_data_grads_norm = 3.7282
	old_data_grads_norm = 4.8762
	sim_grads_norm = 0.0218
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7887
	data_grads_norm = 2.7848
	new_data_grads_norm = 3.8405
	old_data_grads_norm = 4.2267
	sim_grads_norm = -0.1042
-- Starting training on experience 147 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5209
	data_grads_norm = 4.0242
	new_data_grads_norm = 5.6398
	old_data_grads_norm = 5.4968
	sim_grads_norm = 0.0080
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9568
	data_grads_norm = 3.9022
	new_data_grads_norm = 5.3949
	old_data_grads_norm = 4.6596
	sim_grads_norm = 0.0026
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5387
	data_grads_norm = 3.3865
	new_data_grads_norm = 5.2379
	old_data_grads_norm = 4.3136
	sim_grads_norm = -0.0005
-- Starting training on experience 148 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1997
	data_grads_norm = 2.9789
	new_data_grads_norm = 4.6081
	old_data_grads_norm = 3.6624
	sim_grads_norm = 0.0017
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6911
	data_grads_norm = 3.2686
	new_data_grads_norm = 4.3360
	old_data_grads_norm = 4.4257
	sim_grads_norm = -0.0062
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9335
	data_grads_norm = 3.7015
	new_data_grads_norm = 4.8968
	old_data_grads_norm = 5.3550
	sim_grads_norm = 0.0015
-- Starting training on experience 149 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6185
	data_grads_norm = 3.7261
	new_data_grads_norm = 4.4365
	old_data_grads_norm = 5.4457
	sim_grads_norm = 0.0756
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3777
	data_grads_norm = 2.9994
	new_data_grads_norm = 4.1649
	old_data_grads_norm = 4.5056
	sim_grads_norm = 0.0042
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2245
	data_grads_norm = 2.7705
	new_data_grads_norm = 3.9802
	old_data_grads_norm = 3.8850
	sim_grads_norm = -0.0546
-- Starting training on experience 150 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8191
	data_grads_norm = 3.7155
	new_data_grads_norm = 4.3346
	old_data_grads_norm = 5.5335
	sim_grads_norm = 0.0921
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8189
	data_grads_norm = 3.5297
	new_data_grads_norm = 4.3963
	old_data_grads_norm = 5.7070
	sim_grads_norm = 0.0353
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2103
	data_grads_norm = 3.1237
	new_data_grads_norm = 4.1760
	old_data_grads_norm = 4.7816
	sim_grads_norm = 0.0100
-- Starting training on experience 151 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0526
	data_grads_norm = 3.7405
	new_data_grads_norm = 5.5364
	old_data_grads_norm = 3.9624
	sim_grads_norm = -0.0293
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7455
	data_grads_norm = 3.4334
	new_data_grads_norm = 5.7544
	old_data_grads_norm = 4.5249
	sim_grads_norm = 0.0252
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4955
	data_grads_norm = 4.1116
	new_data_grads_norm = 5.5782
	old_data_grads_norm = 4.6148
	sim_grads_norm = 0.1043
-- Starting training on experience 152 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5882
	data_grads_norm = 3.3960
	new_data_grads_norm = 5.0509
	old_data_grads_norm = 4.3992
	sim_grads_norm = 0.0049
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7680
	data_grads_norm = 3.4239
	new_data_grads_norm = 5.6128
	old_data_grads_norm = 4.2649
	sim_grads_norm = 0.0123
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6944
	data_grads_norm = 3.7259
	new_data_grads_norm = 5.4364
	old_data_grads_norm = 5.0599
	sim_grads_norm = 0.0224
-- Starting training on experience 153 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3952
	data_grads_norm = 3.3741
	new_data_grads_norm = 5.2660
	old_data_grads_norm = 3.8795
	sim_grads_norm = 0.0078
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0042
	data_grads_norm = 3.2225
	new_data_grads_norm = 5.2260
	old_data_grads_norm = 3.7871
	sim_grads_norm = -0.0462
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8234
	data_grads_norm = 3.8111
	new_data_grads_norm = 5.0190
	old_data_grads_norm = 4.9420
	sim_grads_norm = 0.0447
-- Starting training on experience 154 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2693
	data_grads_norm = 3.3542
	new_data_grads_norm = 4.0820
	old_data_grads_norm = 4.7283
	sim_grads_norm = 0.0068
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3860
	data_grads_norm = 3.0750
	new_data_grads_norm = 4.2824
	old_data_grads_norm = 3.6884
	sim_grads_norm = 0.1442
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9548
	data_grads_norm = 2.3497
	new_data_grads_norm = 4.0219
	old_data_grads_norm = 2.8712
	sim_grads_norm = 0.0188
-- Starting training on experience 155 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7663
	data_grads_norm = 2.9711
	new_data_grads_norm = 4.6046
	old_data_grads_norm = 3.6713
	sim_grads_norm = 0.0575
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0583
	data_grads_norm = 2.8525
	new_data_grads_norm = 4.4127
	old_data_grads_norm = 3.9465
	sim_grads_norm = -0.0446
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5503
	data_grads_norm = 2.2083
	new_data_grads_norm = 4.0360
	old_data_grads_norm = 2.5375
	sim_grads_norm = -0.0649
-- Starting training on experience 156 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0255
	data_grads_norm = 3.0829
	new_data_grads_norm = 4.7148
	old_data_grads_norm = 4.1116
	sim_grads_norm = -0.0139
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1232
	data_grads_norm = 3.1568
	new_data_grads_norm = 3.8625
	old_data_grads_norm = 4.4645
	sim_grads_norm = 0.0809
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8007
	data_grads_norm = 3.2829
	new_data_grads_norm = 4.4828
	old_data_grads_norm = 3.7369
	sim_grads_norm = 0.0384
-- Starting training on experience 157 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0099
	data_grads_norm = 3.2175
	new_data_grads_norm = 3.8266
	old_data_grads_norm = 5.1967
	sim_grads_norm = -0.0356
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9903
	data_grads_norm = 3.0245
	new_data_grads_norm = 4.0250
	old_data_grads_norm = 4.5544
	sim_grads_norm = 0.0411
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1225
	data_grads_norm = 3.0627
	new_data_grads_norm = 3.9930
	old_data_grads_norm = 5.4635
	sim_grads_norm = -0.0219
-- Starting training on experience 158 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1348
	data_grads_norm = 4.2746
	new_data_grads_norm = 5.7861
	old_data_grads_norm = 5.6368
	sim_grads_norm = -0.0011
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7863
	data_grads_norm = 4.3040
	new_data_grads_norm = 6.3813
	old_data_grads_norm = 4.7272
	sim_grads_norm = 0.0828
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5110
	data_grads_norm = 3.9779
	new_data_grads_norm = 5.8045
	old_data_grads_norm = 4.8285
	sim_grads_norm = 0.1161
-- Starting training on experience 159 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6212
	data_grads_norm = 4.5740
	new_data_grads_norm = 5.7606
	old_data_grads_norm = 5.3623
	sim_grads_norm = 0.0879
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3522
	data_grads_norm = 3.6305
	new_data_grads_norm = 5.3847
	old_data_grads_norm = 5.0803
	sim_grads_norm = 0.0651
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7673
	data_grads_norm = 3.7182
	new_data_grads_norm = 6.0537
	old_data_grads_norm = 4.2162
	sim_grads_norm = 0.0122
-- Starting training on experience 160 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4654
	data_grads_norm = 3.4918
	new_data_grads_norm = 4.6858
	old_data_grads_norm = 4.7141
	sim_grads_norm = 0.0468
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4956
	data_grads_norm = 3.6282
	new_data_grads_norm = 4.6930
	old_data_grads_norm = 5.2161
	sim_grads_norm = -0.0770
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2205
	data_grads_norm = 3.8321
	new_data_grads_norm = 5.5709
	old_data_grads_norm = 3.4513
	sim_grads_norm = 0.0133
-- Starting training on experience 161 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4463
	data_grads_norm = 3.3897
	new_data_grads_norm = 4.9936
	old_data_grads_norm = 3.9299
	sim_grads_norm = 0.0496
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8269
	data_grads_norm = 3.3604
	new_data_grads_norm = 4.6964
	old_data_grads_norm = 4.3651
	sim_grads_norm = -0.0013
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3934
	data_grads_norm = 3.6953
	new_data_grads_norm = 4.5814
	old_data_grads_norm = 5.6340
	sim_grads_norm = 0.0975
-- Starting training on experience 162 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8459
	data_grads_norm = 3.2332
	new_data_grads_norm = 4.4114
	old_data_grads_norm = 4.5962
	sim_grads_norm = -0.0253
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8842
	data_grads_norm = 3.0013
	new_data_grads_norm = 4.4349
	old_data_grads_norm = 4.2845
	sim_grads_norm = -0.0568
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8929
	data_grads_norm = 3.5040
	new_data_grads_norm = 4.4622
	old_data_grads_norm = 4.5306
	sim_grads_norm = 0.2032
-- Starting training on experience 163 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2328
	data_grads_norm = 4.1008
	new_data_grads_norm = 5.5040
	old_data_grads_norm = 4.7519
	sim_grads_norm = 0.0159
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1479
	data_grads_norm = 3.8241
	new_data_grads_norm = 5.6606
	old_data_grads_norm = 4.5195
	sim_grads_norm = -0.0225
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7984
	data_grads_norm = 3.8251
	new_data_grads_norm = 5.8832
	old_data_grads_norm = 3.1897
	sim_grads_norm = 0.1830
-- Starting training on experience 164 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9240
	data_grads_norm = 3.1030
	new_data_grads_norm = 5.1921
	old_data_grads_norm = 4.7171
	sim_grads_norm = -0.0642
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7746
	data_grads_norm = 4.5460
	new_data_grads_norm = 5.6503
	old_data_grads_norm = 6.1629
	sim_grads_norm = 0.0439
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4891
	data_grads_norm = 3.6686
	new_data_grads_norm = 5.2880
	old_data_grads_norm = 5.1204
	sim_grads_norm = -0.0333
-- Starting training on experience 165 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9383
	data_grads_norm = 3.1112
	new_data_grads_norm = 4.4062
	old_data_grads_norm = 4.4943
	sim_grads_norm = -0.0683
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2868
	data_grads_norm = 3.4778
	new_data_grads_norm = 5.0070
	old_data_grads_norm = 4.8398
	sim_grads_norm = -0.0358
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1268
	data_grads_norm = 3.3559
	new_data_grads_norm = 5.3015
	old_data_grads_norm = 3.3512
	sim_grads_norm = -0.0018
-- Starting training on experience 166 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2487
	data_grads_norm = 3.8120
	new_data_grads_norm = 5.6168
	old_data_grads_norm = 4.6312
	sim_grads_norm = 0.0203
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7972
	data_grads_norm = 3.6642
	new_data_grads_norm = 5.3196
	old_data_grads_norm = 4.8610
	sim_grads_norm = -0.0434
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0557
	data_grads_norm = 3.9297
	new_data_grads_norm = 5.8250
	old_data_grads_norm = 5.4886
	sim_grads_norm = -0.0046
-- Starting training on experience 167 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7748
	data_grads_norm = 4.4565
	new_data_grads_norm = 5.5503
	old_data_grads_norm = 5.3948
	sim_grads_norm = 0.0856
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9422
	data_grads_norm = 3.5590
	new_data_grads_norm = 5.5406
	old_data_grads_norm = 4.7824
	sim_grads_norm = -0.0047
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7398
	data_grads_norm = 4.1746
	new_data_grads_norm = 5.1908
	old_data_grads_norm = 4.9684
	sim_grads_norm = 0.0273
-- Starting training on experience 168 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1980
	data_grads_norm = 2.9485
	new_data_grads_norm = 4.1661
	old_data_grads_norm = 4.0349
	sim_grads_norm = 0.0318
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0969
	data_grads_norm = 3.4883
	new_data_grads_norm = 4.3358
	old_data_grads_norm = 5.0667
	sim_grads_norm = -0.0147
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0392
	data_grads_norm = 2.7714
	new_data_grads_norm = 4.5450
	old_data_grads_norm = 3.1638
	sim_grads_norm = -0.0859
-- Starting training on experience 169 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1857
	data_grads_norm = 3.5474
	new_data_grads_norm = 5.6142
	old_data_grads_norm = 4.2730
	sim_grads_norm = -0.0096
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1776
	data_grads_norm = 3.7390
	new_data_grads_norm = 5.2159
	old_data_grads_norm = 5.3038
	sim_grads_norm = -0.0386
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5602
	data_grads_norm = 4.0987
	new_data_grads_norm = 5.8975
	old_data_grads_norm = 5.1213
	sim_grads_norm = 0.0238
-- Starting training on experience 170 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4074
	data_grads_norm = 3.1822
	new_data_grads_norm = 5.2847
	old_data_grads_norm = 3.9127
	sim_grads_norm = -0.0096
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3782
	data_grads_norm = 3.1238
	new_data_grads_norm = 4.7608
	old_data_grads_norm = 3.5908
	sim_grads_norm = 0.1314
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5832
	data_grads_norm = 3.6723
	new_data_grads_norm = 4.9070
	old_data_grads_norm = 4.5586
	sim_grads_norm = 0.0334
-- Starting training on experience 171 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6897
	data_grads_norm = 3.6589
	new_data_grads_norm = 4.7156
	old_data_grads_norm = 5.2023
	sim_grads_norm = -0.0311
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4792
	data_grads_norm = 3.5188
	new_data_grads_norm = 4.5119
	old_data_grads_norm = 5.0477
	sim_grads_norm = -0.0114
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6458
	data_grads_norm = 3.7647
	new_data_grads_norm = 4.6006
	old_data_grads_norm = 6.4135
	sim_grads_norm = 0.0432
-- Starting training on experience 172 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0866
	data_grads_norm = 3.2980
	new_data_grads_norm = 5.2319
	old_data_grads_norm = 4.8534
	sim_grads_norm = 0.0402
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1783
	data_grads_norm = 3.3578
	new_data_grads_norm = 4.7469
	old_data_grads_norm = 4.2612
	sim_grads_norm = -0.0288
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0207
	data_grads_norm = 2.8700
	new_data_grads_norm = 4.4393
	old_data_grads_norm = 3.2925
	sim_grads_norm = 0.0280
-- Starting training on experience 173 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9041
	data_grads_norm = 3.4058
	new_data_grads_norm = 4.6291
	old_data_grads_norm = 4.5755
	sim_grads_norm = 0.0363
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5341
	data_grads_norm = 4.2870
	new_data_grads_norm = 4.8362
	old_data_grads_norm = 6.9706
	sim_grads_norm = 0.0571
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9719
	data_grads_norm = 3.5834
	new_data_grads_norm = 5.1358
	old_data_grads_norm = 4.7285
	sim_grads_norm = -0.0008
-- Starting training on experience 174 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9390
	data_grads_norm = 3.6131
	new_data_grads_norm = 5.7996
	old_data_grads_norm = 4.2505
	sim_grads_norm = 0.0032
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7874
	data_grads_norm = 3.7390
	new_data_grads_norm = 5.4437
	old_data_grads_norm = 3.3747
	sim_grads_norm = -0.0391
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0069
	data_grads_norm = 4.1761
	new_data_grads_norm = 5.6304
	old_data_grads_norm = 5.5577
	sim_grads_norm = 0.1043
-- Starting training on experience 175 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1481
	data_grads_norm = 3.2812
	new_data_grads_norm = 5.6893
	old_data_grads_norm = 4.3954
	sim_grads_norm = 0.0088
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6963
	data_grads_norm = 4.0049
	new_data_grads_norm = 5.6688
	old_data_grads_norm = 4.7968
	sim_grads_norm = 0.0964
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6642
	data_grads_norm = 3.4962
	new_data_grads_norm = 5.3275
	old_data_grads_norm = 4.8724
	sim_grads_norm = -0.0313
-- Starting training on experience 176 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4525
	data_grads_norm = 3.1873
	new_data_grads_norm = 4.8481
	old_data_grads_norm = 4.6638
	sim_grads_norm = -0.0405
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5663
	data_grads_norm = 3.3810
	new_data_grads_norm = 4.7056
	old_data_grads_norm = 4.7288
	sim_grads_norm = -0.0475
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8999
	data_grads_norm = 3.7347
	new_data_grads_norm = 5.0667
	old_data_grads_norm = 4.8538
	sim_grads_norm = 0.1207
-- Starting training on experience 177 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2414
	data_grads_norm = 3.0693
	new_data_grads_norm = 3.8133
	old_data_grads_norm = 4.1955
	sim_grads_norm = -0.0790
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7479
	data_grads_norm = 3.4609
	new_data_grads_norm = 4.5262
	old_data_grads_norm = 4.7091
	sim_grads_norm = 0.0649
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5141
	data_grads_norm = 3.6011
	new_data_grads_norm = 4.1952
	old_data_grads_norm = 4.9825
	sim_grads_norm = 0.1154
-- Starting training on experience 178 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5226
	data_grads_norm = 3.3845
	new_data_grads_norm = 4.3394
	old_data_grads_norm = 4.9830
	sim_grads_norm = 0.0015
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5661
	data_grads_norm = 3.3050
	new_data_grads_norm = 4.4969
	old_data_grads_norm = 4.2049
	sim_grads_norm = 0.1215
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1323
	data_grads_norm = 3.1831
	new_data_grads_norm = 4.4523
	old_data_grads_norm = 4.4934
	sim_grads_norm = 0.0081
-- Starting training on experience 179 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6279
	data_grads_norm = 3.1139
	new_data_grads_norm = 4.2974
	old_data_grads_norm = 4.2986
	sim_grads_norm = -0.0294
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1754
	data_grads_norm = 2.7480
	new_data_grads_norm = 4.1860
	old_data_grads_norm = 3.2202
	sim_grads_norm = 0.0613
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1296
	data_grads_norm = 2.7876
	new_data_grads_norm = 4.4616
	old_data_grads_norm = 2.8865
	sim_grads_norm = 0.0021
-- Starting training on experience 180 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2179
	data_grads_norm = 3.0785
	new_data_grads_norm = 4.7865
	old_data_grads_norm = 3.7281
	sim_grads_norm = 0.0366
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8059
	data_grads_norm = 3.0461
	new_data_grads_norm = 5.2756
	old_data_grads_norm = 3.5960
	sim_grads_norm = -0.0241
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4648
	data_grads_norm = 3.8349
	new_data_grads_norm = 6.6048
	old_data_grads_norm = 4.2387
	sim_grads_norm = 0.0261
-- Starting training on experience 181 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2987
	data_grads_norm = 3.2200
	new_data_grads_norm = 5.0537
	old_data_grads_norm = 4.4675
	sim_grads_norm = -0.0217
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3490
	data_grads_norm = 3.5451
	new_data_grads_norm = 5.2894
	old_data_grads_norm = 4.4017
	sim_grads_norm = 0.0862
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0622
	data_grads_norm = 3.0489
	new_data_grads_norm = 4.6824
	old_data_grads_norm = 4.1727
	sim_grads_norm = 0.0616
-- Starting training on experience 182 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8605
	data_grads_norm = 3.3732
	new_data_grads_norm = 5.2290
	old_data_grads_norm = 4.1822
	sim_grads_norm = -0.1035
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1749
	data_grads_norm = 3.8897
	new_data_grads_norm = 5.8368
	old_data_grads_norm = 4.8978
	sim_grads_norm = -0.0014
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3187
	data_grads_norm = 4.4369
	new_data_grads_norm = 5.5687
	old_data_grads_norm = 6.0695
	sim_grads_norm = 0.0497
-- Starting training on experience 183 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5774
	data_grads_norm = 3.7418
	new_data_grads_norm = 5.7945
	old_data_grads_norm = 4.5753
	sim_grads_norm = 0.0377
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5839
	data_grads_norm = 3.8349
	new_data_grads_norm = 5.6470
	old_data_grads_norm = 4.5560
	sim_grads_norm = 0.1216
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9886
	data_grads_norm = 4.2882
	new_data_grads_norm = 5.9208
	old_data_grads_norm = 5.6077
	sim_grads_norm = 0.0481
-- Starting training on experience 184 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0449
	data_grads_norm = 3.1741
	new_data_grads_norm = 4.3716
	old_data_grads_norm = 4.4068
	sim_grads_norm = 0.0062
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0959
	data_grads_norm = 3.1720
	new_data_grads_norm = 4.9522
	old_data_grads_norm = 4.4003
	sim_grads_norm = -0.0731
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0166
	data_grads_norm = 4.0309
	new_data_grads_norm = 5.1167
	old_data_grads_norm = 5.8450
	sim_grads_norm = 0.0467
-- Starting training on experience 185 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7548
	data_grads_norm = 3.3443
	new_data_grads_norm = 5.2399
	old_data_grads_norm = 4.5671
	sim_grads_norm = 0.0294
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0891
	data_grads_norm = 3.4075
	new_data_grads_norm = 4.2881
	old_data_grads_norm = 5.5400
	sim_grads_norm = 0.0004
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6636
	data_grads_norm = 2.7400
	new_data_grads_norm = 4.4369
	old_data_grads_norm = 3.8067
	sim_grads_norm = -0.0481
-- Starting training on experience 186 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4462
	data_grads_norm = 4.0130
	new_data_grads_norm = 5.6098
	old_data_grads_norm = 4.9973
	sim_grads_norm = 0.1204
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9844
	data_grads_norm = 3.5994
	new_data_grads_norm = 4.7198
	old_data_grads_norm = 4.7323
	sim_grads_norm = -0.0106
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7551
	data_grads_norm = 3.4549
	new_data_grads_norm = 4.5974
	old_data_grads_norm = 4.6134
	sim_grads_norm = -0.0037
-- Starting training on experience 187 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0740
	data_grads_norm = 4.1974
	new_data_grads_norm = 5.9548
	old_data_grads_norm = 5.5841
	sim_grads_norm = 0.0131
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1179
	data_grads_norm = 3.7387
	new_data_grads_norm = 5.9223
	old_data_grads_norm = 5.5996
	sim_grads_norm = 0.0142
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6939
	data_grads_norm = 3.3081
	new_data_grads_norm = 5.7624
	old_data_grads_norm = 4.0674
	sim_grads_norm = -0.0102
-- Starting training on experience 188 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5189
	data_grads_norm = 3.5805
	new_data_grads_norm = 4.7666
	old_data_grads_norm = 5.1460
	sim_grads_norm = -0.0729
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3975
	data_grads_norm = 4.2788
	new_data_grads_norm = 5.5983
	old_data_grads_norm = 4.9450
	sim_grads_norm = 0.1189
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8218
	data_grads_norm = 3.0686
	new_data_grads_norm = 4.9230
	old_data_grads_norm = 4.1023
	sim_grads_norm = -0.1411
-- Starting training on experience 189 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9623
	data_grads_norm = 3.8279
	new_data_grads_norm = 5.1236
	old_data_grads_norm = 4.2407
	sim_grads_norm = 0.1357
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6264
	data_grads_norm = 3.5513
	new_data_grads_norm = 5.1425
	old_data_grads_norm = 4.5904
	sim_grads_norm = -0.0257
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5204
	data_grads_norm = 3.4373
	new_data_grads_norm = 4.6314
	old_data_grads_norm = 4.0036
	sim_grads_norm = -0.0050
-- Starting training on experience 190 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7935
	data_grads_norm = 4.0724
	new_data_grads_norm = 4.6546
	old_data_grads_norm = 5.1604
	sim_grads_norm = 0.1093
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4223
	data_grads_norm = 3.9528
	new_data_grads_norm = 5.2182
	old_data_grads_norm = 4.8322
	sim_grads_norm = 0.0400
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5615
	data_grads_norm = 3.7023
	new_data_grads_norm = 4.9741
	old_data_grads_norm = 5.1972
	sim_grads_norm = 0.0306
-- Starting training on experience 191 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7311
	data_grads_norm = 3.4153
	new_data_grads_norm = 4.6548
	old_data_grads_norm = 4.1708
	sim_grads_norm = 0.0023
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3169
	data_grads_norm = 3.6291
	new_data_grads_norm = 5.2936
	old_data_grads_norm = 4.8769
	sim_grads_norm = 0.0217
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2451
	data_grads_norm = 3.5479
	new_data_grads_norm = 4.3560
	old_data_grads_norm = 4.2387
	sim_grads_norm = 0.1197
-- Starting training on experience 192 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6530
	data_grads_norm = 3.6443
	new_data_grads_norm = 5.7880
	old_data_grads_norm = 4.9979
	sim_grads_norm = -0.0284
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2565
	data_grads_norm = 4.2000
	new_data_grads_norm = 6.4860
	old_data_grads_norm = 5.6682
	sim_grads_norm = -0.0178
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5169
	data_grads_norm = 3.9811
	new_data_grads_norm = 5.5952
	old_data_grads_norm = 5.4048
	sim_grads_norm = 0.0702
-- Starting training on experience 193 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5051
	data_grads_norm = 3.8832
	new_data_grads_norm = 6.1918
	old_data_grads_norm = 4.0398
	sim_grads_norm = 0.0299
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3533
	data_grads_norm = 3.4402
	new_data_grads_norm = 6.2190
	old_data_grads_norm = 4.3217
	sim_grads_norm = -0.0749
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5890
	data_grads_norm = 3.9137
	new_data_grads_norm = 5.6866
	old_data_grads_norm = 5.5889
	sim_grads_norm = 0.0244
-- Starting training on experience 194 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4670
	data_grads_norm = 5.3184
	new_data_grads_norm = 5.0811
	old_data_grads_norm = 8.0134
	sim_grads_norm = 0.1021
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9814
	data_grads_norm = 3.9292
	new_data_grads_norm = 5.3837
	old_data_grads_norm = 5.8692
	sim_grads_norm = 0.0035
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0184
	data_grads_norm = 4.3488
	new_data_grads_norm = 5.6125
	old_data_grads_norm = 6.0980
	sim_grads_norm = 0.1715
-- Starting training on experience 195 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3309
	data_grads_norm = 3.3225
	new_data_grads_norm = 5.0456
	old_data_grads_norm = 3.7517
	sim_grads_norm = 0.0166
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3527
	data_grads_norm = 3.4237
	new_data_grads_norm = 5.1818
	old_data_grads_norm = 3.8036
	sim_grads_norm = 0.0300
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2305
	data_grads_norm = 3.3699
	new_data_grads_norm = 4.7859
	old_data_grads_norm = 4.4533
	sim_grads_norm = -0.0039
-- Starting training on experience 196 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5203
	data_grads_norm = 4.0813
	new_data_grads_norm = 6.0791
	old_data_grads_norm = 4.4509
	sim_grads_norm = 0.1423
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4773
	data_grads_norm = 3.7366
	new_data_grads_norm = 5.9510
	old_data_grads_norm = 4.1717
	sim_grads_norm = 0.0288
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4813
	data_grads_norm = 3.9224
	new_data_grads_norm = 5.4289
	old_data_grads_norm = 5.2695
	sim_grads_norm = 0.0131
-- Starting training on experience 197 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2037
	data_grads_norm = 3.8508
	new_data_grads_norm = 5.8303
	old_data_grads_norm = 3.8256
	sim_grads_norm = 0.0247
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8670
	data_grads_norm = 3.1529
	new_data_grads_norm = 4.7898
	old_data_grads_norm = 3.6969
	sim_grads_norm = -0.0130
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0789
	data_grads_norm = 3.2005
	new_data_grads_norm = 5.3443
	old_data_grads_norm = 3.9481
	sim_grads_norm = -0.0772
-- Starting training on experience 198 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1976
	data_grads_norm = 4.2355
	new_data_grads_norm = 5.4931
	old_data_grads_norm = 5.2233
	sim_grads_norm = 0.0333
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1871
	data_grads_norm = 3.7713
	new_data_grads_norm = 5.7656
	old_data_grads_norm = 4.0115
	sim_grads_norm = -0.0285
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2766
	data_grads_norm = 4.4383
	new_data_grads_norm = 5.8588
	old_data_grads_norm = 5.0462
	sim_grads_norm = 0.2709
-- Starting training on experience 199 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3824
	data_grads_norm = 4.1971
	new_data_grads_norm = 5.3801
	old_data_grads_norm = 5.6613
	sim_grads_norm = 0.0324
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0465
	data_grads_norm = 3.4088
	new_data_grads_norm = 5.2941
	old_data_grads_norm = 4.5170
	sim_grads_norm = -0.0180
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6612
	data_grads_norm = 2.6973
	new_data_grads_norm = 4.7956
	old_data_grads_norm = 3.6597
	sim_grads_norm = -0.0425
-- Starting training on experience 200 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7344
	data_grads_norm = 4.3090
	new_data_grads_norm = 4.8408
	old_data_grads_norm = 5.8980
	sim_grads_norm = 0.0830
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0091
	data_grads_norm = 3.4130
	new_data_grads_norm = 4.7196
	old_data_grads_norm = 5.0766
	sim_grads_norm = -0.0145
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7089
	data_grads_norm = 4.4944
	new_data_grads_norm = 5.2552
	old_data_grads_norm = 6.9813
	sim_grads_norm = -0.0163
-- Starting training on experience 201 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4801
	data_grads_norm = 4.0066
	new_data_grads_norm = 4.8906
	old_data_grads_norm = 5.6421
	sim_grads_norm = 0.0140
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6041
	data_grads_norm = 3.4513
	new_data_grads_norm = 4.5493
	old_data_grads_norm = 5.0408
	sim_grads_norm = 0.0330
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0209
	data_grads_norm = 3.1146
	new_data_grads_norm = 4.4596
	old_data_grads_norm = 4.4601
	sim_grads_norm = -0.0302
-- Starting training on experience 202 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0367
	data_grads_norm = 2.8112
	new_data_grads_norm = 4.3682
	old_data_grads_norm = 3.8773
	sim_grads_norm = -0.0715
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3139
	data_grads_norm = 3.1690
	new_data_grads_norm = 4.5327
	old_data_grads_norm = 4.5847
	sim_grads_norm = -0.0349
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6426
	data_grads_norm = 3.8684
	new_data_grads_norm = 5.1736
	old_data_grads_norm = 4.9383
	sim_grads_norm = 0.0149
-- Starting training on experience 203 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0378
	data_grads_norm = 3.1839
	new_data_grads_norm = 4.6609
	old_data_grads_norm = 3.1724
	sim_grads_norm = 0.0327
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8988
	data_grads_norm = 2.7433
	new_data_grads_norm = 4.3290
	old_data_grads_norm = 2.8761
	sim_grads_norm = 0.0186
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4007
	data_grads_norm = 3.7900
	new_data_grads_norm = 4.4917
	old_data_grads_norm = 4.7759
	sim_grads_norm = 0.0432
-- Starting training on experience 204 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6945
	data_grads_norm = 2.7263
	new_data_grads_norm = 4.5655
	old_data_grads_norm = 3.9807
	sim_grads_norm = -0.0260
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9224
	data_grads_norm = 3.2863
	new_data_grads_norm = 5.3578
	old_data_grads_norm = 3.7078
	sim_grads_norm = 0.0154
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3100
	data_grads_norm = 3.3798
	new_data_grads_norm = 4.4918
	old_data_grads_norm = 4.9922
	sim_grads_norm = 0.0105
-- Starting training on experience 205 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3997
	data_grads_norm = 3.5315
	new_data_grads_norm = 5.3372
	old_data_grads_norm = 4.3828
	sim_grads_norm = 0.1421
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5121
	data_grads_norm = 3.9833
	new_data_grads_norm = 4.9390
	old_data_grads_norm = 6.1540
	sim_grads_norm = 0.0761
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4564
	data_grads_norm = 3.5825
	new_data_grads_norm = 4.5697
	old_data_grads_norm = 6.3500
	sim_grads_norm = 0.0440
-- Starting training on experience 206 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4575
	data_grads_norm = 3.2874
	new_data_grads_norm = 4.2222
	old_data_grads_norm = 4.2270
	sim_grads_norm = -0.0433
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1890
	data_grads_norm = 3.1138
	new_data_grads_norm = 4.3695
	old_data_grads_norm = 3.5563
	sim_grads_norm = 0.0609
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4318
	data_grads_norm = 3.5438
	new_data_grads_norm = 4.5123
	old_data_grads_norm = 5.0341
	sim_grads_norm = 0.0368
-- Starting training on experience 207 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4636
	data_grads_norm = 3.0888
	new_data_grads_norm = 4.0559
	old_data_grads_norm = 4.3480
	sim_grads_norm = 0.0758
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0387
	data_grads_norm = 3.6328
	new_data_grads_norm = 4.0265
	old_data_grads_norm = 5.7012
	sim_grads_norm = -0.0352
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7595
	data_grads_norm = 3.1393
	new_data_grads_norm = 4.5973
	old_data_grads_norm = 4.8027
	sim_grads_norm = 0.0061
-- Starting training on experience 208 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5569
	data_grads_norm = 3.5077
	new_data_grads_norm = 4.6003
	old_data_grads_norm = 5.0871
	sim_grads_norm = 0.0547
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7709
	data_grads_norm = 2.8653
	new_data_grads_norm = 4.4204
	old_data_grads_norm = 3.0610
	sim_grads_norm = 0.0708
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0769
	data_grads_norm = 3.1948
	new_data_grads_norm = 4.8147
	old_data_grads_norm = 4.9554
	sim_grads_norm = -0.0193
-- Starting training on experience 209 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2271
	data_grads_norm = 3.5046
	new_data_grads_norm = 5.5819
	old_data_grads_norm = 3.9373
	sim_grads_norm = -0.0172
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5560
	data_grads_norm = 3.6152
	new_data_grads_norm = 4.9238
	old_data_grads_norm = 4.7873
	sim_grads_norm = 0.0584
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0499
	data_grads_norm = 3.9250
	new_data_grads_norm = 5.2073
	old_data_grads_norm = 4.9479
	sim_grads_norm = 0.0143
-- Starting training on experience 210 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7434
	data_grads_norm = 2.7931
	new_data_grads_norm = 3.7637
	old_data_grads_norm = 3.2926
	sim_grads_norm = 0.0133
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2380
	data_grads_norm = 3.4358
	new_data_grads_norm = 4.3948
	old_data_grads_norm = 4.9489
	sim_grads_norm = -0.0138
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0901
	data_grads_norm = 3.3618
	new_data_grads_norm = 4.1036
	old_data_grads_norm = 4.5663
	sim_grads_norm = -0.0122
-- Starting training on experience 211 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8853
	data_grads_norm = 2.4589
	new_data_grads_norm = 3.9337
	old_data_grads_norm = 2.7885
	sim_grads_norm = -0.0647
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5902
	data_grads_norm = 3.9029
	new_data_grads_norm = 4.5559
	old_data_grads_norm = 5.4095
	sim_grads_norm = -0.0283
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1730
	data_grads_norm = 3.3541
	new_data_grads_norm = 4.8821
	old_data_grads_norm = 3.5304
	sim_grads_norm = 0.1098
-- Starting training on experience 212 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9285
	data_grads_norm = 3.1994
	new_data_grads_norm = 5.3687
	old_data_grads_norm = 4.0906
	sim_grads_norm = -0.1415
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2253
	data_grads_norm = 3.8511
	new_data_grads_norm = 5.6837
	old_data_grads_norm = 4.6378
	sim_grads_norm = 0.0590
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0641
	data_grads_norm = 3.5420
	new_data_grads_norm = 5.3857
	old_data_grads_norm = 4.8852
	sim_grads_norm = -0.0606
-- Starting training on experience 213 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8358
	data_grads_norm = 2.8286
	new_data_grads_norm = 3.9805
	old_data_grads_norm = 4.2650
	sim_grads_norm = -0.0002
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9018
	data_grads_norm = 2.9807
	new_data_grads_norm = 4.8878
	old_data_grads_norm = 3.9054
	sim_grads_norm = 0.0222
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0452
	data_grads_norm = 3.2715
	new_data_grads_norm = 4.8451
	old_data_grads_norm = 4.4834
	sim_grads_norm = -0.0545
-- Starting training on experience 214 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9715
	data_grads_norm = 3.2578
	new_data_grads_norm = 4.9476
	old_data_grads_norm = 4.1878
	sim_grads_norm = -0.0086
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6729
	data_grads_norm = 3.3415
	new_data_grads_norm = 4.8197
	old_data_grads_norm = 4.9179
	sim_grads_norm = 0.0317
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1866
	data_grads_norm = 3.5479
	new_data_grads_norm = 4.8465
	old_data_grads_norm = 5.0801
	sim_grads_norm = 0.0430
-- Starting training on experience 215 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5737
	data_grads_norm = 4.5146
	new_data_grads_norm = 6.1801
	old_data_grads_norm = 5.4571
	sim_grads_norm = 0.0050
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2735
	data_grads_norm = 3.4145
	new_data_grads_norm = 5.8042
	old_data_grads_norm = 4.1413
	sim_grads_norm = 0.0052
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8240
	data_grads_norm = 3.7496
	new_data_grads_norm = 5.3830
	old_data_grads_norm = 4.7148
	sim_grads_norm = 0.0059
-- Starting training on experience 216 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9571
	data_grads_norm = 3.1144
	new_data_grads_norm = 4.3430
	old_data_grads_norm = 4.3826
	sim_grads_norm = 0.0248
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7573
	data_grads_norm = 2.9904
	new_data_grads_norm = 4.6101
	old_data_grads_norm = 3.8624
	sim_grads_norm = 0.0104
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0345
	data_grads_norm = 3.1889
	new_data_grads_norm = 4.8555
	old_data_grads_norm = 3.3102
	sim_grads_norm = 0.0934
-- Starting training on experience 217 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9412
	data_grads_norm = 3.4440
	new_data_grads_norm = 5.5464
	old_data_grads_norm = 3.5649
	sim_grads_norm = 0.0582
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9565
	data_grads_norm = 3.7140
	new_data_grads_norm = 4.8015
	old_data_grads_norm = 5.6130
	sim_grads_norm = -0.0938
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4468
	data_grads_norm = 3.7105
	new_data_grads_norm = 5.9424
	old_data_grads_norm = 3.5263
	sim_grads_norm = 0.1538
-- Starting training on experience 218 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2825
	data_grads_norm = 3.2138
	new_data_grads_norm = 4.5395
	old_data_grads_norm = 4.6929
	sim_grads_norm = -0.0094
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1515
	data_grads_norm = 2.8313
	new_data_grads_norm = 4.3577
	old_data_grads_norm = 3.3767
	sim_grads_norm = 0.0829
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3445
	data_grads_norm = 2.9679
	new_data_grads_norm = 4.1776
	old_data_grads_norm = 4.2764
	sim_grads_norm = -0.0645
-- Starting training on experience 219 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5812
	data_grads_norm = 3.8693
	new_data_grads_norm = 4.8911
	old_data_grads_norm = 5.2068
	sim_grads_norm = 0.0328
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0673
	data_grads_norm = 3.1675
	new_data_grads_norm = 4.9550
	old_data_grads_norm = 3.9302
	sim_grads_norm = 0.0249
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0741
	data_grads_norm = 3.4283
	new_data_grads_norm = 4.7255
	old_data_grads_norm = 5.1694
	sim_grads_norm = 0.0000
-- Starting training on experience 220 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8914
	data_grads_norm = 2.7803
	new_data_grads_norm = 4.7509
	old_data_grads_norm = 2.6030
	sim_grads_norm = -0.0256
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0566
	data_grads_norm = 3.3131
	new_data_grads_norm = 4.7292
	old_data_grads_norm = 4.9143
	sim_grads_norm = 0.0246
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1131
	data_grads_norm = 3.4920
	new_data_grads_norm = 5.0275
	old_data_grads_norm = 4.0792
	sim_grads_norm = 0.0075
-- Starting training on experience 221 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0982
	data_grads_norm = 3.6150
	new_data_grads_norm = 5.3110
	old_data_grads_norm = 4.7804
	sim_grads_norm = 0.0072
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2842
	data_grads_norm = 3.7903
	new_data_grads_norm = 5.6632
	old_data_grads_norm = 4.6745
	sim_grads_norm = 0.1684
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8310
	data_grads_norm = 3.0674
	new_data_grads_norm = 4.4003
	old_data_grads_norm = 3.4675
	sim_grads_norm = 0.0965
-- Starting training on experience 222 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4152
	data_grads_norm = 3.0109
	new_data_grads_norm = 4.0638
	old_data_grads_norm = 4.7460
	sim_grads_norm = 0.0343
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5428
	data_grads_norm = 3.5238
	new_data_grads_norm = 4.6551
	old_data_grads_norm = 4.3894
	sim_grads_norm = 0.1031
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6925
	data_grads_norm = 4.2224
	new_data_grads_norm = 4.8659
	old_data_grads_norm = 6.5793
	sim_grads_norm = -0.0371
-- Starting training on experience 223 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2186
	data_grads_norm = 3.6370
	new_data_grads_norm = 4.9857
	old_data_grads_norm = 5.4923
	sim_grads_norm = 0.0095
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8557
	data_grads_norm = 3.4057
	new_data_grads_norm = 5.5022
	old_data_grads_norm = 4.7392
	sim_grads_norm = 0.0013
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6747
	data_grads_norm = 3.6085
	new_data_grads_norm = 5.1200
	old_data_grads_norm = 5.1136
	sim_grads_norm = 0.0224
-- Starting training on experience 224 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4371
	data_grads_norm = 3.8822
	new_data_grads_norm = 5.9562
	old_data_grads_norm = 4.0031
	sim_grads_norm = 0.0901
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7593
	data_grads_norm = 3.9261
	new_data_grads_norm = 5.7979
	old_data_grads_norm = 5.1085
	sim_grads_norm = 0.0163
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3514
	data_grads_norm = 3.8185
	new_data_grads_norm = 5.3987
	old_data_grads_norm = 4.5055
	sim_grads_norm = 0.0700
-- Starting training on experience 225 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7460
	data_grads_norm = 3.0787
	new_data_grads_norm = 4.9871
	old_data_grads_norm = 4.5505
	sim_grads_norm = -0.0375
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7682
	data_grads_norm = 2.8170
	new_data_grads_norm = 4.8781
	old_data_grads_norm = 3.5901
	sim_grads_norm = -0.0061
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7193
	data_grads_norm = 3.1637
	new_data_grads_norm = 4.7528
	old_data_grads_norm = 4.2664
	sim_grads_norm = -0.0307
-- Starting training on experience 226 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7196
	data_grads_norm = 3.4766
	new_data_grads_norm = 4.5519
	old_data_grads_norm = 4.9035
	sim_grads_norm = 0.0250
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2377
	data_grads_norm = 3.3130
	new_data_grads_norm = 4.4778
	old_data_grads_norm = 4.1349
	sim_grads_norm = 0.0415
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1606
	data_grads_norm = 3.0224
	new_data_grads_norm = 4.7545
	old_data_grads_norm = 4.1871
	sim_grads_norm = -0.0369
-- Starting training on experience 227 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0164
	data_grads_norm = 3.3717
	new_data_grads_norm = 4.7684
	old_data_grads_norm = 4.9323
	sim_grads_norm = -0.0375
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2026
	data_grads_norm = 3.2583
	new_data_grads_norm = 4.4787
	old_data_grads_norm = 4.6248
	sim_grads_norm = 0.1024
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6499
	data_grads_norm = 3.2584
	new_data_grads_norm = 4.7982
	old_data_grads_norm = 4.4038
	sim_grads_norm = -0.0267
-- Starting training on experience 228 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9877
	data_grads_norm = 3.5910
	new_data_grads_norm = 5.8901
	old_data_grads_norm = 4.0763
	sim_grads_norm = -0.0182
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8619
	data_grads_norm = 4.0567
	new_data_grads_norm = 5.7224
	old_data_grads_norm = 4.7786
	sim_grads_norm = 0.0185
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4692
	data_grads_norm = 3.8262
	new_data_grads_norm = 5.6884
	old_data_grads_norm = 4.8936
	sim_grads_norm = -0.0114
-- Starting training on experience 229 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6319
	data_grads_norm = 2.7931
	new_data_grads_norm = 4.0809
	old_data_grads_norm = 4.9391
	sim_grads_norm = -0.1542
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6128
	data_grads_norm = 4.0116
	new_data_grads_norm = 4.7450
	old_data_grads_norm = 6.2422
	sim_grads_norm = 0.0622
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8081
	data_grads_norm = 3.5287
	new_data_grads_norm = 3.8643
	old_data_grads_norm = 5.4917
	sim_grads_norm = 0.0189
-- Starting training on experience 230 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7621
	data_grads_norm = 3.1394
	new_data_grads_norm = 4.7965
	old_data_grads_norm = 4.0111
	sim_grads_norm = 0.0615
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7877
	data_grads_norm = 3.5156
	new_data_grads_norm = 4.5643
	old_data_grads_norm = 5.1715
	sim_grads_norm = -0.0051
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5094
	data_grads_norm = 3.9932
	new_data_grads_norm = 5.1191
	old_data_grads_norm = 5.1855
	sim_grads_norm = -0.0804
-- Starting training on experience 231 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4504
	data_grads_norm = 3.6987
	new_data_grads_norm = 5.7674
	old_data_grads_norm = 4.8148
	sim_grads_norm = -0.0380
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9383
	data_grads_norm = 3.8084
	new_data_grads_norm = 5.7952
	old_data_grads_norm = 4.3640
	sim_grads_norm = 0.0524
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1272
	data_grads_norm = 3.7946
	new_data_grads_norm = 5.7193
	old_data_grads_norm = 5.0029
	sim_grads_norm = -0.0182
-- Starting training on experience 232 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4870
	data_grads_norm = 3.8493
	new_data_grads_norm = 5.1658
	old_data_grads_norm = 5.5985
	sim_grads_norm = 0.0150
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6554
	data_grads_norm = 3.6909
	new_data_grads_norm = 5.2132
	old_data_grads_norm = 4.8698
	sim_grads_norm = -0.0263
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3976
	data_grads_norm = 3.8583
	new_data_grads_norm = 5.3074
	old_data_grads_norm = 5.8625
	sim_grads_norm = -0.0001
-- Starting training on experience 233 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1992
	data_grads_norm = 3.3167
	new_data_grads_norm = 5.0245
	old_data_grads_norm = 4.7960
	sim_grads_norm = 0.0033
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4113
	data_grads_norm = 3.6611
	new_data_grads_norm = 5.1046
	old_data_grads_norm = 4.6772
	sim_grads_norm = -0.0133
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9465
	data_grads_norm = 3.3473
	new_data_grads_norm = 5.2926
	old_data_grads_norm = 4.0342
	sim_grads_norm = -0.0087
-- Starting training on experience 234 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1146
	data_grads_norm = 4.0076
	new_data_grads_norm = 5.2965
	old_data_grads_norm = 5.6364
	sim_grads_norm = -0.0020
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4765
	data_grads_norm = 3.8326
	new_data_grads_norm = 4.9687
	old_data_grads_norm = 5.6958
	sim_grads_norm = 0.0055
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7361
	data_grads_norm = 3.1043
	new_data_grads_norm = 5.2801
	old_data_grads_norm = 3.3572
	sim_grads_norm = -0.0015
-- Starting training on experience 235 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0942
	data_grads_norm = 3.6301
	new_data_grads_norm = 5.7637
	old_data_grads_norm = 4.7669
	sim_grads_norm = -0.0182
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4637
	data_grads_norm = 3.9293
	new_data_grads_norm = 5.7275
	old_data_grads_norm = 4.8583
	sim_grads_norm = -0.0300
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3124
	data_grads_norm = 3.5258
	new_data_grads_norm = 5.4709
	old_data_grads_norm = 3.6668
	sim_grads_norm = 0.1094
-- Starting training on experience 236 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8345
	data_grads_norm = 4.5983
	new_data_grads_norm = 6.0160
	old_data_grads_norm = 5.9530
	sim_grads_norm = 0.0238
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8622
	data_grads_norm = 3.1876
	new_data_grads_norm = 5.5190
	old_data_grads_norm = 3.7024
	sim_grads_norm = 0.0333
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4079
	data_grads_norm = 4.1942
	new_data_grads_norm = 5.4319
	old_data_grads_norm = 5.3644
	sim_grads_norm = 0.1013
-- Starting training on experience 237 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
-- >> End of training phase << --
-- >> Start of eval phase << --
-- Starting eval on experience 0 (Task 0) from test stream --
> Eval on experience 0 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp000 = 2.3730
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.3700
	mb_index = 1904
	time = 374.6316
-- Starting eval on experience 1 (Task 0) from test stream --
> Eval on experience 1 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp001 = 1.8158
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.5660
-- Starting eval on experience 2 (Task 0) from test stream --
> Eval on experience 2 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp002 = 2.5659
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.3180
-- Starting eval on experience 3 (Task 0) from test stream --
> Eval on experience 3 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp003 = 2.0549
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.5000
-- Starting eval on experience 4 (Task 0) from test stream --
> Eval on experience 4 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp004 = 3.2408
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.2680
-- Starting eval on experience 5 (Task 0) from test stream --
> Eval on experience 5 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp005 = 2.2004
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.3860
-- Starting eval on experience 6 (Task 0) from test stream --
> Eval on experience 6 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp006 = 2.4649
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp006 = 0.2840
-- Starting eval on experience 7 (Task 0) from test stream --
> Eval on experience 7 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp007 = 2.7501
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp007 = 0.2440
-- >> End of eval phase << --
	CumulativeAccuracy/eval_phase/test_stream/Exp000 = 0.7100
	CumulativeAccuracy/eval_phase/test_stream/Exp001 = 0.6340
	CumulativeAccuracy/eval_phase/test_stream/Exp002 = 0.5260
	CumulativeAccuracy/eval_phase/test_stream/Exp003 = 0.4980
	CumulativeAccuracy/eval_phase/test_stream/Exp004 = 0.4512
	CumulativeAccuracy/eval_phase/test_stream/Exp005 = 0.4250
	CumulativeAccuracy/eval_phase/test_stream/Exp006 = 0.3943
	CumulativeAccuracy/eval_phase/test_stream/Exp007 = 0.3670
	Loss_Stream/eval_phase/test_stream/Task000 = 2.4332
	Top1_Acc_Stream/eval_phase/test_stream/Task000 = 0.3670
-- >> Start of training phase << --
-- Starting training on experience 0 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2018
	data_grads_norm = 3.7334
	new_data_grads_norm = 4.4012
	old_data_grads_norm = 5.3242
	sim_grads_norm = 0.0176
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0768
	data_grads_norm = 3.4667
	new_data_grads_norm = 4.4849
	old_data_grads_norm = 4.7727
	sim_grads_norm = 0.0099
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7637
	data_grads_norm = 3.5898
	new_data_grads_norm = 4.0677
	old_data_grads_norm = 5.3008
	sim_grads_norm = 0.0037
-- Starting training on experience 1 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6284
	data_grads_norm = 3.3482
	new_data_grads_norm = 4.4449
	old_data_grads_norm = 4.5356
	sim_grads_norm = 0.0165
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3978
	data_grads_norm = 2.9667
	new_data_grads_norm = 4.2367
	old_data_grads_norm = 3.7806
	sim_grads_norm = -0.0280
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5900
	data_grads_norm = 3.3233
	new_data_grads_norm = 5.2270
	old_data_grads_norm = 4.2001
	sim_grads_norm = -0.0218
-- Starting training on experience 2 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6062
	data_grads_norm = 3.3535
	new_data_grads_norm = 4.7318
	old_data_grads_norm = 4.0769
	sim_grads_norm = -0.0104
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9797
	data_grads_norm = 3.7472
	new_data_grads_norm = 4.5640
	old_data_grads_norm = 4.6358
	sim_grads_norm = 0.0059
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3538
	data_grads_norm = 3.2320
	new_data_grads_norm = 5.0351
	old_data_grads_norm = 3.6655
	sim_grads_norm = -0.0012
-- Starting training on experience 3 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0764
	data_grads_norm = 3.6950
	new_data_grads_norm = 5.2342
	old_data_grads_norm = 4.3461
	sim_grads_norm = -0.0076
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7983
	data_grads_norm = 3.2303
	new_data_grads_norm = 4.7247
	old_data_grads_norm = 4.1476
	sim_grads_norm = -0.0210
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8577
	data_grads_norm = 3.6934
	new_data_grads_norm = 5.0410
	old_data_grads_norm = 5.8339
	sim_grads_norm = 0.0136
-- Starting training on experience 4 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1540
	data_grads_norm = 3.6075
	new_data_grads_norm = 5.0151
	old_data_grads_norm = 4.3065
	sim_grads_norm = -0.0224
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4343
	data_grads_norm = 3.5982
	new_data_grads_norm = 5.3978
	old_data_grads_norm = 3.9384
	sim_grads_norm = 0.0620
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0493
	data_grads_norm = 3.8626
	new_data_grads_norm = 5.6666
	old_data_grads_norm = 4.5710
	sim_grads_norm = 0.0191
-- Starting training on experience 5 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5686
	data_grads_norm = 3.3128
	new_data_grads_norm = 5.0324
	old_data_grads_norm = 3.5807
	sim_grads_norm = 0.0202
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1938
	data_grads_norm = 4.2084
	new_data_grads_norm = 5.6598
	old_data_grads_norm = 5.4784
	sim_grads_norm = 0.0898
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7453
	data_grads_norm = 3.6386
	new_data_grads_norm = 5.0968
	old_data_grads_norm = 4.9344
	sim_grads_norm = -0.0017
-- Starting training on experience 6 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.8038
	data_grads_norm = 4.7415
	new_data_grads_norm = 6.0929
	old_data_grads_norm = 5.9611
	sim_grads_norm = 0.0111
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2644
	data_grads_norm = 3.5977
	new_data_grads_norm = 5.9488
	old_data_grads_norm = 3.4796
	sim_grads_norm = -0.0013
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.7176
	data_grads_norm = 4.3966
	new_data_grads_norm = 5.8463
	old_data_grads_norm = 5.5182
	sim_grads_norm = 0.0317
-- Starting training on experience 7 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4579
	data_grads_norm = 3.3214
	new_data_grads_norm = 5.8260
	old_data_grads_norm = 3.0770
	sim_grads_norm = -0.0497
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4820
	data_grads_norm = 3.5405
	new_data_grads_norm = 5.3731
	old_data_grads_norm = 3.8688
	sim_grads_norm = 0.0557
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0289
	data_grads_norm = 4.0686
	new_data_grads_norm = 5.6385
	old_data_grads_norm = 5.4827
	sim_grads_norm = 0.0156
-- Starting training on experience 8 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0687
	data_grads_norm = 3.7628
	new_data_grads_norm = 5.3666
	old_data_grads_norm = 4.1435
	sim_grads_norm = 0.0804
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4572
	data_grads_norm = 3.4390
	new_data_grads_norm = 5.2605
	old_data_grads_norm = 3.9846
	sim_grads_norm = -0.0231
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8402
	data_grads_norm = 3.5257
	new_data_grads_norm = 5.4484
	old_data_grads_norm = 4.0198
	sim_grads_norm = 0.0817
-- Starting training on experience 9 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4425
	data_grads_norm = 3.3059
	new_data_grads_norm = 5.4659
	old_data_grads_norm = 2.7593
	sim_grads_norm = -0.0115
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8312
	data_grads_norm = 3.9767
	new_data_grads_norm = 5.8008
	old_data_grads_norm = 5.5533
	sim_grads_norm = 0.0701
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5369
	data_grads_norm = 3.2400
	new_data_grads_norm = 5.3109
	old_data_grads_norm = 3.1924
	sim_grads_norm = -0.0005
-- Starting training on experience 10 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6402
	data_grads_norm = 3.9278
	new_data_grads_norm = 5.0694
	old_data_grads_norm = 5.2695
	sim_grads_norm = 0.0913
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0821
	data_grads_norm = 3.3126
	new_data_grads_norm = 4.9889
	old_data_grads_norm = 4.1951
	sim_grads_norm = 0.1105
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4945
	data_grads_norm = 4.1678
	new_data_grads_norm = 4.7871
	old_data_grads_norm = 6.3232
	sim_grads_norm = 0.1047
-- Starting training on experience 11 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2379
	data_grads_norm = 3.2757
	new_data_grads_norm = 5.5430
	old_data_grads_norm = 3.1927
	sim_grads_norm = -0.0703
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3412
	data_grads_norm = 3.6393
	new_data_grads_norm = 5.3037
	old_data_grads_norm = 4.5089
	sim_grads_norm = 0.0882
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7069
	data_grads_norm = 2.9454
	new_data_grads_norm = 4.5641
	old_data_grads_norm = 3.9129
	sim_grads_norm = -0.0202
-- Starting training on experience 12 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7777
	data_grads_norm = 4.1155
	new_data_grads_norm = 5.3833
	old_data_grads_norm = 5.5304
	sim_grads_norm = 0.0295
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2032
	data_grads_norm = 3.7835
	new_data_grads_norm = 4.8855
	old_data_grads_norm = 4.6378
	sim_grads_norm = 0.0921
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2018
	data_grads_norm = 3.4063
	new_data_grads_norm = 5.2687
	old_data_grads_norm = 4.0158
	sim_grads_norm = 0.0187
-- Starting training on experience 13 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3432
	data_grads_norm = 3.2928
	new_data_grads_norm = 4.4918
	old_data_grads_norm = 4.6014
	sim_grads_norm = 0.0230
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7860
	data_grads_norm = 3.7493
	new_data_grads_norm = 4.8873
	old_data_grads_norm = 5.6688
	sim_grads_norm = 0.0171
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4999
	data_grads_norm = 3.4909
	new_data_grads_norm = 5.1645
	old_data_grads_norm = 4.9356
	sim_grads_norm = -0.0039
-- Starting training on experience 14 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5671
	data_grads_norm = 3.2462
	new_data_grads_norm = 5.1194
	old_data_grads_norm = 3.0644
	sim_grads_norm = 0.0123
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9359
	data_grads_norm = 3.6792
	new_data_grads_norm = 5.2252
	old_data_grads_norm = 4.7970
	sim_grads_norm = 0.0804
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5079
	data_grads_norm = 3.6608
	new_data_grads_norm = 5.3264
	old_data_grads_norm = 5.0654
	sim_grads_norm = -0.0118
-- Starting training on experience 15 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7744
	data_grads_norm = 3.5869
	new_data_grads_norm = 4.5952
	old_data_grads_norm = 3.7865
	sim_grads_norm = 0.1241
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5041
	data_grads_norm = 3.4348
	new_data_grads_norm = 5.5332
	old_data_grads_norm = 4.3310
	sim_grads_norm = -0.0179
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3404
	data_grads_norm = 3.1867
	new_data_grads_norm = 4.6306
	old_data_grads_norm = 4.1415
	sim_grads_norm = 0.1369
-- Starting training on experience 16 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3137
	data_grads_norm = 3.8495
	new_data_grads_norm = 5.4690
	old_data_grads_norm = 5.0744
	sim_grads_norm = -0.0221
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7368
	data_grads_norm = 3.7114
	new_data_grads_norm = 5.0360
	old_data_grads_norm = 4.7755
	sim_grads_norm = 0.0292
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4735
	data_grads_norm = 3.6259
	new_data_grads_norm = 4.8275
	old_data_grads_norm = 5.0385
	sim_grads_norm = 0.0233
-- Starting training on experience 17 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7978
	data_grads_norm = 3.4463
	new_data_grads_norm = 5.1485
	old_data_grads_norm = 4.2136
	sim_grads_norm = 0.1260
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2413
	data_grads_norm = 4.0043
	new_data_grads_norm = 5.0772
	old_data_grads_norm = 5.4134
	sim_grads_norm = -0.0074
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6768
	data_grads_norm = 3.3470
	new_data_grads_norm = 4.9551
	old_data_grads_norm = 3.8321
	sim_grads_norm = 0.0370
-- Starting training on experience 18 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9998
	data_grads_norm = 3.9038
	new_data_grads_norm = 6.0393
	old_data_grads_norm = 5.1455
	sim_grads_norm = 0.0608
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7098
	data_grads_norm = 4.0262
	new_data_grads_norm = 4.9972
	old_data_grads_norm = 4.5535
	sim_grads_norm = 0.0954
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1409
	data_grads_norm = 4.0791
	new_data_grads_norm = 5.0089
	old_data_grads_norm = 5.9024
	sim_grads_norm = 0.0158
-- Starting training on experience 19 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2636
	data_grads_norm = 3.6918
	new_data_grads_norm = 4.6392
	old_data_grads_norm = 5.3553
	sim_grads_norm = 0.0558
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0667
	data_grads_norm = 3.1901
	new_data_grads_norm = 4.4655
	old_data_grads_norm = 3.9126
	sim_grads_norm = 0.0425
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9430
	data_grads_norm = 3.0664
	new_data_grads_norm = 4.5174
	old_data_grads_norm = 3.8036
	sim_grads_norm = -0.0543
-- Starting training on experience 20 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0446
	data_grads_norm = 2.9711
	new_data_grads_norm = 4.5831
	old_data_grads_norm = 3.3104
	sim_grads_norm = -0.0612
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1440
	data_grads_norm = 3.3393
	new_data_grads_norm = 4.2951
	old_data_grads_norm = 4.4445
	sim_grads_norm = 0.0448
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2307
	data_grads_norm = 3.1234
	new_data_grads_norm = 3.9791
	old_data_grads_norm = 4.2784
	sim_grads_norm = 0.0156
-- Starting training on experience 21 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2674
	data_grads_norm = 4.0073
	new_data_grads_norm = 4.8632
	old_data_grads_norm = 5.7295
	sim_grads_norm = 0.0937
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4892
	data_grads_norm = 3.5923
	new_data_grads_norm = 4.2892
	old_data_grads_norm = 5.6074
	sim_grads_norm = -0.0002
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7761
	data_grads_norm = 3.6490
	new_data_grads_norm = 4.3777
	old_data_grads_norm = 5.7625
	sim_grads_norm = -0.0120
-- Starting training on experience 22 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5596
	data_grads_norm = 3.7297
	new_data_grads_norm = 6.0744
	old_data_grads_norm = 4.0494
	sim_grads_norm = -0.0704
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3975
	data_grads_norm = 3.8016
	new_data_grads_norm = 6.2075
	old_data_grads_norm = 3.7500
	sim_grads_norm = -0.0113
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4784
	data_grads_norm = 3.6797
	new_data_grads_norm = 5.9216
	old_data_grads_norm = 3.9437
	sim_grads_norm = 0.0824
-- Starting training on experience 23 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6135
	data_grads_norm = 3.3806
	new_data_grads_norm = 4.0419
	old_data_grads_norm = 4.8674
	sim_grads_norm = 0.0421
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1984
	data_grads_norm = 3.1683
	new_data_grads_norm = 3.8833
	old_data_grads_norm = 4.8205
	sim_grads_norm = 0.0422
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1994
	data_grads_norm = 3.2174
	new_data_grads_norm = 3.9058
	old_data_grads_norm = 4.9369
	sim_grads_norm = 0.0571
-- Starting training on experience 24 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8807
	data_grads_norm = 2.9739
	new_data_grads_norm = 4.2085
	old_data_grads_norm = 4.4925
	sim_grads_norm = 0.0085
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7024
	data_grads_norm = 3.3689
	new_data_grads_norm = 4.4084
	old_data_grads_norm = 4.6484
	sim_grads_norm = 0.0572
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1768
	data_grads_norm = 2.8168
	new_data_grads_norm = 4.2959
	old_data_grads_norm = 3.9870
	sim_grads_norm = -0.0151
-- Starting training on experience 25 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2434
	data_grads_norm = 3.5732
	new_data_grads_norm = 5.6571
	old_data_grads_norm = 4.3462
	sim_grads_norm = 0.0340
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4922
	data_grads_norm = 3.9039
	new_data_grads_norm = 5.6352
	old_data_grads_norm = 4.8520
	sim_grads_norm = 0.0015
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6795
	data_grads_norm = 3.7523
	new_data_grads_norm = 5.8226
	old_data_grads_norm = 3.8350
	sim_grads_norm = 0.1257
-- Starting training on experience 26 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9200
	data_grads_norm = 2.9394
	new_data_grads_norm = 4.4800
	old_data_grads_norm = 4.2297
	sim_grads_norm = -0.0474
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0999
	data_grads_norm = 3.1862
	new_data_grads_norm = 4.3495
	old_data_grads_norm = 4.4441
	sim_grads_norm = 0.0009
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0577
	data_grads_norm = 3.0143
	new_data_grads_norm = 4.2271
	old_data_grads_norm = 4.0138
	sim_grads_norm = -0.0413
-- Starting training on experience 27 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4326
	data_grads_norm = 3.5955
	new_data_grads_norm = 4.8167
	old_data_grads_norm = 4.2651
	sim_grads_norm = 0.1017
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0827
	data_grads_norm = 3.1790
	new_data_grads_norm = 4.9533
	old_data_grads_norm = 4.1525
	sim_grads_norm = 0.0004
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1382
	data_grads_norm = 4.0963
	new_data_grads_norm = 4.8243
	old_data_grads_norm = 7.4141
	sim_grads_norm = -0.1311
-- Starting training on experience 28 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8770
	data_grads_norm = 4.0348
	new_data_grads_norm = 5.9046
	old_data_grads_norm = 4.9602
	sim_grads_norm = 0.0410
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8552
	data_grads_norm = 4.1955
	new_data_grads_norm = 5.5728
	old_data_grads_norm = 5.6466
	sim_grads_norm = -0.0505
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0449
	data_grads_norm = 4.2140
	new_data_grads_norm = 5.7340
	old_data_grads_norm = 5.0933
	sim_grads_norm = 0.0151
-- Starting training on experience 29 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0663
	data_grads_norm = 3.3592
	new_data_grads_norm = 4.1070
	old_data_grads_norm = 3.8624
	sim_grads_norm = 0.0240
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4544
	data_grads_norm = 3.7087
	new_data_grads_norm = 4.1594
	old_data_grads_norm = 5.0872
	sim_grads_norm = 0.0362
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2403
	data_grads_norm = 3.3138
	new_data_grads_norm = 3.9578
	old_data_grads_norm = 4.8158
	sim_grads_norm = 0.0079
-- Starting training on experience 30 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7325
	data_grads_norm = 3.2389
	new_data_grads_norm = 4.4668
	old_data_grads_norm = 4.0796
	sim_grads_norm = 0.0463
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3812
	data_grads_norm = 2.8505
	new_data_grads_norm = 3.9210
	old_data_grads_norm = 4.2573
	sim_grads_norm = -0.0129
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9341
	data_grads_norm = 3.0844
	new_data_grads_norm = 4.3592
	old_data_grads_norm = 4.3690
	sim_grads_norm = 0.0126
-- Starting training on experience 31 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7891
	data_grads_norm = 3.1292
	new_data_grads_norm = 4.5477
	old_data_grads_norm = 4.4279
	sim_grads_norm = -0.0170
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8144
	data_grads_norm = 3.2704
	new_data_grads_norm = 4.3827
	old_data_grads_norm = 4.4774
	sim_grads_norm = 0.0190
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8636
	data_grads_norm = 2.6555
	new_data_grads_norm = 3.9016
	old_data_grads_norm = 3.4598
	sim_grads_norm = -0.0671
-- Starting training on experience 32 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5468
	data_grads_norm = 3.0693
	new_data_grads_norm = 4.6804
	old_data_grads_norm = 4.2800
	sim_grads_norm = -0.0198
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0559
	data_grads_norm = 3.4744
	new_data_grads_norm = 5.0700
	old_data_grads_norm = 4.3582
	sim_grads_norm = 0.0463
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2213
	data_grads_norm = 3.6620
	new_data_grads_norm = 5.2689
	old_data_grads_norm = 4.0859
	sim_grads_norm = -0.0060
-- Starting training on experience 33 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2648
	data_grads_norm = 4.0499
	new_data_grads_norm = 5.4437
	old_data_grads_norm = 4.8772
	sim_grads_norm = -0.0568
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5769
	data_grads_norm = 3.9497
	new_data_grads_norm = 5.6808
	old_data_grads_norm = 3.6211
	sim_grads_norm = 0.1755
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3653
	data_grads_norm = 4.1959
	new_data_grads_norm = 5.5500
	old_data_grads_norm = 5.1376
	sim_grads_norm = 0.0235
-- Starting training on experience 34 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2306
	data_grads_norm = 4.0509
	new_data_grads_norm = 6.0178
	old_data_grads_norm = 4.9106
	sim_grads_norm = 0.0499
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2445
	data_grads_norm = 3.6668
	new_data_grads_norm = 5.5429
	old_data_grads_norm = 4.3530
	sim_grads_norm = 0.0312
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2127
	data_grads_norm = 3.9252
	new_data_grads_norm = 6.0981
	old_data_grads_norm = 3.7829
	sim_grads_norm = 0.0957
-- Starting training on experience 35 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5364
	data_grads_norm = 3.1499
	new_data_grads_norm = 4.0644
	old_data_grads_norm = 4.5245
	sim_grads_norm = -0.0343
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3937
	data_grads_norm = 2.8368
	new_data_grads_norm = 3.9231
	old_data_grads_norm = 4.0148
	sim_grads_norm = 0.0448
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1019
	data_grads_norm = 3.1352
	new_data_grads_norm = 3.8072
	old_data_grads_norm = 4.3318
	sim_grads_norm = 0.0649
-- Starting training on experience 36 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3697
	data_grads_norm = 2.8252
	new_data_grads_norm = 4.4394
	old_data_grads_norm = 3.3250
	sim_grads_norm = -0.0355
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5236
	data_grads_norm = 3.2786
	new_data_grads_norm = 4.6218
	old_data_grads_norm = 4.0401
	sim_grads_norm = -0.0691
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1082
	data_grads_norm = 3.1080
	new_data_grads_norm = 4.7667
	old_data_grads_norm = 3.3063
	sim_grads_norm = 0.1915
-- Starting training on experience 37 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1748
	data_grads_norm = 3.3486
	new_data_grads_norm = 4.1854
	old_data_grads_norm = 4.5408
	sim_grads_norm = -0.0130
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8777
	data_grads_norm = 3.0532
	new_data_grads_norm = 4.3389
	old_data_grads_norm = 4.1278
	sim_grads_norm = 0.0382
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8842
	data_grads_norm = 3.0838
	new_data_grads_norm = 3.9830
	old_data_grads_norm = 3.9434
	sim_grads_norm = 0.0182
-- Starting training on experience 38 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5771
	data_grads_norm = 3.0884
	new_data_grads_norm = 4.4160
	old_data_grads_norm = 4.0292
	sim_grads_norm = 0.0203
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8356
	data_grads_norm = 3.1806
	new_data_grads_norm = 4.2603
	old_data_grads_norm = 3.6891
	sim_grads_norm = 0.2495
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2236
	data_grads_norm = 2.9264
	new_data_grads_norm = 3.9531
	old_data_grads_norm = 4.4502
	sim_grads_norm = -0.0342
-- Starting training on experience 39 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4047
	data_grads_norm = 2.6972
	new_data_grads_norm = 4.3085
	old_data_grads_norm = 3.4511
	sim_grads_norm = -0.0856
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3840
	data_grads_norm = 3.6999
	new_data_grads_norm = 5.2595
	old_data_grads_norm = 4.8675
	sim_grads_norm = 0.0819
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1875
	data_grads_norm = 3.4765
	new_data_grads_norm = 4.7234
	old_data_grads_norm = 4.4004
	sim_grads_norm = 0.1149
-- Starting training on experience 40 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4028
	data_grads_norm = 2.8952
	new_data_grads_norm = 3.8462
	old_data_grads_norm = 4.6350
	sim_grads_norm = 0.0380
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6608
	data_grads_norm = 3.2526
	new_data_grads_norm = 3.8292
	old_data_grads_norm = 4.3680
	sim_grads_norm = 0.0552
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7200
	data_grads_norm = 2.7968
	new_data_grads_norm = 3.9546
	old_data_grads_norm = 4.0274
	sim_grads_norm = -0.0182
-- Starting training on experience 41 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7857
	data_grads_norm = 3.3440
	new_data_grads_norm = 4.0494
	old_data_grads_norm = 4.6527
	sim_grads_norm = -0.0412
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3045
	data_grads_norm = 2.7891
	new_data_grads_norm = 4.3458
	old_data_grads_norm = 4.0553
	sim_grads_norm = -0.0290
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6747
	data_grads_norm = 3.0523
	new_data_grads_norm = 4.5635
	old_data_grads_norm = 3.2444
	sim_grads_norm = 0.0327
-- Starting training on experience 42 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1611
	data_grads_norm = 3.6663
	new_data_grads_norm = 4.7271
	old_data_grads_norm = 4.9687
	sim_grads_norm = 0.0294
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9945
	data_grads_norm = 3.7667
	new_data_grads_norm = 4.7585
	old_data_grads_norm = 5.0334
	sim_grads_norm = -0.0161
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8449
	data_grads_norm = 3.6451
	new_data_grads_norm = 5.3892
	old_data_grads_norm = 4.2435
	sim_grads_norm = 0.0049
-- Starting training on experience 43 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9924
	data_grads_norm = 3.1960
	new_data_grads_norm = 4.4530
	old_data_grads_norm = 3.2533
	sim_grads_norm = 0.1113
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5141
	data_grads_norm = 3.0447
	new_data_grads_norm = 4.3469
	old_data_grads_norm = 3.8778
	sim_grads_norm = 0.0266
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8587
	data_grads_norm = 3.2879
	new_data_grads_norm = 4.4735
	old_data_grads_norm = 4.6341
	sim_grads_norm = -0.0261
-- Starting training on experience 44 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9361
	data_grads_norm = 3.2749
	new_data_grads_norm = 3.9550
	old_data_grads_norm = 4.9420
	sim_grads_norm = 0.0004
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6050
	data_grads_norm = 2.8527
	new_data_grads_norm = 4.1962
	old_data_grads_norm = 3.1197
	sim_grads_norm = 0.1464
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0600
	data_grads_norm = 3.4544
	new_data_grads_norm = 4.0884
	old_data_grads_norm = 5.2351
	sim_grads_norm = -0.0330
-- Starting training on experience 45 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5487
	data_grads_norm = 2.9673
	new_data_grads_norm = 4.0973
	old_data_grads_norm = 3.3352
	sim_grads_norm = 0.0166
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3450
	data_grads_norm = 2.7504
	new_data_grads_norm = 4.1902
	old_data_grads_norm = 3.8609
	sim_grads_norm = 0.0594
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9887
	data_grads_norm = 3.2096
	new_data_grads_norm = 4.4035
	old_data_grads_norm = 4.2464
	sim_grads_norm = 0.1260
-- Starting training on experience 46 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4215
	data_grads_norm = 2.9809
	new_data_grads_norm = 3.6115
	old_data_grads_norm = 4.4419
	sim_grads_norm = 0.0954
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6556
	data_grads_norm = 3.3118
	new_data_grads_norm = 3.5830
	old_data_grads_norm = 5.4666
	sim_grads_norm = -0.0460
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4818
	data_grads_norm = 3.0009
	new_data_grads_norm = 3.8477
	old_data_grads_norm = 4.5498
	sim_grads_norm = 0.0101
-- Starting training on experience 47 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5064
	data_grads_norm = 3.4924
	new_data_grads_norm = 4.3315
	old_data_grads_norm = 4.5871
	sim_grads_norm = -0.0075
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6970
	data_grads_norm = 3.4553
	new_data_grads_norm = 4.0051
	old_data_grads_norm = 5.2313
	sim_grads_norm = -0.1011
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4541
	data_grads_norm = 3.3428
	new_data_grads_norm = 4.6671
	old_data_grads_norm = 3.7141
	sim_grads_norm = 0.1000
-- Starting training on experience 48 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8182
	data_grads_norm = 3.1615
	new_data_grads_norm = 4.4434
	old_data_grads_norm = 4.4762
	sim_grads_norm = -0.0671
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0417
	data_grads_norm = 3.4220
	new_data_grads_norm = 4.9128
	old_data_grads_norm = 5.3991
	sim_grads_norm = -0.0167
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5424
	data_grads_norm = 3.0039
	new_data_grads_norm = 4.4226
	old_data_grads_norm = 3.1805
	sim_grads_norm = 0.2450
-- Starting training on experience 49 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2115
	data_grads_norm = 4.1581
	new_data_grads_norm = 4.6271
	old_data_grads_norm = 6.1044
	sim_grads_norm = 0.0449
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4027
	data_grads_norm = 3.1439
	new_data_grads_norm = 5.0359
	old_data_grads_norm = 3.6575
	sim_grads_norm = -0.0230
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4798
	data_grads_norm = 2.9206
	new_data_grads_norm = 5.1324
	old_data_grads_norm = 4.0646
	sim_grads_norm = -0.1104
-- Starting training on experience 50 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1784
	data_grads_norm = 2.5693
	new_data_grads_norm = 3.7796
	old_data_grads_norm = 4.4597
	sim_grads_norm = 0.1018
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6720
	data_grads_norm = 3.3195
	new_data_grads_norm = 3.8925
	old_data_grads_norm = 4.8060
	sim_grads_norm = 0.0404
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1638
	data_grads_norm = 2.9268
	new_data_grads_norm = 3.8620
	old_data_grads_norm = 4.5877
	sim_grads_norm = -0.0554
-- Starting training on experience 51 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1124
	data_grads_norm = 2.8338
	new_data_grads_norm = 4.3987
	old_data_grads_norm = 2.5879
	sim_grads_norm = -0.0455
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6134
	data_grads_norm = 3.4205
	new_data_grads_norm = 4.2813
	old_data_grads_norm = 5.2272
	sim_grads_norm = 0.0116
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3340
	data_grads_norm = 2.9870
	new_data_grads_norm = 4.3965
	old_data_grads_norm = 4.2758
	sim_grads_norm = -0.0259
-- Starting training on experience 52 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6151
	data_grads_norm = 3.5330
	new_data_grads_norm = 4.8963
	old_data_grads_norm = 4.5174
	sim_grads_norm = 0.0340
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6458
	data_grads_norm = 3.3430
	new_data_grads_norm = 4.6924
	old_data_grads_norm = 4.3810
	sim_grads_norm = 0.0114
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3425
	data_grads_norm = 3.3395
	new_data_grads_norm = 4.9299
	old_data_grads_norm = 3.9745
	sim_grads_norm = -0.0507
-- Starting training on experience 53 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9577
	data_grads_norm = 3.6509
	new_data_grads_norm = 6.1453
	old_data_grads_norm = 4.4865
	sim_grads_norm = -0.0617
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2490
	data_grads_norm = 4.6378
	new_data_grads_norm = 7.1990
	old_data_grads_norm = 4.8867
	sim_grads_norm = 0.0648
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0917
	data_grads_norm = 4.1026
	new_data_grads_norm = 6.0852
	old_data_grads_norm = 4.3579
	sim_grads_norm = 0.0247
-- Starting training on experience 54 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4344
	data_grads_norm = 3.5217
	new_data_grads_norm = 4.0960
	old_data_grads_norm = 4.4284
	sim_grads_norm = 0.0144
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0943
	data_grads_norm = 3.3524
	new_data_grads_norm = 4.5212
	old_data_grads_norm = 4.8592
	sim_grads_norm = 0.0531
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3962
	data_grads_norm = 3.8608
	new_data_grads_norm = 4.2864
	old_data_grads_norm = 5.7496
	sim_grads_norm = 0.0791
-- Starting training on experience 55 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5673
	data_grads_norm = 3.3643
	new_data_grads_norm = 4.4493
	old_data_grads_norm = 4.2307
	sim_grads_norm = 0.1888
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4861
	data_grads_norm = 3.1895
	new_data_grads_norm = 4.1039
	old_data_grads_norm = 4.9836
	sim_grads_norm = -0.0123
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5925
	data_grads_norm = 3.3245
	new_data_grads_norm = 4.3413
	old_data_grads_norm = 5.2264
	sim_grads_norm = -0.0361
-- Starting training on experience 56 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4276
	data_grads_norm = 3.1386
	new_data_grads_norm = 4.6192
	old_data_grads_norm = 3.5732
	sim_grads_norm = 0.0466
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6561
	data_grads_norm = 3.6715
	new_data_grads_norm = 4.6245
	old_data_grads_norm = 4.7838
	sim_grads_norm = 0.0657
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4455
	data_grads_norm = 3.1961
	new_data_grads_norm = 4.3038
	old_data_grads_norm = 4.5207
	sim_grads_norm = -0.0793
-- Starting training on experience 57 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6918
	data_grads_norm = 3.2164
	new_data_grads_norm = 4.8856
	old_data_grads_norm = 4.5930
	sim_grads_norm = -0.0110
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6898
	data_grads_norm = 3.3789
	new_data_grads_norm = 4.7479
	old_data_grads_norm = 4.6427
	sim_grads_norm = 0.0232
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9883
	data_grads_norm = 2.9916
	new_data_grads_norm = 4.9132
	old_data_grads_norm = 4.0963
	sim_grads_norm = -0.0069
-- Starting training on experience 58 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0148
	data_grads_norm = 3.7394
	new_data_grads_norm = 4.5654
	old_data_grads_norm = 4.9589
	sim_grads_norm = 0.0080
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5193
	data_grads_norm = 4.1069
	new_data_grads_norm = 4.6234
	old_data_grads_norm = 5.5759
	sim_grads_norm = 0.2123
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4824
	data_grads_norm = 3.1852
	new_data_grads_norm = 3.8929
	old_data_grads_norm = 4.9184
	sim_grads_norm = 0.0767
-- Starting training on experience 59 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5232
	data_grads_norm = 3.2399
	new_data_grads_norm = 4.2944
	old_data_grads_norm = 4.1946
	sim_grads_norm = 0.0487
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1004
	data_grads_norm = 3.2847
	new_data_grads_norm = 4.2520
	old_data_grads_norm = 5.0362
	sim_grads_norm = -0.0840
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8128
	data_grads_norm = 3.8296
	new_data_grads_norm = 4.7754
	old_data_grads_norm = 5.2277
	sim_grads_norm = 0.0267
-- Starting training on experience 60 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2733
	data_grads_norm = 3.1819
	new_data_grads_norm = 4.8253
	old_data_grads_norm = 4.1516
	sim_grads_norm = -0.0266
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6986
	data_grads_norm = 3.4950
	new_data_grads_norm = 4.4766
	old_data_grads_norm = 5.1195
	sim_grads_norm = -0.0095
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4561
	data_grads_norm = 3.0030
	new_data_grads_norm = 4.4547
	old_data_grads_norm = 3.8438
	sim_grads_norm = 0.0075
-- Starting training on experience 61 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5987
	data_grads_norm = 3.4274
	new_data_grads_norm = 4.6400
	old_data_grads_norm = 4.4106
	sim_grads_norm = -0.0274
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9302
	data_grads_norm = 4.1014
	new_data_grads_norm = 5.5900
	old_data_grads_norm = 5.4590
	sim_grads_norm = 0.0846
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6939
	data_grads_norm = 3.4732
	new_data_grads_norm = 4.6899
	old_data_grads_norm = 4.6462
	sim_grads_norm = -0.0171
-- Starting training on experience 62 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6560
	data_grads_norm = 3.1650
	new_data_grads_norm = 4.0065
	old_data_grads_norm = 3.6174
	sim_grads_norm = 0.2003
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1839
	data_grads_norm = 2.5773
	new_data_grads_norm = 4.0239
	old_data_grads_norm = 3.7005
	sim_grads_norm = -0.0059
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1512
	data_grads_norm = 2.9194
	new_data_grads_norm = 4.0347
	old_data_grads_norm = 3.9635
	sim_grads_norm = 0.0288
-- Starting training on experience 63 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4856
	data_grads_norm = 3.3636
	new_data_grads_norm = 4.9345
	old_data_grads_norm = 4.2636
	sim_grads_norm = -0.0266
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3607
	data_grads_norm = 2.9137
	new_data_grads_norm = 4.4576
	old_data_grads_norm = 3.6918
	sim_grads_norm = -0.0614
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2938
	data_grads_norm = 3.1375
	new_data_grads_norm = 4.7453
	old_data_grads_norm = 4.0573
	sim_grads_norm = -0.0314
-- Starting training on experience 64 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0319
	data_grads_norm = 2.9297
	new_data_grads_norm = 3.9673
	old_data_grads_norm = 4.6536
	sim_grads_norm = 0.0169
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3506
	data_grads_norm = 2.8431
	new_data_grads_norm = 3.8848
	old_data_grads_norm = 3.9151
	sim_grads_norm = 0.0827
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5418
	data_grads_norm = 3.3851
	new_data_grads_norm = 4.1775
	old_data_grads_norm = 4.8629
	sim_grads_norm = 0.0557
-- Starting training on experience 65 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3014
	data_grads_norm = 3.3760
	new_data_grads_norm = 5.1065
	old_data_grads_norm = 4.8763
	sim_grads_norm = -0.0075
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5306
	data_grads_norm = 3.7061
	new_data_grads_norm = 4.7809
	old_data_grads_norm = 5.2848
	sim_grads_norm = -0.0391
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5227
	data_grads_norm = 3.4233
	new_data_grads_norm = 4.8045
	old_data_grads_norm = 4.5359
	sim_grads_norm = -0.0356
-- Starting training on experience 66 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5883
	data_grads_norm = 3.4505
	new_data_grads_norm = 3.9132
	old_data_grads_norm = 5.6727
	sim_grads_norm = 0.0185
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5198
	data_grads_norm = 3.3837
	new_data_grads_norm = 4.9131
	old_data_grads_norm = 4.1437
	sim_grads_norm = 0.0506
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5599
	data_grads_norm = 3.4753
	new_data_grads_norm = 4.8112
	old_data_grads_norm = 5.8852
	sim_grads_norm = 0.0323
-- Starting training on experience 67 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7690
	data_grads_norm = 3.2883
	new_data_grads_norm = 4.7506
	old_data_grads_norm = 4.8383
	sim_grads_norm = 0.0234
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4601
	data_grads_norm = 3.2042
	new_data_grads_norm = 4.3608
	old_data_grads_norm = 3.9853
	sim_grads_norm = -0.0652
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7281
	data_grads_norm = 3.9425
	new_data_grads_norm = 4.5470
	old_data_grads_norm = 5.8907
	sim_grads_norm = -0.0051
-- Starting training on experience 68 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5316
	data_grads_norm = 2.8681
	new_data_grads_norm = 4.5295
	old_data_grads_norm = 3.4520
	sim_grads_norm = 0.0210
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7005
	data_grads_norm = 3.6235
	new_data_grads_norm = 4.8950
	old_data_grads_norm = 5.3010
	sim_grads_norm = 0.0466
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1849
	data_grads_norm = 3.0406
	new_data_grads_norm = 4.3709
	old_data_grads_norm = 3.6503
	sim_grads_norm = -0.0293
-- Starting training on experience 69 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5570
	data_grads_norm = 3.2130
	new_data_grads_norm = 3.7612
	old_data_grads_norm = 5.1229
	sim_grads_norm = -0.0678
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4415
	data_grads_norm = 3.2106
	new_data_grads_norm = 4.2472
	old_data_grads_norm = 4.4511
	sim_grads_norm = 0.0348
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7361
	data_grads_norm = 3.5284
	new_data_grads_norm = 4.0814
	old_data_grads_norm = 4.6526
	sim_grads_norm = 0.1041
-- Starting training on experience 70 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2235
	data_grads_norm = 2.9575
	new_data_grads_norm = 4.4366
	old_data_grads_norm = 3.7586
	sim_grads_norm = -0.0234
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6079
	data_grads_norm = 3.0201
	new_data_grads_norm = 4.3893
	old_data_grads_norm = 4.1106
	sim_grads_norm = 0.0293
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0464
	data_grads_norm = 2.6170
	new_data_grads_norm = 4.3109
	old_data_grads_norm = 3.2757
	sim_grads_norm = -0.0309
-- Starting training on experience 71 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9727
	data_grads_norm = 3.1519
	new_data_grads_norm = 3.8105
	old_data_grads_norm = 4.8536
	sim_grads_norm = -0.0287
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2436
	data_grads_norm = 2.6895
	new_data_grads_norm = 3.8364
	old_data_grads_norm = 3.2063
	sim_grads_norm = 0.0387
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5885
	data_grads_norm = 2.7543
	new_data_grads_norm = 3.7162
	old_data_grads_norm = 3.7534
	sim_grads_norm = 0.0332
-- Starting training on experience 72 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2335
	data_grads_norm = 3.0250
	new_data_grads_norm = 4.1207
	old_data_grads_norm = 3.9992
	sim_grads_norm = -0.0198
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2070
	data_grads_norm = 3.0239
	new_data_grads_norm = 4.1887
	old_data_grads_norm = 4.5616
	sim_grads_norm = -0.0328
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3918
	data_grads_norm = 2.9892
	new_data_grads_norm = 4.4567
	old_data_grads_norm = 4.2037
	sim_grads_norm = -0.0224
-- Starting training on experience 73 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6081
	data_grads_norm = 3.2611
	new_data_grads_norm = 4.4636
	old_data_grads_norm = 4.6149
	sim_grads_norm = 0.1212
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5441
	data_grads_norm = 2.9209
	new_data_grads_norm = 4.0701
	old_data_grads_norm = 3.9467
	sim_grads_norm = 0.0619
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4222
	data_grads_norm = 2.9372
	new_data_grads_norm = 3.9950
	old_data_grads_norm = 4.0737
	sim_grads_norm = -0.0175
-- Starting training on experience 74 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9553
	data_grads_norm = 2.5977
	new_data_grads_norm = 4.7805
	old_data_grads_norm = 2.8530
	sim_grads_norm = -0.1173
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1555
	data_grads_norm = 3.2261
	new_data_grads_norm = 4.4698
	old_data_grads_norm = 4.2188
	sim_grads_norm = 0.0131
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5894
	data_grads_norm = 3.6935
	new_data_grads_norm = 4.9366
	old_data_grads_norm = 5.5893
	sim_grads_norm = -0.0439
-- Starting training on experience 75 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9133
	data_grads_norm = 3.2084
	new_data_grads_norm = 5.4777
	old_data_grads_norm = 4.2751
	sim_grads_norm = -0.0269
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2826
	data_grads_norm = 3.3922
	new_data_grads_norm = 5.2152
	old_data_grads_norm = 3.8994
	sim_grads_norm = 0.0018
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6766
	data_grads_norm = 3.3494
	new_data_grads_norm = 4.9576
	old_data_grads_norm = 4.3739
	sim_grads_norm = -0.0011
-- Starting training on experience 76 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1164
	data_grads_norm = 3.0146
	new_data_grads_norm = 4.6876
	old_data_grads_norm = 4.3244
	sim_grads_norm = -0.0586
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2385
	data_grads_norm = 3.0064
	new_data_grads_norm = 4.7096
	old_data_grads_norm = 4.9684
	sim_grads_norm = -0.0306
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5694
	data_grads_norm = 3.0795
	new_data_grads_norm = 5.0959
	old_data_grads_norm = 3.6554
	sim_grads_norm = -0.0015
-- Starting training on experience 77 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6470
	data_grads_norm = 3.7833
	new_data_grads_norm = 5.5186
	old_data_grads_norm = 4.9221
	sim_grads_norm = -0.0110
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8200
	data_grads_norm = 3.4982
	new_data_grads_norm = 5.1140
	old_data_grads_norm = 4.9092
	sim_grads_norm = -0.0031
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6324
	data_grads_norm = 3.9444
	new_data_grads_norm = 5.0075
	old_data_grads_norm = 4.6878
	sim_grads_norm = -0.0040
-- Starting training on experience 78 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6346
	data_grads_norm = 3.9213
	new_data_grads_norm = 5.6396
	old_data_grads_norm = 5.1699
	sim_grads_norm = 0.0219
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1702
	data_grads_norm = 4.0459
	new_data_grads_norm = 5.5640
	old_data_grads_norm = 4.7144
	sim_grads_norm = 0.0993
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0578
	data_grads_norm = 3.4293
	new_data_grads_norm = 4.4990
	old_data_grads_norm = 5.0058
	sim_grads_norm = 0.0300
-- Starting training on experience 79 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4445
	data_grads_norm = 3.0275
	new_data_grads_norm = 4.2838
	old_data_grads_norm = 3.4861
	sim_grads_norm = 0.0877
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7150
	data_grads_norm = 3.6528
	new_data_grads_norm = 4.0808
	old_data_grads_norm = 5.2929
	sim_grads_norm = 0.0137
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0426
	data_grads_norm = 3.4400
	new_data_grads_norm = 4.0910
	old_data_grads_norm = 5.6682
	sim_grads_norm = -0.0048
-- Starting training on experience 80 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8192
	data_grads_norm = 3.8570
	new_data_grads_norm = 4.5734
	old_data_grads_norm = 5.1760
	sim_grads_norm = -0.0025
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8435
	data_grads_norm = 3.2851
	new_data_grads_norm = 4.2366
	old_data_grads_norm = 4.9787
	sim_grads_norm = -0.0288
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1225
	data_grads_norm = 3.9230
	new_data_grads_norm = 4.6249
	old_data_grads_norm = 5.4290
	sim_grads_norm = 0.0214
-- Starting training on experience 81 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4988
	data_grads_norm = 3.5194
	new_data_grads_norm = 5.2442
	old_data_grads_norm = 4.6702
	sim_grads_norm = -0.0658
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7310
	data_grads_norm = 3.9512
	new_data_grads_norm = 5.6132
	old_data_grads_norm = 4.9849
	sim_grads_norm = 0.0684
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3565
	data_grads_norm = 3.4036
	new_data_grads_norm = 5.0818
	old_data_grads_norm = 3.5733
	sim_grads_norm = 0.0169
-- Starting training on experience 82 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3758
	data_grads_norm = 3.3986
	new_data_grads_norm = 4.6082
	old_data_grads_norm = 4.9696
	sim_grads_norm = -0.0065
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6013
	data_grads_norm = 3.7937
	new_data_grads_norm = 5.1958
	old_data_grads_norm = 5.4137
	sim_grads_norm = -0.0326
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5948
	data_grads_norm = 4.0462
	new_data_grads_norm = 5.5203
	old_data_grads_norm = 5.1286
	sim_grads_norm = 0.0735
-- Starting training on experience 83 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6365
	data_grads_norm = 3.6785
	new_data_grads_norm = 5.3080
	old_data_grads_norm = 4.4792
	sim_grads_norm = 0.0102
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7813
	data_grads_norm = 3.6814
	new_data_grads_norm = 4.9377
	old_data_grads_norm = 5.0537
	sim_grads_norm = 0.0297
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8001
	data_grads_norm = 3.8879
	new_data_grads_norm = 4.9596
	old_data_grads_norm = 5.1620
	sim_grads_norm = 0.0235
-- Starting training on experience 84 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5593
	data_grads_norm = 3.9439
	new_data_grads_norm = 4.6787
	old_data_grads_norm = 5.8650
	sim_grads_norm = 0.0832
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9760
	data_grads_norm = 2.5946
	new_data_grads_norm = 4.0509
	old_data_grads_norm = 3.1163
	sim_grads_norm = -0.0381
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5742
	data_grads_norm = 3.3641
	new_data_grads_norm = 4.4872
	old_data_grads_norm = 4.9971
	sim_grads_norm = -0.0079
-- Starting training on experience 85 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2098
	data_grads_norm = 2.9713
	new_data_grads_norm = 4.6180
	old_data_grads_norm = 3.8615
	sim_grads_norm = -0.0167
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5346
	data_grads_norm = 3.1983
	new_data_grads_norm = 4.8243
	old_data_grads_norm = 4.1853
	sim_grads_norm = -0.0019
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7161
	data_grads_norm = 4.1937
	new_data_grads_norm = 4.9557
	old_data_grads_norm = 6.3248
	sim_grads_norm = 0.0849
-- Starting training on experience 86 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4767
	data_grads_norm = 3.3723
	new_data_grads_norm = 4.9223
	old_data_grads_norm = 4.3418
	sim_grads_norm = 0.0139
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0655
	data_grads_norm = 3.7744
	new_data_grads_norm = 4.5767
	old_data_grads_norm = 5.0181
	sim_grads_norm = 0.0428
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3949
	data_grads_norm = 3.4758
	new_data_grads_norm = 5.1109
	old_data_grads_norm = 4.7164
	sim_grads_norm = 0.0266
-- Starting training on experience 87 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5880
	data_grads_norm = 4.2362
	new_data_grads_norm = 5.3484
	old_data_grads_norm = 5.9143
	sim_grads_norm = 0.0665
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5635
	data_grads_norm = 3.9833
	new_data_grads_norm = 5.1983
	old_data_grads_norm = 5.5719
	sim_grads_norm = 0.0071
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7924
	data_grads_norm = 3.3225
	new_data_grads_norm = 5.5123
	old_data_grads_norm = 4.6750
	sim_grads_norm = -0.0003
-- Starting training on experience 88 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3161
	data_grads_norm = 3.1529
	new_data_grads_norm = 4.1665
	old_data_grads_norm = 4.6686
	sim_grads_norm = 0.0108
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4777
	data_grads_norm = 3.0524
	new_data_grads_norm = 4.2665
	old_data_grads_norm = 4.4416
	sim_grads_norm = -0.0245
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1783
	data_grads_norm = 2.8821
	new_data_grads_norm = 4.3220
	old_data_grads_norm = 4.0442
	sim_grads_norm = -0.0528
-- Starting training on experience 89 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0759
	data_grads_norm = 3.1726
	new_data_grads_norm = 3.7153
	old_data_grads_norm = 3.8661
	sim_grads_norm = 0.0714
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8965
	data_grads_norm = 2.7835
	new_data_grads_norm = 3.8512
	old_data_grads_norm = 4.1361
	sim_grads_norm = -0.0297
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5644
	data_grads_norm = 3.6521
	new_data_grads_norm = 4.3789
	old_data_grads_norm = 5.4928
	sim_grads_norm = -0.0019
-- Starting training on experience 90 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7628
	data_grads_norm = 3.9912
	new_data_grads_norm = 4.6432
	old_data_grads_norm = 5.3722
	sim_grads_norm = 0.0153
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0725
	data_grads_norm = 3.1580
	new_data_grads_norm = 5.2339
	old_data_grads_norm = 4.6763
	sim_grads_norm = 0.0642
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0271
	data_grads_norm = 2.8720
	new_data_grads_norm = 4.5105
	old_data_grads_norm = 3.5481
	sim_grads_norm = -0.0247
-- Starting training on experience 91 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1345
	data_grads_norm = 3.6846
	new_data_grads_norm = 6.0987
	old_data_grads_norm = 4.0555
	sim_grads_norm = -0.0531
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9311
	data_grads_norm = 4.4126
	new_data_grads_norm = 6.3271
	old_data_grads_norm = 6.5570
	sim_grads_norm = 0.0318
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6138
	data_grads_norm = 3.3620
	new_data_grads_norm = 5.1945
	old_data_grads_norm = 4.2279
	sim_grads_norm = 0.0183
-- Starting training on experience 92 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9039
	data_grads_norm = 3.4110
	new_data_grads_norm = 4.6252
	old_data_grads_norm = 4.5170
	sim_grads_norm = 0.0218
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1350
	data_grads_norm = 3.7853
	new_data_grads_norm = 5.0622
	old_data_grads_norm = 5.2866
	sim_grads_norm = 0.0058
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6327
	data_grads_norm = 3.4567
	new_data_grads_norm = 4.9031
	old_data_grads_norm = 4.2278
	sim_grads_norm = -0.0317
-- Starting training on experience 93 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8661
	data_grads_norm = 3.5112
	new_data_grads_norm = 4.7307
	old_data_grads_norm = 4.6595
	sim_grads_norm = -0.0121
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1042
	data_grads_norm = 3.1359
	new_data_grads_norm = 4.7140
	old_data_grads_norm = 4.1185
	sim_grads_norm = -0.0259
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2241
	data_grads_norm = 3.6495
	new_data_grads_norm = 5.2436
	old_data_grads_norm = 4.4024
	sim_grads_norm = 0.1093
-- Starting training on experience 94 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8373
	data_grads_norm = 2.7946
	new_data_grads_norm = 3.6704
	old_data_grads_norm = 4.4076
	sim_grads_norm = -0.0538
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5872
	data_grads_norm = 3.8440
	new_data_grads_norm = 3.9563
	old_data_grads_norm = 6.2323
	sim_grads_norm = 0.0393
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6794
	data_grads_norm = 2.1993
	new_data_grads_norm = 3.6085
	old_data_grads_norm = 3.0484
	sim_grads_norm = -0.1071
-- Starting training on experience 95 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0038
	data_grads_norm = 3.3431
	new_data_grads_norm = 4.3003
	old_data_grads_norm = 4.6025
	sim_grads_norm = 0.0501
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7123
	data_grads_norm = 3.1248
	new_data_grads_norm = 4.2111
	old_data_grads_norm = 4.0329
	sim_grads_norm = 0.1128
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6665
	data_grads_norm = 3.2228
	new_data_grads_norm = 4.7034
	old_data_grads_norm = 4.4823
	sim_grads_norm = 0.0020
-- Starting training on experience 96 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1529
	data_grads_norm = 3.6060
	new_data_grads_norm = 4.8285
	old_data_grads_norm = 4.5387
	sim_grads_norm = 0.1334
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0253
	data_grads_norm = 3.3975
	new_data_grads_norm = 4.9754
	old_data_grads_norm = 4.5414
	sim_grads_norm = 0.0074
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4672
	data_grads_norm = 3.9975
	new_data_grads_norm = 4.9118
	old_data_grads_norm = 5.7855
	sim_grads_norm = 0.0071
-- Starting training on experience 97 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2798
	data_grads_norm = 3.4940
	new_data_grads_norm = 5.2298
	old_data_grads_norm = 3.8865
	sim_grads_norm = 0.0842
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4837
	data_grads_norm = 3.8058
	new_data_grads_norm = 4.6917
	old_data_grads_norm = 5.1060
	sim_grads_norm = 0.0540
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9332
	data_grads_norm = 2.7950
	new_data_grads_norm = 4.1849
	old_data_grads_norm = 3.5223
	sim_grads_norm = 0.0019
-- Starting training on experience 98 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1779
	data_grads_norm = 3.1606
	new_data_grads_norm = 4.6151
	old_data_grads_norm = 4.5353
	sim_grads_norm = 0.0502
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9699
	data_grads_norm = 3.2370
	new_data_grads_norm = 4.8147
	old_data_grads_norm = 4.8105
	sim_grads_norm = 0.0061
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4314
	data_grads_norm = 3.8686
	new_data_grads_norm = 5.1857
	old_data_grads_norm = 5.5226
	sim_grads_norm = -0.0409
-- Starting training on experience 99 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5312
	data_grads_norm = 3.6228
	new_data_grads_norm = 5.4898
	old_data_grads_norm = 4.8145
	sim_grads_norm = -0.0471
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4666
	data_grads_norm = 3.9275
	new_data_grads_norm = 5.6519
	old_data_grads_norm = 4.7409
	sim_grads_norm = 0.1092
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2436
	data_grads_norm = 3.8843
	new_data_grads_norm = 5.8654
	old_data_grads_norm = 4.6192
	sim_grads_norm = 0.0017
-- Starting training on experience 100 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4654
	data_grads_norm = 3.6067
	new_data_grads_norm = 4.8879
	old_data_grads_norm = 5.0896
	sim_grads_norm = 0.0456
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3830
	data_grads_norm = 3.5159
	new_data_grads_norm = 4.8805
	old_data_grads_norm = 4.7843
	sim_grads_norm = 0.0533
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2620
	data_grads_norm = 3.7939
	new_data_grads_norm = 4.9449
	old_data_grads_norm = 4.9626
	sim_grads_norm = 0.0035
-- Starting training on experience 101 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5418
	data_grads_norm = 3.5338
	new_data_grads_norm = 5.6511
	old_data_grads_norm = 4.0481
	sim_grads_norm = -0.0408
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4441
	data_grads_norm = 4.1051
	new_data_grads_norm = 6.5489
	old_data_grads_norm = 4.8744
	sim_grads_norm = 0.0331
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6022
	data_grads_norm = 4.1772
	new_data_grads_norm = 5.8721
	old_data_grads_norm = 4.0891
	sim_grads_norm = 0.0158
-- Starting training on experience 102 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6972
	data_grads_norm = 2.9198
	new_data_grads_norm = 4.7209
	old_data_grads_norm = 4.4023
	sim_grads_norm = -0.0900
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3380
	data_grads_norm = 3.5103
	new_data_grads_norm = 4.5671
	old_data_grads_norm = 4.9143
	sim_grads_norm = 0.0715
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7312
	data_grads_norm = 3.2294
	new_data_grads_norm = 4.3000
	old_data_grads_norm = 4.4275
	sim_grads_norm = 0.0956
-- Starting training on experience 103 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4690
	data_grads_norm = 2.9609
	new_data_grads_norm = 4.3606
	old_data_grads_norm = 4.4028
	sim_grads_norm = -0.0414
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1951
	data_grads_norm = 3.8324
	new_data_grads_norm = 4.2559
	old_data_grads_norm = 5.7563
	sim_grads_norm = -0.0309
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2600
	data_grads_norm = 3.2757
	new_data_grads_norm = 4.6099
	old_data_grads_norm = 5.3534
	sim_grads_norm = -0.0270
-- Starting training on experience 104 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4972
	data_grads_norm = 4.0748
	new_data_grads_norm = 4.9729
	old_data_grads_norm = 6.5336
	sim_grads_norm = 0.0491
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6977
	data_grads_norm = 3.8008
	new_data_grads_norm = 4.5228
	old_data_grads_norm = 5.1265
	sim_grads_norm = 0.1277
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1886
	data_grads_norm = 3.2065
	new_data_grads_norm = 4.3699
	old_data_grads_norm = 4.3033
	sim_grads_norm = -0.0226
-- Starting training on experience 105 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0882
	data_grads_norm = 3.2772
	new_data_grads_norm = 4.5061
	old_data_grads_norm = 4.3037
	sim_grads_norm = 0.0114
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9313
	data_grads_norm = 2.9814
	new_data_grads_norm = 4.0918
	old_data_grads_norm = 3.9702
	sim_grads_norm = -0.0762
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0272
	data_grads_norm = 3.3180
	new_data_grads_norm = 4.3012
	old_data_grads_norm = 4.5082
	sim_grads_norm = -0.0274
-- Starting training on experience 106 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2174
	data_grads_norm = 3.6338
	new_data_grads_norm = 5.2722
	old_data_grads_norm = 4.9860
	sim_grads_norm = 0.0099
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3815
	data_grads_norm = 3.7100
	new_data_grads_norm = 5.1051
	old_data_grads_norm = 4.8180
	sim_grads_norm = 0.0104
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1876
	data_grads_norm = 3.1738
	new_data_grads_norm = 5.0819
	old_data_grads_norm = 4.1171
	sim_grads_norm = -0.0327
-- Starting training on experience 107 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2563
	data_grads_norm = 3.0423
	new_data_grads_norm = 4.3109
	old_data_grads_norm = 4.4877
	sim_grads_norm = -0.0485
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4443
	data_grads_norm = 3.3625
	new_data_grads_norm = 4.5965
	old_data_grads_norm = 4.3629
	sim_grads_norm = 0.0291
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5986
	data_grads_norm = 3.3918
	new_data_grads_norm = 4.3290
	old_data_grads_norm = 4.7156
	sim_grads_norm = 0.0902
-- Starting training on experience 108 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4756
	data_grads_norm = 3.1297
	new_data_grads_norm = 4.5960
	old_data_grads_norm = 4.1388
	sim_grads_norm = 0.0649
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7470
	data_grads_norm = 3.3218
	new_data_grads_norm = 4.0566
	old_data_grads_norm = 5.2768
	sim_grads_norm = 0.0135
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0002
	data_grads_norm = 3.5684
	new_data_grads_norm = 4.2630
	old_data_grads_norm = 5.6705
	sim_grads_norm = 0.0218
-- Starting training on experience 109 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0049
	data_grads_norm = 3.9015
	new_data_grads_norm = 5.2497
	old_data_grads_norm = 5.0919
	sim_grads_norm = 0.0441
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6082
	data_grads_norm = 3.7252
	new_data_grads_norm = 4.8348
	old_data_grads_norm = 5.2403
	sim_grads_norm = -0.0061
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5837
	data_grads_norm = 3.8251
	new_data_grads_norm = 5.3716
	old_data_grads_norm = 4.3357
	sim_grads_norm = 0.1643
-- Starting training on experience 110 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0382
	data_grads_norm = 3.1631
	new_data_grads_norm = 4.3650
	old_data_grads_norm = 3.4134
	sim_grads_norm = 0.2784
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3258
	data_grads_norm = 3.2406
	new_data_grads_norm = 4.5040
	old_data_grads_norm = 3.8019
	sim_grads_norm = 0.0685
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5644
	data_grads_norm = 3.6178
	new_data_grads_norm = 4.1778
	old_data_grads_norm = 5.3484
	sim_grads_norm = -0.0276
-- Starting training on experience 111 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8824
	data_grads_norm = 3.3991
	new_data_grads_norm = 5.0961
	old_data_grads_norm = 3.9823
	sim_grads_norm = -0.0155
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2569
	data_grads_norm = 3.7102
	new_data_grads_norm = 5.2763
	old_data_grads_norm = 4.5256
	sim_grads_norm = -0.0554
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3311
	data_grads_norm = 3.8591
	new_data_grads_norm = 5.3018
	old_data_grads_norm = 4.7131
	sim_grads_norm = 0.0082
-- Starting training on experience 112 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3013
	data_grads_norm = 3.2914
	new_data_grads_norm = 4.2934
	old_data_grads_norm = 3.7680
	sim_grads_norm = -0.0182
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9348
	data_grads_norm = 2.7725
	new_data_grads_norm = 4.2649
	old_data_grads_norm = 4.2874
	sim_grads_norm = 0.0406
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1317
	data_grads_norm = 2.6943
	new_data_grads_norm = 4.0419
	old_data_grads_norm = 3.6659
	sim_grads_norm = 0.0660
-- Starting training on experience 113 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4426
	data_grads_norm = 3.2145
	new_data_grads_norm = 4.0192
	old_data_grads_norm = 4.2339
	sim_grads_norm = 0.0957
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4647
	data_grads_norm = 3.2819
	new_data_grads_norm = 3.9170
	old_data_grads_norm = 4.8699
	sim_grads_norm = 0.0434
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1418
	data_grads_norm = 2.8725
	new_data_grads_norm = 3.7751
	old_data_grads_norm = 4.6211
	sim_grads_norm = -0.0777
-- Starting training on experience 114 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9133
	data_grads_norm = 3.1488
	new_data_grads_norm = 4.3517
	old_data_grads_norm = 4.3497
	sim_grads_norm = -0.0203
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2611
	data_grads_norm = 3.8234
	new_data_grads_norm = 5.2684
	old_data_grads_norm = 5.3209
	sim_grads_norm = -0.0110
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9997
	data_grads_norm = 3.7808
	new_data_grads_norm = 4.5383
	old_data_grads_norm = 6.0782
	sim_grads_norm = 0.0591
-- Starting training on experience 115 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8342
	data_grads_norm = 3.0812
	new_data_grads_norm = 3.9773
	old_data_grads_norm = 4.2434
	sim_grads_norm = 0.0516
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8101
	data_grads_norm = 3.2007
	new_data_grads_norm = 4.2549
	old_data_grads_norm = 4.4206
	sim_grads_norm = 0.0479
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1882
	data_grads_norm = 3.4479
	new_data_grads_norm = 4.5241
	old_data_grads_norm = 5.0804
	sim_grads_norm = 0.0345
-- Starting training on experience 116 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8946
	data_grads_norm = 2.8819
	new_data_grads_norm = 4.0767
	old_data_grads_norm = 4.0014
	sim_grads_norm = -0.0440
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4897
	data_grads_norm = 3.6426
	new_data_grads_norm = 3.9380
	old_data_grads_norm = 6.2437
	sim_grads_norm = -0.0504
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9420
	data_grads_norm = 3.1435
	new_data_grads_norm = 4.3683
	old_data_grads_norm = 4.2416
	sim_grads_norm = -0.0086
-- Starting training on experience 117 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4402
	data_grads_norm = 3.8267
	new_data_grads_norm = 5.1629
	old_data_grads_norm = 5.4831
	sim_grads_norm = 0.0129
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5368
	data_grads_norm = 3.7216
	new_data_grads_norm = 4.9777
	old_data_grads_norm = 5.3844
	sim_grads_norm = 0.0029
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6042
	data_grads_norm = 4.0865
	new_data_grads_norm = 5.2089
	old_data_grads_norm = 5.5062
	sim_grads_norm = 0.0274
-- Starting training on experience 118 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0053
	data_grads_norm = 3.6780
	new_data_grads_norm = 5.2409
	old_data_grads_norm = 4.9979
	sim_grads_norm = 0.0364
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7571
	data_grads_norm = 3.0405
	new_data_grads_norm = 5.5966
	old_data_grads_norm = 3.1927
	sim_grads_norm = -0.0171
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7715
	data_grads_norm = 3.1492
	new_data_grads_norm = 5.6657
	old_data_grads_norm = 4.0542
	sim_grads_norm = -0.0328
-- Starting training on experience 119 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1438
	data_grads_norm = 3.7015
	new_data_grads_norm = 4.9993
	old_data_grads_norm = 4.7985
	sim_grads_norm = -0.0016
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3240
	data_grads_norm = 3.5383
	new_data_grads_norm = 5.3553
	old_data_grads_norm = 4.1589
	sim_grads_norm = -0.0171
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6981
	data_grads_norm = 3.8464
	new_data_grads_norm = 5.4620
	old_data_grads_norm = 4.3649
	sim_grads_norm = 0.1060
-- Starting training on experience 120 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5281
	data_grads_norm = 4.1475
	new_data_grads_norm = 5.5325
	old_data_grads_norm = 5.7037
	sim_grads_norm = 0.0376
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0474
	data_grads_norm = 3.3371
	new_data_grads_norm = 5.1624
	old_data_grads_norm = 3.8919
	sim_grads_norm = 0.0473
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3852
	data_grads_norm = 3.7934
	new_data_grads_norm = 4.9301
	old_data_grads_norm = 5.6520
	sim_grads_norm = 0.0199
-- Starting training on experience 121 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2384
	data_grads_norm = 4.3221
	new_data_grads_norm = 4.2894
	old_data_grads_norm = 6.8868
	sim_grads_norm = -0.0062
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0451
	data_grads_norm = 3.3047
	new_data_grads_norm = 4.5155
	old_data_grads_norm = 4.6631
	sim_grads_norm = -0.0601
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8970
	data_grads_norm = 3.3620
	new_data_grads_norm = 4.5829
	old_data_grads_norm = 4.5061
	sim_grads_norm = -0.0268
-- Starting training on experience 122 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6394
	data_grads_norm = 3.8907
	new_data_grads_norm = 5.0055
	old_data_grads_norm = 5.2505
	sim_grads_norm = 0.0729
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3982
	data_grads_norm = 3.4096
	new_data_grads_norm = 4.0577
	old_data_grads_norm = 4.6691
	sim_grads_norm = 0.0721
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1015
	data_grads_norm = 2.9445
	new_data_grads_norm = 4.5580
	old_data_grads_norm = 3.7639
	sim_grads_norm = -0.0067
-- Starting training on experience 123 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6809
	data_grads_norm = 3.7403
	new_data_grads_norm = 5.6540
	old_data_grads_norm = 4.3845
	sim_grads_norm = -0.0216
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6242
	data_grads_norm = 4.4413
	new_data_grads_norm = 6.0146
	old_data_grads_norm = 5.4302
	sim_grads_norm = 0.0340
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1434
	data_grads_norm = 3.7524
	new_data_grads_norm = 5.7254
	old_data_grads_norm = 4.7428
	sim_grads_norm = -0.0109
-- Starting training on experience 124 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5325
	data_grads_norm = 4.0384
	new_data_grads_norm = 4.9230
	old_data_grads_norm = 5.7031
	sim_grads_norm = 0.0613
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2350
	data_grads_norm = 3.4437
	new_data_grads_norm = 5.0208
	old_data_grads_norm = 4.7257
	sim_grads_norm = 0.0067
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9017
	data_grads_norm = 3.0428
	new_data_grads_norm = 5.0317
	old_data_grads_norm = 3.9325
	sim_grads_norm = 0.0335
-- Starting training on experience 125 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1931
	data_grads_norm = 3.2624
	new_data_grads_norm = 4.8585
	old_data_grads_norm = 4.9508
	sim_grads_norm = -0.0161
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4341
	data_grads_norm = 3.7322
	new_data_grads_norm = 4.9995
	old_data_grads_norm = 5.5826
	sim_grads_norm = -0.0100
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1544
	data_grads_norm = 3.7559
	new_data_grads_norm = 5.0697
	old_data_grads_norm = 5.5345
	sim_grads_norm = 0.0006
-- Starting training on experience 126 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4947
	data_grads_norm = 2.9962
	new_data_grads_norm = 4.0783
	old_data_grads_norm = 4.0346
	sim_grads_norm = 0.0230
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1283
	data_grads_norm = 3.2308
	new_data_grads_norm = 4.4233
	old_data_grads_norm = 4.2936
	sim_grads_norm = 0.0315
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7747
	data_grads_norm = 3.0897
	new_data_grads_norm = 4.0722
	old_data_grads_norm = 4.2893
	sim_grads_norm = 0.0230
-- Starting training on experience 127 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1364
	data_grads_norm = 3.5687
	new_data_grads_norm = 4.9702
	old_data_grads_norm = 5.5158
	sim_grads_norm = -0.0011
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8830
	data_grads_norm = 3.0644
	new_data_grads_norm = 4.3494
	old_data_grads_norm = 3.6285
	sim_grads_norm = 0.0239
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2151
	data_grads_norm = 3.8590
	new_data_grads_norm = 4.8094
	old_data_grads_norm = 5.9537
	sim_grads_norm = -0.0610
-- Starting training on experience 128 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3474
	data_grads_norm = 3.4007
	new_data_grads_norm = 4.6225
	old_data_grads_norm = 4.9350
	sim_grads_norm = 0.0244
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4548
	data_grads_norm = 3.8784
	new_data_grads_norm = 4.6370
	old_data_grads_norm = 5.2755
	sim_grads_norm = 0.0907
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2354
	data_grads_norm = 3.4871
	new_data_grads_norm = 4.7291
	old_data_grads_norm = 5.5294
	sim_grads_norm = -0.0325
-- Starting training on experience 129 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0581
	data_grads_norm = 3.6980
	new_data_grads_norm = 5.1445
	old_data_grads_norm = 4.4538
	sim_grads_norm = 0.0649
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8127
	data_grads_norm = 3.3634
	new_data_grads_norm = 4.9892
	old_data_grads_norm = 4.4983
	sim_grads_norm = 0.0567
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6069
	data_grads_norm = 3.4646
	new_data_grads_norm = 5.5890
	old_data_grads_norm = 3.9045
	sim_grads_norm = -0.0384
-- Starting training on experience 130 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1133
	data_grads_norm = 2.9889
	new_data_grads_norm = 5.1206
	old_data_grads_norm = 3.2730
	sim_grads_norm = 0.1254
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0636
	data_grads_norm = 3.1984
	new_data_grads_norm = 4.9054
	old_data_grads_norm = 3.9131
	sim_grads_norm = 0.1249
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0145
	data_grads_norm = 3.1056
	new_data_grads_norm = 4.7729
	old_data_grads_norm = 4.7528
	sim_grads_norm = -0.0787
-- Starting training on experience 131 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2617
	data_grads_norm = 2.9128
	new_data_grads_norm = 5.5349
	old_data_grads_norm = 2.8481
	sim_grads_norm = 0.0073
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5381
	data_grads_norm = 3.4483
	new_data_grads_norm = 5.0355
	old_data_grads_norm = 4.7866
	sim_grads_norm = -0.0032
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2121
	data_grads_norm = 3.3823
	new_data_grads_norm = 5.1006
	old_data_grads_norm = 3.9355
	sim_grads_norm = -0.0677
-- Starting training on experience 132 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1405
	data_grads_norm = 3.2865
	new_data_grads_norm = 4.4847
	old_data_grads_norm = 4.5126
	sim_grads_norm = -0.0083
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3486
	data_grads_norm = 3.3720
	new_data_grads_norm = 5.0233
	old_data_grads_norm = 4.3435
	sim_grads_norm = -0.0337
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3671
	data_grads_norm = 3.6482
	new_data_grads_norm = 4.4586
	old_data_grads_norm = 6.2793
	sim_grads_norm = 0.0462
-- Starting training on experience 133 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6261
	data_grads_norm = 3.8435
	new_data_grads_norm = 4.3563
	old_data_grads_norm = 6.1826
	sim_grads_norm = 0.1136
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0992
	data_grads_norm = 3.1373
	new_data_grads_norm = 4.3154
	old_data_grads_norm = 4.4912
	sim_grads_norm = -0.0002
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3634
	data_grads_norm = 3.7721
	new_data_grads_norm = 4.1927
	old_data_grads_norm = 5.2622
	sim_grads_norm = 0.1182
-- Starting training on experience 134 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1892
	data_grads_norm = 3.1549
	new_data_grads_norm = 4.6943
	old_data_grads_norm = 4.3887
	sim_grads_norm = -0.0940
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4384
	data_grads_norm = 3.8093
	new_data_grads_norm = 4.8767
	old_data_grads_norm = 4.7799
	sim_grads_norm = 0.1044
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3492
	data_grads_norm = 3.0829
	new_data_grads_norm = 4.8489
	old_data_grads_norm = 3.5803
	sim_grads_norm = 0.0675
-- Starting training on experience 135 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7364
	data_grads_norm = 2.8802
	new_data_grads_norm = 5.0021
	old_data_grads_norm = 3.4222
	sim_grads_norm = -0.0470
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3964
	data_grads_norm = 3.8750
	new_data_grads_norm = 4.7001
	old_data_grads_norm = 5.4379
	sim_grads_norm = 0.0070
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5090
	data_grads_norm = 3.9017
	new_data_grads_norm = 4.5220
	old_data_grads_norm = 6.0497
	sim_grads_norm = -0.0240
-- Starting training on experience 136 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2542
	data_grads_norm = 3.6676
	new_data_grads_norm = 5.2266
	old_data_grads_norm = 4.1462
	sim_grads_norm = 0.0499
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9667
	data_grads_norm = 4.1553
	new_data_grads_norm = 5.4427
	old_data_grads_norm = 5.2187
	sim_grads_norm = 0.0329
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3875
	data_grads_norm = 3.8420
	new_data_grads_norm = 4.2710
	old_data_grads_norm = 5.6533
	sim_grads_norm = 0.0332
-- Starting training on experience 137 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8715
	data_grads_norm = 3.7364
	new_data_grads_norm = 5.0306
	old_data_grads_norm = 5.7565
	sim_grads_norm = -0.0686
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7690
	data_grads_norm = 3.8910
	new_data_grads_norm = 5.2782
	old_data_grads_norm = 5.1520
	sim_grads_norm = 0.0246
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5066
	data_grads_norm = 3.5420
	new_data_grads_norm = 4.8549
	old_data_grads_norm = 5.3625
	sim_grads_norm = 0.0831
-- Starting training on experience 138 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7820
	data_grads_norm = 3.7394
	new_data_grads_norm = 6.4120
	old_data_grads_norm = 4.1294
	sim_grads_norm = -0.0700
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3465
	data_grads_norm = 4.5541
	new_data_grads_norm = 6.4559
	old_data_grads_norm = 5.5232
	sim_grads_norm = 0.0442
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2350
	data_grads_norm = 3.1562
	new_data_grads_norm = 5.8302
	old_data_grads_norm = 3.2574
	sim_grads_norm = 0.0211
-- Starting training on experience 139 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0925
	data_grads_norm = 3.2946
	new_data_grads_norm = 4.7786
	old_data_grads_norm = 3.6488
	sim_grads_norm = 0.0305
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2280
	data_grads_norm = 3.7599
	new_data_grads_norm = 4.5166
	old_data_grads_norm = 5.5849
	sim_grads_norm = -0.0035
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3619
	data_grads_norm = 3.9417
	new_data_grads_norm = 5.2280
	old_data_grads_norm = 5.1399
	sim_grads_norm = 0.0412
-- Starting training on experience 140 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2682
	data_grads_norm = 3.3334
	new_data_grads_norm = 5.0969
	old_data_grads_norm = 4.0375
	sim_grads_norm = 0.1106
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9968
	data_grads_norm = 3.3248
	new_data_grads_norm = 4.6605
	old_data_grads_norm = 5.4993
	sim_grads_norm = -0.0116
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6528
	data_grads_norm = 4.2974
	new_data_grads_norm = 5.1923
	old_data_grads_norm = 6.5102
	sim_grads_norm = -0.0238
-- Starting training on experience 141 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0250
	data_grads_norm = 3.5979
	new_data_grads_norm = 5.7145
	old_data_grads_norm = 4.3468
	sim_grads_norm = -0.0689
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6589
	data_grads_norm = 4.1890
	new_data_grads_norm = 5.9289
	old_data_grads_norm = 5.4811
	sim_grads_norm = 0.0589
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5773
	data_grads_norm = 3.9735
	new_data_grads_norm = 5.5160
	old_data_grads_norm = 4.9985
	sim_grads_norm = -0.0036
-- Starting training on experience 142 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5530
	data_grads_norm = 3.3675
	new_data_grads_norm = 4.3683
	old_data_grads_norm = 4.1746
	sim_grads_norm = 0.0997
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6518
	data_grads_norm = 3.3234
	new_data_grads_norm = 4.4203
	old_data_grads_norm = 4.4161
	sim_grads_norm = 0.0993
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5781
	data_grads_norm = 3.2195
	new_data_grads_norm = 3.8433
	old_data_grads_norm = 4.7238
	sim_grads_norm = -0.0315
-- Starting training on experience 143 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1927
	data_grads_norm = 3.5746
	new_data_grads_norm = 4.3183
	old_data_grads_norm = 4.5011
	sim_grads_norm = 0.0662
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1162
	data_grads_norm = 3.2859
	new_data_grads_norm = 4.1974
	old_data_grads_norm = 4.8813
	sim_grads_norm = -0.0161
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0205
	data_grads_norm = 3.3742
	new_data_grads_norm = 4.0105
	old_data_grads_norm = 5.1080
	sim_grads_norm = 0.0609
-- Starting training on experience 144 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3331
	data_grads_norm = 3.4340
	new_data_grads_norm = 4.6374
	old_data_grads_norm = 4.4426
	sim_grads_norm = 0.0396
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4564
	data_grads_norm = 3.2808
	new_data_grads_norm = 5.2650
	old_data_grads_norm = 4.3293
	sim_grads_norm = 0.0238
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0176
	data_grads_norm = 2.8944
	new_data_grads_norm = 4.5298
	old_data_grads_norm = 4.3299
	sim_grads_norm = -0.0546
-- Starting training on experience 145 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8544
	data_grads_norm = 3.4913
	new_data_grads_norm = 5.7924
	old_data_grads_norm = 4.3482
	sim_grads_norm = -0.0156
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7733
	data_grads_norm = 3.3422
	new_data_grads_norm = 5.2077
	old_data_grads_norm = 4.4360
	sim_grads_norm = 0.0093
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9413
	data_grads_norm = 3.5708
	new_data_grads_norm = 5.2657
	old_data_grads_norm = 4.1855
	sim_grads_norm = -0.0054
-- Starting training on experience 146 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3609
	data_grads_norm = 3.3944
	new_data_grads_norm = 4.7800
	old_data_grads_norm = 4.6850
	sim_grads_norm = -0.0062
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2762
	data_grads_norm = 3.7049
	new_data_grads_norm = 5.0802
	old_data_grads_norm = 4.2193
	sim_grads_norm = 0.1255
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4750
	data_grads_norm = 3.4278
	new_data_grads_norm = 4.6099
	old_data_grads_norm = 4.1824
	sim_grads_norm = -0.0477
-- Starting training on experience 147 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9019
	data_grads_norm = 2.7676
	new_data_grads_norm = 4.1693
	old_data_grads_norm = 3.6381
	sim_grads_norm = -0.0784
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8588
	data_grads_norm = 3.0058
	new_data_grads_norm = 4.6101
	old_data_grads_norm = 3.9943
	sim_grads_norm = 0.0407
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5167
	data_grads_norm = 3.5206
	new_data_grads_norm = 4.9882
	old_data_grads_norm = 4.7836
	sim_grads_norm = -0.0043
-- Starting training on experience 148 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3691
	data_grads_norm = 3.2751
	new_data_grads_norm = 4.9248
	old_data_grads_norm = 3.7266
	sim_grads_norm = 0.0206
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2934
	data_grads_norm = 3.4555
	new_data_grads_norm = 5.5432
	old_data_grads_norm = 4.7336
	sim_grads_norm = 0.1163
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2436
	data_grads_norm = 3.5730
	new_data_grads_norm = 4.7273
	old_data_grads_norm = 4.8366
	sim_grads_norm = 0.0932
-- Starting training on experience 149 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4672
	data_grads_norm = 3.2511
	new_data_grads_norm = 4.2577
	old_data_grads_norm = 4.7893
	sim_grads_norm = -0.0058
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4376
	data_grads_norm = 3.3847
	new_data_grads_norm = 4.3045
	old_data_grads_norm = 4.9777
	sim_grads_norm = -0.0784
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1962
	data_grads_norm = 3.0528
	new_data_grads_norm = 4.4832
	old_data_grads_norm = 4.4477
	sim_grads_norm = -0.0585
-- Starting training on experience 150 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7973
	data_grads_norm = 2.5636
	new_data_grads_norm = 4.4629
	old_data_grads_norm = 3.1678
	sim_grads_norm = -0.0833
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2419
	data_grads_norm = 3.5570
	new_data_grads_norm = 4.7727
	old_data_grads_norm = 4.9435
	sim_grads_norm = -0.0314
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8152
	data_grads_norm = 2.7124
	new_data_grads_norm = 4.7096
	old_data_grads_norm = 3.4082
	sim_grads_norm = -0.1031
-- Starting training on experience 151 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3018
	data_grads_norm = 3.4530
	new_data_grads_norm = 4.5887
	old_data_grads_norm = 5.0050
	sim_grads_norm = 0.0242
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4036
	data_grads_norm = 3.7247
	new_data_grads_norm = 5.1405
	old_data_grads_norm = 4.7485
	sim_grads_norm = 0.1138
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0345
	data_grads_norm = 2.8333
	new_data_grads_norm = 4.2457
	old_data_grads_norm = 3.6249
	sim_grads_norm = -0.0679
-- Starting training on experience 152 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1301
	data_grads_norm = 3.9754
	new_data_grads_norm = 5.4546
	old_data_grads_norm = 4.9908
	sim_grads_norm = 0.0880
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6188
	data_grads_norm = 3.6790
	new_data_grads_norm = 5.5850
	old_data_grads_norm = 4.7039
	sim_grads_norm = 0.0029
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7109
	data_grads_norm = 3.4659
	new_data_grads_norm = 6.0831
	old_data_grads_norm = 3.5489
	sim_grads_norm = 0.0254
-- Starting training on experience 153 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5518
	data_grads_norm = 3.2374
	new_data_grads_norm = 4.5074
	old_data_grads_norm = 4.4421
	sim_grads_norm = -0.0304
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7020
	data_grads_norm = 3.5128
	new_data_grads_norm = 4.4610
	old_data_grads_norm = 5.3115
	sim_grads_norm = 0.0925
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9209
	data_grads_norm = 2.7167
	new_data_grads_norm = 4.1599
	old_data_grads_norm = 3.3847
	sim_grads_norm = -0.0590
-- Starting training on experience 154 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5058
	data_grads_norm = 3.7356
	new_data_grads_norm = 5.4514
	old_data_grads_norm = 5.2078
	sim_grads_norm = -0.0168
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3254
	data_grads_norm = 3.7255
	new_data_grads_norm = 5.8970
	old_data_grads_norm = 5.1113
	sim_grads_norm = 0.0443
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3257
	data_grads_norm = 3.3582
	new_data_grads_norm = 5.4505
	old_data_grads_norm = 3.5708
	sim_grads_norm = 0.0411
-- Starting training on experience 155 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1102
	data_grads_norm = 4.6929
	new_data_grads_norm = 6.3201
	old_data_grads_norm = 5.4670
	sim_grads_norm = -0.0040
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1731
	data_grads_norm = 4.2397
	new_data_grads_norm = 6.0554
	old_data_grads_norm = 5.7433
	sim_grads_norm = -0.0183
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5817
	data_grads_norm = 3.6526
	new_data_grads_norm = 5.6014
	old_data_grads_norm = 4.2881
	sim_grads_norm = 0.0792
-- Starting training on experience 156 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9261
	data_grads_norm = 3.4625
	new_data_grads_norm = 4.6644
	old_data_grads_norm = 5.0915
	sim_grads_norm = -0.0248
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1568
	data_grads_norm = 3.3849
	new_data_grads_norm = 4.7081
	old_data_grads_norm = 4.3748
	sim_grads_norm = -0.0597
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7496
	data_grads_norm = 3.1367
	new_data_grads_norm = 4.8298
	old_data_grads_norm = 3.8971
	sim_grads_norm = -0.0095
-- Starting training on experience 157 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1248
	data_grads_norm = 3.0208
	new_data_grads_norm = 4.4895
	old_data_grads_norm = 3.7859
	sim_grads_norm = -0.0093
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6247
	data_grads_norm = 3.9460
	new_data_grads_norm = 5.2398
	old_data_grads_norm = 5.7736
	sim_grads_norm = -0.0413
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1911
	data_grads_norm = 3.2999
	new_data_grads_norm = 4.3490
	old_data_grads_norm = 3.8883
	sim_grads_norm = 0.0269
-- Starting training on experience 158 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6747
	data_grads_norm = 3.8861
	new_data_grads_norm = 4.7349
	old_data_grads_norm = 5.1649
	sim_grads_norm = 0.1022
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6059
	data_grads_norm = 3.3653
	new_data_grads_norm = 4.6326
	old_data_grads_norm = 4.5247
	sim_grads_norm = -0.0332
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0793
	data_grads_norm = 2.6592
	new_data_grads_norm = 4.5826
	old_data_grads_norm = 2.7456
	sim_grads_norm = -0.0955
-- Starting training on experience 159 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7193
	data_grads_norm = 3.7102
	new_data_grads_norm = 4.5627
	old_data_grads_norm = 4.9332
	sim_grads_norm = 0.0702
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2644
	data_grads_norm = 3.4073
	new_data_grads_norm = 4.4402
	old_data_grads_norm = 4.7243
	sim_grads_norm = -0.0045
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6840
	data_grads_norm = 3.4466
	new_data_grads_norm = 4.5320
	old_data_grads_norm = 4.9328
	sim_grads_norm = -0.0028
-- Starting training on experience 160 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5433
	data_grads_norm = 3.4707
	new_data_grads_norm = 4.6360
	old_data_grads_norm = 5.0294
	sim_grads_norm = -0.0509
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9959
	data_grads_norm = 3.4709
	new_data_grads_norm = 4.4285
	old_data_grads_norm = 5.6460
	sim_grads_norm = 0.0385
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0545
	data_grads_norm = 3.4482
	new_data_grads_norm = 4.7369
	old_data_grads_norm = 3.9778
	sim_grads_norm = 0.0059
-- Starting training on experience 161 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9746
	data_grads_norm = 3.2262
	new_data_grads_norm = 4.7861
	old_data_grads_norm = 4.1649
	sim_grads_norm = -0.0334
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0455
	data_grads_norm = 3.5497
	new_data_grads_norm = 4.9163
	old_data_grads_norm = 4.3164
	sim_grads_norm = 0.0876
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0105
	data_grads_norm = 3.3480
	new_data_grads_norm = 5.1690
	old_data_grads_norm = 3.9544
	sim_grads_norm = -0.0148
-- Starting training on experience 162 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1468
	data_grads_norm = 2.9266
	new_data_grads_norm = 4.6735
	old_data_grads_norm = 3.5947
	sim_grads_norm = 0.0166
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3392
	data_grads_norm = 3.2952
	new_data_grads_norm = 4.9449
	old_data_grads_norm = 4.2382
	sim_grads_norm = 0.0049
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2937
	data_grads_norm = 3.2868
	new_data_grads_norm = 5.4021
	old_data_grads_norm = 4.6957
	sim_grads_norm = 0.0299
-- Starting training on experience 163 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2602
	data_grads_norm = 3.6280
	new_data_grads_norm = 4.8830
	old_data_grads_norm = 4.9559
	sim_grads_norm = 0.0735
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9148
	data_grads_norm = 3.3172
	new_data_grads_norm = 4.3118
	old_data_grads_norm = 5.0474
	sim_grads_norm = -0.0341
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9419
	data_grads_norm = 3.4409
	new_data_grads_norm = 4.7267
	old_data_grads_norm = 4.3716
	sim_grads_norm = 0.0523
-- Starting training on experience 164 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7230
	data_grads_norm = 3.3913
	new_data_grads_norm = 5.7175
	old_data_grads_norm = 4.5964
	sim_grads_norm = -0.0437
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0761
	data_grads_norm = 4.2312
	new_data_grads_norm = 6.3833
	old_data_grads_norm = 5.7006
	sim_grads_norm = 0.0700
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0025
	data_grads_norm = 3.7828
	new_data_grads_norm = 6.3016
	old_data_grads_norm = 4.5599
	sim_grads_norm = -0.0429
-- Starting training on experience 165 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4858
	data_grads_norm = 4.1265
	new_data_grads_norm = 5.8251
	old_data_grads_norm = 5.3641
	sim_grads_norm = -0.0101
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1509
	data_grads_norm = 5.2778
	new_data_grads_norm = 6.5034
	old_data_grads_norm = 6.6618
	sim_grads_norm = 0.0750
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3301
	data_grads_norm = 3.8076
	new_data_grads_norm = 5.6024
	old_data_grads_norm = 4.9925
	sim_grads_norm = -0.0744
-- Starting training on experience 166 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2977
	data_grads_norm = 4.2726
	new_data_grads_norm = 5.6653
	old_data_grads_norm = 6.1016
	sim_grads_norm = 0.0196
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1402
	data_grads_norm = 3.2974
	new_data_grads_norm = 5.2609
	old_data_grads_norm = 4.2011
	sim_grads_norm = 0.0339
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6344
	data_grads_norm = 3.7144
	new_data_grads_norm = 5.1753
	old_data_grads_norm = 5.0568
	sim_grads_norm = 0.0365
-- Starting training on experience 167 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2716
	data_grads_norm = 3.3766
	new_data_grads_norm = 5.0197
	old_data_grads_norm = 4.5507
	sim_grads_norm = 0.0075
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9972
	data_grads_norm = 3.4600
	new_data_grads_norm = 5.0249
	old_data_grads_norm = 4.6363
	sim_grads_norm = -0.0434
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7142
	data_grads_norm = 4.1444
	new_data_grads_norm = 4.8072
	old_data_grads_norm = 6.3007
	sim_grads_norm = 0.0400
-- Starting training on experience 168 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2603
	data_grads_norm = 3.9793
	new_data_grads_norm = 4.6903
	old_data_grads_norm = 6.0589
	sim_grads_norm = 0.0441
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3827
	data_grads_norm = 3.6155
	new_data_grads_norm = 4.8569
	old_data_grads_norm = 5.1491
	sim_grads_norm = 0.0831
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8810
	data_grads_norm = 3.1848
	new_data_grads_norm = 4.3354
	old_data_grads_norm = 3.8233
	sim_grads_norm = -0.0074
-- Starting training on experience 169 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8809
	data_grads_norm = 4.2309
	new_data_grads_norm = 5.5421
	old_data_grads_norm = 5.7468
	sim_grads_norm = -0.0147
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8465
	data_grads_norm = 3.0573
	new_data_grads_norm = 5.3005
	old_data_grads_norm = 3.0285
	sim_grads_norm = 0.0781
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4115
	data_grads_norm = 3.6357
	new_data_grads_norm = 5.1140
	old_data_grads_norm = 4.6153
	sim_grads_norm = 0.0009
-- Starting training on experience 170 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6125
	data_grads_norm = 3.5045
	new_data_grads_norm = 5.8747
	old_data_grads_norm = 3.7103
	sim_grads_norm = 0.0666
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8611
	data_grads_norm = 4.3611
	new_data_grads_norm = 5.7117
	old_data_grads_norm = 4.9872
	sim_grads_norm = 0.0980
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8179
	data_grads_norm = 3.7329
	new_data_grads_norm = 5.6400
	old_data_grads_norm = 4.2139
	sim_grads_norm = 0.0302
-- Starting training on experience 171 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4697
	data_grads_norm = 3.7718
	new_data_grads_norm = 5.6010
	old_data_grads_norm = 4.5579
	sim_grads_norm = -0.0035
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2609
	data_grads_norm = 3.0065
	new_data_grads_norm = 5.5246
	old_data_grads_norm = 3.4609
	sim_grads_norm = 0.0186
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1769
	data_grads_norm = 3.3886
	new_data_grads_norm = 5.4450
	old_data_grads_norm = 4.6158
	sim_grads_norm = -0.0132
-- Starting training on experience 172 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4019
	data_grads_norm = 3.6002
	new_data_grads_norm = 5.2278
	old_data_grads_norm = 4.7419
	sim_grads_norm = 0.0082
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6899
	data_grads_norm = 4.4599
	new_data_grads_norm = 5.5200
	old_data_grads_norm = 5.5282
	sim_grads_norm = -0.0406
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6827
	data_grads_norm = 3.7561
	new_data_grads_norm = 5.4108
	old_data_grads_norm = 4.4584
	sim_grads_norm = 0.0225
-- Starting training on experience 173 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3306
	data_grads_norm = 3.8067
	new_data_grads_norm = 5.3805
	old_data_grads_norm = 4.8506
	sim_grads_norm = -0.0099
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6274
	data_grads_norm = 3.9512
	new_data_grads_norm = 5.2154
	old_data_grads_norm = 5.6275
	sim_grads_norm = -0.0246
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8740
	data_grads_norm = 3.5777
	new_data_grads_norm = 5.1352
	old_data_grads_norm = 4.6663
	sim_grads_norm = 0.0277
-- Starting training on experience 174 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8638
	data_grads_norm = 3.9952
	new_data_grads_norm = 5.3533
	old_data_grads_norm = 5.3553
	sim_grads_norm = 0.0443
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3128
	data_grads_norm = 2.8588
	new_data_grads_norm = 4.4865
	old_data_grads_norm = 4.2628
	sim_grads_norm = 0.0526
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3757
	data_grads_norm = 3.0117
	new_data_grads_norm = 4.4573
	old_data_grads_norm = 4.0127
	sim_grads_norm = -0.0037
-- Starting training on experience 175 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6501
	data_grads_norm = 3.5764
	new_data_grads_norm = 4.6191
	old_data_grads_norm = 4.7216
	sim_grads_norm = 0.0872
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2259
	data_grads_norm = 4.1201
	new_data_grads_norm = 4.5895
	old_data_grads_norm = 5.9338
	sim_grads_norm = 0.0980
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5583
	data_grads_norm = 3.0825
	new_data_grads_norm = 3.9204
	old_data_grads_norm = 4.7603
	sim_grads_norm = 0.0463
-- Starting training on experience 176 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4593
	data_grads_norm = 3.5578
	new_data_grads_norm = 4.0612
	old_data_grads_norm = 5.0597
	sim_grads_norm = -0.0133
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2364
	data_grads_norm = 3.2180
	new_data_grads_norm = 4.9584
	old_data_grads_norm = 4.4406
	sim_grads_norm = 0.0530
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1798
	data_grads_norm = 3.8066
	new_data_grads_norm = 4.6449
	old_data_grads_norm = 4.7235
	sim_grads_norm = 0.0861
-- Starting training on experience 177 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6264
	data_grads_norm = 3.7187
	new_data_grads_norm = 6.0111
	old_data_grads_norm = 4.5991
	sim_grads_norm = 0.0738
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4428
	data_grads_norm = 3.7186
	new_data_grads_norm = 5.3360
	old_data_grads_norm = 5.8964
	sim_grads_norm = 0.0397
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1167
	data_grads_norm = 3.1581
	new_data_grads_norm = 4.7463
	old_data_grads_norm = 3.8009
	sim_grads_norm = 0.0633
-- Starting training on experience 178 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5994
	data_grads_norm = 3.1889
	new_data_grads_norm = 4.3138
	old_data_grads_norm = 3.0478
	sim_grads_norm = 0.0561
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8773
	data_grads_norm = 3.3952
	new_data_grads_norm = 4.8543
	old_data_grads_norm = 3.5680
	sim_grads_norm = 0.0586
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2090
	data_grads_norm = 3.7837
	new_data_grads_norm = 5.5075
	old_data_grads_norm = 5.5590
	sim_grads_norm = 0.1260
-- Starting training on experience 179 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3134
	data_grads_norm = 3.6608
	new_data_grads_norm = 4.1467
	old_data_grads_norm = 6.4208
	sim_grads_norm = -0.0595
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0671
	data_grads_norm = 3.4260
	new_data_grads_norm = 4.7210
	old_data_grads_norm = 4.4331
	sim_grads_norm = 0.0593
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1542
	data_grads_norm = 3.3872
	new_data_grads_norm = 4.0930
	old_data_grads_norm = 5.3021
	sim_grads_norm = -0.0866
-- Starting training on experience 180 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3962
	data_grads_norm = 3.2966
	new_data_grads_norm = 4.1385
	old_data_grads_norm = 4.8717
	sim_grads_norm = 0.0130
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3005
	data_grads_norm = 3.0288
	new_data_grads_norm = 4.2605
	old_data_grads_norm = 4.2516
	sim_grads_norm = -0.0340
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4236
	data_grads_norm = 3.1228
	new_data_grads_norm = 4.3790
	old_data_grads_norm = 4.4349
	sim_grads_norm = 0.0594
-- Starting training on experience 181 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0205
	data_grads_norm = 3.9541
	new_data_grads_norm = 4.5034
	old_data_grads_norm = 6.4710
	sim_grads_norm = -0.0348
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4290
	data_grads_norm = 3.4561
	new_data_grads_norm = 4.4019
	old_data_grads_norm = 5.2190
	sim_grads_norm = 0.0290
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5624
	data_grads_norm = 3.1595
	new_data_grads_norm = 4.3158
	old_data_grads_norm = 4.0111
	sim_grads_norm = 0.0600
-- Starting training on experience 182 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3179
	data_grads_norm = 3.3042
	new_data_grads_norm = 5.3363
	old_data_grads_norm = 4.4525
	sim_grads_norm = -0.0234
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9681
	data_grads_norm = 4.8178
	new_data_grads_norm = 5.1711
	old_data_grads_norm = 7.8564
	sim_grads_norm = 0.1125
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2015
	data_grads_norm = 3.0570
	new_data_grads_norm = 4.6758
	old_data_grads_norm = 4.3531
	sim_grads_norm = 0.0343
-- Starting training on experience 183 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2046
	data_grads_norm = 3.3503
	new_data_grads_norm = 4.9061
	old_data_grads_norm = 4.5062
	sim_grads_norm = -0.0598
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0593
	data_grads_norm = 3.5844
	new_data_grads_norm = 5.0178
	old_data_grads_norm = 4.2357
	sim_grads_norm = 0.0133
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1551
	data_grads_norm = 3.6862
	new_data_grads_norm = 5.2003
	old_data_grads_norm = 4.7920
	sim_grads_norm = -0.0034
-- Starting training on experience 184 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8071
	data_grads_norm = 3.2121
	new_data_grads_norm = 5.1000
	old_data_grads_norm = 3.9216
	sim_grads_norm = 0.0971
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1284
	data_grads_norm = 3.4856
	new_data_grads_norm = 5.1405
	old_data_grads_norm = 4.7329
	sim_grads_norm = 0.1048
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6610
	data_grads_norm = 3.1623
	new_data_grads_norm = 4.7134
	old_data_grads_norm = 3.4707
	sim_grads_norm = -0.0372
-- Starting training on experience 185 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9732
	data_grads_norm = 3.3407
	new_data_grads_norm = 4.8182
	old_data_grads_norm = 4.4361
	sim_grads_norm = 0.0061
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9925
	data_grads_norm = 3.2606
	new_data_grads_norm = 4.6865
	old_data_grads_norm = 4.2140
	sim_grads_norm = 0.1184
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0210
	data_grads_norm = 3.4393
	new_data_grads_norm = 4.5688
	old_data_grads_norm = 4.4384
	sim_grads_norm = 0.0674
-- Starting training on experience 186 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8948
	data_grads_norm = 3.7766
	new_data_grads_norm = 5.0718
	old_data_grads_norm = 5.5843
	sim_grads_norm = 0.0119
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6234
	data_grads_norm = 3.5500
	new_data_grads_norm = 4.9885
	old_data_grads_norm = 4.3758
	sim_grads_norm = 0.0602
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5652
	data_grads_norm = 3.5139
	new_data_grads_norm = 5.1310
	old_data_grads_norm = 4.3972
	sim_grads_norm = 0.0581
-- Starting training on experience 187 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9367
	data_grads_norm = 3.8006
	new_data_grads_norm = 5.9079
	old_data_grads_norm = 4.2050
	sim_grads_norm = 0.0493
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5582
	data_grads_norm = 3.5743
	new_data_grads_norm = 5.3556
	old_data_grads_norm = 5.3157
	sim_grads_norm = 0.0388
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9847
	data_grads_norm = 3.8089
	new_data_grads_norm = 4.9816
	old_data_grads_norm = 5.4948
	sim_grads_norm = -0.0416
-- Starting training on experience 188 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3463
	data_grads_norm = 4.5589
	new_data_grads_norm = 6.9673
	old_data_grads_norm = 3.7219
	sim_grads_norm = 0.0886
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1347
	data_grads_norm = 4.4825
	new_data_grads_norm = 5.8177
	old_data_grads_norm = 5.8071
	sim_grads_norm = 0.0041
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4980
	data_grads_norm = 4.7160
	new_data_grads_norm = 5.8889
	old_data_grads_norm = 5.5610
	sim_grads_norm = -0.0138
-- Starting training on experience 189 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1923
	data_grads_norm = 3.9870
	new_data_grads_norm = 5.5503
	old_data_grads_norm = 5.8509
	sim_grads_norm = -0.0226
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4036
	data_grads_norm = 4.1145
	new_data_grads_norm = 6.7301
	old_data_grads_norm = 4.4243
	sim_grads_norm = 0.0368
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1764
	data_grads_norm = 3.8900
	new_data_grads_norm = 6.0781
	old_data_grads_norm = 4.0626
	sim_grads_norm = 0.0099
-- Starting training on experience 190 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4670
	data_grads_norm = 3.1880
	new_data_grads_norm = 4.8763
	old_data_grads_norm = 3.8806
	sim_grads_norm = 0.0749
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7553
	data_grads_norm = 2.9781
	new_data_grads_norm = 4.2974
	old_data_grads_norm = 4.0210
	sim_grads_norm = 0.0490
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2799
	data_grads_norm = 3.3321
	new_data_grads_norm = 4.9657
	old_data_grads_norm = 4.2737
	sim_grads_norm = 0.0163
-- Starting training on experience 191 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0683
	data_grads_norm = 3.2026
	new_data_grads_norm = 4.5414
	old_data_grads_norm = 3.8871
	sim_grads_norm = -0.0097
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8791
	data_grads_norm = 3.1116
	new_data_grads_norm = 4.6507
	old_data_grads_norm = 4.0511
	sim_grads_norm = 0.0001
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4453
	data_grads_norm = 3.7850
	new_data_grads_norm = 4.8663
	old_data_grads_norm = 5.2152
	sim_grads_norm = 0.0639
-- Starting training on experience 192 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1212
	data_grads_norm = 3.1831
	new_data_grads_norm = 4.4615
	old_data_grads_norm = 4.1908
	sim_grads_norm = -0.0317
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0173
	data_grads_norm = 2.9794
	new_data_grads_norm = 4.4397
	old_data_grads_norm = 3.4669
	sim_grads_norm = -0.0550
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2744
	data_grads_norm = 3.7223
	new_data_grads_norm = 4.4858
	old_data_grads_norm = 5.2822
	sim_grads_norm = -0.0116
-- Starting training on experience 193 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8317
	data_grads_norm = 3.1396
	new_data_grads_norm = 5.3665
	old_data_grads_norm = 3.4932
	sim_grads_norm = 0.0042
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6967
	data_grads_norm = 3.0712
	new_data_grads_norm = 4.6193
	old_data_grads_norm = 4.4834
	sim_grads_norm = 0.0521
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8498
	data_grads_norm = 3.1746
	new_data_grads_norm = 5.4875
	old_data_grads_norm = 4.5699
	sim_grads_norm = -0.0231
-- Starting training on experience 194 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4075
	data_grads_norm = 2.8337
	new_data_grads_norm = 5.4412
	old_data_grads_norm = 3.0245
	sim_grads_norm = -0.0721
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6800
	data_grads_norm = 3.8433
	new_data_grads_norm = 5.6839
	old_data_grads_norm = 5.4628
	sim_grads_norm = -0.0285
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3791
	data_grads_norm = 3.9674
	new_data_grads_norm = 6.0208
	old_data_grads_norm = 4.4228
	sim_grads_norm = 0.0157
-- Starting training on experience 195 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2605
	data_grads_norm = 3.3948
	new_data_grads_norm = 5.0777
	old_data_grads_norm = 4.5492
	sim_grads_norm = 0.0136
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1076
	data_grads_norm = 3.5330
	new_data_grads_norm = 4.9226
	old_data_grads_norm = 4.2663
	sim_grads_norm = 0.0143
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7014
	data_grads_norm = 3.9601
	new_data_grads_norm = 6.6228
	old_data_grads_norm = 5.8346
	sim_grads_norm = 0.0310
-- Starting training on experience 196 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0711
	data_grads_norm = 3.4959
	new_data_grads_norm = 5.5793
	old_data_grads_norm = 4.0680
	sim_grads_norm = 0.0693
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9159
	data_grads_norm = 3.4137
	new_data_grads_norm = 4.8056
	old_data_grads_norm = 4.2526
	sim_grads_norm = -0.0366
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1669
	data_grads_norm = 3.7273
	new_data_grads_norm = 6.1186
	old_data_grads_norm = 4.4149
	sim_grads_norm = 0.0097
-- Starting training on experience 197 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8846
	data_grads_norm = 3.0596
	new_data_grads_norm = 5.2541
	old_data_grads_norm = 3.2732
	sim_grads_norm = 0.0299
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1631
	data_grads_norm = 3.1036
	new_data_grads_norm = 5.2141
	old_data_grads_norm = 3.8550
	sim_grads_norm = 0.0026
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2144
	data_grads_norm = 3.4910
	new_data_grads_norm = 4.9746
	old_data_grads_norm = 4.5677
	sim_grads_norm = 0.0527
-- Starting training on experience 198 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4412
	data_grads_norm = 3.7011
	new_data_grads_norm = 6.0251
	old_data_grads_norm = 5.0076
	sim_grads_norm = -0.0306
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6888
	data_grads_norm = 3.9406
	new_data_grads_norm = 5.8473
	old_data_grads_norm = 5.1093
	sim_grads_norm = 0.0778
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6470
	data_grads_norm = 3.2523
	new_data_grads_norm = 5.0206
	old_data_grads_norm = 3.9884
	sim_grads_norm = -0.0255
-- Starting training on experience 199 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8152
	data_grads_norm = 3.1991
	new_data_grads_norm = 5.2037
	old_data_grads_norm = 3.2972
	sim_grads_norm = -0.0287
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2217
	data_grads_norm = 3.8708
	new_data_grads_norm = 6.2024
	old_data_grads_norm = 4.9398
	sim_grads_norm = -0.0460
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0002
	data_grads_norm = 3.7000
	new_data_grads_norm = 6.1716
	old_data_grads_norm = 3.5913
	sim_grads_norm = 0.0373
-- Starting training on experience 200 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4808
	data_grads_norm = 4.1756
	new_data_grads_norm = 4.7392
	old_data_grads_norm = 6.1877
	sim_grads_norm = 0.0619
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1110
	data_grads_norm = 3.5027
	new_data_grads_norm = 4.3678
	old_data_grads_norm = 4.7727
	sim_grads_norm = 0.0967
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2664
	data_grads_norm = 3.3155
	new_data_grads_norm = 4.0609
	old_data_grads_norm = 5.3247
	sim_grads_norm = -0.0389
-- Starting training on experience 201 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5115
	data_grads_norm = 3.7175
	new_data_grads_norm = 6.2767
	old_data_grads_norm = 4.5333
	sim_grads_norm = -0.0931
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3557
	data_grads_norm = 4.0888
	new_data_grads_norm = 6.7187
	old_data_grads_norm = 5.3712
	sim_grads_norm = -0.0376
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5626
	data_grads_norm = 4.5305
	new_data_grads_norm = 6.9266
	old_data_grads_norm = 5.2307
	sim_grads_norm = 0.0433
-- Starting training on experience 202 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2894
	data_grads_norm = 3.9924
	new_data_grads_norm = 4.5964
	old_data_grads_norm = 5.2078
	sim_grads_norm = 0.0388
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3254
	data_grads_norm = 2.9568
	new_data_grads_norm = 4.2096
	old_data_grads_norm = 4.4021
	sim_grads_norm = -0.0475
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0944
	data_grads_norm = 2.8851
	new_data_grads_norm = 4.2574
	old_data_grads_norm = 3.9530
	sim_grads_norm = 0.0791
-- Starting training on experience 203 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7984
	data_grads_norm = 3.1626
	new_data_grads_norm = 5.0312
	old_data_grads_norm = 4.3262
	sim_grads_norm = -0.0281
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8489
	data_grads_norm = 3.3185
	new_data_grads_norm = 5.1898
	old_data_grads_norm = 3.8450
	sim_grads_norm = 0.0086
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9165
	data_grads_norm = 3.2687
	new_data_grads_norm = 5.2338
	old_data_grads_norm = 3.4181
	sim_grads_norm = 0.0565
-- Starting training on experience 204 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2458
	data_grads_norm = 4.2505
	new_data_grads_norm = 6.6826
	old_data_grads_norm = 6.8420
	sim_grads_norm = -0.0102
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2943
	data_grads_norm = 3.6541
	new_data_grads_norm = 6.0871
	old_data_grads_norm = 5.4968
	sim_grads_norm = -0.0007
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3225
	data_grads_norm = 3.9538
	new_data_grads_norm = 6.5939
	old_data_grads_norm = 5.0949
	sim_grads_norm = 0.0708
-- Starting training on experience 205 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5942
	data_grads_norm = 2.8527
	new_data_grads_norm = 4.6152
	old_data_grads_norm = 3.4835
	sim_grads_norm = -0.0291
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7709
	data_grads_norm = 3.1282
	new_data_grads_norm = 4.7188
	old_data_grads_norm = 4.6540
	sim_grads_norm = 0.0371
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3420
	data_grads_norm = 3.5801
	new_data_grads_norm = 4.5493
	old_data_grads_norm = 5.2824
	sim_grads_norm = 0.1286
-- Starting training on experience 206 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3631
	data_grads_norm = 3.0455
	new_data_grads_norm = 5.3774
	old_data_grads_norm = 3.3617
	sim_grads_norm = -0.0532
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9178
	data_grads_norm = 4.1813
	new_data_grads_norm = 6.0119
	old_data_grads_norm = 6.3286
	sim_grads_norm = 0.0154
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6225
	data_grads_norm = 4.2560
	new_data_grads_norm = 5.7517
	old_data_grads_norm = 6.6214
	sim_grads_norm = 0.0424
-- Starting training on experience 207 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8044
	data_grads_norm = 3.3990
	new_data_grads_norm = 5.4129
	old_data_grads_norm = 4.5177
	sim_grads_norm = 0.0114
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9708
	data_grads_norm = 3.9037
	new_data_grads_norm = 4.4283
	old_data_grads_norm = 6.3009
	sim_grads_norm = 0.0297
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3066
	data_grads_norm = 3.9838
	new_data_grads_norm = 5.3157
	old_data_grads_norm = 4.4720
	sim_grads_norm = 0.0469
-- Starting training on experience 208 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3833
	data_grads_norm = 3.7306
	new_data_grads_norm = 5.3662
	old_data_grads_norm = 4.4929
	sim_grads_norm = -0.0136
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5099
	data_grads_norm = 4.4591
	new_data_grads_norm = 5.2152
	old_data_grads_norm = 6.5980
	sim_grads_norm = -0.0315
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9613
	data_grads_norm = 4.0950
	new_data_grads_norm = 6.0947
	old_data_grads_norm = 4.9089
	sim_grads_norm = 0.0738
-- Starting training on experience 209 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4407
	data_grads_norm = 4.6617
	new_data_grads_norm = 4.7156
	old_data_grads_norm = 6.6273
	sim_grads_norm = 0.0878
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1308
	data_grads_norm = 3.5294
	new_data_grads_norm = 5.2636
	old_data_grads_norm = 4.8985
	sim_grads_norm = -0.0816
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4641
	data_grads_norm = 3.7778
	new_data_grads_norm = 5.0579
	old_data_grads_norm = 4.6594
	sim_grads_norm = 0.1139
-- Starting training on experience 210 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7227
	data_grads_norm = 3.0045
	new_data_grads_norm = 4.9293
	old_data_grads_norm = 3.6904
	sim_grads_norm = 0.0299
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9751
	data_grads_norm = 3.2106
	new_data_grads_norm = 4.7503
	old_data_grads_norm = 5.0905
	sim_grads_norm = -0.0202
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3588
	data_grads_norm = 3.4673
	new_data_grads_norm = 5.0066
	old_data_grads_norm = 4.7968
	sim_grads_norm = -0.0109
-- Starting training on experience 211 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2355
	data_grads_norm = 3.5736
	new_data_grads_norm = 4.6961
	old_data_grads_norm = 4.7668
	sim_grads_norm = 0.0216
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0989
	data_grads_norm = 3.4826
	new_data_grads_norm = 4.4877
	old_data_grads_norm = 5.2912
	sim_grads_norm = -0.0021
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1598
	data_grads_norm = 3.3676
	new_data_grads_norm = 5.0483
	old_data_grads_norm = 4.7516
	sim_grads_norm = -0.0098
-- Starting training on experience 212 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6966
	data_grads_norm = 3.1852
	new_data_grads_norm = 4.9311
	old_data_grads_norm = 4.0777
	sim_grads_norm = -0.0165
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0314
	data_grads_norm = 3.5048
	new_data_grads_norm = 4.4577
	old_data_grads_norm = 5.4772
	sim_grads_norm = -0.0044
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0657
	data_grads_norm = 3.5840
	new_data_grads_norm = 5.1344
	old_data_grads_norm = 5.0921
	sim_grads_norm = -0.0429
-- Starting training on experience 213 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2567
	data_grads_norm = 3.3949
	new_data_grads_norm = 5.6712
	old_data_grads_norm = 3.9680
	sim_grads_norm = 0.0046
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0107
	data_grads_norm = 3.2286
	new_data_grads_norm = 5.4636
	old_data_grads_norm = 3.6440
	sim_grads_norm = -0.0243
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6910
	data_grads_norm = 4.0793
	new_data_grads_norm = 5.9114
	old_data_grads_norm = 5.7699
	sim_grads_norm = 0.0485
-- Starting training on experience 214 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0649
	data_grads_norm = 3.3975
	new_data_grads_norm = 5.3435
	old_data_grads_norm = 4.2878
	sim_grads_norm = 0.0272
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2345
	data_grads_norm = 3.1097
	new_data_grads_norm = 4.8711
	old_data_grads_norm = 3.6750
	sim_grads_norm = 0.0936
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2924
	data_grads_norm = 3.9245
	new_data_grads_norm = 4.6943
	old_data_grads_norm = 5.7377
	sim_grads_norm = -0.0457
-- Starting training on experience 215 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3215
	data_grads_norm = 3.5015
	new_data_grads_norm = 5.4790
	old_data_grads_norm = 4.4787
	sim_grads_norm = 0.0884
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0579
	data_grads_norm = 3.0168
	new_data_grads_norm = 5.4865
	old_data_grads_norm = 3.5170
	sim_grads_norm = -0.0112
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5970
	data_grads_norm = 3.9399
	new_data_grads_norm = 5.5482
	old_data_grads_norm = 4.7837
	sim_grads_norm = 0.0218
-- Starting training on experience 216 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9346
	data_grads_norm = 3.5505
	new_data_grads_norm = 5.3261
	old_data_grads_norm = 4.5929
	sim_grads_norm = 0.0152
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9739
	data_grads_norm = 3.9419
	new_data_grads_norm = 5.8801
	old_data_grads_norm = 4.8328
	sim_grads_norm = 0.1295
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2787
	data_grads_norm = 3.6409
	new_data_grads_norm = 5.1596
	old_data_grads_norm = 5.4084
	sim_grads_norm = 0.0061
-- Starting training on experience 217 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7941
	data_grads_norm = 3.5619
	new_data_grads_norm = 4.8143
	old_data_grads_norm = 5.2162
	sim_grads_norm = 0.0513
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5847
	data_grads_norm = 3.7488
	new_data_grads_norm = 4.8159
	old_data_grads_norm = 5.6252
	sim_grads_norm = 0.0471
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1409
	data_grads_norm = 3.5810
	new_data_grads_norm = 4.7271
	old_data_grads_norm = 5.7927
	sim_grads_norm = -0.0012
-- Starting training on experience 218 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9656
	data_grads_norm = 3.9195
	new_data_grads_norm = 6.1519
	old_data_grads_norm = 4.3759
	sim_grads_norm = 0.0167
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1140
	data_grads_norm = 3.7674
	new_data_grads_norm = 5.6638
	old_data_grads_norm = 4.6125
	sim_grads_norm = 0.1360
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7327
	data_grads_norm = 3.4492
	new_data_grads_norm = 5.3519
	old_data_grads_norm = 4.3344
	sim_grads_norm = -0.0494
-- Starting training on experience 219 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8113
	data_grads_norm = 3.9909
	new_data_grads_norm = 6.8986
	old_data_grads_norm = 3.6746
	sim_grads_norm = 0.0090
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6807
	data_grads_norm = 4.7454
	new_data_grads_norm = 7.0784
	old_data_grads_norm = 5.7367
	sim_grads_norm = 0.0029
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0466
	data_grads_norm = 3.7767
	new_data_grads_norm = 6.2091
	old_data_grads_norm = 5.8298
	sim_grads_norm = 0.0087
-- Starting training on experience 220 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5540
	data_grads_norm = 2.7732
	new_data_grads_norm = 4.3257
	old_data_grads_norm = 4.0287
	sim_grads_norm = -0.0330
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9266
	data_grads_norm = 3.0875
	new_data_grads_norm = 4.7979
	old_data_grads_norm = 4.3015
	sim_grads_norm = 0.0100
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8204
	data_grads_norm = 3.1874
	new_data_grads_norm = 5.1009
	old_data_grads_norm = 3.8109
	sim_grads_norm = 0.0093
-- Starting training on experience 221 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9546
	data_grads_norm = 3.4608
	new_data_grads_norm = 6.8110
	old_data_grads_norm = 3.3229
	sim_grads_norm = 0.0449
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2731
	data_grads_norm = 4.4947
	new_data_grads_norm = 7.0683
	old_data_grads_norm = 4.9796
	sim_grads_norm = 0.0023
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8707
	data_grads_norm = 4.5112
	new_data_grads_norm = 6.6389
	old_data_grads_norm = 5.0646
	sim_grads_norm = 0.0329
-- Starting training on experience 222 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7547
	data_grads_norm = 3.0444
	new_data_grads_norm = 5.1760
	old_data_grads_norm = 4.1436
	sim_grads_norm = 0.0292
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3080
	data_grads_norm = 4.3413
	new_data_grads_norm = 5.1099
	old_data_grads_norm = 6.4498
	sim_grads_norm = -0.0337
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3577
	data_grads_norm = 3.5634
	new_data_grads_norm = 6.1059
	old_data_grads_norm = 4.0892
	sim_grads_norm = -0.0048
-- Starting training on experience 223 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4907
	data_grads_norm = 2.8326
	new_data_grads_norm = 4.4120
	old_data_grads_norm = 3.8081
	sim_grads_norm = 0.0249
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0165
	data_grads_norm = 3.3411
	new_data_grads_norm = 4.5948
	old_data_grads_norm = 5.4098
	sim_grads_norm = 0.0150
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5083
	data_grads_norm = 3.4543
	new_data_grads_norm = 4.3893
	old_data_grads_norm = 4.6078
	sim_grads_norm = 0.0156
-- Starting training on experience 224 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6637
	data_grads_norm = 3.9478
	new_data_grads_norm = 4.9598
	old_data_grads_norm = 5.3708
	sim_grads_norm = 0.0508
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2420
	data_grads_norm = 3.4877
	new_data_grads_norm = 5.5200
	old_data_grads_norm = 4.7444
	sim_grads_norm = -0.0197
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8846
	data_grads_norm = 4.0492
	new_data_grads_norm = 5.9853
	old_data_grads_norm = 5.3168
	sim_grads_norm = 0.0420
-- Starting training on experience 225 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9105
	data_grads_norm = 3.8518
	new_data_grads_norm = 5.6385
	old_data_grads_norm = 5.3734
	sim_grads_norm = -0.0137
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8533
	data_grads_norm = 3.5010
	new_data_grads_norm = 5.4511
	old_data_grads_norm = 4.1314
	sim_grads_norm = -0.0061
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5636
	data_grads_norm = 3.6919
	new_data_grads_norm = 5.7252
	old_data_grads_norm = 4.9419
	sim_grads_norm = 0.0834
-- Starting training on experience 226 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0929
	data_grads_norm = 3.3664
	new_data_grads_norm = 5.0904
	old_data_grads_norm = 4.4770
	sim_grads_norm = -0.0819
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7286
	data_grads_norm = 3.7723
	new_data_grads_norm = 5.6098
	old_data_grads_norm = 5.2389
	sim_grads_norm = -0.0351
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6701
	data_grads_norm = 4.3095
	new_data_grads_norm = 5.5811
	old_data_grads_norm = 6.0292
	sim_grads_norm = -0.0562
-- Starting training on experience 227 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9927
	data_grads_norm = 3.8851
	new_data_grads_norm = 6.0821
	old_data_grads_norm = 4.7732
	sim_grads_norm = 0.0137
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3195
	data_grads_norm = 4.0459
	new_data_grads_norm = 5.7249
	old_data_grads_norm = 3.9606
	sim_grads_norm = 0.0780
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4490
	data_grads_norm = 4.1214
	new_data_grads_norm = 6.6083
	old_data_grads_norm = 5.4507
	sim_grads_norm = 0.0956
-- Starting training on experience 228 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8570
	data_grads_norm = 3.9251
	new_data_grads_norm = 4.9719
	old_data_grads_norm = 4.3721
	sim_grads_norm = -0.0291
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9716
	data_grads_norm = 3.3370
	new_data_grads_norm = 5.5059
	old_data_grads_norm = 3.6661
	sim_grads_norm = 0.0367
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8756
	data_grads_norm = 4.1689
	new_data_grads_norm = 6.4020
	old_data_grads_norm = 4.8048
	sim_grads_norm = 0.0371
-- Starting training on experience 229 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9778
	data_grads_norm = 3.4421
	new_data_grads_norm = 4.3800
	old_data_grads_norm = 5.0530
	sim_grads_norm = -0.0295
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0104
	data_grads_norm = 3.1893
	new_data_grads_norm = 5.0945
	old_data_grads_norm = 4.8796
	sim_grads_norm = -0.0289
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0227
	data_grads_norm = 3.9302
	new_data_grads_norm = 5.2145
	old_data_grads_norm = 5.2246
	sim_grads_norm = 0.0382
-- Starting training on experience 230 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5361
	data_grads_norm = 3.6148
	new_data_grads_norm = 5.9066
	old_data_grads_norm = 4.3898
	sim_grads_norm = -0.0544
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2344
	data_grads_norm = 3.7832
	new_data_grads_norm = 5.7483
	old_data_grads_norm = 5.1376
	sim_grads_norm = 0.0839
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3055
	data_grads_norm = 3.4599
	new_data_grads_norm = 5.6849
	old_data_grads_norm = 4.0766
	sim_grads_norm = -0.0085
-- Starting training on experience 231 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0308
	data_grads_norm = 3.7388
	new_data_grads_norm = 6.2293
	old_data_grads_norm = 3.7086
	sim_grads_norm = 0.0109
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1174
	data_grads_norm = 4.1248
	new_data_grads_norm = 6.6525
	old_data_grads_norm = 4.1344
	sim_grads_norm = 0.0366
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8238
	data_grads_norm = 4.7935
	new_data_grads_norm = 6.3774
	old_data_grads_norm = 6.8555
	sim_grads_norm = 0.0948
-- Starting training on experience 232 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8103
	data_grads_norm = 3.0775
	new_data_grads_norm = 5.9673
	old_data_grads_norm = 2.7918
	sim_grads_norm = 0.0018
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4959
	data_grads_norm = 4.3941
	new_data_grads_norm = 7.1826
	old_data_grads_norm = 4.9587
	sim_grads_norm = -0.0178
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4736
	data_grads_norm = 4.0455
	new_data_grads_norm = 6.1327
	old_data_grads_norm = 4.6528
	sim_grads_norm = 0.0373
-- Starting training on experience 233 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6219
	data_grads_norm = 3.2539
	new_data_grads_norm = 5.2647
	old_data_grads_norm = 4.1629
	sim_grads_norm = -0.0046
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0534
	data_grads_norm = 3.8265
	new_data_grads_norm = 5.5383
	old_data_grads_norm = 4.4280
	sim_grads_norm = 0.0613
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1415
	data_grads_norm = 3.8355
	new_data_grads_norm = 5.4221
	old_data_grads_norm = 4.5258
	sim_grads_norm = 0.0865
-- Starting training on experience 234 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6748
	data_grads_norm = 3.5587
	new_data_grads_norm = 5.0520
	old_data_grads_norm = 4.9050
	sim_grads_norm = 0.0203
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7243
	data_grads_norm = 3.6246
	new_data_grads_norm = 5.2806
	old_data_grads_norm = 4.7589
	sim_grads_norm = -0.0439
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8415
	data_grads_norm = 3.3808
	new_data_grads_norm = 5.0138
	old_data_grads_norm = 5.0547
	sim_grads_norm = 0.0097
-- Starting training on experience 235 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0786
	data_grads_norm = 3.3692
	new_data_grads_norm = 4.3734
	old_data_grads_norm = 5.5682
	sim_grads_norm = 0.0211
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1438
	data_grads_norm = 3.8003
	new_data_grads_norm = 4.7655
	old_data_grads_norm = 5.1460
	sim_grads_norm = 0.0461
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2442
	data_grads_norm = 3.0518
	new_data_grads_norm = 4.4364
	old_data_grads_norm = 4.7460
	sim_grads_norm = -0.0858
-- Starting training on experience 236 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2625
	data_grads_norm = 4.1897
	new_data_grads_norm = 5.8048
	old_data_grads_norm = 4.6051
	sim_grads_norm = -0.0660
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4960
	data_grads_norm = 4.1756
	new_data_grads_norm = 6.1098
	old_data_grads_norm = 4.0995
	sim_grads_norm = 0.0242
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4160
	data_grads_norm = 4.0564
	new_data_grads_norm = 6.3885
	old_data_grads_norm = 4.6852
	sim_grads_norm = -0.0444
-- Starting training on experience 237 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
-- >> End of training phase << --
-- >> Start of eval phase << --
-- Starting eval on experience 0 (Task 0) from test stream --
> Eval on experience 0 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp000 = 2.5624
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.3960
	mb_index = 2142
	time = 447.4620
-- Starting eval on experience 1 (Task 0) from test stream --
> Eval on experience 1 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp001 = 1.5722
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.6320
-- Starting eval on experience 2 (Task 0) from test stream --
> Eval on experience 2 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp002 = 2.7963
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.3440
-- Starting eval on experience 3 (Task 0) from test stream --
> Eval on experience 3 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp003 = 2.1739
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.4560
-- Starting eval on experience 4 (Task 0) from test stream --
> Eval on experience 4 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp004 = 3.0563
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.3060
-- Starting eval on experience 5 (Task 0) from test stream --
> Eval on experience 5 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp005 = 2.8686
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.3100
-- Starting eval on experience 6 (Task 0) from test stream --
> Eval on experience 6 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp006 = 3.0277
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp006 = 0.2320
-- Starting eval on experience 7 (Task 0) from test stream --
> Eval on experience 7 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp007 = 2.7044
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp007 = 0.3240
-- Starting eval on experience 8 (Task 0) from test stream --
> Eval on experience 8 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp008 = 2.9260
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp008 = 0.2220
-- >> End of eval phase << --
	CumulativeAccuracy/eval_phase/test_stream/Exp000 = 0.7540
	CumulativeAccuracy/eval_phase/test_stream/Exp001 = 0.6870
	CumulativeAccuracy/eval_phase/test_stream/Exp002 = 0.5747
	CumulativeAccuracy/eval_phase/test_stream/Exp003 = 0.5295
	CumulativeAccuracy/eval_phase/test_stream/Exp004 = 0.4760
	CumulativeAccuracy/eval_phase/test_stream/Exp005 = 0.4417
	CumulativeAccuracy/eval_phase/test_stream/Exp006 = 0.4080
	CumulativeAccuracy/eval_phase/test_stream/Exp007 = 0.3830
	CumulativeAccuracy/eval_phase/test_stream/Exp008 = 0.3580
	Loss_Stream/eval_phase/test_stream/Task000 = 2.6320
	Top1_Acc_Stream/eval_phase/test_stream/Task000 = 0.3580
-- >> Start of training phase << --
-- Starting training on experience 0 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1136
	data_grads_norm = 4.3865
	new_data_grads_norm = 6.1660
	old_data_grads_norm = 4.1261
	sim_grads_norm = 0.0400
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9381
	data_grads_norm = 4.4572
	new_data_grads_norm = 5.9945
	old_data_grads_norm = 5.1764
	sim_grads_norm = -0.0247
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1027
	data_grads_norm = 4.5895
	new_data_grads_norm = 5.6911
	old_data_grads_norm = 5.9579
	sim_grads_norm = 0.0181
-- Starting training on experience 1 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7262
	data_grads_norm = 3.8209
	new_data_grads_norm = 6.1877
	old_data_grads_norm = 4.4470
	sim_grads_norm = -0.0588
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5928
	data_grads_norm = 5.4080
	new_data_grads_norm = 6.3900
	old_data_grads_norm = 7.8046
	sim_grads_norm = 0.0659
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5908
	data_grads_norm = 4.2796
	new_data_grads_norm = 5.5740
	old_data_grads_norm = 5.8131
	sim_grads_norm = 0.0297
-- Starting training on experience 2 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4135
	data_grads_norm = 4.0170
	new_data_grads_norm = 5.2000
	old_data_grads_norm = 5.4157
	sim_grads_norm = -0.0129
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3875
	data_grads_norm = 4.1681
	new_data_grads_norm = 5.6238
	old_data_grads_norm = 4.7006
	sim_grads_norm = 0.0278
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.7416
	data_grads_norm = 4.7708
	new_data_grads_norm = 5.9019
	old_data_grads_norm = 6.5627
	sim_grads_norm = 0.0178
-- Starting training on experience 3 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4514
	data_grads_norm = 3.4706
	new_data_grads_norm = 6.1315
	old_data_grads_norm = 3.8985
	sim_grads_norm = -0.0217
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1613
	data_grads_norm = 4.3236
	new_data_grads_norm = 5.9554
	old_data_grads_norm = 5.3796
	sim_grads_norm = 0.0151
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9374
	data_grads_norm = 3.6310
	new_data_grads_norm = 5.7105
	old_data_grads_norm = 3.9006
	sim_grads_norm = 0.0184
-- Starting training on experience 4 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4574
	data_grads_norm = 3.2903
	new_data_grads_norm = 5.0879
	old_data_grads_norm = 4.4444
	sim_grads_norm = 0.0392
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2246
	data_grads_norm = 3.8649
	new_data_grads_norm = 5.2238
	old_data_grads_norm = 5.0927
	sim_grads_norm = 0.0211
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4791
	data_grads_norm = 3.9560
	new_data_grads_norm = 5.2914
	old_data_grads_norm = 5.5731
	sim_grads_norm = 0.0359
-- Starting training on experience 5 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5297
	data_grads_norm = 3.6784
	new_data_grads_norm = 5.0028
	old_data_grads_norm = 4.9863
	sim_grads_norm = 0.0279
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7749
	data_grads_norm = 3.2154
	new_data_grads_norm = 5.1323
	old_data_grads_norm = 3.7887
	sim_grads_norm = 0.0189
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8868
	data_grads_norm = 3.8778
	new_data_grads_norm = 4.8012
	old_data_grads_norm = 5.3497
	sim_grads_norm = -0.0095
-- Starting training on experience 6 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7329
	data_grads_norm = 3.1902
	new_data_grads_norm = 5.0224
	old_data_grads_norm = 3.5960
	sim_grads_norm = -0.0232
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2377
	data_grads_norm = 4.1571
	new_data_grads_norm = 5.6067
	old_data_grads_norm = 5.3102
	sim_grads_norm = 0.0018
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2282
	data_grads_norm = 3.0503
	new_data_grads_norm = 5.4677
	old_data_grads_norm = 2.3102
	sim_grads_norm = -0.0362
-- Starting training on experience 7 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0141
	data_grads_norm = 4.1854
	new_data_grads_norm = 5.6764
	old_data_grads_norm = 3.9525
	sim_grads_norm = 0.0047
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1886
	data_grads_norm = 4.5322
	new_data_grads_norm = 4.9979
	old_data_grads_norm = 4.6567
	sim_grads_norm = 0.0170
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4676
	data_grads_norm = 4.1885
	new_data_grads_norm = 5.1906
	old_data_grads_norm = 5.7526
	sim_grads_norm = 0.0277
-- Starting training on experience 8 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8879
	data_grads_norm = 4.3887
	new_data_grads_norm = 6.2906
	old_data_grads_norm = 5.0701
	sim_grads_norm = 0.0083
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0530
	data_grads_norm = 4.6719
	new_data_grads_norm = 6.5716
	old_data_grads_norm = 4.8049
	sim_grads_norm = -0.0069
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9870
	data_grads_norm = 5.0181
	new_data_grads_norm = 6.2403
	old_data_grads_norm = 6.8154
	sim_grads_norm = -0.0312
-- Starting training on experience 9 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0486
	data_grads_norm = 4.1734
	new_data_grads_norm = 5.6572
	old_data_grads_norm = 5.6249
	sim_grads_norm = -0.0184
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2103
	data_grads_norm = 4.3125
	new_data_grads_norm = 5.5663
	old_data_grads_norm = 5.1799
	sim_grads_norm = 0.0391
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6256
	data_grads_norm = 4.1482
	new_data_grads_norm = 5.5291
	old_data_grads_norm = 4.7839
	sim_grads_norm = 0.1122
-- Starting training on experience 10 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7834
	data_grads_norm = 3.4684
	new_data_grads_norm = 4.7063
	old_data_grads_norm = 4.3301
	sim_grads_norm = -0.0003
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3783
	data_grads_norm = 4.0239
	new_data_grads_norm = 5.0398
	old_data_grads_norm = 5.6156
	sim_grads_norm = 0.0628
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8234
	data_grads_norm = 3.7820
	new_data_grads_norm = 5.6423
	old_data_grads_norm = 4.2193
	sim_grads_norm = 0.0409
-- Starting training on experience 11 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5062
	data_grads_norm = 3.8128
	new_data_grads_norm = 4.9428
	old_data_grads_norm = 5.8152
	sim_grads_norm = -0.0283
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7859
	data_grads_norm = 3.2801
	new_data_grads_norm = 5.0501
	old_data_grads_norm = 4.2266
	sim_grads_norm = 0.0085
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4051
	data_grads_norm = 3.8671
	new_data_grads_norm = 5.0233
	old_data_grads_norm = 5.1029
	sim_grads_norm = -0.0061
-- Starting training on experience 12 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0278
	data_grads_norm = 3.9552
	new_data_grads_norm = 5.0408
	old_data_grads_norm = 6.1823
	sim_grads_norm = 0.0404
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5280
	data_grads_norm = 3.6039
	new_data_grads_norm = 4.9348
	old_data_grads_norm = 4.9591
	sim_grads_norm = -0.0019
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3755
	data_grads_norm = 3.4189
	new_data_grads_norm = 4.8996
	old_data_grads_norm = 4.0184
	sim_grads_norm = -0.0002
-- Starting training on experience 13 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.7713
	data_grads_norm = 4.0382
	new_data_grads_norm = 5.3198
	old_data_grads_norm = 4.8181
	sim_grads_norm = 0.1473
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8791
	data_grads_norm = 3.6046
	new_data_grads_norm = 5.2346
	old_data_grads_norm = 4.9201
	sim_grads_norm = 0.0919
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6960
	data_grads_norm = 3.7090
	new_data_grads_norm = 5.2170
	old_data_grads_norm = 4.8390
	sim_grads_norm = -0.0754
-- Starting training on experience 14 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9645
	data_grads_norm = 4.7169
	new_data_grads_norm = 5.5539
	old_data_grads_norm = 6.0748
	sim_grads_norm = 0.0483
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0915
	data_grads_norm = 4.7089
	new_data_grads_norm = 6.3027
	old_data_grads_norm = 4.5632
	sim_grads_norm = -0.0345
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6590
	data_grads_norm = 4.1828
	new_data_grads_norm = 6.1356
	old_data_grads_norm = 4.9880
	sim_grads_norm = -0.0225
-- Starting training on experience 15 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1872
	data_grads_norm = 4.2254
	new_data_grads_norm = 5.3501
	old_data_grads_norm = 5.4721
	sim_grads_norm = 0.0731
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8523
	data_grads_norm = 4.0827
	new_data_grads_norm = 5.8506
	old_data_grads_norm = 5.5136
	sim_grads_norm = 0.0091
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5953
	data_grads_norm = 3.8041
	new_data_grads_norm = 5.5391
	old_data_grads_norm = 4.2767
	sim_grads_norm = 0.0488
-- Starting training on experience 16 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4795
	data_grads_norm = 3.5765
	new_data_grads_norm = 4.9977
	old_data_grads_norm = 4.1213
	sim_grads_norm = 0.0340
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7878
	data_grads_norm = 3.7488
	new_data_grads_norm = 5.7840
	old_data_grads_norm = 4.3183
	sim_grads_norm = -0.0299
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8225
	data_grads_norm = 4.1126
	new_data_grads_norm = 5.1486
	old_data_grads_norm = 5.3990
	sim_grads_norm = 0.1088
-- Starting training on experience 17 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1763
	data_grads_norm = 3.7845
	new_data_grads_norm = 4.7201
	old_data_grads_norm = 5.4409
	sim_grads_norm = 0.0171
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1690
	data_grads_norm = 3.4405
	new_data_grads_norm = 5.0117
	old_data_grads_norm = 4.4835
	sim_grads_norm = -0.0481
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3337
	data_grads_norm = 4.1009
	new_data_grads_norm = 5.0160
	old_data_grads_norm = 5.5419
	sim_grads_norm = 0.1080
-- Starting training on experience 18 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7582
	data_grads_norm = 3.3160
	new_data_grads_norm = 4.9741
	old_data_grads_norm = 3.5641
	sim_grads_norm = 0.1160
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4659
	data_grads_norm = 3.9545
	new_data_grads_norm = 5.1411
	old_data_grads_norm = 5.3504
	sim_grads_norm = 0.0214
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5843
	data_grads_norm = 3.7792
	new_data_grads_norm = 4.7390
	old_data_grads_norm = 5.2273
	sim_grads_norm = 0.0543
-- Starting training on experience 19 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2711
	data_grads_norm = 3.9889
	new_data_grads_norm = 5.0193
	old_data_grads_norm = 5.9073
	sim_grads_norm = -0.0263
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7102
	data_grads_norm = 3.3149
	new_data_grads_norm = 5.0442
	old_data_grads_norm = 4.0784
	sim_grads_norm = 0.0173
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4120
	data_grads_norm = 3.7729
	new_data_grads_norm = 5.1098
	old_data_grads_norm = 4.9803
	sim_grads_norm = -0.0068
-- Starting training on experience 20 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7675
	data_grads_norm = 4.0534
	new_data_grads_norm = 5.6092
	old_data_grads_norm = 4.1607
	sim_grads_norm = 0.0468
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2545
	data_grads_norm = 3.8738
	new_data_grads_norm = 5.0796
	old_data_grads_norm = 5.2494
	sim_grads_norm = 0.0725
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3868
	data_grads_norm = 4.1140
	new_data_grads_norm = 6.0815
	old_data_grads_norm = 5.1656
	sim_grads_norm = -0.0179
-- Starting training on experience 21 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6606
	data_grads_norm = 3.7713
	new_data_grads_norm = 5.1182
	old_data_grads_norm = 4.6164
	sim_grads_norm = 0.0156
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3344
	data_grads_norm = 3.9095
	new_data_grads_norm = 5.3342
	old_data_grads_norm = 4.4642
	sim_grads_norm = 0.0252
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7254
	data_grads_norm = 4.1716
	new_data_grads_norm = 4.9043
	old_data_grads_norm = 5.5855
	sim_grads_norm = 0.0773
-- Starting training on experience 22 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6128
	data_grads_norm = 3.9075
	new_data_grads_norm = 4.9078
	old_data_grads_norm = 5.1525
	sim_grads_norm = 0.0822
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3397
	data_grads_norm = 3.5160
	new_data_grads_norm = 4.5526
	old_data_grads_norm = 4.7375
	sim_grads_norm = 0.1468
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4210
	data_grads_norm = 3.3930
	new_data_grads_norm = 4.5536
	old_data_grads_norm = 4.3163
	sim_grads_norm = 0.1300
-- Starting training on experience 23 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4497
	data_grads_norm = 3.1936
	new_data_grads_norm = 4.0191
	old_data_grads_norm = 4.5167
	sim_grads_norm = -0.0128
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5191
	data_grads_norm = 3.0262
	new_data_grads_norm = 4.1828
	old_data_grads_norm = 4.0715
	sim_grads_norm = 0.0045
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8937
	data_grads_norm = 3.2831
	new_data_grads_norm = 4.0802
	old_data_grads_norm = 4.4941
	sim_grads_norm = -0.0494
-- Starting training on experience 24 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5341
	data_grads_norm = 4.1764
	new_data_grads_norm = 5.0128
	old_data_grads_norm = 5.5760
	sim_grads_norm = 0.0498
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3302
	data_grads_norm = 3.5066
	new_data_grads_norm = 4.9714
	old_data_grads_norm = 4.4447
	sim_grads_norm = -0.0045
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1836
	data_grads_norm = 3.8084
	new_data_grads_norm = 4.5738
	old_data_grads_norm = 5.3956
	sim_grads_norm = -0.0003
-- Starting training on experience 25 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6633
	data_grads_norm = 2.7854
	new_data_grads_norm = 4.3006
	old_data_grads_norm = 3.4158
	sim_grads_norm = -0.0567
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9822
	data_grads_norm = 3.2853
	new_data_grads_norm = 4.8957
	old_data_grads_norm = 3.9695
	sim_grads_norm = -0.0104
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2233
	data_grads_norm = 3.4300
	new_data_grads_norm = 5.0109
	old_data_grads_norm = 4.4093
	sim_grads_norm = -0.0122
-- Starting training on experience 26 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5832
	data_grads_norm = 3.8669
	new_data_grads_norm = 5.0202
	old_data_grads_norm = 5.3091
	sim_grads_norm = -0.0063
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5122
	data_grads_norm = 3.8312
	new_data_grads_norm = 5.2017
	old_data_grads_norm = 5.6032
	sim_grads_norm = -0.0397
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4086
	data_grads_norm = 3.6378
	new_data_grads_norm = 5.0642
	old_data_grads_norm = 5.0494
	sim_grads_norm = 0.0151
-- Starting training on experience 27 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2679
	data_grads_norm = 3.7061
	new_data_grads_norm = 5.6069
	old_data_grads_norm = 3.8139
	sim_grads_norm = 0.0041
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5276
	data_grads_norm = 3.7531
	new_data_grads_norm = 5.1526
	old_data_grads_norm = 4.6110
	sim_grads_norm = -0.0021
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3492
	data_grads_norm = 3.6875
	new_data_grads_norm = 5.1864
	old_data_grads_norm = 4.1969
	sim_grads_norm = 0.0007
-- Starting training on experience 28 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6174
	data_grads_norm = 3.7066
	new_data_grads_norm = 4.4974
	old_data_grads_norm = 5.0457
	sim_grads_norm = 0.0308
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9174
	data_grads_norm = 3.4417
	new_data_grads_norm = 4.3995
	old_data_grads_norm = 4.4639
	sim_grads_norm = 0.0071
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5218
	data_grads_norm = 3.3470
	new_data_grads_norm = 4.2153
	old_data_grads_norm = 4.7416
	sim_grads_norm = 0.0423
-- Starting training on experience 29 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3195
	data_grads_norm = 3.8628
	new_data_grads_norm = 4.3788
	old_data_grads_norm = 5.4019
	sim_grads_norm = 0.0142
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0787
	data_grads_norm = 3.4722
	new_data_grads_norm = 4.4929
	old_data_grads_norm = 4.6640
	sim_grads_norm = -0.0333
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0577
	data_grads_norm = 3.6937
	new_data_grads_norm = 4.7749
	old_data_grads_norm = 5.6544
	sim_grads_norm = 0.0197
-- Starting training on experience 30 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0365
	data_grads_norm = 3.5619
	new_data_grads_norm = 4.6924
	old_data_grads_norm = 5.2032
	sim_grads_norm = -0.0622
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1232
	data_grads_norm = 3.4612
	new_data_grads_norm = 4.4883
	old_data_grads_norm = 4.2150
	sim_grads_norm = 0.1964
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9987
	data_grads_norm = 3.3888
	new_data_grads_norm = 4.5941
	old_data_grads_norm = 4.4520
	sim_grads_norm = 0.0325
-- Starting training on experience 31 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9952
	data_grads_norm = 3.5727
	new_data_grads_norm = 4.6530
	old_data_grads_norm = 5.0892
	sim_grads_norm = 0.0068
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1320
	data_grads_norm = 3.5918
	new_data_grads_norm = 4.6202
	old_data_grads_norm = 4.9212
	sim_grads_norm = -0.0585
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0802
	data_grads_norm = 3.3059
	new_data_grads_norm = 5.3239
	old_data_grads_norm = 4.1749
	sim_grads_norm = 0.0105
-- Starting training on experience 32 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6826
	data_grads_norm = 3.9016
	new_data_grads_norm = 5.4159
	old_data_grads_norm = 4.3100
	sim_grads_norm = 0.0586
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3990
	data_grads_norm = 4.0183
	new_data_grads_norm = 4.9595
	old_data_grads_norm = 5.7821
	sim_grads_norm = 0.0815
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0352
	data_grads_norm = 3.7694
	new_data_grads_norm = 5.0885
	old_data_grads_norm = 5.4620
	sim_grads_norm = 0.0030
-- Starting training on experience 33 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8449
	data_grads_norm = 3.2489
	new_data_grads_norm = 4.1583
	old_data_grads_norm = 4.9018
	sim_grads_norm = -0.0044
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7512
	data_grads_norm = 3.6782
	new_data_grads_norm = 4.5054
	old_data_grads_norm = 5.2345
	sim_grads_norm = 0.1128
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9727
	data_grads_norm = 3.8522
	new_data_grads_norm = 4.2467
	old_data_grads_norm = 5.1378
	sim_grads_norm = 0.0862
-- Starting training on experience 34 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6662
	data_grads_norm = 3.0901
	new_data_grads_norm = 4.3577
	old_data_grads_norm = 4.1211
	sim_grads_norm = -0.0924
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5177
	data_grads_norm = 2.9884
	new_data_grads_norm = 4.3651
	old_data_grads_norm = 3.9811
	sim_grads_norm = -0.0415
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2339
	data_grads_norm = 3.6977
	new_data_grads_norm = 4.3203
	old_data_grads_norm = 5.2162
	sim_grads_norm = 0.0569
-- Starting training on experience 35 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7866
	data_grads_norm = 3.5641
	new_data_grads_norm = 4.5888
	old_data_grads_norm = 5.2110
	sim_grads_norm = 0.0250
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6320
	data_grads_norm = 4.4663
	new_data_grads_norm = 5.6929
	old_data_grads_norm = 5.4396
	sim_grads_norm = 0.0411
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8403
	data_grads_norm = 3.9424
	new_data_grads_norm = 5.1070
	old_data_grads_norm = 5.4988
	sim_grads_norm = 0.0164
-- Starting training on experience 36 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0309
	data_grads_norm = 4.1131
	new_data_grads_norm = 5.2110
	old_data_grads_norm = 6.3257
	sim_grads_norm = -0.0023
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5674
	data_grads_norm = 4.1124
	new_data_grads_norm = 5.1028
	old_data_grads_norm = 5.0611
	sim_grads_norm = 0.0180
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5724
	data_grads_norm = 2.8262
	new_data_grads_norm = 5.0585
	old_data_grads_norm = 2.8064
	sim_grads_norm = -0.0044
-- Starting training on experience 37 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5868
	data_grads_norm = 3.1234
	new_data_grads_norm = 4.8178
	old_data_grads_norm = 3.5165
	sim_grads_norm = 0.0321
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4947
	data_grads_norm = 3.7391
	new_data_grads_norm = 5.6248
	old_data_grads_norm = 4.5245
	sim_grads_norm = 0.0065
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9127
	data_grads_norm = 3.8418
	new_data_grads_norm = 5.3474
	old_data_grads_norm = 5.4007
	sim_grads_norm = 0.0567
-- Starting training on experience 38 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6913
	data_grads_norm = 3.1587
	new_data_grads_norm = 4.4343
	old_data_grads_norm = 3.8242
	sim_grads_norm = 0.1114
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7336
	data_grads_norm = 3.5872
	new_data_grads_norm = 4.7114
	old_data_grads_norm = 5.2231
	sim_grads_norm = -0.0125
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8200
	data_grads_norm = 3.3184
	new_data_grads_norm = 4.0227
	old_data_grads_norm = 5.0220
	sim_grads_norm = 0.0254
-- Starting training on experience 39 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5122
	data_grads_norm = 3.2266
	new_data_grads_norm = 4.5022
	old_data_grads_norm = 4.6123
	sim_grads_norm = -0.0587
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8040
	data_grads_norm = 4.1228
	new_data_grads_norm = 4.9638
	old_data_grads_norm = 5.7193
	sim_grads_norm = 0.0016
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5665
	data_grads_norm = 3.2043
	new_data_grads_norm = 4.5387
	old_data_grads_norm = 3.9372
	sim_grads_norm = -0.0015
-- Starting training on experience 40 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4979
	data_grads_norm = 4.6763
	new_data_grads_norm = 4.6613
	old_data_grads_norm = 7.6112
	sim_grads_norm = 0.0194
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7327
	data_grads_norm = 3.3872
	new_data_grads_norm = 4.3279
	old_data_grads_norm = 4.8696
	sim_grads_norm = 0.0524
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6065
	data_grads_norm = 3.0904
	new_data_grads_norm = 4.4298
	old_data_grads_norm = 4.3091
	sim_grads_norm = -0.0465
-- Starting training on experience 41 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7397
	data_grads_norm = 3.3536
	new_data_grads_norm = 5.1857
	old_data_grads_norm = 3.7653
	sim_grads_norm = 0.0530
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9583
	data_grads_norm = 3.4993
	new_data_grads_norm = 4.5954
	old_data_grads_norm = 4.6511
	sim_grads_norm = 0.0159
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7000
	data_grads_norm = 3.1234
	new_data_grads_norm = 4.3767
	old_data_grads_norm = 4.1647
	sim_grads_norm = 0.0207
-- Starting training on experience 42 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9462
	data_grads_norm = 3.6067
	new_data_grads_norm = 4.2881
	old_data_grads_norm = 4.7633
	sim_grads_norm = 0.0134
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1998
	data_grads_norm = 2.9915
	new_data_grads_norm = 4.5327
	old_data_grads_norm = 3.0950
	sim_grads_norm = -0.0492
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5907
	data_grads_norm = 3.8214
	new_data_grads_norm = 4.5496
	old_data_grads_norm = 5.4867
	sim_grads_norm = 0.0455
-- Starting training on experience 43 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6191
	data_grads_norm = 3.0591
	new_data_grads_norm = 3.9956
	old_data_grads_norm = 3.8946
	sim_grads_norm = 0.0296
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4624
	data_grads_norm = 3.0950
	new_data_grads_norm = 3.5167
	old_data_grads_norm = 4.3623
	sim_grads_norm = -0.0107
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3700
	data_grads_norm = 2.8454
	new_data_grads_norm = 3.8288
	old_data_grads_norm = 4.1525
	sim_grads_norm = -0.0165
-- Starting training on experience 44 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2327
	data_grads_norm = 2.9905
	new_data_grads_norm = 4.3083
	old_data_grads_norm = 3.5787
	sim_grads_norm = -0.0009
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5864
	data_grads_norm = 3.5876
	new_data_grads_norm = 4.5331
	old_data_grads_norm = 4.8562
	sim_grads_norm = 0.0284
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8280
	data_grads_norm = 3.7949
	new_data_grads_norm = 4.7898
	old_data_grads_norm = 5.5846
	sim_grads_norm = 0.0598
-- Starting training on experience 45 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6257
	data_grads_norm = 3.7639
	new_data_grads_norm = 4.5640
	old_data_grads_norm = 4.4562
	sim_grads_norm = 0.0074
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5148
	data_grads_norm = 3.0393
	new_data_grads_norm = 4.3838
	old_data_grads_norm = 3.9347
	sim_grads_norm = -0.0352
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3926
	data_grads_norm = 3.0057
	new_data_grads_norm = 4.4415
	old_data_grads_norm = 3.8236
	sim_grads_norm = 0.0265
-- Starting training on experience 46 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5392
	data_grads_norm = 4.5143
	new_data_grads_norm = 5.9521
	old_data_grads_norm = 5.9363
	sim_grads_norm = 0.0465
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3769
	data_grads_norm = 4.2585
	new_data_grads_norm = 5.6801
	old_data_grads_norm = 5.2010
	sim_grads_norm = 0.0666
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2813
	data_grads_norm = 4.4109
	new_data_grads_norm = 5.8316
	old_data_grads_norm = 6.3578
	sim_grads_norm = -0.0385
-- Starting training on experience 47 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9673
	data_grads_norm = 3.7971
	new_data_grads_norm = 5.3578
	old_data_grads_norm = 4.3491
	sim_grads_norm = 0.0387
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7170
	data_grads_norm = 3.9030
	new_data_grads_norm = 5.5680
	old_data_grads_norm = 3.6037
	sim_grads_norm = 0.0445
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2918
	data_grads_norm = 3.7907
	new_data_grads_norm = 4.4727
	old_data_grads_norm = 4.6611
	sim_grads_norm = 0.0677
-- Starting training on experience 48 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1476
	data_grads_norm = 3.5720
	new_data_grads_norm = 4.2345
	old_data_grads_norm = 5.0712
	sim_grads_norm = 0.0627
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1818
	data_grads_norm = 2.8588
	new_data_grads_norm = 4.1296
	old_data_grads_norm = 3.8059
	sim_grads_norm = -0.0341
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2717
	data_grads_norm = 3.2417
	new_data_grads_norm = 4.6268
	old_data_grads_norm = 3.5712
	sim_grads_norm = -0.0366
-- Starting training on experience 49 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4917
	data_grads_norm = 3.4456
	new_data_grads_norm = 4.6929
	old_data_grads_norm = 4.5978
	sim_grads_norm = 0.0819
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8204
	data_grads_norm = 3.4588
	new_data_grads_norm = 5.0964
	old_data_grads_norm = 4.2672
	sim_grads_norm = 0.0464
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5528
	data_grads_norm = 3.4970
	new_data_grads_norm = 4.1611
	old_data_grads_norm = 4.8839
	sim_grads_norm = 0.0492
-- Starting training on experience 50 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7624
	data_grads_norm = 3.4090
	new_data_grads_norm = 4.8568
	old_data_grads_norm = 4.2737
	sim_grads_norm = 0.0662
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9509
	data_grads_norm = 3.5434
	new_data_grads_norm = 4.2220
	old_data_grads_norm = 5.4706
	sim_grads_norm = -0.0311
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6511
	data_grads_norm = 3.3148
	new_data_grads_norm = 4.6747
	old_data_grads_norm = 4.3299
	sim_grads_norm = -0.0165
-- Starting training on experience 51 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1147
	data_grads_norm = 3.5759
	new_data_grads_norm = 4.5403
	old_data_grads_norm = 5.1896
	sim_grads_norm = -0.0273
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8817
	data_grads_norm = 3.6971
	new_data_grads_norm = 4.4414
	old_data_grads_norm = 4.9905
	sim_grads_norm = 0.0109
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9065
	data_grads_norm = 3.9753
	new_data_grads_norm = 4.9496
	old_data_grads_norm = 5.9519
	sim_grads_norm = 0.0219
-- Starting training on experience 52 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6391
	data_grads_norm = 3.2085
	new_data_grads_norm = 4.2366
	old_data_grads_norm = 4.4061
	sim_grads_norm = 0.0669
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6126
	data_grads_norm = 3.4294
	new_data_grads_norm = 4.3092
	old_data_grads_norm = 5.4941
	sim_grads_norm = -0.0406
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6004
	data_grads_norm = 3.1572
	new_data_grads_norm = 4.5836
	old_data_grads_norm = 3.8053
	sim_grads_norm = 0.0043
-- Starting training on experience 53 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5168
	data_grads_norm = 3.1161
	new_data_grads_norm = 4.6118
	old_data_grads_norm = 3.6953
	sim_grads_norm = -0.0448
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9824
	data_grads_norm = 3.5198
	new_data_grads_norm = 4.7853
	old_data_grads_norm = 4.7969
	sim_grads_norm = 0.0575
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7182
	data_grads_norm = 3.7448
	new_data_grads_norm = 4.9825
	old_data_grads_norm = 4.5463
	sim_grads_norm = 0.0051
-- Starting training on experience 54 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6372
	data_grads_norm = 3.7808
	new_data_grads_norm = 4.8181
	old_data_grads_norm = 5.0841
	sim_grads_norm = 0.0682
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3552
	data_grads_norm = 3.2545
	new_data_grads_norm = 4.7036
	old_data_grads_norm = 4.0999
	sim_grads_norm = -0.0435
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8266
	data_grads_norm = 3.7537
	new_data_grads_norm = 4.9535
	old_data_grads_norm = 5.9218
	sim_grads_norm = -0.0229
-- Starting training on experience 55 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7894
	data_grads_norm = 3.6507
	new_data_grads_norm = 5.4717
	old_data_grads_norm = 4.4646
	sim_grads_norm = 0.0424
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1139
	data_grads_norm = 2.9786
	new_data_grads_norm = 4.4240
	old_data_grads_norm = 4.4270
	sim_grads_norm = -0.0331
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3367
	data_grads_norm = 3.1672
	new_data_grads_norm = 4.4927
	old_data_grads_norm = 3.9159
	sim_grads_norm = 0.0041
-- Starting training on experience 56 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2690
	data_grads_norm = 3.3149
	new_data_grads_norm = 4.7636
	old_data_grads_norm = 4.2306
	sim_grads_norm = -0.0329
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5805
	data_grads_norm = 3.8946
	new_data_grads_norm = 4.4880
	old_data_grads_norm = 5.2253
	sim_grads_norm = 0.0032
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3368
	data_grads_norm = 3.3274
	new_data_grads_norm = 4.7767
	old_data_grads_norm = 4.3456
	sim_grads_norm = -0.0040
-- Starting training on experience 57 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1998
	data_grads_norm = 3.9434
	new_data_grads_norm = 5.5989
	old_data_grads_norm = 4.3684
	sim_grads_norm = -0.0255
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3016
	data_grads_norm = 3.9787
	new_data_grads_norm = 5.6067
	old_data_grads_norm = 4.7002
	sim_grads_norm = -0.0032
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0972
	data_grads_norm = 4.6438
	new_data_grads_norm = 6.1638
	old_data_grads_norm = 6.0164
	sim_grads_norm = 0.0102
-- Starting training on experience 58 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4584
	data_grads_norm = 3.5613
	new_data_grads_norm = 4.9604
	old_data_grads_norm = 5.0782
	sim_grads_norm = -0.0216
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4759
	data_grads_norm = 3.5123
	new_data_grads_norm = 4.8551
	old_data_grads_norm = 4.1484
	sim_grads_norm = 0.0723
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3990
	data_grads_norm = 3.8408
	new_data_grads_norm = 4.4589
	old_data_grads_norm = 5.8517
	sim_grads_norm = 0.0365
-- Starting training on experience 59 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8725
	data_grads_norm = 3.7475
	new_data_grads_norm = 5.1437
	old_data_grads_norm = 4.7797
	sim_grads_norm = 0.0056
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4842
	data_grads_norm = 3.0709
	new_data_grads_norm = 4.7725
	old_data_grads_norm = 3.4522
	sim_grads_norm = 0.0295
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1991
	data_grads_norm = 4.1165
	new_data_grads_norm = 5.5193
	old_data_grads_norm = 5.6039
	sim_grads_norm = 0.0524
-- Starting training on experience 60 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3971
	data_grads_norm = 3.1362
	new_data_grads_norm = 4.4216
	old_data_grads_norm = 4.2232
	sim_grads_norm = 0.0537
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6733
	data_grads_norm = 3.9913
	new_data_grads_norm = 4.9432
	old_data_grads_norm = 5.2264
	sim_grads_norm = -0.0021
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4896
	data_grads_norm = 3.5815
	new_data_grads_norm = 4.6628
	old_data_grads_norm = 5.2848
	sim_grads_norm = 0.0513
-- Starting training on experience 61 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7255
	data_grads_norm = 3.7601
	new_data_grads_norm = 5.4557
	old_data_grads_norm = 5.3854
	sim_grads_norm = 0.0730
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6058
	data_grads_norm = 3.6402
	new_data_grads_norm = 5.3007
	old_data_grads_norm = 4.4806
	sim_grads_norm = -0.0024
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9727
	data_grads_norm = 4.5407
	new_data_grads_norm = 6.0233
	old_data_grads_norm = 6.3593
	sim_grads_norm = -0.0497
-- Starting training on experience 62 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5650
	data_grads_norm = 3.7538
	new_data_grads_norm = 4.2679
	old_data_grads_norm = 6.0398
	sim_grads_norm = 0.0572
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4409
	data_grads_norm = 3.4152
	new_data_grads_norm = 4.4260
	old_data_grads_norm = 5.0043
	sim_grads_norm = -0.0066
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1787
	data_grads_norm = 3.1459
	new_data_grads_norm = 4.4153
	old_data_grads_norm = 4.6438
	sim_grads_norm = 0.0044
-- Starting training on experience 63 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0852
	data_grads_norm = 2.7506
	new_data_grads_norm = 3.8853
	old_data_grads_norm = 4.3619
	sim_grads_norm = -0.0155
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0806
	data_grads_norm = 3.4219
	new_data_grads_norm = 4.2835
	old_data_grads_norm = 4.7533
	sim_grads_norm = -0.0082
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2766
	data_grads_norm = 3.5151
	new_data_grads_norm = 4.3943
	old_data_grads_norm = 4.9378
	sim_grads_norm = -0.0103
-- Starting training on experience 64 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3057
	data_grads_norm = 3.3582
	new_data_grads_norm = 4.7000
	old_data_grads_norm = 3.8531
	sim_grads_norm = -0.0193
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8213
	data_grads_norm = 3.4366
	new_data_grads_norm = 4.9009
	old_data_grads_norm = 4.7713
	sim_grads_norm = -0.0410
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5785
	data_grads_norm = 3.4658
	new_data_grads_norm = 5.2404
	old_data_grads_norm = 4.6551
	sim_grads_norm = 0.0099
-- Starting training on experience 65 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2796
	data_grads_norm = 4.1028
	new_data_grads_norm = 5.0220
	old_data_grads_norm = 5.2058
	sim_grads_norm = 0.0328
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4220
	data_grads_norm = 3.1557
	new_data_grads_norm = 4.3791
	old_data_grads_norm = 4.1382
	sim_grads_norm = -0.0299
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6346
	data_grads_norm = 3.2018
	new_data_grads_norm = 4.2522
	old_data_grads_norm = 4.8923
	sim_grads_norm = -0.0199
-- Starting training on experience 66 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5740
	data_grads_norm = 3.2795
	new_data_grads_norm = 5.0496
	old_data_grads_norm = 3.9263
	sim_grads_norm = -0.0173
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3082
	data_grads_norm = 3.0355
	new_data_grads_norm = 4.6427
	old_data_grads_norm = 3.8089
	sim_grads_norm = 0.0356
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4980
	data_grads_norm = 3.5104
	new_data_grads_norm = 5.2557
	old_data_grads_norm = 4.5204
	sim_grads_norm = -0.0433
-- Starting training on experience 67 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6514
	data_grads_norm = 3.7578
	new_data_grads_norm = 5.3859
	old_data_grads_norm = 5.3722
	sim_grads_norm = 0.0662
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0185
	data_grads_norm = 3.3813
	new_data_grads_norm = 4.9680
	old_data_grads_norm = 4.3197
	sim_grads_norm = -0.0181
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5217
	data_grads_norm = 3.5766
	new_data_grads_norm = 4.9780
	old_data_grads_norm = 5.2006
	sim_grads_norm = -0.0396
-- Starting training on experience 68 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5823
	data_grads_norm = 3.5433
	new_data_grads_norm = 4.3979
	old_data_grads_norm = 4.5713
	sim_grads_norm = 0.0266
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1881
	data_grads_norm = 3.2362
	new_data_grads_norm = 4.6159
	old_data_grads_norm = 4.5695
	sim_grads_norm = -0.0252
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8090
	data_grads_norm = 3.5271
	new_data_grads_norm = 4.2396
	old_data_grads_norm = 4.9959
	sim_grads_norm = 0.0286
-- Starting training on experience 69 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7098
	data_grads_norm = 4.1103
	new_data_grads_norm = 4.6627
	old_data_grads_norm = 5.0628
	sim_grads_norm = 0.1210
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6885
	data_grads_norm = 3.7018
	new_data_grads_norm = 4.8654
	old_data_grads_norm = 4.5841
	sim_grads_norm = 0.1315
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6910
	data_grads_norm = 3.9648
	new_data_grads_norm = 4.6822
	old_data_grads_norm = 5.4203
	sim_grads_norm = 0.0205
-- Starting training on experience 70 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9269
	data_grads_norm = 3.7220
	new_data_grads_norm = 5.8986
	old_data_grads_norm = 3.4172
	sim_grads_norm = -0.0045
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3397
	data_grads_norm = 3.8138
	new_data_grads_norm = 5.7000
	old_data_grads_norm = 4.7342
	sim_grads_norm = -0.0734
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3280
	data_grads_norm = 3.7367
	new_data_grads_norm = 5.5233
	old_data_grads_norm = 4.3753
	sim_grads_norm = 0.0680
-- Starting training on experience 71 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1672
	data_grads_norm = 3.5238
	new_data_grads_norm = 4.5358
	old_data_grads_norm = 4.9313
	sim_grads_norm = -0.0140
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0727
	data_grads_norm = 3.2165
	new_data_grads_norm = 5.1696
	old_data_grads_norm = 4.7134
	sim_grads_norm = 0.0874
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4204
	data_grads_norm = 3.6460
	new_data_grads_norm = 4.2054
	old_data_grads_norm = 5.3372
	sim_grads_norm = 0.0476
-- Starting training on experience 72 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1750
	data_grads_norm = 3.2568
	new_data_grads_norm = 5.1687
	old_data_grads_norm = 3.9973
	sim_grads_norm = -0.0347
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6223
	data_grads_norm = 3.8370
	new_data_grads_norm = 5.0611
	old_data_grads_norm = 4.3876
	sim_grads_norm = 0.1015
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5132
	data_grads_norm = 3.8165
	new_data_grads_norm = 5.0400
	old_data_grads_norm = 5.4617
	sim_grads_norm = -0.0386
-- Starting training on experience 73 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5723
	data_grads_norm = 3.7873
	new_data_grads_norm = 4.3410
	old_data_grads_norm = 5.7749
	sim_grads_norm = 0.0170
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1848
	data_grads_norm = 3.6733
	new_data_grads_norm = 4.3514
	old_data_grads_norm = 5.3681
	sim_grads_norm = 0.0329
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3384
	data_grads_norm = 3.6264
	new_data_grads_norm = 4.5429
	old_data_grads_norm = 5.4009
	sim_grads_norm = 0.0315
-- Starting training on experience 74 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0390
	data_grads_norm = 3.1892
	new_data_grads_norm = 4.0410
	old_data_grads_norm = 5.0693
	sim_grads_norm = 0.0306
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3594
	data_grads_norm = 3.5983
	new_data_grads_norm = 4.5038
	old_data_grads_norm = 5.0113
	sim_grads_norm = 0.0673
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1145
	data_grads_norm = 3.3350
	new_data_grads_norm = 4.1766
	old_data_grads_norm = 5.1751
	sim_grads_norm = 0.0403
-- Starting training on experience 75 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9571
	data_grads_norm = 3.8064
	new_data_grads_norm = 4.7196
	old_data_grads_norm = 4.9552
	sim_grads_norm = 0.0529
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0433
	data_grads_norm = 3.2590
	new_data_grads_norm = 4.0156
	old_data_grads_norm = 4.1179
	sim_grads_norm = 0.0448
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1925
	data_grads_norm = 2.8525
	new_data_grads_norm = 4.3232
	old_data_grads_norm = 3.3842
	sim_grads_norm = 0.0178
-- Starting training on experience 76 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3124
	data_grads_norm = 3.5218
	new_data_grads_norm = 5.1343
	old_data_grads_norm = 5.6209
	sim_grads_norm = -0.0589
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1862
	data_grads_norm = 3.5845
	new_data_grads_norm = 4.9606
	old_data_grads_norm = 4.9489
	sim_grads_norm = -0.0440
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6523
	data_grads_norm = 3.0539
	new_data_grads_norm = 4.8943
	old_data_grads_norm = 3.7057
	sim_grads_norm = -0.0189
-- Starting training on experience 77 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8811
	data_grads_norm = 3.3080
	new_data_grads_norm = 4.0510
	old_data_grads_norm = 5.2813
	sim_grads_norm = -0.0212
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2141
	data_grads_norm = 2.8241
	new_data_grads_norm = 4.4198
	old_data_grads_norm = 3.6967
	sim_grads_norm = -0.0100
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8474
	data_grads_norm = 3.5187
	new_data_grads_norm = 4.3406
	old_data_grads_norm = 4.4710
	sim_grads_norm = 0.0755
-- Starting training on experience 78 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2212
	data_grads_norm = 3.4884
	new_data_grads_norm = 4.9707
	old_data_grads_norm = 4.6450
	sim_grads_norm = 0.0350
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5479
	data_grads_norm = 3.9443
	new_data_grads_norm = 4.9428
	old_data_grads_norm = 5.2500
	sim_grads_norm = 0.1206
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0154
	data_grads_norm = 3.0250
	new_data_grads_norm = 4.5668
	old_data_grads_norm = 3.3818
	sim_grads_norm = -0.0689
-- Starting training on experience 79 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8309
	data_grads_norm = 3.3719
	new_data_grads_norm = 3.8738
	old_data_grads_norm = 5.7477
	sim_grads_norm = 0.0057
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2669
	data_grads_norm = 3.1943
	new_data_grads_norm = 4.7647
	old_data_grads_norm = 4.8852
	sim_grads_norm = 0.0064
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4166
	data_grads_norm = 3.8468
	new_data_grads_norm = 4.6475
	old_data_grads_norm = 5.4465
	sim_grads_norm = 0.0664
-- Starting training on experience 80 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5374
	data_grads_norm = 4.0350
	new_data_grads_norm = 4.9570
	old_data_grads_norm = 5.7294
	sim_grads_norm = -0.0124
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6627
	data_grads_norm = 3.5348
	new_data_grads_norm = 4.5067
	old_data_grads_norm = 5.3202
	sim_grads_norm = -0.0237
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2840
	data_grads_norm = 3.4896
	new_data_grads_norm = 4.2463
	old_data_grads_norm = 4.8301
	sim_grads_norm = 0.0181
-- Starting training on experience 81 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4343
	data_grads_norm = 3.2218
	new_data_grads_norm = 4.4270
	old_data_grads_norm = 4.5869
	sim_grads_norm = 0.0558
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0599
	data_grads_norm = 3.0601
	new_data_grads_norm = 4.4621
	old_data_grads_norm = 4.2587
	sim_grads_norm = -0.0056
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3322
	data_grads_norm = 3.1972
	new_data_grads_norm = 4.1628
	old_data_grads_norm = 4.7826
	sim_grads_norm = -0.0295
-- Starting training on experience 82 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2949
	data_grads_norm = 3.5895
	new_data_grads_norm = 5.0285
	old_data_grads_norm = 4.9499
	sim_grads_norm = 0.0748
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1943
	data_grads_norm = 3.3398
	new_data_grads_norm = 4.9538
	old_data_grads_norm = 3.8786
	sim_grads_norm = -0.0078
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7317
	data_grads_norm = 4.2540
	new_data_grads_norm = 5.8099
	old_data_grads_norm = 5.5759
	sim_grads_norm = 0.0100
-- Starting training on experience 83 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5568
	data_grads_norm = 3.7241
	new_data_grads_norm = 4.5094
	old_data_grads_norm = 5.4825
	sim_grads_norm = -0.0222
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6094
	data_grads_norm = 3.3347
	new_data_grads_norm = 4.7904
	old_data_grads_norm = 4.6517
	sim_grads_norm = -0.0119
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5171
	data_grads_norm = 3.7110
	new_data_grads_norm = 5.1153
	old_data_grads_norm = 4.5239
	sim_grads_norm = 0.0415
-- Starting training on experience 84 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5179
	data_grads_norm = 3.6584
	new_data_grads_norm = 5.0610
	old_data_grads_norm = 4.9294
	sim_grads_norm = 0.0492
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4204
	data_grads_norm = 3.8904
	new_data_grads_norm = 5.5101
	old_data_grads_norm = 5.0969
	sim_grads_norm = -0.0028
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9854
	data_grads_norm = 3.3556
	new_data_grads_norm = 5.7903
	old_data_grads_norm = 4.1248
	sim_grads_norm = -0.0124
-- Starting training on experience 85 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5981
	data_grads_norm = 3.5375
	new_data_grads_norm = 5.1535
	old_data_grads_norm = 5.1596
	sim_grads_norm = 0.0364
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4858
	data_grads_norm = 3.3674
	new_data_grads_norm = 4.9231
	old_data_grads_norm = 4.6820
	sim_grads_norm = 0.0158
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5686
	data_grads_norm = 3.6592
	new_data_grads_norm = 4.4851
	old_data_grads_norm = 5.9020
	sim_grads_norm = 0.0148
-- Starting training on experience 86 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4033
	data_grads_norm = 3.8329
	new_data_grads_norm = 4.3370
	old_data_grads_norm = 5.8918
	sim_grads_norm = -0.0193
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6560
	data_grads_norm = 3.6166
	new_data_grads_norm = 4.2559
	old_data_grads_norm = 5.6749
	sim_grads_norm = -0.0390
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6350
	data_grads_norm = 3.8704
	new_data_grads_norm = 4.7885
	old_data_grads_norm = 6.1185
	sim_grads_norm = 0.0075
-- Starting training on experience 87 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3612
	data_grads_norm = 3.4087
	new_data_grads_norm = 5.1210
	old_data_grads_norm = 4.8696
	sim_grads_norm = -0.0272
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3646
	data_grads_norm = 3.7368
	new_data_grads_norm = 5.0487
	old_data_grads_norm = 5.5356
	sim_grads_norm = 0.0466
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2383
	data_grads_norm = 3.9143
	new_data_grads_norm = 4.9155
	old_data_grads_norm = 5.9027
	sim_grads_norm = -0.0218
-- Starting training on experience 88 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0048
	data_grads_norm = 2.6711
	new_data_grads_norm = 4.1858
	old_data_grads_norm = 3.9352
	sim_grads_norm = -0.0225
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3562
	data_grads_norm = 3.9619
	new_data_grads_norm = 4.3850
	old_data_grads_norm = 4.8302
	sim_grads_norm = 0.0083
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3308
	data_grads_norm = 3.4377
	new_data_grads_norm = 4.9389
	old_data_grads_norm = 4.7335
	sim_grads_norm = 0.0484
-- Starting training on experience 89 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4952
	data_grads_norm = 3.6402
	new_data_grads_norm = 5.1044
	old_data_grads_norm = 5.0004
	sim_grads_norm = 0.0297
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5349
	data_grads_norm = 3.5447
	new_data_grads_norm = 4.8261
	old_data_grads_norm = 4.6609
	sim_grads_norm = 0.0592
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0279
	data_grads_norm = 3.4153
	new_data_grads_norm = 4.5864
	old_data_grads_norm = 5.1676
	sim_grads_norm = -0.0252
-- Starting training on experience 90 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0901
	data_grads_norm = 3.5315
	new_data_grads_norm = 4.9733
	old_data_grads_norm = 4.2794
	sim_grads_norm = 0.0587
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3720
	data_grads_norm = 3.5402
	new_data_grads_norm = 5.0617
	old_data_grads_norm = 4.4101
	sim_grads_norm = -0.0309
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1131
	data_grads_norm = 3.4250
	new_data_grads_norm = 4.8864
	old_data_grads_norm = 3.8847
	sim_grads_norm = 0.2175
-- Starting training on experience 91 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1059
	data_grads_norm = 3.1086
	new_data_grads_norm = 4.6750
	old_data_grads_norm = 4.2853
	sim_grads_norm = -0.0378
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4592
	data_grads_norm = 3.3146
	new_data_grads_norm = 4.4591
	old_data_grads_norm = 4.1588
	sim_grads_norm = 0.0385
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1847
	data_grads_norm = 2.9849
	new_data_grads_norm = 4.3938
	old_data_grads_norm = 3.7928
	sim_grads_norm = 0.0013
-- Starting training on experience 92 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7027
	data_grads_norm = 3.8261
	new_data_grads_norm = 5.0940
	old_data_grads_norm = 4.7565
	sim_grads_norm = 0.0570
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4393
	data_grads_norm = 3.8600
	new_data_grads_norm = 4.9174
	old_data_grads_norm = 5.8025
	sim_grads_norm = 0.0488
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4395
	data_grads_norm = 3.2615
	new_data_grads_norm = 4.7769
	old_data_grads_norm = 4.5491
	sim_grads_norm = -0.0151
-- Starting training on experience 93 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5293
	data_grads_norm = 3.5028
	new_data_grads_norm = 4.9618
	old_data_grads_norm = 4.6033
	sim_grads_norm = 0.0071
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3863
	data_grads_norm = 2.8905
	new_data_grads_norm = 4.8932
	old_data_grads_norm = 3.7168
	sim_grads_norm = -0.0354
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6089
	data_grads_norm = 3.2623
	new_data_grads_norm = 5.6632
	old_data_grads_norm = 3.7545
	sim_grads_norm = -0.0217
-- Starting training on experience 94 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7127
	data_grads_norm = 3.9331
	new_data_grads_norm = 5.0099
	old_data_grads_norm = 5.1689
	sim_grads_norm = 0.0298
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3361
	data_grads_norm = 3.3629
	new_data_grads_norm = 4.5449
	old_data_grads_norm = 4.9047
	sim_grads_norm = 0.0125
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5740
	data_grads_norm = 3.1576
	new_data_grads_norm = 4.8427
	old_data_grads_norm = 4.0842
	sim_grads_norm = -0.0015
-- Starting training on experience 95 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4403
	data_grads_norm = 3.5106
	new_data_grads_norm = 4.4366
	old_data_grads_norm = 6.2465
	sim_grads_norm = 0.0035
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5599
	data_grads_norm = 3.9508
	new_data_grads_norm = 5.2476
	old_data_grads_norm = 4.5940
	sim_grads_norm = -0.0189
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3151
	data_grads_norm = 3.4110
	new_data_grads_norm = 5.6785
	old_data_grads_norm = 3.5682
	sim_grads_norm = -0.0250
-- Starting training on experience 96 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3686
	data_grads_norm = 3.4631
	new_data_grads_norm = 5.2384
	old_data_grads_norm = 5.1743
	sim_grads_norm = -0.0258
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7045
	data_grads_norm = 4.1626
	new_data_grads_norm = 5.5337
	old_data_grads_norm = 5.4574
	sim_grads_norm = 0.0176
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6689
	data_grads_norm = 3.6383
	new_data_grads_norm = 5.0760
	old_data_grads_norm = 5.0506
	sim_grads_norm = 0.0656
-- Starting training on experience 97 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7171
	data_grads_norm = 3.7823
	new_data_grads_norm = 5.6375
	old_data_grads_norm = 4.8686
	sim_grads_norm = 0.0632
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7701
	data_grads_norm = 4.2506
	new_data_grads_norm = 5.1404
	old_data_grads_norm = 6.6400
	sim_grads_norm = 0.0390
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8210
	data_grads_norm = 4.1274
	new_data_grads_norm = 5.1628
	old_data_grads_norm = 5.9562
	sim_grads_norm = 0.0686
-- Starting training on experience 98 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6888
	data_grads_norm = 3.4159
	new_data_grads_norm = 4.8917
	old_data_grads_norm = 3.6566
	sim_grads_norm = 0.0254
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1530
	data_grads_norm = 3.2896
	new_data_grads_norm = 4.6289
	old_data_grads_norm = 5.2947
	sim_grads_norm = 0.0260
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9929
	data_grads_norm = 3.1518
	new_data_grads_norm = 4.5110
	old_data_grads_norm = 3.3061
	sim_grads_norm = 0.0827
-- Starting training on experience 99 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3489
	data_grads_norm = 3.6289
	new_data_grads_norm = 5.0832
	old_data_grads_norm = 4.2215
	sim_grads_norm = 0.0258
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8275
	data_grads_norm = 3.5775
	new_data_grads_norm = 5.5488
	old_data_grads_norm = 5.1430
	sim_grads_norm = -0.0120
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2256
	data_grads_norm = 3.2348
	new_data_grads_norm = 4.9544
	old_data_grads_norm = 3.9002
	sim_grads_norm = 0.1653
-- Starting training on experience 100 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3964
	data_grads_norm = 3.7557
	new_data_grads_norm = 5.2616
	old_data_grads_norm = 4.1880
	sim_grads_norm = 0.1184
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9691
	data_grads_norm = 3.2527
	new_data_grads_norm = 4.7142
	old_data_grads_norm = 4.4299
	sim_grads_norm = -0.0010
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6007
	data_grads_norm = 4.1036
	new_data_grads_norm = 4.4842
	old_data_grads_norm = 6.2582
	sim_grads_norm = 0.0128
-- Starting training on experience 101 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2231
	data_grads_norm = 3.6066
	new_data_grads_norm = 5.3098
	old_data_grads_norm = 5.2084
	sim_grads_norm = -0.0020
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0223
	data_grads_norm = 3.3300
	new_data_grads_norm = 5.2533
	old_data_grads_norm = 3.5039
	sim_grads_norm = 0.0314
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9425
	data_grads_norm = 3.2209
	new_data_grads_norm = 5.7165
	old_data_grads_norm = 4.8090
	sim_grads_norm = -0.1618
-- Starting training on experience 102 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4250
	data_grads_norm = 4.0107
	new_data_grads_norm = 5.2945
	old_data_grads_norm = 5.0484
	sim_grads_norm = 0.0965
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2830
	data_grads_norm = 3.7767
	new_data_grads_norm = 4.4434
	old_data_grads_norm = 5.6037
	sim_grads_norm = 0.0639
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2739
	data_grads_norm = 3.4900
	new_data_grads_norm = 4.0290
	old_data_grads_norm = 4.6992
	sim_grads_norm = -0.0280
-- Starting training on experience 103 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5614
	data_grads_norm = 3.7119
	new_data_grads_norm = 5.1335
	old_data_grads_norm = 4.8405
	sim_grads_norm = 0.1020
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2011
	data_grads_norm = 3.3425
	new_data_grads_norm = 4.2655
	old_data_grads_norm = 4.8363
	sim_grads_norm = -0.0060
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2493
	data_grads_norm = 3.4781
	new_data_grads_norm = 4.7732
	old_data_grads_norm = 5.1316
	sim_grads_norm = -0.0066
-- Starting training on experience 104 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5442
	data_grads_norm = 3.4909
	new_data_grads_norm = 4.9191
	old_data_grads_norm = 4.0844
	sim_grads_norm = -0.0174
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5181
	data_grads_norm = 3.3775
	new_data_grads_norm = 4.9645
	old_data_grads_norm = 3.6590
	sim_grads_norm = 0.0542
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3268
	data_grads_norm = 3.2772
	new_data_grads_norm = 4.8802
	old_data_grads_norm = 4.1842
	sim_grads_norm = -0.0459
-- Starting training on experience 105 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6374
	data_grads_norm = 3.5708
	new_data_grads_norm = 4.9534
	old_data_grads_norm = 4.8661
	sim_grads_norm = 0.0479
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2128
	data_grads_norm = 3.2200
	new_data_grads_norm = 5.1914
	old_data_grads_norm = 3.3140
	sim_grads_norm = -0.0192
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1854
	data_grads_norm = 3.1408
	new_data_grads_norm = 5.1026
	old_data_grads_norm = 4.2837
	sim_grads_norm = -0.0080
-- Starting training on experience 106 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9233
	data_grads_norm = 3.6069
	new_data_grads_norm = 5.1588
	old_data_grads_norm = 5.2543
	sim_grads_norm = -0.0784
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0800
	data_grads_norm = 3.6076
	new_data_grads_norm = 4.8049
	old_data_grads_norm = 4.3175
	sim_grads_norm = 0.0559
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6692
	data_grads_norm = 3.9608
	new_data_grads_norm = 4.7941
	old_data_grads_norm = 5.2023
	sim_grads_norm = 0.0574
-- Starting training on experience 107 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7324
	data_grads_norm = 3.0521
	new_data_grads_norm = 5.0312
	old_data_grads_norm = 3.3986
	sim_grads_norm = -0.0222
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3173
	data_grads_norm = 3.8480
	new_data_grads_norm = 4.9143
	old_data_grads_norm = 5.4107
	sim_grads_norm = -0.0418
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9728
	data_grads_norm = 3.4126
	new_data_grads_norm = 5.2012
	old_data_grads_norm = 3.9161
	sim_grads_norm = -0.0427
-- Starting training on experience 108 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0925
	data_grads_norm = 3.0166
	new_data_grads_norm = 4.3122
	old_data_grads_norm = 3.8625
	sim_grads_norm = -0.0283
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0098
	data_grads_norm = 2.9305
	new_data_grads_norm = 4.8204
	old_data_grads_norm = 3.6497
	sim_grads_norm = 0.0023
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3487
	data_grads_norm = 3.7283
	new_data_grads_norm = 4.8851
	old_data_grads_norm = 5.2198
	sim_grads_norm = -0.0420
-- Starting training on experience 109 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8414
	data_grads_norm = 4.5211
	new_data_grads_norm = 5.8718
	old_data_grads_norm = 5.8989
	sim_grads_norm = 0.0664
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2975
	data_grads_norm = 3.8447
	new_data_grads_norm = 5.2525
	old_data_grads_norm = 5.2050
	sim_grads_norm = -0.0245
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2594
	data_grads_norm = 3.5508
	new_data_grads_norm = 5.6112
	old_data_grads_norm = 3.7297
	sim_grads_norm = 0.0904
-- Starting training on experience 110 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2443
	data_grads_norm = 3.2718
	new_data_grads_norm = 4.7112
	old_data_grads_norm = 4.6741
	sim_grads_norm = 0.0410
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5597
	data_grads_norm = 3.8473
	new_data_grads_norm = 4.4659
	old_data_grads_norm = 5.3539
	sim_grads_norm = 0.0762
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0413
	data_grads_norm = 3.3260
	new_data_grads_norm = 4.0101
	old_data_grads_norm = 4.7059
	sim_grads_norm = 0.0665
-- Starting training on experience 111 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4254
	data_grads_norm = 4.4197
	new_data_grads_norm = 5.6830
	old_data_grads_norm = 5.6971
	sim_grads_norm = 0.0263
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7071
	data_grads_norm = 3.4704
	new_data_grads_norm = 5.4321
	old_data_grads_norm = 4.0966
	sim_grads_norm = 0.0017
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0623
	data_grads_norm = 3.7801
	new_data_grads_norm = 5.6794
	old_data_grads_norm = 4.2071
	sim_grads_norm = 0.0169
-- Starting training on experience 112 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5455
	data_grads_norm = 3.6429
	new_data_grads_norm = 4.8889
	old_data_grads_norm = 5.4407
	sim_grads_norm = 0.0140
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9649
	data_grads_norm = 3.8246
	new_data_grads_norm = 4.6927
	old_data_grads_norm = 4.8023
	sim_grads_norm = 0.0008
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0297
	data_grads_norm = 3.2952
	new_data_grads_norm = 4.4433
	old_data_grads_norm = 4.0280
	sim_grads_norm = 0.0058
-- Starting training on experience 113 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2202
	data_grads_norm = 3.4582
	new_data_grads_norm = 4.9751
	old_data_grads_norm = 4.2750
	sim_grads_norm = 0.0642
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2856
	data_grads_norm = 3.7534
	new_data_grads_norm = 5.3952
	old_data_grads_norm = 5.4648
	sim_grads_norm = 0.0361
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1444
	data_grads_norm = 3.3425
	new_data_grads_norm = 5.0692
	old_data_grads_norm = 4.3324
	sim_grads_norm = -0.0287
-- Starting training on experience 114 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3599
	data_grads_norm = 3.8983
	new_data_grads_norm = 6.0757
	old_data_grads_norm = 4.0696
	sim_grads_norm = -0.0134
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3198
	data_grads_norm = 3.8925
	new_data_grads_norm = 5.8512
	old_data_grads_norm = 4.6525
	sim_grads_norm = 0.0078
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0584
	data_grads_norm = 3.3015
	new_data_grads_norm = 4.8702
	old_data_grads_norm = 4.0049
	sim_grads_norm = -0.0113
-- Starting training on experience 115 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4781
	data_grads_norm = 3.3016
	new_data_grads_norm = 5.4649
	old_data_grads_norm = 3.3336
	sim_grads_norm = -0.0279
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3725
	data_grads_norm = 3.1839
	new_data_grads_norm = 5.0563
	old_data_grads_norm = 3.9966
	sim_grads_norm = -0.0316
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0511
	data_grads_norm = 3.8110
	new_data_grads_norm = 5.0794
	old_data_grads_norm = 5.0274
	sim_grads_norm = 0.0236
-- Starting training on experience 116 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9667
	data_grads_norm = 4.4932
	new_data_grads_norm = 5.4936
	old_data_grads_norm = 6.6494
	sim_grads_norm = -0.0505
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8448
	data_grads_norm = 4.0358
	new_data_grads_norm = 5.4282
	old_data_grads_norm = 5.4039
	sim_grads_norm = 0.0149
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8794
	data_grads_norm = 4.0472
	new_data_grads_norm = 5.5954
	old_data_grads_norm = 4.6545
	sim_grads_norm = 0.0894
-- Starting training on experience 117 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5316
	data_grads_norm = 3.6591
	new_data_grads_norm = 4.0853
	old_data_grads_norm = 5.5540
	sim_grads_norm = 0.0895
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1395
	data_grads_norm = 3.4758
	new_data_grads_norm = 4.0025
	old_data_grads_norm = 5.6674
	sim_grads_norm = 0.0114
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6122
	data_grads_norm = 3.5236
	new_data_grads_norm = 4.8223
	old_data_grads_norm = 5.0541
	sim_grads_norm = -0.0251
-- Starting training on experience 118 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5474
	data_grads_norm = 4.3121
	new_data_grads_norm = 4.8903
	old_data_grads_norm = 6.1733
	sim_grads_norm = 0.0361
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2849
	data_grads_norm = 3.5812
	new_data_grads_norm = 4.7015
	old_data_grads_norm = 4.4264
	sim_grads_norm = 0.0624
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0220
	data_grads_norm = 2.9140
	new_data_grads_norm = 4.8644
	old_data_grads_norm = 4.4079
	sim_grads_norm = -0.0998
-- Starting training on experience 119 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0624
	data_grads_norm = 3.1427
	new_data_grads_norm = 4.7445
	old_data_grads_norm = 4.0539
	sim_grads_norm = -0.0579
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3786
	data_grads_norm = 3.6818
	new_data_grads_norm = 4.6430
	old_data_grads_norm = 4.4237
	sim_grads_norm = 0.1408
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5154
	data_grads_norm = 3.4421
	new_data_grads_norm = 4.0707
	old_data_grads_norm = 5.1785
	sim_grads_norm = -0.0106
-- Starting training on experience 120 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3043
	data_grads_norm = 3.3443
	new_data_grads_norm = 5.0004
	old_data_grads_norm = 4.5084
	sim_grads_norm = -0.0608
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1170
	data_grads_norm = 3.2810
	new_data_grads_norm = 4.7529
	old_data_grads_norm = 4.1233
	sim_grads_norm = 0.0345
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5220
	data_grads_norm = 3.8338
	new_data_grads_norm = 4.9605
	old_data_grads_norm = 5.4264
	sim_grads_norm = -0.0073
-- Starting training on experience 121 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6030
	data_grads_norm = 3.6499
	new_data_grads_norm = 4.6131
	old_data_grads_norm = 4.9191
	sim_grads_norm = 0.0068
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1232
	data_grads_norm = 4.1778
	new_data_grads_norm = 5.4904
	old_data_grads_norm = 6.0464
	sim_grads_norm = 0.0195
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6535
	data_grads_norm = 4.0226
	new_data_grads_norm = 4.6270
	old_data_grads_norm = 6.7799
	sim_grads_norm = 0.0910
-- Starting training on experience 122 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6434
	data_grads_norm = 3.1673
	new_data_grads_norm = 5.1387
	old_data_grads_norm = 3.1678
	sim_grads_norm = 0.0629
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3330
	data_grads_norm = 4.1774
	new_data_grads_norm = 5.2142
	old_data_grads_norm = 6.3428
	sim_grads_norm = 0.0389
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4287
	data_grads_norm = 4.0259
	new_data_grads_norm = 4.9665
	old_data_grads_norm = 6.0996
	sim_grads_norm = 0.0017
-- Starting training on experience 123 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2930
	data_grads_norm = 3.4902
	new_data_grads_norm = 4.6175
	old_data_grads_norm = 5.1422
	sim_grads_norm = 0.0210
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3992
	data_grads_norm = 3.7424
	new_data_grads_norm = 5.0353
	old_data_grads_norm = 5.9428
	sim_grads_norm = -0.0275
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4549
	data_grads_norm = 3.5488
	new_data_grads_norm = 4.6922
	old_data_grads_norm = 4.6919
	sim_grads_norm = -0.0245
-- Starting training on experience 124 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1544
	data_grads_norm = 3.5207
	new_data_grads_norm = 4.6658
	old_data_grads_norm = 3.9184
	sim_grads_norm = 0.0671
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4201
	data_grads_norm = 4.0102
	new_data_grads_norm = 4.5401
	old_data_grads_norm = 6.2612
	sim_grads_norm = 0.0292
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0397
	data_grads_norm = 3.7082
	new_data_grads_norm = 4.4534
	old_data_grads_norm = 5.1442
	sim_grads_norm = 0.1348
-- Starting training on experience 125 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9144
	data_grads_norm = 3.3107
	new_data_grads_norm = 5.2275
	old_data_grads_norm = 4.0193
	sim_grads_norm = 0.0127
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1044
	data_grads_norm = 3.8048
	new_data_grads_norm = 5.6176
	old_data_grads_norm = 5.2702
	sim_grads_norm = 0.0494
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0432
	data_grads_norm = 3.5936
	new_data_grads_norm = 4.6878
	old_data_grads_norm = 5.1094
	sim_grads_norm = 0.0351
-- Starting training on experience 126 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0624
	data_grads_norm = 3.4469
	new_data_grads_norm = 5.0486
	old_data_grads_norm = 4.9106
	sim_grads_norm = -0.0299
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2562
	data_grads_norm = 3.9893
	new_data_grads_norm = 5.7158
	old_data_grads_norm = 5.5601
	sim_grads_norm = -0.0924
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5918
	data_grads_norm = 4.3891
	new_data_grads_norm = 5.8988
	old_data_grads_norm = 5.9148
	sim_grads_norm = 0.1161
-- Starting training on experience 127 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6701
	data_grads_norm = 4.0521
	new_data_grads_norm = 5.6227
	old_data_grads_norm = 5.7626
	sim_grads_norm = -0.0414
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3060
	data_grads_norm = 3.9031
	new_data_grads_norm = 5.5396
	old_data_grads_norm = 5.6997
	sim_grads_norm = -0.0232
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7064
	data_grads_norm = 4.2349
	new_data_grads_norm = 5.8481
	old_data_grads_norm = 5.8283
	sim_grads_norm = 0.0061
-- Starting training on experience 128 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3829
	data_grads_norm = 3.4786
	new_data_grads_norm = 5.4633
	old_data_grads_norm = 4.3641
	sim_grads_norm = -0.0243
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6158
	data_grads_norm = 4.1567
	new_data_grads_norm = 5.1670
	old_data_grads_norm = 5.1693
	sim_grads_norm = 0.0176
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0932
	data_grads_norm = 4.1498
	new_data_grads_norm = 5.4984
	old_data_grads_norm = 5.7684
	sim_grads_norm = 0.0512
-- Starting training on experience 129 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0364
	data_grads_norm = 3.0955
	new_data_grads_norm = 4.4388
	old_data_grads_norm = 4.0692
	sim_grads_norm = -0.0493
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4246
	data_grads_norm = 3.5166
	new_data_grads_norm = 4.5359
	old_data_grads_norm = 4.3020
	sim_grads_norm = 0.0167
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8132
	data_grads_norm = 3.9245
	new_data_grads_norm = 4.4943
	old_data_grads_norm = 5.3515
	sim_grads_norm = 0.0298
-- Starting training on experience 130 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8363
	data_grads_norm = 3.7881
	new_data_grads_norm = 4.6273
	old_data_grads_norm = 6.2878
	sim_grads_norm = 0.0618
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0862
	data_grads_norm = 3.2524
	new_data_grads_norm = 4.2951
	old_data_grads_norm = 4.3061
	sim_grads_norm = 0.0437
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7956
	data_grads_norm = 3.2946
	new_data_grads_norm = 4.5254
	old_data_grads_norm = 4.8681
	sim_grads_norm = -0.0590
-- Starting training on experience 131 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9690
	data_grads_norm = 2.9617
	new_data_grads_norm = 4.9594
	old_data_grads_norm = 3.7915
	sim_grads_norm = -0.0077
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6595
	data_grads_norm = 4.4386
	new_data_grads_norm = 5.5122
	old_data_grads_norm = 7.3504
	sim_grads_norm = 0.0772
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9147
	data_grads_norm = 3.2693
	new_data_grads_norm = 4.2876
	old_data_grads_norm = 3.8206
	sim_grads_norm = 0.0194
-- Starting training on experience 132 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8433
	data_grads_norm = 3.3013
	new_data_grads_norm = 3.9085
	old_data_grads_norm = 5.3417
	sim_grads_norm = 0.0004
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8397
	data_grads_norm = 3.3365
	new_data_grads_norm = 4.0638
	old_data_grads_norm = 6.2920
	sim_grads_norm = -0.0023
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4093
	data_grads_norm = 3.5172
	new_data_grads_norm = 4.3566
	old_data_grads_norm = 5.2288
	sim_grads_norm = 0.0040
-- Starting training on experience 133 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2265
	data_grads_norm = 4.1904
	new_data_grads_norm = 5.6694
	old_data_grads_norm = 6.0137
	sim_grads_norm = -0.0382
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1865
	data_grads_norm = 3.5961
	new_data_grads_norm = 4.9472
	old_data_grads_norm = 4.8128
	sim_grads_norm = 0.0035
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2860
	data_grads_norm = 3.8684
	new_data_grads_norm = 5.6841
	old_data_grads_norm = 5.0242
	sim_grads_norm = -0.0150
-- Starting training on experience 134 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7030
	data_grads_norm = 3.9599
	new_data_grads_norm = 5.3673
	old_data_grads_norm = 4.6082
	sim_grads_norm = 0.0085
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7325
	data_grads_norm = 3.9170
	new_data_grads_norm = 5.1835
	old_data_grads_norm = 5.2733
	sim_grads_norm = 0.0576
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5006
	data_grads_norm = 3.5322
	new_data_grads_norm = 5.0216
	old_data_grads_norm = 4.2187
	sim_grads_norm = 0.0382
-- Starting training on experience 135 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5687
	data_grads_norm = 4.3131
	new_data_grads_norm = 5.0243
	old_data_grads_norm = 6.1225
	sim_grads_norm = 0.0828
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1117
	data_grads_norm = 3.1919
	new_data_grads_norm = 4.4285
	old_data_grads_norm = 4.2613
	sim_grads_norm = -0.0394
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3993
	data_grads_norm = 3.9467
	new_data_grads_norm = 4.4590
	old_data_grads_norm = 5.8501
	sim_grads_norm = 0.0039
-- Starting training on experience 136 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5226
	data_grads_norm = 3.8441
	new_data_grads_norm = 5.6857
	old_data_grads_norm = 4.5828
	sim_grads_norm = 0.0978
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1968
	data_grads_norm = 3.6533
	new_data_grads_norm = 5.1832
	old_data_grads_norm = 6.2606
	sim_grads_norm = -0.0172
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3515
	data_grads_norm = 3.6972
	new_data_grads_norm = 4.9644
	old_data_grads_norm = 4.6452
	sim_grads_norm = 0.0978
-- Starting training on experience 137 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4609
	data_grads_norm = 3.9396
	new_data_grads_norm = 5.0611
	old_data_grads_norm = 5.7598
	sim_grads_norm = 0.0232
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2114
	data_grads_norm = 3.4909
	new_data_grads_norm = 4.9946
	old_data_grads_norm = 4.5955
	sim_grads_norm = -0.0170
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8573
	data_grads_norm = 3.5927
	new_data_grads_norm = 4.6443
	old_data_grads_norm = 4.0133
	sim_grads_norm = 0.0647
-- Starting training on experience 138 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4257
	data_grads_norm = 3.9344
	new_data_grads_norm = 5.2693
	old_data_grads_norm = 5.7406
	sim_grads_norm = 0.0459
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4800
	data_grads_norm = 3.8429
	new_data_grads_norm = 4.8049
	old_data_grads_norm = 5.1128
	sim_grads_norm = 0.0020
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8082
	data_grads_norm = 4.4257
	new_data_grads_norm = 5.7840
	old_data_grads_norm = 5.1476
	sim_grads_norm = 0.0078
-- Starting training on experience 139 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7389
	data_grads_norm = 4.2811
	new_data_grads_norm = 4.9538
	old_data_grads_norm = 5.6843
	sim_grads_norm = 0.0994
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3695
	data_grads_norm = 3.9294
	new_data_grads_norm = 4.6458
	old_data_grads_norm = 4.6135
	sim_grads_norm = 0.0080
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0630
	data_grads_norm = 3.1738
	new_data_grads_norm = 4.5310
	old_data_grads_norm = 4.4009
	sim_grads_norm = 0.0119
-- Starting training on experience 140 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1479
	data_grads_norm = 3.7105
	new_data_grads_norm = 4.8378
	old_data_grads_norm = 5.3932
	sim_grads_norm = -0.0332
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0179
	data_grads_norm = 3.5417
	new_data_grads_norm = 4.6827
	old_data_grads_norm = 4.7741
	sim_grads_norm = 0.0241
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8730
	data_grads_norm = 3.2706
	new_data_grads_norm = 4.6112
	old_data_grads_norm = 4.5876
	sim_grads_norm = -0.0401
-- Starting training on experience 141 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8644
	data_grads_norm = 3.5246
	new_data_grads_norm = 5.8388
	old_data_grads_norm = 3.7910
	sim_grads_norm = 0.0379
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2186
	data_grads_norm = 3.7695
	new_data_grads_norm = 5.7798
	old_data_grads_norm = 4.3274
	sim_grads_norm = -0.0127
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0252
	data_grads_norm = 3.1591
	new_data_grads_norm = 4.6545
	old_data_grads_norm = 3.6262
	sim_grads_norm = 0.0475
-- Starting training on experience 142 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7048
	data_grads_norm = 3.3204
	new_data_grads_norm = 4.3004
	old_data_grads_norm = 4.2043
	sim_grads_norm = 0.0311
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0848
	data_grads_norm = 3.5028
	new_data_grads_norm = 4.7924
	old_data_grads_norm = 5.0944
	sim_grads_norm = 0.0188
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1238
	data_grads_norm = 3.2992
	new_data_grads_norm = 4.3570
	old_data_grads_norm = 4.7376
	sim_grads_norm = 0.0177
-- Starting training on experience 143 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7738
	data_grads_norm = 3.1010
	new_data_grads_norm = 3.4427
	old_data_grads_norm = 5.3291
	sim_grads_norm = -0.0115
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4471
	data_grads_norm = 2.5492
	new_data_grads_norm = 3.4793
	old_data_grads_norm = 3.5339
	sim_grads_norm = -0.0601
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2660
	data_grads_norm = 3.5643
	new_data_grads_norm = 3.6744
	old_data_grads_norm = 6.4290
	sim_grads_norm = 0.0325
-- Starting training on experience 144 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0617
	data_grads_norm = 3.2588
	new_data_grads_norm = 4.6443
	old_data_grads_norm = 4.5437
	sim_grads_norm = 0.0129
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9307
	data_grads_norm = 3.3411
	new_data_grads_norm = 4.5533
	old_data_grads_norm = 4.3760
	sim_grads_norm = -0.0621
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0131
	data_grads_norm = 3.1702
	new_data_grads_norm = 4.6084
	old_data_grads_norm = 3.8373
	sim_grads_norm = 0.0053
-- Starting training on experience 145 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0112
	data_grads_norm = 3.6962
	new_data_grads_norm = 4.9910
	old_data_grads_norm = 4.6884
	sim_grads_norm = 0.0212
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8194
	data_grads_norm = 3.0300
	new_data_grads_norm = 4.2914
	old_data_grads_norm = 4.6656
	sim_grads_norm = -0.0452
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1873
	data_grads_norm = 3.6617
	new_data_grads_norm = 4.8744
	old_data_grads_norm = 4.5677
	sim_grads_norm = 0.1204
-- Starting training on experience 146 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9524
	data_grads_norm = 3.2270
	new_data_grads_norm = 4.0814
	old_data_grads_norm = 4.3020
	sim_grads_norm = -0.0840
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3242
	data_grads_norm = 3.6540
	new_data_grads_norm = 4.3929
	old_data_grads_norm = 4.4060
	sim_grads_norm = 0.0652
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8331
	data_grads_norm = 2.9519
	new_data_grads_norm = 4.4938
	old_data_grads_norm = 3.7215
	sim_grads_norm = -0.0444
-- Starting training on experience 147 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1322
	data_grads_norm = 3.6724
	new_data_grads_norm = 4.2589
	old_data_grads_norm = 5.3884
	sim_grads_norm = -0.0436
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0784
	data_grads_norm = 3.4271
	new_data_grads_norm = 4.3245
	old_data_grads_norm = 5.7442
	sim_grads_norm = -0.0118
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3447
	data_grads_norm = 3.6148
	new_data_grads_norm = 5.2250
	old_data_grads_norm = 4.0376
	sim_grads_norm = 0.0816
-- Starting training on experience 148 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9134
	data_grads_norm = 3.3254
	new_data_grads_norm = 5.6958
	old_data_grads_norm = 4.5824
	sim_grads_norm = -0.0272
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4106
	data_grads_norm = 4.1873
	new_data_grads_norm = 4.8065
	old_data_grads_norm = 5.0997
	sim_grads_norm = 0.1078
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9420
	data_grads_norm = 3.1397
	new_data_grads_norm = 4.4666
	old_data_grads_norm = 4.0948
	sim_grads_norm = -0.0099
-- Starting training on experience 149 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8476
	data_grads_norm = 3.4121
	new_data_grads_norm = 4.7481
	old_data_grads_norm = 4.5893
	sim_grads_norm = -0.0439
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2014
	data_grads_norm = 3.8252
	new_data_grads_norm = 5.1293
	old_data_grads_norm = 5.1091
	sim_grads_norm = 0.0088
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2926
	data_grads_norm = 3.7625
	new_data_grads_norm = 4.9665
	old_data_grads_norm = 5.1297
	sim_grads_norm = -0.0554
-- Starting training on experience 150 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6970
	data_grads_norm = 3.2422
	new_data_grads_norm = 5.1998
	old_data_grads_norm = 4.6072
	sim_grads_norm = -0.0729
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9427
	data_grads_norm = 3.1644
	new_data_grads_norm = 5.0433
	old_data_grads_norm = 4.8993
	sim_grads_norm = -0.0533
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4753
	data_grads_norm = 4.2248
	new_data_grads_norm = 5.9113
	old_data_grads_norm = 5.4405
	sim_grads_norm = 0.0902
-- Starting training on experience 151 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1596
	data_grads_norm = 4.0448
	new_data_grads_norm = 4.7285
	old_data_grads_norm = 6.3874
	sim_grads_norm = 0.0169
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1524
	data_grads_norm = 3.6066
	new_data_grads_norm = 4.7869
	old_data_grads_norm = 5.2591
	sim_grads_norm = 0.0570
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8641
	data_grads_norm = 3.4929
	new_data_grads_norm = 4.8957
	old_data_grads_norm = 5.1883
	sim_grads_norm = -0.0130
-- Starting training on experience 152 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4373
	data_grads_norm = 3.8541
	new_data_grads_norm = 4.8691
	old_data_grads_norm = 5.0696
	sim_grads_norm = 0.0673
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8800
	data_grads_norm = 3.1990
	new_data_grads_norm = 4.6554
	old_data_grads_norm = 4.0106
	sim_grads_norm = -0.0238
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5487
	data_grads_norm = 3.6940
	new_data_grads_norm = 4.4436
	old_data_grads_norm = 5.7683
	sim_grads_norm = -0.0037
-- Starting training on experience 153 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9932
	data_grads_norm = 3.1839
	new_data_grads_norm = 4.3645
	old_data_grads_norm = 4.0452
	sim_grads_norm = -0.0182
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7193
	data_grads_norm = 3.6156
	new_data_grads_norm = 4.8055
	old_data_grads_norm = 5.1708
	sim_grads_norm = 0.0864
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7366
	data_grads_norm = 3.1530
	new_data_grads_norm = 4.3887
	old_data_grads_norm = 4.7131
	sim_grads_norm = -0.0319
-- Starting training on experience 154 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7098
	data_grads_norm = 2.6937
	new_data_grads_norm = 3.7321
	old_data_grads_norm = 3.6946
	sim_grads_norm = 0.0628
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9498
	data_grads_norm = 3.7891
	new_data_grads_norm = 4.3238
	old_data_grads_norm = 6.2357
	sim_grads_norm = -0.0521
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4485
	data_grads_norm = 3.4496
	new_data_grads_norm = 4.3293
	old_data_grads_norm = 4.7407
	sim_grads_norm = -0.0320
-- Starting training on experience 155 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4090
	data_grads_norm = 3.2150
	new_data_grads_norm = 5.1018
	old_data_grads_norm = 3.8856
	sim_grads_norm = -0.0245
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5938
	data_grads_norm = 3.6149
	new_data_grads_norm = 5.6488
	old_data_grads_norm = 4.9680
	sim_grads_norm = 0.0565
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5543
	data_grads_norm = 4.3311
	new_data_grads_norm = 5.0925
	old_data_grads_norm = 6.9601
	sim_grads_norm = 0.0165
-- Starting training on experience 156 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5619
	data_grads_norm = 3.8695
	new_data_grads_norm = 5.5739
	old_data_grads_norm = 5.5229
	sim_grads_norm = -0.0053
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7656
	data_grads_norm = 3.1749
	new_data_grads_norm = 5.1360
	old_data_grads_norm = 4.6356
	sim_grads_norm = -0.0702
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2977
	data_grads_norm = 4.0360
	new_data_grads_norm = 5.1718
	old_data_grads_norm = 4.9414
	sim_grads_norm = 0.1043
-- Starting training on experience 157 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2699
	data_grads_norm = 4.1865
	new_data_grads_norm = 5.8433
	old_data_grads_norm = 5.1820
	sim_grads_norm = 0.0338
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2958
	data_grads_norm = 3.7499
	new_data_grads_norm = 5.5117
	old_data_grads_norm = 4.5196
	sim_grads_norm = 0.0584
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1557
	data_grads_norm = 3.3975
	new_data_grads_norm = 5.2414
	old_data_grads_norm = 4.5050
	sim_grads_norm = -0.0117
-- Starting training on experience 158 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7079
	data_grads_norm = 2.9491
	new_data_grads_norm = 4.6129
	old_data_grads_norm = 4.1128
	sim_grads_norm = -0.0447
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8408
	data_grads_norm = 3.2800
	new_data_grads_norm = 5.2513
	old_data_grads_norm = 3.5611
	sim_grads_norm = 0.0357
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1765
	data_grads_norm = 3.7159
	new_data_grads_norm = 4.8325
	old_data_grads_norm = 5.2613
	sim_grads_norm = -0.0684
-- Starting training on experience 159 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7070
	data_grads_norm = 3.6552
	new_data_grads_norm = 5.1307
	old_data_grads_norm = 5.0364
	sim_grads_norm = 0.0022
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6744
	data_grads_norm = 2.9245
	new_data_grads_norm = 4.9903
	old_data_grads_norm = 3.5918
	sim_grads_norm = 0.0077
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7560
	data_grads_norm = 3.4870
	new_data_grads_norm = 4.9501
	old_data_grads_norm = 4.8818
	sim_grads_norm = 0.0066
-- Starting training on experience 160 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4539
	data_grads_norm = 3.2954
	new_data_grads_norm = 5.5826
	old_data_grads_norm = 4.3170
	sim_grads_norm = -0.0391
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6666
	data_grads_norm = 3.5249
	new_data_grads_norm = 5.3402
	old_data_grads_norm = 4.1026
	sim_grads_norm = 0.0133
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5711
	data_grads_norm = 3.9275
	new_data_grads_norm = 5.5084
	old_data_grads_norm = 5.0997
	sim_grads_norm = -0.0671
-- Starting training on experience 161 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1166
	data_grads_norm = 4.1242
	new_data_grads_norm = 6.3139
	old_data_grads_norm = 5.8637
	sim_grads_norm = 0.0100
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3483
	data_grads_norm = 4.0497
	new_data_grads_norm = 6.7203
	old_data_grads_norm = 5.5228
	sim_grads_norm = -0.0239
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8345
	data_grads_norm = 4.3067
	new_data_grads_norm = 6.1759
	old_data_grads_norm = 5.6037
	sim_grads_norm = 0.1493
-- Starting training on experience 162 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2301
	data_grads_norm = 3.6408
	new_data_grads_norm = 5.3076
	old_data_grads_norm = 4.7853
	sim_grads_norm = -0.0264
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3198
	data_grads_norm = 4.0403
	new_data_grads_norm = 5.3797
	old_data_grads_norm = 5.1530
	sim_grads_norm = 0.0384
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8351
	data_grads_norm = 3.4432
	new_data_grads_norm = 5.3889
	old_data_grads_norm = 3.9706
	sim_grads_norm = -0.0486
-- Starting training on experience 163 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5143
	data_grads_norm = 3.7100
	new_data_grads_norm = 5.4805
	old_data_grads_norm = 4.4922
	sim_grads_norm = 0.0689
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1378
	data_grads_norm = 4.4002
	new_data_grads_norm = 5.8594
	old_data_grads_norm = 5.3089
	sim_grads_norm = 0.0326
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4994
	data_grads_norm = 3.7773
	new_data_grads_norm = 5.6210
	old_data_grads_norm = 4.5298
	sim_grads_norm = 0.1187
-- Starting training on experience 164 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0275
	data_grads_norm = 3.4879
	new_data_grads_norm = 4.9709
	old_data_grads_norm = 5.2486
	sim_grads_norm = -0.0281
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2092
	data_grads_norm = 3.6628
	new_data_grads_norm = 4.9889
	old_data_grads_norm = 4.9435
	sim_grads_norm = 0.0551
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0029
	data_grads_norm = 3.4722
	new_data_grads_norm = 5.1041
	old_data_grads_norm = 5.0438
	sim_grads_norm = -0.0361
-- Starting training on experience 165 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8686
	data_grads_norm = 3.5287
	new_data_grads_norm = 4.4036
	old_data_grads_norm = 4.4814
	sim_grads_norm = -0.0142
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6347
	data_grads_norm = 3.1539
	new_data_grads_norm = 5.2009
	old_data_grads_norm = 3.9539
	sim_grads_norm = 0.0043
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7049
	data_grads_norm = 4.4990
	new_data_grads_norm = 5.4302
	old_data_grads_norm = 7.4203
	sim_grads_norm = 0.0315
-- Starting training on experience 166 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9698
	data_grads_norm = 3.3390
	new_data_grads_norm = 4.9284
	old_data_grads_norm = 4.3305
	sim_grads_norm = -0.0206
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5095
	data_grads_norm = 3.9979
	new_data_grads_norm = 5.0737
	old_data_grads_norm = 5.3976
	sim_grads_norm = -0.0412
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2202
	data_grads_norm = 3.7732
	new_data_grads_norm = 5.5996
	old_data_grads_norm = 4.8041
	sim_grads_norm = -0.0255
-- Starting training on experience 167 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3677
	data_grads_norm = 3.5473
	new_data_grads_norm = 4.4815
	old_data_grads_norm = 5.3644
	sim_grads_norm = 0.0316
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2031
	data_grads_norm = 3.3906
	new_data_grads_norm = 4.7602
	old_data_grads_norm = 4.4211
	sim_grads_norm = 0.0209
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7372
	data_grads_norm = 3.0950
	new_data_grads_norm = 4.2427
	old_data_grads_norm = 4.6713
	sim_grads_norm = -0.0207
-- Starting training on experience 168 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9285
	data_grads_norm = 3.1769
	new_data_grads_norm = 4.5956
	old_data_grads_norm = 4.5453
	sim_grads_norm = -0.0169
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0705
	data_grads_norm = 3.3012
	new_data_grads_norm = 5.2294
	old_data_grads_norm = 4.8245
	sim_grads_norm = -0.0070
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3061
	data_grads_norm = 3.5698
	new_data_grads_norm = 4.8767
	old_data_grads_norm = 5.0505
	sim_grads_norm = 0.0209
-- Starting training on experience 169 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7061
	data_grads_norm = 2.8363
	new_data_grads_norm = 4.8088
	old_data_grads_norm = 3.5743
	sim_grads_norm = -0.0011
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0407
	data_grads_norm = 3.3237
	new_data_grads_norm = 4.7841
	old_data_grads_norm = 4.2064
	sim_grads_norm = 0.0616
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9752
	data_grads_norm = 3.2178
	new_data_grads_norm = 4.0312
	old_data_grads_norm = 4.4193
	sim_grads_norm = 0.1218
-- Starting training on experience 170 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3464
	data_grads_norm = 4.3605
	new_data_grads_norm = 6.5101
	old_data_grads_norm = 4.5171
	sim_grads_norm = 0.1081
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2336
	data_grads_norm = 3.8756
	new_data_grads_norm = 5.9694
	old_data_grads_norm = 5.0737
	sim_grads_norm = -0.0058
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4023
	data_grads_norm = 4.5684
	new_data_grads_norm = 6.4430
	old_data_grads_norm = 4.9747
	sim_grads_norm = 0.0310
-- Starting training on experience 171 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4665
	data_grads_norm = 3.0214
	new_data_grads_norm = 5.1190
	old_data_grads_norm = 3.8769
	sim_grads_norm = -0.0526
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1902
	data_grads_norm = 4.3367
	new_data_grads_norm = 5.0722
	old_data_grads_norm = 6.1974
	sim_grads_norm = 0.0451
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9760
	data_grads_norm = 3.7740
	new_data_grads_norm = 4.3464
	old_data_grads_norm = 5.6205
	sim_grads_norm = -0.0118
-- Starting training on experience 172 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7684
	data_grads_norm = 3.2427
	new_data_grads_norm = 4.8084
	old_data_grads_norm = 4.6167
	sim_grads_norm = -0.0095
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5423
	data_grads_norm = 4.1157
	new_data_grads_norm = 5.0547
	old_data_grads_norm = 6.0604
	sim_grads_norm = 0.0234
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7836
	data_grads_norm = 3.0273
	new_data_grads_norm = 4.7761
	old_data_grads_norm = 3.7886
	sim_grads_norm = -0.0527
-- Starting training on experience 173 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8414
	data_grads_norm = 3.1693
	new_data_grads_norm = 4.5322
	old_data_grads_norm = 4.5397
	sim_grads_norm = -0.0008
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9054
	data_grads_norm = 3.1833
	new_data_grads_norm = 4.2285
	old_data_grads_norm = 5.0187
	sim_grads_norm = -0.0405
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3531
	data_grads_norm = 3.7167
	new_data_grads_norm = 4.3134
	old_data_grads_norm = 5.4623
	sim_grads_norm = 0.0466
-- Starting training on experience 174 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1300
	data_grads_norm = 3.5108
	new_data_grads_norm = 4.7278
	old_data_grads_norm = 4.7901
	sim_grads_norm = 0.0556
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5663
	data_grads_norm = 3.9489
	new_data_grads_norm = 6.0080
	old_data_grads_norm = 5.1904
	sim_grads_norm = -0.0664
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6496
	data_grads_norm = 4.1622
	new_data_grads_norm = 6.1471
	old_data_grads_norm = 5.4505
	sim_grads_norm = 0.0174
-- Starting training on experience 175 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0252
	data_grads_norm = 3.1904
	new_data_grads_norm = 4.2458
	old_data_grads_norm = 5.1741
	sim_grads_norm = -0.0828
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2512
	data_grads_norm = 3.7238
	new_data_grads_norm = 4.8378
	old_data_grads_norm = 5.3054
	sim_grads_norm = 0.0212
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3215
	data_grads_norm = 3.2727
	new_data_grads_norm = 4.3615
	old_data_grads_norm = 4.4390
	sim_grads_norm = 0.0635
-- Starting training on experience 176 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8552
	data_grads_norm = 3.2072
	new_data_grads_norm = 5.2964
	old_data_grads_norm = 3.0938
	sim_grads_norm = -0.0196
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9766
	data_grads_norm = 3.4302
	new_data_grads_norm = 4.9008
	old_data_grads_norm = 4.2095
	sim_grads_norm = 0.0362
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3665
	data_grads_norm = 3.9934
	new_data_grads_norm = 5.3032
	old_data_grads_norm = 5.2905
	sim_grads_norm = -0.0442
-- Starting training on experience 177 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6638
	data_grads_norm = 3.8721
	new_data_grads_norm = 5.1819
	old_data_grads_norm = 5.0937
	sim_grads_norm = 0.0445
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2081
	data_grads_norm = 3.3632
	new_data_grads_norm = 4.5426
	old_data_grads_norm = 4.1555
	sim_grads_norm = 0.0300
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0078
	data_grads_norm = 3.3968
	new_data_grads_norm = 4.7486
	old_data_grads_norm = 4.9494
	sim_grads_norm = 0.0077
-- Starting training on experience 178 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2067
	data_grads_norm = 3.1897
	new_data_grads_norm = 4.7632
	old_data_grads_norm = 3.7907
	sim_grads_norm = 0.0702
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0103
	data_grads_norm = 3.3128
	new_data_grads_norm = 4.2327
	old_data_grads_norm = 5.0059
	sim_grads_norm = 0.0156
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5587
	data_grads_norm = 3.1451
	new_data_grads_norm = 4.4940
	old_data_grads_norm = 4.2655
	sim_grads_norm = 0.0438
-- Starting training on experience 179 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9305
	data_grads_norm = 3.5954
	new_data_grads_norm = 4.7664
	old_data_grads_norm = 5.1530
	sim_grads_norm = -0.0161
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5946
	data_grads_norm = 3.4743
	new_data_grads_norm = 5.3059
	old_data_grads_norm = 3.8757
	sim_grads_norm = 0.0223
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9234
	data_grads_norm = 3.3440
	new_data_grads_norm = 4.6796
	old_data_grads_norm = 4.8934
	sim_grads_norm = -0.0394
-- Starting training on experience 180 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0897
	data_grads_norm = 3.2581
	new_data_grads_norm = 3.9408
	old_data_grads_norm = 5.8052
	sim_grads_norm = -0.0485
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0728
	data_grads_norm = 3.4757
	new_data_grads_norm = 3.9647
	old_data_grads_norm = 5.8075
	sim_grads_norm = -0.0351
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9186
	data_grads_norm = 3.4471
	new_data_grads_norm = 4.4498
	old_data_grads_norm = 5.5330
	sim_grads_norm = 0.1066
-- Starting training on experience 181 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0964
	data_grads_norm = 3.2580
	new_data_grads_norm = 4.4915
	old_data_grads_norm = 4.1621
	sim_grads_norm = 0.0038
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1373
	data_grads_norm = 3.2008
	new_data_grads_norm = 5.2622
	old_data_grads_norm = 4.0923
	sim_grads_norm = 0.0047
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7543
	data_grads_norm = 4.0291
	new_data_grads_norm = 4.4263
	old_data_grads_norm = 5.9882
	sim_grads_norm = -0.0167
-- Starting training on experience 182 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0481
	data_grads_norm = 3.8294
	new_data_grads_norm = 5.7113
	old_data_grads_norm = 5.2650
	sim_grads_norm = -0.0309
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3098
	data_grads_norm = 3.9814
	new_data_grads_norm = 5.7555
	old_data_grads_norm = 4.6466
	sim_grads_norm = 0.0582
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1027
	data_grads_norm = 3.9120
	new_data_grads_norm = 5.9265
	old_data_grads_norm = 4.9861
	sim_grads_norm = 0.0479
-- Starting training on experience 183 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8568
	data_grads_norm = 3.4666
	new_data_grads_norm = 5.0786
	old_data_grads_norm = 4.6233
	sim_grads_norm = 0.0370
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2704
	data_grads_norm = 3.7314
	new_data_grads_norm = 5.1074
	old_data_grads_norm = 4.7857
	sim_grads_norm = -0.0012
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2541
	data_grads_norm = 3.6247
	new_data_grads_norm = 4.9636
	old_data_grads_norm = 4.0573
	sim_grads_norm = 0.1550
-- Starting training on experience 184 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0969
	data_grads_norm = 3.7969
	new_data_grads_norm = 4.8625
	old_data_grads_norm = 5.6058
	sim_grads_norm = -0.0151
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0636
	data_grads_norm = 3.6738
	new_data_grads_norm = 4.6994
	old_data_grads_norm = 5.2277
	sim_grads_norm = 0.0500
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4305
	data_grads_norm = 4.0544
	new_data_grads_norm = 4.8019
	old_data_grads_norm = 6.1852
	sim_grads_norm = -0.0247
-- Starting training on experience 185 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0573
	data_grads_norm = 3.5161
	new_data_grads_norm = 4.7433
	old_data_grads_norm = 4.4554
	sim_grads_norm = 0.0923
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8557
	data_grads_norm = 3.0125
	new_data_grads_norm = 4.7788
	old_data_grads_norm = 3.6438
	sim_grads_norm = 0.0468
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9487
	data_grads_norm = 3.1375
	new_data_grads_norm = 4.6670
	old_data_grads_norm = 4.1593
	sim_grads_norm = 0.0620
-- Starting training on experience 186 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7942
	data_grads_norm = 3.5457
	new_data_grads_norm = 4.2022
	old_data_grads_norm = 5.0901
	sim_grads_norm = 0.0378
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9368
	data_grads_norm = 3.0954
	new_data_grads_norm = 4.2294
	old_data_grads_norm = 5.4603
	sim_grads_norm = -0.0249
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7928
	data_grads_norm = 3.3674
	new_data_grads_norm = 3.9785
	old_data_grads_norm = 4.2550
	sim_grads_norm = 0.1172
-- Starting training on experience 187 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0539
	data_grads_norm = 3.7169
	new_data_grads_norm = 5.5570
	old_data_grads_norm = 3.3063
	sim_grads_norm = -0.0573
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7600
	data_grads_norm = 3.9785
	new_data_grads_norm = 5.5124
	old_data_grads_norm = 4.8669
	sim_grads_norm = 0.1121
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0763
	data_grads_norm = 3.4444
	new_data_grads_norm = 4.8059
	old_data_grads_norm = 4.0698
	sim_grads_norm = -0.0462
-- Starting training on experience 188 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9748
	data_grads_norm = 3.1263
	new_data_grads_norm = 4.6890
	old_data_grads_norm = 4.1373
	sim_grads_norm = 0.0275
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9645
	data_grads_norm = 3.1793
	new_data_grads_norm = 4.5550
	old_data_grads_norm = 4.1025
	sim_grads_norm = -0.0076
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8576
	data_grads_norm = 3.2168
	new_data_grads_norm = 4.7726
	old_data_grads_norm = 4.6526
	sim_grads_norm = -0.0617
-- Starting training on experience 189 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6556
	data_grads_norm = 3.2135
	new_data_grads_norm = 4.7042
	old_data_grads_norm = 4.5357
	sim_grads_norm = 0.0187
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8279
	data_grads_norm = 4.0064
	new_data_grads_norm = 4.5760
	old_data_grads_norm = 6.2059
	sim_grads_norm = -0.0419
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8641
	data_grads_norm = 3.5852
	new_data_grads_norm = 5.0539
	old_data_grads_norm = 5.5847
	sim_grads_norm = 0.0077
-- Starting training on experience 190 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2688
	data_grads_norm = 4.0115
	new_data_grads_norm = 5.5818
	old_data_grads_norm = 4.8385
	sim_grads_norm = -0.0203
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4338
	data_grads_norm = 4.1361
	new_data_grads_norm = 5.9592
	old_data_grads_norm = 5.0811
	sim_grads_norm = 0.0742
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2103
	data_grads_norm = 3.6610
	new_data_grads_norm = 5.4004
	old_data_grads_norm = 4.1826
	sim_grads_norm = 0.1020
-- Starting training on experience 191 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8833
	data_grads_norm = 3.4449
	new_data_grads_norm = 4.7167
	old_data_grads_norm = 4.4805
	sim_grads_norm = 0.0551
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6569
	data_grads_norm = 3.2297
	new_data_grads_norm = 4.7202
	old_data_grads_norm = 3.8394
	sim_grads_norm = 0.0012
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8735
	data_grads_norm = 3.0555
	new_data_grads_norm = 4.8434
	old_data_grads_norm = 4.0170
	sim_grads_norm = -0.0357
-- Starting training on experience 192 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1176
	data_grads_norm = 4.1433
	new_data_grads_norm = 4.9459
	old_data_grads_norm = 6.0110
	sim_grads_norm = -0.0092
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1744
	data_grads_norm = 3.4131
	new_data_grads_norm = 4.5414
	old_data_grads_norm = 4.2980
	sim_grads_norm = 0.0431
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3668
	data_grads_norm = 3.8946
	new_data_grads_norm = 4.5249
	old_data_grads_norm = 6.2101
	sim_grads_norm = 0.0190
-- Starting training on experience 193 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5160
	data_grads_norm = 2.7412
	new_data_grads_norm = 4.1902
	old_data_grads_norm = 3.8887
	sim_grads_norm = -0.0659
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7436
	data_grads_norm = 3.2306
	new_data_grads_norm = 4.1800
	old_data_grads_norm = 4.8129
	sim_grads_norm = -0.0052
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2857
	data_grads_norm = 3.8178
	new_data_grads_norm = 4.2648
	old_data_grads_norm = 5.8254
	sim_grads_norm = 0.0509
-- Starting training on experience 194 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3953
	data_grads_norm = 3.6345
	new_data_grads_norm = 5.6435
	old_data_grads_norm = 4.1659
	sim_grads_norm = 0.0425
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5148
	data_grads_norm = 3.9333
	new_data_grads_norm = 5.6135
	old_data_grads_norm = 6.2632
	sim_grads_norm = -0.0312
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9713
	data_grads_norm = 4.5084
	new_data_grads_norm = 6.3058
	old_data_grads_norm = 5.4853
	sim_grads_norm = 0.0631
-- Starting training on experience 195 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9982
	data_grads_norm = 3.4759
	new_data_grads_norm = 5.3057
	old_data_grads_norm = 3.6899
	sim_grads_norm = -0.0129
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6402
	data_grads_norm = 3.4943
	new_data_grads_norm = 5.6405
	old_data_grads_norm = 4.7239
	sim_grads_norm = 0.0075
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8677
	data_grads_norm = 3.3352
	new_data_grads_norm = 4.9436
	old_data_grads_norm = 5.1590
	sim_grads_norm = -0.0028
-- Starting training on experience 196 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9508
	data_grads_norm = 3.3442
	new_data_grads_norm = 4.4163
	old_data_grads_norm = 4.9167
	sim_grads_norm = 0.0886
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9584
	data_grads_norm = 2.9769
	new_data_grads_norm = 4.8609
	old_data_grads_norm = 4.3450
	sim_grads_norm = -0.0681
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1698
	data_grads_norm = 3.3148
	new_data_grads_norm = 4.8461
	old_data_grads_norm = 4.3048
	sim_grads_norm = -0.0384
-- Starting training on experience 197 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4128
	data_grads_norm = 3.3415
	new_data_grads_norm = 5.4031
	old_data_grads_norm = 3.9360
	sim_grads_norm = -0.0403
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3943
	data_grads_norm = 3.6437
	new_data_grads_norm = 5.0559
	old_data_grads_norm = 5.7688
	sim_grads_norm = -0.0574
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4936
	data_grads_norm = 4.0138
	new_data_grads_norm = 5.8809
	old_data_grads_norm = 4.7054
	sim_grads_norm = 0.0050
-- Starting training on experience 198 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2078
	data_grads_norm = 3.9079
	new_data_grads_norm = 5.7992
	old_data_grads_norm = 4.6138
	sim_grads_norm = 0.0699
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6447
	data_grads_norm = 3.6212
	new_data_grads_norm = 5.6409
	old_data_grads_norm = 4.9292
	sim_grads_norm = 0.0916
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0674
	data_grads_norm = 3.4728
	new_data_grads_norm = 5.3892
	old_data_grads_norm = 4.0068
	sim_grads_norm = 0.0021
-- Starting training on experience 199 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4156
	data_grads_norm = 4.3474
	new_data_grads_norm = 6.1333
	old_data_grads_norm = 5.7086
	sim_grads_norm = 0.0099
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1421
	data_grads_norm = 3.8968
	new_data_grads_norm = 6.1803
	old_data_grads_norm = 4.7496
	sim_grads_norm = 0.0269
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3454
	data_grads_norm = 3.6004
	new_data_grads_norm = 5.5294
	old_data_grads_norm = 4.9034
	sim_grads_norm = 0.0091
-- Starting training on experience 200 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0584
	data_grads_norm = 3.5313
	new_data_grads_norm = 5.5298
	old_data_grads_norm = 3.9285
	sim_grads_norm = 0.0289
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9307
	data_grads_norm = 3.3563
	new_data_grads_norm = 5.7572
	old_data_grads_norm = 3.4933
	sim_grads_norm = -0.0104
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1485
	data_grads_norm = 3.7080
	new_data_grads_norm = 5.2242
	old_data_grads_norm = 5.3904
	sim_grads_norm = -0.0137
-- Starting training on experience 201 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1841
	data_grads_norm = 3.5102
	new_data_grads_norm = 4.7655
	old_data_grads_norm = 4.2384
	sim_grads_norm = 0.1127
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0067
	data_grads_norm = 3.5068
	new_data_grads_norm = 4.8989
	old_data_grads_norm = 4.3084
	sim_grads_norm = 0.0564
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9072
	data_grads_norm = 3.3062
	new_data_grads_norm = 5.0830
	old_data_grads_norm = 4.6149
	sim_grads_norm = 0.0194
-- Starting training on experience 202 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0374
	data_grads_norm = 3.3230
	new_data_grads_norm = 4.1074
	old_data_grads_norm = 5.6574
	sim_grads_norm = -0.0406
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9365
	data_grads_norm = 3.2859
	new_data_grads_norm = 3.9940
	old_data_grads_norm = 4.7258
	sim_grads_norm = 0.0043
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4320
	data_grads_norm = 2.5508
	new_data_grads_norm = 3.7864
	old_data_grads_norm = 3.4046
	sim_grads_norm = 0.0111
-- Starting training on experience 203 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2797
	data_grads_norm = 3.8496
	new_data_grads_norm = 4.9816
	old_data_grads_norm = 5.2240
	sim_grads_norm = 0.0251
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2385
	data_grads_norm = 3.8386
	new_data_grads_norm = 4.8669
	old_data_grads_norm = 4.5208
	sim_grads_norm = 0.0582
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1743
	data_grads_norm = 3.7912
	new_data_grads_norm = 4.7006
	old_data_grads_norm = 5.3377
	sim_grads_norm = 0.0518
-- Starting training on experience 204 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0792
	data_grads_norm = 3.1221
	new_data_grads_norm = 4.6799
	old_data_grads_norm = 4.0774
	sim_grads_norm = 0.0190
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8905
	data_grads_norm = 3.9548
	new_data_grads_norm = 4.9341
	old_data_grads_norm = 5.4386
	sim_grads_norm = 0.0085
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7706
	data_grads_norm = 4.5626
	new_data_grads_norm = 5.1735
	old_data_grads_norm = 6.8926
	sim_grads_norm = 0.0246
-- Starting training on experience 205 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3401
	data_grads_norm = 3.7886
	new_data_grads_norm = 5.7695
	old_data_grads_norm = 3.9548
	sim_grads_norm = 0.0048
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0006
	data_grads_norm = 3.6353
	new_data_grads_norm = 5.4060
	old_data_grads_norm = 4.7139
	sim_grads_norm = 0.0327
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4347
	data_grads_norm = 4.5588
	new_data_grads_norm = 6.4731
	old_data_grads_norm = 4.7612
	sim_grads_norm = 0.0058
-- Starting training on experience 206 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2289
	data_grads_norm = 3.7788
	new_data_grads_norm = 6.1003
	old_data_grads_norm = 4.0859
	sim_grads_norm = 0.0619
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0946
	data_grads_norm = 3.3439
	new_data_grads_norm = 5.1403
	old_data_grads_norm = 4.1174
	sim_grads_norm = 0.1401
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2591
	data_grads_norm = 4.0600
	new_data_grads_norm = 5.1638
	old_data_grads_norm = 5.5546
	sim_grads_norm = 0.0132
-- Starting training on experience 207 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4335
	data_grads_norm = 3.9390
	new_data_grads_norm = 5.2525
	old_data_grads_norm = 5.8645
	sim_grads_norm = 0.0521
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4551
	data_grads_norm = 4.0668
	new_data_grads_norm = 4.7072
	old_data_grads_norm = 5.3883
	sim_grads_norm = 0.0119
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3420
	data_grads_norm = 4.0924
	new_data_grads_norm = 5.9255
	old_data_grads_norm = 4.6436
	sim_grads_norm = 0.0849
-- Starting training on experience 208 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0383
	data_grads_norm = 3.6718
	new_data_grads_norm = 4.6827
	old_data_grads_norm = 4.7687
	sim_grads_norm = 0.0277
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4335
	data_grads_norm = 3.8279
	new_data_grads_norm = 5.3308
	old_data_grads_norm = 4.3235
	sim_grads_norm = 0.1806
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4512
	data_grads_norm = 4.4609
	new_data_grads_norm = 5.3438
	old_data_grads_norm = 6.9620
	sim_grads_norm = -0.0546
-- Starting training on experience 209 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4215
	data_grads_norm = 3.6409
	new_data_grads_norm = 5.5180
	old_data_grads_norm = 4.6371
	sim_grads_norm = -0.0314
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5843
	data_grads_norm = 4.3263
	new_data_grads_norm = 5.6447
	old_data_grads_norm = 5.3727
	sim_grads_norm = 0.0923
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9991
	data_grads_norm = 3.5570
	new_data_grads_norm = 5.0647
	old_data_grads_norm = 5.5885
	sim_grads_norm = -0.0034
-- Starting training on experience 210 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4191
	data_grads_norm = 3.6093
	new_data_grads_norm = 5.1348
	old_data_grads_norm = 5.4881
	sim_grads_norm = 0.0362
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3866
	data_grads_norm = 3.6431
	new_data_grads_norm = 5.0913
	old_data_grads_norm = 4.9801
	sim_grads_norm = -0.0298
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2551
	data_grads_norm = 3.9312
	new_data_grads_norm = 5.4644
	old_data_grads_norm = 5.0663
	sim_grads_norm = 0.0222
-- Starting training on experience 211 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2485
	data_grads_norm = 3.7462
	new_data_grads_norm = 4.9725
	old_data_grads_norm = 4.8513
	sim_grads_norm = 0.1240
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9132
	data_grads_norm = 3.6773
	new_data_grads_norm = 5.1686
	old_data_grads_norm = 3.9021
	sim_grads_norm = -0.0106
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4146
	data_grads_norm = 3.8533
	new_data_grads_norm = 4.6607
	old_data_grads_norm = 5.7852
	sim_grads_norm = 0.0188
-- Starting training on experience 212 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9488
	data_grads_norm = 3.3850
	new_data_grads_norm = 4.9155
	old_data_grads_norm = 4.6890
	sim_grads_norm = 0.0930
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8405
	data_grads_norm = 3.4210
	new_data_grads_norm = 4.5446
	old_data_grads_norm = 5.1264
	sim_grads_norm = 0.0411
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5937
	data_grads_norm = 3.6517
	new_data_grads_norm = 4.7074
	old_data_grads_norm = 5.5606
	sim_grads_norm = 0.0348
-- Starting training on experience 213 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8016
	data_grads_norm = 3.5831
	new_data_grads_norm = 4.4975
	old_data_grads_norm = 4.9805
	sim_grads_norm = -0.0228
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0069
	data_grads_norm = 3.5481
	new_data_grads_norm = 4.3589
	old_data_grads_norm = 5.9191
	sim_grads_norm = -0.0127
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1207
	data_grads_norm = 3.5327
	new_data_grads_norm = 4.2923
	old_data_grads_norm = 6.0778
	sim_grads_norm = -0.0716
-- Starting training on experience 214 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1447
	data_grads_norm = 4.0077
	new_data_grads_norm = 6.0939
	old_data_grads_norm = 4.4813
	sim_grads_norm = -0.0146
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5904
	data_grads_norm = 4.7269
	new_data_grads_norm = 6.2110
	old_data_grads_norm = 6.6147
	sim_grads_norm = 0.0538
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2340
	data_grads_norm = 4.0421
	new_data_grads_norm = 5.2572
	old_data_grads_norm = 4.8812
	sim_grads_norm = 0.0348
-- Starting training on experience 215 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3392
	data_grads_norm = 3.6331
	new_data_grads_norm = 4.6482
	old_data_grads_norm = 5.1093
	sim_grads_norm = 0.0363
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1359
	data_grads_norm = 3.3258
	new_data_grads_norm = 4.8370
	old_data_grads_norm = 4.9372
	sim_grads_norm = 0.0001
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1202
	data_grads_norm = 3.2390
	new_data_grads_norm = 4.9593
	old_data_grads_norm = 4.4782
	sim_grads_norm = -0.0194
-- Starting training on experience 216 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2145
	data_grads_norm = 4.1904
	new_data_grads_norm = 6.6320
	old_data_grads_norm = 4.5703
	sim_grads_norm = 0.0270
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7760
	data_grads_norm = 5.0174
	new_data_grads_norm = 6.4158
	old_data_grads_norm = 6.3361
	sim_grads_norm = 0.0039
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2133
	data_grads_norm = 4.3067
	new_data_grads_norm = 6.1305
	old_data_grads_norm = 4.8068
	sim_grads_norm = 0.0062
-- Starting training on experience 217 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1040
	data_grads_norm = 3.7748
	new_data_grads_norm = 5.6912
	old_data_grads_norm = 5.0042
	sim_grads_norm = -0.0282
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7515
	data_grads_norm = 4.4910
	new_data_grads_norm = 6.0769
	old_data_grads_norm = 5.5899
	sim_grads_norm = -0.0056
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3858
	data_grads_norm = 3.9169
	new_data_grads_norm = 5.8981
	old_data_grads_norm = 5.1042
	sim_grads_norm = 0.0087
-- Starting training on experience 218 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4407
	data_grads_norm = 3.8906
	new_data_grads_norm = 5.0827
	old_data_grads_norm = 4.7214
	sim_grads_norm = 0.0748
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3199
	data_grads_norm = 3.6892
	new_data_grads_norm = 5.0390
	old_data_grads_norm = 4.3110
	sim_grads_norm = 0.0653
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1631
	data_grads_norm = 3.4558
	new_data_grads_norm = 5.5407
	old_data_grads_norm = 5.0810
	sim_grads_norm = 0.0100
-- Starting training on experience 219 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1459
	data_grads_norm = 3.3357
	new_data_grads_norm = 4.8824
	old_data_grads_norm = 4.7563
	sim_grads_norm = -0.0031
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4699
	data_grads_norm = 4.0277
	new_data_grads_norm = 4.9418
	old_data_grads_norm = 6.1108
	sim_grads_norm = -0.0044
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9100
	data_grads_norm = 3.4058
	new_data_grads_norm = 4.8345
	old_data_grads_norm = 5.4020
	sim_grads_norm = 0.0303
-- Starting training on experience 220 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5392
	data_grads_norm = 3.8939
	new_data_grads_norm = 5.0655
	old_data_grads_norm = 4.9671
	sim_grads_norm = -0.0335
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9936
	data_grads_norm = 3.4790
	new_data_grads_norm = 5.5213
	old_data_grads_norm = 4.6602
	sim_grads_norm = -0.0330
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4966
	data_grads_norm = 4.2991
	new_data_grads_norm = 5.2989
	old_data_grads_norm = 5.3903
	sim_grads_norm = 0.1038
-- Starting training on experience 221 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1474
	data_grads_norm = 3.3278
	new_data_grads_norm = 4.9427
	old_data_grads_norm = 4.1777
	sim_grads_norm = 0.0921
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1332
	data_grads_norm = 3.2222
	new_data_grads_norm = 4.4544
	old_data_grads_norm = 5.1256
	sim_grads_norm = -0.0635
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1661
	data_grads_norm = 3.3605
	new_data_grads_norm = 4.8358
	old_data_grads_norm = 4.3294
	sim_grads_norm = 0.0845
-- Starting training on experience 222 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7148
	data_grads_norm = 4.0052
	new_data_grads_norm = 5.7502
	old_data_grads_norm = 4.7252
	sim_grads_norm = -0.0391
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2545
	data_grads_norm = 3.5603
	new_data_grads_norm = 5.4814
	old_data_grads_norm = 5.0036
	sim_grads_norm = -0.1061
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0208
	data_grads_norm = 4.1964
	new_data_grads_norm = 6.2732
	old_data_grads_norm = 4.5558
	sim_grads_norm = 0.0392
-- Starting training on experience 223 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7994
	data_grads_norm = 3.2018
	new_data_grads_norm = 5.0385
	old_data_grads_norm = 4.2226
	sim_grads_norm = -0.0422
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0357
	data_grads_norm = 3.3366
	new_data_grads_norm = 4.8310
	old_data_grads_norm = 4.1046
	sim_grads_norm = 0.0158
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5265
	data_grads_norm = 3.4500
	new_data_grads_norm = 5.1083
	old_data_grads_norm = 4.3853
	sim_grads_norm = -0.0059
-- Starting training on experience 224 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3134
	data_grads_norm = 3.6590
	new_data_grads_norm = 5.3583
	old_data_grads_norm = 5.0947
	sim_grads_norm = -0.0135
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2052
	data_grads_norm = 3.9280
	new_data_grads_norm = 5.5702
	old_data_grads_norm = 5.0941
	sim_grads_norm = 0.0418
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2559
	data_grads_norm = 3.5736
	new_data_grads_norm = 5.4144
	old_data_grads_norm = 3.8677
	sim_grads_norm = 0.0294
-- Starting training on experience 225 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1539
	data_grads_norm = 4.2431
	new_data_grads_norm = 5.6257
	old_data_grads_norm = 6.5927
	sim_grads_norm = -0.0157
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0150
	data_grads_norm = 4.3235
	new_data_grads_norm = 5.9797
	old_data_grads_norm = 5.8770
	sim_grads_norm = -0.0308
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2309
	data_grads_norm = 4.2245
	new_data_grads_norm = 5.4767
	old_data_grads_norm = 4.9405
	sim_grads_norm = 0.0837
-- Starting training on experience 226 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0241
	data_grads_norm = 3.3372
	new_data_grads_norm = 5.1222
	old_data_grads_norm = 4.8157
	sim_grads_norm = 0.0659
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2091
	data_grads_norm = 3.8846
	new_data_grads_norm = 4.9533
	old_data_grads_norm = 5.1195
	sim_grads_norm = 0.0432
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5253
	data_grads_norm = 2.7445
	new_data_grads_norm = 4.6264
	old_data_grads_norm = 3.7364
	sim_grads_norm = -0.0176
-- Starting training on experience 227 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5607
	data_grads_norm = 3.5366
	new_data_grads_norm = 5.1170
	old_data_grads_norm = 4.9537
	sim_grads_norm = 0.0256
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2731
	data_grads_norm = 4.3597
	new_data_grads_norm = 5.6917
	old_data_grads_norm = 5.7844
	sim_grads_norm = 0.0661
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7227
	data_grads_norm = 3.6285
	new_data_grads_norm = 5.1456
	old_data_grads_norm = 4.6998
	sim_grads_norm = 0.1237
-- Starting training on experience 228 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2135
	data_grads_norm = 4.1599
	new_data_grads_norm = 5.5743
	old_data_grads_norm = 5.7798
	sim_grads_norm = -0.0535
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9170
	data_grads_norm = 3.7194
	new_data_grads_norm = 5.3831
	old_data_grads_norm = 5.0603
	sim_grads_norm = -0.0476
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2160
	data_grads_norm = 3.8099
	new_data_grads_norm = 5.6121
	old_data_grads_norm = 5.6728
	sim_grads_norm = -0.0000
-- Starting training on experience 229 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8297
	data_grads_norm = 3.5315
	new_data_grads_norm = 5.1972
	old_data_grads_norm = 3.9604
	sim_grads_norm = -0.0084
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2799
	data_grads_norm = 3.9727
	new_data_grads_norm = 5.6639
	old_data_grads_norm = 4.9301
	sim_grads_norm = -0.0056
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8814
	data_grads_norm = 4.0500
	new_data_grads_norm = 5.1436
	old_data_grads_norm = 4.8150
	sim_grads_norm = 0.0077
-- Starting training on experience 230 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9023
	data_grads_norm = 3.8642
	new_data_grads_norm = 5.5063
	old_data_grads_norm = 4.7817
	sim_grads_norm = 0.0676
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3308
	data_grads_norm = 4.0240
	new_data_grads_norm = 5.3093
	old_data_grads_norm = 6.3285
	sim_grads_norm = -0.0178
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0436
	data_grads_norm = 3.9504
	new_data_grads_norm = 5.9283
	old_data_grads_norm = 5.4698
	sim_grads_norm = -0.0143
-- Starting training on experience 231 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0028
	data_grads_norm = 3.4442
	new_data_grads_norm = 4.8858
	old_data_grads_norm = 4.9833
	sim_grads_norm = -0.0329
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2820
	data_grads_norm = 3.6147
	new_data_grads_norm = 4.7901
	old_data_grads_norm = 5.4422
	sim_grads_norm = 0.0118
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0196
	data_grads_norm = 3.3796
	new_data_grads_norm = 5.0803
	old_data_grads_norm = 4.5967
	sim_grads_norm = 0.0156
-- Starting training on experience 232 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0047
	data_grads_norm = 3.4228
	new_data_grads_norm = 5.6226
	old_data_grads_norm = 3.5439
	sim_grads_norm = -0.0543
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9111
	data_grads_norm = 3.7446
	new_data_grads_norm = 5.6008
	old_data_grads_norm = 4.3529
	sim_grads_norm = -0.0032
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8155
	data_grads_norm = 3.1903
	new_data_grads_norm = 5.8212
	old_data_grads_norm = 3.3489
	sim_grads_norm = -0.0127
-- Starting training on experience 233 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9554
	data_grads_norm = 3.9831
	new_data_grads_norm = 5.2832
	old_data_grads_norm = 6.0228
	sim_grads_norm = -0.0085
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9876
	data_grads_norm = 3.7833
	new_data_grads_norm = 5.2782
	old_data_grads_norm = 5.3506
	sim_grads_norm = 0.0125
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0956
	data_grads_norm = 3.8384
	new_data_grads_norm = 5.0929
	old_data_grads_norm = 4.9923
	sim_grads_norm = 0.0059
-- Starting training on experience 234 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0354
	data_grads_norm = 3.4856
	new_data_grads_norm = 5.2922
	old_data_grads_norm = 4.7684
	sim_grads_norm = -0.0224
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3058
	data_grads_norm = 4.2932
	new_data_grads_norm = 5.8354
	old_data_grads_norm = 5.3679
	sim_grads_norm = 0.0317
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0752
	data_grads_norm = 4.5979
	new_data_grads_norm = 5.9940
	old_data_grads_norm = 5.8235
	sim_grads_norm = 0.0404
-- Starting training on experience 235 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2932
	data_grads_norm = 4.2877
	new_data_grads_norm = 6.0630
	old_data_grads_norm = 5.4977
	sim_grads_norm = -0.0074
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8131
	data_grads_norm = 3.9232
	new_data_grads_norm = 5.5890
	old_data_grads_norm = 5.7527
	sim_grads_norm = 0.0145
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8245
	data_grads_norm = 4.2029
	new_data_grads_norm = 6.4453
	old_data_grads_norm = 4.6977
	sim_grads_norm = -0.0054
-- Starting training on experience 236 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5961
	data_grads_norm = 4.0439
	new_data_grads_norm = 4.6132
	old_data_grads_norm = 6.2566
	sim_grads_norm = 0.0585
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6088
	data_grads_norm = 3.0438
	new_data_grads_norm = 4.6924
	old_data_grads_norm = 3.4326
	sim_grads_norm = 0.0365
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5333
	data_grads_norm = 3.0147
	new_data_grads_norm = 4.2064
	old_data_grads_norm = 4.8780
	sim_grads_norm = -0.0437
-- Starting training on experience 237 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
-- >> End of training phase << --
-- >> Start of eval phase << --
-- Starting eval on experience 0 (Task 0) from test stream --
> Eval on experience 0 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp000 = 2.6931
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.3500
	mb_index = 2380
	time = 526.4791
-- Starting eval on experience 1 (Task 0) from test stream --
> Eval on experience 1 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp001 = 2.2206
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.5020
-- Starting eval on experience 2 (Task 0) from test stream --
> Eval on experience 2 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp002 = 3.3048
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.2360
-- Starting eval on experience 3 (Task 0) from test stream --
> Eval on experience 3 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp003 = 2.6534
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.4140
-- Starting eval on experience 4 (Task 0) from test stream --
> Eval on experience 4 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp004 = 2.8628
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.2940
-- Starting eval on experience 5 (Task 0) from test stream --
> Eval on experience 5 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp005 = 2.8503
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.3160
-- Starting eval on experience 6 (Task 0) from test stream --
> Eval on experience 6 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp006 = 2.7586
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp006 = 0.2700
-- Starting eval on experience 7 (Task 0) from test stream --
> Eval on experience 7 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp007 = 2.5633
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp007 = 0.3700
-- Starting eval on experience 8 (Task 0) from test stream --
> Eval on experience 8 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp008 = 2.5279
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp008 = 0.3080
-- Starting eval on experience 9 (Task 0) from test stream --
> Eval on experience 9 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp009 = 2.8441
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp009 = 0.2480
-- >> End of eval phase << --
	CumulativeAccuracy/eval_phase/test_stream/Exp000 = 0.7280
	CumulativeAccuracy/eval_phase/test_stream/Exp001 = 0.6580
	CumulativeAccuracy/eval_phase/test_stream/Exp002 = 0.5353
	CumulativeAccuracy/eval_phase/test_stream/Exp003 = 0.5055
	CumulativeAccuracy/eval_phase/test_stream/Exp004 = 0.4628
	CumulativeAccuracy/eval_phase/test_stream/Exp005 = 0.4273
	CumulativeAccuracy/eval_phase/test_stream/Exp006 = 0.3926
	CumulativeAccuracy/eval_phase/test_stream/Exp007 = 0.3713
	CumulativeAccuracy/eval_phase/test_stream/Exp008 = 0.3538
	CumulativeAccuracy/eval_phase/test_stream/Exp009 = 0.3308
	Loss_Stream/eval_phase/test_stream/Task000 = 2.7279
	Top1_Acc_Stream/eval_phase/test_stream/Task000 = 0.3308
-- >> Start of training phase << --
-- Starting training on experience 0 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5309
	data_grads_norm = 4.1557
	new_data_grads_norm = 5.3860
	old_data_grads_norm = 5.7497
	sim_grads_norm = -0.0586
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4036
	data_grads_norm = 4.3246
	new_data_grads_norm = 5.6078
	old_data_grads_norm = 5.3912
	sim_grads_norm = 0.0213
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0796
	data_grads_norm = 3.8867
	new_data_grads_norm = 5.5493
	old_data_grads_norm = 3.8412
	sim_grads_norm = -0.0182
-- Starting training on experience 1 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4321
	data_grads_norm = 4.5142
	new_data_grads_norm = 5.7822
	old_data_grads_norm = 5.8539
	sim_grads_norm = 0.0056
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8276
	data_grads_norm = 3.8554
	new_data_grads_norm = 5.4761
	old_data_grads_norm = 5.5763
	sim_grads_norm = 0.0564
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5963
	data_grads_norm = 3.8165
	new_data_grads_norm = 5.6987
	old_data_grads_norm = 3.8096
	sim_grads_norm = -0.0211
-- Starting training on experience 2 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9318
	data_grads_norm = 3.9207
	new_data_grads_norm = 5.4150
	old_data_grads_norm = 5.4235
	sim_grads_norm = 0.0668
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3533
	data_grads_norm = 3.0306
	new_data_grads_norm = 5.3112
	old_data_grads_norm = 3.6388
	sim_grads_norm = -0.0086
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7885
	data_grads_norm = 3.7859
	new_data_grads_norm = 5.5925
	old_data_grads_norm = 5.3479
	sim_grads_norm = -0.0600
-- Starting training on experience 3 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2142
	data_grads_norm = 4.2250
	new_data_grads_norm = 5.6595
	old_data_grads_norm = 6.1958
	sim_grads_norm = 0.0051
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4604
	data_grads_norm = 5.0498
	new_data_grads_norm = 6.8642
	old_data_grads_norm = 6.7360
	sim_grads_norm = 0.0882
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.8855
	data_grads_norm = 4.4883
	new_data_grads_norm = 6.4386
	old_data_grads_norm = 6.3181
	sim_grads_norm = 0.0496
-- Starting training on experience 4 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4187
	data_grads_norm = 4.4988
	new_data_grads_norm = 5.8911
	old_data_grads_norm = 4.8830
	sim_grads_norm = 0.0435
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1937
	data_grads_norm = 4.4415
	new_data_grads_norm = 5.6373
	old_data_grads_norm = 6.5190
	sim_grads_norm = 0.0028
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6690
	data_grads_norm = 3.8135
	new_data_grads_norm = 5.8350
	old_data_grads_norm = 3.4303
	sim_grads_norm = 0.0009
-- Starting training on experience 5 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1778
	data_grads_norm = 3.8642
	new_data_grads_norm = 5.4456
	old_data_grads_norm = 5.4060
	sim_grads_norm = 0.0384
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9874
	data_grads_norm = 3.5591
	new_data_grads_norm = 5.0659
	old_data_grads_norm = 4.1411
	sim_grads_norm = 0.0018
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2272
	data_grads_norm = 4.0262
	new_data_grads_norm = 5.9935
	old_data_grads_norm = 5.2610
	sim_grads_norm = -0.0035
-- Starting training on experience 6 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0059
	data_grads_norm = 3.7218
	new_data_grads_norm = 7.0959
	old_data_grads_norm = 3.5312
	sim_grads_norm = 0.0160
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6410
	data_grads_norm = 4.5720
	new_data_grads_norm = 6.3379
	old_data_grads_norm = 5.4660
	sim_grads_norm = 0.1184
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3239
	data_grads_norm = 3.2146
	new_data_grads_norm = 6.0271
	old_data_grads_norm = 4.2808
	sim_grads_norm = -0.0179
-- Starting training on experience 7 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5272
	data_grads_norm = 4.5709
	new_data_grads_norm = 5.2518
	old_data_grads_norm = 7.2208
	sim_grads_norm = 0.0260
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5701
	data_grads_norm = 3.0565
	new_data_grads_norm = 5.3168
	old_data_grads_norm = 3.9793
	sim_grads_norm = -0.0435
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0134
	data_grads_norm = 3.5009
	new_data_grads_norm = 5.5461
	old_data_grads_norm = 4.1227
	sim_grads_norm = 0.0041
-- Starting training on experience 8 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0406
	data_grads_norm = 3.4477
	new_data_grads_norm = 5.2423
	old_data_grads_norm = 4.2572
	sim_grads_norm = 0.0749
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2581
	data_grads_norm = 4.4023
	new_data_grads_norm = 5.3408
	old_data_grads_norm = 6.5671
	sim_grads_norm = 0.0404
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6233
	data_grads_norm = 3.5320
	new_data_grads_norm = 4.9498
	old_data_grads_norm = 5.5964
	sim_grads_norm = -0.0216
-- Starting training on experience 9 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1400
	data_grads_norm = 3.6179
	new_data_grads_norm = 5.5799
	old_data_grads_norm = 4.4122
	sim_grads_norm = -0.0041
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9709
	data_grads_norm = 3.4808
	new_data_grads_norm = 5.5758
	old_data_grads_norm = 4.0374
	sim_grads_norm = 0.0671
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6973
	data_grads_norm = 3.5142
	new_data_grads_norm = 5.5415
	old_data_grads_norm = 3.9404
	sim_grads_norm = 0.0631
-- Starting training on experience 10 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0110
	data_grads_norm = 4.0333
	new_data_grads_norm = 5.6540
	old_data_grads_norm = 5.0081
	sim_grads_norm = 0.1851
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6060
	data_grads_norm = 3.2258
	new_data_grads_norm = 5.0996
	old_data_grads_norm = 4.4071
	sim_grads_norm = 0.0130
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6659
	data_grads_norm = 3.5238
	new_data_grads_norm = 4.5251
	old_data_grads_norm = 5.6381
	sim_grads_norm = 0.0053
-- Starting training on experience 11 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1899
	data_grads_norm = 4.2663
	new_data_grads_norm = 4.7745
	old_data_grads_norm = 5.6490
	sim_grads_norm = 0.0165
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5607
	data_grads_norm = 3.8666
	new_data_grads_norm = 4.8297
	old_data_grads_norm = 5.2214
	sim_grads_norm = -0.0212
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2012
	data_grads_norm = 3.0277
	new_data_grads_norm = 4.6006
	old_data_grads_norm = 3.5113
	sim_grads_norm = 0.0390
-- Starting training on experience 12 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0568
	data_grads_norm = 3.8549
	new_data_grads_norm = 5.5584
	old_data_grads_norm = 5.0741
	sim_grads_norm = -0.0143
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1630
	data_grads_norm = 4.6680
	new_data_grads_norm = 5.8415
	old_data_grads_norm = 5.7577
	sim_grads_norm = 0.0799
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0254
	data_grads_norm = 4.1170
	new_data_grads_norm = 5.6193
	old_data_grads_norm = 4.7012
	sim_grads_norm = 0.0715
-- Starting training on experience 13 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3623
	data_grads_norm = 3.2685
	new_data_grads_norm = 4.8649
	old_data_grads_norm = 5.3624
	sim_grads_norm = -0.0195
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1203
	data_grads_norm = 3.5318
	new_data_grads_norm = 4.8709
	old_data_grads_norm = 4.7244
	sim_grads_norm = 0.0147
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9140
	data_grads_norm = 3.6231
	new_data_grads_norm = 5.0394
	old_data_grads_norm = 4.7434
	sim_grads_norm = -0.0317
-- Starting training on experience 14 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3792
	data_grads_norm = 4.0944
	new_data_grads_norm = 5.8896
	old_data_grads_norm = 5.3932
	sim_grads_norm = 0.0619
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2270
	data_grads_norm = 3.3662
	new_data_grads_norm = 5.5015
	old_data_grads_norm = 4.1636
	sim_grads_norm = -0.0088
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8828
	data_grads_norm = 4.9891
	new_data_grads_norm = 5.8171
	old_data_grads_norm = 4.6098
	sim_grads_norm = -0.0219
-- Starting training on experience 15 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6211
	data_grads_norm = 4.1725
	new_data_grads_norm = 6.2130
	old_data_grads_norm = 5.0311
	sim_grads_norm = 0.0173
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2462
	data_grads_norm = 4.4047
	new_data_grads_norm = 6.6873
	old_data_grads_norm = 5.7943
	sim_grads_norm = 0.0188
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7380
	data_grads_norm = 3.9174
	new_data_grads_norm = 5.4092
	old_data_grads_norm = 5.1904
	sim_grads_norm = 0.0387
-- Starting training on experience 16 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8663
	data_grads_norm = 4.0659
	new_data_grads_norm = 4.6493
	old_data_grads_norm = 5.8775
	sim_grads_norm = 0.0446
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6139
	data_grads_norm = 3.5573
	new_data_grads_norm = 4.3490
	old_data_grads_norm = 5.3086
	sim_grads_norm = 0.0411
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3188
	data_grads_norm = 2.9187
	new_data_grads_norm = 4.6092
	old_data_grads_norm = 3.6664
	sim_grads_norm = -0.0215
-- Starting training on experience 17 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9897
	data_grads_norm = 3.1333
	new_data_grads_norm = 5.0207
	old_data_grads_norm = 3.9616
	sim_grads_norm = 0.0025
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1730
	data_grads_norm = 3.2703
	new_data_grads_norm = 5.2033
	old_data_grads_norm = 3.7970
	sim_grads_norm = 0.0649
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0676
	data_grads_norm = 3.3004
	new_data_grads_norm = 5.4085
	old_data_grads_norm = 3.7347
	sim_grads_norm = 0.0339
-- Starting training on experience 18 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7340
	data_grads_norm = 2.6481
	new_data_grads_norm = 4.7070
	old_data_grads_norm = 3.9974
	sim_grads_norm = 0.0148
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3068
	data_grads_norm = 3.3552
	new_data_grads_norm = 4.5276
	old_data_grads_norm = 4.9327
	sim_grads_norm = 0.0008
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0431
	data_grads_norm = 3.2104
	new_data_grads_norm = 4.4121
	old_data_grads_norm = 4.7815
	sim_grads_norm = 0.0047
-- Starting training on experience 19 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6467
	data_grads_norm = 3.9671
	new_data_grads_norm = 4.8244
	old_data_grads_norm = 4.8154
	sim_grads_norm = 0.0937
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1762
	data_grads_norm = 3.1235
	new_data_grads_norm = 4.7485
	old_data_grads_norm = 3.9786
	sim_grads_norm = -0.0509
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7227
	data_grads_norm = 3.2130
	new_data_grads_norm = 4.7632
	old_data_grads_norm = 4.3333
	sim_grads_norm = -0.0260
-- Starting training on experience 20 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3999
	data_grads_norm = 3.5425
	new_data_grads_norm = 4.7955
	old_data_grads_norm = 4.5531
	sim_grads_norm = 0.0774
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3211
	data_grads_norm = 2.8859
	new_data_grads_norm = 5.3464
	old_data_grads_norm = 3.0103
	sim_grads_norm = 0.0153
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5314
	data_grads_norm = 3.5144
	new_data_grads_norm = 4.6580
	old_data_grads_norm = 4.9102
	sim_grads_norm = 0.0375
-- Starting training on experience 21 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9565
	data_grads_norm = 3.2938
	new_data_grads_norm = 4.5914
	old_data_grads_norm = 4.2078
	sim_grads_norm = 0.0274
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1815
	data_grads_norm = 3.4674
	new_data_grads_norm = 4.4618
	old_data_grads_norm = 4.7683
	sim_grads_norm = 0.0435
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0747
	data_grads_norm = 3.5516
	new_data_grads_norm = 4.6122
	old_data_grads_norm = 4.8129
	sim_grads_norm = -0.0239
-- Starting training on experience 22 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9660
	data_grads_norm = 3.1169
	new_data_grads_norm = 4.8044
	old_data_grads_norm = 3.9204
	sim_grads_norm = 0.0429
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9094
	data_grads_norm = 3.6679
	new_data_grads_norm = 4.8229
	old_data_grads_norm = 5.3213
	sim_grads_norm = 0.0930
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1237
	data_grads_norm = 3.7353
	new_data_grads_norm = 4.7386
	old_data_grads_norm = 5.1358
	sim_grads_norm = 0.0226
-- Starting training on experience 23 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5667
	data_grads_norm = 3.6695
	new_data_grads_norm = 4.6549
	old_data_grads_norm = 4.3854
	sim_grads_norm = 0.0177
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6991
	data_grads_norm = 4.0937
	new_data_grads_norm = 4.8532
	old_data_grads_norm = 5.2030
	sim_grads_norm = 0.0180
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1805
	data_grads_norm = 3.2049
	new_data_grads_norm = 4.7774
	old_data_grads_norm = 4.5143
	sim_grads_norm = -0.0079
-- Starting training on experience 24 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4681
	data_grads_norm = 4.1350
	new_data_grads_norm = 4.4514
	old_data_grads_norm = 6.2757
	sim_grads_norm = 0.0506
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0905
	data_grads_norm = 2.9866
	new_data_grads_norm = 4.2074
	old_data_grads_norm = 4.0190
	sim_grads_norm = 0.0890
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9161
	data_grads_norm = 3.2225
	new_data_grads_norm = 4.3134
	old_data_grads_norm = 4.7271
	sim_grads_norm = 0.0112
-- Starting training on experience 25 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5710
	data_grads_norm = 3.6222
	new_data_grads_norm = 5.1862
	old_data_grads_norm = 4.1895
	sim_grads_norm = -0.0399
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9934
	data_grads_norm = 4.0059
	new_data_grads_norm = 5.1284
	old_data_grads_norm = 5.7913
	sim_grads_norm = -0.0468
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7098
	data_grads_norm = 4.3757
	new_data_grads_norm = 5.8953
	old_data_grads_norm = 5.1889
	sim_grads_norm = 0.1404
-- Starting training on experience 26 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8740
	data_grads_norm = 4.1537
	new_data_grads_norm = 5.6595
	old_data_grads_norm = 5.0152
	sim_grads_norm = 0.0783
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0823
	data_grads_norm = 4.0942
	new_data_grads_norm = 5.5710
	old_data_grads_norm = 5.1531
	sim_grads_norm = 0.0552
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0751
	data_grads_norm = 3.6100
	new_data_grads_norm = 5.4546
	old_data_grads_norm = 4.2968
	sim_grads_norm = -0.0446
-- Starting training on experience 27 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8861
	data_grads_norm = 3.7239
	new_data_grads_norm = 4.3857
	old_data_grads_norm = 5.1086
	sim_grads_norm = 0.0335
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9232
	data_grads_norm = 3.5034
	new_data_grads_norm = 4.5305
	old_data_grads_norm = 4.5174
	sim_grads_norm = 0.0506
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6439
	data_grads_norm = 4.1991
	new_data_grads_norm = 4.5841
	old_data_grads_norm = 6.0849
	sim_grads_norm = -0.0244
-- Starting training on experience 28 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9083
	data_grads_norm = 2.7367
	new_data_grads_norm = 4.7032
	old_data_grads_norm = 3.4531
	sim_grads_norm = 0.0104
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0594
	data_grads_norm = 3.1472
	new_data_grads_norm = 4.8517
	old_data_grads_norm = 4.4958
	sim_grads_norm = 0.0939
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2580
	data_grads_norm = 3.6756
	new_data_grads_norm = 4.8420
	old_data_grads_norm = 5.3419
	sim_grads_norm = -0.0242
-- Starting training on experience 29 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9473
	data_grads_norm = 3.0784
	new_data_grads_norm = 4.6374
	old_data_grads_norm = 3.6914
	sim_grads_norm = 0.0557
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9829
	data_grads_norm = 3.8651
	new_data_grads_norm = 4.8085
	old_data_grads_norm = 5.3328
	sim_grads_norm = 0.0223
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0679
	data_grads_norm = 3.7603
	new_data_grads_norm = 4.9480
	old_data_grads_norm = 5.1951
	sim_grads_norm = 0.0573
-- Starting training on experience 30 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3523
	data_grads_norm = 3.8528
	new_data_grads_norm = 5.0263
	old_data_grads_norm = 5.4646
	sim_grads_norm = 0.0169
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8551
	data_grads_norm = 3.0761
	new_data_grads_norm = 4.8127
	old_data_grads_norm = 3.9411
	sim_grads_norm = 0.0056
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4115
	data_grads_norm = 3.6667
	new_data_grads_norm = 5.0122
	old_data_grads_norm = 5.2490
	sim_grads_norm = 0.0488
-- Starting training on experience 31 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6926
	data_grads_norm = 2.9683
	new_data_grads_norm = 4.8446
	old_data_grads_norm = 2.7530
	sim_grads_norm = 0.0519
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1080
	data_grads_norm = 3.6799
	new_data_grads_norm = 4.9127
	old_data_grads_norm = 5.2892
	sim_grads_norm = -0.0281
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0686
	data_grads_norm = 3.1585
	new_data_grads_norm = 4.5054
	old_data_grads_norm = 4.2762
	sim_grads_norm = -0.0118
-- Starting training on experience 32 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5393
	data_grads_norm = 3.1732
	new_data_grads_norm = 4.5691
	old_data_grads_norm = 4.7176
	sim_grads_norm = -0.0335
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8756
	data_grads_norm = 3.5385
	new_data_grads_norm = 4.7537
	old_data_grads_norm = 5.0794
	sim_grads_norm = -0.0052
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1409
	data_grads_norm = 3.6170
	new_data_grads_norm = 4.6135
	old_data_grads_norm = 4.6639
	sim_grads_norm = 0.0402
-- Starting training on experience 33 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6496
	data_grads_norm = 3.1734
	new_data_grads_norm = 4.6290
	old_data_grads_norm = 4.2273
	sim_grads_norm = 0.0259
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2249
	data_grads_norm = 3.6432
	new_data_grads_norm = 4.5145
	old_data_grads_norm = 5.3544
	sim_grads_norm = 0.1368
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4622
	data_grads_norm = 3.0943
	new_data_grads_norm = 4.5038
	old_data_grads_norm = 4.5717
	sim_grads_norm = -0.0001
-- Starting training on experience 34 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8432
	data_grads_norm = 3.7035
	new_data_grads_norm = 4.7444
	old_data_grads_norm = 5.0936
	sim_grads_norm = -0.0756
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7732
	data_grads_norm = 3.5610
	new_data_grads_norm = 5.1245
	old_data_grads_norm = 4.0376
	sim_grads_norm = -0.0099
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7427
	data_grads_norm = 3.6154
	new_data_grads_norm = 5.1185
	old_data_grads_norm = 3.8912
	sim_grads_norm = 0.0152
-- Starting training on experience 35 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3178
	data_grads_norm = 3.4040
	new_data_grads_norm = 4.9469
	old_data_grads_norm = 4.9103
	sim_grads_norm = 0.0745
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9511
	data_grads_norm = 3.4993
	new_data_grads_norm = 4.7302
	old_data_grads_norm = 5.1194
	sim_grads_norm = -0.0101
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0148
	data_grads_norm = 3.8385
	new_data_grads_norm = 4.4489
	old_data_grads_norm = 6.0078
	sim_grads_norm = -0.0450
-- Starting training on experience 36 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8198
	data_grads_norm = 3.5076
	new_data_grads_norm = 4.9228
	old_data_grads_norm = 4.4533
	sim_grads_norm = 0.0841
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8729
	data_grads_norm = 3.6953
	new_data_grads_norm = 4.7613
	old_data_grads_norm = 4.9581
	sim_grads_norm = 0.0815
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7228
	data_grads_norm = 3.5600
	new_data_grads_norm = 4.8740
	old_data_grads_norm = 4.3996
	sim_grads_norm = -0.0553
-- Starting training on experience 37 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7511
	data_grads_norm = 3.6170
	new_data_grads_norm = 4.8893
	old_data_grads_norm = 5.2270
	sim_grads_norm = -0.0097
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0361
	data_grads_norm = 3.3502
	new_data_grads_norm = 4.7994
	old_data_grads_norm = 4.1707
	sim_grads_norm = -0.0229
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5629
	data_grads_norm = 4.3912
	new_data_grads_norm = 5.4408
	old_data_grads_norm = 5.2291
	sim_grads_norm = 0.0436
-- Starting training on experience 38 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5485
	data_grads_norm = 4.2116
	new_data_grads_norm = 5.0929
	old_data_grads_norm = 5.3250
	sim_grads_norm = 0.2879
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1093
	data_grads_norm = 3.8752
	new_data_grads_norm = 4.6482
	old_data_grads_norm = 5.1652
	sim_grads_norm = 0.0873
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3044
	data_grads_norm = 3.0199
	new_data_grads_norm = 4.6048
	old_data_grads_norm = 3.4954
	sim_grads_norm = 0.0182
-- Starting training on experience 39 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7835
	data_grads_norm = 3.8781
	new_data_grads_norm = 4.2388
	old_data_grads_norm = 5.8974
	sim_grads_norm = -0.0491
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4884
	data_grads_norm = 3.2804
	new_data_grads_norm = 4.9850
	old_data_grads_norm = 4.3505
	sim_grads_norm = 0.0025
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1840
	data_grads_norm = 3.0708
	new_data_grads_norm = 5.0126
	old_data_grads_norm = 4.6116
	sim_grads_norm = -0.0897
-- Starting training on experience 40 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1811
	data_grads_norm = 3.7936
	new_data_grads_norm = 5.0916
	old_data_grads_norm = 5.5283
	sim_grads_norm = 0.0241
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5239
	data_grads_norm = 3.0616
	new_data_grads_norm = 4.0611
	old_data_grads_norm = 4.0967
	sim_grads_norm = -0.0251
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5479
	data_grads_norm = 3.2342
	new_data_grads_norm = 5.3081
	old_data_grads_norm = 3.5132
	sim_grads_norm = 0.0480
-- Starting training on experience 41 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6516
	data_grads_norm = 3.5009
	new_data_grads_norm = 5.1910
	old_data_grads_norm = 3.9873
	sim_grads_norm = 0.0297
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6930
	data_grads_norm = 3.9306
	new_data_grads_norm = 5.3783
	old_data_grads_norm = 6.0974
	sim_grads_norm = -0.0222
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0612
	data_grads_norm = 3.7392
	new_data_grads_norm = 5.2401
	old_data_grads_norm = 4.0729
	sim_grads_norm = 0.0067
-- Starting training on experience 42 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0499
	data_grads_norm = 3.4209
	new_data_grads_norm = 4.4367
	old_data_grads_norm = 5.0038
	sim_grads_norm = 0.0809
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9835
	data_grads_norm = 3.6886
	new_data_grads_norm = 4.6509
	old_data_grads_norm = 4.9770
	sim_grads_norm = 0.0149
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3676
	data_grads_norm = 3.2777
	new_data_grads_norm = 4.4162
	old_data_grads_norm = 4.6784
	sim_grads_norm = -0.0143
-- Starting training on experience 43 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8887
	data_grads_norm = 3.6929
	new_data_grads_norm = 4.4005
	old_data_grads_norm = 4.4850
	sim_grads_norm = 0.0744
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9654
	data_grads_norm = 2.8800
	new_data_grads_norm = 4.1791
	old_data_grads_norm = 4.1231
	sim_grads_norm = 0.0840
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3550
	data_grads_norm = 3.2679
	new_data_grads_norm = 3.9698
	old_data_grads_norm = 4.8247
	sim_grads_norm = 0.0668
-- Starting training on experience 44 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9833
	data_grads_norm = 3.6226
	new_data_grads_norm = 4.8582
	old_data_grads_norm = 5.8587
	sim_grads_norm = 0.0022
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4581
	data_grads_norm = 3.7858
	new_data_grads_norm = 4.3629
	old_data_grads_norm = 5.9654
	sim_grads_norm = -0.0190
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7756
	data_grads_norm = 3.5503
	new_data_grads_norm = 4.1516
	old_data_grads_norm = 5.7543
	sim_grads_norm = -0.0083
-- Starting training on experience 45 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5023
	data_grads_norm = 3.1539
	new_data_grads_norm = 4.6124
	old_data_grads_norm = 4.5644
	sim_grads_norm = -0.0155
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6019
	data_grads_norm = 3.0560
	new_data_grads_norm = 4.4825
	old_data_grads_norm = 4.1782
	sim_grads_norm = -0.0464
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6606
	data_grads_norm = 3.3442
	new_data_grads_norm = 4.6209
	old_data_grads_norm = 4.7410
	sim_grads_norm = 0.0398
-- Starting training on experience 46 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8405
	data_grads_norm = 3.5293
	new_data_grads_norm = 4.5125
	old_data_grads_norm = 5.0086
	sim_grads_norm = 0.0469
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2813
	data_grads_norm = 3.0641
	new_data_grads_norm = 4.7607
	old_data_grads_norm = 4.3306
	sim_grads_norm = -0.0191
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6951
	data_grads_norm = 3.7035
	new_data_grads_norm = 5.0320
	old_data_grads_norm = 5.2064
	sim_grads_norm = -0.0077
-- Starting training on experience 47 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7272
	data_grads_norm = 3.8858
	new_data_grads_norm = 5.3747
	old_data_grads_norm = 4.8948
	sim_grads_norm = -0.0049
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7793
	data_grads_norm = 3.9246
	new_data_grads_norm = 5.3310
	old_data_grads_norm = 5.7535
	sim_grads_norm = 0.0079
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8597
	data_grads_norm = 3.5439
	new_data_grads_norm = 4.7191
	old_data_grads_norm = 5.1652
	sim_grads_norm = 0.0009
-- Starting training on experience 48 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0595
	data_grads_norm = 3.6336
	new_data_grads_norm = 4.6522
	old_data_grads_norm = 5.4312
	sim_grads_norm = -0.0240
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9598
	data_grads_norm = 3.7407
	new_data_grads_norm = 4.7411
	old_data_grads_norm = 6.1871
	sim_grads_norm = 0.0150
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8358
	data_grads_norm = 3.7516
	new_data_grads_norm = 5.0133
	old_data_grads_norm = 4.5737
	sim_grads_norm = 0.0841
-- Starting training on experience 49 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1938
	data_grads_norm = 3.2916
	new_data_grads_norm = 5.9175
	old_data_grads_norm = 4.0024
	sim_grads_norm = -0.0434
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6194
	data_grads_norm = 3.6630
	new_data_grads_norm = 5.4979
	old_data_grads_norm = 4.6244
	sim_grads_norm = -0.0010
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6426
	data_grads_norm = 3.3725
	new_data_grads_norm = 5.2448
	old_data_grads_norm = 3.3427
	sim_grads_norm = 0.1809
-- Starting training on experience 50 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5632
	data_grads_norm = 3.8655
	new_data_grads_norm = 4.8999
	old_data_grads_norm = 5.8367
	sim_grads_norm = -0.0173
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6696
	data_grads_norm = 4.3617
	new_data_grads_norm = 5.4243
	old_data_grads_norm = 6.7636
	sim_grads_norm = -0.0092
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9130
	data_grads_norm = 3.8228
	new_data_grads_norm = 5.1508
	old_data_grads_norm = 5.1498
	sim_grads_norm = 0.0187
-- Starting training on experience 51 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6330
	data_grads_norm = 3.4581
	new_data_grads_norm = 4.7603
	old_data_grads_norm = 5.1836
	sim_grads_norm = 0.0586
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0089
	data_grads_norm = 3.0171
	new_data_grads_norm = 3.7130
	old_data_grads_norm = 4.7586
	sim_grads_norm = 0.0181
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0923
	data_grads_norm = 2.8181
	new_data_grads_norm = 3.9430
	old_data_grads_norm = 4.1612
	sim_grads_norm = -0.0426
-- Starting training on experience 52 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5436
	data_grads_norm = 3.6542
	new_data_grads_norm = 5.2506
	old_data_grads_norm = 5.0677
	sim_grads_norm = 0.0370
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8399
	data_grads_norm = 4.1592
	new_data_grads_norm = 4.9521
	old_data_grads_norm = 5.9997
	sim_grads_norm = 0.0644
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4463
	data_grads_norm = 3.5635
	new_data_grads_norm = 4.4245
	old_data_grads_norm = 5.5694
	sim_grads_norm = -0.0061
-- Starting training on experience 53 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8736
	data_grads_norm = 4.0822
	new_data_grads_norm = 5.5408
	old_data_grads_norm = 5.5211
	sim_grads_norm = -0.0240
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9947
	data_grads_norm = 4.1060
	new_data_grads_norm = 5.5098
	old_data_grads_norm = 5.7134
	sim_grads_norm = 0.0135
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2042
	data_grads_norm = 2.8363
	new_data_grads_norm = 5.5576
	old_data_grads_norm = 3.3104
	sim_grads_norm = -0.0129
-- Starting training on experience 54 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9825
	data_grads_norm = 3.9459
	new_data_grads_norm = 4.8566
	old_data_grads_norm = 5.1914
	sim_grads_norm = 0.0454
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0446
	data_grads_norm = 3.6769
	new_data_grads_norm = 5.3250
	old_data_grads_norm = 4.7896
	sim_grads_norm = 0.0419
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8835
	data_grads_norm = 3.8627
	new_data_grads_norm = 4.3433
	old_data_grads_norm = 5.2727
	sim_grads_norm = 0.0284
-- Starting training on experience 55 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7035
	data_grads_norm = 3.6075
	new_data_grads_norm = 4.1482
	old_data_grads_norm = 6.4057
	sim_grads_norm = 0.0353
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5898
	data_grads_norm = 3.3538
	new_data_grads_norm = 4.6731
	old_data_grads_norm = 4.8217
	sim_grads_norm = -0.0287
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7472
	data_grads_norm = 3.5316
	new_data_grads_norm = 4.7608
	old_data_grads_norm = 4.3122
	sim_grads_norm = -0.0038
-- Starting training on experience 56 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2526
	data_grads_norm = 4.5106
	new_data_grads_norm = 6.1402
	old_data_grads_norm = 6.8629
	sim_grads_norm = 0.0503
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2087
	data_grads_norm = 4.3396
	new_data_grads_norm = 4.9638
	old_data_grads_norm = 7.3797
	sim_grads_norm = 0.0297
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4486
	data_grads_norm = 3.5512
	new_data_grads_norm = 5.3324
	old_data_grads_norm = 4.9356
	sim_grads_norm = -0.0164
-- Starting training on experience 57 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2325
	data_grads_norm = 3.2665
	new_data_grads_norm = 5.0139
	old_data_grads_norm = 3.9696
	sim_grads_norm = -0.0279
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7332
	data_grads_norm = 3.5049
	new_data_grads_norm = 5.0744
	old_data_grads_norm = 4.5850
	sim_grads_norm = 0.0204
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3678
	data_grads_norm = 3.3238
	new_data_grads_norm = 5.0984
	old_data_grads_norm = 4.1269
	sim_grads_norm = 0.0988
-- Starting training on experience 58 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5302
	data_grads_norm = 3.2243
	new_data_grads_norm = 4.9332
	old_data_grads_norm = 3.5205
	sim_grads_norm = 0.0818
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7608
	data_grads_norm = 3.5505
	new_data_grads_norm = 4.7945
	old_data_grads_norm = 4.2248
	sim_grads_norm = 0.0529
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3818
	data_grads_norm = 3.3804
	new_data_grads_norm = 4.6791
	old_data_grads_norm = 4.6253
	sim_grads_norm = -0.0439
-- Starting training on experience 59 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7568
	data_grads_norm = 3.8337
	new_data_grads_norm = 5.5103
	old_data_grads_norm = 4.5815
	sim_grads_norm = -0.0227
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9917
	data_grads_norm = 3.8179
	new_data_grads_norm = 5.3096
	old_data_grads_norm = 4.8019
	sim_grads_norm = 0.1382
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0849
	data_grads_norm = 3.2351
	new_data_grads_norm = 4.7769
	old_data_grads_norm = 4.3005
	sim_grads_norm = -0.0067
-- Starting training on experience 60 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6912
	data_grads_norm = 3.4308
	new_data_grads_norm = 4.7981
	old_data_grads_norm = 4.3808
	sim_grads_norm = -0.0188
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4926
	data_grads_norm = 3.0497
	new_data_grads_norm = 4.7382
	old_data_grads_norm = 3.4391
	sim_grads_norm = 0.0699
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6611
	data_grads_norm = 3.6352
	new_data_grads_norm = 4.9223
	old_data_grads_norm = 5.1611
	sim_grads_norm = 0.0197
-- Starting training on experience 61 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4685
	data_grads_norm = 3.5710
	new_data_grads_norm = 4.6335
	old_data_grads_norm = 5.1295
	sim_grads_norm = 0.0168
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9059
	data_grads_norm = 3.8328
	new_data_grads_norm = 4.8485
	old_data_grads_norm = 6.0075
	sim_grads_norm = 0.0196
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3771
	data_grads_norm = 3.2632
	new_data_grads_norm = 4.6913
	old_data_grads_norm = 3.6999
	sim_grads_norm = 0.0556
-- Starting training on experience 62 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5738
	data_grads_norm = 3.4411
	new_data_grads_norm = 5.1862
	old_data_grads_norm = 4.2553
	sim_grads_norm = 0.0271
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8562
	data_grads_norm = 4.0090
	new_data_grads_norm = 5.5372
	old_data_grads_norm = 5.1917
	sim_grads_norm = 0.0815
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1585
	data_grads_norm = 2.9949
	new_data_grads_norm = 4.7398
	old_data_grads_norm = 3.9211
	sim_grads_norm = 0.0448
-- Starting training on experience 63 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6141
	data_grads_norm = 3.3995
	new_data_grads_norm = 4.7107
	old_data_grads_norm = 3.9532
	sim_grads_norm = -0.0406
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9067
	data_grads_norm = 3.7642
	new_data_grads_norm = 4.0061
	old_data_grads_norm = 5.5031
	sim_grads_norm = 0.0940
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6253
	data_grads_norm = 3.1064
	new_data_grads_norm = 4.7047
	old_data_grads_norm = 4.9438
	sim_grads_norm = -0.0137
-- Starting training on experience 64 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3633
	data_grads_norm = 3.5276
	new_data_grads_norm = 4.2287
	old_data_grads_norm = 5.0670
	sim_grads_norm = 0.0734
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9402
	data_grads_norm = 2.9534
	new_data_grads_norm = 4.4392
	old_data_grads_norm = 4.2018
	sim_grads_norm = -0.0402
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0689
	data_grads_norm = 3.2438
	new_data_grads_norm = 4.3432
	old_data_grads_norm = 4.1227
	sim_grads_norm = -0.0411
-- Starting training on experience 65 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1970
	data_grads_norm = 3.1298
	new_data_grads_norm = 4.9135
	old_data_grads_norm = 4.5234
	sim_grads_norm = -0.0547
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4005
	data_grads_norm = 3.4245
	new_data_grads_norm = 5.2700
	old_data_grads_norm = 4.7065
	sim_grads_norm = -0.0223
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1110
	data_grads_norm = 3.2692
	new_data_grads_norm = 4.9745
	old_data_grads_norm = 4.9110
	sim_grads_norm = -0.0253
-- Starting training on experience 66 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8109
	data_grads_norm = 3.7666
	new_data_grads_norm = 6.0937
	old_data_grads_norm = 4.6608
	sim_grads_norm = -0.0576
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7861
	data_grads_norm = 3.6896
	new_data_grads_norm = 5.1523
	old_data_grads_norm = 5.7518
	sim_grads_norm = 0.0932
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8342
	data_grads_norm = 3.8270
	new_data_grads_norm = 5.2744
	old_data_grads_norm = 6.3648
	sim_grads_norm = -0.0032
-- Starting training on experience 67 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0461
	data_grads_norm = 3.4854
	new_data_grads_norm = 5.0793
	old_data_grads_norm = 4.3640
	sim_grads_norm = -0.0262
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8334
	data_grads_norm = 4.1471
	new_data_grads_norm = 5.8953
	old_data_grads_norm = 5.5901
	sim_grads_norm = 0.0106
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4148
	data_grads_norm = 3.8033
	new_data_grads_norm = 5.3570
	old_data_grads_norm = 3.9196
	sim_grads_norm = 0.0748
-- Starting training on experience 68 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2707
	data_grads_norm = 3.3366
	new_data_grads_norm = 4.7718
	old_data_grads_norm = 4.9397
	sim_grads_norm = -0.0095
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2356
	data_grads_norm = 3.4439
	new_data_grads_norm = 5.2391
	old_data_grads_norm = 4.5151
	sim_grads_norm = -0.0614
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2766
	data_grads_norm = 3.2895
	new_data_grads_norm = 4.7882
	old_data_grads_norm = 4.4101
	sim_grads_norm = 0.0102
-- Starting training on experience 69 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8315
	data_grads_norm = 4.3729
	new_data_grads_norm = 5.6867
	old_data_grads_norm = 6.5615
	sim_grads_norm = -0.0549
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3736
	data_grads_norm = 3.4604
	new_data_grads_norm = 6.0099
	old_data_grads_norm = 4.7215
	sim_grads_norm = -0.0379
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8000
	data_grads_norm = 3.8369
	new_data_grads_norm = 6.1859
	old_data_grads_norm = 6.1511
	sim_grads_norm = 0.0170
-- Starting training on experience 70 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7018
	data_grads_norm = 3.7751
	new_data_grads_norm = 5.4407
	old_data_grads_norm = 4.5114
	sim_grads_norm = 0.0411
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5800
	data_grads_norm = 4.3375
	new_data_grads_norm = 5.5364
	old_data_grads_norm = 5.4839
	sim_grads_norm = 0.0308
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3511
	data_grads_norm = 4.7726
	new_data_grads_norm = 5.7867
	old_data_grads_norm = 6.5630
	sim_grads_norm = 0.0528
-- Starting training on experience 71 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3319
	data_grads_norm = 3.3070
	new_data_grads_norm = 4.4777
	old_data_grads_norm = 4.8936
	sim_grads_norm = 0.0097
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6484
	data_grads_norm = 3.6376
	new_data_grads_norm = 4.7815
	old_data_grads_norm = 5.1343
	sim_grads_norm = -0.0277
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8011
	data_grads_norm = 4.0539
	new_data_grads_norm = 4.5508
	old_data_grads_norm = 6.2157
	sim_grads_norm = -0.0068
-- Starting training on experience 72 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6526
	data_grads_norm = 3.7390
	new_data_grads_norm = 6.0797
	old_data_grads_norm = 5.2910
	sim_grads_norm = -0.0085
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5294
	data_grads_norm = 3.8253
	new_data_grads_norm = 6.0370
	old_data_grads_norm = 4.7786
	sim_grads_norm = 0.0532
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4359
	data_grads_norm = 3.4600
	new_data_grads_norm = 5.9029
	old_data_grads_norm = 4.1962
	sim_grads_norm = 0.0375
-- Starting training on experience 73 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6695
	data_grads_norm = 3.4447
	new_data_grads_norm = 5.2620
	old_data_grads_norm = 3.8417
	sim_grads_norm = 0.0076
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5378
	data_grads_norm = 3.2234
	new_data_grads_norm = 4.7948
	old_data_grads_norm = 4.9047
	sim_grads_norm = 0.0222
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9473
	data_grads_norm = 3.7955
	new_data_grads_norm = 5.3712
	old_data_grads_norm = 5.6129
	sim_grads_norm = 0.0527
-- Starting training on experience 74 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9167
	data_grads_norm = 3.4959
	new_data_grads_norm = 4.6849
	old_data_grads_norm = 5.0429
	sim_grads_norm = 0.0148
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7332
	data_grads_norm = 4.1671
	new_data_grads_norm = 4.8669
	old_data_grads_norm = 6.2672
	sim_grads_norm = 0.0477
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8469
	data_grads_norm = 3.8852
	new_data_grads_norm = 5.4994
	old_data_grads_norm = 4.9081
	sim_grads_norm = -0.0040
-- Starting training on experience 75 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7361
	data_grads_norm = 3.4918
	new_data_grads_norm = 4.8017
	old_data_grads_norm = 4.0773
	sim_grads_norm = 0.0771
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3733
	data_grads_norm = 3.6066
	new_data_grads_norm = 4.9105
	old_data_grads_norm = 4.9937
	sim_grads_norm = -0.0331
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2644
	data_grads_norm = 3.2154
	new_data_grads_norm = 5.2689
	old_data_grads_norm = 3.7414
	sim_grads_norm = -0.0035
-- Starting training on experience 76 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3316
	data_grads_norm = 3.5778
	new_data_grads_norm = 5.7307
	old_data_grads_norm = 5.3906
	sim_grads_norm = -0.0117
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6985
	data_grads_norm = 3.8892
	new_data_grads_norm = 5.6025
	old_data_grads_norm = 5.2901
	sim_grads_norm = 0.0784
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3699
	data_grads_norm = 3.1679
	new_data_grads_norm = 5.4135
	old_data_grads_norm = 4.1957
	sim_grads_norm = -0.0307
-- Starting training on experience 77 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3863
	data_grads_norm = 3.1050
	new_data_grads_norm = 5.3953
	old_data_grads_norm = 3.6664
	sim_grads_norm = -0.0704
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7433
	data_grads_norm = 3.8328
	new_data_grads_norm = 5.4825
	old_data_grads_norm = 5.8456
	sim_grads_norm = 0.0256
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8047
	data_grads_norm = 4.3701
	new_data_grads_norm = 5.5237
	old_data_grads_norm = 6.4115
	sim_grads_norm = 0.0134
-- Starting training on experience 78 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8229
	data_grads_norm = 4.0478
	new_data_grads_norm = 4.9324
	old_data_grads_norm = 6.3445
	sim_grads_norm = -0.0151
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6005
	data_grads_norm = 3.8090
	new_data_grads_norm = 5.9326
	old_data_grads_norm = 5.4306
	sim_grads_norm = -0.0822
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4137
	data_grads_norm = 3.1028
	new_data_grads_norm = 5.0424
	old_data_grads_norm = 4.5207
	sim_grads_norm = -0.0125
-- Starting training on experience 79 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4681
	data_grads_norm = 3.8301
	new_data_grads_norm = 5.7938
	old_data_grads_norm = 4.9496
	sim_grads_norm = 0.0161
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7767
	data_grads_norm = 3.6429
	new_data_grads_norm = 5.4091
	old_data_grads_norm = 4.7136
	sim_grads_norm = 0.0237
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5672
	data_grads_norm = 3.7020
	new_data_grads_norm = 6.0169
	old_data_grads_norm = 4.3544
	sim_grads_norm = 0.0506
-- Starting training on experience 80 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9071
	data_grads_norm = 3.9904
	new_data_grads_norm = 6.2460
	old_data_grads_norm = 3.3327
	sim_grads_norm = 0.0760
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5416
	data_grads_norm = 3.6678
	new_data_grads_norm = 6.3108
	old_data_grads_norm = 3.9711
	sim_grads_norm = -0.0037
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6761
	data_grads_norm = 4.0593
	new_data_grads_norm = 6.0348
	old_data_grads_norm = 4.3803
	sim_grads_norm = -0.0187
-- Starting training on experience 81 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1013
	data_grads_norm = 3.1643
	new_data_grads_norm = 4.9096
	old_data_grads_norm = 4.4910
	sim_grads_norm = -0.0123
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7508
	data_grads_norm = 3.9780
	new_data_grads_norm = 4.8827
	old_data_grads_norm = 5.7218
	sim_grads_norm = -0.0220
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7209
	data_grads_norm = 3.9474
	new_data_grads_norm = 5.6225
	old_data_grads_norm = 5.1363
	sim_grads_norm = 0.0388
-- Starting training on experience 82 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3180
	data_grads_norm = 3.1445
	new_data_grads_norm = 4.9720
	old_data_grads_norm = 4.2285
	sim_grads_norm = 0.0685
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3533
	data_grads_norm = 3.3834
	new_data_grads_norm = 4.9312
	old_data_grads_norm = 4.5600
	sim_grads_norm = 0.0822
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6210
	data_grads_norm = 3.6568
	new_data_grads_norm = 5.0938
	old_data_grads_norm = 5.3358
	sim_grads_norm = -0.0509
-- Starting training on experience 83 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0657
	data_grads_norm = 3.2472
	new_data_grads_norm = 5.3371
	old_data_grads_norm = 3.5412
	sim_grads_norm = 0.0181
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4330
	data_grads_norm = 3.5313
	new_data_grads_norm = 5.0314
	old_data_grads_norm = 4.5863
	sim_grads_norm = -0.0348
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5390
	data_grads_norm = 3.8669
	new_data_grads_norm = 5.1048
	old_data_grads_norm = 5.6667
	sim_grads_norm = -0.0407
-- Starting training on experience 84 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9852
	data_grads_norm = 4.0265
	new_data_grads_norm = 5.5708
	old_data_grads_norm = 5.0256
	sim_grads_norm = 0.0562
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8856
	data_grads_norm = 4.0472
	new_data_grads_norm = 5.8709
	old_data_grads_norm = 5.8627
	sim_grads_norm = 0.0570
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5471
	data_grads_norm = 4.1250
	new_data_grads_norm = 5.6974
	old_data_grads_norm = 5.2382
	sim_grads_norm = -0.0127
-- Starting training on experience 85 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3785
	data_grads_norm = 3.0324
	new_data_grads_norm = 5.3907
	old_data_grads_norm = 4.3881
	sim_grads_norm = -0.0187
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1180
	data_grads_norm = 4.1115
	new_data_grads_norm = 5.7534
	old_data_grads_norm = 5.2231
	sim_grads_norm = 0.0317
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8229
	data_grads_norm = 3.6255
	new_data_grads_norm = 5.4061
	old_data_grads_norm = 4.8062
	sim_grads_norm = -0.0044
-- Starting training on experience 86 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5125
	data_grads_norm = 4.2047
	new_data_grads_norm = 6.3934
	old_data_grads_norm = 5.3567
	sim_grads_norm = 0.0439
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8750
	data_grads_norm = 3.5277
	new_data_grads_norm = 5.5842
	old_data_grads_norm = 3.6723
	sim_grads_norm = 0.0492
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5599
	data_grads_norm = 4.2881
	new_data_grads_norm = 6.6537
	old_data_grads_norm = 5.3715
	sim_grads_norm = -0.0146
-- Starting training on experience 87 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4220
	data_grads_norm = 3.9028
	new_data_grads_norm = 5.2322
	old_data_grads_norm = 5.4021
	sim_grads_norm = -0.0407
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5096
	data_grads_norm = 3.0594
	new_data_grads_norm = 5.1838
	old_data_grads_norm = 3.6306
	sim_grads_norm = 0.0592
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5358
	data_grads_norm = 3.4364
	new_data_grads_norm = 5.3656
	old_data_grads_norm = 4.3373
	sim_grads_norm = -0.0121
-- Starting training on experience 88 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1147
	data_grads_norm = 4.1587
	new_data_grads_norm = 5.2431
	old_data_grads_norm = 6.0462
	sim_grads_norm = -0.0177
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6606
	data_grads_norm = 3.6011
	new_data_grads_norm = 5.2031
	old_data_grads_norm = 5.3249
	sim_grads_norm = 0.0297
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9827
	data_grads_norm = 3.9015
	new_data_grads_norm = 5.3638
	old_data_grads_norm = 5.4812
	sim_grads_norm = 0.0002
-- Starting training on experience 89 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6158
	data_grads_norm = 3.4938
	new_data_grads_norm = 5.4645
	old_data_grads_norm = 4.0080
	sim_grads_norm = 0.0385
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3570
	data_grads_norm = 4.4103
	new_data_grads_norm = 5.5915
	old_data_grads_norm = 7.2940
	sim_grads_norm = 0.0596
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3024
	data_grads_norm = 3.4380
	new_data_grads_norm = 5.1803
	old_data_grads_norm = 4.6473
	sim_grads_norm = 0.0453
-- Starting training on experience 90 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5939
	data_grads_norm = 4.3154
	new_data_grads_norm = 6.0099
	old_data_grads_norm = 6.1220
	sim_grads_norm = 0.0220
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2238
	data_grads_norm = 3.0478
	new_data_grads_norm = 6.0790
	old_data_grads_norm = 3.2820
	sim_grads_norm = 0.0066
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1639
	data_grads_norm = 3.8967
	new_data_grads_norm = 5.2256
	old_data_grads_norm = 4.8463
	sim_grads_norm = 0.0561
-- Starting training on experience 91 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4213
	data_grads_norm = 3.4917
	new_data_grads_norm = 4.9626
	old_data_grads_norm = 4.7142
	sim_grads_norm = 0.0388
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4947
	data_grads_norm = 3.7462
	new_data_grads_norm = 4.9681
	old_data_grads_norm = 5.7331
	sim_grads_norm = 0.0149
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4787
	data_grads_norm = 3.3972
	new_data_grads_norm = 4.7232
	old_data_grads_norm = 5.2455
	sim_grads_norm = -0.0867
-- Starting training on experience 92 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1230
	data_grads_norm = 2.8616
	new_data_grads_norm = 4.7047
	old_data_grads_norm = 3.8225
	sim_grads_norm = -0.0150
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0876
	data_grads_norm = 3.0277
	new_data_grads_norm = 4.8758
	old_data_grads_norm = 4.0137
	sim_grads_norm = 0.0164
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0053
	data_grads_norm = 4.0694
	new_data_grads_norm = 5.2022
	old_data_grads_norm = 6.7423
	sim_grads_norm = -0.0595
-- Starting training on experience 93 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2091
	data_grads_norm = 3.8252
	new_data_grads_norm = 5.7018
	old_data_grads_norm = 4.6255
	sim_grads_norm = -0.0007
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0813
	data_grads_norm = 3.6984
	new_data_grads_norm = 5.5650
	old_data_grads_norm = 4.4674
	sim_grads_norm = 0.0718
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8734
	data_grads_norm = 3.7455
	new_data_grads_norm = 5.4470
	old_data_grads_norm = 4.3041
	sim_grads_norm = -0.0022
-- Starting training on experience 94 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7199
	data_grads_norm = 3.5065
	new_data_grads_norm = 4.7424
	old_data_grads_norm = 4.5144
	sim_grads_norm = -0.0162
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8519
	data_grads_norm = 3.9777
	new_data_grads_norm = 4.9702
	old_data_grads_norm = 6.2225
	sim_grads_norm = 0.0062
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6424
	data_grads_norm = 3.6826
	new_data_grads_norm = 4.7851
	old_data_grads_norm = 4.9574
	sim_grads_norm = 0.0632
-- Starting training on experience 95 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6240
	data_grads_norm = 3.1592
	new_data_grads_norm = 4.6912
	old_data_grads_norm = 4.2815
	sim_grads_norm = -0.0094
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7877
	data_grads_norm = 3.4066
	new_data_grads_norm = 5.7686
	old_data_grads_norm = 4.5154
	sim_grads_norm = 0.0060
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9420
	data_grads_norm = 3.3886
	new_data_grads_norm = 5.9400
	old_data_grads_norm = 4.4921
	sim_grads_norm = -0.0049
-- Starting training on experience 96 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3147
	data_grads_norm = 3.5386
	new_data_grads_norm = 4.7277
	old_data_grads_norm = 4.3375
	sim_grads_norm = -0.0163
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3817
	data_grads_norm = 4.2786
	new_data_grads_norm = 4.7960
	old_data_grads_norm = 5.2091
	sim_grads_norm = 0.2222
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5728
	data_grads_norm = 3.6005
	new_data_grads_norm = 5.0532
	old_data_grads_norm = 4.7593
	sim_grads_norm = -0.0325
-- Starting training on experience 97 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3452
	data_grads_norm = 3.8320
	new_data_grads_norm = 5.3534
	old_data_grads_norm = 4.7490
	sim_grads_norm = -0.0102
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3956
	data_grads_norm = 3.2842
	new_data_grads_norm = 5.3775
	old_data_grads_norm = 3.7765
	sim_grads_norm = 0.0877
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3157
	data_grads_norm = 4.1985
	new_data_grads_norm = 5.6894
	old_data_grads_norm = 4.0283
	sim_grads_norm = 0.0663
-- Starting training on experience 98 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3175
	data_grads_norm = 3.1869
	new_data_grads_norm = 3.8800
	old_data_grads_norm = 5.1077
	sim_grads_norm = -0.0456
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0843
	data_grads_norm = 3.0084
	new_data_grads_norm = 4.5498
	old_data_grads_norm = 3.5150
	sim_grads_norm = -0.0029
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9145
	data_grads_norm = 4.0849
	new_data_grads_norm = 5.1751
	old_data_grads_norm = 5.2665
	sim_grads_norm = 0.1348
-- Starting training on experience 99 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2738
	data_grads_norm = 3.2327
	new_data_grads_norm = 5.7200
	old_data_grads_norm = 4.3148
	sim_grads_norm = 0.0027
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9304
	data_grads_norm = 3.6623
	new_data_grads_norm = 5.2706
	old_data_grads_norm = 4.7945
	sim_grads_norm = 0.1375
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1890
	data_grads_norm = 3.3993
	new_data_grads_norm = 5.4677
	old_data_grads_norm = 4.3664
	sim_grads_norm = -0.0048
-- Starting training on experience 100 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3163
	data_grads_norm = 3.7599
	new_data_grads_norm = 4.8301
	old_data_grads_norm = 5.2329
	sim_grads_norm = 0.0032
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9513
	data_grads_norm = 3.3113
	new_data_grads_norm = 4.4451
	old_data_grads_norm = 6.3156
	sim_grads_norm = 0.0032
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5199
	data_grads_norm = 3.4114
	new_data_grads_norm = 4.6473
	old_data_grads_norm = 4.8252
	sim_grads_norm = -0.0492
-- Starting training on experience 101 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2981
	data_grads_norm = 3.2432
	new_data_grads_norm = 5.1833
	old_data_grads_norm = 3.3843
	sim_grads_norm = 0.1559
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5925
	data_grads_norm = 4.1124
	new_data_grads_norm = 4.8449
	old_data_grads_norm = 6.6806
	sim_grads_norm = 0.0057
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3808
	data_grads_norm = 3.9277
	new_data_grads_norm = 5.5674
	old_data_grads_norm = 6.1123
	sim_grads_norm = 0.0368
-- Starting training on experience 102 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0457
	data_grads_norm = 3.0518
	new_data_grads_norm = 4.9493
	old_data_grads_norm = 3.6708
	sim_grads_norm = -0.0207
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9135
	data_grads_norm = 3.1239
	new_data_grads_norm = 4.7746
	old_data_grads_norm = 4.5332
	sim_grads_norm = -0.0123
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2616
	data_grads_norm = 3.4766
	new_data_grads_norm = 4.6760
	old_data_grads_norm = 4.4253
	sim_grads_norm = 0.0411
-- Starting training on experience 103 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2139
	data_grads_norm = 3.4239
	new_data_grads_norm = 4.6192
	old_data_grads_norm = 4.6347
	sim_grads_norm = -0.0386
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9295
	data_grads_norm = 3.0688
	new_data_grads_norm = 4.4797
	old_data_grads_norm = 3.9612
	sim_grads_norm = -0.0260
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3751
	data_grads_norm = 3.6515
	new_data_grads_norm = 4.1101
	old_data_grads_norm = 6.1404
	sim_grads_norm = -0.0373
-- Starting training on experience 104 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9501
	data_grads_norm = 3.2637
	new_data_grads_norm = 4.3228
	old_data_grads_norm = 4.5376
	sim_grads_norm = -0.0243
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8807
	data_grads_norm = 3.1065
	new_data_grads_norm = 4.8540
	old_data_grads_norm = 4.3284
	sim_grads_norm = -0.0395
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7196
	data_grads_norm = 4.3018
	new_data_grads_norm = 4.6206
	old_data_grads_norm = 6.5564
	sim_grads_norm = -0.0284
-- Starting training on experience 105 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8765
	data_grads_norm = 4.1993
	new_data_grads_norm = 6.2056
	old_data_grads_norm = 4.5043
	sim_grads_norm = 0.0817
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4509
	data_grads_norm = 3.3740
	new_data_grads_norm = 5.4106
	old_data_grads_norm = 4.0861
	sim_grads_norm = 0.0581
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1824
	data_grads_norm = 3.3054
	new_data_grads_norm = 5.2674
	old_data_grads_norm = 3.3488
	sim_grads_norm = 0.0422
-- Starting training on experience 106 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6728
	data_grads_norm = 3.6426
	new_data_grads_norm = 4.1612
	old_data_grads_norm = 5.6776
	sim_grads_norm = -0.0251
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6508
	data_grads_norm = 3.4571
	new_data_grads_norm = 4.4859
	old_data_grads_norm = 4.6868
	sim_grads_norm = -0.0009
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1601
	data_grads_norm = 3.4146
	new_data_grads_norm = 4.6185
	old_data_grads_norm = 5.2940
	sim_grads_norm = -0.0307
-- Starting training on experience 107 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1400
	data_grads_norm = 3.6963
	new_data_grads_norm = 4.4334
	old_data_grads_norm = 5.3877
	sim_grads_norm = 0.0055
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6997
	data_grads_norm = 4.2528
	new_data_grads_norm = 4.8368
	old_data_grads_norm = 6.7424
	sim_grads_norm = -0.0230
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2339
	data_grads_norm = 3.5410
	new_data_grads_norm = 4.8669
	old_data_grads_norm = 5.4389
	sim_grads_norm = -0.0311
-- Starting training on experience 108 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8254
	data_grads_norm = 3.9196
	new_data_grads_norm = 5.7450
	old_data_grads_norm = 5.5468
	sim_grads_norm = 0.0064
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4625
	data_grads_norm = 4.7914
	new_data_grads_norm = 5.5967
	old_data_grads_norm = 6.7982
	sim_grads_norm = 0.0330
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2598
	data_grads_norm = 3.4251
	new_data_grads_norm = 4.9513
	old_data_grads_norm = 4.4723
	sim_grads_norm = -0.0102
-- Starting training on experience 109 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0487
	data_grads_norm = 3.0272
	new_data_grads_norm = 4.2516
	old_data_grads_norm = 4.2908
	sim_grads_norm = -0.0403
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0954
	data_grads_norm = 2.8955
	new_data_grads_norm = 4.4771
	old_data_grads_norm = 4.4218
	sim_grads_norm = 0.0085
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3235
	data_grads_norm = 3.3999
	new_data_grads_norm = 4.3246
	old_data_grads_norm = 5.3611
	sim_grads_norm = -0.0046
-- Starting training on experience 110 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6313
	data_grads_norm = 3.7551
	new_data_grads_norm = 5.6481
	old_data_grads_norm = 3.6284
	sim_grads_norm = 0.0821
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8901
	data_grads_norm = 4.4540
	new_data_grads_norm = 5.7048
	old_data_grads_norm = 5.7108
	sim_grads_norm = 0.0763
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0712
	data_grads_norm = 3.4006
	new_data_grads_norm = 5.4860
	old_data_grads_norm = 3.9841
	sim_grads_norm = -0.0270
-- Starting training on experience 111 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5761
	data_grads_norm = 4.1998
	new_data_grads_norm = 5.7296
	old_data_grads_norm = 5.3752
	sim_grads_norm = 0.0462
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3177
	data_grads_norm = 3.5773
	new_data_grads_norm = 5.8178
	old_data_grads_norm = 5.0347
	sim_grads_norm = -0.0040
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4610
	data_grads_norm = 3.5358
	new_data_grads_norm = 5.3960
	old_data_grads_norm = 4.4293
	sim_grads_norm = -0.0063
-- Starting training on experience 112 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1662
	data_grads_norm = 3.2765
	new_data_grads_norm = 4.8952
	old_data_grads_norm = 4.1264
	sim_grads_norm = 0.0379
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4683
	data_grads_norm = 3.6560
	new_data_grads_norm = 5.4079
	old_data_grads_norm = 4.5187
	sim_grads_norm = -0.0108
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0820
	data_grads_norm = 3.0005
	new_data_grads_norm = 5.7089
	old_data_grads_norm = 3.7353
	sim_grads_norm = -0.0202
-- Starting training on experience 113 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4368
	data_grads_norm = 3.8499
	new_data_grads_norm = 4.9630
	old_data_grads_norm = 5.7863
	sim_grads_norm = 0.0282
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5976
	data_grads_norm = 3.2049
	new_data_grads_norm = 4.7905
	old_data_grads_norm = 4.0272
	sim_grads_norm = 0.1180
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0663
	data_grads_norm = 3.0575
	new_data_grads_norm = 4.2048
	old_data_grads_norm = 5.5455
	sim_grads_norm = -0.0030
-- Starting training on experience 114 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3520
	data_grads_norm = 3.6556
	new_data_grads_norm = 4.7919
	old_data_grads_norm = 5.6252
	sim_grads_norm = -0.0048
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8997
	data_grads_norm = 2.8392
	new_data_grads_norm = 4.8393
	old_data_grads_norm = 3.1538
	sim_grads_norm = 0.0179
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5943
	data_grads_norm = 3.9042
	new_data_grads_norm = 4.5872
	old_data_grads_norm = 5.2974
	sim_grads_norm = 0.0231
-- Starting training on experience 115 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6109
	data_grads_norm = 4.3220
	new_data_grads_norm = 6.3171
	old_data_grads_norm = 5.8950
	sim_grads_norm = 0.0121
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5175
	data_grads_norm = 3.7669
	new_data_grads_norm = 6.3681
	old_data_grads_norm = 4.1509
	sim_grads_norm = -0.0251
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1796
	data_grads_norm = 3.8868
	new_data_grads_norm = 5.9880
	old_data_grads_norm = 4.6031
	sim_grads_norm = 0.0850
-- Starting training on experience 116 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5033
	data_grads_norm = 3.2597
	new_data_grads_norm = 5.0203
	old_data_grads_norm = 3.7640
	sim_grads_norm = 0.0128
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4419
	data_grads_norm = 3.4211
	new_data_grads_norm = 4.4124
	old_data_grads_norm = 4.0315
	sim_grads_norm = 0.2037
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2281
	data_grads_norm = 3.1036
	new_data_grads_norm = 4.7882
	old_data_grads_norm = 4.0006
	sim_grads_norm = -0.0221
-- Starting training on experience 117 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0244
	data_grads_norm = 3.9710
	new_data_grads_norm = 5.1032
	old_data_grads_norm = 5.6868
	sim_grads_norm = 0.0286
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7583
	data_grads_norm = 4.0045
	new_data_grads_norm = 5.0010
	old_data_grads_norm = 5.6664
	sim_grads_norm = 0.0011
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3040
	data_grads_norm = 3.6865
	new_data_grads_norm = 4.9978
	old_data_grads_norm = 5.6534
	sim_grads_norm = -0.0235
-- Starting training on experience 118 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1420
	data_grads_norm = 3.2114
	new_data_grads_norm = 4.3199
	old_data_grads_norm = 4.7810
	sim_grads_norm = 0.0497
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5120
	data_grads_norm = 4.0247
	new_data_grads_norm = 4.4126
	old_data_grads_norm = 5.9823
	sim_grads_norm = 0.0009
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2770
	data_grads_norm = 4.3470
	new_data_grads_norm = 4.8626
	old_data_grads_norm = 5.9792
	sim_grads_norm = -0.0055
-- Starting training on experience 119 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7481
	data_grads_norm = 4.1903
	new_data_grads_norm = 5.2425
	old_data_grads_norm = 5.9370
	sim_grads_norm = 0.0117
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8212
	data_grads_norm = 4.1587
	new_data_grads_norm = 5.4331
	old_data_grads_norm = 5.3023
	sim_grads_norm = -0.0053
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9583
	data_grads_norm = 3.8351
	new_data_grads_norm = 5.1748
	old_data_grads_norm = 5.0169
	sim_grads_norm = 0.0886
-- Starting training on experience 120 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1193
	data_grads_norm = 3.7151
	new_data_grads_norm = 5.4407
	old_data_grads_norm = 4.6061
	sim_grads_norm = 0.0046
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3601
	data_grads_norm = 3.4706
	new_data_grads_norm = 4.9380
	old_data_grads_norm = 4.7249
	sim_grads_norm = 0.0231
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6633
	data_grads_norm = 4.2348
	new_data_grads_norm = 5.0095
	old_data_grads_norm = 6.3930
	sim_grads_norm = -0.0107
-- Starting training on experience 121 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7214
	data_grads_norm = 3.9868
	new_data_grads_norm = 6.4576
	old_data_grads_norm = 4.2133
	sim_grads_norm = -0.0270
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5613
	data_grads_norm = 4.3273
	new_data_grads_norm = 6.3536
	old_data_grads_norm = 5.3103
	sim_grads_norm = 0.0389
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7216
	data_grads_norm = 4.0595
	new_data_grads_norm = 6.0763
	old_data_grads_norm = 7.1567
	sim_grads_norm = -0.0249
-- Starting training on experience 122 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1770
	data_grads_norm = 3.4911
	new_data_grads_norm = 4.6884
	old_data_grads_norm = 5.9195
	sim_grads_norm = 0.0693
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5100
	data_grads_norm = 4.1723
	new_data_grads_norm = 5.8445
	old_data_grads_norm = 4.9901
	sim_grads_norm = 0.0117
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5361
	data_grads_norm = 4.4867
	new_data_grads_norm = 5.7633
	old_data_grads_norm = 6.4239
	sim_grads_norm = -0.0002
-- Starting training on experience 123 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6053
	data_grads_norm = 3.6057
	new_data_grads_norm = 5.0518
	old_data_grads_norm = 4.5348
	sim_grads_norm = 0.0009
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7866
	data_grads_norm = 4.1563
	new_data_grads_norm = 5.4106
	old_data_grads_norm = 5.3083
	sim_grads_norm = 0.1297
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5571
	data_grads_norm = 3.7873
	new_data_grads_norm = 5.3982
	old_data_grads_norm = 4.6371
	sim_grads_norm = -0.0075
-- Starting training on experience 124 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5110
	data_grads_norm = 3.7816
	new_data_grads_norm = 5.0521
	old_data_grads_norm = 4.7354
	sim_grads_norm = 0.0361
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7577
	data_grads_norm = 4.2306
	new_data_grads_norm = 5.1456
	old_data_grads_norm = 5.5301
	sim_grads_norm = -0.0018
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8004
	data_grads_norm = 4.2620
	new_data_grads_norm = 5.8209
	old_data_grads_norm = 5.9898
	sim_grads_norm = 0.0753
-- Starting training on experience 125 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3592
	data_grads_norm = 3.0210
	new_data_grads_norm = 4.7305
	old_data_grads_norm = 3.7375
	sim_grads_norm = -0.0270
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7123
	data_grads_norm = 4.0855
	new_data_grads_norm = 4.5536
	old_data_grads_norm = 6.5757
	sim_grads_norm = 0.0096
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0700
	data_grads_norm = 3.9392
	new_data_grads_norm = 4.8142
	old_data_grads_norm = 6.5770
	sim_grads_norm = -0.0275
-- Starting training on experience 126 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7469
	data_grads_norm = 4.1237
	new_data_grads_norm = 6.0904
	old_data_grads_norm = 5.1807
	sim_grads_norm = 0.1307
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9329
	data_grads_norm = 4.1879
	new_data_grads_norm = 5.4397
	old_data_grads_norm = 4.7451
	sim_grads_norm = -0.0130
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9423
	data_grads_norm = 3.9107
	new_data_grads_norm = 5.0871
	old_data_grads_norm = 6.4880
	sim_grads_norm = -0.0130
-- Starting training on experience 127 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0273
	data_grads_norm = 3.4973
	new_data_grads_norm = 4.5230
	old_data_grads_norm = 5.6743
	sim_grads_norm = 0.0145
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6133
	data_grads_norm = 4.2465
	new_data_grads_norm = 4.4943
	old_data_grads_norm = 6.6984
	sim_grads_norm = 0.0236
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9004
	data_grads_norm = 3.1281
	new_data_grads_norm = 4.2872
	old_data_grads_norm = 4.0509
	sim_grads_norm = 0.1196
-- Starting training on experience 128 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2930
	data_grads_norm = 3.5902
	new_data_grads_norm = 4.8284
	old_data_grads_norm = 4.8419
	sim_grads_norm = 0.1143
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9027
	data_grads_norm = 2.8730
	new_data_grads_norm = 4.6562
	old_data_grads_norm = 4.1419
	sim_grads_norm = -0.0102
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2271
	data_grads_norm = 4.2058
	new_data_grads_norm = 4.4395
	old_data_grads_norm = 6.4098
	sim_grads_norm = -0.0523
-- Starting training on experience 129 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0346
	data_grads_norm = 3.2037
	new_data_grads_norm = 4.3628
	old_data_grads_norm = 4.1677
	sim_grads_norm = -0.0103
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4105
	data_grads_norm = 3.2647
	new_data_grads_norm = 4.4508
	old_data_grads_norm = 4.6252
	sim_grads_norm = -0.0347
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2843
	data_grads_norm = 3.2282
	new_data_grads_norm = 4.9870
	old_data_grads_norm = 3.7253
	sim_grads_norm = -0.0244
-- Starting training on experience 130 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3065
	data_grads_norm = 3.0949
	new_data_grads_norm = 4.4985
	old_data_grads_norm = 3.8345
	sim_grads_norm = 0.0350
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3628
	data_grads_norm = 3.3876
	new_data_grads_norm = 4.5604
	old_data_grads_norm = 5.4941
	sim_grads_norm = 0.0470
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8303
	data_grads_norm = 2.5353
	new_data_grads_norm = 4.4535
	old_data_grads_norm = 3.1532
	sim_grads_norm = 0.0650
-- Starting training on experience 131 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8959
	data_grads_norm = 2.8662
	new_data_grads_norm = 4.5347
	old_data_grads_norm = 4.0925
	sim_grads_norm = -0.0217
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8325
	data_grads_norm = 3.0620
	new_data_grads_norm = 4.8484
	old_data_grads_norm = 4.1231
	sim_grads_norm = -0.0581
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3636
	data_grads_norm = 3.7720
	new_data_grads_norm = 4.9351
	old_data_grads_norm = 5.2875
	sim_grads_norm = 0.0372
-- Starting training on experience 132 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2226
	data_grads_norm = 3.5040
	new_data_grads_norm = 5.1636
	old_data_grads_norm = 4.8045
	sim_grads_norm = -0.0046
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2513
	data_grads_norm = 3.4840
	new_data_grads_norm = 5.2070
	old_data_grads_norm = 4.5516
	sim_grads_norm = -0.0056
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7584
	data_grads_norm = 4.3962
	new_data_grads_norm = 5.4343
	old_data_grads_norm = 6.7424
	sim_grads_norm = -0.0024
-- Starting training on experience 133 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6862
	data_grads_norm = 3.3242
	new_data_grads_norm = 4.7291
	old_data_grads_norm = 4.8853
	sim_grads_norm = -0.0085
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5404
	data_grads_norm = 4.2232
	new_data_grads_norm = 4.9645
	old_data_grads_norm = 7.0003
	sim_grads_norm = 0.0245
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5439
	data_grads_norm = 3.6913
	new_data_grads_norm = 4.6841
	old_data_grads_norm = 5.6968
	sim_grads_norm = -0.0195
-- Starting training on experience 134 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2254
	data_grads_norm = 3.1724
	new_data_grads_norm = 4.8027
	old_data_grads_norm = 4.1984
	sim_grads_norm = -0.0253
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3654
	data_grads_norm = 3.3919
	new_data_grads_norm = 4.8033
	old_data_grads_norm = 4.3305
	sim_grads_norm = -0.0170
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0482
	data_grads_norm = 3.9971
	new_data_grads_norm = 4.6779
	old_data_grads_norm = 6.2772
	sim_grads_norm = -0.0093
-- Starting training on experience 135 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2512
	data_grads_norm = 3.4876
	new_data_grads_norm = 5.9504
	old_data_grads_norm = 4.1160
	sim_grads_norm = 0.0461
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4943
	data_grads_norm = 3.5775
	new_data_grads_norm = 4.3412
	old_data_grads_norm = 5.4747
	sim_grads_norm = -0.0095
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1807
	data_grads_norm = 3.6499
	new_data_grads_norm = 4.9456
	old_data_grads_norm = 5.8188
	sim_grads_norm = 0.0052
-- Starting training on experience 136 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5630
	data_grads_norm = 4.3437
	new_data_grads_norm = 5.7312
	old_data_grads_norm = 5.9315
	sim_grads_norm = 0.0225
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0754
	data_grads_norm = 4.4551
	new_data_grads_norm = 5.3136
	old_data_grads_norm = 7.2253
	sim_grads_norm = -0.0189
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6259
	data_grads_norm = 3.4202
	new_data_grads_norm = 5.0715
	old_data_grads_norm = 4.6453
	sim_grads_norm = -0.0071
-- Starting training on experience 137 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5273
	data_grads_norm = 3.5459
	new_data_grads_norm = 5.7195
	old_data_grads_norm = 4.6884
	sim_grads_norm = -0.1571
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8925
	data_grads_norm = 4.0194
	new_data_grads_norm = 5.2896
	old_data_grads_norm = 4.6867
	sim_grads_norm = 0.0404
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7696
	data_grads_norm = 4.1253
	new_data_grads_norm = 5.6852
	old_data_grads_norm = 5.6767
	sim_grads_norm = 0.0258
-- Starting training on experience 138 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4007
	data_grads_norm = 3.5636
	new_data_grads_norm = 5.1758
	old_data_grads_norm = 4.6084
	sim_grads_norm = 0.0763
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9960
	data_grads_norm = 3.2300
	new_data_grads_norm = 5.0514
	old_data_grads_norm = 4.9087
	sim_grads_norm = 0.0201
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9812
	data_grads_norm = 3.1950
	new_data_grads_norm = 4.5935
	old_data_grads_norm = 4.2499
	sim_grads_norm = -0.0357
-- Starting training on experience 139 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7080
	data_grads_norm = 3.7182
	new_data_grads_norm = 5.3828
	old_data_grads_norm = 4.8094
	sim_grads_norm = 0.0382
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3522
	data_grads_norm = 3.6505
	new_data_grads_norm = 4.9238
	old_data_grads_norm = 4.9538
	sim_grads_norm = -0.0060
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0494
	data_grads_norm = 3.9492
	new_data_grads_norm = 5.3459
	old_data_grads_norm = 5.2865
	sim_grads_norm = 0.0122
-- Starting training on experience 140 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1550
	data_grads_norm = 3.0709
	new_data_grads_norm = 5.3429
	old_data_grads_norm = 3.3095
	sim_grads_norm = -0.0159
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4341
	data_grads_norm = 3.6215
	new_data_grads_norm = 5.4901
	old_data_grads_norm = 4.4604
	sim_grads_norm = 0.0528
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4547
	data_grads_norm = 3.7683
	new_data_grads_norm = 5.2408
	old_data_grads_norm = 5.5688
	sim_grads_norm = 0.0160
-- Starting training on experience 141 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5375
	data_grads_norm = 4.6873
	new_data_grads_norm = 6.4674
	old_data_grads_norm = 4.5991
	sim_grads_norm = -0.0330
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0065
	data_grads_norm = 5.5031
	new_data_grads_norm = 7.4833
	old_data_grads_norm = 4.5112
	sim_grads_norm = 0.0002
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6194
	data_grads_norm = 4.9402
	new_data_grads_norm = 7.4536
	old_data_grads_norm = 4.4296
	sim_grads_norm = 0.0916
-- Starting training on experience 142 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6010
	data_grads_norm = 4.1160
	new_data_grads_norm = 5.5321
	old_data_grads_norm = 5.8649
	sim_grads_norm = 0.0543
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4063
	data_grads_norm = 4.0198
	new_data_grads_norm = 5.9948
	old_data_grads_norm = 5.7043
	sim_grads_norm = -0.0431
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7445
	data_grads_norm = 4.2147
	new_data_grads_norm = 5.9997
	old_data_grads_norm = 5.8374
	sim_grads_norm = 0.0781
-- Starting training on experience 143 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9047
	data_grads_norm = 2.6503
	new_data_grads_norm = 4.3502
	old_data_grads_norm = 3.7105
	sim_grads_norm = -0.0279
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3756
	data_grads_norm = 3.6629
	new_data_grads_norm = 4.8701
	old_data_grads_norm = 4.4874
	sim_grads_norm = 0.0053
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5053
	data_grads_norm = 3.8842
	new_data_grads_norm = 4.5539
	old_data_grads_norm = 6.3611
	sim_grads_norm = -0.0307
-- Starting training on experience 144 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9461
	data_grads_norm = 4.1905
	new_data_grads_norm = 5.9614
	old_data_grads_norm = 5.1275
	sim_grads_norm = 0.0551
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9467
	data_grads_norm = 4.3731
	new_data_grads_norm = 5.2373
	old_data_grads_norm = 6.2742
	sim_grads_norm = 0.0190
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1288
	data_grads_norm = 3.0856
	new_data_grads_norm = 5.3588
	old_data_grads_norm = 3.2417
	sim_grads_norm = -0.0067
-- Starting training on experience 145 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9538
	data_grads_norm = 3.2203
	new_data_grads_norm = 4.9442
	old_data_grads_norm = 3.2379
	sim_grads_norm = -0.0157
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4148
	data_grads_norm = 3.8202
	new_data_grads_norm = 4.8909
	old_data_grads_norm = 5.1082
	sim_grads_norm = -0.0142
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4899
	data_grads_norm = 3.6907
	new_data_grads_norm = 5.2244
	old_data_grads_norm = 4.7164
	sim_grads_norm = 0.0019
-- Starting training on experience 146 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6270
	data_grads_norm = 4.0993
	new_data_grads_norm = 5.8097
	old_data_grads_norm = 5.4967
	sim_grads_norm = -0.0006
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6938
	data_grads_norm = 3.9526
	new_data_grads_norm = 6.6728
	old_data_grads_norm = 4.4676
	sim_grads_norm = 0.0314
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6611
	data_grads_norm = 3.5482
	new_data_grads_norm = 5.0871
	old_data_grads_norm = 5.0441
	sim_grads_norm = -0.0407
-- Starting training on experience 147 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7958
	data_grads_norm = 3.7849
	new_data_grads_norm = 5.1924
	old_data_grads_norm = 4.9762
	sim_grads_norm = -0.0039
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6974
	data_grads_norm = 3.7152
	new_data_grads_norm = 5.0847
	old_data_grads_norm = 5.2689
	sim_grads_norm = 0.0633
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4550
	data_grads_norm = 3.3072
	new_data_grads_norm = 5.2707
	old_data_grads_norm = 4.1602
	sim_grads_norm = 0.0176
-- Starting training on experience 148 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0856
	data_grads_norm = 3.9585
	new_data_grads_norm = 5.6274
	old_data_grads_norm = 4.6606
	sim_grads_norm = 0.0042
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8076
	data_grads_norm = 3.4047
	new_data_grads_norm = 5.1504
	old_data_grads_norm = 4.3647
	sim_grads_norm = -0.0630
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0984
	data_grads_norm = 4.0480
	new_data_grads_norm = 5.9325
	old_data_grads_norm = 5.0875
	sim_grads_norm = -0.0005
-- Starting training on experience 149 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8264
	data_grads_norm = 3.6392
	new_data_grads_norm = 5.5902
	old_data_grads_norm = 5.5565
	sim_grads_norm = -0.0002
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2218
	data_grads_norm = 3.1608
	new_data_grads_norm = 5.3757
	old_data_grads_norm = 3.7520
	sim_grads_norm = -0.0103
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8621
	data_grads_norm = 3.7026
	new_data_grads_norm = 5.5345
	old_data_grads_norm = 4.7145
	sim_grads_norm = 0.0381
-- Starting training on experience 150 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2480
	data_grads_norm = 3.3446
	new_data_grads_norm = 5.2690
	old_data_grads_norm = 4.0821
	sim_grads_norm = -0.0104
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0004
	data_grads_norm = 3.6423
	new_data_grads_norm = 5.8810
	old_data_grads_norm = 4.9512
	sim_grads_norm = 0.0412
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9475
	data_grads_norm = 3.7797
	new_data_grads_norm = 5.8140
	old_data_grads_norm = 4.7059
	sim_grads_norm = 0.0229
-- Starting training on experience 151 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7550
	data_grads_norm = 3.9065
	new_data_grads_norm = 5.6913
	old_data_grads_norm = 5.4739
	sim_grads_norm = 0.0061
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8766
	data_grads_norm = 3.5012
	new_data_grads_norm = 5.0634
	old_data_grads_norm = 4.2360
	sim_grads_norm = -0.0176
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5952
	data_grads_norm = 3.2829
	new_data_grads_norm = 4.7900
	old_data_grads_norm = 3.8308
	sim_grads_norm = -0.0069
-- Starting training on experience 152 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5659
	data_grads_norm = 3.7244
	new_data_grads_norm = 5.2653
	old_data_grads_norm = 4.9171
	sim_grads_norm = -0.0338
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6388
	data_grads_norm = 3.4756
	new_data_grads_norm = 4.8472
	old_data_grads_norm = 4.6698
	sim_grads_norm = 0.0205
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9130
	data_grads_norm = 3.9086
	new_data_grads_norm = 5.4525
	old_data_grads_norm = 5.6102
	sim_grads_norm = -0.0010
-- Starting training on experience 153 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8929
	data_grads_norm = 3.9924
	new_data_grads_norm = 5.3458
	old_data_grads_norm = 6.0385
	sim_grads_norm = 0.0169
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9225
	data_grads_norm = 3.7307
	new_data_grads_norm = 5.2121
	old_data_grads_norm = 4.8197
	sim_grads_norm = 0.0224
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4883
	data_grads_norm = 3.0948
	new_data_grads_norm = 5.1968
	old_data_grads_norm = 3.8974
	sim_grads_norm = 0.0473
-- Starting training on experience 154 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8685
	data_grads_norm = 3.8540
	new_data_grads_norm = 5.4413
	old_data_grads_norm = 4.4420
	sim_grads_norm = 0.0993
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8315
	data_grads_norm = 4.2765
	new_data_grads_norm = 5.5863
	old_data_grads_norm = 6.3790
	sim_grads_norm = -0.0093
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5496
	data_grads_norm = 3.5316
	new_data_grads_norm = 5.0644
	old_data_grads_norm = 4.8586
	sim_grads_norm = -0.0180
-- Starting training on experience 155 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8615
	data_grads_norm = 3.9282
	new_data_grads_norm = 5.0175
	old_data_grads_norm = 5.1277
	sim_grads_norm = 0.1505
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8471
	data_grads_norm = 4.1240
	new_data_grads_norm = 5.3159
	old_data_grads_norm = 5.5979
	sim_grads_norm = -0.0002
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2990
	data_grads_norm = 3.6065
	new_data_grads_norm = 5.7868
	old_data_grads_norm = 4.9934
	sim_grads_norm = -0.0053
-- Starting training on experience 156 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2818
	data_grads_norm = 3.5646
	new_data_grads_norm = 6.0956
	old_data_grads_norm = 5.0891
	sim_grads_norm = -0.0339
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4900
	data_grads_norm = 3.6513
	new_data_grads_norm = 5.8214
	old_data_grads_norm = 4.9064
	sim_grads_norm = -0.0087
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2451
	data_grads_norm = 3.5511
	new_data_grads_norm = 5.9586
	old_data_grads_norm = 6.1520
	sim_grads_norm = 0.0468
-- Starting training on experience 157 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9495
	data_grads_norm = 4.2016
	new_data_grads_norm = 6.0582
	old_data_grads_norm = 5.0443
	sim_grads_norm = 0.1147
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1107
	data_grads_norm = 3.1999
	new_data_grads_norm = 4.6581
	old_data_grads_norm = 5.1433
	sim_grads_norm = -0.0141
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8399
	data_grads_norm = 4.1505
	new_data_grads_norm = 5.3120
	old_data_grads_norm = 6.3129
	sim_grads_norm = -0.0069
-- Starting training on experience 158 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1622
	data_grads_norm = 3.1258
	new_data_grads_norm = 4.9838
	old_data_grads_norm = 3.6559
	sim_grads_norm = 0.0441
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3940
	data_grads_norm = 3.1234
	new_data_grads_norm = 4.6563
	old_data_grads_norm = 4.3031
	sim_grads_norm = 0.0195
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4574
	data_grads_norm = 3.5295
	new_data_grads_norm = 4.9688
	old_data_grads_norm = 4.2243
	sim_grads_norm = 0.0710
-- Starting training on experience 159 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2362
	data_grads_norm = 3.5602
	new_data_grads_norm = 5.3226
	old_data_grads_norm = 3.7380
	sim_grads_norm = 0.0919
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9650
	data_grads_norm = 3.0233
	new_data_grads_norm = 5.1327
	old_data_grads_norm = 3.4764
	sim_grads_norm = -0.0085
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9406
	data_grads_norm = 3.2418
	new_data_grads_norm = 5.5275
	old_data_grads_norm = 4.8156
	sim_grads_norm = 0.0305
-- Starting training on experience 160 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0790
	data_grads_norm = 3.4003
	new_data_grads_norm = 4.6982
	old_data_grads_norm = 4.7703
	sim_grads_norm = 0.0508
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3650
	data_grads_norm = 3.7777
	new_data_grads_norm = 5.1125
	old_data_grads_norm = 5.3737
	sim_grads_norm = 0.0174
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7527
	data_grads_norm = 2.8452
	new_data_grads_norm = 4.9364
	old_data_grads_norm = 2.9380
	sim_grads_norm = -0.0032
-- Starting training on experience 161 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6770
	data_grads_norm = 4.2593
	new_data_grads_norm = 5.2018
	old_data_grads_norm = 6.8243
	sim_grads_norm = 0.0776
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6281
	data_grads_norm = 3.8083
	new_data_grads_norm = 5.3253
	old_data_grads_norm = 5.0706
	sim_grads_norm = 0.0104
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2999
	data_grads_norm = 3.8840
	new_data_grads_norm = 4.7458
	old_data_grads_norm = 6.1220
	sim_grads_norm = -0.0014
-- Starting training on experience 162 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1557
	data_grads_norm = 3.7047
	new_data_grads_norm = 5.1899
	old_data_grads_norm = 5.9531
	sim_grads_norm = 0.0052
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9063
	data_grads_norm = 3.6250
	new_data_grads_norm = 4.8485
	old_data_grads_norm = 4.6215
	sim_grads_norm = 0.0798
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3659
	data_grads_norm = 3.7564
	new_data_grads_norm = 5.0324
	old_data_grads_norm = 4.8948
	sim_grads_norm = 0.0046
-- Starting training on experience 163 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3017
	data_grads_norm = 4.0597
	new_data_grads_norm = 5.7295
	old_data_grads_norm = 5.2290
	sim_grads_norm = 0.0009
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4245
	data_grads_norm = 3.6980
	new_data_grads_norm = 5.7919
	old_data_grads_norm = 4.4136
	sim_grads_norm = -0.0461
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7448
	data_grads_norm = 4.0785
	new_data_grads_norm = 5.5407
	old_data_grads_norm = 4.9267
	sim_grads_norm = 0.2105
-- Starting training on experience 164 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2252
	data_grads_norm = 3.0268
	new_data_grads_norm = 5.0533
	old_data_grads_norm = 4.4333
	sim_grads_norm = -0.0062
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5393
	data_grads_norm = 3.4984
	new_data_grads_norm = 5.3600
	old_data_grads_norm = 5.1132
	sim_grads_norm = -0.0167
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6219
	data_grads_norm = 3.3746
	new_data_grads_norm = 5.0945
	old_data_grads_norm = 4.4292
	sim_grads_norm = 0.0225
-- Starting training on experience 165 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5312
	data_grads_norm = 3.7597
	new_data_grads_norm = 5.4908
	old_data_grads_norm = 4.9398
	sim_grads_norm = 0.0126
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3207
	data_grads_norm = 3.6557
	new_data_grads_norm = 5.4916
	old_data_grads_norm = 4.8175
	sim_grads_norm = 0.0368
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6860
	data_grads_norm = 3.7326
	new_data_grads_norm = 4.9230
	old_data_grads_norm = 5.0178
	sim_grads_norm = 0.0214
-- Starting training on experience 166 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8268
	data_grads_norm = 4.5569
	new_data_grads_norm = 5.6052
	old_data_grads_norm = 6.4119
	sim_grads_norm = 0.0418
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5437
	data_grads_norm = 3.9379
	new_data_grads_norm = 5.7791
	old_data_grads_norm = 5.1228
	sim_grads_norm = -0.0124
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5245
	data_grads_norm = 3.7981
	new_data_grads_norm = 5.2551
	old_data_grads_norm = 4.5624
	sim_grads_norm = 0.0154
-- Starting training on experience 167 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8556
	data_grads_norm = 4.0410
	new_data_grads_norm = 6.1170
	old_data_grads_norm = 5.8348
	sim_grads_norm = -0.0105
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1713
	data_grads_norm = 4.2034
	new_data_grads_norm = 5.8759
	old_data_grads_norm = 5.5327
	sim_grads_norm = 0.0111
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1536
	data_grads_norm = 3.8959
	new_data_grads_norm = 6.4129
	old_data_grads_norm = 4.7387
	sim_grads_norm = -0.0105
-- Starting training on experience 168 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8602
	data_grads_norm = 4.2043
	new_data_grads_norm = 4.7990
	old_data_grads_norm = 5.8383
	sim_grads_norm = 0.0887
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3958
	data_grads_norm = 3.5167
	new_data_grads_norm = 4.6378
	old_data_grads_norm = 5.3385
	sim_grads_norm = 0.0064
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3605
	data_grads_norm = 3.5188
	new_data_grads_norm = 4.5960
	old_data_grads_norm = 5.9119
	sim_grads_norm = -0.0391
-- Starting training on experience 169 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8422
	data_grads_norm = 4.1755
	new_data_grads_norm = 6.1948
	old_data_grads_norm = 5.2452
	sim_grads_norm = 0.1020
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4519
	data_grads_norm = 3.9026
	new_data_grads_norm = 5.4902
	old_data_grads_norm = 5.2695
	sim_grads_norm = -0.0250
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4033
	data_grads_norm = 3.7688
	new_data_grads_norm = 5.2193
	old_data_grads_norm = 4.5979
	sim_grads_norm = 0.0022
-- Starting training on experience 170 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3291
	data_grads_norm = 4.1814
	new_data_grads_norm = 5.3876
	old_data_grads_norm = 5.1025
	sim_grads_norm = -0.0136
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2028
	data_grads_norm = 3.8082
	new_data_grads_norm = 5.3604
	old_data_grads_norm = 3.9282
	sim_grads_norm = 0.0700
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1636
	data_grads_norm = 3.6360
	new_data_grads_norm = 5.6578
	old_data_grads_norm = 4.1282
	sim_grads_norm = -0.0484
-- Starting training on experience 171 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0780
	data_grads_norm = 3.0053
	new_data_grads_norm = 5.1856
	old_data_grads_norm = 2.9305
	sim_grads_norm = 0.0016
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2133
	data_grads_norm = 3.6028
	new_data_grads_norm = 5.3262
	old_data_grads_norm = 4.5793
	sim_grads_norm = -0.0347
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6950
	data_grads_norm = 3.8416
	new_data_grads_norm = 5.4015
	old_data_grads_norm = 5.3744
	sim_grads_norm = -0.0590
-- Starting training on experience 172 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7465
	data_grads_norm = 4.2363
	new_data_grads_norm = 5.2434
	old_data_grads_norm = 5.0268
	sim_grads_norm = 0.0813
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3045
	data_grads_norm = 3.1703
	new_data_grads_norm = 5.2731
	old_data_grads_norm = 4.3811
	sim_grads_norm = -0.0023
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2824
	data_grads_norm = 3.8917
	new_data_grads_norm = 4.7511
	old_data_grads_norm = 6.4076
	sim_grads_norm = 0.0195
-- Starting training on experience 173 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8251
	data_grads_norm = 3.8912
	new_data_grads_norm = 5.7442
	old_data_grads_norm = 4.3000
	sim_grads_norm = 0.0628
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6052
	data_grads_norm = 4.1186
	new_data_grads_norm = 6.3115
	old_data_grads_norm = 5.3888
	sim_grads_norm = -0.0044
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5617
	data_grads_norm = 3.6912
	new_data_grads_norm = 5.9082
	old_data_grads_norm = 4.5212
	sim_grads_norm = -0.0176
-- Starting training on experience 174 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7650
	data_grads_norm = 3.9459
	new_data_grads_norm = 4.9334
	old_data_grads_norm = 6.2604
	sim_grads_norm = -0.0101
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1905
	data_grads_norm = 3.5638
	new_data_grads_norm = 5.7801
	old_data_grads_norm = 3.6769
	sim_grads_norm = -0.0362
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6417
	data_grads_norm = 4.0441
	new_data_grads_norm = 5.6942
	old_data_grads_norm = 5.5890
	sim_grads_norm = 0.0306
-- Starting training on experience 175 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7854
	data_grads_norm = 4.7607
	new_data_grads_norm = 5.3950
	old_data_grads_norm = 6.1795
	sim_grads_norm = -0.0362
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9416
	data_grads_norm = 4.2293
	new_data_grads_norm = 5.6364
	old_data_grads_norm = 5.3966
	sim_grads_norm = 0.0687
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3126
	data_grads_norm = 3.4849
	new_data_grads_norm = 5.6705
	old_data_grads_norm = 4.4795
	sim_grads_norm = -0.0054
-- Starting training on experience 176 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3568
	data_grads_norm = 2.9974
	new_data_grads_norm = 4.9743
	old_data_grads_norm = 3.5496
	sim_grads_norm = 0.0413
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8838
	data_grads_norm = 2.7122
	new_data_grads_norm = 4.4976
	old_data_grads_norm = 3.6772
	sim_grads_norm = -0.0211
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6470
	data_grads_norm = 3.8840
	new_data_grads_norm = 5.4880
	old_data_grads_norm = 4.8268
	sim_grads_norm = 0.0950
-- Starting training on experience 177 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3156
	data_grads_norm = 3.4587
	new_data_grads_norm = 5.0272
	old_data_grads_norm = 4.7004
	sim_grads_norm = 0.0076
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3966
	data_grads_norm = 4.2011
	new_data_grads_norm = 4.6371
	old_data_grads_norm = 6.5649
	sim_grads_norm = 0.0037
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0539
	data_grads_norm = 3.9415
	new_data_grads_norm = 5.3750
	old_data_grads_norm = 5.5589
	sim_grads_norm = 0.0179
-- Starting training on experience 178 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1923
	data_grads_norm = 3.6456
	new_data_grads_norm = 5.9606
	old_data_grads_norm = 4.1415
	sim_grads_norm = -0.1147
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7276
	data_grads_norm = 4.2568
	new_data_grads_norm = 5.9900
	old_data_grads_norm = 5.1294
	sim_grads_norm = -0.0003
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4278
	data_grads_norm = 4.4590
	new_data_grads_norm = 5.6393
	old_data_grads_norm = 5.8958
	sim_grads_norm = 0.0078
-- Starting training on experience 179 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0807
	data_grads_norm = 3.4024
	new_data_grads_norm = 5.5582
	old_data_grads_norm = 3.8372
	sim_grads_norm = 0.0145
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7527
	data_grads_norm = 2.7721
	new_data_grads_norm = 4.6282
	old_data_grads_norm = 3.9303
	sim_grads_norm = -0.0168
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3511
	data_grads_norm = 3.2963
	new_data_grads_norm = 4.9336
	old_data_grads_norm = 4.3593
	sim_grads_norm = 0.0471
-- Starting training on experience 180 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2739
	data_grads_norm = 3.8014
	new_data_grads_norm = 5.4072
	old_data_grads_norm = 4.8322
	sim_grads_norm = -0.0146
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3172
	data_grads_norm = 3.3946
	new_data_grads_norm = 5.1194
	old_data_grads_norm = 4.1758
	sim_grads_norm = 0.0432
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4514
	data_grads_norm = 3.6261
	new_data_grads_norm = 5.6282
	old_data_grads_norm = 4.4537
	sim_grads_norm = 0.0015
-- Starting training on experience 181 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9855
	data_grads_norm = 3.3644
	new_data_grads_norm = 4.7394
	old_data_grads_norm = 5.6849
	sim_grads_norm = 0.0282
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2709
	data_grads_norm = 3.3062
	new_data_grads_norm = 4.2042
	old_data_grads_norm = 4.3285
	sim_grads_norm = 0.0993
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0647
	data_grads_norm = 3.2701
	new_data_grads_norm = 4.0062
	old_data_grads_norm = 5.4988
	sim_grads_norm = -0.0019
-- Starting training on experience 182 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2763
	data_grads_norm = 3.7737
	new_data_grads_norm = 5.2675
	old_data_grads_norm = 4.5091
	sim_grads_norm = -0.0235
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1455
	data_grads_norm = 3.1803
	new_data_grads_norm = 5.0538
	old_data_grads_norm = 4.4726
	sim_grads_norm = -0.0367
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3719
	data_grads_norm = 3.7320
	new_data_grads_norm = 5.3633
	old_data_grads_norm = 4.9564
	sim_grads_norm = -0.0191
-- Starting training on experience 183 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5221
	data_grads_norm = 3.6701
	new_data_grads_norm = 5.4081
	old_data_grads_norm = 4.8809
	sim_grads_norm = -0.0202
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9327
	data_grads_norm = 3.8606
	new_data_grads_norm = 5.4071
	old_data_grads_norm = 6.0559
	sim_grads_norm = 0.0557
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1057
	data_grads_norm = 3.6948
	new_data_grads_norm = 5.1228
	old_data_grads_norm = 5.7562
	sim_grads_norm = 0.0319
-- Starting training on experience 184 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8596
	data_grads_norm = 3.3302
	new_data_grads_norm = 5.2149
	old_data_grads_norm = 4.9217
	sim_grads_norm = -0.0315
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3640
	data_grads_norm = 3.5166
	new_data_grads_norm = 5.0172
	old_data_grads_norm = 4.5734
	sim_grads_norm = 0.0260
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4736
	data_grads_norm = 3.8309
	new_data_grads_norm = 5.0226
	old_data_grads_norm = 4.7994
	sim_grads_norm = 0.0700
-- Starting training on experience 185 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6343
	data_grads_norm = 4.1058
	new_data_grads_norm = 6.2690
	old_data_grads_norm = 5.0310
	sim_grads_norm = -0.0151
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2150
	data_grads_norm = 3.9329
	new_data_grads_norm = 6.2953
	old_data_grads_norm = 4.6082
	sim_grads_norm = -0.0296
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0237
	data_grads_norm = 3.8763
	new_data_grads_norm = 6.3606
	old_data_grads_norm = 4.4523
	sim_grads_norm = 0.0592
-- Starting training on experience 186 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4479
	data_grads_norm = 4.1015
	new_data_grads_norm = 6.9254
	old_data_grads_norm = 3.6400
	sim_grads_norm = 0.0558
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7209
	data_grads_norm = 4.2829
	new_data_grads_norm = 6.7766
	old_data_grads_norm = 5.1308
	sim_grads_norm = 0.0247
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7157
	data_grads_norm = 4.5950
	new_data_grads_norm = 6.9400
	old_data_grads_norm = 5.4260
	sim_grads_norm = -0.0527
-- Starting training on experience 187 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5278
	data_grads_norm = 3.0592
	new_data_grads_norm = 4.8300
	old_data_grads_norm = 3.7633
	sim_grads_norm = -0.0543
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4734
	data_grads_norm = 2.8358
	new_data_grads_norm = 4.8295
	old_data_grads_norm = 3.9235
	sim_grads_norm = -0.0430
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0561
	data_grads_norm = 3.3157
	new_data_grads_norm = 5.3018
	old_data_grads_norm = 4.2531
	sim_grads_norm = 0.0718
-- Starting training on experience 188 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8959
	data_grads_norm = 3.3689
	new_data_grads_norm = 5.2317
	old_data_grads_norm = 4.2603
	sim_grads_norm = 0.0102
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9250
	data_grads_norm = 3.2528
	new_data_grads_norm = 5.6189
	old_data_grads_norm = 4.3647
	sim_grads_norm = 0.0584
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8385
	data_grads_norm = 3.4998
	new_data_grads_norm = 4.9818
	old_data_grads_norm = 4.3909
	sim_grads_norm = 0.0471
-- Starting training on experience 189 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6481
	data_grads_norm = 3.3461
	new_data_grads_norm = 5.1507
	old_data_grads_norm = 4.0370
	sim_grads_norm = -0.0389
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2209
	data_grads_norm = 4.1086
	new_data_grads_norm = 5.5066
	old_data_grads_norm = 6.1108
	sim_grads_norm = -0.0369
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8388
	data_grads_norm = 3.6961
	new_data_grads_norm = 4.7309
	old_data_grads_norm = 5.1867
	sim_grads_norm = -0.0110
-- Starting training on experience 190 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3007
	data_grads_norm = 3.8780
	new_data_grads_norm = 5.6357
	old_data_grads_norm = 6.2000
	sim_grads_norm = -0.0412
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5147
	data_grads_norm = 3.8896
	new_data_grads_norm = 5.4101
	old_data_grads_norm = 4.8646
	sim_grads_norm = -0.0209
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6094
	data_grads_norm = 3.5207
	new_data_grads_norm = 5.5823
	old_data_grads_norm = 4.5185
	sim_grads_norm = -0.0110
-- Starting training on experience 191 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0735
	data_grads_norm = 3.3675
	new_data_grads_norm = 5.2779
	old_data_grads_norm = 3.8653
	sim_grads_norm = -0.0073
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9600
	data_grads_norm = 3.5768
	new_data_grads_norm = 5.7183
	old_data_grads_norm = 3.7598
	sim_grads_norm = 0.0596
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9033
	data_grads_norm = 3.5238
	new_data_grads_norm = 5.5134
	old_data_grads_norm = 3.6639
	sim_grads_norm = 0.0113
-- Starting training on experience 192 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4159
	data_grads_norm = 3.8922
	new_data_grads_norm = 5.6082
	old_data_grads_norm = 5.3297
	sim_grads_norm = 0.0060
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1838
	data_grads_norm = 3.7095
	new_data_grads_norm = 5.7127
	old_data_grads_norm = 6.0115
	sim_grads_norm = -0.0652
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8867
	data_grads_norm = 3.1911
	new_data_grads_norm = 5.8709
	old_data_grads_norm = 3.6781
	sim_grads_norm = -0.0540
-- Starting training on experience 193 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2026
	data_grads_norm = 4.2148
	new_data_grads_norm = 6.5902
	old_data_grads_norm = 3.9059
	sim_grads_norm = -0.0313
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0936
	data_grads_norm = 4.2336
	new_data_grads_norm = 5.8046
	old_data_grads_norm = 4.7374
	sim_grads_norm = -0.0596
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0891
	data_grads_norm = 5.3507
	new_data_grads_norm = 6.3839
	old_data_grads_norm = 6.7242
	sim_grads_norm = 0.0792
-- Starting training on experience 194 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4742
	data_grads_norm = 4.3249
	new_data_grads_norm = 6.4994
	old_data_grads_norm = 4.6654
	sim_grads_norm = 0.0430
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4050
	data_grads_norm = 3.7152
	new_data_grads_norm = 5.5519
	old_data_grads_norm = 4.6997
	sim_grads_norm = 0.0521
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2099
	data_grads_norm = 3.8265
	new_data_grads_norm = 5.7508
	old_data_grads_norm = 5.1001
	sim_grads_norm = -0.0212
-- Starting training on experience 195 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8068
	data_grads_norm = 2.9040
	new_data_grads_norm = 4.7972
	old_data_grads_norm = 4.3135
	sim_grads_norm = 0.0116
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0862
	data_grads_norm = 3.2014
	new_data_grads_norm = 4.9888
	old_data_grads_norm = 4.1942
	sim_grads_norm = -0.0483
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7335
	data_grads_norm = 2.6478
	new_data_grads_norm = 4.4491
	old_data_grads_norm = 3.5657
	sim_grads_norm = -0.0298
-- Starting training on experience 196 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6859
	data_grads_norm = 3.7885
	new_data_grads_norm = 5.9619
	old_data_grads_norm = 4.2991
	sim_grads_norm = -0.0105
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5605
	data_grads_norm = 3.5545
	new_data_grads_norm = 5.7229
	old_data_grads_norm = 4.6251
	sim_grads_norm = -0.0076
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7936
	data_grads_norm = 4.1672
	new_data_grads_norm = 6.6653
	old_data_grads_norm = 4.6848
	sim_grads_norm = -0.0052
-- Starting training on experience 197 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7549
	data_grads_norm = 3.9164
	new_data_grads_norm = 5.3935
	old_data_grads_norm = 4.8911
	sim_grads_norm = 0.0424
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8170
	data_grads_norm = 4.4457
	new_data_grads_norm = 5.5836
	old_data_grads_norm = 5.8134
	sim_grads_norm = 0.0221
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1390
	data_grads_norm = 3.4351
	new_data_grads_norm = 5.3441
	old_data_grads_norm = 4.2042
	sim_grads_norm = -0.0083
-- Starting training on experience 198 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5739
	data_grads_norm = 3.4859
	new_data_grads_norm = 5.5156
	old_data_grads_norm = 3.5978
	sim_grads_norm = 0.0786
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3952
	data_grads_norm = 3.8203
	new_data_grads_norm = 5.3745
	old_data_grads_norm = 5.9344
	sim_grads_norm = 0.0491
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8819
	data_grads_norm = 3.5212
	new_data_grads_norm = 4.8543
	old_data_grads_norm = 5.4289
	sim_grads_norm = -0.0063
-- Starting training on experience 199 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1271
	data_grads_norm = 3.7672
	new_data_grads_norm = 5.9840
	old_data_grads_norm = 3.9184
	sim_grads_norm = 0.0710
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3104
	data_grads_norm = 3.8267
	new_data_grads_norm = 5.9792
	old_data_grads_norm = 4.5412
	sim_grads_norm = -0.0113
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0992
	data_grads_norm = 3.6489
	new_data_grads_norm = 5.8808
	old_data_grads_norm = 4.9483
	sim_grads_norm = 0.0631
-- Starting training on experience 200 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7189
	data_grads_norm = 3.2902
	new_data_grads_norm = 5.7700
	old_data_grads_norm = 4.8754
	sim_grads_norm = -0.1217
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3213
	data_grads_norm = 3.6592
	new_data_grads_norm = 5.6757
	old_data_grads_norm = 3.8543
	sim_grads_norm = 0.0928
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0042
	data_grads_norm = 3.8029
	new_data_grads_norm = 5.9560
	old_data_grads_norm = 5.3246
	sim_grads_norm = -0.0180
-- Starting training on experience 201 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1221
	data_grads_norm = 4.0467
	new_data_grads_norm = 5.0849
	old_data_grads_norm = 6.5516
	sim_grads_norm = 0.0304
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1958
	data_grads_norm = 3.9466
	new_data_grads_norm = 5.2578
	old_data_grads_norm = 5.4431
	sim_grads_norm = -0.0005
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9176
	data_grads_norm = 3.1471
	new_data_grads_norm = 4.7580
	old_data_grads_norm = 4.1614
	sim_grads_norm = -0.0184
-- Starting training on experience 202 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3321
	data_grads_norm = 4.7177
	new_data_grads_norm = 6.7356
	old_data_grads_norm = 5.9541
	sim_grads_norm = 0.0246
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2002
	data_grads_norm = 4.0623
	new_data_grads_norm = 6.7064
	old_data_grads_norm = 5.9978
	sim_grads_norm = 0.0321
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4689
	data_grads_norm = 4.3208
	new_data_grads_norm = 6.8595
	old_data_grads_norm = 5.3292
	sim_grads_norm = 0.1738
-- Starting training on experience 203 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2686
	data_grads_norm = 3.4951
	new_data_grads_norm = 6.0691
	old_data_grads_norm = 3.8897
	sim_grads_norm = -0.0356
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8135
	data_grads_norm = 3.8135
	new_data_grads_norm = 5.5645
	old_data_grads_norm = 4.7129
	sim_grads_norm = 0.0198
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5037
	data_grads_norm = 3.8848
	new_data_grads_norm = 5.5125
	old_data_grads_norm = 5.3367
	sim_grads_norm = 0.0067
-- Starting training on experience 204 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2552
	data_grads_norm = 3.7634
	new_data_grads_norm = 5.2542
	old_data_grads_norm = 4.8742
	sim_grads_norm = -0.0042
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6879
	data_grads_norm = 4.8568
	new_data_grads_norm = 5.6646
	old_data_grads_norm = 6.0351
	sim_grads_norm = 0.0071
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9113
	data_grads_norm = 4.1823
	new_data_grads_norm = 5.6563
	old_data_grads_norm = 5.9714
	sim_grads_norm = -0.0010
-- Starting training on experience 205 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0848
	data_grads_norm = 3.7898
	new_data_grads_norm = 5.3920
	old_data_grads_norm = 5.4393
	sim_grads_norm = -0.0287
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1970
	data_grads_norm = 3.5174
	new_data_grads_norm = 5.3693
	old_data_grads_norm = 3.6680
	sim_grads_norm = 0.0626
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2402
	data_grads_norm = 4.1305
	new_data_grads_norm = 6.1777
	old_data_grads_norm = 5.3950
	sim_grads_norm = -0.0208
-- Starting training on experience 206 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9831
	data_grads_norm = 4.5037
	new_data_grads_norm = 6.7589
	old_data_grads_norm = 5.6967
	sim_grads_norm = 0.0098
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6709
	data_grads_norm = 3.9258
	new_data_grads_norm = 6.3632
	old_data_grads_norm = 4.7530
	sim_grads_norm = -0.0192
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9349
	data_grads_norm = 4.3181
	new_data_grads_norm = 6.2566
	old_data_grads_norm = 4.1915
	sim_grads_norm = 0.0367
-- Starting training on experience 207 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6255
	data_grads_norm = 3.8593
	new_data_grads_norm = 5.8839
	old_data_grads_norm = 4.4226
	sim_grads_norm = 0.0397
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4225
	data_grads_norm = 3.9248
	new_data_grads_norm = 5.7417
	old_data_grads_norm = 4.9564
	sim_grads_norm = -0.0278
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6905
	data_grads_norm = 3.8815
	new_data_grads_norm = 5.5876
	old_data_grads_norm = 5.0580
	sim_grads_norm = 0.1703
-- Starting training on experience 208 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4877
	data_grads_norm = 4.1794
	new_data_grads_norm = 5.6076
	old_data_grads_norm = 5.7049
	sim_grads_norm = -0.0044
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7205
	data_grads_norm = 3.9366
	new_data_grads_norm = 5.4269
	old_data_grads_norm = 5.1907
	sim_grads_norm = 0.0299
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4950
	data_grads_norm = 3.2603
	new_data_grads_norm = 5.1460
	old_data_grads_norm = 4.1780
	sim_grads_norm = 0.0848
-- Starting training on experience 209 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4380
	data_grads_norm = 2.7600
	new_data_grads_norm = 4.8029
	old_data_grads_norm = 4.1695
	sim_grads_norm = -0.0170
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3277
	data_grads_norm = 3.8152
	new_data_grads_norm = 4.5063
	old_data_grads_norm = 5.4316
	sim_grads_norm = 0.1382
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4222
	data_grads_norm = 2.4678
	new_data_grads_norm = 4.4375
	old_data_grads_norm = 3.4506
	sim_grads_norm = 0.0086
-- Starting training on experience 210 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5020
	data_grads_norm = 4.0305
	new_data_grads_norm = 5.0906
	old_data_grads_norm = 5.6378
	sim_grads_norm = -0.0372
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6919
	data_grads_norm = 4.2167
	new_data_grads_norm = 5.4993
	old_data_grads_norm = 5.4704
	sim_grads_norm = 0.0076
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7403
	data_grads_norm = 3.6598
	new_data_grads_norm = 5.5864
	old_data_grads_norm = 4.7326
	sim_grads_norm = 0.0652
-- Starting training on experience 211 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9471
	data_grads_norm = 3.4607
	new_data_grads_norm = 5.4287
	old_data_grads_norm = 4.5566
	sim_grads_norm = -0.0289
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9526
	data_grads_norm = 4.7372
	new_data_grads_norm = 4.8264
	old_data_grads_norm = 5.7563
	sim_grads_norm = 0.0101
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0882
	data_grads_norm = 3.3745
	new_data_grads_norm = 5.1903
	old_data_grads_norm = 3.5533
	sim_grads_norm = 0.0248
-- Starting training on experience 212 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7535
	data_grads_norm = 3.3968
	new_data_grads_norm = 4.7544
	old_data_grads_norm = 5.0071
	sim_grads_norm = -0.0216
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4009
	data_grads_norm = 3.8819
	new_data_grads_norm = 4.9763
	old_data_grads_norm = 5.9299
	sim_grads_norm = -0.0141
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9814
	data_grads_norm = 3.6987
	new_data_grads_norm = 5.1258
	old_data_grads_norm = 4.9181
	sim_grads_norm = 0.0071
-- Starting training on experience 213 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6032
	data_grads_norm = 4.1243
	new_data_grads_norm = 5.3341
	old_data_grads_norm = 6.4556
	sim_grads_norm = 0.0304
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8154
	data_grads_norm = 3.9325
	new_data_grads_norm = 5.1498
	old_data_grads_norm = 6.1492
	sim_grads_norm = -0.0035
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5758
	data_grads_norm = 3.6735
	new_data_grads_norm = 4.6130
	old_data_grads_norm = 4.8008
	sim_grads_norm = 0.0243
-- Starting training on experience 214 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2138
	data_grads_norm = 4.2439
	new_data_grads_norm = 6.0197
	old_data_grads_norm = 5.9202
	sim_grads_norm = 0.0169
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3918
	data_grads_norm = 3.7304
	new_data_grads_norm = 5.4712
	old_data_grads_norm = 5.6147
	sim_grads_norm = 0.0016
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7303
	data_grads_norm = 4.1837
	new_data_grads_norm = 5.4592
	old_data_grads_norm = 5.8437
	sim_grads_norm = 0.0662
-- Starting training on experience 215 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6262
	data_grads_norm = 3.4463
	new_data_grads_norm = 5.5296
	old_data_grads_norm = 4.8433
	sim_grads_norm = -0.0347
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2497
	data_grads_norm = 4.0472
	new_data_grads_norm = 5.8589
	old_data_grads_norm = 4.8958
	sim_grads_norm = 0.0373
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1949
	data_grads_norm = 3.9471
	new_data_grads_norm = 5.1172
	old_data_grads_norm = 5.9837
	sim_grads_norm = -0.0471
-- Starting training on experience 216 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8560
	data_grads_norm = 4.7343
	new_data_grads_norm = 6.2418
	old_data_grads_norm = 5.4108
	sim_grads_norm = -0.0105
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2257
	data_grads_norm = 3.9839
	new_data_grads_norm = 6.3220
	old_data_grads_norm = 3.7397
	sim_grads_norm = 0.0763
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0047
	data_grads_norm = 3.2986
	new_data_grads_norm = 5.5025
	old_data_grads_norm = 3.6973
	sim_grads_norm = -0.0668
-- Starting training on experience 217 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4993
	data_grads_norm = 4.0053
	new_data_grads_norm = 5.3718
	old_data_grads_norm = 5.6732
	sim_grads_norm = -0.0241
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4756
	data_grads_norm = 3.8758
	new_data_grads_norm = 5.6065
	old_data_grads_norm = 5.6428
	sim_grads_norm = -0.0032
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7780
	data_grads_norm = 4.1974
	new_data_grads_norm = 5.1239
	old_data_grads_norm = 6.8553
	sim_grads_norm = -0.0082
-- Starting training on experience 218 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4542
	data_grads_norm = 3.9809
	new_data_grads_norm = 6.2358
	old_data_grads_norm = 4.6590
	sim_grads_norm = 0.0107
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5419
	data_grads_norm = 4.0023
	new_data_grads_norm = 6.5123
	old_data_grads_norm = 4.7017
	sim_grads_norm = 0.0202
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4604
	data_grads_norm = 4.3852
	new_data_grads_norm = 5.7814
	old_data_grads_norm = 5.1715
	sim_grads_norm = 0.0165
-- Starting training on experience 219 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8052
	data_grads_norm = 4.2586
	new_data_grads_norm = 5.5582
	old_data_grads_norm = 5.6179
	sim_grads_norm = 0.0947
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4974
	data_grads_norm = 3.6151
	new_data_grads_norm = 5.4670
	old_data_grads_norm = 3.8066
	sim_grads_norm = 0.0038
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6095
	data_grads_norm = 4.2794
	new_data_grads_norm = 5.5450
	old_data_grads_norm = 5.5610
	sim_grads_norm = 0.0055
-- Starting training on experience 220 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2989
	data_grads_norm = 3.4825
	new_data_grads_norm = 5.4071
	old_data_grads_norm = 4.4034
	sim_grads_norm = -0.0190
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8625
	data_grads_norm = 4.2728
	new_data_grads_norm = 6.3718
	old_data_grads_norm = 4.7281
	sim_grads_norm = -0.0268
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7992
	data_grads_norm = 3.9540
	new_data_grads_norm = 6.3273
	old_data_grads_norm = 3.3321
	sim_grads_norm = 0.0060
-- Starting training on experience 221 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5529
	data_grads_norm = 3.5065
	new_data_grads_norm = 5.0634
	old_data_grads_norm = 4.0267
	sim_grads_norm = -0.0249
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3577
	data_grads_norm = 3.1212
	new_data_grads_norm = 4.3701
	old_data_grads_norm = 4.0122
	sim_grads_norm = 0.0357
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0932
	data_grads_norm = 4.6911
	new_data_grads_norm = 5.2437
	old_data_grads_norm = 7.2584
	sim_grads_norm = 0.1034
-- Starting training on experience 222 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6238
	data_grads_norm = 3.9254
	new_data_grads_norm = 5.0813
	old_data_grads_norm = 5.4174
	sim_grads_norm = 0.0981
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0521
	data_grads_norm = 3.2505
	new_data_grads_norm = 4.5964
	old_data_grads_norm = 4.3042
	sim_grads_norm = -0.0348
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0189
	data_grads_norm = 3.4360
	new_data_grads_norm = 4.9202
	old_data_grads_norm = 4.2395
	sim_grads_norm = 0.0347
-- Starting training on experience 223 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8054
	data_grads_norm = 3.4712
	new_data_grads_norm = 6.2521
	old_data_grads_norm = 4.8226
	sim_grads_norm = 0.0084
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0656
	data_grads_norm = 3.4920
	new_data_grads_norm = 5.1140
	old_data_grads_norm = 4.7619
	sim_grads_norm = -0.0067
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1025
	data_grads_norm = 3.8807
	new_data_grads_norm = 5.0255
	old_data_grads_norm = 5.0793
	sim_grads_norm = 0.0515
-- Starting training on experience 224 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6813
	data_grads_norm = 3.9894
	new_data_grads_norm = 6.0913
	old_data_grads_norm = 4.7420
	sim_grads_norm = 0.1688
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7518
	data_grads_norm = 3.3436
	new_data_grads_norm = 5.6513
	old_data_grads_norm = 4.6013
	sim_grads_norm = -0.0131
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1109
	data_grads_norm = 3.5382
	new_data_grads_norm = 5.4257
	old_data_grads_norm = 4.8182
	sim_grads_norm = 0.0025
-- Starting training on experience 225 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6821
	data_grads_norm = 4.2756
	new_data_grads_norm = 5.2644
	old_data_grads_norm = 6.0392
	sim_grads_norm = -0.0163
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5773
	data_grads_norm = 3.6016
	new_data_grads_norm = 5.6610
	old_data_grads_norm = 4.2571
	sim_grads_norm = 0.0080
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4753
	data_grads_norm = 3.7366
	new_data_grads_norm = 5.2301
	old_data_grads_norm = 4.7575
	sim_grads_norm = 0.0336
-- Starting training on experience 226 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4614
	data_grads_norm = 4.7177
	new_data_grads_norm = 5.7815
	old_data_grads_norm = 6.2458
	sim_grads_norm = 0.1404
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0046
	data_grads_norm = 3.3337
	new_data_grads_norm = 5.2545
	old_data_grads_norm = 4.7385
	sim_grads_norm = -0.0392
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7018
	data_grads_norm = 3.5848
	new_data_grads_norm = 5.1866
	old_data_grads_norm = 5.2101
	sim_grads_norm = -0.0624
-- Starting training on experience 227 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6033
	data_grads_norm = 4.1408
	new_data_grads_norm = 5.1580
	old_data_grads_norm = 5.1827
	sim_grads_norm = 0.0336
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2569
	data_grads_norm = 3.9838
	new_data_grads_norm = 5.4481
	old_data_grads_norm = 5.3455
	sim_grads_norm = -0.0365
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2627
	data_grads_norm = 4.3037
	new_data_grads_norm = 6.4096
	old_data_grads_norm = 5.3429
	sim_grads_norm = -0.0233
-- Starting training on experience 228 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2551
	data_grads_norm = 3.7205
	new_data_grads_norm = 5.9582
	old_data_grads_norm = 4.5281
	sim_grads_norm = -0.0162
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9233
	data_grads_norm = 3.1359
	new_data_grads_norm = 5.3174
	old_data_grads_norm = 4.0298
	sim_grads_norm = -0.0374
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2148
	data_grads_norm = 3.6112
	new_data_grads_norm = 5.5906
	old_data_grads_norm = 5.0740
	sim_grads_norm = -0.0729
-- Starting training on experience 229 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4748
	data_grads_norm = 3.5154
	new_data_grads_norm = 6.2201
	old_data_grads_norm = 4.1683
	sim_grads_norm = 0.0154
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2534
	data_grads_norm = 3.7524
	new_data_grads_norm = 5.6887
	old_data_grads_norm = 4.6689
	sim_grads_norm = -0.0504
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3785
	data_grads_norm = 4.6927
	new_data_grads_norm = 6.1943
	old_data_grads_norm = 6.5850
	sim_grads_norm = 0.0021
-- Starting training on experience 230 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2197
	data_grads_norm = 3.5783
	new_data_grads_norm = 6.1639
	old_data_grads_norm = 3.2479
	sim_grads_norm = -0.0007
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7818
	data_grads_norm = 4.2026
	new_data_grads_norm = 5.6986
	old_data_grads_norm = 5.6981
	sim_grads_norm = -0.0095
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4992
	data_grads_norm = 4.2746
	new_data_grads_norm = 5.7693
	old_data_grads_norm = 6.4920
	sim_grads_norm = 0.0058
-- Starting training on experience 231 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0194
	data_grads_norm = 4.4125
	new_data_grads_norm = 5.3847
	old_data_grads_norm = 5.6355
	sim_grads_norm = 0.0032
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0031
	data_grads_norm = 4.2854
	new_data_grads_norm = 5.4927
	old_data_grads_norm = 4.6519
	sim_grads_norm = 0.1111
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5446
	data_grads_norm = 4.2960
	new_data_grads_norm = 5.7104
	old_data_grads_norm = 5.6252
	sim_grads_norm = -0.0343
-- Starting training on experience 232 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1626
	data_grads_norm = 3.5635
	new_data_grads_norm = 5.7950
	old_data_grads_norm = 4.7600
	sim_grads_norm = 0.0781
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3995
	data_grads_norm = 4.0987
	new_data_grads_norm = 5.8184
	old_data_grads_norm = 5.2224
	sim_grads_norm = 0.0967
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1623
	data_grads_norm = 3.8119
	new_data_grads_norm = 5.4482
	old_data_grads_norm = 5.7311
	sim_grads_norm = -0.0060
-- Starting training on experience 233 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0422
	data_grads_norm = 3.3483
	new_data_grads_norm = 5.5948
	old_data_grads_norm = 4.0662
	sim_grads_norm = 0.0114
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2954
	data_grads_norm = 3.6902
	new_data_grads_norm = 5.5350
	old_data_grads_norm = 3.1313
	sim_grads_norm = 0.0888
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8505
	data_grads_norm = 4.4875
	new_data_grads_norm = 5.8688
	old_data_grads_norm = 6.4860
	sim_grads_norm = 0.0447
-- Starting training on experience 234 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1392
	data_grads_norm = 4.0869
	new_data_grads_norm = 6.3089
	old_data_grads_norm = 5.3996
	sim_grads_norm = -0.0163
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5455
	data_grads_norm = 4.7442
	new_data_grads_norm = 6.1839
	old_data_grads_norm = 5.1067
	sim_grads_norm = -0.0298
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8898
	data_grads_norm = 3.2600
	new_data_grads_norm = 6.0708
	old_data_grads_norm = 3.5195
	sim_grads_norm = -0.0438
-- Starting training on experience 235 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3527
	data_grads_norm = 4.5245
	new_data_grads_norm = 5.6985
	old_data_grads_norm = 6.0168
	sim_grads_norm = 0.0235
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8175
	data_grads_norm = 3.4183
	new_data_grads_norm = 5.6295
	old_data_grads_norm = 3.8569
	sim_grads_norm = -0.0122
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2227
	data_grads_norm = 3.9070
	new_data_grads_norm = 5.4230
	old_data_grads_norm = 5.4993
	sim_grads_norm = -0.0193
-- Starting training on experience 236 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0336
	data_grads_norm = 3.3376
	new_data_grads_norm = 5.3581
	old_data_grads_norm = 4.6683
	sim_grads_norm = -0.0760
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1975
	data_grads_norm = 3.7549
	new_data_grads_norm = 5.3413
	old_data_grads_norm = 4.1719
	sim_grads_norm = 0.1800
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6855
	data_grads_norm = 3.1688
	new_data_grads_norm = 5.7290
	old_data_grads_norm = 3.4893
	sim_grads_norm = -0.0252
-- Starting training on experience 237 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
-- >> End of training phase << --
-- >> Start of eval phase << --
-- Starting eval on experience 0 (Task 0) from test stream --
> Eval on experience 0 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp000 = 2.7660
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.3320
	mb_index = 2618
	time = 611.9333
-- Starting eval on experience 1 (Task 0) from test stream --
> Eval on experience 1 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp001 = 2.5006
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.4240
-- Starting eval on experience 2 (Task 0) from test stream --
> Eval on experience 2 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp002 = 2.7834
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.3740
-- Starting eval on experience 3 (Task 0) from test stream --
> Eval on experience 3 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp003 = 2.2969
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.4940
-- Starting eval on experience 4 (Task 0) from test stream --
> Eval on experience 4 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp004 = 3.3876
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.2620
-- Starting eval on experience 5 (Task 0) from test stream --
> Eval on experience 5 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp005 = 2.7415
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.3960
-- Starting eval on experience 6 (Task 0) from test stream --
> Eval on experience 6 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp006 = 2.6218
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp006 = 0.3800
-- Starting eval on experience 7 (Task 0) from test stream --
> Eval on experience 7 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp007 = 2.9284
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp007 = 0.3740
-- Starting eval on experience 8 (Task 0) from test stream --
> Eval on experience 8 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp008 = 3.1451
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp008 = 0.2420
-- Starting eval on experience 9 (Task 0) from test stream --
> Eval on experience 9 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp009 = 2.7625
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp009 = 0.3120
-- Starting eval on experience 10 (Task 0) from test stream --
> Eval on experience 10 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp010 = 3.7307
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp010 = 0.0480
-- >> End of eval phase << --
	CumulativeAccuracy/eval_phase/test_stream/Exp000 = 0.7360
	CumulativeAccuracy/eval_phase/test_stream/Exp001 = 0.6910
	CumulativeAccuracy/eval_phase/test_stream/Exp002 = 0.5860
	CumulativeAccuracy/eval_phase/test_stream/Exp003 = 0.5620
	CumulativeAccuracy/eval_phase/test_stream/Exp004 = 0.5040
	CumulativeAccuracy/eval_phase/test_stream/Exp005 = 0.4620
	CumulativeAccuracy/eval_phase/test_stream/Exp006 = 0.4243
	CumulativeAccuracy/eval_phase/test_stream/Exp007 = 0.4015
	CumulativeAccuracy/eval_phase/test_stream/Exp008 = 0.3733
	CumulativeAccuracy/eval_phase/test_stream/Exp009 = 0.3610
	CumulativeAccuracy/eval_phase/test_stream/Exp010 = 0.3307
	Loss_Stream/eval_phase/test_stream/Task000 = 2.8786
	Top1_Acc_Stream/eval_phase/test_stream/Task000 = 0.3307
-- >> Start of training phase << --
-- Starting training on experience 0 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9161
	data_grads_norm = 3.6814
	new_data_grads_norm = 5.9737
	old_data_grads_norm = 3.6522
	sim_grads_norm = -0.0133
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9679
	data_grads_norm = 3.8629
	new_data_grads_norm = 5.9548
	old_data_grads_norm = 4.4281
	sim_grads_norm = 0.0218
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5384
	data_grads_norm = 4.4321
	new_data_grads_norm = 5.6590
	old_data_grads_norm = 5.9653
	sim_grads_norm = 0.0078
-- Starting training on experience 1 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2741
	data_grads_norm = 4.0259
	new_data_grads_norm = 5.3087
	old_data_grads_norm = 5.6277
	sim_grads_norm = 0.0278
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0687
	data_grads_norm = 4.1356
	new_data_grads_norm = 5.2598
	old_data_grads_norm = 5.4112
	sim_grads_norm = -0.0065
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1723
	data_grads_norm = 3.7190
	new_data_grads_norm = 5.6075
	old_data_grads_norm = 4.0545
	sim_grads_norm = -0.0192
-- Starting training on experience 2 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8618
	data_grads_norm = 4.0851
	new_data_grads_norm = 6.0647
	old_data_grads_norm = 3.8654
	sim_grads_norm = -0.0209
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1491
	data_grads_norm = 3.9376
	new_data_grads_norm = 5.9607
	old_data_grads_norm = 3.9573
	sim_grads_norm = -0.0323
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1461
	data_grads_norm = 3.7263
	new_data_grads_norm = 6.0645
	old_data_grads_norm = 3.0196
	sim_grads_norm = 0.0535
-- Starting training on experience 3 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0697
	data_grads_norm = 3.8803
	new_data_grads_norm = 5.7389
	old_data_grads_norm = 4.0837
	sim_grads_norm = -0.0212
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4475
	data_grads_norm = 4.7182
	new_data_grads_norm = 6.1601
	old_data_grads_norm = 5.3117
	sim_grads_norm = 0.0110
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5542
	data_grads_norm = 4.5276
	new_data_grads_norm = 6.3795
	old_data_grads_norm = 4.9659
	sim_grads_norm = -0.0339
-- Starting training on experience 4 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0190
	data_grads_norm = 4.9840
	new_data_grads_norm = 5.6152
	old_data_grads_norm = 5.5531
	sim_grads_norm = -0.0173
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8798
	data_grads_norm = 4.3437
	new_data_grads_norm = 5.8258
	old_data_grads_norm = 5.2209
	sim_grads_norm = 0.0336
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0043
	data_grads_norm = 4.4683
	new_data_grads_norm = 5.6514
	old_data_grads_norm = 5.6026
	sim_grads_norm = 0.0018
-- Starting training on experience 5 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.9477
	data_grads_norm = 4.9629
	new_data_grads_norm = 5.9153
	old_data_grads_norm = 6.2899
	sim_grads_norm = 0.0718
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2878
	data_grads_norm = 4.3243
	new_data_grads_norm = 6.0540
	old_data_grads_norm = 4.7781
	sim_grads_norm = 0.0146
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7301
	data_grads_norm = 4.0407
	new_data_grads_norm = 5.8193
	old_data_grads_norm = 5.5519
	sim_grads_norm = 0.0058
-- Starting training on experience 6 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3381
	data_grads_norm = 4.1566
	new_data_grads_norm = 6.5240
	old_data_grads_norm = 4.6544
	sim_grads_norm = 0.0089
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5108
	data_grads_norm = 4.1630
	new_data_grads_norm = 6.3532
	old_data_grads_norm = 5.5309
	sim_grads_norm = 0.0090
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5466
	data_grads_norm = 4.3736
	new_data_grads_norm = 6.2239
	old_data_grads_norm = 6.3302
	sim_grads_norm = 0.0913
-- Starting training on experience 7 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4016
	data_grads_norm = 3.9016
	new_data_grads_norm = 6.1773
	old_data_grads_norm = 5.2321
	sim_grads_norm = 0.0608
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8619
	data_grads_norm = 4.0839
	new_data_grads_norm = 6.5804
	old_data_grads_norm = 4.3782
	sim_grads_norm = 0.0007
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6270
	data_grads_norm = 3.7366
	new_data_grads_norm = 6.6060
	old_data_grads_norm = 3.3748
	sim_grads_norm = 0.0090
-- Starting training on experience 8 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1697
	data_grads_norm = 2.9609
	new_data_grads_norm = 5.1762
	old_data_grads_norm = 3.7714
	sim_grads_norm = -0.0094
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8640
	data_grads_norm = 4.0369
	new_data_grads_norm = 5.5617
	old_data_grads_norm = 5.3555
	sim_grads_norm = 0.0268
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2542
	data_grads_norm = 4.2668
	new_data_grads_norm = 5.4634
	old_data_grads_norm = 4.7027
	sim_grads_norm = 0.0557
-- Starting training on experience 9 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2154
	data_grads_norm = 3.8936
	new_data_grads_norm = 5.7896
	old_data_grads_norm = 4.3750
	sim_grads_norm = -0.0150
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0718
	data_grads_norm = 3.9301
	new_data_grads_norm = 5.7465
	old_data_grads_norm = 4.9234
	sim_grads_norm = -0.0043
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9653
	data_grads_norm = 3.8692
	new_data_grads_norm = 5.6818
	old_data_grads_norm = 4.9657
	sim_grads_norm = 0.0171
-- Starting training on experience 10 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4473
	data_grads_norm = 3.5326
	new_data_grads_norm = 5.6357
	old_data_grads_norm = 3.4945
	sim_grads_norm = 0.0272
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4854
	data_grads_norm = 3.7672
	new_data_grads_norm = 5.5875
	old_data_grads_norm = 3.9746
	sim_grads_norm = 0.0110
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7825
	data_grads_norm = 4.3063
	new_data_grads_norm = 5.6908
	old_data_grads_norm = 4.6481
	sim_grads_norm = -0.0014
-- Starting training on experience 11 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3908
	data_grads_norm = 3.8831
	new_data_grads_norm = 5.6455
	old_data_grads_norm = 4.8947
	sim_grads_norm = 0.0511
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9872
	data_grads_norm = 4.6441
	new_data_grads_norm = 5.9509
	old_data_grads_norm = 6.4051
	sim_grads_norm = 0.0065
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4590
	data_grads_norm = 4.4541
	new_data_grads_norm = 5.5489
	old_data_grads_norm = 6.6686
	sim_grads_norm = 0.0114
-- Starting training on experience 12 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1652
	data_grads_norm = 3.9611
	new_data_grads_norm = 5.8469
	old_data_grads_norm = 4.6867
	sim_grads_norm = -0.0347
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1782
	data_grads_norm = 4.2045
	new_data_grads_norm = 5.3550
	old_data_grads_norm = 5.4897
	sim_grads_norm = 0.0132
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6466
	data_grads_norm = 4.1152
	new_data_grads_norm = 5.9319
	old_data_grads_norm = 5.2902
	sim_grads_norm = 0.0128
-- Starting training on experience 13 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7961
	data_grads_norm = 4.0366
	new_data_grads_norm = 5.5565
	old_data_grads_norm = 5.9212
	sim_grads_norm = 0.0293
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6097
	data_grads_norm = 4.1253
	new_data_grads_norm = 5.9078
	old_data_grads_norm = 4.8454
	sim_grads_norm = -0.0093
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9635
	data_grads_norm = 4.0893
	new_data_grads_norm = 5.8159
	old_data_grads_norm = 5.5276
	sim_grads_norm = 0.1190
-- Starting training on experience 14 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8027
	data_grads_norm = 3.9844
	new_data_grads_norm = 5.5044
	old_data_grads_norm = 4.8929
	sim_grads_norm = -0.0313
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2887
	data_grads_norm = 3.9676
	new_data_grads_norm = 5.7716
	old_data_grads_norm = 4.5096
	sim_grads_norm = 0.0682
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3569
	data_grads_norm = 4.1190
	new_data_grads_norm = 5.6206
	old_data_grads_norm = 5.5000
	sim_grads_norm = -0.0010
-- Starting training on experience 15 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3030
	data_grads_norm = 4.7043
	new_data_grads_norm = 5.6430
	old_data_grads_norm = 6.4727
	sim_grads_norm = 0.0312
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8469
	data_grads_norm = 4.0539
	new_data_grads_norm = 6.0315
	old_data_grads_norm = 5.4417
	sim_grads_norm = 0.0902
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9968
	data_grads_norm = 4.0309
	new_data_grads_norm = 5.9318
	old_data_grads_norm = 5.0476
	sim_grads_norm = -0.0155
-- Starting training on experience 16 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4307
	data_grads_norm = 3.6070
	new_data_grads_norm = 5.5330
	old_data_grads_norm = 4.0380
	sim_grads_norm = -0.0038
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4030
	data_grads_norm = 3.8487
	new_data_grads_norm = 6.1195
	old_data_grads_norm = 3.9704
	sim_grads_norm = 0.0054
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4943
	data_grads_norm = 3.7975
	new_data_grads_norm = 5.6425
	old_data_grads_norm = 3.6908
	sim_grads_norm = 0.0371
-- Starting training on experience 17 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0129
	data_grads_norm = 4.1616
	new_data_grads_norm = 5.2986
	old_data_grads_norm = 5.2749
	sim_grads_norm = -0.0309
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6418
	data_grads_norm = 3.7449
	new_data_grads_norm = 5.4533
	old_data_grads_norm = 3.9950
	sim_grads_norm = 0.0039
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0144
	data_grads_norm = 4.0061
	new_data_grads_norm = 5.2941
	old_data_grads_norm = 4.3881
	sim_grads_norm = 0.1617
-- Starting training on experience 18 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7450
	data_grads_norm = 4.0010
	new_data_grads_norm = 5.0291
	old_data_grads_norm = 4.7137
	sim_grads_norm = 0.0735
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3019
	data_grads_norm = 3.6114
	new_data_grads_norm = 5.4209
	old_data_grads_norm = 5.5798
	sim_grads_norm = 0.0516
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3369
	data_grads_norm = 3.6535
	new_data_grads_norm = 4.9807
	old_data_grads_norm = 4.7756
	sim_grads_norm = -0.0040
-- Starting training on experience 19 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4014
	data_grads_norm = 4.2073
	new_data_grads_norm = 5.3965
	old_data_grads_norm = 4.9596
	sim_grads_norm = -0.0074
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5394
	data_grads_norm = 4.1525
	new_data_grads_norm = 5.1973
	old_data_grads_norm = 4.5183
	sim_grads_norm = 0.0130
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4164
	data_grads_norm = 4.1266
	new_data_grads_norm = 5.3598
	old_data_grads_norm = 5.8036
	sim_grads_norm = 0.0138
-- Starting training on experience 20 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6375
	data_grads_norm = 4.3413
	new_data_grads_norm = 5.7895
	old_data_grads_norm = 4.2260
	sim_grads_norm = 0.0052
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3248
	data_grads_norm = 4.2824
	new_data_grads_norm = 6.0080
	old_data_grads_norm = 5.8691
	sim_grads_norm = -0.0276
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4855
	data_grads_norm = 4.5634
	new_data_grads_norm = 5.7767
	old_data_grads_norm = 5.6407
	sim_grads_norm = 0.0315
-- Starting training on experience 21 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4089
	data_grads_norm = 3.8156
	new_data_grads_norm = 5.8473
	old_data_grads_norm = 4.5284
	sim_grads_norm = -0.0166
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4259
	data_grads_norm = 3.9476
	new_data_grads_norm = 5.5162
	old_data_grads_norm = 4.4548
	sim_grads_norm = 0.0251
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7384
	data_grads_norm = 4.0667
	new_data_grads_norm = 5.1960
	old_data_grads_norm = 5.3002
	sim_grads_norm = 0.1051
-- Starting training on experience 22 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1151
	data_grads_norm = 3.9757
	new_data_grads_norm = 6.3211
	old_data_grads_norm = 4.8048
	sim_grads_norm = -0.0239
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5417
	data_grads_norm = 4.4062
	new_data_grads_norm = 6.3905
	old_data_grads_norm = 5.7209
	sim_grads_norm = 0.0232
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6876
	data_grads_norm = 4.2524
	new_data_grads_norm = 5.4458
	old_data_grads_norm = 6.1813
	sim_grads_norm = 0.0061
-- Starting training on experience 23 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3443
	data_grads_norm = 3.8421
	new_data_grads_norm = 5.1050
	old_data_grads_norm = 5.7949
	sim_grads_norm = -0.0524
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7757
	data_grads_norm = 3.3622
	new_data_grads_norm = 5.8790
	old_data_grads_norm = 3.8866
	sim_grads_norm = -0.0024
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8940
	data_grads_norm = 3.1166
	new_data_grads_norm = 5.6396
	old_data_grads_norm = 3.7163
	sim_grads_norm = -0.0526
-- Starting training on experience 24 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6520
	data_grads_norm = 3.5352
	new_data_grads_norm = 4.7626
	old_data_grads_norm = 4.2219
	sim_grads_norm = -0.0346
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9970
	data_grads_norm = 3.7017
	new_data_grads_norm = 5.5642
	old_data_grads_norm = 3.9767
	sim_grads_norm = 0.0088
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0571
	data_grads_norm = 3.3750
	new_data_grads_norm = 4.8677
	old_data_grads_norm = 4.0660
	sim_grads_norm = 0.0115
-- Starting training on experience 25 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9818
	data_grads_norm = 3.8979
	new_data_grads_norm = 5.2577
	old_data_grads_norm = 2.6317
	sim_grads_norm = -0.0352
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6258
	data_grads_norm = 4.1691
	new_data_grads_norm = 6.0220
	old_data_grads_norm = 4.3807
	sim_grads_norm = 0.0001
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3148
	data_grads_norm = 3.9961
	new_data_grads_norm = 5.6228
	old_data_grads_norm = 3.9001
	sim_grads_norm = -0.0009
-- Starting training on experience 26 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7983
	data_grads_norm = 3.5457
	new_data_grads_norm = 5.2154
	old_data_grads_norm = 5.2575
	sim_grads_norm = 0.0169
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7610
	data_grads_norm = 3.3331
	new_data_grads_norm = 5.3018
	old_data_grads_norm = 4.6116
	sim_grads_norm = -0.0155
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4163
	data_grads_norm = 3.3914
	new_data_grads_norm = 5.3472
	old_data_grads_norm = 4.1258
	sim_grads_norm = 0.0305
-- Starting training on experience 27 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7815
	data_grads_norm = 3.7055
	new_data_grads_norm = 5.2510
	old_data_grads_norm = 4.4947
	sim_grads_norm = 0.0831
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7422
	data_grads_norm = 2.8469
	new_data_grads_norm = 4.4195
	old_data_grads_norm = 3.4119
	sim_grads_norm = -0.0116
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7256
	data_grads_norm = 4.5744
	new_data_grads_norm = 5.0399
	old_data_grads_norm = 6.8402
	sim_grads_norm = 0.0067
-- Starting training on experience 28 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3614
	data_grads_norm = 3.9711
	new_data_grads_norm = 5.4496
	old_data_grads_norm = 4.7855
	sim_grads_norm = -0.0176
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0868
	data_grads_norm = 3.9603
	new_data_grads_norm = 5.4393
	old_data_grads_norm = 4.2821
	sim_grads_norm = 0.0791
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3917
	data_grads_norm = 3.9853
	new_data_grads_norm = 4.7408
	old_data_grads_norm = 4.1708
	sim_grads_norm = 0.0001
-- Starting training on experience 29 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7910
	data_grads_norm = 3.2615
	new_data_grads_norm = 5.6299
	old_data_grads_norm = 3.1253
	sim_grads_norm = -0.0205
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3718
	data_grads_norm = 4.0169
	new_data_grads_norm = 5.4225
	old_data_grads_norm = 5.1892
	sim_grads_norm = -0.0283
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5964
	data_grads_norm = 4.0402
	new_data_grads_norm = 5.5208
	old_data_grads_norm = 5.0527
	sim_grads_norm = 0.0856
-- Starting training on experience 30 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8029
	data_grads_norm = 3.4392
	new_data_grads_norm = 5.4728
	old_data_grads_norm = 3.6684
	sim_grads_norm = 0.1211
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5987
	data_grads_norm = 3.5582
	new_data_grads_norm = 5.1713
	old_data_grads_norm = 4.8950
	sim_grads_norm = 0.0103
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0937
	data_grads_norm = 4.3786
	new_data_grads_norm = 5.6384
	old_data_grads_norm = 6.3753
	sim_grads_norm = 0.0257
-- Starting training on experience 31 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1413
	data_grads_norm = 4.2598
	new_data_grads_norm = 4.9612
	old_data_grads_norm = 5.5141
	sim_grads_norm = 0.0573
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7336
	data_grads_norm = 4.0472
	new_data_grads_norm = 4.3690
	old_data_grads_norm = 5.6818
	sim_grads_norm = -0.0241
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3505
	data_grads_norm = 3.6242
	new_data_grads_norm = 5.0508
	old_data_grads_norm = 4.4807
	sim_grads_norm = -0.0403
-- Starting training on experience 32 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0586
	data_grads_norm = 4.0604
	new_data_grads_norm = 5.0430
	old_data_grads_norm = 5.3520
	sim_grads_norm = 0.0028
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7774
	data_grads_norm = 3.4102
	new_data_grads_norm = 5.3104
	old_data_grads_norm = 3.8495
	sim_grads_norm = 0.0299
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8362
	data_grads_norm = 4.0015
	new_data_grads_norm = 5.1314
	old_data_grads_norm = 4.8252
	sim_grads_norm = 0.0238
-- Starting training on experience 33 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4036
	data_grads_norm = 3.3998
	new_data_grads_norm = 4.8584
	old_data_grads_norm = 4.5085
	sim_grads_norm = 0.0875
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6989
	data_grads_norm = 3.4631
	new_data_grads_norm = 4.8544
	old_data_grads_norm = 3.9460
	sim_grads_norm = -0.0365
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3059
	data_grads_norm = 2.9989
	new_data_grads_norm = 4.7771
	old_data_grads_norm = 3.4264
	sim_grads_norm = -0.0447
-- Starting training on experience 34 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4587
	data_grads_norm = 3.9600
	new_data_grads_norm = 4.7257
	old_data_grads_norm = 5.4371
	sim_grads_norm = 0.0197
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0109
	data_grads_norm = 3.7578
	new_data_grads_norm = 4.3107
	old_data_grads_norm = 5.6849
	sim_grads_norm = -0.0102
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0043
	data_grads_norm = 3.6464
	new_data_grads_norm = 4.4797
	old_data_grads_norm = 4.8295
	sim_grads_norm = 0.0099
-- Starting training on experience 35 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8634
	data_grads_norm = 3.6504
	new_data_grads_norm = 4.7244
	old_data_grads_norm = 4.2460
	sim_grads_norm = -0.0227
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4990
	data_grads_norm = 3.1368
	new_data_grads_norm = 4.7487
	old_data_grads_norm = 4.7174
	sim_grads_norm = 0.0139
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9300
	data_grads_norm = 3.7495
	new_data_grads_norm = 4.8879
	old_data_grads_norm = 5.2760
	sim_grads_norm = 0.0245
-- Starting training on experience 36 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7552
	data_grads_norm = 4.7002
	new_data_grads_norm = 5.4091
	old_data_grads_norm = 6.5367
	sim_grads_norm = 0.0766
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7595
	data_grads_norm = 3.8651
	new_data_grads_norm = 5.2930
	old_data_grads_norm = 5.1571
	sim_grads_norm = 0.0059
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2067
	data_grads_norm = 4.0746
	new_data_grads_norm = 4.8827
	old_data_grads_norm = 5.6393
	sim_grads_norm = 0.0071
-- Starting training on experience 37 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6927
	data_grads_norm = 3.2931
	new_data_grads_norm = 4.0970
	old_data_grads_norm = 4.1094
	sim_grads_norm = 0.0804
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7315
	data_grads_norm = 3.8387
	new_data_grads_norm = 4.3501
	old_data_grads_norm = 4.5500
	sim_grads_norm = 0.0084
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3377
	data_grads_norm = 2.9511
	new_data_grads_norm = 4.1482
	old_data_grads_norm = 3.9112
	sim_grads_norm = 0.0070
-- Starting training on experience 38 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1527
	data_grads_norm = 3.4326
	new_data_grads_norm = 4.4284
	old_data_grads_norm = 4.3999
	sim_grads_norm = 0.0234
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5150
	data_grads_norm = 3.3233
	new_data_grads_norm = 4.6461
	old_data_grads_norm = 4.4502
	sim_grads_norm = 0.0018
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4463
	data_grads_norm = 3.2229
	new_data_grads_norm = 4.2935
	old_data_grads_norm = 4.6347
	sim_grads_norm = 0.0142
-- Starting training on experience 39 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7466
	data_grads_norm = 3.9429
	new_data_grads_norm = 4.3931
	old_data_grads_norm = 6.4971
	sim_grads_norm = -0.0450
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8616
	data_grads_norm = 4.1732
	new_data_grads_norm = 4.6362
	old_data_grads_norm = 5.3054
	sim_grads_norm = -0.0055
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3067
	data_grads_norm = 2.9216
	new_data_grads_norm = 4.4730
	old_data_grads_norm = 4.4126
	sim_grads_norm = -0.0434
-- Starting training on experience 40 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1219
	data_grads_norm = 3.8799
	new_data_grads_norm = 5.4283
	old_data_grads_norm = 4.9423
	sim_grads_norm = 0.0038
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2983
	data_grads_norm = 3.8423
	new_data_grads_norm = 5.3942
	old_data_grads_norm = 3.6379
	sim_grads_norm = 0.0712
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1129
	data_grads_norm = 3.4026
	new_data_grads_norm = 5.4094
	old_data_grads_norm = 4.9900
	sim_grads_norm = 0.0042
-- Starting training on experience 41 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1093
	data_grads_norm = 3.4210
	new_data_grads_norm = 4.9863
	old_data_grads_norm = 4.3794
	sim_grads_norm = 0.1019
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8306
	data_grads_norm = 3.1551
	new_data_grads_norm = 4.9955
	old_data_grads_norm = 3.4420
	sim_grads_norm = 0.0848
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1731
	data_grads_norm = 3.7002
	new_data_grads_norm = 4.5060
	old_data_grads_norm = 5.0089
	sim_grads_norm = 0.0248
-- Starting training on experience 42 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9016
	data_grads_norm = 4.2479
	new_data_grads_norm = 4.4843
	old_data_grads_norm = 5.2614
	sim_grads_norm = 0.0485
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8555
	data_grads_norm = 3.9713
	new_data_grads_norm = 4.3758
	old_data_grads_norm = 5.3665
	sim_grads_norm = 0.0473
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4176
	data_grads_norm = 3.1161
	new_data_grads_norm = 4.2815
	old_data_grads_norm = 3.8971
	sim_grads_norm = 0.0716
-- Starting training on experience 43 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6983
	data_grads_norm = 3.9001
	new_data_grads_norm = 5.5224
	old_data_grads_norm = 5.1984
	sim_grads_norm = 0.0052
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6643
	data_grads_norm = 3.6643
	new_data_grads_norm = 5.6541
	old_data_grads_norm = 4.2787
	sim_grads_norm = 0.0789
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5826
	data_grads_norm = 3.7054
	new_data_grads_norm = 4.8876
	old_data_grads_norm = 4.7856
	sim_grads_norm = -0.0113
-- Starting training on experience 44 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3457
	data_grads_norm = 3.3797
	new_data_grads_norm = 4.7344
	old_data_grads_norm = 4.8310
	sim_grads_norm = 0.0020
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2712
	data_grads_norm = 3.3089
	new_data_grads_norm = 4.2736
	old_data_grads_norm = 5.2366
	sim_grads_norm = 0.0024
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7401
	data_grads_norm = 3.5351
	new_data_grads_norm = 4.4312
	old_data_grads_norm = 6.1124
	sim_grads_norm = 0.0411
-- Starting training on experience 45 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7484
	data_grads_norm = 3.2403
	new_data_grads_norm = 4.7249
	old_data_grads_norm = 4.3977
	sim_grads_norm = 0.0111
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6012
	data_grads_norm = 3.5170
	new_data_grads_norm = 5.2527
	old_data_grads_norm = 4.3043
	sim_grads_norm = -0.0000
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2100
	data_grads_norm = 4.2721
	new_data_grads_norm = 4.5162
	old_data_grads_norm = 6.2455
	sim_grads_norm = -0.0021
-- Starting training on experience 46 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2506
	data_grads_norm = 3.8210
	new_data_grads_norm = 4.7713
	old_data_grads_norm = 5.5699
	sim_grads_norm = 0.0365
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7321
	data_grads_norm = 3.9890
	new_data_grads_norm = 5.2892
	old_data_grads_norm = 6.3130
	sim_grads_norm = 0.0056
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0457
	data_grads_norm = 3.0848
	new_data_grads_norm = 4.7373
	old_data_grads_norm = 3.8465
	sim_grads_norm = -0.0327
-- Starting training on experience 47 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1356
	data_grads_norm = 3.5438
	new_data_grads_norm = 5.3743
	old_data_grads_norm = 5.2709
	sim_grads_norm = -0.0619
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6087
	data_grads_norm = 3.6093
	new_data_grads_norm = 5.6543
	old_data_grads_norm = 3.3719
	sim_grads_norm = 0.0883
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4712
	data_grads_norm = 3.5810
	new_data_grads_norm = 6.1222
	old_data_grads_norm = 4.2783
	sim_grads_norm = -0.0250
-- Starting training on experience 48 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5470
	data_grads_norm = 3.8772
	new_data_grads_norm = 5.3790
	old_data_grads_norm = 4.4418
	sim_grads_norm = -0.0267
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3879
	data_grads_norm = 3.5772
	new_data_grads_norm = 5.1803
	old_data_grads_norm = 4.1325
	sim_grads_norm = 0.0850
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2123
	data_grads_norm = 3.2068
	new_data_grads_norm = 5.3770
	old_data_grads_norm = 3.0236
	sim_grads_norm = -0.0145
-- Starting training on experience 49 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7556
	data_grads_norm = 3.9029
	new_data_grads_norm = 4.1863
	old_data_grads_norm = 5.7537
	sim_grads_norm = -0.0139
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7089
	data_grads_norm = 4.0793
	new_data_grads_norm = 4.5589
	old_data_grads_norm = 5.7105
	sim_grads_norm = -0.0280
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1131
	data_grads_norm = 3.8605
	new_data_grads_norm = 4.6873
	old_data_grads_norm = 5.2787
	sim_grads_norm = 0.1141
-- Starting training on experience 50 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3977
	data_grads_norm = 3.2195
	new_data_grads_norm = 4.6328
	old_data_grads_norm = 5.1223
	sim_grads_norm = -0.0061
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7878
	data_grads_norm = 3.8025
	new_data_grads_norm = 4.8950
	old_data_grads_norm = 4.9290
	sim_grads_norm = 0.0250
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1695
	data_grads_norm = 3.1505
	new_data_grads_norm = 4.7128
	old_data_grads_norm = 4.0571
	sim_grads_norm = 0.0089
-- Starting training on experience 51 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2503
	data_grads_norm = 3.8284
	new_data_grads_norm = 5.1237
	old_data_grads_norm = 5.7824
	sim_grads_norm = -0.0308
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0661
	data_grads_norm = 3.5129
	new_data_grads_norm = 4.4832
	old_data_grads_norm = 4.7922
	sim_grads_norm = 0.0011
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1809
	data_grads_norm = 3.5643
	new_data_grads_norm = 4.9220
	old_data_grads_norm = 4.4776
	sim_grads_norm = 0.0757
-- Starting training on experience 52 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1260
	data_grads_norm = 3.5743
	new_data_grads_norm = 5.3527
	old_data_grads_norm = 4.3072
	sim_grads_norm = 0.0221
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2238
	data_grads_norm = 3.4255
	new_data_grads_norm = 4.9198
	old_data_grads_norm = 4.2976
	sim_grads_norm = -0.0228
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3153
	data_grads_norm = 3.7561
	new_data_grads_norm = 5.2481
	old_data_grads_norm = 5.2136
	sim_grads_norm = -0.0551
-- Starting training on experience 53 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1868
	data_grads_norm = 2.8753
	new_data_grads_norm = 4.7696
	old_data_grads_norm = 3.8206
	sim_grads_norm = -0.0345
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8088
	data_grads_norm = 3.8673
	new_data_grads_norm = 4.5939
	old_data_grads_norm = 4.5526
	sim_grads_norm = 0.1341
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2466
	data_grads_norm = 3.1638
	new_data_grads_norm = 4.3162
	old_data_grads_norm = 5.6148
	sim_grads_norm = 0.0144
-- Starting training on experience 54 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0395
	data_grads_norm = 4.0299
	new_data_grads_norm = 4.6898
	old_data_grads_norm = 5.7184
	sim_grads_norm = 0.0503
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2874
	data_grads_norm = 3.0559
	new_data_grads_norm = 4.9617
	old_data_grads_norm = 4.0808
	sim_grads_norm = -0.0148
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4614
	data_grads_norm = 3.7546
	new_data_grads_norm = 5.5309
	old_data_grads_norm = 4.9527
	sim_grads_norm = -0.0115
-- Starting training on experience 55 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9211
	data_grads_norm = 3.3352
	new_data_grads_norm = 5.4645
	old_data_grads_norm = 3.8620
	sim_grads_norm = -0.0351
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3814
	data_grads_norm = 4.3069
	new_data_grads_norm = 5.7069
	old_data_grads_norm = 6.1553
	sim_grads_norm = 0.0185
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1513
	data_grads_norm = 4.0951
	new_data_grads_norm = 5.4637
	old_data_grads_norm = 5.4188
	sim_grads_norm = -0.0143
-- Starting training on experience 56 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1692
	data_grads_norm = 3.4027
	new_data_grads_norm = 5.7997
	old_data_grads_norm = 3.5434
	sim_grads_norm = -0.0489
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3264
	data_grads_norm = 3.5823
	new_data_grads_norm = 6.1043
	old_data_grads_norm = 4.1531
	sim_grads_norm = -0.0068
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3585
	data_grads_norm = 3.2732
	new_data_grads_norm = 5.7887
	old_data_grads_norm = 3.2684
	sim_grads_norm = -0.0327
-- Starting training on experience 57 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4146
	data_grads_norm = 3.8066
	new_data_grads_norm = 5.1845
	old_data_grads_norm = 4.6678
	sim_grads_norm = 0.0160
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7991
	data_grads_norm = 3.5842
	new_data_grads_norm = 5.0201
	old_data_grads_norm = 5.1052
	sim_grads_norm = -0.0099
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6343
	data_grads_norm = 3.3474
	new_data_grads_norm = 4.8508
	old_data_grads_norm = 4.2222
	sim_grads_norm = 0.0093
-- Starting training on experience 58 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4099
	data_grads_norm = 3.7503
	new_data_grads_norm = 4.3377
	old_data_grads_norm = 5.4637
	sim_grads_norm = 0.0582
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0411
	data_grads_norm = 3.3370
	new_data_grads_norm = 4.4195
	old_data_grads_norm = 5.6195
	sim_grads_norm = -0.0330
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6208
	data_grads_norm = 2.5076
	new_data_grads_norm = 4.5213
	old_data_grads_norm = 3.2687
	sim_grads_norm = -0.0148
-- Starting training on experience 59 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8152
	data_grads_norm = 3.9145
	new_data_grads_norm = 5.2563
	old_data_grads_norm = 5.3915
	sim_grads_norm = -0.0044
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9910
	data_grads_norm = 3.4493
	new_data_grads_norm = 5.5768
	old_data_grads_norm = 4.4021
	sim_grads_norm = 0.0037
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3450
	data_grads_norm = 3.4752
	new_data_grads_norm = 5.7533
	old_data_grads_norm = 3.8362
	sim_grads_norm = -0.0003
-- Starting training on experience 60 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0299
	data_grads_norm = 4.4774
	new_data_grads_norm = 5.8691
	old_data_grads_norm = 6.4883
	sim_grads_norm = -0.0387
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5612
	data_grads_norm = 3.5195
	new_data_grads_norm = 5.6554
	old_data_grads_norm = 4.4759
	sim_grads_norm = -0.0097
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9037
	data_grads_norm = 4.1118
	new_data_grads_norm = 6.1300
	old_data_grads_norm = 4.9754
	sim_grads_norm = -0.0241
-- Starting training on experience 61 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5742
	data_grads_norm = 3.7977
	new_data_grads_norm = 4.9491
	old_data_grads_norm = 5.1159
	sim_grads_norm = 0.0235
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5814
	data_grads_norm = 3.5955
	new_data_grads_norm = 4.7408
	old_data_grads_norm = 4.7629
	sim_grads_norm = -0.0126
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4208
	data_grads_norm = 3.2568
	new_data_grads_norm = 4.8192
	old_data_grads_norm = 4.1576
	sim_grads_norm = 0.0033
-- Starting training on experience 62 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5773
	data_grads_norm = 3.6777
	new_data_grads_norm = 6.0511
	old_data_grads_norm = 4.4684
	sim_grads_norm = 0.0369
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8485
	data_grads_norm = 4.7132
	new_data_grads_norm = 6.2142
	old_data_grads_norm = 5.3482
	sim_grads_norm = 0.0535
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7311
	data_grads_norm = 4.0336
	new_data_grads_norm = 6.4762
	old_data_grads_norm = 4.9119
	sim_grads_norm = -0.0211
-- Starting training on experience 63 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6480
	data_grads_norm = 3.9945
	new_data_grads_norm = 5.8511
	old_data_grads_norm = 5.1208
	sim_grads_norm = 0.0040
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7112
	data_grads_norm = 4.0716
	new_data_grads_norm = 5.6549
	old_data_grads_norm = 5.0210
	sim_grads_norm = -0.0096
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1811
	data_grads_norm = 2.9032
	new_data_grads_norm = 5.2632
	old_data_grads_norm = 3.5055
	sim_grads_norm = 0.0001
-- Starting training on experience 64 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4972
	data_grads_norm = 4.2671
	new_data_grads_norm = 5.7586
	old_data_grads_norm = 6.2881
	sim_grads_norm = 0.0129
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9221
	data_grads_norm = 3.4960
	new_data_grads_norm = 5.3793
	old_data_grads_norm = 3.9754
	sim_grads_norm = 0.0195
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4130
	data_grads_norm = 4.4134
	new_data_grads_norm = 5.7940
	old_data_grads_norm = 6.4692
	sim_grads_norm = -0.0243
-- Starting training on experience 65 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7883
	data_grads_norm = 4.0142
	new_data_grads_norm = 5.5475
	old_data_grads_norm = 5.0942
	sim_grads_norm = 0.0239
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3750
	data_grads_norm = 3.7010
	new_data_grads_norm = 5.6378
	old_data_grads_norm = 4.4788
	sim_grads_norm = 0.0041
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3151
	data_grads_norm = 3.8553
	new_data_grads_norm = 5.7475
	old_data_grads_norm = 5.3867
	sim_grads_norm = 0.0937
-- Starting training on experience 66 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4012
	data_grads_norm = 3.5361
	new_data_grads_norm = 5.4970
	old_data_grads_norm = 5.0581
	sim_grads_norm = 0.0099
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6555
	data_grads_norm = 3.9439
	new_data_grads_norm = 4.7892
	old_data_grads_norm = 5.5648
	sim_grads_norm = 0.0780
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4764
	data_grads_norm = 3.7321
	new_data_grads_norm = 5.3886
	old_data_grads_norm = 5.0260
	sim_grads_norm = -0.0744
-- Starting training on experience 67 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5382
	data_grads_norm = 3.8191
	new_data_grads_norm = 5.9190
	old_data_grads_norm = 4.5952
	sim_grads_norm = -0.0101
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5168
	data_grads_norm = 4.1044
	new_data_grads_norm = 6.2738
	old_data_grads_norm = 4.0937
	sim_grads_norm = 0.0207
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6808
	data_grads_norm = 4.0588
	new_data_grads_norm = 5.7693
	old_data_grads_norm = 3.9780
	sim_grads_norm = 0.0724
-- Starting training on experience 68 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6469
	data_grads_norm = 3.9112
	new_data_grads_norm = 4.9456
	old_data_grads_norm = 5.7113
	sim_grads_norm = 0.0162
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4866
	data_grads_norm = 3.9652
	new_data_grads_norm = 5.0579
	old_data_grads_norm = 5.5638
	sim_grads_norm = -0.0427
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3451
	data_grads_norm = 3.8702
	new_data_grads_norm = 5.1988
	old_data_grads_norm = 6.2882
	sim_grads_norm = -0.0531
-- Starting training on experience 69 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5426
	data_grads_norm = 3.5687
	new_data_grads_norm = 5.1674
	old_data_grads_norm = 4.6309
	sim_grads_norm = -0.0207
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2621
	data_grads_norm = 3.4265
	new_data_grads_norm = 4.9971
	old_data_grads_norm = 5.0949
	sim_grads_norm = -0.0284
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2281
	data_grads_norm = 4.3512
	new_data_grads_norm = 5.0193
	old_data_grads_norm = 6.1940
	sim_grads_norm = 0.0091
-- Starting training on experience 70 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7295
	data_grads_norm = 4.4246
	new_data_grads_norm = 6.4970
	old_data_grads_norm = 5.6402
	sim_grads_norm = 0.0180
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9712
	data_grads_norm = 4.1063
	new_data_grads_norm = 5.3544
	old_data_grads_norm = 5.3284
	sim_grads_norm = -0.0111
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6048
	data_grads_norm = 4.1312
	new_data_grads_norm = 5.7272
	old_data_grads_norm = 4.6650
	sim_grads_norm = 0.1084
-- Starting training on experience 71 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9794
	data_grads_norm = 3.9329
	new_data_grads_norm = 5.8715
	old_data_grads_norm = 4.4953
	sim_grads_norm = 0.0975
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1132
	data_grads_norm = 4.1937
	new_data_grads_norm = 5.7289
	old_data_grads_norm = 5.6814
	sim_grads_norm = 0.0321
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0683
	data_grads_norm = 4.0033
	new_data_grads_norm = 5.4372
	old_data_grads_norm = 4.2689
	sim_grads_norm = 0.0158
-- Starting training on experience 72 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2444
	data_grads_norm = 3.3426
	new_data_grads_norm = 5.3942
	old_data_grads_norm = 4.2967
	sim_grads_norm = 0.0086
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1956
	data_grads_norm = 3.1085
	new_data_grads_norm = 5.1727
	old_data_grads_norm = 4.2909
	sim_grads_norm = 0.0305
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1663
	data_grads_norm = 3.0021
	new_data_grads_norm = 4.9698
	old_data_grads_norm = 4.1510
	sim_grads_norm = -0.0339
-- Starting training on experience 73 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2697
	data_grads_norm = 3.7054
	new_data_grads_norm = 4.6448
	old_data_grads_norm = 4.4934
	sim_grads_norm = 0.0337
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2145
	data_grads_norm = 3.5041
	new_data_grads_norm = 4.5542
	old_data_grads_norm = 4.8343
	sim_grads_norm = -0.0288
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2233
	data_grads_norm = 3.3430
	new_data_grads_norm = 5.0624
	old_data_grads_norm = 4.4791
	sim_grads_norm = -0.0509
-- Starting training on experience 74 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3659
	data_grads_norm = 3.8772
	new_data_grads_norm = 4.7340
	old_data_grads_norm = 5.0961
	sim_grads_norm = -0.0205
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0672
	data_grads_norm = 2.8959
	new_data_grads_norm = 5.0483
	old_data_grads_norm = 3.4004
	sim_grads_norm = -0.0365
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7898
	data_grads_norm = 3.5121
	new_data_grads_norm = 4.6820
	old_data_grads_norm = 5.1482
	sim_grads_norm = -0.0045
-- Starting training on experience 75 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5313
	data_grads_norm = 3.6410
	new_data_grads_norm = 5.7913
	old_data_grads_norm = 3.9501
	sim_grads_norm = 0.0004
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6032
	data_grads_norm = 3.9287
	new_data_grads_norm = 5.7360
	old_data_grads_norm = 4.6170
	sim_grads_norm = -0.0168
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7875
	data_grads_norm = 4.1322
	new_data_grads_norm = 5.5506
	old_data_grads_norm = 4.6697
	sim_grads_norm = 0.0243
-- Starting training on experience 76 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5863
	data_grads_norm = 3.9990
	new_data_grads_norm = 6.6843
	old_data_grads_norm = 3.3616
	sim_grads_norm = -0.0044
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8899
	data_grads_norm = 4.1677
	new_data_grads_norm = 6.8777
	old_data_grads_norm = 4.7713
	sim_grads_norm = -0.0467
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5703
	data_grads_norm = 4.1288
	new_data_grads_norm = 6.0507
	old_data_grads_norm = 5.4668
	sim_grads_norm = 0.0367
-- Starting training on experience 77 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7564
	data_grads_norm = 3.7774
	new_data_grads_norm = 5.5526
	old_data_grads_norm = 5.4766
	sim_grads_norm = 0.0584
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0584
	data_grads_norm = 4.1114
	new_data_grads_norm = 4.7996
	old_data_grads_norm = 5.7060
	sim_grads_norm = 0.0295
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5302
	data_grads_norm = 3.8285
	new_data_grads_norm = 5.1255
	old_data_grads_norm = 5.9353
	sim_grads_norm = 0.0601
-- Starting training on experience 78 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5873
	data_grads_norm = 3.9702
	new_data_grads_norm = 5.1970
	old_data_grads_norm = 6.2499
	sim_grads_norm = 0.0153
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5188
	data_grads_norm = 3.7465
	new_data_grads_norm = 5.1066
	old_data_grads_norm = 5.1841
	sim_grads_norm = 0.0053
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3769
	data_grads_norm = 3.7133
	new_data_grads_norm = 5.1189
	old_data_grads_norm = 4.5029
	sim_grads_norm = 0.0052
-- Starting training on experience 79 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5204
	data_grads_norm = 3.7015
	new_data_grads_norm = 5.3446
	old_data_grads_norm = 4.5335
	sim_grads_norm = 0.0492
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6306
	data_grads_norm = 3.4582
	new_data_grads_norm = 5.1867
	old_data_grads_norm = 5.5222
	sim_grads_norm = -0.0608
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9882
	data_grads_norm = 4.3280
	new_data_grads_norm = 5.2159
	old_data_grads_norm = 5.8498
	sim_grads_norm = 0.0795
-- Starting training on experience 80 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7415
	data_grads_norm = 3.6753
	new_data_grads_norm = 5.3656
	old_data_grads_norm = 4.7698
	sim_grads_norm = 0.0022
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5144
	data_grads_norm = 3.3708
	new_data_grads_norm = 5.3644
	old_data_grads_norm = 4.1158
	sim_grads_norm = -0.0163
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5205
	data_grads_norm = 3.6530
	new_data_grads_norm = 5.3768
	old_data_grads_norm = 4.5094
	sim_grads_norm = 0.0056
-- Starting training on experience 81 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3312
	data_grads_norm = 3.7196
	new_data_grads_norm = 5.3392
	old_data_grads_norm = 5.1736
	sim_grads_norm = -0.0083
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2306
	data_grads_norm = 3.3556
	new_data_grads_norm = 5.1865
	old_data_grads_norm = 4.0490
	sim_grads_norm = 0.0246
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8879
	data_grads_norm = 4.0141
	new_data_grads_norm = 5.3366
	old_data_grads_norm = 5.3512
	sim_grads_norm = 0.0409
-- Starting training on experience 82 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6490
	data_grads_norm = 4.0424
	new_data_grads_norm = 5.4563
	old_data_grads_norm = 5.2572
	sim_grads_norm = -0.0145
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3014
	data_grads_norm = 3.6739
	new_data_grads_norm = 5.1894
	old_data_grads_norm = 5.1585
	sim_grads_norm = 0.0102
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2758
	data_grads_norm = 3.6779
	new_data_grads_norm = 5.6849
	old_data_grads_norm = 3.3069
	sim_grads_norm = -0.0067
-- Starting training on experience 83 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4194
	data_grads_norm = 4.0595
	new_data_grads_norm = 5.6230
	old_data_grads_norm = 4.8802
	sim_grads_norm = 0.0567
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9269
	data_grads_norm = 4.3465
	new_data_grads_norm = 5.5210
	old_data_grads_norm = 5.4214
	sim_grads_norm = 0.0495
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6840
	data_grads_norm = 4.2399
	new_data_grads_norm = 5.7371
	old_data_grads_norm = 6.2326
	sim_grads_norm = 0.0285
-- Starting training on experience 84 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8892
	data_grads_norm = 3.5572
	new_data_grads_norm = 4.7563
	old_data_grads_norm = 4.8858
	sim_grads_norm = -0.0077
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0565
	data_grads_norm = 3.2132
	new_data_grads_norm = 4.9474
	old_data_grads_norm = 4.1798
	sim_grads_norm = -0.0157
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5051
	data_grads_norm = 3.6102
	new_data_grads_norm = 4.8865
	old_data_grads_norm = 5.2766
	sim_grads_norm = -0.0016
-- Starting training on experience 85 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3114
	data_grads_norm = 3.2907
	new_data_grads_norm = 5.0817
	old_data_grads_norm = 4.2530
	sim_grads_norm = 0.0273
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2858
	data_grads_norm = 3.5041
	new_data_grads_norm = 5.1959
	old_data_grads_norm = 4.6851
	sim_grads_norm = -0.0016
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2531
	data_grads_norm = 3.3697
	new_data_grads_norm = 5.3116
	old_data_grads_norm = 4.6183
	sim_grads_norm = -0.0311
-- Starting training on experience 86 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9339
	data_grads_norm = 3.2234
	new_data_grads_norm = 5.0405
	old_data_grads_norm = 4.4587
	sim_grads_norm = -0.0685
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3635
	data_grads_norm = 4.1179
	new_data_grads_norm = 4.9989
	old_data_grads_norm = 5.0441
	sim_grads_norm = 0.0105
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4924
	data_grads_norm = 3.5233
	new_data_grads_norm = 5.4669
	old_data_grads_norm = 3.9426
	sim_grads_norm = 0.0939
-- Starting training on experience 87 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0482
	data_grads_norm = 3.4831
	new_data_grads_norm = 4.7023
	old_data_grads_norm = 5.0511
	sim_grads_norm = -0.0135
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5133
	data_grads_norm = 3.7446
	new_data_grads_norm = 5.1818
	old_data_grads_norm = 4.8371
	sim_grads_norm = 0.0293
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5906
	data_grads_norm = 3.6145
	new_data_grads_norm = 4.7987
	old_data_grads_norm = 5.4292
	sim_grads_norm = -0.0010
-- Starting training on experience 88 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9164
	data_grads_norm = 4.2229
	new_data_grads_norm = 6.5998
	old_data_grads_norm = 5.1076
	sim_grads_norm = -0.0221
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7638
	data_grads_norm = 3.9104
	new_data_grads_norm = 5.8120
	old_data_grads_norm = 5.8480
	sim_grads_norm = -0.0617
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9085
	data_grads_norm = 3.9191
	new_data_grads_norm = 5.8830
	old_data_grads_norm = 5.0299
	sim_grads_norm = -0.0257
-- Starting training on experience 89 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8963
	data_grads_norm = 4.4260
	new_data_grads_norm = 6.4639
	old_data_grads_norm = 5.6987
	sim_grads_norm = -0.0217
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2827
	data_grads_norm = 3.9533
	new_data_grads_norm = 5.6521
	old_data_grads_norm = 5.7486
	sim_grads_norm = 0.0211
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4030
	data_grads_norm = 3.8778
	new_data_grads_norm = 5.7892
	old_data_grads_norm = 4.8854
	sim_grads_norm = -0.0097
-- Starting training on experience 90 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1106
	data_grads_norm = 3.6662
	new_data_grads_norm = 6.6396
	old_data_grads_norm = 4.9334
	sim_grads_norm = -0.0023
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9329
	data_grads_norm = 5.1571
	new_data_grads_norm = 6.8905
	old_data_grads_norm = 6.7779
	sim_grads_norm = -0.0157
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9728
	data_grads_norm = 4.7757
	new_data_grads_norm = 6.7103
	old_data_grads_norm = 5.7308
	sim_grads_norm = 0.0160
-- Starting training on experience 91 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1548
	data_grads_norm = 4.7440
	new_data_grads_norm = 5.9306
	old_data_grads_norm = 6.0915
	sim_grads_norm = 0.0781
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7192
	data_grads_norm = 4.2420
	new_data_grads_norm = 5.9313
	old_data_grads_norm = 5.8395
	sim_grads_norm = -0.0167
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2813
	data_grads_norm = 4.6496
	new_data_grads_norm = 6.4060
	old_data_grads_norm = 5.0363
	sim_grads_norm = -0.0056
-- Starting training on experience 92 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1693
	data_grads_norm = 3.2500
	new_data_grads_norm = 6.1137
	old_data_grads_norm = 3.6237
	sim_grads_norm = 0.0286
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3230
	data_grads_norm = 3.0374
	new_data_grads_norm = 4.8924
	old_data_grads_norm = 3.7438
	sim_grads_norm = 0.0397
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1696
	data_grads_norm = 3.3511
	new_data_grads_norm = 5.0921
	old_data_grads_norm = 4.1683
	sim_grads_norm = 0.0060
-- Starting training on experience 93 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8731
	data_grads_norm = 2.9740
	new_data_grads_norm = 4.3019
	old_data_grads_norm = 4.4385
	sim_grads_norm = -0.0617
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3017
	data_grads_norm = 3.3603
	new_data_grads_norm = 4.6335
	old_data_grads_norm = 5.0694
	sim_grads_norm = -0.0051
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4597
	data_grads_norm = 4.5563
	new_data_grads_norm = 4.8621
	old_data_grads_norm = 5.9786
	sim_grads_norm = 0.0174
-- Starting training on experience 94 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4562
	data_grads_norm = 3.7625
	new_data_grads_norm = 5.9677
	old_data_grads_norm = 3.7607
	sim_grads_norm = 0.0786
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4812
	data_grads_norm = 4.3567
	new_data_grads_norm = 6.5210
	old_data_grads_norm = 5.0190
	sim_grads_norm = 0.1090
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3067
	data_grads_norm = 3.7679
	new_data_grads_norm = 6.0171
	old_data_grads_norm = 4.7063
	sim_grads_norm = 0.0026
-- Starting training on experience 95 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8007
	data_grads_norm = 3.3726
	new_data_grads_norm = 4.9920
	old_data_grads_norm = 4.4921
	sim_grads_norm = 0.0570
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3659
	data_grads_norm = 3.5642
	new_data_grads_norm = 4.5805
	old_data_grads_norm = 5.3854
	sim_grads_norm = 0.0238
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9752
	data_grads_norm = 3.7739
	new_data_grads_norm = 4.4379
	old_data_grads_norm = 5.9610
	sim_grads_norm = 0.0161
-- Starting training on experience 96 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5869
	data_grads_norm = 4.0438
	new_data_grads_norm = 6.2655
	old_data_grads_norm = 5.3131
	sim_grads_norm = 0.0305
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5080
	data_grads_norm = 3.9387
	new_data_grads_norm = 6.5293
	old_data_grads_norm = 5.9419
	sim_grads_norm = -0.0100
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2461
	data_grads_norm = 4.0911
	new_data_grads_norm = 6.2447
	old_data_grads_norm = 3.9125
	sim_grads_norm = -0.0317
-- Starting training on experience 97 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3552
	data_grads_norm = 3.4053
	new_data_grads_norm = 5.3558
	old_data_grads_norm = 4.0180
	sim_grads_norm = 0.0734
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5525
	data_grads_norm = 4.2731
	new_data_grads_norm = 5.8113
	old_data_grads_norm = 5.0284
	sim_grads_norm = -0.0018
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5194
	data_grads_norm = 3.5286
	new_data_grads_norm = 5.8364
	old_data_grads_norm = 4.6049
	sim_grads_norm = 0.0453
-- Starting training on experience 98 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5112
	data_grads_norm = 3.9482
	new_data_grads_norm = 4.4984
	old_data_grads_norm = 7.3290
	sim_grads_norm = 0.0366
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2600
	data_grads_norm = 3.3810
	new_data_grads_norm = 5.2730
	old_data_grads_norm = 3.6454
	sim_grads_norm = -0.0767
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2677
	data_grads_norm = 3.7074
	new_data_grads_norm = 5.4673
	old_data_grads_norm = 4.1157
	sim_grads_norm = 0.0361
-- Starting training on experience 99 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3142
	data_grads_norm = 3.5667
	new_data_grads_norm = 5.1110
	old_data_grads_norm = 5.3668
	sim_grads_norm = -0.0245
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0133
	data_grads_norm = 3.0529
	new_data_grads_norm = 4.7326
	old_data_grads_norm = 4.1182
	sim_grads_norm = 0.0053
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3022
	data_grads_norm = 3.8074
	new_data_grads_norm = 5.6022
	old_data_grads_norm = 5.0179
	sim_grads_norm = -0.0154
-- Starting training on experience 100 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4448
	data_grads_norm = 3.4062
	new_data_grads_norm = 5.1889
	old_data_grads_norm = 3.8260
	sim_grads_norm = 0.0524
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3376
	data_grads_norm = 3.6318
	new_data_grads_norm = 4.7561
	old_data_grads_norm = 5.3847
	sim_grads_norm = -0.0185
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0182
	data_grads_norm = 3.0699
	new_data_grads_norm = 4.5785
	old_data_grads_norm = 5.2074
	sim_grads_norm = -0.0596
-- Starting training on experience 101 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2763
	data_grads_norm = 4.0595
	new_data_grads_norm = 5.1437
	old_data_grads_norm = 6.5377
	sim_grads_norm = 0.0175
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2538
	data_grads_norm = 3.4960
	new_data_grads_norm = 5.1221
	old_data_grads_norm = 4.4087
	sim_grads_norm = 0.0384
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4677
	data_grads_norm = 3.5578
	new_data_grads_norm = 4.7160
	old_data_grads_norm = 5.4897
	sim_grads_norm = -0.0488
-- Starting training on experience 102 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3042
	data_grads_norm = 3.5403
	new_data_grads_norm = 4.6557
	old_data_grads_norm = 4.7662
	sim_grads_norm = 0.0630
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1604
	data_grads_norm = 3.0974
	new_data_grads_norm = 4.6743
	old_data_grads_norm = 4.0827
	sim_grads_norm = -0.0270
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2732
	data_grads_norm = 3.2781
	new_data_grads_norm = 4.7866
	old_data_grads_norm = 3.1421
	sim_grads_norm = 0.0917
-- Starting training on experience 103 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0281
	data_grads_norm = 4.5981
	new_data_grads_norm = 4.9894
	old_data_grads_norm = 6.0549
	sim_grads_norm = 0.0249
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5842
	data_grads_norm = 3.8970
	new_data_grads_norm = 4.8592
	old_data_grads_norm = 5.3652
	sim_grads_norm = -0.0188
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6938
	data_grads_norm = 4.6708
	new_data_grads_norm = 5.3400
	old_data_grads_norm = 5.9819
	sim_grads_norm = 0.1329
-- Starting training on experience 104 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6786
	data_grads_norm = 3.6612
	new_data_grads_norm = 5.3994
	old_data_grads_norm = 4.2222
	sim_grads_norm = -0.0016
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0939
	data_grads_norm = 3.9392
	new_data_grads_norm = 5.0062
	old_data_grads_norm = 5.6221
	sim_grads_norm = 0.0267
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3625
	data_grads_norm = 3.9829
	new_data_grads_norm = 5.5440
	old_data_grads_norm = 4.8654
	sim_grads_norm = 0.0444
-- Starting training on experience 105 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9070
	data_grads_norm = 4.0748
	new_data_grads_norm = 5.0601
	old_data_grads_norm = 5.4118
	sim_grads_norm = 0.0651
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2777
	data_grads_norm = 3.9073
	new_data_grads_norm = 4.7019
	old_data_grads_norm = 4.2276
	sim_grads_norm = 0.0706
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2939
	data_grads_norm = 3.2378
	new_data_grads_norm = 4.9646
	old_data_grads_norm = 4.0621
	sim_grads_norm = 0.0307
-- Starting training on experience 106 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2443
	data_grads_norm = 3.5888
	new_data_grads_norm = 5.3587
	old_data_grads_norm = 4.7574
	sim_grads_norm = -0.0348
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3444
	data_grads_norm = 3.6165
	new_data_grads_norm = 4.9313
	old_data_grads_norm = 4.6440
	sim_grads_norm = 0.0504
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1231
	data_grads_norm = 3.2633
	new_data_grads_norm = 4.8968
	old_data_grads_norm = 4.1267
	sim_grads_norm = 0.0057
-- Starting training on experience 107 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1724
	data_grads_norm = 3.4553
	new_data_grads_norm = 3.9685
	old_data_grads_norm = 5.5892
	sim_grads_norm = 0.0038
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0386
	data_grads_norm = 3.5503
	new_data_grads_norm = 4.0161
	old_data_grads_norm = 5.5845
	sim_grads_norm = 0.0114
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1957
	data_grads_norm = 3.7731
	new_data_grads_norm = 4.2539
	old_data_grads_norm = 5.8094
	sim_grads_norm = -0.0600
-- Starting training on experience 108 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5011
	data_grads_norm = 3.7639
	new_data_grads_norm = 4.9171
	old_data_grads_norm = 5.4708
	sim_grads_norm = -0.0111
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5048
	data_grads_norm = 3.6060
	new_data_grads_norm = 5.2840
	old_data_grads_norm = 4.4261
	sim_grads_norm = 0.0342
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0546
	data_grads_norm = 3.2192
	new_data_grads_norm = 4.8572
	old_data_grads_norm = 3.7737
	sim_grads_norm = -0.1149
-- Starting training on experience 109 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8219
	data_grads_norm = 3.1830
	new_data_grads_norm = 5.2009
	old_data_grads_norm = 4.0403
	sim_grads_norm = 0.0031
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0041
	data_grads_norm = 3.7686
	new_data_grads_norm = 5.5782
	old_data_grads_norm = 4.8359
	sim_grads_norm = -0.0011
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8328
	data_grads_norm = 3.0274
	new_data_grads_norm = 4.8826
	old_data_grads_norm = 3.1858
	sim_grads_norm = -0.0009
-- Starting training on experience 110 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8812
	data_grads_norm = 3.9812
	new_data_grads_norm = 4.4023
	old_data_grads_norm = 6.7898
	sim_grads_norm = -0.0199
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0180
	data_grads_norm = 3.4974
	new_data_grads_norm = 5.2626
	old_data_grads_norm = 3.4290
	sim_grads_norm = -0.0253
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9942
	data_grads_norm = 3.4047
	new_data_grads_norm = 5.2143
	old_data_grads_norm = 4.9202
	sim_grads_norm = -0.0063
-- Starting training on experience 111 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7571
	data_grads_norm = 4.8831
	new_data_grads_norm = 5.9594
	old_data_grads_norm = 6.7397
	sim_grads_norm = 0.0373
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9918
	data_grads_norm = 3.9475
	new_data_grads_norm = 5.3451
	old_data_grads_norm = 5.1931
	sim_grads_norm = -0.0277
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2830
	data_grads_norm = 4.8263
	new_data_grads_norm = 6.3352
	old_data_grads_norm = 6.2053
	sim_grads_norm = 0.0658
-- Starting training on experience 112 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3828
	data_grads_norm = 4.1122
	new_data_grads_norm = 5.2617
	old_data_grads_norm = 5.8988
	sim_grads_norm = 0.0271
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2726
	data_grads_norm = 4.1671
	new_data_grads_norm = 5.5271
	old_data_grads_norm = 5.0318
	sim_grads_norm = -0.0205
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7461
	data_grads_norm = 5.0633
	new_data_grads_norm = 5.9918
	old_data_grads_norm = 6.4888
	sim_grads_norm = 0.0197
-- Starting training on experience 113 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6965
	data_grads_norm = 3.1992
	new_data_grads_norm = 4.9573
	old_data_grads_norm = 4.8070
	sim_grads_norm = -0.0305
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1493
	data_grads_norm = 3.6521
	new_data_grads_norm = 5.5821
	old_data_grads_norm = 5.3869
	sim_grads_norm = 0.0401
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3486
	data_grads_norm = 3.9084
	new_data_grads_norm = 5.1648
	old_data_grads_norm = 6.2076
	sim_grads_norm = 0.0383
-- Starting training on experience 114 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3426
	data_grads_norm = 3.6632
	new_data_grads_norm = 5.7380
	old_data_grads_norm = 4.4569
	sim_grads_norm = 0.0180
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7498
	data_grads_norm = 4.0177
	new_data_grads_norm = 6.0100
	old_data_grads_norm = 4.7502
	sim_grads_norm = -0.0316
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3453
	data_grads_norm = 3.4348
	new_data_grads_norm = 5.2312
	old_data_grads_norm = 4.3940
	sim_grads_norm = 0.0130
-- Starting training on experience 115 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1927
	data_grads_norm = 3.6742
	new_data_grads_norm = 5.8969
	old_data_grads_norm = 3.7729
	sim_grads_norm = 0.0203
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9165
	data_grads_norm = 3.6285
	new_data_grads_norm = 5.6506
	old_data_grads_norm = 4.0041
	sim_grads_norm = -0.0037
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3754
	data_grads_norm = 3.8891
	new_data_grads_norm = 5.5428
	old_data_grads_norm = 5.5515
	sim_grads_norm = 0.0046
-- Starting training on experience 116 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9349
	data_grads_norm = 3.8089
	new_data_grads_norm = 6.4522
	old_data_grads_norm = 4.1407
	sim_grads_norm = -0.0111
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9576
	data_grads_norm = 4.3612
	new_data_grads_norm = 6.7232
	old_data_grads_norm = 5.0022
	sim_grads_norm = -0.0396
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2942
	data_grads_norm = 4.7082
	new_data_grads_norm = 6.8541
	old_data_grads_norm = 5.7156
	sim_grads_norm = 0.0112
-- Starting training on experience 117 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0608
	data_grads_norm = 3.5380
	new_data_grads_norm = 6.0089
	old_data_grads_norm = 4.5396
	sim_grads_norm = -0.0263
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9347
	data_grads_norm = 3.5169
	new_data_grads_norm = 5.9364
	old_data_grads_norm = 4.9637
	sim_grads_norm = 0.0100
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0463
	data_grads_norm = 3.5493
	new_data_grads_norm = 5.3156
	old_data_grads_norm = 6.6961
	sim_grads_norm = -0.0274
-- Starting training on experience 118 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2938
	data_grads_norm = 3.8307
	new_data_grads_norm = 5.6072
	old_data_grads_norm = 5.6917
	sim_grads_norm = 0.0312
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5240
	data_grads_norm = 4.2210
	new_data_grads_norm = 4.6895
	old_data_grads_norm = 6.5179
	sim_grads_norm = 0.0662
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9610
	data_grads_norm = 3.6106
	new_data_grads_norm = 4.8286
	old_data_grads_norm = 3.8958
	sim_grads_norm = 0.0148
-- Starting training on experience 119 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1891
	data_grads_norm = 3.5482
	new_data_grads_norm = 5.4920
	old_data_grads_norm = 5.1485
	sim_grads_norm = 0.0208
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5717
	data_grads_norm = 3.5966
	new_data_grads_norm = 4.8971
	old_data_grads_norm = 4.6029
	sim_grads_norm = 0.0259
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5398
	data_grads_norm = 4.1758
	new_data_grads_norm = 4.6201
	old_data_grads_norm = 5.9463
	sim_grads_norm = -0.0231
-- Starting training on experience 120 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4794
	data_grads_norm = 4.1922
	new_data_grads_norm = 5.3761
	old_data_grads_norm = 5.9078
	sim_grads_norm = 0.0254
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7630
	data_grads_norm = 4.3809
	new_data_grads_norm = 5.8792
	old_data_grads_norm = 5.7462
	sim_grads_norm = 0.0083
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2778
	data_grads_norm = 3.1469
	new_data_grads_norm = 4.7714
	old_data_grads_norm = 4.0943
	sim_grads_norm = -0.0095
-- Starting training on experience 121 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5612
	data_grads_norm = 3.8625
	new_data_grads_norm = 5.3787
	old_data_grads_norm = 5.4773
	sim_grads_norm = 0.0843
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1687
	data_grads_norm = 3.7013
	new_data_grads_norm = 4.8102
	old_data_grads_norm = 6.4574
	sim_grads_norm = -0.0237
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9089
	data_grads_norm = 4.2404
	new_data_grads_norm = 5.1719
	old_data_grads_norm = 5.6433
	sim_grads_norm = 0.1771
-- Starting training on experience 122 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5006
	data_grads_norm = 4.3373
	new_data_grads_norm = 5.5424
	old_data_grads_norm = 6.0356
	sim_grads_norm = 0.0165
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8064
	data_grads_norm = 4.9858
	new_data_grads_norm = 5.8907
	old_data_grads_norm = 6.5177
	sim_grads_norm = 0.0629
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1619
	data_grads_norm = 3.6944
	new_data_grads_norm = 6.1194
	old_data_grads_norm = 4.0478
	sim_grads_norm = 0.0076
-- Starting training on experience 123 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6224
	data_grads_norm = 4.1627
	new_data_grads_norm = 5.7687
	old_data_grads_norm = 6.1033
	sim_grads_norm = -0.0160
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6409
	data_grads_norm = 4.1046
	new_data_grads_norm = 5.8018
	old_data_grads_norm = 5.4039
	sim_grads_norm = -0.0278
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2081
	data_grads_norm = 4.3923
	new_data_grads_norm = 5.7708
	old_data_grads_norm = 6.1918
	sim_grads_norm = 0.0613
-- Starting training on experience 124 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5375
	data_grads_norm = 4.6752
	new_data_grads_norm = 5.2000
	old_data_grads_norm = 7.0968
	sim_grads_norm = 0.0596
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3096
	data_grads_norm = 3.9376
	new_data_grads_norm = 5.1609
	old_data_grads_norm = 5.3994
	sim_grads_norm = -0.0129
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5541
	data_grads_norm = 3.7091
	new_data_grads_norm = 5.4301
	old_data_grads_norm = 4.6782
	sim_grads_norm = -0.0114
-- Starting training on experience 125 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8018
	data_grads_norm = 4.1387
	new_data_grads_norm = 6.2365
	old_data_grads_norm = 4.9978
	sim_grads_norm = -0.0332
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5217
	data_grads_norm = 3.6938
	new_data_grads_norm = 6.0778
	old_data_grads_norm = 3.9082
	sim_grads_norm = 0.0428
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1356
	data_grads_norm = 3.5476
	new_data_grads_norm = 5.5384
	old_data_grads_norm = 4.1879
	sim_grads_norm = -0.0166
-- Starting training on experience 126 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0825
	data_grads_norm = 4.1738
	new_data_grads_norm = 5.0947
	old_data_grads_norm = 5.8032
	sim_grads_norm = -0.0286
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1526
	data_grads_norm = 3.8958
	new_data_grads_norm = 5.5837
	old_data_grads_norm = 3.6567
	sim_grads_norm = 0.1244
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1035
	data_grads_norm = 3.0344
	new_data_grads_norm = 4.9964
	old_data_grads_norm = 4.2518
	sim_grads_norm = -0.0302
-- Starting training on experience 127 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2184
	data_grads_norm = 3.7609
	new_data_grads_norm = 5.2087
	old_data_grads_norm = 5.0381
	sim_grads_norm = 0.0332
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4960
	data_grads_norm = 4.1104
	new_data_grads_norm = 5.3449
	old_data_grads_norm = 5.3571
	sim_grads_norm = 0.0929
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5053
	data_grads_norm = 3.9339
	new_data_grads_norm = 4.6180
	old_data_grads_norm = 6.0108
	sim_grads_norm = -0.0183
-- Starting training on experience 128 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4959
	data_grads_norm = 3.9314
	new_data_grads_norm = 5.5847
	old_data_grads_norm = 5.6249
	sim_grads_norm = 0.0018
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3906
	data_grads_norm = 3.7310
	new_data_grads_norm = 5.7874
	old_data_grads_norm = 4.3588
	sim_grads_norm = -0.0393
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1558
	data_grads_norm = 3.7764
	new_data_grads_norm = 5.9413
	old_data_grads_norm = 3.9700
	sim_grads_norm = 0.0167
-- Starting training on experience 129 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8717
	data_grads_norm = 3.1597
	new_data_grads_norm = 5.9336
	old_data_grads_norm = 3.2842
	sim_grads_norm = -0.0596
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3739
	data_grads_norm = 4.1236
	new_data_grads_norm = 5.7571
	old_data_grads_norm = 5.4710
	sim_grads_norm = -0.0108
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5359
	data_grads_norm = 4.1780
	new_data_grads_norm = 5.8370
	old_data_grads_norm = 5.0449
	sim_grads_norm = 0.0282
-- Starting training on experience 130 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3865
	data_grads_norm = 4.0519
	new_data_grads_norm = 4.9471
	old_data_grads_norm = 5.8829
	sim_grads_norm = -0.0186
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5729
	data_grads_norm = 4.4401
	new_data_grads_norm = 5.3131
	old_data_grads_norm = 6.1635
	sim_grads_norm = 0.0146
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4477
	data_grads_norm = 4.4654
	new_data_grads_norm = 5.4295
	old_data_grads_norm = 5.8106
	sim_grads_norm = 0.0203
-- Starting training on experience 131 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9680
	data_grads_norm = 3.6146
	new_data_grads_norm = 4.8197
	old_data_grads_norm = 5.0704
	sim_grads_norm = -0.0084
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0846
	data_grads_norm = 3.5035
	new_data_grads_norm = 4.8046
	old_data_grads_norm = 4.5455
	sim_grads_norm = 0.0648
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7176
	data_grads_norm = 3.1192
	new_data_grads_norm = 5.1305
	old_data_grads_norm = 4.4546
	sim_grads_norm = -0.0312
-- Starting training on experience 132 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5597
	data_grads_norm = 2.4172
	new_data_grads_norm = 4.8238
	old_data_grads_norm = 1.7563
	sim_grads_norm = 0.0079
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9602
	data_grads_norm = 3.0109
	new_data_grads_norm = 4.6114
	old_data_grads_norm = 4.0075
	sim_grads_norm = 0.0082
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9114
	data_grads_norm = 3.0878
	new_data_grads_norm = 4.8675
	old_data_grads_norm = 4.5527
	sim_grads_norm = -0.0173
-- Starting training on experience 133 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0123
	data_grads_norm = 3.5206
	new_data_grads_norm = 4.8251
	old_data_grads_norm = 5.1776
	sim_grads_norm = -0.0707
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4173
	data_grads_norm = 3.6984
	new_data_grads_norm = 5.2636
	old_data_grads_norm = 4.7936
	sim_grads_norm = -0.0136
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1761
	data_grads_norm = 3.6089
	new_data_grads_norm = 5.2586
	old_data_grads_norm = 4.8346
	sim_grads_norm = 0.0064
-- Starting training on experience 134 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8384
	data_grads_norm = 3.1804
	new_data_grads_norm = 4.5361
	old_data_grads_norm = 4.9540
	sim_grads_norm = -0.0479
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1890
	data_grads_norm = 3.4980
	new_data_grads_norm = 4.6953
	old_data_grads_norm = 3.9695
	sim_grads_norm = 0.1084
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0887
	data_grads_norm = 3.2885
	new_data_grads_norm = 4.7155
	old_data_grads_norm = 4.1149
	sim_grads_norm = 0.0225
-- Starting training on experience 135 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0598
	data_grads_norm = 3.7463
	new_data_grads_norm = 5.2718
	old_data_grads_norm = 6.0618
	sim_grads_norm = 0.0317
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4855
	data_grads_norm = 4.6380
	new_data_grads_norm = 6.4076
	old_data_grads_norm = 5.8189
	sim_grads_norm = 0.0493
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4080
	data_grads_norm = 4.1781
	new_data_grads_norm = 5.8915
	old_data_grads_norm = 5.5801
	sim_grads_norm = -0.0246
-- Starting training on experience 136 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9128
	data_grads_norm = 3.6101
	new_data_grads_norm = 4.9905
	old_data_grads_norm = 5.1663
	sim_grads_norm = 0.0325
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0585
	data_grads_norm = 3.7995
	new_data_grads_norm = 4.5875
	old_data_grads_norm = 4.8285
	sim_grads_norm = -0.0041
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5590
	data_grads_norm = 3.1152
	new_data_grads_norm = 4.9062
	old_data_grads_norm = 3.0334
	sim_grads_norm = -0.0456
-- Starting training on experience 137 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2807
	data_grads_norm = 4.0723
	new_data_grads_norm = 5.5934
	old_data_grads_norm = 5.4151
	sim_grads_norm = -0.0121
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2971
	data_grads_norm = 4.3690
	new_data_grads_norm = 5.9073
	old_data_grads_norm = 6.4521
	sim_grads_norm = 0.0320
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2505
	data_grads_norm = 3.5420
	new_data_grads_norm = 5.2304
	old_data_grads_norm = 4.4632
	sim_grads_norm = -0.0181
-- Starting training on experience 138 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7522
	data_grads_norm = 4.4829
	new_data_grads_norm = 5.7956
	old_data_grads_norm = 6.1180
	sim_grads_norm = -0.0046
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9960
	data_grads_norm = 3.4946
	new_data_grads_norm = 5.4609
	old_data_grads_norm = 5.7368
	sim_grads_norm = -0.0231
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4502
	data_grads_norm = 3.8994
	new_data_grads_norm = 5.7695
	old_data_grads_norm = 5.3079
	sim_grads_norm = -0.0156
-- Starting training on experience 139 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1785
	data_grads_norm = 4.1626
	new_data_grads_norm = 5.2432
	old_data_grads_norm = 6.0172
	sim_grads_norm = -0.0551
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7469
	data_grads_norm = 4.1594
	new_data_grads_norm = 5.8511
	old_data_grads_norm = 6.1769
	sim_grads_norm = -0.0086
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3114
	data_grads_norm = 4.1382
	new_data_grads_norm = 6.5868
	old_data_grads_norm = 6.1579
	sim_grads_norm = -0.0080
-- Starting training on experience 140 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8908
	data_grads_norm = 3.3029
	new_data_grads_norm = 5.8412
	old_data_grads_norm = 5.2200
	sim_grads_norm = -0.0125
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5635
	data_grads_norm = 4.1360
	new_data_grads_norm = 6.3318
	old_data_grads_norm = 4.7692
	sim_grads_norm = 0.1001
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2254
	data_grads_norm = 3.7859
	new_data_grads_norm = 5.9820
	old_data_grads_norm = 5.3359
	sim_grads_norm = -0.0082
-- Starting training on experience 141 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2281
	data_grads_norm = 4.1676
	new_data_grads_norm = 5.8177
	old_data_grads_norm = 4.9097
	sim_grads_norm = 0.0191
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2459
	data_grads_norm = 3.6553
	new_data_grads_norm = 5.0089
	old_data_grads_norm = 4.9005
	sim_grads_norm = -0.0337
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8926
	data_grads_norm = 4.4630
	new_data_grads_norm = 5.5191
	old_data_grads_norm = 5.9634
	sim_grads_norm = 0.0486
-- Starting training on experience 142 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1119
	data_grads_norm = 4.2627
	new_data_grads_norm = 4.9675
	old_data_grads_norm = 5.6417
	sim_grads_norm = -0.0271
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9828
	data_grads_norm = 3.6610
	new_data_grads_norm = 5.0366
	old_data_grads_norm = 4.7807
	sim_grads_norm = 0.0771
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8735
	data_grads_norm = 3.3382
	new_data_grads_norm = 4.7376
	old_data_grads_norm = 3.9612
	sim_grads_norm = 0.0212
-- Starting training on experience 143 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9676
	data_grads_norm = 4.0654
	new_data_grads_norm = 4.8394
	old_data_grads_norm = 6.5469
	sim_grads_norm = 0.0071
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9120
	data_grads_norm = 3.2686
	new_data_grads_norm = 4.0230
	old_data_grads_norm = 5.2601
	sim_grads_norm = -0.0186
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8258
	data_grads_norm = 3.5256
	new_data_grads_norm = 4.8228
	old_data_grads_norm = 4.6760
	sim_grads_norm = 0.0579
-- Starting training on experience 144 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1753
	data_grads_norm = 3.8514
	new_data_grads_norm = 4.9574
	old_data_grads_norm = 5.6288
	sim_grads_norm = 0.0559
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8098
	data_grads_norm = 3.3757
	new_data_grads_norm = 4.9469
	old_data_grads_norm = 4.6996
	sim_grads_norm = -0.0339
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8406
	data_grads_norm = 3.6069
	new_data_grads_norm = 5.5835
	old_data_grads_norm = 3.9093
	sim_grads_norm = 0.0599
-- Starting training on experience 145 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5158
	data_grads_norm = 3.3255
	new_data_grads_norm = 5.5129
	old_data_grads_norm = 4.8556
	sim_grads_norm = -0.0210
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2403
	data_grads_norm = 4.2211
	new_data_grads_norm = 5.2244
	old_data_grads_norm = 6.2715
	sim_grads_norm = 0.0364
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0321
	data_grads_norm = 3.3641
	new_data_grads_norm = 5.0504
	old_data_grads_norm = 4.1511
	sim_grads_norm = 0.0409
-- Starting training on experience 146 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0366
	data_grads_norm = 3.5094
	new_data_grads_norm = 5.3116
	old_data_grads_norm = 4.6119
	sim_grads_norm = 0.0471
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1111
	data_grads_norm = 3.6232
	new_data_grads_norm = 5.4753
	old_data_grads_norm = 5.0608
	sim_grads_norm = -0.0399
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8936
	data_grads_norm = 3.6349
	new_data_grads_norm = 5.9396
	old_data_grads_norm = 4.7631
	sim_grads_norm = -0.0525
-- Starting training on experience 147 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7705
	data_grads_norm = 3.4207
	new_data_grads_norm = 4.5757
	old_data_grads_norm = 4.3056
	sim_grads_norm = 0.0419
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1741
	data_grads_norm = 3.5069
	new_data_grads_norm = 4.5578
	old_data_grads_norm = 5.2327
	sim_grads_norm = 0.0359
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3945
	data_grads_norm = 3.8309
	new_data_grads_norm = 4.5944
	old_data_grads_norm = 5.5795
	sim_grads_norm = -0.0038
-- Starting training on experience 148 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2570
	data_grads_norm = 3.3158
	new_data_grads_norm = 5.1301
	old_data_grads_norm = 3.9935
	sim_grads_norm = 0.0013
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2976
	data_grads_norm = 3.9448
	new_data_grads_norm = 5.6298
	old_data_grads_norm = 5.3601
	sim_grads_norm = 0.0103
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2204
	data_grads_norm = 4.0082
	new_data_grads_norm = 5.3684
	old_data_grads_norm = 5.8034
	sim_grads_norm = -0.0132
-- Starting training on experience 149 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9942
	data_grads_norm = 5.3832
	new_data_grads_norm = 6.4109
	old_data_grads_norm = 6.4048
	sim_grads_norm = -0.0117
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3301
	data_grads_norm = 3.9995
	new_data_grads_norm = 6.8691
	old_data_grads_norm = 4.4178
	sim_grads_norm = -0.0243
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0407
	data_grads_norm = 3.4929
	new_data_grads_norm = 6.5465
	old_data_grads_norm = 3.2991
	sim_grads_norm = -0.0065
-- Starting training on experience 150 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5353
	data_grads_norm = 3.7625
	new_data_grads_norm = 5.5518
	old_data_grads_norm = 4.1860
	sim_grads_norm = 0.1485
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3639
	data_grads_norm = 3.5556
	new_data_grads_norm = 5.0223
	old_data_grads_norm = 4.8635
	sim_grads_norm = -0.0090
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4338
	data_grads_norm = 4.1373
	new_data_grads_norm = 5.0737
	old_data_grads_norm = 5.0647
	sim_grads_norm = -0.0062
-- Starting training on experience 151 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9083
	data_grads_norm = 3.5359
	new_data_grads_norm = 5.1891
	old_data_grads_norm = 4.9763
	sim_grads_norm = 0.0111
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9736
	data_grads_norm = 3.3264
	new_data_grads_norm = 4.8331
	old_data_grads_norm = 4.3300
	sim_grads_norm = -0.0451
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1386
	data_grads_norm = 3.5386
	new_data_grads_norm = 4.8889
	old_data_grads_norm = 3.9867
	sim_grads_norm = 0.1270
-- Starting training on experience 152 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6520
	data_grads_norm = 3.2972
	new_data_grads_norm = 4.5689
	old_data_grads_norm = 4.8794
	sim_grads_norm = -0.0127
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2997
	data_grads_norm = 3.7998
	new_data_grads_norm = 4.5335
	old_data_grads_norm = 5.2657
	sim_grads_norm = 0.0259
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2167
	data_grads_norm = 3.5582
	new_data_grads_norm = 4.9727
	old_data_grads_norm = 4.4325
	sim_grads_norm = 0.0823
-- Starting training on experience 153 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8779
	data_grads_norm = 3.4443
	new_data_grads_norm = 4.9773
	old_data_grads_norm = 4.8387
	sim_grads_norm = 0.0124
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1919
	data_grads_norm = 3.5151
	new_data_grads_norm = 4.9836
	old_data_grads_norm = 5.1010
	sim_grads_norm = -0.0817
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2612
	data_grads_norm = 3.8030
	new_data_grads_norm = 5.0114
	old_data_grads_norm = 6.0634
	sim_grads_norm = 0.0830
-- Starting training on experience 154 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3789
	data_grads_norm = 4.0267
	new_data_grads_norm = 5.8149
	old_data_grads_norm = 4.4891
	sim_grads_norm = 0.0033
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2980
	data_grads_norm = 3.5433
	new_data_grads_norm = 5.2516
	old_data_grads_norm = 5.0108
	sim_grads_norm = -0.0346
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1022
	data_grads_norm = 3.7866
	new_data_grads_norm = 5.6140
	old_data_grads_norm = 5.3227
	sim_grads_norm = -0.0202
-- Starting training on experience 155 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7941
	data_grads_norm = 3.1133
	new_data_grads_norm = 4.9239
	old_data_grads_norm = 4.2206
	sim_grads_norm = 0.0369
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6376
	data_grads_norm = 3.2104
	new_data_grads_norm = 4.8059
	old_data_grads_norm = 4.6606
	sim_grads_norm = -0.0481
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8351
	data_grads_norm = 3.5971
	new_data_grads_norm = 4.8818
	old_data_grads_norm = 6.6477
	sim_grads_norm = -0.0298
-- Starting training on experience 156 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4252
	data_grads_norm = 3.9548
	new_data_grads_norm = 5.6386
	old_data_grads_norm = 4.8192
	sim_grads_norm = 0.1358
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1147
	data_grads_norm = 3.3862
	new_data_grads_norm = 5.3228
	old_data_grads_norm = 3.5521
	sim_grads_norm = -0.0298
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4003
	data_grads_norm = 4.0154
	new_data_grads_norm = 5.7405
	old_data_grads_norm = 4.5139
	sim_grads_norm = 0.0812
-- Starting training on experience 157 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1698
	data_grads_norm = 3.6610
	new_data_grads_norm = 5.3651
	old_data_grads_norm = 4.4892
	sim_grads_norm = 0.0228
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7656
	data_grads_norm = 3.2433
	new_data_grads_norm = 5.4342
	old_data_grads_norm = 3.9531
	sim_grads_norm = 0.0322
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7752
	data_grads_norm = 3.4284
	new_data_grads_norm = 5.4611
	old_data_grads_norm = 3.3448
	sim_grads_norm = -0.0532
-- Starting training on experience 158 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1152
	data_grads_norm = 3.5969
	new_data_grads_norm = 5.2445
	old_data_grads_norm = 4.9281
	sim_grads_norm = 0.0121
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0861
	data_grads_norm = 3.5207
	new_data_grads_norm = 5.1142
	old_data_grads_norm = 5.1962
	sim_grads_norm = -0.0289
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1634
	data_grads_norm = 3.7982
	new_data_grads_norm = 4.9049
	old_data_grads_norm = 5.4295
	sim_grads_norm = -0.0268
-- Starting training on experience 159 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2964
	data_grads_norm = 3.7838
	new_data_grads_norm = 6.4714
	old_data_grads_norm = 4.0213
	sim_grads_norm = -0.0185
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4941
	data_grads_norm = 4.1777
	new_data_grads_norm = 6.1394
	old_data_grads_norm = 4.8780
	sim_grads_norm = 0.0585
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7233
	data_grads_norm = 4.2597
	new_data_grads_norm = 6.2066
	old_data_grads_norm = 5.2105
	sim_grads_norm = 0.0016
-- Starting training on experience 160 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0844
	data_grads_norm = 3.3363
	new_data_grads_norm = 4.9727
	old_data_grads_norm = 4.4822
	sim_grads_norm = -0.0262
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4202
	data_grads_norm = 3.4748
	new_data_grads_norm = 4.9946
	old_data_grads_norm = 4.7883
	sim_grads_norm = -0.0386
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5334
	data_grads_norm = 4.1109
	new_data_grads_norm = 5.1321
	old_data_grads_norm = 5.7294
	sim_grads_norm = 0.0696
-- Starting training on experience 161 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4517
	data_grads_norm = 3.6967
	new_data_grads_norm = 5.4590
	old_data_grads_norm = 5.3811
	sim_grads_norm = -0.0445
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5350
	data_grads_norm = 4.0309
	new_data_grads_norm = 6.0883
	old_data_grads_norm = 5.3002
	sim_grads_norm = 0.0084
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2142
	data_grads_norm = 3.3760
	new_data_grads_norm = 5.9327
	old_data_grads_norm = 2.3299
	sim_grads_norm = -0.0069
-- Starting training on experience 162 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1177
	data_grads_norm = 3.8054
	new_data_grads_norm = 4.7725
	old_data_grads_norm = 5.3832
	sim_grads_norm = 0.0405
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2684
	data_grads_norm = 4.5817
	new_data_grads_norm = 5.2281
	old_data_grads_norm = 5.8203
	sim_grads_norm = 0.0042
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2773
	data_grads_norm = 4.1824
	new_data_grads_norm = 5.1197
	old_data_grads_norm = 5.7399
	sim_grads_norm = -0.0317
-- Starting training on experience 163 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8684
	data_grads_norm = 3.9097
	new_data_grads_norm = 5.9543
	old_data_grads_norm = 5.6006
	sim_grads_norm = 0.0191
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1507
	data_grads_norm = 3.9937
	new_data_grads_norm = 6.1459
	old_data_grads_norm = 5.4052
	sim_grads_norm = 0.0388
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0583
	data_grads_norm = 3.6114
	new_data_grads_norm = 6.2192
	old_data_grads_norm = 4.3447
	sim_grads_norm = -0.0226
-- Starting training on experience 164 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8286
	data_grads_norm = 3.7285
	new_data_grads_norm = 5.3579
	old_data_grads_norm = 4.0556
	sim_grads_norm = -0.0510
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4371
	data_grads_norm = 4.1384
	new_data_grads_norm = 5.5237
	old_data_grads_norm = 4.7812
	sim_grads_norm = 0.0303
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7492
	data_grads_norm = 3.8548
	new_data_grads_norm = 5.7165
	old_data_grads_norm = 6.3630
	sim_grads_norm = -0.0194
-- Starting training on experience 165 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8292
	data_grads_norm = 3.2419
	new_data_grads_norm = 5.5416
	old_data_grads_norm = 3.4237
	sim_grads_norm = -0.0316
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2150
	data_grads_norm = 4.1552
	new_data_grads_norm = 5.5412
	old_data_grads_norm = 5.9664
	sim_grads_norm = -0.0193
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0373
	data_grads_norm = 3.3322
	new_data_grads_norm = 5.1784
	old_data_grads_norm = 3.8871
	sim_grads_norm = -0.0139
-- Starting training on experience 166 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2913
	data_grads_norm = 3.8991
	new_data_grads_norm = 4.7942
	old_data_grads_norm = 5.4854
	sim_grads_norm = 0.0604
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6988
	data_grads_norm = 3.0317
	new_data_grads_norm = 4.7806
	old_data_grads_norm = 3.5440
	sim_grads_norm = 0.0347
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0366
	data_grads_norm = 3.5585
	new_data_grads_norm = 4.5413
	old_data_grads_norm = 6.3982
	sim_grads_norm = -0.0341
-- Starting training on experience 167 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5429
	data_grads_norm = 4.2566
	new_data_grads_norm = 5.7902
	old_data_grads_norm = 5.8114
	sim_grads_norm = 0.0011
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1006
	data_grads_norm = 3.4899
	new_data_grads_norm = 6.0059
	old_data_grads_norm = 3.7987
	sim_grads_norm = 0.0128
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5078
	data_grads_norm = 4.5409
	new_data_grads_norm = 5.5876
	old_data_grads_norm = 6.3091
	sim_grads_norm = 0.0310
-- Starting training on experience 168 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5153
	data_grads_norm = 4.0164
	new_data_grads_norm = 5.9850
	old_data_grads_norm = 5.1412
	sim_grads_norm = -0.0026
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3764
	data_grads_norm = 3.5446
	new_data_grads_norm = 5.3749
	old_data_grads_norm = 4.2158
	sim_grads_norm = -0.0217
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3519
	data_grads_norm = 3.5650
	new_data_grads_norm = 5.7056
	old_data_grads_norm = 4.8380
	sim_grads_norm = -0.0136
-- Starting training on experience 169 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2545
	data_grads_norm = 3.7063
	new_data_grads_norm = 5.8761
	old_data_grads_norm = 4.0594
	sim_grads_norm = 0.0173
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7706
	data_grads_norm = 4.3409
	new_data_grads_norm = 6.0434
	old_data_grads_norm = 4.8458
	sim_grads_norm = 0.0854
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2134
	data_grads_norm = 3.8167
	new_data_grads_norm = 6.1802
	old_data_grads_norm = 4.9870
	sim_grads_norm = -0.0128
-- Starting training on experience 170 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8739
	data_grads_norm = 3.8878
	new_data_grads_norm = 5.9568
	old_data_grads_norm = 4.6090
	sim_grads_norm = 0.0286
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7057
	data_grads_norm = 4.5629
	new_data_grads_norm = 6.2709
	old_data_grads_norm = 6.1470
	sim_grads_norm = 0.0343
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4565
	data_grads_norm = 4.2316
	new_data_grads_norm = 6.5368
	old_data_grads_norm = 3.9000
	sim_grads_norm = 0.0457
-- Starting training on experience 171 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1818
	data_grads_norm = 4.1454
	new_data_grads_norm = 5.5037
	old_data_grads_norm = 6.0039
	sim_grads_norm = -0.0096
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1350
	data_grads_norm = 4.0204
	new_data_grads_norm = 5.1459
	old_data_grads_norm = 5.8249
	sim_grads_norm = 0.0299
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1021
	data_grads_norm = 3.8276
	new_data_grads_norm = 5.3763
	old_data_grads_norm = 6.4929
	sim_grads_norm = -0.0026
-- Starting training on experience 172 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6107
	data_grads_norm = 4.1705
	new_data_grads_norm = 5.4815
	old_data_grads_norm = 5.6900
	sim_grads_norm = 0.0232
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2531
	data_grads_norm = 3.8501
	new_data_grads_norm = 4.8919
	old_data_grads_norm = 4.7913
	sim_grads_norm = 0.0350
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2547
	data_grads_norm = 4.0188
	new_data_grads_norm = 5.3924
	old_data_grads_norm = 5.3336
	sim_grads_norm = -0.0243
-- Starting training on experience 173 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1844
	data_grads_norm = 3.8028
	new_data_grads_norm = 5.8197
	old_data_grads_norm = 4.6005
	sim_grads_norm = 0.0262
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2202
	data_grads_norm = 3.6919
	new_data_grads_norm = 6.3174
	old_data_grads_norm = 4.0717
	sim_grads_norm = -0.0005
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0431
	data_grads_norm = 3.5882
	new_data_grads_norm = 6.0584
	old_data_grads_norm = 4.3370
	sim_grads_norm = 0.0303
-- Starting training on experience 174 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6874
	data_grads_norm = 4.1396
	new_data_grads_norm = 6.1120
	old_data_grads_norm = 4.7578
	sim_grads_norm = 0.0502
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8568
	data_grads_norm = 4.3857
	new_data_grads_norm = 5.6601
	old_data_grads_norm = 5.8391
	sim_grads_norm = 0.0305
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8349
	data_grads_norm = 4.4664
	new_data_grads_norm = 5.7580
	old_data_grads_norm = 6.8642
	sim_grads_norm = -0.0264
-- Starting training on experience 175 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4531
	data_grads_norm = 4.5130
	new_data_grads_norm = 6.6091
	old_data_grads_norm = 6.6132
	sim_grads_norm = -0.0103
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2333
	data_grads_norm = 4.4767
	new_data_grads_norm = 6.7404
	old_data_grads_norm = 5.9644
	sim_grads_norm = -0.0100
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6349
	data_grads_norm = 5.1636
	new_data_grads_norm = 7.1090
	old_data_grads_norm = 5.7989
	sim_grads_norm = 0.0444
-- Starting training on experience 176 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4367
	data_grads_norm = 3.5936
	new_data_grads_norm = 4.8330
	old_data_grads_norm = 5.8509
	sim_grads_norm = 0.0216
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1549
	data_grads_norm = 3.3629
	new_data_grads_norm = 4.6423
	old_data_grads_norm = 4.9778
	sim_grads_norm = 0.0105
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9902
	data_grads_norm = 3.3184
	new_data_grads_norm = 5.2287
	old_data_grads_norm = 4.9482
	sim_grads_norm = -0.0571
-- Starting training on experience 177 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9679
	data_grads_norm = 4.6508
	new_data_grads_norm = 5.6919
	old_data_grads_norm = 6.9264
	sim_grads_norm = 0.0288
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9956
	data_grads_norm = 4.1064
	new_data_grads_norm = 5.4591
	old_data_grads_norm = 5.3469
	sim_grads_norm = -0.0095
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1391
	data_grads_norm = 3.9886
	new_data_grads_norm = 5.3138
	old_data_grads_norm = 6.6315
	sim_grads_norm = 0.0234
-- Starting training on experience 178 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2387
	data_grads_norm = 3.8233
	new_data_grads_norm = 5.5681
	old_data_grads_norm = 5.5704
	sim_grads_norm = 0.0243
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0702
	data_grads_norm = 3.5755
	new_data_grads_norm = 5.9026
	old_data_grads_norm = 4.2109
	sim_grads_norm = -0.0434
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7092
	data_grads_norm = 5.0040
	new_data_grads_norm = 5.4589
	old_data_grads_norm = 6.5201
	sim_grads_norm = -0.0162
-- Starting training on experience 179 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0822
	data_grads_norm = 3.8053
	new_data_grads_norm = 5.9429
	old_data_grads_norm = 4.2029
	sim_grads_norm = -0.0333
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3671
	data_grads_norm = 3.7618
	new_data_grads_norm = 5.6298
	old_data_grads_norm = 4.5859
	sim_grads_norm = 0.0484
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5559
	data_grads_norm = 4.0162
	new_data_grads_norm = 5.6105
	old_data_grads_norm = 5.6277
	sim_grads_norm = -0.0139
-- Starting training on experience 180 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4784
	data_grads_norm = 4.0942
	new_data_grads_norm = 5.0910
	old_data_grads_norm = 6.1846
	sim_grads_norm = -0.0470
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0651
	data_grads_norm = 3.4249
	new_data_grads_norm = 5.7945
	old_data_grads_norm = 3.2117
	sim_grads_norm = 0.0089
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0241
	data_grads_norm = 3.1415
	new_data_grads_norm = 5.5257
	old_data_grads_norm = 2.8201
	sim_grads_norm = 0.1236
-- Starting training on experience 181 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4050
	data_grads_norm = 4.3297
	new_data_grads_norm = 5.5959
	old_data_grads_norm = 6.5339
	sim_grads_norm = 0.0268
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8472
	data_grads_norm = 3.3442
	new_data_grads_norm = 5.4787
	old_data_grads_norm = 3.6936
	sim_grads_norm = -0.0299
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9010
	data_grads_norm = 3.4302
	new_data_grads_norm = 5.3695
	old_data_grads_norm = 4.1149
	sim_grads_norm = -0.0403
-- Starting training on experience 182 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4085
	data_grads_norm = 4.4090
	new_data_grads_norm = 6.2377
	old_data_grads_norm = 4.8221
	sim_grads_norm = 0.0305
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3183
	data_grads_norm = 3.9723
	new_data_grads_norm = 6.1671
	old_data_grads_norm = 4.3623
	sim_grads_norm = 0.0121
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9335
	data_grads_norm = 3.8038
	new_data_grads_norm = 6.1373
	old_data_grads_norm = 4.2994
	sim_grads_norm = 0.0024
-- Starting training on experience 183 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2212
	data_grads_norm = 3.9997
	new_data_grads_norm = 6.1157
	old_data_grads_norm = 4.5951
	sim_grads_norm = 0.0167
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4374
	data_grads_norm = 4.5467
	new_data_grads_norm = 5.4848
	old_data_grads_norm = 6.1803
	sim_grads_norm = 0.0464
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1821
	data_grads_norm = 4.9222
	new_data_grads_norm = 6.1555
	old_data_grads_norm = 6.4455
	sim_grads_norm = 0.0218
-- Starting training on experience 184 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5814
	data_grads_norm = 4.0419
	new_data_grads_norm = 5.9124
	old_data_grads_norm = 5.5455
	sim_grads_norm = 0.0233
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3079
	data_grads_norm = 4.1186
	new_data_grads_norm = 5.3754
	old_data_grads_norm = 5.6668
	sim_grads_norm = 0.0177
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6265
	data_grads_norm = 3.5705
	new_data_grads_norm = 5.7984
	old_data_grads_norm = 4.2727
	sim_grads_norm = 0.0163
-- Starting training on experience 185 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1567
	data_grads_norm = 4.4006
	new_data_grads_norm = 6.1240
	old_data_grads_norm = 5.8710
	sim_grads_norm = 0.0185
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8573
	data_grads_norm = 3.3289
	new_data_grads_norm = 6.0201
	old_data_grads_norm = 4.0757
	sim_grads_norm = 0.0166
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8881
	data_grads_norm = 3.7715
	new_data_grads_norm = 5.7119
	old_data_grads_norm = 4.7803
	sim_grads_norm = -0.0058
-- Starting training on experience 186 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9017
	data_grads_norm = 3.1482
	new_data_grads_norm = 5.3744
	old_data_grads_norm = 3.9834
	sim_grads_norm = 0.0081
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9597
	data_grads_norm = 3.5306
	new_data_grads_norm = 6.1633
	old_data_grads_norm = 3.5930
	sim_grads_norm = 0.0092
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1365
	data_grads_norm = 4.1801
	new_data_grads_norm = 6.6851
	old_data_grads_norm = 4.6620
	sim_grads_norm = -0.0152
-- Starting training on experience 187 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8229
	data_grads_norm = 3.0403
	new_data_grads_norm = 4.7745
	old_data_grads_norm = 4.6268
	sim_grads_norm = -0.0214
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7100
	data_grads_norm = 3.1496
	new_data_grads_norm = 4.8428
	old_data_grads_norm = 3.5888
	sim_grads_norm = -0.0714
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0924
	data_grads_norm = 3.7460
	new_data_grads_norm = 5.6314
	old_data_grads_norm = 4.2623
	sim_grads_norm = 0.0719
-- Starting training on experience 188 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1220
	data_grads_norm = 3.9295
	new_data_grads_norm = 5.5585
	old_data_grads_norm = 5.7674
	sim_grads_norm = 0.0212
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2492
	data_grads_norm = 3.8521
	new_data_grads_norm = 6.0236
	old_data_grads_norm = 4.1996
	sim_grads_norm = 0.1209
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2026
	data_grads_norm = 3.6726
	new_data_grads_norm = 5.3195
	old_data_grads_norm = 5.4598
	sim_grads_norm = -0.0491
-- Starting training on experience 189 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8059
	data_grads_norm = 4.8889
	new_data_grads_norm = 5.8260
	old_data_grads_norm = 7.0437
	sim_grads_norm = -0.0008
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1521
	data_grads_norm = 3.8723
	new_data_grads_norm = 6.0347
	old_data_grads_norm = 4.1020
	sim_grads_norm = -0.0342
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0814
	data_grads_norm = 3.7957
	new_data_grads_norm = 6.2707
	old_data_grads_norm = 4.0217
	sim_grads_norm = -0.0129
-- Starting training on experience 190 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5215
	data_grads_norm = 4.7615
	new_data_grads_norm = 7.5101
	old_data_grads_norm = 5.8301
	sim_grads_norm = 0.0003
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5998
	data_grads_norm = 4.8293
	new_data_grads_norm = 7.3826
	old_data_grads_norm = 4.5136
	sim_grads_norm = -0.0475
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0942
	data_grads_norm = 5.0469
	new_data_grads_norm = 7.7120
	old_data_grads_norm = 5.1831
	sim_grads_norm = -0.0095
-- Starting training on experience 191 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8752
	data_grads_norm = 3.3024
	new_data_grads_norm = 5.2759
	old_data_grads_norm = 4.7704
	sim_grads_norm = -0.0184
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2837
	data_grads_norm = 3.9961
	new_data_grads_norm = 5.3861
	old_data_grads_norm = 5.7319
	sim_grads_norm = -0.0450
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5773
	data_grads_norm = 3.9896
	new_data_grads_norm = 5.2726
	old_data_grads_norm = 5.5122
	sim_grads_norm = 0.0746
-- Starting training on experience 192 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9714
	data_grads_norm = 3.7643
	new_data_grads_norm = 5.7761
	old_data_grads_norm = 3.6196
	sim_grads_norm = -0.0062
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4286
	data_grads_norm = 4.2242
	new_data_grads_norm = 6.0597
	old_data_grads_norm = 5.5889
	sim_grads_norm = -0.0655
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4356
	data_grads_norm = 4.3147
	new_data_grads_norm = 6.2430
	old_data_grads_norm = 5.3763
	sim_grads_norm = 0.0606
-- Starting training on experience 193 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9188
	data_grads_norm = 4.7808
	new_data_grads_norm = 6.4870
	old_data_grads_norm = 4.8952
	sim_grads_norm = -0.0057
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2983
	data_grads_norm = 4.0581
	new_data_grads_norm = 6.0340
	old_data_grads_norm = 5.2974
	sim_grads_norm = -0.0230
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5899
	data_grads_norm = 4.0846
	new_data_grads_norm = 6.4488
	old_data_grads_norm = 3.7694
	sim_grads_norm = 0.0540
-- Starting training on experience 194 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7146
	data_grads_norm = 4.1762
	new_data_grads_norm = 6.1476
	old_data_grads_norm = 5.6642
	sim_grads_norm = 0.0019
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7640
	data_grads_norm = 4.4159
	new_data_grads_norm = 6.4922
	old_data_grads_norm = 5.5326
	sim_grads_norm = 0.0395
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4240
	data_grads_norm = 3.8185
	new_data_grads_norm = 6.8838
	old_data_grads_norm = 3.1988
	sim_grads_norm = -0.0211
-- Starting training on experience 195 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1920
	data_grads_norm = 4.1667
	new_data_grads_norm = 5.3689
	old_data_grads_norm = 5.7064
	sim_grads_norm = -0.0169
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3274
	data_grads_norm = 3.8011
	new_data_grads_norm = 5.5269
	old_data_grads_norm = 5.0713
	sim_grads_norm = 0.0069
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4262
	data_grads_norm = 4.3193
	new_data_grads_norm = 5.3337
	old_data_grads_norm = 6.0657
	sim_grads_norm = 0.0137
-- Starting training on experience 196 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0706
	data_grads_norm = 3.7497
	new_data_grads_norm = 6.3345
	old_data_grads_norm = 4.2553
	sim_grads_norm = 0.0087
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7469
	data_grads_norm = 4.2639
	new_data_grads_norm = 6.2646
	old_data_grads_norm = 4.8484
	sim_grads_norm = 0.0682
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2640
	data_grads_norm = 4.2498
	new_data_grads_norm = 6.2709
	old_data_grads_norm = 5.3322
	sim_grads_norm = 0.0334
-- Starting training on experience 197 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8678
	data_grads_norm = 3.7467
	new_data_grads_norm = 6.4315
	old_data_grads_norm = 4.1338
	sim_grads_norm = -0.0785
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4441
	data_grads_norm = 4.7727
	new_data_grads_norm = 6.8072
	old_data_grads_norm = 5.2478
	sim_grads_norm = 0.1129
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4001
	data_grads_norm = 4.2345
	new_data_grads_norm = 6.5036
	old_data_grads_norm = 4.1145
	sim_grads_norm = 0.0054
-- Starting training on experience 198 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7731
	data_grads_norm = 4.2699
	new_data_grads_norm = 6.1632
	old_data_grads_norm = 5.3219
	sim_grads_norm = 0.0337
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4887
	data_grads_norm = 3.5743
	new_data_grads_norm = 5.6273
	old_data_grads_norm = 3.8980
	sim_grads_norm = 0.0239
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8793
	data_grads_norm = 4.5193
	new_data_grads_norm = 6.3201
	old_data_grads_norm = 4.9899
	sim_grads_norm = 0.0250
-- Starting training on experience 199 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9377
	data_grads_norm = 5.0917
	new_data_grads_norm = 6.7695
	old_data_grads_norm = 7.0697
	sim_grads_norm = -0.0089
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6838
	data_grads_norm = 4.2776
	new_data_grads_norm = 7.2099
	old_data_grads_norm = 5.6942
	sim_grads_norm = -0.0229
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2011
	data_grads_norm = 4.8334
	new_data_grads_norm = 6.9517
	old_data_grads_norm = 5.4950
	sim_grads_norm = 0.0774
-- Starting training on experience 200 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1437
	data_grads_norm = 3.4383
	new_data_grads_norm = 5.6210
	old_data_grads_norm = 4.4647
	sim_grads_norm = -0.0499
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3971
	data_grads_norm = 4.0259
	new_data_grads_norm = 5.6625
	old_data_grads_norm = 5.7146
	sim_grads_norm = 0.0013
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3609
	data_grads_norm = 3.8304
	new_data_grads_norm = 5.4283
	old_data_grads_norm = 5.8589
	sim_grads_norm = -0.0236
-- Starting training on experience 201 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0518
	data_grads_norm = 4.6149
	new_data_grads_norm = 5.4758
	old_data_grads_norm = 6.4559
	sim_grads_norm = 0.0866
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2690
	data_grads_norm = 4.1887
	new_data_grads_norm = 5.6849
	old_data_grads_norm = 5.4999
	sim_grads_norm = -0.0200
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9365
	data_grads_norm = 3.6139
	new_data_grads_norm = 5.6158
	old_data_grads_norm = 4.4464
	sim_grads_norm = 0.0259
-- Starting training on experience 202 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0071
	data_grads_norm = 4.9661
	new_data_grads_norm = 7.4282
	old_data_grads_norm = 6.0636
	sim_grads_norm = 0.0220
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7335
	data_grads_norm = 4.2979
	new_data_grads_norm = 7.3282
	old_data_grads_norm = 5.1179
	sim_grads_norm = -0.0446
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8309
	data_grads_norm = 4.4354
	new_data_grads_norm = 7.3212
	old_data_grads_norm = 3.8520
	sim_grads_norm = 0.0086
-- Starting training on experience 203 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4275
	data_grads_norm = 4.1544
	new_data_grads_norm = 5.3671
	old_data_grads_norm = 5.4906
	sim_grads_norm = 0.0544
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3444
	data_grads_norm = 3.6741
	new_data_grads_norm = 4.7287
	old_data_grads_norm = 5.2848
	sim_grads_norm = -0.0127
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2124
	data_grads_norm = 3.8448
	new_data_grads_norm = 5.5822
	old_data_grads_norm = 4.4186
	sim_grads_norm = 0.0428
-- Starting training on experience 204 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9643
	data_grads_norm = 3.8070
	new_data_grads_norm = 6.4259
	old_data_grads_norm = 4.5387
	sim_grads_norm = -0.0127
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6436
	data_grads_norm = 4.6029
	new_data_grads_norm = 6.8478
	old_data_grads_norm = 5.6818
	sim_grads_norm = 0.0523
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8700
	data_grads_norm = 3.6526
	new_data_grads_norm = 6.3407
	old_data_grads_norm = 4.8141
	sim_grads_norm = -0.0291
-- Starting training on experience 205 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0290
	data_grads_norm = 3.9711
	new_data_grads_norm = 6.5123
	old_data_grads_norm = 4.6949
	sim_grads_norm = -0.0277
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9203
	data_grads_norm = 4.0766
	new_data_grads_norm = 6.7470
	old_data_grads_norm = 4.5955
	sim_grads_norm = 0.0041
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1397
	data_grads_norm = 4.0269
	new_data_grads_norm = 6.6180
	old_data_grads_norm = 4.8638
	sim_grads_norm = 0.0523
-- Starting training on experience 206 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8116
	data_grads_norm = 4.5379
	new_data_grads_norm = 5.7415
	old_data_grads_norm = 5.5394
	sim_grads_norm = 0.0144
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5907
	data_grads_norm = 3.5285
	new_data_grads_norm = 5.6568
	old_data_grads_norm = 3.3378
	sim_grads_norm = 0.0704
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4779
	data_grads_norm = 3.6611
	new_data_grads_norm = 5.5109
	old_data_grads_norm = 4.0664
	sim_grads_norm = 0.0010
-- Starting training on experience 207 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6949
	data_grads_norm = 3.9638
	new_data_grads_norm = 5.0942
	old_data_grads_norm = 5.6424
	sim_grads_norm = 0.0262
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3509
	data_grads_norm = 4.2506
	new_data_grads_norm = 5.6024
	old_data_grads_norm = 5.4544
	sim_grads_norm = 0.0200
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3262
	data_grads_norm = 3.6670
	new_data_grads_norm = 5.2162
	old_data_grads_norm = 5.2443
	sim_grads_norm = -0.0188
-- Starting training on experience 208 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6302
	data_grads_norm = 3.0707
	new_data_grads_norm = 5.9218
	old_data_grads_norm = 3.7640
	sim_grads_norm = -0.0184
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8088
	data_grads_norm = 3.6139
	new_data_grads_norm = 5.4680
	old_data_grads_norm = 5.0334
	sim_grads_norm = -0.0832
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2048
	data_grads_norm = 3.6284
	new_data_grads_norm = 6.1245
	old_data_grads_norm = 4.6714
	sim_grads_norm = 0.0268
-- Starting training on experience 209 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8764
	data_grads_norm = 4.0515
	new_data_grads_norm = 5.1829
	old_data_grads_norm = 4.4276
	sim_grads_norm = 0.0122
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1509
	data_grads_norm = 3.5253
	new_data_grads_norm = 4.8475
	old_data_grads_norm = 4.6933
	sim_grads_norm = 0.0451
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6322
	data_grads_norm = 3.3625
	new_data_grads_norm = 5.2341
	old_data_grads_norm = 3.9672
	sim_grads_norm = 0.0576
-- Starting training on experience 210 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2082
	data_grads_norm = 4.0286
	new_data_grads_norm = 5.3867
	old_data_grads_norm = 6.0073
	sim_grads_norm = 0.0410
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6257
	data_grads_norm = 2.9600
	new_data_grads_norm = 5.7245
	old_data_grads_norm = 3.8102
	sim_grads_norm = -0.0231
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0126
	data_grads_norm = 3.4100
	new_data_grads_norm = 4.9175
	old_data_grads_norm = 4.5186
	sim_grads_norm = 0.0548
-- Starting training on experience 211 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2815
	data_grads_norm = 3.8215
	new_data_grads_norm = 5.5495
	old_data_grads_norm = 3.9230
	sim_grads_norm = -0.0017
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3144
	data_grads_norm = 3.7925
	new_data_grads_norm = 5.5081
	old_data_grads_norm = 5.3990
	sim_grads_norm = -0.0426
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6731
	data_grads_norm = 4.4766
	new_data_grads_norm = 5.4853
	old_data_grads_norm = 6.5279
	sim_grads_norm = -0.0070
-- Starting training on experience 212 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1302
	data_grads_norm = 4.6326
	new_data_grads_norm = 5.6206
	old_data_grads_norm = 7.2885
	sim_grads_norm = 0.0119
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8615
	data_grads_norm = 3.7702
	new_data_grads_norm = 5.7930
	old_data_grads_norm = 5.5610
	sim_grads_norm = -0.0247
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6168
	data_grads_norm = 4.5538
	new_data_grads_norm = 5.7082
	old_data_grads_norm = 6.0184
	sim_grads_norm = 0.0352
-- Starting training on experience 213 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4813
	data_grads_norm = 4.3720
	new_data_grads_norm = 6.5949
	old_data_grads_norm = 5.8549
	sim_grads_norm = -0.0396
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8400
	data_grads_norm = 3.4979
	new_data_grads_norm = 6.7145
	old_data_grads_norm = 4.8913
	sim_grads_norm = 0.0121
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6872
	data_grads_norm = 4.6296
	new_data_grads_norm = 6.6854
	old_data_grads_norm = 6.6968
	sim_grads_norm = 0.0037
-- Starting training on experience 214 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6297
	data_grads_norm = 5.1051
	new_data_grads_norm = 7.1053
	old_data_grads_norm = 5.2302
	sim_grads_norm = 0.0104
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1097
	data_grads_norm = 4.4130
	new_data_grads_norm = 6.4470
	old_data_grads_norm = 3.7617
	sim_grads_norm = -0.0072
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3078
	data_grads_norm = 4.1878
	new_data_grads_norm = 7.0112
	old_data_grads_norm = 4.7003
	sim_grads_norm = 0.0018
-- Starting training on experience 215 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2590
	data_grads_norm = 3.9239
	new_data_grads_norm = 5.9826
	old_data_grads_norm = 5.1991
	sim_grads_norm = -0.0149
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5223
	data_grads_norm = 4.2870
	new_data_grads_norm = 5.7935
	old_data_grads_norm = 5.6995
	sim_grads_norm = -0.0461
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0922
	data_grads_norm = 5.0308
	new_data_grads_norm = 5.8571
	old_data_grads_norm = 7.4220
	sim_grads_norm = 0.0200
-- Starting training on experience 216 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0758
	data_grads_norm = 3.9372
	new_data_grads_norm = 5.4627
	old_data_grads_norm = 2.8004
	sim_grads_norm = 0.0763
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9620
	data_grads_norm = 3.6874
	new_data_grads_norm = 5.2927
	old_data_grads_norm = 4.4737
	sim_grads_norm = 0.0384
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5665
	data_grads_norm = 4.1390
	new_data_grads_norm = 5.1573
	old_data_grads_norm = 6.0368
	sim_grads_norm = 0.0433
-- Starting training on experience 217 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0246
	data_grads_norm = 4.4427
	new_data_grads_norm = 7.4440
	old_data_grads_norm = 5.3592
	sim_grads_norm = -0.0363
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9092
	data_grads_norm = 4.0805
	new_data_grads_norm = 6.8279
	old_data_grads_norm = 5.5853
	sim_grads_norm = -0.0024
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6271
	data_grads_norm = 3.1769
	new_data_grads_norm = 6.7313
	old_data_grads_norm = 3.2633
	sim_grads_norm = -0.0522
-- Starting training on experience 218 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1434
	data_grads_norm = 4.1545
	new_data_grads_norm = 7.1090
	old_data_grads_norm = 3.7277
	sim_grads_norm = -0.0214
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6329
	data_grads_norm = 4.7947
	new_data_grads_norm = 7.2091
	old_data_grads_norm = 4.9331
	sim_grads_norm = 0.0385
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5342
	data_grads_norm = 5.1435
	new_data_grads_norm = 6.9069
	old_data_grads_norm = 6.6958
	sim_grads_norm = 0.0496
-- Starting training on experience 219 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7855
	data_grads_norm = 5.0907
	new_data_grads_norm = 6.2390
	old_data_grads_norm = 5.4991
	sim_grads_norm = 0.0222
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2235
	data_grads_norm = 4.1898
	new_data_grads_norm = 6.1833
	old_data_grads_norm = 4.4406
	sim_grads_norm = 0.0036
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3931
	data_grads_norm = 4.5042
	new_data_grads_norm = 6.3358
	old_data_grads_norm = 4.2156
	sim_grads_norm = -0.0177
-- Starting training on experience 220 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8402
	data_grads_norm = 3.5461
	new_data_grads_norm = 5.0261
	old_data_grads_norm = 3.8957
	sim_grads_norm = 0.1062
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0291
	data_grads_norm = 4.6394
	new_data_grads_norm = 5.4756
	old_data_grads_norm = 7.1811
	sim_grads_norm = -0.0306
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3043
	data_grads_norm = 3.7439
	new_data_grads_norm = 4.9047
	old_data_grads_norm = 4.6138
	sim_grads_norm = 0.1448
-- Starting training on experience 221 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6097
	data_grads_norm = 3.6888
	new_data_grads_norm = 5.8581
	old_data_grads_norm = 3.7473
	sim_grads_norm = 0.0365
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0979
	data_grads_norm = 4.3542
	new_data_grads_norm = 6.4687
	old_data_grads_norm = 5.7877
	sim_grads_norm = -0.0364
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9413
	data_grads_norm = 4.3495
	new_data_grads_norm = 6.6625
	old_data_grads_norm = 4.8650
	sim_grads_norm = -0.0169
-- Starting training on experience 222 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1642
	data_grads_norm = 3.5600
	new_data_grads_norm = 5.0698
	old_data_grads_norm = 5.2782
	sim_grads_norm = -0.0280
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7677
	data_grads_norm = 3.5676
	new_data_grads_norm = 4.9870
	old_data_grads_norm = 5.5662
	sim_grads_norm = -0.0077
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6240
	data_grads_norm = 3.4111
	new_data_grads_norm = 5.5830
	old_data_grads_norm = 4.1219
	sim_grads_norm = 0.0001
-- Starting training on experience 223 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5374
	data_grads_norm = 3.8085
	new_data_grads_norm = 5.1381
	old_data_grads_norm = 5.0701
	sim_grads_norm = -0.0117
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6486
	data_grads_norm = 3.7238
	new_data_grads_norm = 5.5155
	old_data_grads_norm = 5.9241
	sim_grads_norm = 0.0199
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7658
	data_grads_norm = 4.1727
	new_data_grads_norm = 5.3999
	old_data_grads_norm = 5.6157
	sim_grads_norm = 0.0127
-- Starting training on experience 224 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5230
	data_grads_norm = 4.1334
	new_data_grads_norm = 6.0497
	old_data_grads_norm = 5.1252
	sim_grads_norm = 0.0210
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5845
	data_grads_norm = 4.2442
	new_data_grads_norm = 6.1147
	old_data_grads_norm = 5.6341
	sim_grads_norm = 0.0442
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7984
	data_grads_norm = 3.3487
	new_data_grads_norm = 6.0154
	old_data_grads_norm = 3.8398
	sim_grads_norm = -0.0257
-- Starting training on experience 225 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2637
	data_grads_norm = 3.8612
	new_data_grads_norm = 6.5603
	old_data_grads_norm = 4.7687
	sim_grads_norm = -0.0547
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7866
	data_grads_norm = 4.5694
	new_data_grads_norm = 6.3839
	old_data_grads_norm = 6.1619
	sim_grads_norm = -0.0041
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6282
	data_grads_norm = 4.3496
	new_data_grads_norm = 6.5517
	old_data_grads_norm = 4.7268
	sim_grads_norm = 0.0286
-- Starting training on experience 226 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0056
	data_grads_norm = 3.3340
	new_data_grads_norm = 5.5289
	old_data_grads_norm = 3.6864
	sim_grads_norm = 0.0183
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7688
	data_grads_norm = 4.2626
	new_data_grads_norm = 5.1912
	old_data_grads_norm = 6.6756
	sim_grads_norm = 0.0917
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1480
	data_grads_norm = 3.6828
	new_data_grads_norm = 5.1829
	old_data_grads_norm = 4.1690
	sim_grads_norm = 0.0845
-- Starting training on experience 227 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3386
	data_grads_norm = 3.6144
	new_data_grads_norm = 4.7766
	old_data_grads_norm = 5.8692
	sim_grads_norm = -0.0450
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8689
	data_grads_norm = 4.8394
	new_data_grads_norm = 5.0970
	old_data_grads_norm = 8.8431
	sim_grads_norm = -0.0237
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5660
	data_grads_norm = 4.0256
	new_data_grads_norm = 5.0849
	old_data_grads_norm = 5.8892
	sim_grads_norm = 0.0278
-- Starting training on experience 228 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4478
	data_grads_norm = 3.8355
	new_data_grads_norm = 5.7096
	old_data_grads_norm = 4.2868
	sim_grads_norm = 0.0869
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9576
	data_grads_norm = 3.4714
	new_data_grads_norm = 5.2761
	old_data_grads_norm = 4.1748
	sim_grads_norm = 0.0150
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6092
	data_grads_norm = 4.0705
	new_data_grads_norm = 5.4692
	old_data_grads_norm = 5.2493
	sim_grads_norm = -0.0055
-- Starting training on experience 229 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1637
	data_grads_norm = 3.7407
	new_data_grads_norm = 5.0832
	old_data_grads_norm = 6.4776
	sim_grads_norm = -0.0344
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2688
	data_grads_norm = 4.0681
	new_data_grads_norm = 5.4409
	old_data_grads_norm = 5.8607
	sim_grads_norm = -0.0178
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3774
	data_grads_norm = 3.5513
	new_data_grads_norm = 5.3595
	old_data_grads_norm = 3.7925
	sim_grads_norm = 0.0084
-- Starting training on experience 230 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2482
	data_grads_norm = 3.6572
	new_data_grads_norm = 5.5836
	old_data_grads_norm = 5.2127
	sim_grads_norm = -0.0345
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0944
	data_grads_norm = 3.0324
	new_data_grads_norm = 5.4865
	old_data_grads_norm = 2.6968
	sim_grads_norm = -0.0398
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3585
	data_grads_norm = 4.3136
	new_data_grads_norm = 5.7942
	old_data_grads_norm = 5.9820
	sim_grads_norm = 0.0682
-- Starting training on experience 231 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1907
	data_grads_norm = 3.3885
	new_data_grads_norm = 4.7474
	old_data_grads_norm = 5.6745
	sim_grads_norm = 0.0419
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9477
	data_grads_norm = 4.0710
	new_data_grads_norm = 4.8435
	old_data_grads_norm = 6.5475
	sim_grads_norm = -0.0251
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3835
	data_grads_norm = 3.9203
	new_data_grads_norm = 5.3761
	old_data_grads_norm = 5.9310
	sim_grads_norm = 0.0035
-- Starting training on experience 232 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2021
	data_grads_norm = 4.0580
	new_data_grads_norm = 5.8124
	old_data_grads_norm = 4.4938
	sim_grads_norm = 0.0867
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1179
	data_grads_norm = 4.3581
	new_data_grads_norm = 5.5211
	old_data_grads_norm = 5.4653
	sim_grads_norm = -0.0258
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2527
	data_grads_norm = 4.1129
	new_data_grads_norm = 6.2890
	old_data_grads_norm = 4.6540
	sim_grads_norm = 0.0152
-- Starting training on experience 233 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1876
	data_grads_norm = 4.2393
	new_data_grads_norm = 7.0663
	old_data_grads_norm = 4.1107
	sim_grads_norm = 0.0348
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5721
	data_grads_norm = 4.4396
	new_data_grads_norm = 6.5839
	old_data_grads_norm = 4.1037
	sim_grads_norm = 0.1174
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4984
	data_grads_norm = 4.4140
	new_data_grads_norm = 6.1910
	old_data_grads_norm = 5.6794
	sim_grads_norm = -0.0114
-- Starting training on experience 234 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9953
	data_grads_norm = 3.6554
	new_data_grads_norm = 5.3585
	old_data_grads_norm = 5.7146
	sim_grads_norm = -0.0162
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2197
	data_grads_norm = 3.5248
	new_data_grads_norm = 5.7840
	old_data_grads_norm = 4.9919
	sim_grads_norm = -0.0341
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9154
	data_grads_norm = 3.5390
	new_data_grads_norm = 6.0515
	old_data_grads_norm = 4.8072
	sim_grads_norm = -0.0006
-- Starting training on experience 235 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2102
	data_grads_norm = 4.5470
	new_data_grads_norm = 6.3137
	old_data_grads_norm = 5.1201
	sim_grads_norm = 0.0584
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8040
	data_grads_norm = 4.9347
	new_data_grads_norm = 6.0697
	old_data_grads_norm = 5.8944
	sim_grads_norm = 0.0105
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9046
	data_grads_norm = 3.8270
	new_data_grads_norm = 6.6247
	old_data_grads_norm = 3.9267
	sim_grads_norm = 0.0009
-- Starting training on experience 236 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3351
	data_grads_norm = 3.8407
	new_data_grads_norm = 5.3329
	old_data_grads_norm = 5.6306
	sim_grads_norm = -0.0669
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1731
	data_grads_norm = 3.7233
	new_data_grads_norm = 5.4507
	old_data_grads_norm = 4.6237
	sim_grads_norm = -0.0548
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0845
	data_grads_norm = 4.3497
	new_data_grads_norm = 6.1723
	old_data_grads_norm = 6.4947
	sim_grads_norm = -0.0139
-- Starting training on experience 237 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
-- >> End of training phase << --
-- >> Start of eval phase << --
-- Starting eval on experience 0 (Task 0) from test stream --
> Eval on experience 0 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp000 = 4.2128
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.1440
	mb_index = 2856
	time = 703.1736
-- Starting eval on experience 1 (Task 0) from test stream --
> Eval on experience 1 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp001 = 2.6522
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.4340
-- Starting eval on experience 2 (Task 0) from test stream --
> Eval on experience 2 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp002 = 2.8644
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.3400
-- Starting eval on experience 3 (Task 0) from test stream --
> Eval on experience 3 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp003 = 2.3584
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.4920
-- Starting eval on experience 4 (Task 0) from test stream --
> Eval on experience 4 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp004 = 3.3320
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.2640
-- Starting eval on experience 5 (Task 0) from test stream --
> Eval on experience 5 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp005 = 2.7171
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.4000
-- Starting eval on experience 6 (Task 0) from test stream --
> Eval on experience 6 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp006 = 3.3479
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp006 = 0.2100
-- Starting eval on experience 7 (Task 0) from test stream --
> Eval on experience 7 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp007 = 2.4178
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp007 = 0.4540
-- Starting eval on experience 8 (Task 0) from test stream --
> Eval on experience 8 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp008 = 2.7747
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp008 = 0.3480
-- Starting eval on experience 9 (Task 0) from test stream --
> Eval on experience 9 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp009 = 2.5067
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp009 = 0.3120
-- Starting eval on experience 10 (Task 0) from test stream --
> Eval on experience 10 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp010 = 3.4833
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp010 = 0.1900
-- Starting eval on experience 11 (Task 0) from test stream --
> Eval on experience 11 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp011 = 2.8999
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp011 = 0.2700
-- >> End of eval phase << --
	CumulativeAccuracy/eval_phase/test_stream/Exp000 = 0.7220
	CumulativeAccuracy/eval_phase/test_stream/Exp001 = 0.6780
	CumulativeAccuracy/eval_phase/test_stream/Exp002 = 0.5853
	CumulativeAccuracy/eval_phase/test_stream/Exp003 = 0.5435
	CumulativeAccuracy/eval_phase/test_stream/Exp004 = 0.4876
	CumulativeAccuracy/eval_phase/test_stream/Exp005 = 0.4450
	CumulativeAccuracy/eval_phase/test_stream/Exp006 = 0.4117
	CumulativeAccuracy/eval_phase/test_stream/Exp007 = 0.3827
	CumulativeAccuracy/eval_phase/test_stream/Exp008 = 0.3671
	CumulativeAccuracy/eval_phase/test_stream/Exp009 = 0.3566
	CumulativeAccuracy/eval_phase/test_stream/Exp010 = 0.3320
	CumulativeAccuracy/eval_phase/test_stream/Exp011 = 0.3215
	Loss_Stream/eval_phase/test_stream/Task000 = 2.9639
	Top1_Acc_Stream/eval_phase/test_stream/Task000 = 0.3215
-- >> Start of training phase << --
-- Starting training on experience 0 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3325
	data_grads_norm = 4.0281
	new_data_grads_norm = 5.9195
	old_data_grads_norm = 5.6602
	sim_grads_norm = 0.0310
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0379
	data_grads_norm = 3.8951
	new_data_grads_norm = 5.5914
	old_data_grads_norm = 5.3409
	sim_grads_norm = 0.0185
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0554
	data_grads_norm = 3.5190
	new_data_grads_norm = 5.8080
	old_data_grads_norm = 4.7766
	sim_grads_norm = -0.0165
-- Starting training on experience 1 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.7244
	data_grads_norm = 3.9706
	new_data_grads_norm = 5.5203
	old_data_grads_norm = 5.3819
	sim_grads_norm = 0.0029
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1517
	data_grads_norm = 3.7889
	new_data_grads_norm = 5.6448
	old_data_grads_norm = 4.1318
	sim_grads_norm = -0.0052
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4055
	data_grads_norm = 4.1586
	new_data_grads_norm = 5.9066
	old_data_grads_norm = 5.5246
	sim_grads_norm = 0.0102
-- Starting training on experience 2 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3117
	data_grads_norm = 4.5117
	new_data_grads_norm = 5.1778
	old_data_grads_norm = 7.0430
	sim_grads_norm = 0.0605
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9191
	data_grads_norm = 3.6074
	new_data_grads_norm = 4.7862
	old_data_grads_norm = 5.0657
	sim_grads_norm = -0.0159
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4916
	data_grads_norm = 3.7266
	new_data_grads_norm = 5.1285
	old_data_grads_norm = 4.9081
	sim_grads_norm = 0.0014
-- Starting training on experience 3 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3363
	data_grads_norm = 4.3498
	new_data_grads_norm = 5.5765
	old_data_grads_norm = 5.4804
	sim_grads_norm = 0.0122
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.1269
	data_grads_norm = 4.8979
	new_data_grads_norm = 6.2183
	old_data_grads_norm = 6.1402
	sim_grads_norm = 0.0134
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4972
	data_grads_norm = 4.0712
	new_data_grads_norm = 5.9579
	old_data_grads_norm = 5.1175
	sim_grads_norm = 0.0099
-- Starting training on experience 4 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7649
	data_grads_norm = 3.3905
	new_data_grads_norm = 5.8543
	old_data_grads_norm = 3.4585
	sim_grads_norm = 0.0371
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5172
	data_grads_norm = 3.6632
	new_data_grads_norm = 4.7265
	old_data_grads_norm = 4.8048
	sim_grads_norm = 0.1253
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7316
	data_grads_norm = 3.4422
	new_data_grads_norm = 4.9978
	old_data_grads_norm = 5.3838
	sim_grads_norm = 0.0089
-- Starting training on experience 5 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2501
	data_grads_norm = 4.5262
	new_data_grads_norm = 6.6662
	old_data_grads_norm = 5.2523
	sim_grads_norm = -0.0033
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0613
	data_grads_norm = 4.0896
	new_data_grads_norm = 5.9111
	old_data_grads_norm = 5.0573
	sim_grads_norm = -0.0090
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1287
	data_grads_norm = 4.1634
	new_data_grads_norm = 6.1196
	old_data_grads_norm = 5.7140
	sim_grads_norm = 0.0058
-- Starting training on experience 6 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9650
	data_grads_norm = 3.9508
	new_data_grads_norm = 5.3720
	old_data_grads_norm = 5.6697
	sim_grads_norm = 0.0017
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2628
	data_grads_norm = 3.9988
	new_data_grads_norm = 6.3026
	old_data_grads_norm = 5.4651
	sim_grads_norm = -0.0185
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2789
	data_grads_norm = 4.1280
	new_data_grads_norm = 5.9517
	old_data_grads_norm = 5.2209
	sim_grads_norm = 0.0437
-- Starting training on experience 7 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8487
	data_grads_norm = 3.8459
	new_data_grads_norm = 5.5426
	old_data_grads_norm = 4.3839
	sim_grads_norm = -0.0314
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0701
	data_grads_norm = 3.9362
	new_data_grads_norm = 5.6985
	old_data_grads_norm = 4.9517
	sim_grads_norm = -0.0199
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4641
	data_grads_norm = 4.1528
	new_data_grads_norm = 6.0160
	old_data_grads_norm = 5.1348
	sim_grads_norm = 0.0505
-- Starting training on experience 8 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1278
	data_grads_norm = 4.1569
	new_data_grads_norm = 6.2309
	old_data_grads_norm = 4.4791
	sim_grads_norm = 0.0075
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2044
	data_grads_norm = 4.2435
	new_data_grads_norm = 5.7936
	old_data_grads_norm = 5.6809
	sim_grads_norm = -0.0158
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0501
	data_grads_norm = 4.1105
	new_data_grads_norm = 6.1088
	old_data_grads_norm = 5.4516
	sim_grads_norm = 0.0255
-- Starting training on experience 9 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2177
	data_grads_norm = 4.1793
	new_data_grads_norm = 5.5709
	old_data_grads_norm = 5.3841
	sim_grads_norm = -0.0133
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3820
	data_grads_norm = 4.4890
	new_data_grads_norm = 5.1736
	old_data_grads_norm = 6.2079
	sim_grads_norm = -0.0036
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9353
	data_grads_norm = 3.5837
	new_data_grads_norm = 5.9792
	old_data_grads_norm = 3.4822
	sim_grads_norm = 0.0326
-- Starting training on experience 10 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6761
	data_grads_norm = 4.5952
	new_data_grads_norm = 6.3101
	old_data_grads_norm = 5.9571
	sim_grads_norm = 0.0272
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3984
	data_grads_norm = 4.3730
	new_data_grads_norm = 5.7369
	old_data_grads_norm = 6.4286
	sim_grads_norm = 0.0094
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8418
	data_grads_norm = 3.5511
	new_data_grads_norm = 5.9073
	old_data_grads_norm = 4.1992
	sim_grads_norm = -0.0007
-- Starting training on experience 11 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5067
	data_grads_norm = 3.9209
	new_data_grads_norm = 6.0586
	old_data_grads_norm = 4.3807
	sim_grads_norm = 0.1428
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3214
	data_grads_norm = 4.7703
	new_data_grads_norm = 5.8407
	old_data_grads_norm = 6.5707
	sim_grads_norm = -0.0149
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7576
	data_grads_norm = 3.4257
	new_data_grads_norm = 5.5828
	old_data_grads_norm = 4.2764
	sim_grads_norm = -0.0099
-- Starting training on experience 12 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5394
	data_grads_norm = 4.3515
	new_data_grads_norm = 5.7555
	old_data_grads_norm = 5.0550
	sim_grads_norm = 0.0031
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0020
	data_grads_norm = 3.5979
	new_data_grads_norm = 6.1512
	old_data_grads_norm = 4.4854
	sim_grads_norm = -0.0194
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7956
	data_grads_norm = 3.3940
	new_data_grads_norm = 5.6720
	old_data_grads_norm = 4.9035
	sim_grads_norm = -0.0359
-- Starting training on experience 13 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0916
	data_grads_norm = 3.6898
	new_data_grads_norm = 5.5282
	old_data_grads_norm = 5.7131
	sim_grads_norm = 0.0289
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9146
	data_grads_norm = 3.5023
	new_data_grads_norm = 4.7935
	old_data_grads_norm = 4.6740
	sim_grads_norm = 0.0575
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6996
	data_grads_norm = 3.4799
	new_data_grads_norm = 5.1339
	old_data_grads_norm = 5.7889
	sim_grads_norm = 0.0396
-- Starting training on experience 14 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8671
	data_grads_norm = 4.0334
	new_data_grads_norm = 5.4938
	old_data_grads_norm = 5.1419
	sim_grads_norm = 0.0338
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6586
	data_grads_norm = 4.3197
	new_data_grads_norm = 6.0414
	old_data_grads_norm = 4.7985
	sim_grads_norm = 0.0289
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5113
	data_grads_norm = 4.1959
	new_data_grads_norm = 5.6466
	old_data_grads_norm = 5.2954
	sim_grads_norm = 0.0031
-- Starting training on experience 15 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5502
	data_grads_norm = 3.8297
	new_data_grads_norm = 5.7115
	old_data_grads_norm = 4.7748
	sim_grads_norm = 0.0089
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8612
	data_grads_norm = 4.1668
	new_data_grads_norm = 5.7954
	old_data_grads_norm = 5.3514
	sim_grads_norm = 0.0093
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2196
	data_grads_norm = 4.1313
	new_data_grads_norm = 5.7338
	old_data_grads_norm = 5.0866
	sim_grads_norm = 0.0622
-- Starting training on experience 16 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5641
	data_grads_norm = 3.7067
	new_data_grads_norm = 4.9458
	old_data_grads_norm = 5.5298
	sim_grads_norm = 0.0445
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0224
	data_grads_norm = 3.5613
	new_data_grads_norm = 5.1933
	old_data_grads_norm = 3.7199
	sim_grads_norm = 0.0107
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8266
	data_grads_norm = 4.3680
	new_data_grads_norm = 5.6386
	old_data_grads_norm = 5.8273
	sim_grads_norm = 0.0031
-- Starting training on experience 17 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9460
	data_grads_norm = 3.0431
	new_data_grads_norm = 5.5266
	old_data_grads_norm = 3.1078
	sim_grads_norm = -0.0042
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4618
	data_grads_norm = 3.7927
	new_data_grads_norm = 5.4916
	old_data_grads_norm = 5.0720
	sim_grads_norm = 0.0124
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4699
	data_grads_norm = 4.2267
	new_data_grads_norm = 5.9160
	old_data_grads_norm = 5.6884
	sim_grads_norm = 0.0303
-- Starting training on experience 18 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8608
	data_grads_norm = 4.5758
	new_data_grads_norm = 5.4199
	old_data_grads_norm = 6.0997
	sim_grads_norm = 0.0224
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8707
	data_grads_norm = 4.2712
	new_data_grads_norm = 5.2023
	old_data_grads_norm = 6.1683
	sim_grads_norm = 0.0400
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2591
	data_grads_norm = 3.6784
	new_data_grads_norm = 5.2735
	old_data_grads_norm = 5.5030
	sim_grads_norm = -0.0326
-- Starting training on experience 19 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2082
	data_grads_norm = 3.6002
	new_data_grads_norm = 5.2232
	old_data_grads_norm = 5.0569
	sim_grads_norm = -0.0216
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3916
	data_grads_norm = 3.5228
	new_data_grads_norm = 5.2005
	old_data_grads_norm = 4.7387
	sim_grads_norm = 0.0071
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4018
	data_grads_norm = 3.7422
	new_data_grads_norm = 5.3658
	old_data_grads_norm = 4.3810
	sim_grads_norm = -0.0038
-- Starting training on experience 20 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8807
	data_grads_norm = 4.6685
	new_data_grads_norm = 5.3167
	old_data_grads_norm = 6.0206
	sim_grads_norm = 0.0192
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6039
	data_grads_norm = 3.8757
	new_data_grads_norm = 5.6195
	old_data_grads_norm = 4.0264
	sim_grads_norm = 0.0533
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4627
	data_grads_norm = 4.1741
	new_data_grads_norm = 5.1937
	old_data_grads_norm = 5.3289
	sim_grads_norm = 0.0204
-- Starting training on experience 21 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8632
	data_grads_norm = 4.3995
	new_data_grads_norm = 5.8525
	old_data_grads_norm = 6.9147
	sim_grads_norm = -0.0071
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3359
	data_grads_norm = 3.7756
	new_data_grads_norm = 6.0946
	old_data_grads_norm = 5.1865
	sim_grads_norm = 0.0311
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5077
	data_grads_norm = 3.5911
	new_data_grads_norm = 5.5339
	old_data_grads_norm = 4.2361
	sim_grads_norm = -0.0027
-- Starting training on experience 22 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6249
	data_grads_norm = 4.0539
	new_data_grads_norm = 6.1915
	old_data_grads_norm = 4.8282
	sim_grads_norm = 0.0667
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2640
	data_grads_norm = 3.7119
	new_data_grads_norm = 5.5257
	old_data_grads_norm = 4.3080
	sim_grads_norm = -0.0294
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3874
	data_grads_norm = 3.9667
	new_data_grads_norm = 5.7481
	old_data_grads_norm = 4.6014
	sim_grads_norm = 0.0133
-- Starting training on experience 23 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1630
	data_grads_norm = 3.5546
	new_data_grads_norm = 4.5439
	old_data_grads_norm = 4.4250
	sim_grads_norm = 0.0836
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4158
	data_grads_norm = 3.6765
	new_data_grads_norm = 5.3760
	old_data_grads_norm = 5.0249
	sim_grads_norm = 0.0898
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8116
	data_grads_norm = 3.2241
	new_data_grads_norm = 4.6865
	old_data_grads_norm = 4.9604
	sim_grads_norm = -0.0081
-- Starting training on experience 24 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1721
	data_grads_norm = 4.3898
	new_data_grads_norm = 5.8108
	old_data_grads_norm = 6.2616
	sim_grads_norm = 0.0263
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6523
	data_grads_norm = 3.7374
	new_data_grads_norm = 5.5019
	old_data_grads_norm = 4.4134
	sim_grads_norm = -0.0000
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3125
	data_grads_norm = 3.3271
	new_data_grads_norm = 5.4444
	old_data_grads_norm = 4.0063
	sim_grads_norm = -0.0172
-- Starting training on experience 25 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2577
	data_grads_norm = 4.1030
	new_data_grads_norm = 5.0748
	old_data_grads_norm = 6.3773
	sim_grads_norm = 0.0030
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7516
	data_grads_norm = 4.2255
	new_data_grads_norm = 5.2935
	old_data_grads_norm = 6.2376
	sim_grads_norm = 0.0270
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4978
	data_grads_norm = 3.8596
	new_data_grads_norm = 5.4504
	old_data_grads_norm = 5.7189
	sim_grads_norm = 0.0273
-- Starting training on experience 26 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3869
	data_grads_norm = 3.8388
	new_data_grads_norm = 5.7978
	old_data_grads_norm = 5.1742
	sim_grads_norm = 0.0319
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9966
	data_grads_norm = 3.3495
	new_data_grads_norm = 5.4312
	old_data_grads_norm = 4.1575
	sim_grads_norm = 0.0245
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4340
	data_grads_norm = 3.8776
	new_data_grads_norm = 5.9142
	old_data_grads_norm = 4.7808
	sim_grads_norm = 0.0482
-- Starting training on experience 27 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0362
	data_grads_norm = 3.7708
	new_data_grads_norm = 5.0029
	old_data_grads_norm = 5.2137
	sim_grads_norm = -0.0019
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5777
	data_grads_norm = 3.8731
	new_data_grads_norm = 5.1700
	old_data_grads_norm = 5.8925
	sim_grads_norm = 0.0119
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8705
	data_grads_norm = 3.5326
	new_data_grads_norm = 5.7695
	old_data_grads_norm = 4.2892
	sim_grads_norm = 0.0041
-- Starting training on experience 28 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1273
	data_grads_norm = 4.0206
	new_data_grads_norm = 5.9049
	old_data_grads_norm = 5.3113
	sim_grads_norm = 0.0212
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0173
	data_grads_norm = 3.5633
	new_data_grads_norm = 5.5387
	old_data_grads_norm = 4.5470
	sim_grads_norm = 0.0190
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2435
	data_grads_norm = 4.0419
	new_data_grads_norm = 5.0466
	old_data_grads_norm = 5.4746
	sim_grads_norm = 0.0630
-- Starting training on experience 29 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9587
	data_grads_norm = 3.7788
	new_data_grads_norm = 5.4447
	old_data_grads_norm = 4.4532
	sim_grads_norm = -0.0164
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5883
	data_grads_norm = 3.9821
	new_data_grads_norm = 5.9503
	old_data_grads_norm = 6.2429
	sim_grads_norm = 0.0689
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0422
	data_grads_norm = 4.0869
	new_data_grads_norm = 6.2381
	old_data_grads_norm = 5.4155
	sim_grads_norm = 0.0557
-- Starting training on experience 30 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0875
	data_grads_norm = 4.2660
	new_data_grads_norm = 4.8248
	old_data_grads_norm = 6.1992
	sim_grads_norm = -0.0076
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2099
	data_grads_norm = 3.8363
	new_data_grads_norm = 5.1502
	old_data_grads_norm = 4.9671
	sim_grads_norm = 0.0172
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2384
	data_grads_norm = 3.8185
	new_data_grads_norm = 5.8067
	old_data_grads_norm = 6.4780
	sim_grads_norm = -0.0414
-- Starting training on experience 31 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8416
	data_grads_norm = 3.7228
	new_data_grads_norm = 6.0563
	old_data_grads_norm = 4.3354
	sim_grads_norm = 0.0105
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0307
	data_grads_norm = 3.6450
	new_data_grads_norm = 5.8255
	old_data_grads_norm = 3.6927
	sim_grads_norm = 0.0422
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5312
	data_grads_norm = 3.9596
	new_data_grads_norm = 5.8454
	old_data_grads_norm = 5.6222
	sim_grads_norm = 0.0324
-- Starting training on experience 32 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8762
	data_grads_norm = 4.2781
	new_data_grads_norm = 5.0078
	old_data_grads_norm = 5.9406
	sim_grads_norm = -0.0080
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1418
	data_grads_norm = 4.4905
	new_data_grads_norm = 5.3782
	old_data_grads_norm = 5.9112
	sim_grads_norm = -0.0252
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9516
	data_grads_norm = 3.5596
	new_data_grads_norm = 5.2882
	old_data_grads_norm = 3.9798
	sim_grads_norm = 0.0389
-- Starting training on experience 33 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2175
	data_grads_norm = 3.9052
	new_data_grads_norm = 5.4792
	old_data_grads_norm = 4.6222
	sim_grads_norm = 0.0280
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0405
	data_grads_norm = 3.4423
	new_data_grads_norm = 5.6203
	old_data_grads_norm = 4.0143
	sim_grads_norm = -0.0357
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1505
	data_grads_norm = 4.0177
	new_data_grads_norm = 5.8717
	old_data_grads_norm = 4.9245
	sim_grads_norm = 0.0008
-- Starting training on experience 34 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9746
	data_grads_norm = 3.8312
	new_data_grads_norm = 5.9277
	old_data_grads_norm = 5.5386
	sim_grads_norm = -0.0387
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7706
	data_grads_norm = 3.6717
	new_data_grads_norm = 4.7976
	old_data_grads_norm = 5.3825
	sim_grads_norm = -0.0184
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0824
	data_grads_norm = 3.6384
	new_data_grads_norm = 5.2748
	old_data_grads_norm = 4.9620
	sim_grads_norm = 0.0072
-- Starting training on experience 35 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2618
	data_grads_norm = 4.0401
	new_data_grads_norm = 6.0129
	old_data_grads_norm = 4.9073
	sim_grads_norm = -0.0138
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2310
	data_grads_norm = 3.8627
	new_data_grads_norm = 6.2715
	old_data_grads_norm = 3.6314
	sim_grads_norm = 0.0625
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3292
	data_grads_norm = 4.0113
	new_data_grads_norm = 5.7990
	old_data_grads_norm = 5.0373
	sim_grads_norm = 0.0382
-- Starting training on experience 36 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8636
	data_grads_norm = 3.3555
	new_data_grads_norm = 5.8895
	old_data_grads_norm = 3.4441
	sim_grads_norm = 0.0355
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8255
	data_grads_norm = 3.8250
	new_data_grads_norm = 5.8214
	old_data_grads_norm = 5.2292
	sim_grads_norm = -0.0205
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9434
	data_grads_norm = 3.8052
	new_data_grads_norm = 5.4544
	old_data_grads_norm = 4.5364
	sim_grads_norm = 0.1017
-- Starting training on experience 37 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7199
	data_grads_norm = 3.5464
	new_data_grads_norm = 5.4132
	old_data_grads_norm = 5.4522
	sim_grads_norm = -0.0099
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9421
	data_grads_norm = 3.9574
	new_data_grads_norm = 5.5787
	old_data_grads_norm = 5.6459
	sim_grads_norm = -0.0711
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7985
	data_grads_norm = 3.6085
	new_data_grads_norm = 5.5349
	old_data_grads_norm = 4.7824
	sim_grads_norm = -0.0007
-- Starting training on experience 38 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9152
	data_grads_norm = 3.3625
	new_data_grads_norm = 5.0007
	old_data_grads_norm = 4.0572
	sim_grads_norm = -0.0038
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7483
	data_grads_norm = 3.2664
	new_data_grads_norm = 5.0682
	old_data_grads_norm = 3.3856
	sim_grads_norm = -0.0056
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0446
	data_grads_norm = 3.3660
	new_data_grads_norm = 5.0189
	old_data_grads_norm = 4.8658
	sim_grads_norm = 0.0268
-- Starting training on experience 39 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1065
	data_grads_norm = 3.5014
	new_data_grads_norm = 4.4817
	old_data_grads_norm = 5.3635
	sim_grads_norm = -0.0036
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1721
	data_grads_norm = 3.9096
	new_data_grads_norm = 5.0331
	old_data_grads_norm = 6.3526
	sim_grads_norm = 0.0175
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2420
	data_grads_norm = 4.0354
	new_data_grads_norm = 4.6082
	old_data_grads_norm = 6.4239
	sim_grads_norm = 0.0467
-- Starting training on experience 40 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4247
	data_grads_norm = 4.3275
	new_data_grads_norm = 5.2495
	old_data_grads_norm = 6.2630
	sim_grads_norm = -0.0171
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0681
	data_grads_norm = 3.7570
	new_data_grads_norm = 5.4629
	old_data_grads_norm = 4.3316
	sim_grads_norm = 0.0097
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7769
	data_grads_norm = 4.5220
	new_data_grads_norm = 5.9764
	old_data_grads_norm = 5.6441
	sim_grads_norm = -0.0048
-- Starting training on experience 41 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9573
	data_grads_norm = 3.6619
	new_data_grads_norm = 5.7936
	old_data_grads_norm = 5.2032
	sim_grads_norm = -0.0093
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3992
	data_grads_norm = 4.6177
	new_data_grads_norm = 5.1906
	old_data_grads_norm = 6.5089
	sim_grads_norm = 0.0624
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7687
	data_grads_norm = 3.7243
	new_data_grads_norm = 5.3537
	old_data_grads_norm = 5.2184
	sim_grads_norm = -0.0229
-- Starting training on experience 42 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6430
	data_grads_norm = 3.6585
	new_data_grads_norm = 5.1312
	old_data_grads_norm = 4.4449
	sim_grads_norm = -0.0309
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4222
	data_grads_norm = 3.4315
	new_data_grads_norm = 4.9130
	old_data_grads_norm = 4.5628
	sim_grads_norm = -0.0091
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5993
	data_grads_norm = 4.3743
	new_data_grads_norm = 4.9762
	old_data_grads_norm = 5.5392
	sim_grads_norm = -0.0506
-- Starting training on experience 43 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8761
	data_grads_norm = 3.7743
	new_data_grads_norm = 5.3708
	old_data_grads_norm = 4.7823
	sim_grads_norm = 0.0052
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4082
	data_grads_norm = 3.9351
	new_data_grads_norm = 5.1687
	old_data_grads_norm = 5.3225
	sim_grads_norm = 0.0599
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9382
	data_grads_norm = 3.9114
	new_data_grads_norm = 5.2173
	old_data_grads_norm = 5.3951
	sim_grads_norm = 0.0942
-- Starting training on experience 44 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7835
	data_grads_norm = 3.9616
	new_data_grads_norm = 5.3138
	old_data_grads_norm = 5.4548
	sim_grads_norm = -0.0092
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3052
	data_grads_norm = 3.9039
	new_data_grads_norm = 5.5403
	old_data_grads_norm = 5.3364
	sim_grads_norm = 0.0199
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4787
	data_grads_norm = 4.4493
	new_data_grads_norm = 5.2555
	old_data_grads_norm = 6.8372
	sim_grads_norm = -0.0178
-- Starting training on experience 45 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6504
	data_grads_norm = 3.5704
	new_data_grads_norm = 5.7639
	old_data_grads_norm = 4.0851
	sim_grads_norm = 0.0250
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6037
	data_grads_norm = 4.4212
	new_data_grads_norm = 5.7082
	old_data_grads_norm = 5.8823
	sim_grads_norm = 0.0688
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7060
	data_grads_norm = 3.6684
	new_data_grads_norm = 5.6947
	old_data_grads_norm = 4.1063
	sim_grads_norm = -0.0150
-- Starting training on experience 46 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5857
	data_grads_norm = 3.4149
	new_data_grads_norm = 5.2868
	old_data_grads_norm = 3.9203
	sim_grads_norm = -0.0254
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9499
	data_grads_norm = 3.6296
	new_data_grads_norm = 5.2422
	old_data_grads_norm = 3.8366
	sim_grads_norm = 0.0879
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0475
	data_grads_norm = 3.9365
	new_data_grads_norm = 5.4947
	old_data_grads_norm = 4.9715
	sim_grads_norm = -0.0224
-- Starting training on experience 47 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8981
	data_grads_norm = 3.5355
	new_data_grads_norm = 5.3124
	old_data_grads_norm = 4.4867
	sim_grads_norm = 0.0415
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6834
	data_grads_norm = 3.6431
	new_data_grads_norm = 5.8632
	old_data_grads_norm = 4.4684
	sim_grads_norm = -0.0324
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6755
	data_grads_norm = 3.5874
	new_data_grads_norm = 5.1976
	old_data_grads_norm = 5.1833
	sim_grads_norm = 0.0398
-- Starting training on experience 48 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5507
	data_grads_norm = 3.8016
	new_data_grads_norm = 5.0611
	old_data_grads_norm = 5.6309
	sim_grads_norm = -0.0054
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9044
	data_grads_norm = 3.5713
	new_data_grads_norm = 4.6587
	old_data_grads_norm = 5.3040
	sim_grads_norm = -0.0182
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5974
	data_grads_norm = 3.1814
	new_data_grads_norm = 5.1462
	old_data_grads_norm = 3.8175
	sim_grads_norm = -0.0079
-- Starting training on experience 49 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0435
	data_grads_norm = 4.1396
	new_data_grads_norm = 5.8837
	old_data_grads_norm = 5.7133
	sim_grads_norm = 0.0227
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3633
	data_grads_norm = 4.1518
	new_data_grads_norm = 6.0900
	old_data_grads_norm = 4.8479
	sim_grads_norm = 0.0320
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9722
	data_grads_norm = 4.0753
	new_data_grads_norm = 6.4950
	old_data_grads_norm = 5.0267
	sim_grads_norm = -0.0032
-- Starting training on experience 50 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1191
	data_grads_norm = 3.8804
	new_data_grads_norm = 5.5780
	old_data_grads_norm = 4.1642
	sim_grads_norm = 0.0790
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1388
	data_grads_norm = 3.7045
	new_data_grads_norm = 4.9337
	old_data_grads_norm = 4.5875
	sim_grads_norm = 0.0586
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0914
	data_grads_norm = 3.9017
	new_data_grads_norm = 5.6195
	old_data_grads_norm = 4.4410
	sim_grads_norm = 0.0548
-- Starting training on experience 51 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9734
	data_grads_norm = 3.9267
	new_data_grads_norm = 5.7977
	old_data_grads_norm = 5.1787
	sim_grads_norm = -0.0010
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6093
	data_grads_norm = 4.0415
	new_data_grads_norm = 6.3813
	old_data_grads_norm = 3.4525
	sim_grads_norm = 0.0468
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8174
	data_grads_norm = 3.9185
	new_data_grads_norm = 5.6362
	old_data_grads_norm = 4.5116
	sim_grads_norm = -0.0096
-- Starting training on experience 52 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3552
	data_grads_norm = 3.3233
	new_data_grads_norm = 4.7933
	old_data_grads_norm = 4.9888
	sim_grads_norm = -0.0170
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5287
	data_grads_norm = 3.8375
	new_data_grads_norm = 4.5750
	old_data_grads_norm = 5.5872
	sim_grads_norm = 0.0160
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5608
	data_grads_norm = 3.3994
	new_data_grads_norm = 4.8444
	old_data_grads_norm = 5.0767
	sim_grads_norm = -0.0039
-- Starting training on experience 53 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9039
	data_grads_norm = 4.0403
	new_data_grads_norm = 5.3880
	old_data_grads_norm = 5.7486
	sim_grads_norm = -0.0266
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6363
	data_grads_norm = 3.3663
	new_data_grads_norm = 5.4851
	old_data_grads_norm = 4.6820
	sim_grads_norm = 0.0090
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1113
	data_grads_norm = 4.3021
	new_data_grads_norm = 5.6329
	old_data_grads_norm = 5.7616
	sim_grads_norm = 0.0718
-- Starting training on experience 54 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6079
	data_grads_norm = 3.4068
	new_data_grads_norm = 5.6759
	old_data_grads_norm = 4.3786
	sim_grads_norm = -0.0213
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0217
	data_grads_norm = 4.1475
	new_data_grads_norm = 5.6378
	old_data_grads_norm = 5.6319
	sim_grads_norm = -0.0168
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7825
	data_grads_norm = 3.7658
	new_data_grads_norm = 5.2824
	old_data_grads_norm = 4.5137
	sim_grads_norm = -0.0113
-- Starting training on experience 55 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0771
	data_grads_norm = 3.3753
	new_data_grads_norm = 5.8208
	old_data_grads_norm = 5.9086
	sim_grads_norm = 0.0058
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2856
	data_grads_norm = 3.2673
	new_data_grads_norm = 5.3727
	old_data_grads_norm = 3.6795
	sim_grads_norm = -0.0165
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8975
	data_grads_norm = 4.4643
	new_data_grads_norm = 5.5884
	old_data_grads_norm = 6.9094
	sim_grads_norm = -0.0035
-- Starting training on experience 56 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5677
	data_grads_norm = 4.0107
	new_data_grads_norm = 4.6848
	old_data_grads_norm = 6.3454
	sim_grads_norm = -0.0532
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4091
	data_grads_norm = 3.0254
	new_data_grads_norm = 5.0253
	old_data_grads_norm = 3.8578
	sim_grads_norm = 0.0097
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7311
	data_grads_norm = 3.3456
	new_data_grads_norm = 5.0518
	old_data_grads_norm = 4.4782
	sim_grads_norm = 0.0815
-- Starting training on experience 57 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8954
	data_grads_norm = 4.1132
	new_data_grads_norm = 4.8598
	old_data_grads_norm = 6.3638
	sim_grads_norm = 0.0240
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2621
	data_grads_norm = 4.7093
	new_data_grads_norm = 5.0904
	old_data_grads_norm = 6.3969
	sim_grads_norm = 0.0263
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5517
	data_grads_norm = 3.7871
	new_data_grads_norm = 4.2618
	old_data_grads_norm = 6.2309
	sim_grads_norm = -0.0526
-- Starting training on experience 58 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0253
	data_grads_norm = 4.0236
	new_data_grads_norm = 5.7900
	old_data_grads_norm = 5.1726
	sim_grads_norm = 0.0085
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0449
	data_grads_norm = 3.9037
	new_data_grads_norm = 5.4659
	old_data_grads_norm = 5.0670
	sim_grads_norm = -0.0081
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9600
	data_grads_norm = 4.2106
	new_data_grads_norm = 6.1153
	old_data_grads_norm = 5.5999
	sim_grads_norm = 0.0453
-- Starting training on experience 59 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1097
	data_grads_norm = 4.1794
	new_data_grads_norm = 6.3545
	old_data_grads_norm = 4.9214
	sim_grads_norm = 0.0109
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2978
	data_grads_norm = 4.2101
	new_data_grads_norm = 6.4922
	old_data_grads_norm = 5.0110
	sim_grads_norm = -0.0040
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0771
	data_grads_norm = 4.0494
	new_data_grads_norm = 5.9587
	old_data_grads_norm = 4.2526
	sim_grads_norm = 0.0941
-- Starting training on experience 60 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9063
	data_grads_norm = 4.1357
	new_data_grads_norm = 5.5902
	old_data_grads_norm = 5.3591
	sim_grads_norm = -0.0067
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8380
	data_grads_norm = 3.3813
	new_data_grads_norm = 5.2092
	old_data_grads_norm = 4.5809
	sim_grads_norm = 0.0222
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9609
	data_grads_norm = 3.6177
	new_data_grads_norm = 5.1399
	old_data_grads_norm = 5.1403
	sim_grads_norm = 0.0104
-- Starting training on experience 61 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3272
	data_grads_norm = 4.0564
	new_data_grads_norm = 5.2320
	old_data_grads_norm = 4.5653
	sim_grads_norm = 0.0469
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8912
	data_grads_norm = 3.7433
	new_data_grads_norm = 5.8030
	old_data_grads_norm = 4.4786
	sim_grads_norm = 0.0193
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8420
	data_grads_norm = 3.8172
	new_data_grads_norm = 6.0266
	old_data_grads_norm = 5.6564
	sim_grads_norm = 0.0091
-- Starting training on experience 62 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7789
	data_grads_norm = 3.5317
	new_data_grads_norm = 4.5405
	old_data_grads_norm = 5.4548
	sim_grads_norm = -0.0210
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8840
	data_grads_norm = 3.5945
	new_data_grads_norm = 4.7132
	old_data_grads_norm = 4.9278
	sim_grads_norm = -0.0025
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6826
	data_grads_norm = 3.5080
	new_data_grads_norm = 5.1664
	old_data_grads_norm = 4.1556
	sim_grads_norm = -0.0216
-- Starting training on experience 63 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8161
	data_grads_norm = 3.1183
	new_data_grads_norm = 4.9903
	old_data_grads_norm = 3.3753
	sim_grads_norm = 0.0813
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7669
	data_grads_norm = 3.6278
	new_data_grads_norm = 5.0484
	old_data_grads_norm = 4.9267
	sim_grads_norm = -0.0184
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7268
	data_grads_norm = 3.4763
	new_data_grads_norm = 5.0759
	old_data_grads_norm = 4.0526
	sim_grads_norm = 0.0582
-- Starting training on experience 64 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4746
	data_grads_norm = 3.6600
	new_data_grads_norm = 4.9039
	old_data_grads_norm = 5.2859
	sim_grads_norm = -0.0252
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2946
	data_grads_norm = 3.0545
	new_data_grads_norm = 5.0340
	old_data_grads_norm = 3.1571
	sim_grads_norm = -0.0096
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6125
	data_grads_norm = 4.4783
	new_data_grads_norm = 5.3185
	old_data_grads_norm = 5.6637
	sim_grads_norm = 0.0533
-- Starting training on experience 65 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1930
	data_grads_norm = 4.0655
	new_data_grads_norm = 6.9265
	old_data_grads_norm = 4.2687
	sim_grads_norm = -0.0272
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0810
	data_grads_norm = 4.2629
	new_data_grads_norm = 7.0549
	old_data_grads_norm = 4.5410
	sim_grads_norm = 0.0031
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2535
	data_grads_norm = 4.0020
	new_data_grads_norm = 6.6775
	old_data_grads_norm = 5.4481
	sim_grads_norm = -0.0006
-- Starting training on experience 66 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5199
	data_grads_norm = 3.4801
	new_data_grads_norm = 4.8773
	old_data_grads_norm = 4.9919
	sim_grads_norm = 0.0193
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4819
	data_grads_norm = 3.0939
	new_data_grads_norm = 5.6747
	old_data_grads_norm = 3.6929
	sim_grads_norm = -0.0571
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5739
	data_grads_norm = 3.5705
	new_data_grads_norm = 5.4687
	old_data_grads_norm = 5.4345
	sim_grads_norm = 0.0183
-- Starting training on experience 67 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6592
	data_grads_norm = 3.1491
	new_data_grads_norm = 5.0614
	old_data_grads_norm = 3.1793
	sim_grads_norm = -0.0119
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8372
	data_grads_norm = 3.4878
	new_data_grads_norm = 5.3992
	old_data_grads_norm = 4.7028
	sim_grads_norm = -0.0152
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2775
	data_grads_norm = 3.8237
	new_data_grads_norm = 5.4565
	old_data_grads_norm = 4.6901
	sim_grads_norm = 0.0423
-- Starting training on experience 68 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0787
	data_grads_norm = 3.6928
	new_data_grads_norm = 5.3789
	old_data_grads_norm = 4.9532
	sim_grads_norm = 0.0082
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1257
	data_grads_norm = 3.2010
	new_data_grads_norm = 4.6884
	old_data_grads_norm = 3.9760
	sim_grads_norm = -0.0568
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7972
	data_grads_norm = 3.4504
	new_data_grads_norm = 4.9052
	old_data_grads_norm = 4.5222
	sim_grads_norm = -0.0039
-- Starting training on experience 69 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6444
	data_grads_norm = 3.7558
	new_data_grads_norm = 4.8591
	old_data_grads_norm = 5.9578
	sim_grads_norm = -0.0023
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9566
	data_grads_norm = 4.0226
	new_data_grads_norm = 5.7541
	old_data_grads_norm = 5.7172
	sim_grads_norm = -0.0087
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0988
	data_grads_norm = 3.8036
	new_data_grads_norm = 5.0743
	old_data_grads_norm = 5.0557
	sim_grads_norm = 0.0532
-- Starting training on experience 70 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4392
	data_grads_norm = 3.1947
	new_data_grads_norm = 4.8690
	old_data_grads_norm = 4.9150
	sim_grads_norm = -0.0033
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5839
	data_grads_norm = 3.9052
	new_data_grads_norm = 5.3821
	old_data_grads_norm = 5.4637
	sim_grads_norm = 0.0137
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7045
	data_grads_norm = 4.7243
	new_data_grads_norm = 6.4117
	old_data_grads_norm = 7.3753
	sim_grads_norm = 0.0458
-- Starting training on experience 71 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1225
	data_grads_norm = 3.6088
	new_data_grads_norm = 5.8746
	old_data_grads_norm = 4.1641
	sim_grads_norm = -0.0095
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8180
	data_grads_norm = 4.0217
	new_data_grads_norm = 6.2276
	old_data_grads_norm = 4.1647
	sim_grads_norm = -0.0189
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2196
	data_grads_norm = 3.5307
	new_data_grads_norm = 5.7084
	old_data_grads_norm = 3.3742
	sim_grads_norm = 0.0259
-- Starting training on experience 72 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6879
	data_grads_norm = 3.5676
	new_data_grads_norm = 5.4871
	old_data_grads_norm = 4.6030
	sim_grads_norm = -0.0452
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9321
	data_grads_norm = 3.7975
	new_data_grads_norm = 6.0949
	old_data_grads_norm = 4.8137
	sim_grads_norm = 0.0070
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0781
	data_grads_norm = 3.9711
	new_data_grads_norm = 5.7047
	old_data_grads_norm = 5.9481
	sim_grads_norm = -0.0009
-- Starting training on experience 73 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2119
	data_grads_norm = 4.0056
	new_data_grads_norm = 6.5809
	old_data_grads_norm = 5.8021
	sim_grads_norm = 0.0262
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2144
	data_grads_norm = 4.1116
	new_data_grads_norm = 6.3485
	old_data_grads_norm = 6.0350
	sim_grads_norm = 0.0208
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5169
	data_grads_norm = 3.8136
	new_data_grads_norm = 5.8548
	old_data_grads_norm = 5.0349
	sim_grads_norm = 0.0143
-- Starting training on experience 74 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9913
	data_grads_norm = 3.9571
	new_data_grads_norm = 4.8881
	old_data_grads_norm = 5.2359
	sim_grads_norm = 0.0208
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7212
	data_grads_norm = 3.7800
	new_data_grads_norm = 5.0232
	old_data_grads_norm = 5.7464
	sim_grads_norm = 0.0455
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1996
	data_grads_norm = 3.1555
	new_data_grads_norm = 4.8454
	old_data_grads_norm = 2.8765
	sim_grads_norm = 0.0197
-- Starting training on experience 75 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5107
	data_grads_norm = 3.6032
	new_data_grads_norm = 5.0949
	old_data_grads_norm = 3.8515
	sim_grads_norm = 0.2516
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3210
	data_grads_norm = 3.3458
	new_data_grads_norm = 4.7101
	old_data_grads_norm = 4.1756
	sim_grads_norm = 0.0412
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5089
	data_grads_norm = 3.6001
	new_data_grads_norm = 4.6772
	old_data_grads_norm = 5.6025
	sim_grads_norm = -0.0222
-- Starting training on experience 76 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9480
	data_grads_norm = 3.2205
	new_data_grads_norm = 4.5120
	old_data_grads_norm = 4.4416
	sim_grads_norm = -0.0012
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0240
	data_grads_norm = 3.9768
	new_data_grads_norm = 4.6518
	old_data_grads_norm = 5.8928
	sim_grads_norm = 0.0134
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6833
	data_grads_norm = 3.6400
	new_data_grads_norm = 4.8902
	old_data_grads_norm = 5.0980
	sim_grads_norm = 0.0774
-- Starting training on experience 77 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8709
	data_grads_norm = 4.2085
	new_data_grads_norm = 5.8809
	old_data_grads_norm = 4.6153
	sim_grads_norm = 0.0830
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8747
	data_grads_norm = 3.9948
	new_data_grads_norm = 6.0273
	old_data_grads_norm = 5.1927
	sim_grads_norm = -0.0374
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6733
	data_grads_norm = 4.1261
	new_data_grads_norm = 5.4512
	old_data_grads_norm = 5.4778
	sim_grads_norm = 0.0569
-- Starting training on experience 78 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4672
	data_grads_norm = 4.2507
	new_data_grads_norm = 5.8863
	old_data_grads_norm = 5.3112
	sim_grads_norm = -0.0117
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6714
	data_grads_norm = 4.2325
	new_data_grads_norm = 6.6153
	old_data_grads_norm = 5.1966
	sim_grads_norm = -0.0255
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8346
	data_grads_norm = 4.4484
	new_data_grads_norm = 6.0532
	old_data_grads_norm = 5.8078
	sim_grads_norm = 0.0161
-- Starting training on experience 79 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7882
	data_grads_norm = 4.1260
	new_data_grads_norm = 5.3055
	old_data_grads_norm = 6.5344
	sim_grads_norm = -0.0071
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3092
	data_grads_norm = 3.1022
	new_data_grads_norm = 5.2139
	old_data_grads_norm = 3.2453
	sim_grads_norm = 0.0551
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5658
	data_grads_norm = 3.6444
	new_data_grads_norm = 4.9191
	old_data_grads_norm = 5.5064
	sim_grads_norm = -0.0080
-- Starting training on experience 80 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3749
	data_grads_norm = 3.5492
	new_data_grads_norm = 4.6048
	old_data_grads_norm = 5.6474
	sim_grads_norm = -0.0250
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4117
	data_grads_norm = 3.9359
	new_data_grads_norm = 4.6070
	old_data_grads_norm = 5.8634
	sim_grads_norm = 0.0026
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7867
	data_grads_norm = 4.1108
	new_data_grads_norm = 4.8904
	old_data_grads_norm = 6.2315
	sim_grads_norm = 0.0355
-- Starting training on experience 81 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0434
	data_grads_norm = 3.5756
	new_data_grads_norm = 5.4104
	old_data_grads_norm = 4.7280
	sim_grads_norm = 0.0014
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6708
	data_grads_norm = 3.0861
	new_data_grads_norm = 5.0792
	old_data_grads_norm = 3.9648
	sim_grads_norm = 0.0312
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5902
	data_grads_norm = 3.9073
	new_data_grads_norm = 5.7888
	old_data_grads_norm = 5.5888
	sim_grads_norm = 0.0039
-- Starting training on experience 82 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4110
	data_grads_norm = 3.4377
	new_data_grads_norm = 4.8772
	old_data_grads_norm = 5.2824
	sim_grads_norm = -0.0218
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5708
	data_grads_norm = 3.8167
	new_data_grads_norm = 4.9369
	old_data_grads_norm = 4.8375
	sim_grads_norm = -0.0266
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4924
	data_grads_norm = 4.5875
	new_data_grads_norm = 4.9227
	old_data_grads_norm = 7.7219
	sim_grads_norm = -0.0287
-- Starting training on experience 83 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8976
	data_grads_norm = 4.5745
	new_data_grads_norm = 6.3119
	old_data_grads_norm = 6.8398
	sim_grads_norm = 0.0569
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7088
	data_grads_norm = 3.7594
	new_data_grads_norm = 5.8068
	old_data_grads_norm = 4.2687
	sim_grads_norm = 0.0095
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7427
	data_grads_norm = 3.3637
	new_data_grads_norm = 5.7701
	old_data_grads_norm = 5.0556
	sim_grads_norm = -0.0013
-- Starting training on experience 84 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6051
	data_grads_norm = 3.6568
	new_data_grads_norm = 5.6748
	old_data_grads_norm = 4.7567
	sim_grads_norm = 0.0113
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4759
	data_grads_norm = 4.2030
	new_data_grads_norm = 5.7453
	old_data_grads_norm = 5.4343
	sim_grads_norm = -0.0201
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2879
	data_grads_norm = 4.0744
	new_data_grads_norm = 5.6564
	old_data_grads_norm = 5.1616
	sim_grads_norm = -0.0580
-- Starting training on experience 85 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6391
	data_grads_norm = 3.4860
	new_data_grads_norm = 5.9572
	old_data_grads_norm = 4.8614
	sim_grads_norm = 0.0196
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9142
	data_grads_norm = 4.1694
	new_data_grads_norm = 6.2572
	old_data_grads_norm = 5.9489
	sim_grads_norm = -0.0270
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1073
	data_grads_norm = 4.1525
	new_data_grads_norm = 6.2911
	old_data_grads_norm = 5.4751
	sim_grads_norm = 0.0994
-- Starting training on experience 86 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3372
	data_grads_norm = 4.5571
	new_data_grads_norm = 6.3760
	old_data_grads_norm = 5.8176
	sim_grads_norm = 0.0263
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8460
	data_grads_norm = 4.0843
	new_data_grads_norm = 5.8833
	old_data_grads_norm = 5.9058
	sim_grads_norm = 0.0380
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9148
	data_grads_norm = 3.9665
	new_data_grads_norm = 5.5134
	old_data_grads_norm = 5.0171
	sim_grads_norm = 0.0407
-- Starting training on experience 87 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1229
	data_grads_norm = 3.0868
	new_data_grads_norm = 4.7184
	old_data_grads_norm = 4.7014
	sim_grads_norm = -0.0171
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8205
	data_grads_norm = 3.8623
	new_data_grads_norm = 4.4977
	old_data_grads_norm = 6.6291
	sim_grads_norm = -0.0392
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9450
	data_grads_norm = 4.1801
	new_data_grads_norm = 4.9016
	old_data_grads_norm = 5.8533
	sim_grads_norm = -0.0078
-- Starting training on experience 88 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8084
	data_grads_norm = 4.0466
	new_data_grads_norm = 5.9098
	old_data_grads_norm = 5.0249
	sim_grads_norm = -0.0482
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4302
	data_grads_norm = 4.0947
	new_data_grads_norm = 6.4778
	old_data_grads_norm = 4.7615
	sim_grads_norm = 0.0123
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0721
	data_grads_norm = 4.0949
	new_data_grads_norm = 6.1483
	old_data_grads_norm = 5.3176
	sim_grads_norm = -0.0195
-- Starting training on experience 89 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0658
	data_grads_norm = 4.2401
	new_data_grads_norm = 5.2126
	old_data_grads_norm = 6.2818
	sim_grads_norm = -0.0095
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7752
	data_grads_norm = 3.5262
	new_data_grads_norm = 5.2467
	old_data_grads_norm = 4.0920
	sim_grads_norm = 0.0336
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7304
	data_grads_norm = 3.3978
	new_data_grads_norm = 4.9799
	old_data_grads_norm = 4.7427
	sim_grads_norm = 0.0104
-- Starting training on experience 90 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3745
	data_grads_norm = 3.5696
	new_data_grads_norm = 6.4462
	old_data_grads_norm = 4.6079
	sim_grads_norm = -0.0056
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6916
	data_grads_norm = 3.9470
	new_data_grads_norm = 5.5675
	old_data_grads_norm = 5.4533
	sim_grads_norm = 0.0321
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8042
	data_grads_norm = 4.8707
	new_data_grads_norm = 5.5019
	old_data_grads_norm = 5.8855
	sim_grads_norm = 0.0552
-- Starting training on experience 91 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2730
	data_grads_norm = 4.2390
	new_data_grads_norm = 6.2716
	old_data_grads_norm = 4.3509
	sim_grads_norm = -0.0046
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1975
	data_grads_norm = 4.1936
	new_data_grads_norm = 6.1293
	old_data_grads_norm = 4.9727
	sim_grads_norm = 0.0371
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0003
	data_grads_norm = 4.0714
	new_data_grads_norm = 5.7960
	old_data_grads_norm = 5.3204
	sim_grads_norm = -0.0163
-- Starting training on experience 92 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0189
	data_grads_norm = 3.7883
	new_data_grads_norm = 5.4170
	old_data_grads_norm = 5.3103
	sim_grads_norm = 0.0007
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0093
	data_grads_norm = 3.4583
	new_data_grads_norm = 5.7730
	old_data_grads_norm = 3.9713
	sim_grads_norm = 0.0115
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7767
	data_grads_norm = 3.4998
	new_data_grads_norm = 5.6840
	old_data_grads_norm = 3.4184
	sim_grads_norm = -0.0280
-- Starting training on experience 93 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9700
	data_grads_norm = 3.9438
	new_data_grads_norm = 5.6267
	old_data_grads_norm = 5.6316
	sim_grads_norm = 0.0786
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9484
	data_grads_norm = 3.8476
	new_data_grads_norm = 5.8056
	old_data_grads_norm = 5.1074
	sim_grads_norm = 0.0615
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0275
	data_grads_norm = 4.2209
	new_data_grads_norm = 5.8136
	old_data_grads_norm = 5.9016
	sim_grads_norm = 0.0483
-- Starting training on experience 94 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5855
	data_grads_norm = 3.7175
	new_data_grads_norm = 5.4000
	old_data_grads_norm = 4.7101
	sim_grads_norm = 0.0417
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2385
	data_grads_norm = 3.3548
	new_data_grads_norm = 5.5433
	old_data_grads_norm = 5.6971
	sim_grads_norm = -0.0535
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8246
	data_grads_norm = 4.4175
	new_data_grads_norm = 6.4624
	old_data_grads_norm = 4.7064
	sim_grads_norm = 0.0377
-- Starting training on experience 95 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6604
	data_grads_norm = 3.7386
	new_data_grads_norm = 5.0354
	old_data_grads_norm = 5.2150
	sim_grads_norm = 0.0196
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6505
	data_grads_norm = 4.0079
	new_data_grads_norm = 5.2554
	old_data_grads_norm = 4.8665
	sim_grads_norm = -0.0174
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6589
	data_grads_norm = 4.1011
	new_data_grads_norm = 6.0519
	old_data_grads_norm = 5.1244
	sim_grads_norm = -0.0011
-- Starting training on experience 96 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0432
	data_grads_norm = 3.4817
	new_data_grads_norm = 5.4688
	old_data_grads_norm = 4.1813
	sim_grads_norm = 0.0061
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1031
	data_grads_norm = 3.8676
	new_data_grads_norm = 5.5287
	old_data_grads_norm = 5.0612
	sim_grads_norm = -0.0086
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2224
	data_grads_norm = 4.1274
	new_data_grads_norm = 5.7439
	old_data_grads_norm = 4.9378
	sim_grads_norm = 0.0739
-- Starting training on experience 97 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0268
	data_grads_norm = 3.7137
	new_data_grads_norm = 6.2298
	old_data_grads_norm = 4.6671
	sim_grads_norm = -0.0037
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6441
	data_grads_norm = 4.0772
	new_data_grads_norm = 5.7218
	old_data_grads_norm = 4.4387
	sim_grads_norm = 0.0059
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8373
	data_grads_norm = 4.1699
	new_data_grads_norm = 5.9114
	old_data_grads_norm = 5.0602
	sim_grads_norm = 0.0053
-- Starting training on experience 98 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2230
	data_grads_norm = 2.9196
	new_data_grads_norm = 5.3432
	old_data_grads_norm = 3.7944
	sim_grads_norm = -0.0044
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4453
	data_grads_norm = 3.3171
	new_data_grads_norm = 4.7631
	old_data_grads_norm = 4.5781
	sim_grads_norm = -0.0226
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3282
	data_grads_norm = 3.4288
	new_data_grads_norm = 5.6308
	old_data_grads_norm = 4.3010
	sim_grads_norm = -0.0006
-- Starting training on experience 99 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4093
	data_grads_norm = 2.9051
	new_data_grads_norm = 4.4560
	old_data_grads_norm = 4.1034
	sim_grads_norm = 0.0147
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0347
	data_grads_norm = 4.1358
	new_data_grads_norm = 4.5202
	old_data_grads_norm = 6.1719
	sim_grads_norm = 0.0238
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5825
	data_grads_norm = 3.5871
	new_data_grads_norm = 4.4153
	old_data_grads_norm = 5.8900
	sim_grads_norm = 0.0145
-- Starting training on experience 100 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6009
	data_grads_norm = 3.5482
	new_data_grads_norm = 5.1663
	old_data_grads_norm = 4.9140
	sim_grads_norm = 0.0418
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5640
	data_grads_norm = 3.4105
	new_data_grads_norm = 4.6301
	old_data_grads_norm = 4.6594
	sim_grads_norm = 0.0364
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7088
	data_grads_norm = 3.7925
	new_data_grads_norm = 4.6319
	old_data_grads_norm = 5.7983
	sim_grads_norm = -0.0128
-- Starting training on experience 101 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6686
	data_grads_norm = 3.9835
	new_data_grads_norm = 6.1796
	old_data_grads_norm = 5.5572
	sim_grads_norm = -0.0043
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9458
	data_grads_norm = 3.6771
	new_data_grads_norm = 5.9087
	old_data_grads_norm = 4.0249
	sim_grads_norm = 0.0201
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0564
	data_grads_norm = 4.5561
	new_data_grads_norm = 6.8424
	old_data_grads_norm = 6.1945
	sim_grads_norm = -0.0275
-- Starting training on experience 102 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0239
	data_grads_norm = 4.6583
	new_data_grads_norm = 5.9529
	old_data_grads_norm = 6.2110
	sim_grads_norm = -0.0030
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5518
	data_grads_norm = 4.3688
	new_data_grads_norm = 6.3681
	old_data_grads_norm = 6.1388
	sim_grads_norm = 0.0716
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6021
	data_grads_norm = 3.5382
	new_data_grads_norm = 5.3158
	old_data_grads_norm = 4.2023
	sim_grads_norm = -0.0080
-- Starting training on experience 103 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5098
	data_grads_norm = 3.5201
	new_data_grads_norm = 4.8451
	old_data_grads_norm = 4.6983
	sim_grads_norm = 0.0549
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4635
	data_grads_norm = 3.1163
	new_data_grads_norm = 4.7395
	old_data_grads_norm = 4.3399
	sim_grads_norm = -0.0207
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7710
	data_grads_norm = 3.7565
	new_data_grads_norm = 4.9023
	old_data_grads_norm = 5.2348
	sim_grads_norm = 0.0408
-- Starting training on experience 104 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0524
	data_grads_norm = 4.1796
	new_data_grads_norm = 5.5706
	old_data_grads_norm = 6.6019
	sim_grads_norm = 0.0313
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9470
	data_grads_norm = 4.4113
	new_data_grads_norm = 5.8746
	old_data_grads_norm = 5.5545
	sim_grads_norm = -0.0028
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2505
	data_grads_norm = 4.2898
	new_data_grads_norm = 5.4435
	old_data_grads_norm = 5.3016
	sim_grads_norm = 0.0400
-- Starting training on experience 105 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4077
	data_grads_norm = 3.9636
	new_data_grads_norm = 7.2517
	old_data_grads_norm = 3.4927
	sim_grads_norm = -0.0144
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8176
	data_grads_norm = 3.8619
	new_data_grads_norm = 6.7407
	old_data_grads_norm = 3.7154
	sim_grads_norm = 0.0366
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9316
	data_grads_norm = 4.3268
	new_data_grads_norm = 6.2099
	old_data_grads_norm = 5.9501
	sim_grads_norm = 0.0130
-- Starting training on experience 106 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4589
	data_grads_norm = 3.3416
	new_data_grads_norm = 5.8301
	old_data_grads_norm = 4.5133
	sim_grads_norm = -0.0029
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7540
	data_grads_norm = 3.8442
	new_data_grads_norm = 6.1798
	old_data_grads_norm = 3.8220
	sim_grads_norm = 0.0653
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0481
	data_grads_norm = 4.2518
	new_data_grads_norm = 6.0877
	old_data_grads_norm = 5.5481
	sim_grads_norm = -0.0248
-- Starting training on experience 107 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0127
	data_grads_norm = 4.4338
	new_data_grads_norm = 5.7402
	old_data_grads_norm = 5.9577
	sim_grads_norm = 0.0156
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0055
	data_grads_norm = 2.8800
	new_data_grads_norm = 5.0929
	old_data_grads_norm = 4.0564
	sim_grads_norm = -0.0880
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6871
	data_grads_norm = 3.8490
	new_data_grads_norm = 5.6518
	old_data_grads_norm = 4.7530
	sim_grads_norm = 0.0240
-- Starting training on experience 108 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9108
	data_grads_norm = 4.1679
	new_data_grads_norm = 4.8443
	old_data_grads_norm = 5.9001
	sim_grads_norm = -0.0060
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1169
	data_grads_norm = 2.9245
	new_data_grads_norm = 4.5622
	old_data_grads_norm = 4.2231
	sim_grads_norm = -0.0630
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1659
	data_grads_norm = 3.0822
	new_data_grads_norm = 4.8570
	old_data_grads_norm = 3.3341
	sim_grads_norm = 0.0363
-- Starting training on experience 109 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3566
	data_grads_norm = 4.0190
	new_data_grads_norm = 4.4634
	old_data_grads_norm = 6.3857
	sim_grads_norm = 0.0093
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5362
	data_grads_norm = 4.1365
	new_data_grads_norm = 5.4237
	old_data_grads_norm = 5.6949
	sim_grads_norm = -0.0251
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5401
	data_grads_norm = 3.5657
	new_data_grads_norm = 5.3076
	old_data_grads_norm = 5.1011
	sim_grads_norm = -0.0009
-- Starting training on experience 110 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5845
	data_grads_norm = 3.9611
	new_data_grads_norm = 6.2287
	old_data_grads_norm = 4.8516
	sim_grads_norm = -0.0049
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4488
	data_grads_norm = 3.5801
	new_data_grads_norm = 5.1989
	old_data_grads_norm = 4.2119
	sim_grads_norm = 0.1000
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6249
	data_grads_norm = 4.0074
	new_data_grads_norm = 6.0198
	old_data_grads_norm = 5.7464
	sim_grads_norm = -0.0400
-- Starting training on experience 111 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3409
	data_grads_norm = 3.6434
	new_data_grads_norm = 6.1476
	old_data_grads_norm = 5.1272
	sim_grads_norm = -0.0284
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9715
	data_grads_norm = 4.3697
	new_data_grads_norm = 6.3022
	old_data_grads_norm = 4.5305
	sim_grads_norm = 0.0600
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6227
	data_grads_norm = 4.6734
	new_data_grads_norm = 6.4724
	old_data_grads_norm = 6.2232
	sim_grads_norm = 0.0525
-- Starting training on experience 112 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2654
	data_grads_norm = 3.8274
	new_data_grads_norm = 5.6038
	old_data_grads_norm = 4.6648
	sim_grads_norm = 0.0364
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6515
	data_grads_norm = 3.3398
	new_data_grads_norm = 5.3834
	old_data_grads_norm = 3.4592
	sim_grads_norm = -0.0034
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8388
	data_grads_norm = 3.3296
	new_data_grads_norm = 5.6494
	old_data_grads_norm = 3.9466
	sim_grads_norm = -0.0190
-- Starting training on experience 113 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8160
	data_grads_norm = 3.6240
	new_data_grads_norm = 6.1666
	old_data_grads_norm = 3.6627
	sim_grads_norm = 0.0855
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1426
	data_grads_norm = 4.6799
	new_data_grads_norm = 6.1002
	old_data_grads_norm = 6.1289
	sim_grads_norm = 0.0225
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1713
	data_grads_norm = 4.1903
	new_data_grads_norm = 6.0060
	old_data_grads_norm = 5.1912
	sim_grads_norm = 0.0432
-- Starting training on experience 114 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2285
	data_grads_norm = 3.2912
	new_data_grads_norm = 4.9983
	old_data_grads_norm = 5.2870
	sim_grads_norm = -0.0703
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9119
	data_grads_norm = 4.0270
	new_data_grads_norm = 5.5218
	old_data_grads_norm = 6.4143
	sim_grads_norm = -0.0293
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6946
	data_grads_norm = 3.9229
	new_data_grads_norm = 5.2246
	old_data_grads_norm = 6.3010
	sim_grads_norm = 0.0553
-- Starting training on experience 115 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8250
	data_grads_norm = 4.3920
	new_data_grads_norm = 6.1470
	old_data_grads_norm = 5.9915
	sim_grads_norm = -0.0199
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7905
	data_grads_norm = 4.0653
	new_data_grads_norm = 6.1636
	old_data_grads_norm = 5.1253
	sim_grads_norm = 0.0554
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3825
	data_grads_norm = 4.1101
	new_data_grads_norm = 6.0407
	old_data_grads_norm = 5.1013
	sim_grads_norm = -0.0107
-- Starting training on experience 116 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7766
	data_grads_norm = 4.1584
	new_data_grads_norm = 6.2987
	old_data_grads_norm = 5.0072
	sim_grads_norm = -0.0230
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9420
	data_grads_norm = 4.5818
	new_data_grads_norm = 5.5838
	old_data_grads_norm = 6.7110
	sim_grads_norm = 0.0942
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4150
	data_grads_norm = 3.6396
	new_data_grads_norm = 4.9921
	old_data_grads_norm = 5.2403
	sim_grads_norm = 0.0216
-- Starting training on experience 117 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4069
	data_grads_norm = 4.2276
	new_data_grads_norm = 5.9895
	old_data_grads_norm = 7.7880
	sim_grads_norm = 0.0085
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4005
	data_grads_norm = 3.9776
	new_data_grads_norm = 5.3059
	old_data_grads_norm = 5.9606
	sim_grads_norm = -0.0352
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6267
	data_grads_norm = 3.9882
	new_data_grads_norm = 6.4039
	old_data_grads_norm = 4.4904
	sim_grads_norm = -0.0037
-- Starting training on experience 118 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0533
	data_grads_norm = 2.9570
	new_data_grads_norm = 4.3785
	old_data_grads_norm = 4.7608
	sim_grads_norm = -0.0237
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6981
	data_grads_norm = 4.3566
	new_data_grads_norm = 4.7910
	old_data_grads_norm = 6.8307
	sim_grads_norm = -0.0063
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0849
	data_grads_norm = 4.8861
	new_data_grads_norm = 5.0285
	old_data_grads_norm = 7.0912
	sim_grads_norm = -0.0020
-- Starting training on experience 119 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5613
	data_grads_norm = 3.4947
	new_data_grads_norm = 5.1686
	old_data_grads_norm = 4.3363
	sim_grads_norm = 0.1000
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9374
	data_grads_norm = 4.1611
	new_data_grads_norm = 5.0709
	old_data_grads_norm = 6.0586
	sim_grads_norm = 0.0253
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9163
	data_grads_norm = 4.3945
	new_data_grads_norm = 4.5227
	old_data_grads_norm = 6.9458
	sim_grads_norm = -0.0067
-- Starting training on experience 120 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3739
	data_grads_norm = 3.1986
	new_data_grads_norm = 4.6709
	old_data_grads_norm = 3.7658
	sim_grads_norm = 0.0788
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1963
	data_grads_norm = 3.0163
	new_data_grads_norm = 4.3406
	old_data_grads_norm = 4.2752
	sim_grads_norm = 0.0010
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6680
	data_grads_norm = 3.7047
	new_data_grads_norm = 4.5644
	old_data_grads_norm = 5.3288
	sim_grads_norm = 0.0526
-- Starting training on experience 121 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5585
	data_grads_norm = 3.7062
	new_data_grads_norm = 5.0669
	old_data_grads_norm = 4.9868
	sim_grads_norm = -0.0433
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5121
	data_grads_norm = 3.4892
	new_data_grads_norm = 5.4076
	old_data_grads_norm = 4.7727
	sim_grads_norm = -0.0040
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0214
	data_grads_norm = 3.8270
	new_data_grads_norm = 5.1782
	old_data_grads_norm = 5.3816
	sim_grads_norm = 0.0499
-- Starting training on experience 122 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3608
	data_grads_norm = 3.5343
	new_data_grads_norm = 5.1732
	old_data_grads_norm = 4.7340
	sim_grads_norm = -0.0283
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7746
	data_grads_norm = 3.7412
	new_data_grads_norm = 5.0620
	old_data_grads_norm = 5.0781
	sim_grads_norm = -0.0116
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2453
	data_grads_norm = 3.2696
	new_data_grads_norm = 4.7970
	old_data_grads_norm = 4.2002
	sim_grads_norm = -0.0507
-- Starting training on experience 123 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9014
	data_grads_norm = 3.8458
	new_data_grads_norm = 4.4978
	old_data_grads_norm = 5.4785
	sim_grads_norm = 0.0053
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4453
	data_grads_norm = 3.4667
	new_data_grads_norm = 5.1355
	old_data_grads_norm = 4.4142
	sim_grads_norm = 0.0736
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4216
	data_grads_norm = 3.6021
	new_data_grads_norm = 4.8753
	old_data_grads_norm = 5.6926
	sim_grads_norm = 0.0073
-- Starting training on experience 124 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9975
	data_grads_norm = 4.2992
	new_data_grads_norm = 6.3734
	old_data_grads_norm = 5.3628
	sim_grads_norm = -0.0118
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9146
	data_grads_norm = 4.2229
	new_data_grads_norm = 5.9881
	old_data_grads_norm = 5.7607
	sim_grads_norm = 0.0472
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7428
	data_grads_norm = 4.2325
	new_data_grads_norm = 5.8146
	old_data_grads_norm = 5.6192
	sim_grads_norm = -0.0351
-- Starting training on experience 125 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4252
	data_grads_norm = 3.7948
	new_data_grads_norm = 5.2106
	old_data_grads_norm = 4.9017
	sim_grads_norm = 0.0079
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7890
	data_grads_norm = 4.0130
	new_data_grads_norm = 5.1595
	old_data_grads_norm = 5.9992
	sim_grads_norm = -0.0068
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3610
	data_grads_norm = 3.9601
	new_data_grads_norm = 5.2465
	old_data_grads_norm = 5.9639
	sim_grads_norm = 0.0307
-- Starting training on experience 126 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4997
	data_grads_norm = 3.8476
	new_data_grads_norm = 5.5820
	old_data_grads_norm = 5.6310
	sim_grads_norm = 0.0118
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3543
	data_grads_norm = 2.9917
	new_data_grads_norm = 5.4387
	old_data_grads_norm = 3.0059
	sim_grads_norm = -0.0173
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4097
	data_grads_norm = 3.3119
	new_data_grads_norm = 5.3903
	old_data_grads_norm = 3.7056
	sim_grads_norm = -0.0521
-- Starting training on experience 127 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6896
	data_grads_norm = 4.0890
	new_data_grads_norm = 6.0822
	old_data_grads_norm = 5.5119
	sim_grads_norm = -0.0171
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0494
	data_grads_norm = 4.6619
	new_data_grads_norm = 5.6952
	old_data_grads_norm = 6.0454
	sim_grads_norm = 0.0404
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2649
	data_grads_norm = 3.5307
	new_data_grads_norm = 6.0191
	old_data_grads_norm = 3.8524
	sim_grads_norm = 0.0159
-- Starting training on experience 128 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6696
	data_grads_norm = 3.7728
	new_data_grads_norm = 5.0496
	old_data_grads_norm = 6.0227
	sim_grads_norm = -0.0326
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2555
	data_grads_norm = 3.4392
	new_data_grads_norm = 5.1889
	old_data_grads_norm = 3.7360
	sim_grads_norm = 0.0347
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8505
	data_grads_norm = 4.1214
	new_data_grads_norm = 4.9968
	old_data_grads_norm = 5.6007
	sim_grads_norm = 0.0076
-- Starting training on experience 129 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1022
	data_grads_norm = 4.2149
	new_data_grads_norm = 6.0558
	old_data_grads_norm = 5.1883
	sim_grads_norm = -0.0091
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7938
	data_grads_norm = 3.9338
	new_data_grads_norm = 6.1170
	old_data_grads_norm = 4.7889
	sim_grads_norm = -0.0050
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6784
	data_grads_norm = 4.3637
	new_data_grads_norm = 6.3498
	old_data_grads_norm = 5.8392
	sim_grads_norm = 0.0083
-- Starting training on experience 130 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1987
	data_grads_norm = 3.0286
	new_data_grads_norm = 5.1522
	old_data_grads_norm = 3.4825
	sim_grads_norm = -0.0161
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8151
	data_grads_norm = 3.6630
	new_data_grads_norm = 4.8988
	old_data_grads_norm = 4.7597
	sim_grads_norm = 0.0103
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8610
	data_grads_norm = 4.1333
	new_data_grads_norm = 4.9444
	old_data_grads_norm = 6.1110
	sim_grads_norm = -0.0006
-- Starting training on experience 131 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8314
	data_grads_norm = 3.6126
	new_data_grads_norm = 4.9687
	old_data_grads_norm = 4.4355
	sim_grads_norm = 0.1158
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5130
	data_grads_norm = 3.7868
	new_data_grads_norm = 5.2962
	old_data_grads_norm = 5.2510
	sim_grads_norm = 0.0171
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6163
	data_grads_norm = 3.5318
	new_data_grads_norm = 5.9790
	old_data_grads_norm = 3.7732
	sim_grads_norm = 0.0531
-- Starting training on experience 132 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1868
	data_grads_norm = 3.1218
	new_data_grads_norm = 5.2470
	old_data_grads_norm = 3.1080
	sim_grads_norm = -0.0238
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7572
	data_grads_norm = 3.7067
	new_data_grads_norm = 5.7835
	old_data_grads_norm = 4.7255
	sim_grads_norm = 0.0128
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7331
	data_grads_norm = 3.5397
	new_data_grads_norm = 5.4204
	old_data_grads_norm = 3.7361
	sim_grads_norm = 0.0042
-- Starting training on experience 133 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5966
	data_grads_norm = 3.7446
	new_data_grads_norm = 5.1349
	old_data_grads_norm = 5.3946
	sim_grads_norm = -0.0167
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3381
	data_grads_norm = 3.2998
	new_data_grads_norm = 5.4971
	old_data_grads_norm = 4.8894
	sim_grads_norm = 0.0071
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4736
	data_grads_norm = 3.4314
	new_data_grads_norm = 4.6350
	old_data_grads_norm = 4.5706
	sim_grads_norm = -0.0090
-- Starting training on experience 134 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8262
	data_grads_norm = 3.9567
	new_data_grads_norm = 5.7021
	old_data_grads_norm = 4.9831
	sim_grads_norm = -0.0307
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7086
	data_grads_norm = 4.1614
	new_data_grads_norm = 5.9106
	old_data_grads_norm = 5.3887
	sim_grads_norm = -0.0041
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7859
	data_grads_norm = 4.3276
	new_data_grads_norm = 6.3597
	old_data_grads_norm = 5.0061
	sim_grads_norm = 0.0069
-- Starting training on experience 135 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9572
	data_grads_norm = 3.4426
	new_data_grads_norm = 5.5486
	old_data_grads_norm = 4.0435
	sim_grads_norm = 0.0162
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1127
	data_grads_norm = 3.1349
	new_data_grads_norm = 5.7089
	old_data_grads_norm = 3.3439
	sim_grads_norm = 0.0238
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4776
	data_grads_norm = 4.2086
	new_data_grads_norm = 5.9681
	old_data_grads_norm = 5.2371
	sim_grads_norm = -0.0396
-- Starting training on experience 136 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9140
	data_grads_norm = 3.6396
	new_data_grads_norm = 6.1591
	old_data_grads_norm = 4.4918
	sim_grads_norm = -0.0024
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1402
	data_grads_norm = 3.9076
	new_data_grads_norm = 5.8331
	old_data_grads_norm = 4.2907
	sim_grads_norm = -0.0022
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6142
	data_grads_norm = 4.0595
	new_data_grads_norm = 6.1465
	old_data_grads_norm = 5.0573
	sim_grads_norm = 0.0145
-- Starting training on experience 137 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0975
	data_grads_norm = 4.3548
	new_data_grads_norm = 5.9319
	old_data_grads_norm = 6.1916
	sim_grads_norm = 0.0397
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8295
	data_grads_norm = 3.4823
	new_data_grads_norm = 6.4229
	old_data_grads_norm = 4.7480
	sim_grads_norm = 0.0046
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7396
	data_grads_norm = 3.6906
	new_data_grads_norm = 6.3276
	old_data_grads_norm = 4.7048
	sim_grads_norm = 0.0383
-- Starting training on experience 138 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6146
	data_grads_norm = 4.0286
	new_data_grads_norm = 5.1917
	old_data_grads_norm = 5.5337
	sim_grads_norm = 0.0218
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2189
	data_grads_norm = 3.0809
	new_data_grads_norm = 4.7049
	old_data_grads_norm = 3.7474
	sim_grads_norm = -0.0338
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6118
	data_grads_norm = 4.3052
	new_data_grads_norm = 5.1451
	old_data_grads_norm = 6.5164
	sim_grads_norm = 0.0393
-- Starting training on experience 139 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5823
	data_grads_norm = 4.2548
	new_data_grads_norm = 4.5303
	old_data_grads_norm = 6.2455
	sim_grads_norm = 0.0707
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2476
	data_grads_norm = 3.2193
	new_data_grads_norm = 4.3430
	old_data_grads_norm = 4.8340
	sim_grads_norm = -0.0004
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1106
	data_grads_norm = 2.9966
	new_data_grads_norm = 4.8896
	old_data_grads_norm = 3.9297
	sim_grads_norm = 0.0098
-- Starting training on experience 140 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3639
	data_grads_norm = 5.0461
	new_data_grads_norm = 7.1118
	old_data_grads_norm = 5.8305
	sim_grads_norm = 0.0664
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1126
	data_grads_norm = 4.3858
	new_data_grads_norm = 6.8130
	old_data_grads_norm = 5.1220
	sim_grads_norm = 0.0168
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3902
	data_grads_norm = 3.7616
	new_data_grads_norm = 5.9977
	old_data_grads_norm = 5.0468
	sim_grads_norm = -0.0597
-- Starting training on experience 141 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1944
	data_grads_norm = 3.5054
	new_data_grads_norm = 4.8348
	old_data_grads_norm = 5.4224
	sim_grads_norm = 0.0225
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8691
	data_grads_norm = 3.6282
	new_data_grads_norm = 4.8422
	old_data_grads_norm = 5.4586
	sim_grads_norm = -0.0019
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6447
	data_grads_norm = 4.1269
	new_data_grads_norm = 4.9354
	old_data_grads_norm = 6.8289
	sim_grads_norm = 0.0055
-- Starting training on experience 142 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8853
	data_grads_norm = 3.8921
	new_data_grads_norm = 5.5734
	old_data_grads_norm = 5.4063
	sim_grads_norm = 0.0235
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6136
	data_grads_norm = 3.5121
	new_data_grads_norm = 5.0112
	old_data_grads_norm = 4.5027
	sim_grads_norm = 0.0637
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4053
	data_grads_norm = 3.2783
	new_data_grads_norm = 5.1767
	old_data_grads_norm = 4.0565
	sim_grads_norm = -0.0573
-- Starting training on experience 143 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1994
	data_grads_norm = 3.8057
	new_data_grads_norm = 5.9054
	old_data_grads_norm = 3.9061
	sim_grads_norm = -0.0705
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9282
	data_grads_norm = 4.7118
	new_data_grads_norm = 5.8902
	old_data_grads_norm = 7.2557
	sim_grads_norm = 0.0033
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3929
	data_grads_norm = 3.6166
	new_data_grads_norm = 5.7194
	old_data_grads_norm = 5.0684
	sim_grads_norm = 0.0007
-- Starting training on experience 144 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1252
	data_grads_norm = 4.0822
	new_data_grads_norm = 6.0337
	old_data_grads_norm = 5.1575
	sim_grads_norm = 0.0574
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8282
	data_grads_norm = 3.6137
	new_data_grads_norm = 4.7908
	old_data_grads_norm = 4.9578
	sim_grads_norm = 0.0143
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1158
	data_grads_norm = 4.4542
	new_data_grads_norm = 5.9146
	old_data_grads_norm = 6.3650
	sim_grads_norm = 0.0076
-- Starting training on experience 145 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3952
	data_grads_norm = 3.5818
	new_data_grads_norm = 5.4105
	old_data_grads_norm = 5.0653
	sim_grads_norm = -0.0117
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2652
	data_grads_norm = 3.0889
	new_data_grads_norm = 5.1790
	old_data_grads_norm = 3.5266
	sim_grads_norm = 0.0141
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5662
	data_grads_norm = 4.0324
	new_data_grads_norm = 4.8037
	old_data_grads_norm = 6.4494
	sim_grads_norm = 0.0155
-- Starting training on experience 146 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9604
	data_grads_norm = 3.8657
	new_data_grads_norm = 6.4327
	old_data_grads_norm = 4.4999
	sim_grads_norm = 0.0052
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4573
	data_grads_norm = 4.3128
	new_data_grads_norm = 6.0566
	old_data_grads_norm = 4.3586
	sim_grads_norm = 0.0132
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7511
	data_grads_norm = 4.0487
	new_data_grads_norm = 5.6663
	old_data_grads_norm = 5.7219
	sim_grads_norm = -0.0028
-- Starting training on experience 147 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7891
	data_grads_norm = 4.0404
	new_data_grads_norm = 5.1802
	old_data_grads_norm = 4.9359
	sim_grads_norm = 0.0819
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6480
	data_grads_norm = 3.8101
	new_data_grads_norm = 4.9653
	old_data_grads_norm = 5.4963
	sim_grads_norm = 0.0198
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8728
	data_grads_norm = 4.3758
	new_data_grads_norm = 5.1320
	old_data_grads_norm = 6.6269
	sim_grads_norm = 0.0386
-- Starting training on experience 148 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2188
	data_grads_norm = 3.7901
	new_data_grads_norm = 6.4142
	old_data_grads_norm = 4.5811
	sim_grads_norm = 0.0026
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6925
	data_grads_norm = 3.8649
	new_data_grads_norm = 6.1531
	old_data_grads_norm = 3.9586
	sim_grads_norm = 0.0533
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8621
	data_grads_norm = 4.6911
	new_data_grads_norm = 6.2095
	old_data_grads_norm = 5.9361
	sim_grads_norm = -0.0408
-- Starting training on experience 149 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0343
	data_grads_norm = 3.8720
	new_data_grads_norm = 5.9391
	old_data_grads_norm = 5.5346
	sim_grads_norm = 0.0089
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7480
	data_grads_norm = 3.7423
	new_data_grads_norm = 5.4283
	old_data_grads_norm = 4.6320
	sim_grads_norm = 0.0430
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7352
	data_grads_norm = 3.5472
	new_data_grads_norm = 5.5992
	old_data_grads_norm = 4.8606
	sim_grads_norm = 0.0282
-- Starting training on experience 150 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5691
	data_grads_norm = 3.9596
	new_data_grads_norm = 5.6873
	old_data_grads_norm = 5.1823
	sim_grads_norm = -0.0044
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0864
	data_grads_norm = 4.0280
	new_data_grads_norm = 6.3885
	old_data_grads_norm = 4.9655
	sim_grads_norm = 0.0148
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5847
	data_grads_norm = 3.4315
	new_data_grads_norm = 5.6997
	old_data_grads_norm = 4.0107
	sim_grads_norm = -0.0379
-- Starting training on experience 151 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4096
	data_grads_norm = 3.3988
	new_data_grads_norm = 5.1676
	old_data_grads_norm = 3.8884
	sim_grads_norm = -0.0357
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2697
	data_grads_norm = 3.5276
	new_data_grads_norm = 4.9768
	old_data_grads_norm = 4.9496
	sim_grads_norm = 0.0450
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2399
	data_grads_norm = 3.6029
	new_data_grads_norm = 5.5022
	old_data_grads_norm = 5.3279
	sim_grads_norm = 0.0279
-- Starting training on experience 152 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2515
	data_grads_norm = 3.3938
	new_data_grads_norm = 5.3122
	old_data_grads_norm = 5.0853
	sim_grads_norm = 0.0248
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0710
	data_grads_norm = 3.8085
	new_data_grads_norm = 5.2507
	old_data_grads_norm = 5.6747
	sim_grads_norm = -0.0188
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2853
	data_grads_norm = 4.1787
	new_data_grads_norm = 5.1979
	old_data_grads_norm = 6.2547
	sim_grads_norm = -0.0187
-- Starting training on experience 153 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3609
	data_grads_norm = 3.7864
	new_data_grads_norm = 4.8403
	old_data_grads_norm = 5.8068
	sim_grads_norm = -0.0238
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2098
	data_grads_norm = 4.3127
	new_data_grads_norm = 4.9155
	old_data_grads_norm = 6.4811
	sim_grads_norm = 0.0804
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3449
	data_grads_norm = 3.9063
	new_data_grads_norm = 4.8693
	old_data_grads_norm = 5.7115
	sim_grads_norm = -0.0835
-- Starting training on experience 154 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3516
	data_grads_norm = 3.8183
	new_data_grads_norm = 5.8904
	old_data_grads_norm = 3.7817
	sim_grads_norm = 0.0809
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3088
	data_grads_norm = 3.3145
	new_data_grads_norm = 5.5270
	old_data_grads_norm = 3.6920
	sim_grads_norm = -0.0047
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7847
	data_grads_norm = 3.9587
	new_data_grads_norm = 5.2499
	old_data_grads_norm = 5.2217
	sim_grads_norm = -0.0097
-- Starting training on experience 155 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0023
	data_grads_norm = 3.3194
	new_data_grads_norm = 5.3170
	old_data_grads_norm = 5.4899
	sim_grads_norm = -0.0403
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4185
	data_grads_norm = 4.2649
	new_data_grads_norm = 5.9367
	old_data_grads_norm = 6.5672
	sim_grads_norm = -0.0414
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4242
	data_grads_norm = 3.6708
	new_data_grads_norm = 5.8011
	old_data_grads_norm = 5.2830
	sim_grads_norm = -0.0438
-- Starting training on experience 156 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7821
	data_grads_norm = 4.0712
	new_data_grads_norm = 5.3809
	old_data_grads_norm = 5.0567
	sim_grads_norm = 0.0466
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2598
	data_grads_norm = 3.5941
	new_data_grads_norm = 4.6709
	old_data_grads_norm = 4.6776
	sim_grads_norm = 0.1199
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3122
	data_grads_norm = 3.4644
	new_data_grads_norm = 4.9049
	old_data_grads_norm = 3.4860
	sim_grads_norm = -0.0606
-- Starting training on experience 157 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2616
	data_grads_norm = 3.5480
	new_data_grads_norm = 4.9986
	old_data_grads_norm = 4.7497
	sim_grads_norm = -0.0085
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0754
	data_grads_norm = 3.1678
	new_data_grads_norm = 4.5006
	old_data_grads_norm = 4.5903
	sim_grads_norm = 0.0273
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1635
	data_grads_norm = 3.4929
	new_data_grads_norm = 4.7945
	old_data_grads_norm = 4.8095
	sim_grads_norm = 0.0328
-- Starting training on experience 158 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4428
	data_grads_norm = 3.9060
	new_data_grads_norm = 5.6599
	old_data_grads_norm = 4.9627
	sim_grads_norm = -0.0124
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6233
	data_grads_norm = 3.8929
	new_data_grads_norm = 5.5235
	old_data_grads_norm = 5.5795
	sim_grads_norm = 0.0454
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7483
	data_grads_norm = 4.2890
	new_data_grads_norm = 5.7602
	old_data_grads_norm = 5.2800
	sim_grads_norm = 0.0572
-- Starting training on experience 159 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7092
	data_grads_norm = 3.1035
	new_data_grads_norm = 4.4797
	old_data_grads_norm = 4.9541
	sim_grads_norm = -0.0069
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9625
	data_grads_norm = 3.4237
	new_data_grads_norm = 4.9996
	old_data_grads_norm = 4.3778
	sim_grads_norm = -0.0349
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3075
	data_grads_norm = 3.9944
	new_data_grads_norm = 5.7073
	old_data_grads_norm = 4.9818
	sim_grads_norm = 0.0434
-- Starting training on experience 160 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2288
	data_grads_norm = 3.7231
	new_data_grads_norm = 5.1521
	old_data_grads_norm = 4.8162
	sim_grads_norm = -0.0532
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7790
	data_grads_norm = 4.3917
	new_data_grads_norm = 5.8768
	old_data_grads_norm = 5.0358
	sim_grads_norm = -0.0008
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9769
	data_grads_norm = 4.0945
	new_data_grads_norm = 5.6085
	old_data_grads_norm = 5.3555
	sim_grads_norm = 0.0213
-- Starting training on experience 161 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2231
	data_grads_norm = 3.6696
	new_data_grads_norm = 5.7702
	old_data_grads_norm = 4.0388
	sim_grads_norm = -0.0280
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9833
	data_grads_norm = 3.1924
	new_data_grads_norm = 5.6972
	old_data_grads_norm = 4.7412
	sim_grads_norm = -0.0053
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0724
	data_grads_norm = 3.4354
	new_data_grads_norm = 5.3055
	old_data_grads_norm = 5.1057
	sim_grads_norm = -0.0055
-- Starting training on experience 162 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8893
	data_grads_norm = 4.8933
	new_data_grads_norm = 7.1665
	old_data_grads_norm = 7.0096
	sim_grads_norm = -0.0460
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9204
	data_grads_norm = 4.1469
	new_data_grads_norm = 6.9091
	old_data_grads_norm = 4.1679
	sim_grads_norm = 0.0483
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5232
	data_grads_norm = 4.7852
	new_data_grads_norm = 7.2045
	old_data_grads_norm = 5.8054
	sim_grads_norm = 0.0456
-- Starting training on experience 163 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5968
	data_grads_norm = 3.9827
	new_data_grads_norm = 6.1238
	old_data_grads_norm = 5.0186
	sim_grads_norm = 0.0103
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9091
	data_grads_norm = 4.4974
	new_data_grads_norm = 6.3976
	old_data_grads_norm = 6.4907
	sim_grads_norm = -0.0312
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0266
	data_grads_norm = 4.6820
	new_data_grads_norm = 5.9058
	old_data_grads_norm = 7.1887
	sim_grads_norm = 0.0083
-- Starting training on experience 164 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3919
	data_grads_norm = 3.7580
	new_data_grads_norm = 5.7803
	old_data_grads_norm = 3.9311
	sim_grads_norm = 0.0793
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8670
	data_grads_norm = 3.3638
	new_data_grads_norm = 5.2232
	old_data_grads_norm = 5.3153
	sim_grads_norm = 0.0170
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8766
	data_grads_norm = 4.8016
	new_data_grads_norm = 5.5257
	old_data_grads_norm = 7.3771
	sim_grads_norm = 0.0054
-- Starting training on experience 165 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7820
	data_grads_norm = 4.0293
	new_data_grads_norm = 6.5404
	old_data_grads_norm = 4.3107
	sim_grads_norm = 0.0782
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0543
	data_grads_norm = 4.2231
	new_data_grads_norm = 5.3029
	old_data_grads_norm = 3.8876
	sim_grads_norm = 0.1344
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6856
	data_grads_norm = 4.3854
	new_data_grads_norm = 6.0924
	old_data_grads_norm = 5.2430
	sim_grads_norm = 0.0195
-- Starting training on experience 166 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6467
	data_grads_norm = 3.5784
	new_data_grads_norm = 5.1791
	old_data_grads_norm = 5.1621
	sim_grads_norm = 0.0707
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7449
	data_grads_norm = 3.0874
	new_data_grads_norm = 5.2596
	old_data_grads_norm = 4.5135
	sim_grads_norm = -0.0276
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8482
	data_grads_norm = 4.6133
	new_data_grads_norm = 5.5925
	old_data_grads_norm = 7.0358
	sim_grads_norm = 0.0253
-- Starting training on experience 167 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2951
	data_grads_norm = 3.7152
	new_data_grads_norm = 5.3549
	old_data_grads_norm = 5.9779
	sim_grads_norm = -0.0388
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2616
	data_grads_norm = 3.6475
	new_data_grads_norm = 5.2743
	old_data_grads_norm = 4.4615
	sim_grads_norm = 0.0531
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8960
	data_grads_norm = 3.6542
	new_data_grads_norm = 5.1626
	old_data_grads_norm = 4.4556
	sim_grads_norm = -0.0282
-- Starting training on experience 168 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3684
	data_grads_norm = 3.6001
	new_data_grads_norm = 5.8527
	old_data_grads_norm = 4.7253
	sim_grads_norm = 0.0126
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0919
	data_grads_norm = 4.1104
	new_data_grads_norm = 6.1324
	old_data_grads_norm = 5.5014
	sim_grads_norm = -0.0015
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4095
	data_grads_norm = 3.8481
	new_data_grads_norm = 5.3838
	old_data_grads_norm = 4.0887
	sim_grads_norm = 0.0065
-- Starting training on experience 169 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6112
	data_grads_norm = 3.9659
	new_data_grads_norm = 5.3413
	old_data_grads_norm = 4.8014
	sim_grads_norm = 0.0009
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7727
	data_grads_norm = 4.2991
	new_data_grads_norm = 5.0680
	old_data_grads_norm = 6.2508
	sim_grads_norm = 0.0488
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6346
	data_grads_norm = 3.6812
	new_data_grads_norm = 5.4389
	old_data_grads_norm = 5.4328
	sim_grads_norm = -0.0007
-- Starting training on experience 170 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0647
	data_grads_norm = 4.4554
	new_data_grads_norm = 6.2083
	old_data_grads_norm = 6.2672
	sim_grads_norm = 0.0527
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7035
	data_grads_norm = 4.3951
	new_data_grads_norm = 6.0444
	old_data_grads_norm = 5.3476
	sim_grads_norm = -0.0065
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4417
	data_grads_norm = 3.3891
	new_data_grads_norm = 5.6284
	old_data_grads_norm = 4.2493
	sim_grads_norm = 0.0275
-- Starting training on experience 171 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9268
	data_grads_norm = 4.4965
	new_data_grads_norm = 6.2617
	old_data_grads_norm = 5.2546
	sim_grads_norm = 0.0192
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4653
	data_grads_norm = 3.7387
	new_data_grads_norm = 5.8109
	old_data_grads_norm = 4.3744
	sim_grads_norm = -0.0158
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2452
	data_grads_norm = 4.4778
	new_data_grads_norm = 6.3196
	old_data_grads_norm = 5.2401
	sim_grads_norm = 0.0343
-- Starting training on experience 172 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3681
	data_grads_norm = 3.8785
	new_data_grads_norm = 5.5642
	old_data_grads_norm = 5.4526
	sim_grads_norm = -0.0180
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5356
	data_grads_norm = 3.5742
	new_data_grads_norm = 5.6620
	old_data_grads_norm = 4.6302
	sim_grads_norm = 0.0236
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6953
	data_grads_norm = 4.3339
	new_data_grads_norm = 5.4997
	old_data_grads_norm = 6.3070
	sim_grads_norm = -0.0088
-- Starting training on experience 173 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5970
	data_grads_norm = 3.5377
	new_data_grads_norm = 6.2778
	old_data_grads_norm = 3.6331
	sim_grads_norm = -0.0592
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8790
	data_grads_norm = 4.5425
	new_data_grads_norm = 6.9836
	old_data_grads_norm = 5.7826
	sim_grads_norm = -0.0393
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9799
	data_grads_norm = 4.2979
	new_data_grads_norm = 7.4330
	old_data_grads_norm = 5.2007
	sim_grads_norm = -0.0028
-- Starting training on experience 174 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4702
	data_grads_norm = 3.8832
	new_data_grads_norm = 5.0971
	old_data_grads_norm = 4.8249
	sim_grads_norm = 0.0533
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1764
	data_grads_norm = 4.6721
	new_data_grads_norm = 5.2300
	old_data_grads_norm = 7.3617
	sim_grads_norm = 0.0637
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5025
	data_grads_norm = 4.5787
	new_data_grads_norm = 4.9065
	old_data_grads_norm = 5.9937
	sim_grads_norm = 0.0538
-- Starting training on experience 175 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4186
	data_grads_norm = 3.9609
	new_data_grads_norm = 4.7182
	old_data_grads_norm = 4.9182
	sim_grads_norm = 0.0162
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0826
	data_grads_norm = 3.4175
	new_data_grads_norm = 4.9839
	old_data_grads_norm = 5.0963
	sim_grads_norm = -0.0043
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5559
	data_grads_norm = 3.2899
	new_data_grads_norm = 5.4543
	old_data_grads_norm = 5.0414
	sim_grads_norm = 0.0088
-- Starting training on experience 176 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0827
	data_grads_norm = 3.5216
	new_data_grads_norm = 4.9294
	old_data_grads_norm = 4.2920
	sim_grads_norm = -0.0205
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0248
	data_grads_norm = 3.5745
	new_data_grads_norm = 4.6929
	old_data_grads_norm = 4.7463
	sim_grads_norm = -0.0233
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4124
	data_grads_norm = 3.7172
	new_data_grads_norm = 5.8710
	old_data_grads_norm = 4.1219
	sim_grads_norm = 0.0196
-- Starting training on experience 177 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4934
	data_grads_norm = 3.7371
	new_data_grads_norm = 5.9662
	old_data_grads_norm = 4.5275
	sim_grads_norm = 0.0430
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3957
	data_grads_norm = 4.0632
	new_data_grads_norm = 5.6005
	old_data_grads_norm = 6.3808
	sim_grads_norm = 0.0134
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9076
	data_grads_norm = 4.4419
	new_data_grads_norm = 6.2250
	old_data_grads_norm = 6.5113
	sim_grads_norm = 0.0121
-- Starting training on experience 178 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9994
	data_grads_norm = 2.8962
	new_data_grads_norm = 5.6193
	old_data_grads_norm = 4.5838
	sim_grads_norm = 0.0070
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8211
	data_grads_norm = 4.2787
	new_data_grads_norm = 5.8718
	old_data_grads_norm = 4.8038
	sim_grads_norm = 0.0707
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6480
	data_grads_norm = 3.5909
	new_data_grads_norm = 5.4236
	old_data_grads_norm = 3.8754
	sim_grads_norm = 0.0633
-- Starting training on experience 179 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6382
	data_grads_norm = 3.8192
	new_data_grads_norm = 5.8196
	old_data_grads_norm = 5.0866
	sim_grads_norm = 0.0043
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8939
	data_grads_norm = 3.9800
	new_data_grads_norm = 5.5106
	old_data_grads_norm = 5.0727
	sim_grads_norm = 0.0294
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4792
	data_grads_norm = 3.6660
	new_data_grads_norm = 5.5560
	old_data_grads_norm = 4.3855
	sim_grads_norm = -0.0382
-- Starting training on experience 180 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0737
	data_grads_norm = 4.0298
	new_data_grads_norm = 6.2923
	old_data_grads_norm = 5.4905
	sim_grads_norm = 0.0691
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6288
	data_grads_norm = 3.9764
	new_data_grads_norm = 5.9129
	old_data_grads_norm = 5.1275
	sim_grads_norm = -0.0201
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5309
	data_grads_norm = 3.5617
	new_data_grads_norm = 5.9430
	old_data_grads_norm = 5.3835
	sim_grads_norm = 0.0353
-- Starting training on experience 181 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9425
	data_grads_norm = 3.8918
	new_data_grads_norm = 5.9793
	old_data_grads_norm = 5.0259
	sim_grads_norm = -0.0121
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1526
	data_grads_norm = 3.6726
	new_data_grads_norm = 6.0038
	old_data_grads_norm = 4.5148
	sim_grads_norm = -0.0327
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0521
	data_grads_norm = 3.6936
	new_data_grads_norm = 6.1739
	old_data_grads_norm = 5.8456
	sim_grads_norm = -0.0150
-- Starting training on experience 182 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0405
	data_grads_norm = 3.0540
	new_data_grads_norm = 5.1257
	old_data_grads_norm = 3.8515
	sim_grads_norm = -0.0006
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1754
	data_grads_norm = 3.1931
	new_data_grads_norm = 5.2259
	old_data_grads_norm = 4.3088
	sim_grads_norm = 0.0629
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4099
	data_grads_norm = 4.0409
	new_data_grads_norm = 5.1763
	old_data_grads_norm = 5.4040
	sim_grads_norm = 0.0532
-- Starting training on experience 183 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4871
	data_grads_norm = 3.4485
	new_data_grads_norm = 6.7233
	old_data_grads_norm = 3.7708
	sim_grads_norm = 0.0141
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4045
	data_grads_norm = 3.8854
	new_data_grads_norm = 5.7688
	old_data_grads_norm = 5.6749
	sim_grads_norm = 0.0318
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0358
	data_grads_norm = 3.2649
	new_data_grads_norm = 6.0085
	old_data_grads_norm = 3.5041
	sim_grads_norm = -0.0245
-- Starting training on experience 184 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2383
	data_grads_norm = 4.3248
	new_data_grads_norm = 5.0620
	old_data_grads_norm = 5.8742
	sim_grads_norm = -0.0485
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1381
	data_grads_norm = 3.5857
	new_data_grads_norm = 5.6003
	old_data_grads_norm = 4.0796
	sim_grads_norm = -0.0387
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4679
	data_grads_norm = 4.8844
	new_data_grads_norm = 5.4744
	old_data_grads_norm = 5.9877
	sim_grads_norm = 0.0071
-- Starting training on experience 185 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8151
	data_grads_norm = 4.2118
	new_data_grads_norm = 6.4435
	old_data_grads_norm = 4.6644
	sim_grads_norm = -0.0103
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0372
	data_grads_norm = 4.4350
	new_data_grads_norm = 6.5995
	old_data_grads_norm = 5.4759
	sim_grads_norm = 0.0456
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8548
	data_grads_norm = 4.2002
	new_data_grads_norm = 6.6059
	old_data_grads_norm = 4.4517
	sim_grads_norm = 0.0225
-- Starting training on experience 186 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6068
	data_grads_norm = 3.7106
	new_data_grads_norm = 5.8839
	old_data_grads_norm = 4.5105
	sim_grads_norm = -0.0032
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3661
	data_grads_norm = 3.8416
	new_data_grads_norm = 6.1946
	old_data_grads_norm = 4.4145
	sim_grads_norm = 0.0037
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4691
	data_grads_norm = 3.9533
	new_data_grads_norm = 6.1780
	old_data_grads_norm = 5.0992
	sim_grads_norm = -0.0443
-- Starting training on experience 187 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5357
	data_grads_norm = 3.6128
	new_data_grads_norm = 5.7224
	old_data_grads_norm = 3.9933
	sim_grads_norm = 0.0681
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8286
	data_grads_norm = 4.2094
	new_data_grads_norm = 5.7614
	old_data_grads_norm = 5.8794
	sim_grads_norm = -0.0001
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6859
	data_grads_norm = 4.2800
	new_data_grads_norm = 5.3978
	old_data_grads_norm = 6.1580
	sim_grads_norm = -0.0414
-- Starting training on experience 188 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7160
	data_grads_norm = 4.2452
	new_data_grads_norm = 5.7080
	old_data_grads_norm = 5.8940
	sim_grads_norm = 0.0257
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7569
	data_grads_norm = 4.2559
	new_data_grads_norm = 5.5413
	old_data_grads_norm = 5.7027
	sim_grads_norm = 0.0253
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3500
	data_grads_norm = 3.0194
	new_data_grads_norm = 5.2812
	old_data_grads_norm = 3.0579
	sim_grads_norm = 0.0422
-- Starting training on experience 189 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7041
	data_grads_norm = 3.9493
	new_data_grads_norm = 5.6974
	old_data_grads_norm = 6.1382
	sim_grads_norm = -0.0139
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6194
	data_grads_norm = 3.6834
	new_data_grads_norm = 6.9235
	old_data_grads_norm = 3.6258
	sim_grads_norm = 0.0003
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1433
	data_grads_norm = 4.1123
	new_data_grads_norm = 6.4786
	old_data_grads_norm = 5.1413
	sim_grads_norm = 0.0817
-- Starting training on experience 190 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5578
	data_grads_norm = 4.4932
	new_data_grads_norm = 5.0336
	old_data_grads_norm = 6.8860
	sim_grads_norm = -0.0053
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0682
	data_grads_norm = 3.5050
	new_data_grads_norm = 5.1885
	old_data_grads_norm = 4.1400
	sim_grads_norm = 0.0680
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3875
	data_grads_norm = 4.5406
	new_data_grads_norm = 5.3640
	old_data_grads_norm = 6.1579
	sim_grads_norm = 0.0248
-- Starting training on experience 191 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1999
	data_grads_norm = 3.9017
	new_data_grads_norm = 5.4242
	old_data_grads_norm = 6.1859
	sim_grads_norm = -0.0365
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3891
	data_grads_norm = 3.7194
	new_data_grads_norm = 5.4718
	old_data_grads_norm = 4.7222
	sim_grads_norm = -0.0202
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2139
	data_grads_norm = 3.2720
	new_data_grads_norm = 5.6455
	old_data_grads_norm = 4.2852
	sim_grads_norm = 0.0063
-- Starting training on experience 192 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0703
	data_grads_norm = 3.7856
	new_data_grads_norm = 5.2103
	old_data_grads_norm = 5.6427
	sim_grads_norm = -0.0320
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4839
	data_grads_norm = 4.4487
	new_data_grads_norm = 5.2313
	old_data_grads_norm = 5.5236
	sim_grads_norm = -0.0173
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3017
	data_grads_norm = 3.8304
	new_data_grads_norm = 5.6592
	old_data_grads_norm = 5.7687
	sim_grads_norm = 0.0026
-- Starting training on experience 193 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6239
	data_grads_norm = 4.4433
	new_data_grads_norm = 5.4489
	old_data_grads_norm = 7.1529
	sim_grads_norm = 0.0024
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2923
	data_grads_norm = 3.5192
	new_data_grads_norm = 5.1672
	old_data_grads_norm = 4.5856
	sim_grads_norm = 0.0427
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8166
	data_grads_norm = 4.2814
	new_data_grads_norm = 5.5492
	old_data_grads_norm = 5.3136
	sim_grads_norm = 0.0770
-- Starting training on experience 194 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4750
	data_grads_norm = 4.3912
	new_data_grads_norm = 5.3806
	old_data_grads_norm = 6.8136
	sim_grads_norm = -0.0108
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0159
	data_grads_norm = 3.3582
	new_data_grads_norm = 5.6778
	old_data_grads_norm = 4.5317
	sim_grads_norm = 0.0302
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2420
	data_grads_norm = 3.5703
	new_data_grads_norm = 5.7322
	old_data_grads_norm = 4.6989
	sim_grads_norm = -0.0207
-- Starting training on experience 195 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5280
	data_grads_norm = 3.7410
	new_data_grads_norm = 5.4012
	old_data_grads_norm = 5.3713
	sim_grads_norm = 0.0025
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4729
	data_grads_norm = 3.8278
	new_data_grads_norm = 5.2701
	old_data_grads_norm = 4.9368
	sim_grads_norm = -0.0222
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5424
	data_grads_norm = 4.0589
	new_data_grads_norm = 5.7108
	old_data_grads_norm = 6.0629
	sim_grads_norm = -0.0388
-- Starting training on experience 196 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7272
	data_grads_norm = 4.0384
	new_data_grads_norm = 6.0056
	old_data_grads_norm = 4.6883
	sim_grads_norm = 0.0877
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2717
	data_grads_norm = 3.8624
	new_data_grads_norm = 5.2187
	old_data_grads_norm = 5.3002
	sim_grads_norm = -0.0266
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3160
	data_grads_norm = 4.0799
	new_data_grads_norm = 5.7581
	old_data_grads_norm = 5.2219
	sim_grads_norm = 0.0564
-- Starting training on experience 197 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4609
	data_grads_norm = 3.5613
	new_data_grads_norm = 5.5851
	old_data_grads_norm = 5.0495
	sim_grads_norm = 0.0201
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6006
	data_grads_norm = 4.2409
	new_data_grads_norm = 5.3772
	old_data_grads_norm = 6.0784
	sim_grads_norm = 0.0088
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3193
	data_grads_norm = 4.1920
	new_data_grads_norm = 5.6031
	old_data_grads_norm = 5.9757
	sim_grads_norm = 0.0404
-- Starting training on experience 198 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7353
	data_grads_norm = 3.7547
	new_data_grads_norm = 5.9435
	old_data_grads_norm = 5.5140
	sim_grads_norm = -0.0012
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5671
	data_grads_norm = 4.3978
	new_data_grads_norm = 7.1294
	old_data_grads_norm = 5.7836
	sim_grads_norm = 0.0504
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4706
	data_grads_norm = 3.8444
	new_data_grads_norm = 5.5674
	old_data_grads_norm = 5.6617
	sim_grads_norm = -0.0198
-- Starting training on experience 199 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3954
	data_grads_norm = 3.6953
	new_data_grads_norm = 6.0572
	old_data_grads_norm = 5.2976
	sim_grads_norm = -0.0016
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1885
	data_grads_norm = 3.7099
	new_data_grads_norm = 6.1203
	old_data_grads_norm = 4.4007
	sim_grads_norm = -0.0223
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6342
	data_grads_norm = 4.0853
	new_data_grads_norm = 6.1745
	old_data_grads_norm = 6.1896
	sim_grads_norm = -0.1049
-- Starting training on experience 200 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2794
	data_grads_norm = 4.1925
	new_data_grads_norm = 5.7795
	old_data_grads_norm = 5.3142
	sim_grads_norm = 0.0492
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3134
	data_grads_norm = 4.0323
	new_data_grads_norm = 5.2198
	old_data_grads_norm = 5.8330
	sim_grads_norm = 0.0085
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3695
	data_grads_norm = 3.5470
	new_data_grads_norm = 5.1666
	old_data_grads_norm = 4.1674
	sim_grads_norm = 0.1047
-- Starting training on experience 201 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1995
	data_grads_norm = 3.9280
	new_data_grads_norm = 5.7656
	old_data_grads_norm = 4.8716
	sim_grads_norm = -0.0306
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1392
	data_grads_norm = 3.6527
	new_data_grads_norm = 5.3304
	old_data_grads_norm = 5.0008
	sim_grads_norm = -0.0425
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3972
	data_grads_norm = 3.8162
	new_data_grads_norm = 5.0837
	old_data_grads_norm = 6.0460
	sim_grads_norm = -0.0712
-- Starting training on experience 202 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5664
	data_grads_norm = 3.5775
	new_data_grads_norm = 5.5950
	old_data_grads_norm = 4.9221
	sim_grads_norm = 0.0293
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6232
	data_grads_norm = 3.9802
	new_data_grads_norm = 5.6935
	old_data_grads_norm = 5.4774
	sim_grads_norm = 0.0377
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8045
	data_grads_norm = 4.3477
	new_data_grads_norm = 5.0877
	old_data_grads_norm = 6.7689
	sim_grads_norm = -0.0065
-- Starting training on experience 203 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2331
	data_grads_norm = 3.7937
	new_data_grads_norm = 5.7500
	old_data_grads_norm = 4.4493
	sim_grads_norm = 0.0501
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7048
	data_grads_norm = 4.5560
	new_data_grads_norm = 5.7440
	old_data_grads_norm = 5.8375
	sim_grads_norm = 0.0292
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1684
	data_grads_norm = 3.6909
	new_data_grads_norm = 6.0380
	old_data_grads_norm = 4.6739
	sim_grads_norm = -0.0122
-- Starting training on experience 204 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8456
	data_grads_norm = 3.8520
	new_data_grads_norm = 5.7104
	old_data_grads_norm = 5.1009
	sim_grads_norm = 0.0022
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0733
	data_grads_norm = 3.0924
	new_data_grads_norm = 5.3876
	old_data_grads_norm = 2.6782
	sim_grads_norm = -0.0396
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3588
	data_grads_norm = 3.7625
	new_data_grads_norm = 6.0689
	old_data_grads_norm = 4.3919
	sim_grads_norm = 0.0000
-- Starting training on experience 205 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3677
	data_grads_norm = 3.9106
	new_data_grads_norm = 5.8935
	old_data_grads_norm = 6.0497
	sim_grads_norm = 0.0271
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4008
	data_grads_norm = 4.1725
	new_data_grads_norm = 5.8536
	old_data_grads_norm = 5.9512
	sim_grads_norm = 0.0148
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5842
	data_grads_norm = 4.3973
	new_data_grads_norm = 5.7109
	old_data_grads_norm = 6.8234
	sim_grads_norm = -0.0138
-- Starting training on experience 206 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9446
	data_grads_norm = 4.6597
	new_data_grads_norm = 6.1280
	old_data_grads_norm = 5.8265
	sim_grads_norm = 0.0555
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5390
	data_grads_norm = 4.1154
	new_data_grads_norm = 6.6140
	old_data_grads_norm = 5.6089
	sim_grads_norm = -0.0292
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5769
	data_grads_norm = 3.3950
	new_data_grads_norm = 5.3512
	old_data_grads_norm = 4.6455
	sim_grads_norm = 0.0163
-- Starting training on experience 207 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2708
	data_grads_norm = 4.1475
	new_data_grads_norm = 5.6656
	old_data_grads_norm = 5.9179
	sim_grads_norm = 0.1084
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2378
	data_grads_norm = 4.0120
	new_data_grads_norm = 5.6177
	old_data_grads_norm = 5.7103
	sim_grads_norm = 0.0513
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1844
	data_grads_norm = 3.7468
	new_data_grads_norm = 6.0260
	old_data_grads_norm = 5.1956
	sim_grads_norm = -0.0212
-- Starting training on experience 208 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5516
	data_grads_norm = 4.9180
	new_data_grads_norm = 7.0851
	old_data_grads_norm = 5.7042
	sim_grads_norm = 0.0075
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6802
	data_grads_norm = 4.6298
	new_data_grads_norm = 7.0004
	old_data_grads_norm = 4.6751
	sim_grads_norm = 0.0097
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3610
	data_grads_norm = 4.7957
	new_data_grads_norm = 7.1475
	old_data_grads_norm = 5.4225
	sim_grads_norm = 0.0170
-- Starting training on experience 209 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8807
	data_grads_norm = 3.9951
	new_data_grads_norm = 6.3339
	old_data_grads_norm = 4.6103
	sim_grads_norm = 0.0046
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7772
	data_grads_norm = 4.1209
	new_data_grads_norm = 6.5902
	old_data_grads_norm = 4.6146
	sim_grads_norm = 0.0842
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1305
	data_grads_norm = 4.3213
	new_data_grads_norm = 6.4617
	old_data_grads_norm = 5.3707
	sim_grads_norm = 0.0447
-- Starting training on experience 210 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5324
	data_grads_norm = 4.8033
	new_data_grads_norm = 6.8505
	old_data_grads_norm = 5.7273
	sim_grads_norm = 0.0180
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7381
	data_grads_norm = 4.4001
	new_data_grads_norm = 6.4648
	old_data_grads_norm = 5.4217
	sim_grads_norm = 0.0570
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5956
	data_grads_norm = 4.4061
	new_data_grads_norm = 6.0794
	old_data_grads_norm = 5.6111
	sim_grads_norm = -0.0387
-- Starting training on experience 211 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6845
	data_grads_norm = 3.6902
	new_data_grads_norm = 5.5899
	old_data_grads_norm = 4.4278
	sim_grads_norm = 0.0492
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4781
	data_grads_norm = 3.3143
	new_data_grads_norm = 5.0442
	old_data_grads_norm = 4.4684
	sim_grads_norm = 0.0231
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6260
	data_grads_norm = 4.5449
	new_data_grads_norm = 5.6704
	old_data_grads_norm = 5.3335
	sim_grads_norm = 0.0495
-- Starting training on experience 212 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9093
	data_grads_norm = 3.6256
	new_data_grads_norm = 6.2016
	old_data_grads_norm = 4.4870
	sim_grads_norm = 0.0374
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6069
	data_grads_norm = 4.0080
	new_data_grads_norm = 5.3502
	old_data_grads_norm = 6.0953
	sim_grads_norm = -0.0187
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0906
	data_grads_norm = 3.6108
	new_data_grads_norm = 5.7159
	old_data_grads_norm = 5.1569
	sim_grads_norm = 0.0078
-- Starting training on experience 213 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4225
	data_grads_norm = 3.4149
	new_data_grads_norm = 5.3250
	old_data_grads_norm = 4.5677
	sim_grads_norm = -0.0173
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8325
	data_grads_norm = 3.7202
	new_data_grads_norm = 5.9151
	old_data_grads_norm = 4.8033
	sim_grads_norm = -0.0123
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4108
	data_grads_norm = 3.3950
	new_data_grads_norm = 5.7276
	old_data_grads_norm = 4.7012
	sim_grads_norm = 0.0289
-- Starting training on experience 214 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6221
	data_grads_norm = 4.1768
	new_data_grads_norm = 5.6586
	old_data_grads_norm = 6.0263
	sim_grads_norm = 0.0074
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4144
	data_grads_norm = 3.7219
	new_data_grads_norm = 5.3540
	old_data_grads_norm = 4.9995
	sim_grads_norm = 0.0325
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3492
	data_grads_norm = 3.7057
	new_data_grads_norm = 5.7769
	old_data_grads_norm = 5.1193
	sim_grads_norm = -0.0224
-- Starting training on experience 215 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2430
	data_grads_norm = 4.1608
	new_data_grads_norm = 6.1629
	old_data_grads_norm = 5.1702
	sim_grads_norm = -0.0202
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1959
	data_grads_norm = 4.2441
	new_data_grads_norm = 6.2590
	old_data_grads_norm = 5.8903
	sim_grads_norm = -0.0115
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4964
	data_grads_norm = 4.3352
	new_data_grads_norm = 6.9190
	old_data_grads_norm = 5.5519
	sim_grads_norm = 0.0416
-- Starting training on experience 216 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3191
	data_grads_norm = 3.5364
	new_data_grads_norm = 6.5023
	old_data_grads_norm = 3.7375
	sim_grads_norm = 0.0124
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7434
	data_grads_norm = 4.2504
	new_data_grads_norm = 6.4531
	old_data_grads_norm = 4.7801
	sim_grads_norm = 0.0230
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7829
	data_grads_norm = 4.5833
	new_data_grads_norm = 6.5218
	old_data_grads_norm = 6.0269
	sim_grads_norm = -0.0165
-- Starting training on experience 217 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6287
	data_grads_norm = 4.4622
	new_data_grads_norm = 6.6638
	old_data_grads_norm = 5.7412
	sim_grads_norm = -0.0269
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7287
	data_grads_norm = 4.4030
	new_data_grads_norm = 6.5334
	old_data_grads_norm = 4.7395
	sim_grads_norm = 0.0737
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9502
	data_grads_norm = 4.3138
	new_data_grads_norm = 6.5606
	old_data_grads_norm = 4.8448
	sim_grads_norm = 0.1085
-- Starting training on experience 218 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9253
	data_grads_norm = 5.2615
	new_data_grads_norm = 6.4180
	old_data_grads_norm = 7.7098
	sim_grads_norm = 0.0921
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8761
	data_grads_norm = 4.4986
	new_data_grads_norm = 5.9220
	old_data_grads_norm = 6.4214
	sim_grads_norm = -0.0148
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2507
	data_grads_norm = 3.5664
	new_data_grads_norm = 5.6182
	old_data_grads_norm = 4.9909
	sim_grads_norm = 0.0064
-- Starting training on experience 219 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6520
	data_grads_norm = 4.4144
	new_data_grads_norm = 6.4540
	old_data_grads_norm = 5.2269
	sim_grads_norm = 0.0442
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1931
	data_grads_norm = 3.6483
	new_data_grads_norm = 5.9243
	old_data_grads_norm = 3.7476
	sim_grads_norm = 0.0211
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1588
	data_grads_norm = 3.8329
	new_data_grads_norm = 5.8616
	old_data_grads_norm = 5.3848
	sim_grads_norm = 0.0291
-- Starting training on experience 220 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9015
	data_grads_norm = 3.4177
	new_data_grads_norm = 5.3031
	old_data_grads_norm = 4.9310
	sim_grads_norm = 0.0167
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0875
	data_grads_norm = 3.6754
	new_data_grads_norm = 4.7216
	old_data_grads_norm = 4.9765
	sim_grads_norm = 0.0034
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6599
	data_grads_norm = 4.0504
	new_data_grads_norm = 5.5630
	old_data_grads_norm = 5.7684
	sim_grads_norm = -0.0582
-- Starting training on experience 221 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6273
	data_grads_norm = 4.1187
	new_data_grads_norm = 5.6112
	old_data_grads_norm = 5.8835
	sim_grads_norm = -0.0327
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4112
	data_grads_norm = 3.7683
	new_data_grads_norm = 6.0217
	old_data_grads_norm = 4.5934
	sim_grads_norm = -0.0785
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1147
	data_grads_norm = 4.6505
	new_data_grads_norm = 6.7745
	old_data_grads_norm = 5.0618
	sim_grads_norm = 0.0174
-- Starting training on experience 222 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5994
	data_grads_norm = 4.5347
	new_data_grads_norm = 6.9024
	old_data_grads_norm = 5.3690
	sim_grads_norm = 0.0224
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4038
	data_grads_norm = 4.0970
	new_data_grads_norm = 6.6266
	old_data_grads_norm = 4.4942
	sim_grads_norm = -0.0396
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0178
	data_grads_norm = 4.5760
	new_data_grads_norm = 7.2927
	old_data_grads_norm = 5.7279
	sim_grads_norm = 0.0442
-- Starting training on experience 223 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3980
	data_grads_norm = 4.0795
	new_data_grads_norm = 5.8403
	old_data_grads_norm = 5.6585
	sim_grads_norm = -0.0082
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7528
	data_grads_norm = 4.5571
	new_data_grads_norm = 5.9368
	old_data_grads_norm = 6.2258
	sim_grads_norm = 0.0142
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2543
	data_grads_norm = 3.9712
	new_data_grads_norm = 5.9413
	old_data_grads_norm = 4.7910
	sim_grads_norm = 0.0008
-- Starting training on experience 224 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3552
	data_grads_norm = 3.8089
	new_data_grads_norm = 5.6604
	old_data_grads_norm = 4.5671
	sim_grads_norm = -0.0185
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3746
	data_grads_norm = 3.8466
	new_data_grads_norm = 5.9341
	old_data_grads_norm = 6.3144
	sim_grads_norm = -0.0333
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6207
	data_grads_norm = 4.3891
	new_data_grads_norm = 6.6263
	old_data_grads_norm = 5.1725
	sim_grads_norm = 0.0387
-- Starting training on experience 225 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3343
	data_grads_norm = 4.6208
	new_data_grads_norm = 5.6904
	old_data_grads_norm = 7.3103
	sim_grads_norm = 0.0097
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6420
	data_grads_norm = 4.3057
	new_data_grads_norm = 5.4918
	old_data_grads_norm = 4.3455
	sim_grads_norm = 0.0657
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0365
	data_grads_norm = 3.6830
	new_data_grads_norm = 5.9276
	old_data_grads_norm = 3.9529
	sim_grads_norm = -0.0282
-- Starting training on experience 226 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8701
	data_grads_norm = 4.6649
	new_data_grads_norm = 5.9461
	old_data_grads_norm = 6.6229
	sim_grads_norm = 0.0063
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3331
	data_grads_norm = 4.4142
	new_data_grads_norm = 6.2073
	old_data_grads_norm = 6.2107
	sim_grads_norm = -0.0054
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4939
	data_grads_norm = 4.2962
	new_data_grads_norm = 6.6913
	old_data_grads_norm = 5.7679
	sim_grads_norm = 0.0122
-- Starting training on experience 227 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4627
	data_grads_norm = 4.1099
	new_data_grads_norm = 5.4968
	old_data_grads_norm = 5.2956
	sim_grads_norm = -0.0149
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2024
	data_grads_norm = 3.5808
	new_data_grads_norm = 5.4365
	old_data_grads_norm = 4.3414
	sim_grads_norm = 0.0180
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1263
	data_grads_norm = 3.3851
	new_data_grads_norm = 5.3132
	old_data_grads_norm = 4.6379
	sim_grads_norm = -0.0622
-- Starting training on experience 228 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4688
	data_grads_norm = 4.1977
	new_data_grads_norm = 5.6903
	old_data_grads_norm = 6.4556
	sim_grads_norm = 0.0024
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1852
	data_grads_norm = 3.4039
	new_data_grads_norm = 5.1980
	old_data_grads_norm = 4.4627
	sim_grads_norm = -0.0014
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7006
	data_grads_norm = 3.9140
	new_data_grads_norm = 5.8262
	old_data_grads_norm = 5.1256
	sim_grads_norm = 0.0255
-- Starting training on experience 229 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9623
	data_grads_norm = 3.8482
	new_data_grads_norm = 6.1601
	old_data_grads_norm = 4.8548
	sim_grads_norm = -0.0524
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4917
	data_grads_norm = 4.2742
	new_data_grads_norm = 6.9528
	old_data_grads_norm = 5.1269
	sim_grads_norm = 0.0296
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9353
	data_grads_norm = 4.0754
	new_data_grads_norm = 6.3156
	old_data_grads_norm = 4.5417
	sim_grads_norm = -0.0292
-- Starting training on experience 230 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1093
	data_grads_norm = 3.6669
	new_data_grads_norm = 5.6972
	old_data_grads_norm = 4.8725
	sim_grads_norm = -0.0138
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1504
	data_grads_norm = 3.4988
	new_data_grads_norm = 5.5198
	old_data_grads_norm = 4.5684
	sim_grads_norm = -0.0021
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9646
	data_grads_norm = 3.2102
	new_data_grads_norm = 5.7279
	old_data_grads_norm = 3.6604
	sim_grads_norm = -0.0219
-- Starting training on experience 231 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4658
	data_grads_norm = 4.1545
	new_data_grads_norm = 5.9500
	old_data_grads_norm = 5.2865
	sim_grads_norm = -0.0297
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4602
	data_grads_norm = 4.5512
	new_data_grads_norm = 5.6634
	old_data_grads_norm = 6.4791
	sim_grads_norm = 0.0618
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4233
	data_grads_norm = 3.9562
	new_data_grads_norm = 5.5986
	old_data_grads_norm = 4.7347
	sim_grads_norm = 0.0392
-- Starting training on experience 232 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4871
	data_grads_norm = 4.5561
	new_data_grads_norm = 6.1031
	old_data_grads_norm = 6.2765
	sim_grads_norm = -0.0397
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5009
	data_grads_norm = 4.0019
	new_data_grads_norm = 6.2809
	old_data_grads_norm = 4.4662
	sim_grads_norm = 0.0662
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1036
	data_grads_norm = 4.0162
	new_data_grads_norm = 6.2614
	old_data_grads_norm = 5.9266
	sim_grads_norm = -0.0335
-- Starting training on experience 233 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8835
	data_grads_norm = 3.8961
	new_data_grads_norm = 6.3728
	old_data_grads_norm = 3.4619
	sim_grads_norm = 0.0408
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0648
	data_grads_norm = 3.8768
	new_data_grads_norm = 5.9896
	old_data_grads_norm = 4.4375
	sim_grads_norm = -0.0706
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6067
	data_grads_norm = 4.4673
	new_data_grads_norm = 6.9983
	old_data_grads_norm = 5.3350
	sim_grads_norm = 0.0284
-- Starting training on experience 234 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4604
	data_grads_norm = 4.0820
	new_data_grads_norm = 7.2063
	old_data_grads_norm = 3.4967
	sim_grads_norm = 0.0515
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1144
	data_grads_norm = 5.2213
	new_data_grads_norm = 7.0747
	old_data_grads_norm = 5.8741
	sim_grads_norm = -0.0255
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1188
	data_grads_norm = 4.7741
	new_data_grads_norm = 6.8291
	old_data_grads_norm = 5.4490
	sim_grads_norm = 0.0375
-- Starting training on experience 235 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6390
	data_grads_norm = 4.1348
	new_data_grads_norm = 5.5349
	old_data_grads_norm = 5.0357
	sim_grads_norm = 0.0262
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7825
	data_grads_norm = 4.4999
	new_data_grads_norm = 5.5954
	old_data_grads_norm = 6.4574
	sim_grads_norm = 0.0638
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2602
	data_grads_norm = 4.3470
	new_data_grads_norm = 5.4888
	old_data_grads_norm = 5.8791
	sim_grads_norm = 0.0062
-- Starting training on experience 236 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0884
	data_grads_norm = 3.6549
	new_data_grads_norm = 6.4778
	old_data_grads_norm = 4.3570
	sim_grads_norm = 0.0042
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9402
	data_grads_norm = 3.0529
	new_data_grads_norm = 5.8600
	old_data_grads_norm = 3.2105
	sim_grads_norm = -0.0192
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4374
	data_grads_norm = 3.8690
	new_data_grads_norm = 6.5036
	old_data_grads_norm = 4.2778
	sim_grads_norm = 0.0414
-- Starting training on experience 237 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
-- >> End of training phase << --
-- >> Start of eval phase << --
-- Starting eval on experience 0 (Task 0) from test stream --
> Eval on experience 0 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp000 = 3.6476
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.2480
	mb_index = 3094
	time = 802.0016
-- Starting eval on experience 1 (Task 0) from test stream --
> Eval on experience 1 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp001 = 2.2978
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.4980
-- Starting eval on experience 2 (Task 0) from test stream --
> Eval on experience 2 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp002 = 3.1004
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.3140
-- Starting eval on experience 3 (Task 0) from test stream --
> Eval on experience 3 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp003 = 2.5288
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.4680
-- Starting eval on experience 4 (Task 0) from test stream --
> Eval on experience 4 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp004 = 4.0238
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.2220
-- Starting eval on experience 5 (Task 0) from test stream --
> Eval on experience 5 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp005 = 2.9857
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.3820
-- Starting eval on experience 6 (Task 0) from test stream --
> Eval on experience 6 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp006 = 2.9799
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp006 = 0.3120
-- Starting eval on experience 7 (Task 0) from test stream --
> Eval on experience 7 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp007 = 3.0873
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp007 = 0.3400
-- Starting eval on experience 8 (Task 0) from test stream --
> Eval on experience 8 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp008 = 2.8648
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp008 = 0.3580
-- Starting eval on experience 9 (Task 0) from test stream --
> Eval on experience 9 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp009 = 2.4946
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp009 = 0.4140
-- Starting eval on experience 10 (Task 0) from test stream --
> Eval on experience 10 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp010 = 3.0097
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp010 = 0.2580
-- Starting eval on experience 11 (Task 0) from test stream --
> Eval on experience 11 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp011 = 2.3312
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp011 = 0.3820
-- Starting eval on experience 12 (Task 0) from test stream --
> Eval on experience 12 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp012 = 3.6637
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp012 = 0.0600
-- >> End of eval phase << --
	CumulativeAccuracy/eval_phase/test_stream/Exp000 = 0.7400
	CumulativeAccuracy/eval_phase/test_stream/Exp001 = 0.7020
	CumulativeAccuracy/eval_phase/test_stream/Exp002 = 0.6067
	CumulativeAccuracy/eval_phase/test_stream/Exp003 = 0.5705
	CumulativeAccuracy/eval_phase/test_stream/Exp004 = 0.5204
	CumulativeAccuracy/eval_phase/test_stream/Exp005 = 0.4793
	CumulativeAccuracy/eval_phase/test_stream/Exp006 = 0.4371
	CumulativeAccuracy/eval_phase/test_stream/Exp007 = 0.4123
	CumulativeAccuracy/eval_phase/test_stream/Exp008 = 0.3953
	CumulativeAccuracy/eval_phase/test_stream/Exp009 = 0.3856
	CumulativeAccuracy/eval_phase/test_stream/Exp010 = 0.3642
	CumulativeAccuracy/eval_phase/test_stream/Exp011 = 0.3527
	CumulativeAccuracy/eval_phase/test_stream/Exp012 = 0.3274
	Loss_Stream/eval_phase/test_stream/Task000 = 3.0012
	Top1_Acc_Stream/eval_phase/test_stream/Task000 = 0.3274
-- >> Start of training phase << --
-- Starting training on experience 0 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.9471
	data_grads_norm = 4.6422
	new_data_grads_norm = 6.3696
	old_data_grads_norm = 5.8015
	sim_grads_norm = 0.0230
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.8897
	data_grads_norm = 4.9867
	new_data_grads_norm = 6.2644
	old_data_grads_norm = 5.4282
	sim_grads_norm = -0.0071
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6614
	data_grads_norm = 4.5192
	new_data_grads_norm = 6.5058
	old_data_grads_norm = 5.8582
	sim_grads_norm = 0.0165
-- Starting training on experience 1 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2655
	data_grads_norm = 4.4972
	new_data_grads_norm = 6.8333
	old_data_grads_norm = 5.4301
	sim_grads_norm = 0.0196
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.9688
	data_grads_norm = 4.9595
	new_data_grads_norm = 6.8556
	old_data_grads_norm = 6.5265
	sim_grads_norm = 0.0099
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.8474
	data_grads_norm = 5.0874
	new_data_grads_norm = 7.2908
	old_data_grads_norm = 4.8201
	sim_grads_norm = -0.0168
-- Starting training on experience 2 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.9307
	data_grads_norm = 4.8031
	new_data_grads_norm = 6.7122
	old_data_grads_norm = 5.9449
	sim_grads_norm = 0.0000
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5246
	data_grads_norm = 4.5206
	new_data_grads_norm = 6.1894
	old_data_grads_norm = 5.3877
	sim_grads_norm = 0.1595
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3545
	data_grads_norm = 4.3414
	new_data_grads_norm = 6.2765
	old_data_grads_norm = 4.7949
	sim_grads_norm = 0.0156
-- Starting training on experience 3 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5365
	data_grads_norm = 4.1346
	new_data_grads_norm = 6.2659
	old_data_grads_norm = 4.4323
	sim_grads_norm = -0.0451
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.1293
	data_grads_norm = 4.6765
	new_data_grads_norm = 6.2919
	old_data_grads_norm = 6.4579
	sim_grads_norm = 0.0365
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6178
	data_grads_norm = 4.3862
	new_data_grads_norm = 5.9716
	old_data_grads_norm = 5.3890
	sim_grads_norm = -0.0122
-- Starting training on experience 4 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2331
	data_grads_norm = 3.9846
	new_data_grads_norm = 6.3027
	old_data_grads_norm = 4.5341
	sim_grads_norm = 0.0004
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1101
	data_grads_norm = 4.2141
	new_data_grads_norm = 5.8837
	old_data_grads_norm = 5.6505
	sim_grads_norm = 0.0524
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.7158
	data_grads_norm = 4.5885
	new_data_grads_norm = 6.4626
	old_data_grads_norm = 5.6922
	sim_grads_norm = 0.0348
-- Starting training on experience 5 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.3197
	data_grads_norm = 4.0881
	new_data_grads_norm = 5.5744
	old_data_grads_norm = 5.4543
	sim_grads_norm = 0.0784
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6011
	data_grads_norm = 4.1373
	new_data_grads_norm = 5.7741
	old_data_grads_norm = 5.0724
	sim_grads_norm = 0.0264
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9916
	data_grads_norm = 3.6984
	new_data_grads_norm = 5.7638
	old_data_grads_norm = 3.8061
	sim_grads_norm = 0.0239
-- Starting training on experience 6 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7250
	data_grads_norm = 3.8406
	new_data_grads_norm = 5.3956
	old_data_grads_norm = 5.7002
	sim_grads_norm = -0.0085
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0270
	data_grads_norm = 3.8581
	new_data_grads_norm = 5.3004
	old_data_grads_norm = 3.9716
	sim_grads_norm = -0.0038
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9884
	data_grads_norm = 3.6612
	new_data_grads_norm = 5.5703
	old_data_grads_norm = 3.8605
	sim_grads_norm = 0.0100
-- Starting training on experience 7 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6062
	data_grads_norm = 3.7782
	new_data_grads_norm = 5.4317
	old_data_grads_norm = 5.5967
	sim_grads_norm = -0.0419
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8861
	data_grads_norm = 4.4043
	new_data_grads_norm = 6.3564
	old_data_grads_norm = 5.4805
	sim_grads_norm = 0.0236
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9924
	data_grads_norm = 4.1918
	new_data_grads_norm = 6.1760
	old_data_grads_norm = 5.5025
	sim_grads_norm = 0.0081
-- Starting training on experience 8 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4090
	data_grads_norm = 4.5423
	new_data_grads_norm = 6.6303
	old_data_grads_norm = 5.0477
	sim_grads_norm = -0.0158
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4306
	data_grads_norm = 4.6112
	new_data_grads_norm = 6.8430
	old_data_grads_norm = 4.4304
	sim_grads_norm = -0.0043
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.7510
	data_grads_norm = 4.7206
	new_data_grads_norm = 6.5752
	old_data_grads_norm = 5.8994
	sim_grads_norm = 0.0350
-- Starting training on experience 9 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1399
	data_grads_norm = 4.7081
	new_data_grads_norm = 5.8170
	old_data_grads_norm = 5.6427
	sim_grads_norm = 0.0580
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5195
	data_grads_norm = 4.5542
	new_data_grads_norm = 5.4477
	old_data_grads_norm = 5.3985
	sim_grads_norm = -0.0301
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6071
	data_grads_norm = 3.4415
	new_data_grads_norm = 5.2756
	old_data_grads_norm = 3.6810
	sim_grads_norm = 0.1350
-- Starting training on experience 10 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6933
	data_grads_norm = 4.1332
	new_data_grads_norm = 6.7026
	old_data_grads_norm = 4.4900
	sim_grads_norm = 0.0160
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0115
	data_grads_norm = 4.0075
	new_data_grads_norm = 6.0040
	old_data_grads_norm = 4.1226
	sim_grads_norm = 0.0081
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5960
	data_grads_norm = 3.9900
	new_data_grads_norm = 6.0498
	old_data_grads_norm = 4.5707
	sim_grads_norm = -0.0112
-- Starting training on experience 11 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0212
	data_grads_norm = 4.1601
	new_data_grads_norm = 6.8584
	old_data_grads_norm = 4.3601
	sim_grads_norm = -0.0513
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4022
	data_grads_norm = 4.4513
	new_data_grads_norm = 7.1350
	old_data_grads_norm = 4.7030
	sim_grads_norm = -0.0176
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9513
	data_grads_norm = 4.1262
	new_data_grads_norm = 7.0486
	old_data_grads_norm = 2.7644
	sim_grads_norm = -0.0033
-- Starting training on experience 12 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.7564
	data_grads_norm = 4.5055
	new_data_grads_norm = 5.6888
	old_data_grads_norm = 6.3403
	sim_grads_norm = 0.0100
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.7001
	data_grads_norm = 4.5801
	new_data_grads_norm = 5.4858
	old_data_grads_norm = 6.2738
	sim_grads_norm = 0.0464
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4716
	data_grads_norm = 4.1085
	new_data_grads_norm = 5.6522
	old_data_grads_norm = 5.2907
	sim_grads_norm = -0.0015
-- Starting training on experience 13 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6955
	data_grads_norm = 4.8090
	new_data_grads_norm = 6.9666
	old_data_grads_norm = 5.9395
	sim_grads_norm = 0.1530
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8666
	data_grads_norm = 4.3816
	new_data_grads_norm = 7.0533
	old_data_grads_norm = 5.1488
	sim_grads_norm = 0.0543
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5985
	data_grads_norm = 3.4292
	new_data_grads_norm = 5.2854
	old_data_grads_norm = 4.3848
	sim_grads_norm = 0.0126
-- Starting training on experience 14 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7837
	data_grads_norm = 4.2365
	new_data_grads_norm = 5.4911
	old_data_grads_norm = 6.0922
	sim_grads_norm = 0.0193
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6635
	data_grads_norm = 3.3899
	new_data_grads_norm = 5.4868
	old_data_grads_norm = 3.6653
	sim_grads_norm = 0.0400
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3616
	data_grads_norm = 4.0772
	new_data_grads_norm = 5.5479
	old_data_grads_norm = 5.3308
	sim_grads_norm = -0.0093
-- Starting training on experience 15 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7589
	data_grads_norm = 3.7046
	new_data_grads_norm = 5.0411
	old_data_grads_norm = 5.2871
	sim_grads_norm = 0.0176
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5564
	data_grads_norm = 4.2237
	new_data_grads_norm = 5.4749
	old_data_grads_norm = 6.0214
	sim_grads_norm = 0.0100
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3905
	data_grads_norm = 3.1204
	new_data_grads_norm = 4.7519
	old_data_grads_norm = 5.4289
	sim_grads_norm = 0.0617
-- Starting training on experience 16 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.8812
	data_grads_norm = 4.7686
	new_data_grads_norm = 7.1297
	old_data_grads_norm = 4.7668
	sim_grads_norm = 0.1923
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0452
	data_grads_norm = 4.3571
	new_data_grads_norm = 6.2616
	old_data_grads_norm = 5.7638
	sim_grads_norm = -0.0128
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2688
	data_grads_norm = 4.5694
	new_data_grads_norm = 6.8055
	old_data_grads_norm = 4.7979
	sim_grads_norm = 0.0014
-- Starting training on experience 17 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6234
	data_grads_norm = 4.3191
	new_data_grads_norm = 5.6322
	old_data_grads_norm = 6.0831
	sim_grads_norm = 0.0137
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5832
	data_grads_norm = 4.2883
	new_data_grads_norm = 5.4608
	old_data_grads_norm = 6.0218
	sim_grads_norm = 0.0459
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7174
	data_grads_norm = 4.2362
	new_data_grads_norm = 6.3437
	old_data_grads_norm = 6.1755
	sim_grads_norm = -0.0059
-- Starting training on experience 18 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1272
	data_grads_norm = 4.7795
	new_data_grads_norm = 6.8776
	old_data_grads_norm = 6.3625
	sim_grads_norm = 0.0700
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3317
	data_grads_norm = 4.4563
	new_data_grads_norm = 6.3874
	old_data_grads_norm = 6.3138
	sim_grads_norm = 0.0081
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7837
	data_grads_norm = 3.5701
	new_data_grads_norm = 5.4692
	old_data_grads_norm = 3.9302
	sim_grads_norm = -0.0155
-- Starting training on experience 19 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1905
	data_grads_norm = 3.7033
	new_data_grads_norm = 5.9966
	old_data_grads_norm = 4.5075
	sim_grads_norm = 0.0828
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4187
	data_grads_norm = 3.8629
	new_data_grads_norm = 5.7881
	old_data_grads_norm = 4.9253
	sim_grads_norm = 0.0287
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6577
	data_grads_norm = 3.4360
	new_data_grads_norm = 5.0766
	old_data_grads_norm = 3.6792
	sim_grads_norm = 0.0006
-- Starting training on experience 20 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6285
	data_grads_norm = 4.3540
	new_data_grads_norm = 6.1985
	old_data_grads_norm = 5.3441
	sim_grads_norm = 0.0299
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6546
	data_grads_norm = 3.9916
	new_data_grads_norm = 5.6888
	old_data_grads_norm = 5.4396
	sim_grads_norm = 0.0849
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7322
	data_grads_norm = 4.6848
	new_data_grads_norm = 5.9534
	old_data_grads_norm = 5.6311
	sim_grads_norm = 0.0405
-- Starting training on experience 21 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0363
	data_grads_norm = 4.3545
	new_data_grads_norm = 6.6651
	old_data_grads_norm = 4.6614
	sim_grads_norm = 0.0336
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9213
	data_grads_norm = 4.1475
	new_data_grads_norm = 6.0986
	old_data_grads_norm = 4.3199
	sim_grads_norm = 0.0536
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8221
	data_grads_norm = 4.5218
	new_data_grads_norm = 6.8840
	old_data_grads_norm = 5.1286
	sim_grads_norm = -0.0045
-- Starting training on experience 22 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9381
	data_grads_norm = 3.7109
	new_data_grads_norm = 6.5356
	old_data_grads_norm = 4.4600
	sim_grads_norm = 0.0218
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0851
	data_grads_norm = 4.0620
	new_data_grads_norm = 5.5887
	old_data_grads_norm = 5.5107
	sim_grads_norm = 0.0229
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3746
	data_grads_norm = 4.2467
	new_data_grads_norm = 5.4949
	old_data_grads_norm = 5.8413
	sim_grads_norm = 0.0571
-- Starting training on experience 23 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4456
	data_grads_norm = 4.2629
	new_data_grads_norm = 5.8950
	old_data_grads_norm = 5.8157
	sim_grads_norm = 0.0018
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3333
	data_grads_norm = 4.1946
	new_data_grads_norm = 6.7268
	old_data_grads_norm = 4.3176
	sim_grads_norm = 0.0366
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2252
	data_grads_norm = 4.1331
	new_data_grads_norm = 5.9686
	old_data_grads_norm = 4.9632
	sim_grads_norm = 0.0106
-- Starting training on experience 24 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5487
	data_grads_norm = 4.3893
	new_data_grads_norm = 7.1956
	old_data_grads_norm = 5.0856
	sim_grads_norm = 0.0496
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4969
	data_grads_norm = 4.3199
	new_data_grads_norm = 5.6819
	old_data_grads_norm = 5.3775
	sim_grads_norm = 0.0319
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0694
	data_grads_norm = 4.2067
	new_data_grads_norm = 6.4376
	old_data_grads_norm = 4.4904
	sim_grads_norm = -0.0192
-- Starting training on experience 25 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0883
	data_grads_norm = 3.7376
	new_data_grads_norm = 4.7604
	old_data_grads_norm = 5.0811
	sim_grads_norm = 0.0384
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0987
	data_grads_norm = 3.7473
	new_data_grads_norm = 5.3787
	old_data_grads_norm = 4.9546
	sim_grads_norm = -0.0327
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0950
	data_grads_norm = 3.8156
	new_data_grads_norm = 5.1889
	old_data_grads_norm = 5.5894
	sim_grads_norm = 0.0116
-- Starting training on experience 26 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9456
	data_grads_norm = 3.5496
	new_data_grads_norm = 5.4612
	old_data_grads_norm = 4.7292
	sim_grads_norm = -0.0126
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0369
	data_grads_norm = 3.3371
	new_data_grads_norm = 5.3963
	old_data_grads_norm = 3.4328
	sim_grads_norm = 0.0416
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1934
	data_grads_norm = 3.6915
	new_data_grads_norm = 5.2329
	old_data_grads_norm = 4.7317
	sim_grads_norm = 0.0549
-- Starting training on experience 27 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8669
	data_grads_norm = 3.6350
	new_data_grads_norm = 5.0060
	old_data_grads_norm = 4.3352
	sim_grads_norm = 0.0220
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0004
	data_grads_norm = 3.7134
	new_data_grads_norm = 5.6250
	old_data_grads_norm = 4.6033
	sim_grads_norm = 0.0107
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6156
	data_grads_norm = 3.2339
	new_data_grads_norm = 5.5068
	old_data_grads_norm = 3.3141
	sim_grads_norm = -0.0326
-- Starting training on experience 28 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7109
	data_grads_norm = 3.4232
	new_data_grads_norm = 5.3440
	old_data_grads_norm = 4.2851
	sim_grads_norm = -0.0475
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8929
	data_grads_norm = 3.8115
	new_data_grads_norm = 5.4030
	old_data_grads_norm = 5.1975
	sim_grads_norm = 0.0087
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0297
	data_grads_norm = 3.7167
	new_data_grads_norm = 5.6378
	old_data_grads_norm = 5.0828
	sim_grads_norm = 0.0569
-- Starting training on experience 29 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9271
	data_grads_norm = 3.8282
	new_data_grads_norm = 5.6062
	old_data_grads_norm = 4.8274
	sim_grads_norm = 0.0381
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1579
	data_grads_norm = 3.9661
	new_data_grads_norm = 5.8271
	old_data_grads_norm = 4.5446
	sim_grads_norm = 0.0107
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2446
	data_grads_norm = 4.0403
	new_data_grads_norm = 6.2205
	old_data_grads_norm = 4.0430
	sim_grads_norm = 0.0113
-- Starting training on experience 30 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0863
	data_grads_norm = 3.9614
	new_data_grads_norm = 5.7002
	old_data_grads_norm = 5.0840
	sim_grads_norm = -0.0198
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1324
	data_grads_norm = 4.2401
	new_data_grads_norm = 5.4343
	old_data_grads_norm = 6.8671
	sim_grads_norm = -0.0009
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3868
	data_grads_norm = 4.3643
	new_data_grads_norm = 5.7712
	old_data_grads_norm = 5.4068
	sim_grads_norm = -0.0207
-- Starting training on experience 31 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4331
	data_grads_norm = 3.7377
	new_data_grads_norm = 5.1480
	old_data_grads_norm = 5.2960
	sim_grads_norm = 0.0005
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5156
	data_grads_norm = 3.1091
	new_data_grads_norm = 4.5216
	old_data_grads_norm = 4.8457
	sim_grads_norm = 0.0130
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2815
	data_grads_norm = 3.2113
	new_data_grads_norm = 5.0562
	old_data_grads_norm = 4.2199
	sim_grads_norm = -0.0027
-- Starting training on experience 32 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1845
	data_grads_norm = 4.1086
	new_data_grads_norm = 6.3253
	old_data_grads_norm = 5.3437
	sim_grads_norm = 0.0170
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1246
	data_grads_norm = 4.1357
	new_data_grads_norm = 5.7866
	old_data_grads_norm = 5.1863
	sim_grads_norm = 0.0014
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2432
	data_grads_norm = 4.4476
	new_data_grads_norm = 6.2354
	old_data_grads_norm = 5.8068
	sim_grads_norm = -0.0139
-- Starting training on experience 33 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5494
	data_grads_norm = 3.4558
	new_data_grads_norm = 5.3518
	old_data_grads_norm = 3.8169
	sim_grads_norm = 0.0426
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8413
	data_grads_norm = 3.9719
	new_data_grads_norm = 5.3481
	old_data_grads_norm = 6.2567
	sim_grads_norm = -0.0123
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5105
	data_grads_norm = 3.3590
	new_data_grads_norm = 5.3448
	old_data_grads_norm = 4.1993
	sim_grads_norm = 0.0051
-- Starting training on experience 34 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1655
	data_grads_norm = 3.7138
	new_data_grads_norm = 5.8253
	old_data_grads_norm = 4.7576
	sim_grads_norm = 0.0182
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7871
	data_grads_norm = 3.8102
	new_data_grads_norm = 5.9914
	old_data_grads_norm = 5.6707
	sim_grads_norm = -0.0368
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8201
	data_grads_norm = 3.9571
	new_data_grads_norm = 5.7552
	old_data_grads_norm = 4.7422
	sim_grads_norm = 0.0656
-- Starting training on experience 35 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7740
	data_grads_norm = 4.7736
	new_data_grads_norm = 7.2838
	old_data_grads_norm = 5.5690
	sim_grads_norm = 0.0813
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3549
	data_grads_norm = 4.2162
	new_data_grads_norm = 7.0145
	old_data_grads_norm = 4.0037
	sim_grads_norm = -0.0186
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4920
	data_grads_norm = 4.8611
	new_data_grads_norm = 6.5135
	old_data_grads_norm = 5.9692
	sim_grads_norm = 0.0234
-- Starting training on experience 36 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6623
	data_grads_norm = 4.2188
	new_data_grads_norm = 5.4496
	old_data_grads_norm = 6.2111
	sim_grads_norm = -0.0240
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3560
	data_grads_norm = 3.7485
	new_data_grads_norm = 5.0869
	old_data_grads_norm = 4.6657
	sim_grads_norm = -0.0285
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2965
	data_grads_norm = 4.9788
	new_data_grads_norm = 6.3198
	old_data_grads_norm = 7.8372
	sim_grads_norm = -0.0046
-- Starting training on experience 37 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6190
	data_grads_norm = 3.7501
	new_data_grads_norm = 5.6416
	old_data_grads_norm = 4.0035
	sim_grads_norm = 0.0233
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9796
	data_grads_norm = 4.3650
	new_data_grads_norm = 5.1788
	old_data_grads_norm = 6.2853
	sim_grads_norm = 0.0210
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8640
	data_grads_norm = 4.2117
	new_data_grads_norm = 5.7186
	old_data_grads_norm = 5.5345
	sim_grads_norm = -0.0202
-- Starting training on experience 38 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5467
	data_grads_norm = 3.5729
	new_data_grads_norm = 5.7631
	old_data_grads_norm = 4.5267
	sim_grads_norm = 0.0436
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9865
	data_grads_norm = 4.1488
	new_data_grads_norm = 5.6192
	old_data_grads_norm = 5.5839
	sim_grads_norm = -0.0134
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9102
	data_grads_norm = 4.5274
	new_data_grads_norm = 5.5975
	old_data_grads_norm = 6.0850
	sim_grads_norm = -0.0146
-- Starting training on experience 39 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6016
	data_grads_norm = 4.0666
	new_data_grads_norm = 4.9226
	old_data_grads_norm = 6.2908
	sim_grads_norm = -0.0003
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0010
	data_grads_norm = 3.7800
	new_data_grads_norm = 4.6505
	old_data_grads_norm = 5.1459
	sim_grads_norm = 0.0481
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6928
	data_grads_norm = 3.4940
	new_data_grads_norm = 4.8526
	old_data_grads_norm = 4.5752
	sim_grads_norm = -0.0249
-- Starting training on experience 40 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0211
	data_grads_norm = 4.2917
	new_data_grads_norm = 6.6895
	old_data_grads_norm = 6.2078
	sim_grads_norm = 0.0138
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0456
	data_grads_norm = 4.1379
	new_data_grads_norm = 6.8866
	old_data_grads_norm = 4.0118
	sim_grads_norm = -0.0225
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2540
	data_grads_norm = 4.1633
	new_data_grads_norm = 6.2193
	old_data_grads_norm = 4.5324
	sim_grads_norm = 0.0104
-- Starting training on experience 41 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9192
	data_grads_norm = 4.0900
	new_data_grads_norm = 6.2459
	old_data_grads_norm = 5.3718
	sim_grads_norm = 0.1181
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6852
	data_grads_norm = 3.8521
	new_data_grads_norm = 6.0224
	old_data_grads_norm = 3.8805
	sim_grads_norm = 0.0320
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7753
	data_grads_norm = 4.7664
	new_data_grads_norm = 6.2547
	old_data_grads_norm = 6.4372
	sim_grads_norm = 0.0219
-- Starting training on experience 42 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8825
	data_grads_norm = 4.4460
	new_data_grads_norm = 6.4482
	old_data_grads_norm = 6.2785
	sim_grads_norm = -0.0201
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0887
	data_grads_norm = 4.1654
	new_data_grads_norm = 5.9919
	old_data_grads_norm = 4.6628
	sim_grads_norm = -0.0075
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2447
	data_grads_norm = 4.7381
	new_data_grads_norm = 6.0590
	old_data_grads_norm = 6.9144
	sim_grads_norm = 0.0410
-- Starting training on experience 43 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3663
	data_grads_norm = 2.7808
	new_data_grads_norm = 4.6804
	old_data_grads_norm = 3.2110
	sim_grads_norm = -0.0008
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8008
	data_grads_norm = 3.9460
	new_data_grads_norm = 4.8109
	old_data_grads_norm = 6.9203
	sim_grads_norm = -0.0490
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1483
	data_grads_norm = 4.0083
	new_data_grads_norm = 4.4351
	old_data_grads_norm = 5.8201
	sim_grads_norm = 0.0992
-- Starting training on experience 44 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1086
	data_grads_norm = 4.3866
	new_data_grads_norm = 5.9585
	old_data_grads_norm = 5.4452
	sim_grads_norm = 0.0332
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6634
	data_grads_norm = 3.9525
	new_data_grads_norm = 5.1196
	old_data_grads_norm = 4.7918
	sim_grads_norm = -0.0422
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6919
	data_grads_norm = 3.9292
	new_data_grads_norm = 5.7887
	old_data_grads_norm = 5.4897
	sim_grads_norm = 0.0408
-- Starting training on experience 45 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1655
	data_grads_norm = 4.9173
	new_data_grads_norm = 5.5511
	old_data_grads_norm = 6.8795
	sim_grads_norm = -0.0037
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8435
	data_grads_norm = 3.7624
	new_data_grads_norm = 6.0185
	old_data_grads_norm = 3.2470
	sim_grads_norm = 0.0080
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7663
	data_grads_norm = 3.8047
	new_data_grads_norm = 5.0644
	old_data_grads_norm = 5.2968
	sim_grads_norm = -0.0355
-- Starting training on experience 46 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1363
	data_grads_norm = 3.6608
	new_data_grads_norm = 5.7364
	old_data_grads_norm = 4.3782
	sim_grads_norm = -0.0023
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5622
	data_grads_norm = 3.9457
	new_data_grads_norm = 5.1451
	old_data_grads_norm = 5.1799
	sim_grads_norm = -0.0261
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1050
	data_grads_norm = 4.2845
	new_data_grads_norm = 5.8038
	old_data_grads_norm = 5.2287
	sim_grads_norm = 0.0757
-- Starting training on experience 47 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6913
	data_grads_norm = 4.7398
	new_data_grads_norm = 6.7918
	old_data_grads_norm = 5.3310
	sim_grads_norm = 0.0497
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3685
	data_grads_norm = 5.1935
	new_data_grads_norm = 7.2112
	old_data_grads_norm = 5.8921
	sim_grads_norm = -0.0021
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9188
	data_grads_norm = 5.0846
	new_data_grads_norm = 7.5879
	old_data_grads_norm = 4.3023
	sim_grads_norm = 0.0218
-- Starting training on experience 48 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9722
	data_grads_norm = 3.4945
	new_data_grads_norm = 5.6883
	old_data_grads_norm = 5.2963
	sim_grads_norm = -0.0474
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2351
	data_grads_norm = 4.0169
	new_data_grads_norm = 6.1666
	old_data_grads_norm = 5.0408
	sim_grads_norm = 0.1139
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1983
	data_grads_norm = 4.2465
	new_data_grads_norm = 5.8051
	old_data_grads_norm = 5.9550
	sim_grads_norm = 0.0592
-- Starting training on experience 49 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0746
	data_grads_norm = 4.5172
	new_data_grads_norm = 6.5623
	old_data_grads_norm = 5.2174
	sim_grads_norm = -0.0041
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9905
	data_grads_norm = 4.7638
	new_data_grads_norm = 6.2476
	old_data_grads_norm = 6.8248
	sim_grads_norm = 0.0063
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0030
	data_grads_norm = 4.2359
	new_data_grads_norm = 6.2849
	old_data_grads_norm = 4.7301
	sim_grads_norm = 0.1181
-- Starting training on experience 50 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4862
	data_grads_norm = 3.4977
	new_data_grads_norm = 5.6742
	old_data_grads_norm = 4.5557
	sim_grads_norm = 0.0534
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7497
	data_grads_norm = 4.2972
	new_data_grads_norm = 6.2173
	old_data_grads_norm = 4.2961
	sim_grads_norm = 0.0273
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6765
	data_grads_norm = 4.3147
	new_data_grads_norm = 6.3346
	old_data_grads_norm = 5.2614
	sim_grads_norm = 0.0231
-- Starting training on experience 51 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4280
	data_grads_norm = 3.5715
	new_data_grads_norm = 5.0942
	old_data_grads_norm = 5.5333
	sim_grads_norm = -0.0095
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3429
	data_grads_norm = 3.6143
	new_data_grads_norm = 5.1855
	old_data_grads_norm = 5.0583
	sim_grads_norm = -0.0522
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9735
	data_grads_norm = 3.7756
	new_data_grads_norm = 5.3743
	old_data_grads_norm = 5.3037
	sim_grads_norm = -0.0109
-- Starting training on experience 52 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8688
	data_grads_norm = 4.2627
	new_data_grads_norm = 6.4342
	old_data_grads_norm = 5.6159
	sim_grads_norm = -0.0826
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1865
	data_grads_norm = 3.9960
	new_data_grads_norm = 6.0551
	old_data_grads_norm = 5.1405
	sim_grads_norm = -0.0123
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5337
	data_grads_norm = 3.6366
	new_data_grads_norm = 6.5300
	old_data_grads_norm = 3.2570
	sim_grads_norm = 0.0013
-- Starting training on experience 53 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8796
	data_grads_norm = 4.1501
	new_data_grads_norm = 5.2911
	old_data_grads_norm = 4.9900
	sim_grads_norm = 0.0428
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2722
	data_grads_norm = 3.8953
	new_data_grads_norm = 5.3380
	old_data_grads_norm = 5.0889
	sim_grads_norm = -0.0265
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0424
	data_grads_norm = 4.2072
	new_data_grads_norm = 5.0373
	old_data_grads_norm = 4.7700
	sim_grads_norm = 0.0509
-- Starting training on experience 54 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5442
	data_grads_norm = 3.7264
	new_data_grads_norm = 5.7892
	old_data_grads_norm = 5.2829
	sim_grads_norm = -0.0151
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5890
	data_grads_norm = 3.5546
	new_data_grads_norm = 5.7639
	old_data_grads_norm = 4.8705
	sim_grads_norm = -0.0220
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4395
	data_grads_norm = 3.6860
	new_data_grads_norm = 5.0485
	old_data_grads_norm = 4.6713
	sim_grads_norm = -0.0006
-- Starting training on experience 55 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7144
	data_grads_norm = 4.1729
	new_data_grads_norm = 4.9581
	old_data_grads_norm = 6.9803
	sim_grads_norm = -0.0023
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5228
	data_grads_norm = 3.5098
	new_data_grads_norm = 5.1306
	old_data_grads_norm = 4.3121
	sim_grads_norm = 0.0065
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7131
	data_grads_norm = 3.7197
	new_data_grads_norm = 4.5952
	old_data_grads_norm = 5.2619
	sim_grads_norm = -0.0102
-- Starting training on experience 56 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9459
	data_grads_norm = 4.8370
	new_data_grads_norm = 6.4282
	old_data_grads_norm = 6.9476
	sim_grads_norm = 0.0066
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0483
	data_grads_norm = 4.3038
	new_data_grads_norm = 5.6936
	old_data_grads_norm = 5.7116
	sim_grads_norm = 0.0826
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1203
	data_grads_norm = 4.4482
	new_data_grads_norm = 6.1055
	old_data_grads_norm = 5.7194
	sim_grads_norm = -0.0149
-- Starting training on experience 57 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4990
	data_grads_norm = 3.7520
	new_data_grads_norm = 5.6563
	old_data_grads_norm = 3.6890
	sim_grads_norm = -0.0126
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9454
	data_grads_norm = 3.9425
	new_data_grads_norm = 5.4221
	old_data_grads_norm = 5.0643
	sim_grads_norm = -0.0219
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7364
	data_grads_norm = 3.7895
	new_data_grads_norm = 5.4912
	old_data_grads_norm = 3.4278
	sim_grads_norm = -0.0302
-- Starting training on experience 58 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6810
	data_grads_norm = 5.2286
	new_data_grads_norm = 7.6511
	old_data_grads_norm = 5.8432
	sim_grads_norm = 0.1525
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0119
	data_grads_norm = 4.2371
	new_data_grads_norm = 5.5283
	old_data_grads_norm = 6.2905
	sim_grads_norm = -0.0186
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7390
	data_grads_norm = 4.0844
	new_data_grads_norm = 5.8150
	old_data_grads_norm = 4.0579
	sim_grads_norm = 0.0086
-- Starting training on experience 59 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5253
	data_grads_norm = 3.8835
	new_data_grads_norm = 5.4475
	old_data_grads_norm = 4.8165
	sim_grads_norm = 0.0031
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1906
	data_grads_norm = 2.9140
	new_data_grads_norm = 5.5949
	old_data_grads_norm = 2.0544
	sim_grads_norm = 0.0104
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4722
	data_grads_norm = 4.4720
	new_data_grads_norm = 5.7138
	old_data_grads_norm = 6.0891
	sim_grads_norm = 0.0456
-- Starting training on experience 60 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8393
	data_grads_norm = 4.1915
	new_data_grads_norm = 5.5806
	old_data_grads_norm = 4.7176
	sim_grads_norm = -0.0175
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9035
	data_grads_norm = 4.1033
	new_data_grads_norm = 5.4796
	old_data_grads_norm = 5.1275
	sim_grads_norm = 0.0249
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3571
	data_grads_norm = 4.0514
	new_data_grads_norm = 5.3804
	old_data_grads_norm = 5.2735
	sim_grads_norm = -0.0224
-- Starting training on experience 61 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6484
	data_grads_norm = 4.0318
	new_data_grads_norm = 5.3987
	old_data_grads_norm = 5.6643
	sim_grads_norm = 0.0360
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4691
	data_grads_norm = 3.8970
	new_data_grads_norm = 5.2514
	old_data_grads_norm = 5.4323
	sim_grads_norm = -0.0094
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2584
	data_grads_norm = 3.4122
	new_data_grads_norm = 5.6865
	old_data_grads_norm = 4.5709
	sim_grads_norm = -0.0539
-- Starting training on experience 62 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4590
	data_grads_norm = 3.8971
	new_data_grads_norm = 5.9403
	old_data_grads_norm = 4.1395
	sim_grads_norm = 0.0419
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4882
	data_grads_norm = 4.3781
	new_data_grads_norm = 5.2872
	old_data_grads_norm = 6.4058
	sim_grads_norm = -0.0164
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7263
	data_grads_norm = 3.6991
	new_data_grads_norm = 4.9182
	old_data_grads_norm = 4.8970
	sim_grads_norm = 0.0404
-- Starting training on experience 63 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2050
	data_grads_norm = 3.4664
	new_data_grads_norm = 5.6815
	old_data_grads_norm = 3.3495
	sim_grads_norm = -0.0182
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0711
	data_grads_norm = 4.5198
	new_data_grads_norm = 5.5083
	old_data_grads_norm = 6.6686
	sim_grads_norm = -0.0032
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6977
	data_grads_norm = 4.3099
	new_data_grads_norm = 5.4343
	old_data_grads_norm = 5.3887
	sim_grads_norm = 0.0440
-- Starting training on experience 64 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7849
	data_grads_norm = 3.5560
	new_data_grads_norm = 4.7635
	old_data_grads_norm = 5.0510
	sim_grads_norm = 0.0258
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4028
	data_grads_norm = 4.2967
	new_data_grads_norm = 5.3054
	old_data_grads_norm = 6.1092
	sim_grads_norm = 0.0042
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0660
	data_grads_norm = 3.6152
	new_data_grads_norm = 4.7355
	old_data_grads_norm = 4.9026
	sim_grads_norm = -0.0077
-- Starting training on experience 65 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0650
	data_grads_norm = 4.2571
	new_data_grads_norm = 6.2097
	old_data_grads_norm = 4.8300
	sim_grads_norm = 0.0069
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3236
	data_grads_norm = 4.6337
	new_data_grads_norm = 6.4838
	old_data_grads_norm = 6.0185
	sim_grads_norm = -0.0222
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1526
	data_grads_norm = 3.8725
	new_data_grads_norm = 5.9676
	old_data_grads_norm = 5.8803
	sim_grads_norm = -0.0039
-- Starting training on experience 66 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1582
	data_grads_norm = 3.8066
	new_data_grads_norm = 4.5010
	old_data_grads_norm = 4.8170
	sim_grads_norm = 0.0615
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9643
	data_grads_norm = 3.7250
	new_data_grads_norm = 4.9047
	old_data_grads_norm = 5.0628
	sim_grads_norm = 0.0382
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4997
	data_grads_norm = 3.6785
	new_data_grads_norm = 4.4977
	old_data_grads_norm = 5.7450
	sim_grads_norm = -0.0123
-- Starting training on experience 67 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2051
	data_grads_norm = 3.3524
	new_data_grads_norm = 5.0487
	old_data_grads_norm = 3.5090
	sim_grads_norm = 0.0054
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7816
	data_grads_norm = 4.9133
	new_data_grads_norm = 5.7664
	old_data_grads_norm = 6.3785
	sim_grads_norm = -0.0281
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0780
	data_grads_norm = 4.4300
	new_data_grads_norm = 5.5694
	old_data_grads_norm = 7.5979
	sim_grads_norm = 0.0003
-- Starting training on experience 68 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6834
	data_grads_norm = 3.1824
	new_data_grads_norm = 4.3008
	old_data_grads_norm = 4.0731
	sim_grads_norm = 0.1493
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6402
	data_grads_norm = 3.5469
	new_data_grads_norm = 4.4393
	old_data_grads_norm = 5.0990
	sim_grads_norm = -0.0258
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5549
	data_grads_norm = 3.7844
	new_data_grads_norm = 4.3811
	old_data_grads_norm = 5.4398
	sim_grads_norm = 0.0636
-- Starting training on experience 69 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3388
	data_grads_norm = 4.0786
	new_data_grads_norm = 6.0336
	old_data_grads_norm = 4.7203
	sim_grads_norm = -0.0246
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3683
	data_grads_norm = 4.2646
	new_data_grads_norm = 6.5460
	old_data_grads_norm = 5.7118
	sim_grads_norm = -0.0618
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7820
	data_grads_norm = 4.8194
	new_data_grads_norm = 7.3687
	old_data_grads_norm = 4.7136
	sim_grads_norm = 0.0295
-- Starting training on experience 70 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9043
	data_grads_norm = 4.5669
	new_data_grads_norm = 5.0970
	old_data_grads_norm = 5.8778
	sim_grads_norm = 0.0034
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7598
	data_grads_norm = 3.6221
	new_data_grads_norm = 4.4965
	old_data_grads_norm = 3.9422
	sim_grads_norm = 0.0822
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5653
	data_grads_norm = 3.5737
	new_data_grads_norm = 4.3864
	old_data_grads_norm = 4.8394
	sim_grads_norm = -0.0177
-- Starting training on experience 71 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7533
	data_grads_norm = 3.9129
	new_data_grads_norm = 5.4426
	old_data_grads_norm = 5.0836
	sim_grads_norm = -0.0118
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6902
	data_grads_norm = 3.5740
	new_data_grads_norm = 5.6907
	old_data_grads_norm = 4.5496
	sim_grads_norm = 0.0097
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4496
	data_grads_norm = 3.5156
	new_data_grads_norm = 5.9649
	old_data_grads_norm = 3.7602
	sim_grads_norm = 0.0387
-- Starting training on experience 72 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8118
	data_grads_norm = 4.4897
	new_data_grads_norm = 5.6895
	old_data_grads_norm = 5.2849
	sim_grads_norm = -0.0309
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8649
	data_grads_norm = 4.1593
	new_data_grads_norm = 6.3683
	old_data_grads_norm = 4.1493
	sim_grads_norm = 0.0224
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4319
	data_grads_norm = 4.0227
	new_data_grads_norm = 5.6206
	old_data_grads_norm = 5.4567
	sim_grads_norm = -0.0096
-- Starting training on experience 73 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1990
	data_grads_norm = 4.4049
	new_data_grads_norm = 6.3708
	old_data_grads_norm = 6.9629
	sim_grads_norm = -0.0355
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6323
	data_grads_norm = 4.6023
	new_data_grads_norm = 7.1924
	old_data_grads_norm = 6.0666
	sim_grads_norm = 0.0300
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2111
	data_grads_norm = 4.1558
	new_data_grads_norm = 6.7444
	old_data_grads_norm = 4.5213
	sim_grads_norm = 0.0402
-- Starting training on experience 74 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8419
	data_grads_norm = 3.7409
	new_data_grads_norm = 5.3453
	old_data_grads_norm = 5.9040
	sim_grads_norm = 0.0443
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1590
	data_grads_norm = 4.7974
	new_data_grads_norm = 5.3958
	old_data_grads_norm = 7.6920
	sim_grads_norm = -0.0311
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1607
	data_grads_norm = 3.8455
	new_data_grads_norm = 5.6786
	old_data_grads_norm = 4.4201
	sim_grads_norm = 0.0394
-- Starting training on experience 75 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8885
	data_grads_norm = 4.6529
	new_data_grads_norm = 5.2630
	old_data_grads_norm = 7.4636
	sim_grads_norm = 0.0319
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5761
	data_grads_norm = 4.2332
	new_data_grads_norm = 4.9719
	old_data_grads_norm = 6.9382
	sim_grads_norm = -0.0056
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6204
	data_grads_norm = 3.9769
	new_data_grads_norm = 5.6805
	old_data_grads_norm = 6.2174
	sim_grads_norm = -0.0279
-- Starting training on experience 76 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0287
	data_grads_norm = 4.4015
	new_data_grads_norm = 5.7395
	old_data_grads_norm = 5.3477
	sim_grads_norm = -0.0066
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2524
	data_grads_norm = 4.2115
	new_data_grads_norm = 5.6202
	old_data_grads_norm = 5.9506
	sim_grads_norm = 0.0157
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9614
	data_grads_norm = 4.0490
	new_data_grads_norm = 5.7382
	old_data_grads_norm = 3.9905
	sim_grads_norm = -0.0195
-- Starting training on experience 77 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7419
	data_grads_norm = 3.9581
	new_data_grads_norm = 5.7559
	old_data_grads_norm = 4.9241
	sim_grads_norm = -0.0246
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4411
	data_grads_norm = 4.5524
	new_data_grads_norm = 5.7148
	old_data_grads_norm = 6.3011
	sim_grads_norm = -0.0211
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9594
	data_grads_norm = 3.8456
	new_data_grads_norm = 6.3012
	old_data_grads_norm = 3.5764
	sim_grads_norm = 0.0639
-- Starting training on experience 78 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0186
	data_grads_norm = 4.7777
	new_data_grads_norm = 6.0396
	old_data_grads_norm = 6.3737
	sim_grads_norm = 0.0419
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9600
	data_grads_norm = 4.7977
	new_data_grads_norm = 6.0162
	old_data_grads_norm = 6.5323
	sim_grads_norm = 0.0240
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7588
	data_grads_norm = 4.3995
	new_data_grads_norm = 5.9120
	old_data_grads_norm = 5.1589
	sim_grads_norm = -0.0037
-- Starting training on experience 79 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2537
	data_grads_norm = 4.8571
	new_data_grads_norm = 5.5569
	old_data_grads_norm = 6.5432
	sim_grads_norm = 0.0199
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9532
	data_grads_norm = 4.1348
	new_data_grads_norm = 5.2487
	old_data_grads_norm = 5.9017
	sim_grads_norm = -0.0249
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9686
	data_grads_norm = 3.8899
	new_data_grads_norm = 5.7970
	old_data_grads_norm = 4.2995
	sim_grads_norm = 0.0282
-- Starting training on experience 80 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6632
	data_grads_norm = 4.1627
	new_data_grads_norm = 6.2655
	old_data_grads_norm = 4.3638
	sim_grads_norm = -0.0259
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5381
	data_grads_norm = 4.5129
	new_data_grads_norm = 5.6103
	old_data_grads_norm = 7.1544
	sim_grads_norm = 0.0466
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5163
	data_grads_norm = 3.5489
	new_data_grads_norm = 5.2190
	old_data_grads_norm = 4.7907
	sim_grads_norm = -0.0027
-- Starting training on experience 81 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7144
	data_grads_norm = 4.5383
	new_data_grads_norm = 5.7569
	old_data_grads_norm = 6.4451
	sim_grads_norm = 0.0613
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4135
	data_grads_norm = 4.0005
	new_data_grads_norm = 5.4864
	old_data_grads_norm = 4.8207
	sim_grads_norm = 0.0207
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7114
	data_grads_norm = 3.7404
	new_data_grads_norm = 5.7375
	old_data_grads_norm = 3.7467
	sim_grads_norm = 0.0294
-- Starting training on experience 82 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9622
	data_grads_norm = 3.9385
	new_data_grads_norm = 5.5589
	old_data_grads_norm = 4.9902
	sim_grads_norm = 0.1466
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5377
	data_grads_norm = 3.5941
	new_data_grads_norm = 4.9084
	old_data_grads_norm = 4.0997
	sim_grads_norm = 0.0971
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4560
	data_grads_norm = 3.3625
	new_data_grads_norm = 4.5022
	old_data_grads_norm = 4.8311
	sim_grads_norm = -0.0304
-- Starting training on experience 83 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8977
	data_grads_norm = 4.4139
	new_data_grads_norm = 6.5178
	old_data_grads_norm = 5.8320
	sim_grads_norm = 0.0262
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6384
	data_grads_norm = 4.0896
	new_data_grads_norm = 6.3154
	old_data_grads_norm = 5.0393
	sim_grads_norm = -0.0086
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2860
	data_grads_norm = 4.6156
	new_data_grads_norm = 5.9970
	old_data_grads_norm = 5.1926
	sim_grads_norm = 0.2303
-- Starting training on experience 84 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5504
	data_grads_norm = 3.6931
	new_data_grads_norm = 5.8772
	old_data_grads_norm = 3.6899
	sim_grads_norm = 0.0310
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4504
	data_grads_norm = 4.1210
	new_data_grads_norm = 6.4376
	old_data_grads_norm = 4.9910
	sim_grads_norm = -0.0559
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1348
	data_grads_norm = 3.3656
	new_data_grads_norm = 5.7403
	old_data_grads_norm = 3.7543
	sim_grads_norm = -0.0090
-- Starting training on experience 85 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9671
	data_grads_norm = 3.8293
	new_data_grads_norm = 5.9644
	old_data_grads_norm = 5.2697
	sim_grads_norm = -0.0117
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5492
	data_grads_norm = 3.5028
	new_data_grads_norm = 5.2948
	old_data_grads_norm = 3.8539
	sim_grads_norm = 0.0603
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2401
	data_grads_norm = 3.5498
	new_data_grads_norm = 5.2889
	old_data_grads_norm = 4.3626
	sim_grads_norm = -0.0447
-- Starting training on experience 86 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6298
	data_grads_norm = 3.5505
	new_data_grads_norm = 5.4937
	old_data_grads_norm = 5.8447
	sim_grads_norm = -0.0088
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3529
	data_grads_norm = 4.7472
	new_data_grads_norm = 5.9283
	old_data_grads_norm = 6.4085
	sim_grads_norm = 0.1179
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4957
	data_grads_norm = 3.4634
	new_data_grads_norm = 5.4928
	old_data_grads_norm = 4.4971
	sim_grads_norm = -0.0294
-- Starting training on experience 87 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8434
	data_grads_norm = 3.8329
	new_data_grads_norm = 5.8536
	old_data_grads_norm = 4.4018
	sim_grads_norm = 0.0248
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6719
	data_grads_norm = 3.6249
	new_data_grads_norm = 5.6287
	old_data_grads_norm = 4.4223
	sim_grads_norm = 0.0038
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2959
	data_grads_norm = 3.6413
	new_data_grads_norm = 6.1867
	old_data_grads_norm = 3.4516
	sim_grads_norm = -0.0110
-- Starting training on experience 88 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2268
	data_grads_norm = 3.3205
	new_data_grads_norm = 4.5366
	old_data_grads_norm = 5.3543
	sim_grads_norm = -0.0188
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5190
	data_grads_norm = 3.2095
	new_data_grads_norm = 4.6673
	old_data_grads_norm = 4.3863
	sim_grads_norm = 0.0354
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5924
	data_grads_norm = 3.8674
	new_data_grads_norm = 4.7572
	old_data_grads_norm = 5.4841
	sim_grads_norm = 0.0208
-- Starting training on experience 89 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1501
	data_grads_norm = 3.5747
	new_data_grads_norm = 5.5594
	old_data_grads_norm = 4.5504
	sim_grads_norm = -0.0466
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5478
	data_grads_norm = 4.2892
	new_data_grads_norm = 6.5658
	old_data_grads_norm = 5.7642
	sim_grads_norm = -0.0357
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4595
	data_grads_norm = 4.0873
	new_data_grads_norm = 5.8461
	old_data_grads_norm = 4.6700
	sim_grads_norm = -0.0212
-- Starting training on experience 90 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4827
	data_grads_norm = 3.7804
	new_data_grads_norm = 5.0200
	old_data_grads_norm = 5.7956
	sim_grads_norm = 0.0008
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1146
	data_grads_norm = 2.8475
	new_data_grads_norm = 4.8333
	old_data_grads_norm = 3.2647
	sim_grads_norm = -0.0244
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3187
	data_grads_norm = 3.1377
	new_data_grads_norm = 5.2724
	old_data_grads_norm = 3.1310
	sim_grads_norm = 0.1021
-- Starting training on experience 91 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4249
	data_grads_norm = 3.7040
	new_data_grads_norm = 6.0953
	old_data_grads_norm = 3.9665
	sim_grads_norm = -0.0392
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6728
	data_grads_norm = 3.9781
	new_data_grads_norm = 5.7784
	old_data_grads_norm = 5.5157
	sim_grads_norm = -0.0255
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8030
	data_grads_norm = 5.1139
	new_data_grads_norm = 6.8597
	old_data_grads_norm = 6.2022
	sim_grads_norm = -0.0628
-- Starting training on experience 92 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6320
	data_grads_norm = 3.7873
	new_data_grads_norm = 5.9386
	old_data_grads_norm = 4.9361
	sim_grads_norm = -0.0483
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8501
	data_grads_norm = 4.0885
	new_data_grads_norm = 6.3362
	old_data_grads_norm = 5.1486
	sim_grads_norm = 0.0337
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3801
	data_grads_norm = 3.7064
	new_data_grads_norm = 5.7514
	old_data_grads_norm = 4.6551
	sim_grads_norm = -0.0390
-- Starting training on experience 93 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6081
	data_grads_norm = 3.7525
	new_data_grads_norm = 5.5672
	old_data_grads_norm = 4.6504
	sim_grads_norm = 0.0658
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7299
	data_grads_norm = 3.8751
	new_data_grads_norm = 4.9965
	old_data_grads_norm = 5.2612
	sim_grads_norm = 0.0464
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1403
	data_grads_norm = 2.9735
	new_data_grads_norm = 4.6840
	old_data_grads_norm = 3.6447
	sim_grads_norm = -0.0084
-- Starting training on experience 94 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3938
	data_grads_norm = 3.2964
	new_data_grads_norm = 4.9322
	old_data_grads_norm = 3.6519
	sim_grads_norm = -0.0235
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0339
	data_grads_norm = 3.7722
	new_data_grads_norm = 5.0768
	old_data_grads_norm = 4.7598
	sim_grads_norm = 0.0242
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2625
	data_grads_norm = 3.4028
	new_data_grads_norm = 4.8960
	old_data_grads_norm = 5.6728
	sim_grads_norm = 0.0293
-- Starting training on experience 95 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5375
	data_grads_norm = 3.7809
	new_data_grads_norm = 5.5427
	old_data_grads_norm = 4.8724
	sim_grads_norm = 0.0480
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4052
	data_grads_norm = 3.4026
	new_data_grads_norm = 5.4394
	old_data_grads_norm = 4.7606
	sim_grads_norm = 0.0277
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7753
	data_grads_norm = 4.4753
	new_data_grads_norm = 5.6770
	old_data_grads_norm = 6.0403
	sim_grads_norm = 0.0232
-- Starting training on experience 96 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7740
	data_grads_norm = 4.0578
	new_data_grads_norm = 4.7109
	old_data_grads_norm = 5.4099
	sim_grads_norm = 0.0111
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9659
	data_grads_norm = 4.2020
	new_data_grads_norm = 5.2608
	old_data_grads_norm = 6.5063
	sim_grads_norm = 0.0726
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5218
	data_grads_norm = 3.9017
	new_data_grads_norm = 5.0160
	old_data_grads_norm = 5.8728
	sim_grads_norm = 0.0555
-- Starting training on experience 97 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4953
	data_grads_norm = 3.7792
	new_data_grads_norm = 6.3403
	old_data_grads_norm = 4.5701
	sim_grads_norm = -0.0085
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4162
	data_grads_norm = 4.1204
	new_data_grads_norm = 6.8290
	old_data_grads_norm = 4.1823
	sim_grads_norm = 0.0019
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7622
	data_grads_norm = 4.4478
	new_data_grads_norm = 6.2891
	old_data_grads_norm = 5.6176
	sim_grads_norm = 0.0053
-- Starting training on experience 98 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0994
	data_grads_norm = 3.6788
	new_data_grads_norm = 5.9924
	old_data_grads_norm = 3.5785
	sim_grads_norm = 0.0154
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2603
	data_grads_norm = 3.7811
	new_data_grads_norm = 5.4649
	old_data_grads_norm = 4.8333
	sim_grads_norm = -0.0025
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4264
	data_grads_norm = 3.5965
	new_data_grads_norm = 5.8382
	old_data_grads_norm = 4.6219
	sim_grads_norm = 0.0009
-- Starting training on experience 99 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7740
	data_grads_norm = 3.9199
	new_data_grads_norm = 5.1025
	old_data_grads_norm = 5.5051
	sim_grads_norm = 0.0082
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4417
	data_grads_norm = 3.6960
	new_data_grads_norm = 5.1716
	old_data_grads_norm = 4.4401
	sim_grads_norm = 0.0112
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9754
	data_grads_norm = 4.3042
	new_data_grads_norm = 4.8988
	old_data_grads_norm = 5.9804
	sim_grads_norm = 0.0672
-- Starting training on experience 100 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1034
	data_grads_norm = 4.4969
	new_data_grads_norm = 6.2499
	old_data_grads_norm = 5.5448
	sim_grads_norm = 0.0216
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9130
	data_grads_norm = 4.3108
	new_data_grads_norm = 5.6738
	old_data_grads_norm = 4.7470
	sim_grads_norm = 0.0470
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6757
	data_grads_norm = 4.4753
	new_data_grads_norm = 5.8965
	old_data_grads_norm = 6.7842
	sim_grads_norm = -0.0092
-- Starting training on experience 101 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1407
	data_grads_norm = 3.6462
	new_data_grads_norm = 5.5367
	old_data_grads_norm = 4.4267
	sim_grads_norm = 0.1690
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5334
	data_grads_norm = 4.4966
	new_data_grads_norm = 6.1214
	old_data_grads_norm = 5.7897
	sim_grads_norm = -0.0321
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8792
	data_grads_norm = 3.3468
	new_data_grads_norm = 5.4244
	old_data_grads_norm = 2.8098
	sim_grads_norm = 0.0029
-- Starting training on experience 102 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6950
	data_grads_norm = 4.6430
	new_data_grads_norm = 4.7737
	old_data_grads_norm = 7.1714
	sim_grads_norm = 0.0324
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1861
	data_grads_norm = 3.8673
	new_data_grads_norm = 4.4662
	old_data_grads_norm = 6.4003
	sim_grads_norm = -0.0389
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3620
	data_grads_norm = 3.8619
	new_data_grads_norm = 5.2337
	old_data_grads_norm = 5.6838
	sim_grads_norm = 0.0121
-- Starting training on experience 103 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1197
	data_grads_norm = 3.1750
	new_data_grads_norm = 4.8286
	old_data_grads_norm = 4.5970
	sim_grads_norm = -0.0692
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1264
	data_grads_norm = 2.8882
	new_data_grads_norm = 4.6856
	old_data_grads_norm = 3.5770
	sim_grads_norm = 0.0074
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3309
	data_grads_norm = 3.7571
	new_data_grads_norm = 5.4059
	old_data_grads_norm = 4.6612
	sim_grads_norm = 0.0449
-- Starting training on experience 104 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5140
	data_grads_norm = 3.5871
	new_data_grads_norm = 5.5969
	old_data_grads_norm = 4.4866
	sim_grads_norm = -0.0389
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5562
	data_grads_norm = 4.0781
	new_data_grads_norm = 5.5482
	old_data_grads_norm = 5.5604
	sim_grads_norm = -0.0371
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4304
	data_grads_norm = 3.9915
	new_data_grads_norm = 6.1156
	old_data_grads_norm = 4.2702
	sim_grads_norm = -0.0272
-- Starting training on experience 105 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5649
	data_grads_norm = 3.8086
	new_data_grads_norm = 4.9173
	old_data_grads_norm = 5.2757
	sim_grads_norm = -0.0312
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4608
	data_grads_norm = 4.0097
	new_data_grads_norm = 5.4498
	old_data_grads_norm = 4.7858
	sim_grads_norm = -0.0234
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0398
	data_grads_norm = 3.4066
	new_data_grads_norm = 4.9299
	old_data_grads_norm = 4.7241
	sim_grads_norm = -0.0037
-- Starting training on experience 106 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0348
	data_grads_norm = 3.7218
	new_data_grads_norm = 6.3956
	old_data_grads_norm = 5.8318
	sim_grads_norm = -0.0391
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4881
	data_grads_norm = 3.7822
	new_data_grads_norm = 6.2694
	old_data_grads_norm = 4.4527
	sim_grads_norm = 0.0001
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2455
	data_grads_norm = 4.2546
	new_data_grads_norm = 5.9660
	old_data_grads_norm = 5.2130
	sim_grads_norm = -0.0355
-- Starting training on experience 107 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8618
	data_grads_norm = 4.6835
	new_data_grads_norm = 7.1319
	old_data_grads_norm = 6.4653
	sim_grads_norm = 0.0445
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9641
	data_grads_norm = 4.1283
	new_data_grads_norm = 6.6956
	old_data_grads_norm = 5.1025
	sim_grads_norm = -0.0189
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9773
	data_grads_norm = 4.3076
	new_data_grads_norm = 6.6415
	old_data_grads_norm = 5.5796
	sim_grads_norm = 0.0144
-- Starting training on experience 108 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9831
	data_grads_norm = 3.1548
	new_data_grads_norm = 4.7577
	old_data_grads_norm = 4.3351
	sim_grads_norm = -0.0030
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8470
	data_grads_norm = 4.2507
	new_data_grads_norm = 4.9424
	old_data_grads_norm = 6.6625
	sim_grads_norm = 0.0370
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4242
	data_grads_norm = 3.6802
	new_data_grads_norm = 4.7380
	old_data_grads_norm = 4.2353
	sim_grads_norm = 0.1605
-- Starting training on experience 109 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8869
	data_grads_norm = 3.2496
	new_data_grads_norm = 4.8789
	old_data_grads_norm = 4.0875
	sim_grads_norm = 0.0324
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4854
	data_grads_norm = 3.5614
	new_data_grads_norm = 5.4778
	old_data_grads_norm = 4.4766
	sim_grads_norm = 0.1059
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1696
	data_grads_norm = 3.2816
	new_data_grads_norm = 4.8079
	old_data_grads_norm = 3.3068
	sim_grads_norm = 0.0526
-- Starting training on experience 110 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1154
	data_grads_norm = 3.8066
	new_data_grads_norm = 4.4877
	old_data_grads_norm = 5.9398
	sim_grads_norm = 0.0136
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5828
	data_grads_norm = 4.6200
	new_data_grads_norm = 4.3818
	old_data_grads_norm = 6.7458
	sim_grads_norm = 0.0663
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7822
	data_grads_norm = 3.1402
	new_data_grads_norm = 4.1979
	old_data_grads_norm = 4.8890
	sim_grads_norm = -0.0384
-- Starting training on experience 111 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3261
	data_grads_norm = 3.7414
	new_data_grads_norm = 5.9732
	old_data_grads_norm = 4.8408
	sim_grads_norm = -0.0563
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5062
	data_grads_norm = 4.0417
	new_data_grads_norm = 5.3083
	old_data_grads_norm = 6.0306
	sim_grads_norm = -0.0201
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5515
	data_grads_norm = 3.8606
	new_data_grads_norm = 6.1003
	old_data_grads_norm = 4.4961
	sim_grads_norm = -0.0232
-- Starting training on experience 112 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4611
	data_grads_norm = 4.4976
	new_data_grads_norm = 6.5555
	old_data_grads_norm = 5.2558
	sim_grads_norm = -0.0142
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2668
	data_grads_norm = 4.2119
	new_data_grads_norm = 6.5822
	old_data_grads_norm = 4.5236
	sim_grads_norm = 0.0317
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2430
	data_grads_norm = 4.1831
	new_data_grads_norm = 6.3233
	old_data_grads_norm = 4.8400
	sim_grads_norm = 0.0128
-- Starting training on experience 113 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3927
	data_grads_norm = 3.8176
	new_data_grads_norm = 5.8385
	old_data_grads_norm = 4.7993
	sim_grads_norm = 0.0397
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3508
	data_grads_norm = 3.7155
	new_data_grads_norm = 6.0983
	old_data_grads_norm = 4.4204
	sim_grads_norm = -0.0215
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0146
	data_grads_norm = 4.6466
	new_data_grads_norm = 6.0094
	old_data_grads_norm = 6.7771
	sim_grads_norm = -0.0091
-- Starting training on experience 114 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3444
	data_grads_norm = 3.6890
	new_data_grads_norm = 6.2284
	old_data_grads_norm = 3.5973
	sim_grads_norm = -0.0062
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5619
	data_grads_norm = 4.9280
	new_data_grads_norm = 6.5482
	old_data_grads_norm = 6.0311
	sim_grads_norm = 0.0138
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4355
	data_grads_norm = 4.2004
	new_data_grads_norm = 5.9524
	old_data_grads_norm = 5.4501
	sim_grads_norm = -0.0148
-- Starting training on experience 115 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7179
	data_grads_norm = 4.3555
	new_data_grads_norm = 5.9063
	old_data_grads_norm = 6.3319
	sim_grads_norm = -0.0057
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2868
	data_grads_norm = 3.3368
	new_data_grads_norm = 5.3688
	old_data_grads_norm = 4.2992
	sim_grads_norm = -0.0165
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5461
	data_grads_norm = 4.1581
	new_data_grads_norm = 5.4512
	old_data_grads_norm = 6.0768
	sim_grads_norm = 0.0419
-- Starting training on experience 116 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7103
	data_grads_norm = 4.3281
	new_data_grads_norm = 5.7566
	old_data_grads_norm = 5.2577
	sim_grads_norm = 0.1128
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0514
	data_grads_norm = 3.7966
	new_data_grads_norm = 5.6792
	old_data_grads_norm = 4.5556
	sim_grads_norm = 0.0130
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1270
	data_grads_norm = 3.6627
	new_data_grads_norm = 5.2972
	old_data_grads_norm = 4.3038
	sim_grads_norm = -0.0060
-- Starting training on experience 117 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7201
	data_grads_norm = 4.1885
	new_data_grads_norm = 5.8802
	old_data_grads_norm = 5.5731
	sim_grads_norm = -0.0038
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4073
	data_grads_norm = 4.1773
	new_data_grads_norm = 6.5274
	old_data_grads_norm = 5.1948
	sim_grads_norm = 0.0433
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3481
	data_grads_norm = 3.7627
	new_data_grads_norm = 6.3967
	old_data_grads_norm = 3.9852
	sim_grads_norm = -0.0305
-- Starting training on experience 118 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4162
	data_grads_norm = 3.6283
	new_data_grads_norm = 4.8530
	old_data_grads_norm = 4.7981
	sim_grads_norm = -0.0153
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2153
	data_grads_norm = 4.0909
	new_data_grads_norm = 6.3884
	old_data_grads_norm = 5.4457
	sim_grads_norm = 0.0760
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9619
	data_grads_norm = 3.4145
	new_data_grads_norm = 5.1174
	old_data_grads_norm = 4.5512
	sim_grads_norm = -0.0398
-- Starting training on experience 119 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3008
	data_grads_norm = 4.0942
	new_data_grads_norm = 6.6664
	old_data_grads_norm = 4.5329
	sim_grads_norm = -0.0326
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6274
	data_grads_norm = 4.5314
	new_data_grads_norm = 5.6544
	old_data_grads_norm = 6.4761
	sim_grads_norm = 0.0051
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7800
	data_grads_norm = 3.8387
	new_data_grads_norm = 5.6271
	old_data_grads_norm = 5.2756
	sim_grads_norm = -0.0425
-- Starting training on experience 120 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2030
	data_grads_norm = 4.2627
	new_data_grads_norm = 6.3058
	old_data_grads_norm = 6.1491
	sim_grads_norm = 0.0098
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2951
	data_grads_norm = 3.7654
	new_data_grads_norm = 6.1138
	old_data_grads_norm = 4.5118
	sim_grads_norm = -0.0042
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1668
	data_grads_norm = 3.4836
	new_data_grads_norm = 5.3112
	old_data_grads_norm = 4.1292
	sim_grads_norm = 0.0271
-- Starting training on experience 121 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3483
	data_grads_norm = 3.7344
	new_data_grads_norm = 5.6419
	old_data_grads_norm = 5.7251
	sim_grads_norm = -0.0120
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3405
	data_grads_norm = 3.3982
	new_data_grads_norm = 5.1991
	old_data_grads_norm = 4.2854
	sim_grads_norm = 0.0059
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6288
	data_grads_norm = 3.5252
	new_data_grads_norm = 5.5355
	old_data_grads_norm = 4.7565
	sim_grads_norm = 0.0643
-- Starting training on experience 122 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2876
	data_grads_norm = 3.9298
	new_data_grads_norm = 6.3271
	old_data_grads_norm = 4.3713
	sim_grads_norm = -0.0109
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9034
	data_grads_norm = 4.4330
	new_data_grads_norm = 6.2484
	old_data_grads_norm = 5.5386
	sim_grads_norm = 0.0826
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4564
	data_grads_norm = 4.1560
	new_data_grads_norm = 5.5927
	old_data_grads_norm = 5.8295
	sim_grads_norm = -0.0239
-- Starting training on experience 123 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8375
	data_grads_norm = 4.3915
	new_data_grads_norm = 6.0736
	old_data_grads_norm = 6.4571
	sim_grads_norm = 0.0146
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4312
	data_grads_norm = 4.0483
	new_data_grads_norm = 5.9908
	old_data_grads_norm = 5.1026
	sim_grads_norm = 0.0562
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4032
	data_grads_norm = 4.5541
	new_data_grads_norm = 6.1679
	old_data_grads_norm = 6.1648
	sim_grads_norm = -0.0017
-- Starting training on experience 124 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2043
	data_grads_norm = 4.1314
	new_data_grads_norm = 6.0928
	old_data_grads_norm = 5.4922
	sim_grads_norm = -0.0031
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1179
	data_grads_norm = 3.6958
	new_data_grads_norm = 5.2931
	old_data_grads_norm = 5.1482
	sim_grads_norm = 0.0031
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8293
	data_grads_norm = 3.4387
	new_data_grads_norm = 5.3184
	old_data_grads_norm = 3.8772
	sim_grads_norm = -0.0053
-- Starting training on experience 125 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6319
	data_grads_norm = 4.6817
	new_data_grads_norm = 6.7436
	old_data_grads_norm = 5.8396
	sim_grads_norm = -0.0098
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0298
	data_grads_norm = 4.4355
	new_data_grads_norm = 6.4855
	old_data_grads_norm = 4.9184
	sim_grads_norm = 0.0418
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3203
	data_grads_norm = 3.4403
	new_data_grads_norm = 5.8769
	old_data_grads_norm = 3.6136
	sim_grads_norm = 0.0449
-- Starting training on experience 126 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3175
	data_grads_norm = 3.9428
	new_data_grads_norm = 5.7530
	old_data_grads_norm = 5.0211
	sim_grads_norm = -0.0047
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4240
	data_grads_norm = 4.0309
	new_data_grads_norm = 6.2028
	old_data_grads_norm = 4.9713
	sim_grads_norm = 0.0001
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3379
	data_grads_norm = 4.4089
	new_data_grads_norm = 6.5240
	old_data_grads_norm = 4.9763
	sim_grads_norm = -0.0257
-- Starting training on experience 127 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6161
	data_grads_norm = 4.1980
	new_data_grads_norm = 5.9602
	old_data_grads_norm = 5.4287
	sim_grads_norm = 0.0030
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4780
	data_grads_norm = 4.1385
	new_data_grads_norm = 6.0985
	old_data_grads_norm = 5.6518
	sim_grads_norm = -0.0342
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5022
	data_grads_norm = 4.1379
	new_data_grads_norm = 5.9081
	old_data_grads_norm = 5.3667
	sim_grads_norm = -0.0077
-- Starting training on experience 128 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7554
	data_grads_norm = 4.9901
	new_data_grads_norm = 7.3520
	old_data_grads_norm = 5.6703
	sim_grads_norm = 0.0422
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7964
	data_grads_norm = 4.5109
	new_data_grads_norm = 6.4979
	old_data_grads_norm = 5.6166
	sim_grads_norm = -0.0006
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3948
	data_grads_norm = 3.8522
	new_data_grads_norm = 5.7177
	old_data_grads_norm = 4.6626
	sim_grads_norm = 0.0918
-- Starting training on experience 129 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0473
	data_grads_norm = 3.0168
	new_data_grads_norm = 4.7452
	old_data_grads_norm = 3.8266
	sim_grads_norm = -0.0506
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7469
	data_grads_norm = 4.4409
	new_data_grads_norm = 4.9312
	old_data_grads_norm = 6.6543
	sim_grads_norm = -0.0218
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7107
	data_grads_norm = 3.9348
	new_data_grads_norm = 5.2314
	old_data_grads_norm = 5.0127
	sim_grads_norm = 0.0232
-- Starting training on experience 130 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2012
	data_grads_norm = 3.8859
	new_data_grads_norm = 5.9960
	old_data_grads_norm = 4.8941
	sim_grads_norm = -0.0440
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3674
	data_grads_norm = 3.9223
	new_data_grads_norm = 6.2725
	old_data_grads_norm = 4.8629
	sim_grads_norm = 0.0170
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3413
	data_grads_norm = 3.9520
	new_data_grads_norm = 6.0226
	old_data_grads_norm = 4.9693
	sim_grads_norm = 0.0154
-- Starting training on experience 131 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4297
	data_grads_norm = 3.9734
	new_data_grads_norm = 5.7068
	old_data_grads_norm = 6.0937
	sim_grads_norm = -0.0386
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2447
	data_grads_norm = 3.3869
	new_data_grads_norm = 5.7765
	old_data_grads_norm = 3.8739
	sim_grads_norm = -0.0265
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0560
	data_grads_norm = 3.4920
	new_data_grads_norm = 5.3252
	old_data_grads_norm = 4.5369
	sim_grads_norm = -0.0069
-- Starting training on experience 132 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4849
	data_grads_norm = 4.2866
	new_data_grads_norm = 6.1318
	old_data_grads_norm = 5.9421
	sim_grads_norm = 0.0528
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3481
	data_grads_norm = 3.5134
	new_data_grads_norm = 5.7862
	old_data_grads_norm = 3.3504
	sim_grads_norm = 0.0561
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2279
	data_grads_norm = 3.8177
	new_data_grads_norm = 5.6378
	old_data_grads_norm = 5.4899
	sim_grads_norm = -0.0298
-- Starting training on experience 133 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2811
	data_grads_norm = 3.6256
	new_data_grads_norm = 5.1988
	old_data_grads_norm = 4.6819
	sim_grads_norm = -0.0060
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2483
	data_grads_norm = 3.5500
	new_data_grads_norm = 5.4934
	old_data_grads_norm = 5.3878
	sim_grads_norm = -0.0829
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4701
	data_grads_norm = 4.2983
	new_data_grads_norm = 6.0925
	old_data_grads_norm = 5.2077
	sim_grads_norm = 0.0614
-- Starting training on experience 134 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7095
	data_grads_norm = 4.0083
	new_data_grads_norm = 6.4819
	old_data_grads_norm = 5.5940
	sim_grads_norm = 0.0035
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4862
	data_grads_norm = 4.3509
	new_data_grads_norm = 5.8272
	old_data_grads_norm = 6.5760
	sim_grads_norm = -0.0063
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6765
	data_grads_norm = 4.3969
	new_data_grads_norm = 6.7011
	old_data_grads_norm = 5.8557
	sim_grads_norm = -0.0375
-- Starting training on experience 135 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8085
	data_grads_norm = 4.7967
	new_data_grads_norm = 6.7681
	old_data_grads_norm = 6.1480
	sim_grads_norm = 0.0240
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7632
	data_grads_norm = 4.7861
	new_data_grads_norm = 7.1812
	old_data_grads_norm = 6.4548
	sim_grads_norm = 0.0042
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5860
	data_grads_norm = 4.1416
	new_data_grads_norm = 6.4590
	old_data_grads_norm = 5.6304
	sim_grads_norm = 0.0002
-- Starting training on experience 136 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8177
	data_grads_norm = 4.1884
	new_data_grads_norm = 6.4568
	old_data_grads_norm = 4.4663
	sim_grads_norm = 0.0338
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2640
	data_grads_norm = 3.8825
	new_data_grads_norm = 6.1177
	old_data_grads_norm = 4.6661
	sim_grads_norm = -0.0154
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9819
	data_grads_norm = 4.7484
	new_data_grads_norm = 6.5380
	old_data_grads_norm = 5.9453
	sim_grads_norm = 0.0245
-- Starting training on experience 137 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6008
	data_grads_norm = 4.1338
	new_data_grads_norm = 6.7513
	old_data_grads_norm = 5.6442
	sim_grads_norm = 0.0143
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8655
	data_grads_norm = 4.6421
	new_data_grads_norm = 7.0603
	old_data_grads_norm = 5.7500
	sim_grads_norm = 0.0075
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5336
	data_grads_norm = 4.0663
	new_data_grads_norm = 7.2696
	old_data_grads_norm = 3.6216
	sim_grads_norm = 0.0937
-- Starting training on experience 138 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6838
	data_grads_norm = 4.1094
	new_data_grads_norm = 5.6934
	old_data_grads_norm = 6.8910
	sim_grads_norm = -0.0188
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7113
	data_grads_norm = 4.3472
	new_data_grads_norm = 6.2259
	old_data_grads_norm = 6.4629
	sim_grads_norm = -0.0064
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9931
	data_grads_norm = 4.2092
	new_data_grads_norm = 6.0927
	old_data_grads_norm = 6.1709
	sim_grads_norm = -0.0200
-- Starting training on experience 139 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3582
	data_grads_norm = 3.6786
	new_data_grads_norm = 5.0684
	old_data_grads_norm = 5.1039
	sim_grads_norm = 0.0173
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5328
	data_grads_norm = 4.7912
	new_data_grads_norm = 5.7827
	old_data_grads_norm = 7.3342
	sim_grads_norm = 0.0087
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7655
	data_grads_norm = 4.6311
	new_data_grads_norm = 5.7955
	old_data_grads_norm = 6.9004
	sim_grads_norm = 0.0141
-- Starting training on experience 140 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5733
	data_grads_norm = 4.0079
	new_data_grads_norm = 5.4158
	old_data_grads_norm = 5.4518
	sim_grads_norm = 0.0588
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4156
	data_grads_norm = 4.3066
	new_data_grads_norm = 5.6970
	old_data_grads_norm = 5.6150
	sim_grads_norm = 0.0461
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4926
	data_grads_norm = 3.6582
	new_data_grads_norm = 5.9786
	old_data_grads_norm = 4.1950
	sim_grads_norm = -0.0050
-- Starting training on experience 141 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4532
	data_grads_norm = 4.2530
	new_data_grads_norm = 5.4905
	old_data_grads_norm = 4.9181
	sim_grads_norm = -0.0197
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3641
	data_grads_norm = 3.8263
	new_data_grads_norm = 5.4066
	old_data_grads_norm = 4.4660
	sim_grads_norm = -0.0086
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6621
	data_grads_norm = 4.6513
	new_data_grads_norm = 6.6717
	old_data_grads_norm = 4.7691
	sim_grads_norm = 0.0490
-- Starting training on experience 142 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1487
	data_grads_norm = 4.1919
	new_data_grads_norm = 5.7001
	old_data_grads_norm = 6.1718
	sim_grads_norm = 0.0285
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0611
	data_grads_norm = 4.8579
	new_data_grads_norm = 5.4956
	old_data_grads_norm = 5.9935
	sim_grads_norm = 0.0818
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2029
	data_grads_norm = 4.1171
	new_data_grads_norm = 4.7727
	old_data_grads_norm = 5.8971
	sim_grads_norm = -0.0146
-- Starting training on experience 143 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3203
	data_grads_norm = 3.6367
	new_data_grads_norm = 5.1107
	old_data_grads_norm = 4.8963
	sim_grads_norm = -0.0082
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5249
	data_grads_norm = 3.9987
	new_data_grads_norm = 5.5616
	old_data_grads_norm = 4.7018
	sim_grads_norm = 0.0406
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6772
	data_grads_norm = 3.8248
	new_data_grads_norm = 5.1789
	old_data_grads_norm = 5.9467
	sim_grads_norm = 0.0629
-- Starting training on experience 144 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0499
	data_grads_norm = 3.7410
	new_data_grads_norm = 5.4910
	old_data_grads_norm = 4.0900
	sim_grads_norm = -0.0033
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9589
	data_grads_norm = 3.9330
	new_data_grads_norm = 5.9716
	old_data_grads_norm = 4.4956
	sim_grads_norm = -0.0381
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0106
	data_grads_norm = 3.9646
	new_data_grads_norm = 5.6393
	old_data_grads_norm = 5.4084
	sim_grads_norm = -0.0092
-- Starting training on experience 145 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2167
	data_grads_norm = 3.2857
	new_data_grads_norm = 5.6419
	old_data_grads_norm = 4.0797
	sim_grads_norm = -0.0201
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7518
	data_grads_norm = 3.9458
	new_data_grads_norm = 4.8986
	old_data_grads_norm = 5.5417
	sim_grads_norm = 0.0604
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3016
	data_grads_norm = 4.0277
	new_data_grads_norm = 5.4350
	old_data_grads_norm = 4.9215
	sim_grads_norm = -0.0130
-- Starting training on experience 146 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9130
	data_grads_norm = 4.2994
	new_data_grads_norm = 4.7877
	old_data_grads_norm = 7.0372
	sim_grads_norm = 0.0226
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9702
	data_grads_norm = 3.5454
	new_data_grads_norm = 4.8137
	old_data_grads_norm = 6.0955
	sim_grads_norm = -0.0029
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2981
	data_grads_norm = 3.6057
	new_data_grads_norm = 5.0677
	old_data_grads_norm = 5.0197
	sim_grads_norm = -0.0176
-- Starting training on experience 147 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2823
	data_grads_norm = 4.0471
	new_data_grads_norm = 5.6118
	old_data_grads_norm = 4.9581
	sim_grads_norm = -0.0201
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5019
	data_grads_norm = 3.9085
	new_data_grads_norm = 5.3521
	old_data_grads_norm = 4.9272
	sim_grads_norm = 0.0254
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7289
	data_grads_norm = 4.3139
	new_data_grads_norm = 5.2811
	old_data_grads_norm = 6.2642
	sim_grads_norm = 0.0102
-- Starting training on experience 148 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8601
	data_grads_norm = 4.0073
	new_data_grads_norm = 5.8195
	old_data_grads_norm = 5.3887
	sim_grads_norm = -0.0684
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3913
	data_grads_norm = 4.6225
	new_data_grads_norm = 5.9761
	old_data_grads_norm = 6.1465
	sim_grads_norm = 0.1020
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7152
	data_grads_norm = 4.0811
	new_data_grads_norm = 5.6418
	old_data_grads_norm = 5.3074
	sim_grads_norm = 0.0981
-- Starting training on experience 149 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8915
	data_grads_norm = 3.4236
	new_data_grads_norm = 5.5528
	old_data_grads_norm = 4.0601
	sim_grads_norm = -0.0033
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2865
	data_grads_norm = 4.7464
	new_data_grads_norm = 7.0974
	old_data_grads_norm = 5.8683
	sim_grads_norm = -0.0431
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4003
	data_grads_norm = 4.1987
	new_data_grads_norm = 6.4944
	old_data_grads_norm = 4.6266
	sim_grads_norm = 0.0119
-- Starting training on experience 150 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4234
	data_grads_norm = 4.0387
	new_data_grads_norm = 5.3757
	old_data_grads_norm = 5.5105
	sim_grads_norm = -0.0247
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2170
	data_grads_norm = 3.4640
	new_data_grads_norm = 5.8313
	old_data_grads_norm = 4.0249
	sim_grads_norm = -0.0108
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7378
	data_grads_norm = 4.2213
	new_data_grads_norm = 5.9938
	old_data_grads_norm = 6.3763
	sim_grads_norm = -0.0073
-- Starting training on experience 151 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6319
	data_grads_norm = 4.1028
	new_data_grads_norm = 5.5440
	old_data_grads_norm = 5.3071
	sim_grads_norm = 0.0217
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2144
	data_grads_norm = 3.9570
	new_data_grads_norm = 5.9184
	old_data_grads_norm = 5.2758
	sim_grads_norm = 0.0083
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2970
	data_grads_norm = 3.9200
	new_data_grads_norm = 5.3838
	old_data_grads_norm = 5.6028
	sim_grads_norm = -0.0100
-- Starting training on experience 152 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8345
	data_grads_norm = 4.0742
	new_data_grads_norm = 6.4084
	old_data_grads_norm = 4.7236
	sim_grads_norm = 0.0299
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8325
	data_grads_norm = 4.1784
	new_data_grads_norm = 6.9501
	old_data_grads_norm = 5.4793
	sim_grads_norm = -0.0292
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6933
	data_grads_norm = 3.8171
	new_data_grads_norm = 6.0478
	old_data_grads_norm = 4.5653
	sim_grads_norm = 0.0119
-- Starting training on experience 153 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5129
	data_grads_norm = 3.8201
	new_data_grads_norm = 6.2958
	old_data_grads_norm = 4.6472
	sim_grads_norm = 0.0619
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0112
	data_grads_norm = 4.4437
	new_data_grads_norm = 5.7119
	old_data_grads_norm = 5.6412
	sim_grads_norm = 0.0184
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7204
	data_grads_norm = 3.9464
	new_data_grads_norm = 5.8659
	old_data_grads_norm = 4.6972
	sim_grads_norm = 0.0258
-- Starting training on experience 154 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2487
	data_grads_norm = 3.4924
	new_data_grads_norm = 5.2392
	old_data_grads_norm = 3.8014
	sim_grads_norm = -0.0173
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1644
	data_grads_norm = 3.2311
	new_data_grads_norm = 5.4993
	old_data_grads_norm = 4.1316
	sim_grads_norm = -0.0259
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2068
	data_grads_norm = 4.4351
	new_data_grads_norm = 5.5571
	old_data_grads_norm = 6.2508
	sim_grads_norm = 0.0305
-- Starting training on experience 155 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4913
	data_grads_norm = 3.5836
	new_data_grads_norm = 5.5785
	old_data_grads_norm = 4.5058
	sim_grads_norm = 0.0594
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3702
	data_grads_norm = 3.6376
	new_data_grads_norm = 5.5495
	old_data_grads_norm = 3.4513
	sim_grads_norm = 0.1141
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1038
	data_grads_norm = 3.2463
	new_data_grads_norm = 4.8902
	old_data_grads_norm = 4.3862
	sim_grads_norm = 0.0025
-- Starting training on experience 156 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5681
	data_grads_norm = 3.8845
	new_data_grads_norm = 5.7816
	old_data_grads_norm = 4.9263
	sim_grads_norm = -0.0694
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4182
	data_grads_norm = 4.2334
	new_data_grads_norm = 6.2230
	old_data_grads_norm = 4.2539
	sim_grads_norm = -0.0013
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7632
	data_grads_norm = 4.0878
	new_data_grads_norm = 5.8129
	old_data_grads_norm = 4.8613
	sim_grads_norm = 0.0055
-- Starting training on experience 157 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1980
	data_grads_norm = 3.4366
	new_data_grads_norm = 5.8870
	old_data_grads_norm = 3.3175
	sim_grads_norm = 0.0141
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1027
	data_grads_norm = 3.5303
	new_data_grads_norm = 5.6057
	old_data_grads_norm = 4.6661
	sim_grads_norm = -0.0409
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7750
	data_grads_norm = 4.1828
	new_data_grads_norm = 5.8499
	old_data_grads_norm = 5.3982
	sim_grads_norm = 0.0537
-- Starting training on experience 158 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4349
	data_grads_norm = 3.6269
	new_data_grads_norm = 5.7736
	old_data_grads_norm = 3.3505
	sim_grads_norm = -0.0072
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3957
	data_grads_norm = 3.5460
	new_data_grads_norm = 5.9914
	old_data_grads_norm = 3.8797
	sim_grads_norm = 0.0778
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3239
	data_grads_norm = 3.4628
	new_data_grads_norm = 4.8368
	old_data_grads_norm = 5.2397
	sim_grads_norm = -0.0506
-- Starting training on experience 159 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7440
	data_grads_norm = 4.4354
	new_data_grads_norm = 5.3881
	old_data_grads_norm = 5.7939
	sim_grads_norm = 0.0302
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8531
	data_grads_norm = 4.1817
	new_data_grads_norm = 5.5584
	old_data_grads_norm = 4.5807
	sim_grads_norm = 0.0641
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4526
	data_grads_norm = 3.9808
	new_data_grads_norm = 5.2877
	old_data_grads_norm = 5.5254
	sim_grads_norm = 0.0140
-- Starting training on experience 160 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3675
	data_grads_norm = 4.0199
	new_data_grads_norm = 6.1242
	old_data_grads_norm = 4.7809
	sim_grads_norm = 0.0232
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4468
	data_grads_norm = 4.6081
	new_data_grads_norm = 6.0067
	old_data_grads_norm = 6.2881
	sim_grads_norm = 0.0055
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1152
	data_grads_norm = 3.7688
	new_data_grads_norm = 6.0525
	old_data_grads_norm = 4.9210
	sim_grads_norm = -0.0287
-- Starting training on experience 161 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4375
	data_grads_norm = 3.9050
	new_data_grads_norm = 5.9116
	old_data_grads_norm = 4.5059
	sim_grads_norm = 0.0598
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1862
	data_grads_norm = 3.3920
	new_data_grads_norm = 5.6789
	old_data_grads_norm = 2.7916
	sim_grads_norm = 0.0254
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6018
	data_grads_norm = 4.2538
	new_data_grads_norm = 5.5071
	old_data_grads_norm = 5.1926
	sim_grads_norm = -0.0227
-- Starting training on experience 162 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0984
	data_grads_norm = 3.6992
	new_data_grads_norm = 6.2840
	old_data_grads_norm = 4.9114
	sim_grads_norm = -0.0146
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4023
	data_grads_norm = 4.1839
	new_data_grads_norm = 6.9858
	old_data_grads_norm = 4.1389
	sim_grads_norm = 0.0048
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4646
	data_grads_norm = 4.0421
	new_data_grads_norm = 6.5327
	old_data_grads_norm = 4.5890
	sim_grads_norm = 0.0078
-- Starting training on experience 163 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5425
	data_grads_norm = 4.1258
	new_data_grads_norm = 6.3526
	old_data_grads_norm = 4.8733
	sim_grads_norm = 0.0472
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4828
	data_grads_norm = 4.8323
	new_data_grads_norm = 7.3040
	old_data_grads_norm = 4.5677
	sim_grads_norm = -0.0272
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4228
	data_grads_norm = 4.9338
	new_data_grads_norm = 7.4940
	old_data_grads_norm = 4.9451
	sim_grads_norm = 0.0515
-- Starting training on experience 164 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9732
	data_grads_norm = 3.8679
	new_data_grads_norm = 5.8866
	old_data_grads_norm = 4.2910
	sim_grads_norm = -0.0094
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3205
	data_grads_norm = 4.1308
	new_data_grads_norm = 6.3770
	old_data_grads_norm = 4.4258
	sim_grads_norm = -0.0051
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0982
	data_grads_norm = 4.3246
	new_data_grads_norm = 6.3661
	old_data_grads_norm = 4.6126
	sim_grads_norm = 0.0825
-- Starting training on experience 165 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0788
	data_grads_norm = 3.2993
	new_data_grads_norm = 5.2623
	old_data_grads_norm = 3.8367
	sim_grads_norm = 0.0286
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2980
	data_grads_norm = 4.2096
	new_data_grads_norm = 5.1984
	old_data_grads_norm = 5.4341
	sim_grads_norm = 0.0784
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4972
	data_grads_norm = 4.2183
	new_data_grads_norm = 4.7535
	old_data_grads_norm = 6.6670
	sim_grads_norm = -0.0261
-- Starting training on experience 166 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5678
	data_grads_norm = 4.0796
	new_data_grads_norm = 6.1972
	old_data_grads_norm = 5.4021
	sim_grads_norm = 0.0157
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6686
	data_grads_norm = 3.7918
	new_data_grads_norm = 6.0773
	old_data_grads_norm = 5.0005
	sim_grads_norm = 0.0049
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3523
	data_grads_norm = 3.8152
	new_data_grads_norm = 6.6772
	old_data_grads_norm = 4.5165
	sim_grads_norm = -0.0238
-- Starting training on experience 167 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9172
	data_grads_norm = 3.4486
	new_data_grads_norm = 4.8175
	old_data_grads_norm = 3.8666
	sim_grads_norm = 0.0535
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2483
	data_grads_norm = 4.1541
	new_data_grads_norm = 5.3124
	old_data_grads_norm = 5.6988
	sim_grads_norm = -0.0436
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9916
	data_grads_norm = 3.7484
	new_data_grads_norm = 5.9219
	old_data_grads_norm = 4.7752
	sim_grads_norm = 0.0245
-- Starting training on experience 168 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7375
	data_grads_norm = 3.4526
	new_data_grads_norm = 5.8024
	old_data_grads_norm = 4.5386
	sim_grads_norm = -0.0477
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1381
	data_grads_norm = 3.9832
	new_data_grads_norm = 5.7418
	old_data_grads_norm = 5.4800
	sim_grads_norm = -0.0012
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2817
	data_grads_norm = 3.7188
	new_data_grads_norm = 5.7115
	old_data_grads_norm = 4.8431
	sim_grads_norm = 0.0308
-- Starting training on experience 169 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3083
	data_grads_norm = 3.9214
	new_data_grads_norm = 6.2060
	old_data_grads_norm = 4.6511
	sim_grads_norm = 0.0585
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9810
	data_grads_norm = 4.1955
	new_data_grads_norm = 6.0840
	old_data_grads_norm = 3.9388
	sim_grads_norm = -0.0566
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4925
	data_grads_norm = 4.3105
	new_data_grads_norm = 6.3693
	old_data_grads_norm = 5.5685
	sim_grads_norm = -0.0025
-- Starting training on experience 170 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2989
	data_grads_norm = 3.9498
	new_data_grads_norm = 6.1550
	old_data_grads_norm = 4.4976
	sim_grads_norm = -0.0236
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1513
	data_grads_norm = 3.7651
	new_data_grads_norm = 5.8085
	old_data_grads_norm = 4.0290
	sim_grads_norm = -0.0114
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3992
	data_grads_norm = 4.6816
	new_data_grads_norm = 6.3721
	old_data_grads_norm = 6.3798
	sim_grads_norm = -0.0054
-- Starting training on experience 171 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7660
	data_grads_norm = 4.1254
	new_data_grads_norm = 6.0937
	old_data_grads_norm = 5.4098
	sim_grads_norm = 0.0499
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2061
	data_grads_norm = 3.5789
	new_data_grads_norm = 5.6293
	old_data_grads_norm = 3.4993
	sim_grads_norm = -0.0017
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1040
	data_grads_norm = 3.2256
	new_data_grads_norm = 5.4741
	old_data_grads_norm = 3.6997
	sim_grads_norm = 0.0013
-- Starting training on experience 172 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0598
	data_grads_norm = 3.5929
	new_data_grads_norm = 5.7002
	old_data_grads_norm = 4.5977
	sim_grads_norm = -0.0435
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1643
	data_grads_norm = 4.1115
	new_data_grads_norm = 5.9022
	old_data_grads_norm = 5.3408
	sim_grads_norm = -0.0142
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1120
	data_grads_norm = 4.1036
	new_data_grads_norm = 5.7960
	old_data_grads_norm = 6.6914
	sim_grads_norm = 0.0298
-- Starting training on experience 173 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2855
	data_grads_norm = 4.0053
	new_data_grads_norm = 5.6991
	old_data_grads_norm = 5.3986
	sim_grads_norm = 0.0579
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1481
	data_grads_norm = 4.2145
	new_data_grads_norm = 6.2103
	old_data_grads_norm = 5.0847
	sim_grads_norm = 0.0089
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1671
	data_grads_norm = 3.6070
	new_data_grads_norm = 5.6082
	old_data_grads_norm = 4.0073
	sim_grads_norm = 0.0308
-- Starting training on experience 174 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2029
	data_grads_norm = 3.8835
	new_data_grads_norm = 5.4850
	old_data_grads_norm = 5.5593
	sim_grads_norm = 0.0446
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1797
	data_grads_norm = 3.9041
	new_data_grads_norm = 5.4271
	old_data_grads_norm = 5.2141
	sim_grads_norm = 0.0228
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4802
	data_grads_norm = 3.7702
	new_data_grads_norm = 5.4596
	old_data_grads_norm = 4.6509
	sim_grads_norm = -0.0020
-- Starting training on experience 175 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2018
	data_grads_norm = 4.0565
	new_data_grads_norm = 6.0393
	old_data_grads_norm = 5.4684
	sim_grads_norm = 0.0466
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5295
	data_grads_norm = 4.1164
	new_data_grads_norm = 6.0245
	old_data_grads_norm = 5.2681
	sim_grads_norm = 0.0306
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3180
	data_grads_norm = 3.8769
	new_data_grads_norm = 5.9427
	old_data_grads_norm = 4.3367
	sim_grads_norm = 0.0210
-- Starting training on experience 176 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2561
	data_grads_norm = 4.0278
	new_data_grads_norm = 5.9454
	old_data_grads_norm = 5.2423
	sim_grads_norm = -0.0434
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1335
	data_grads_norm = 3.7712
	new_data_grads_norm = 5.9286
	old_data_grads_norm = 3.6598
	sim_grads_norm = 0.0067
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3976
	data_grads_norm = 3.9830
	new_data_grads_norm = 6.0115
	old_data_grads_norm = 4.7691
	sim_grads_norm = 0.0398
-- Starting training on experience 177 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8535
	data_grads_norm = 4.4394
	new_data_grads_norm = 6.3134
	old_data_grads_norm = 5.9539
	sim_grads_norm = 0.0698
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8364
	data_grads_norm = 3.1894
	new_data_grads_norm = 5.1213
	old_data_grads_norm = 3.5017
	sim_grads_norm = 0.0139
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8892
	data_grads_norm = 4.6114
	new_data_grads_norm = 5.9219
	old_data_grads_norm = 6.8656
	sim_grads_norm = 0.0775
-- Starting training on experience 178 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9519
	data_grads_norm = 3.9586
	new_data_grads_norm = 5.7543
	old_data_grads_norm = 4.4488
	sim_grads_norm = -0.0109
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2917
	data_grads_norm = 3.8081
	new_data_grads_norm = 6.3853
	old_data_grads_norm = 5.0421
	sim_grads_norm = -0.0152
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3059
	data_grads_norm = 3.7210
	new_data_grads_norm = 5.8227
	old_data_grads_norm = 4.6462
	sim_grads_norm = -0.0526
-- Starting training on experience 179 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1650
	data_grads_norm = 4.6331
	new_data_grads_norm = 5.9820
	old_data_grads_norm = 6.9196
	sim_grads_norm = 0.0182
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9323
	data_grads_norm = 4.3488
	new_data_grads_norm = 5.9494
	old_data_grads_norm = 5.3881
	sim_grads_norm = 0.0706
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3546
	data_grads_norm = 4.1230
	new_data_grads_norm = 5.9159
	old_data_grads_norm = 5.2102
	sim_grads_norm = -0.0222
-- Starting training on experience 180 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9811
	data_grads_norm = 4.5440
	new_data_grads_norm = 5.6588
	old_data_grads_norm = 7.1454
	sim_grads_norm = 0.0027
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0241
	data_grads_norm = 3.9974
	new_data_grads_norm = 5.1863
	old_data_grads_norm = 5.7362
	sim_grads_norm = -0.0092
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2118
	data_grads_norm = 4.1282
	new_data_grads_norm = 5.4574
	old_data_grads_norm = 5.4821
	sim_grads_norm = 0.0363
-- Starting training on experience 181 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1931
	data_grads_norm = 3.6879
	new_data_grads_norm = 5.8916
	old_data_grads_norm = 4.1238
	sim_grads_norm = 0.0699
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6830
	data_grads_norm = 4.5011
	new_data_grads_norm = 6.0999
	old_data_grads_norm = 6.7896
	sim_grads_norm = -0.0440
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5317
	data_grads_norm = 4.1231
	new_data_grads_norm = 6.4369
	old_data_grads_norm = 4.3339
	sim_grads_norm = 0.0204
-- Starting training on experience 182 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0060
	data_grads_norm = 3.6586
	new_data_grads_norm = 4.7506
	old_data_grads_norm = 5.5333
	sim_grads_norm = 0.0085
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9005
	data_grads_norm = 3.8075
	new_data_grads_norm = 5.1983
	old_data_grads_norm = 4.1289
	sim_grads_norm = 0.0251
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5998
	data_grads_norm = 4.8510
	new_data_grads_norm = 5.7106
	old_data_grads_norm = 6.4547
	sim_grads_norm = -0.0058
-- Starting training on experience 183 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9140
	data_grads_norm = 4.5003
	new_data_grads_norm = 5.8426
	old_data_grads_norm = 6.4262
	sim_grads_norm = 0.0089
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4058
	data_grads_norm = 3.7311
	new_data_grads_norm = 5.6229
	old_data_grads_norm = 4.5850
	sim_grads_norm = -0.0673
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6728
	data_grads_norm = 4.4314
	new_data_grads_norm = 5.7250
	old_data_grads_norm = 6.0085
	sim_grads_norm = 0.0274
-- Starting training on experience 184 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8196
	data_grads_norm = 3.4662
	new_data_grads_norm = 5.0306
	old_data_grads_norm = 4.3730
	sim_grads_norm = -0.0368
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2832
	data_grads_norm = 4.1201
	new_data_grads_norm = 6.1863
	old_data_grads_norm = 5.8938
	sim_grads_norm = -0.0135
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0516
	data_grads_norm = 3.8222
	new_data_grads_norm = 6.3804
	old_data_grads_norm = 4.7793
	sim_grads_norm = 0.0465
-- Starting training on experience 185 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6440
	data_grads_norm = 4.0450
	new_data_grads_norm = 5.3904
	old_data_grads_norm = 5.9788
	sim_grads_norm = 0.0392
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5087
	data_grads_norm = 3.8594
	new_data_grads_norm = 5.4746
	old_data_grads_norm = 5.4443
	sim_grads_norm = -0.0166
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7371
	data_grads_norm = 4.4312
	new_data_grads_norm = 6.1675
	old_data_grads_norm = 5.8106
	sim_grads_norm = 0.0383
-- Starting training on experience 186 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2249
	data_grads_norm = 3.4735
	new_data_grads_norm = 4.8886
	old_data_grads_norm = 4.2245
	sim_grads_norm = -0.0128
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2069
	data_grads_norm = 3.5223
	new_data_grads_norm = 5.1082
	old_data_grads_norm = 3.8608
	sim_grads_norm = -0.0101
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3462
	data_grads_norm = 3.9240
	new_data_grads_norm = 5.7116
	old_data_grads_norm = 4.3263
	sim_grads_norm = -0.0048
-- Starting training on experience 187 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2611
	data_grads_norm = 3.4991
	new_data_grads_norm = 4.9824
	old_data_grads_norm = 4.7043
	sim_grads_norm = -0.0178
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2225
	data_grads_norm = 3.9211
	new_data_grads_norm = 5.3568
	old_data_grads_norm = 5.8690
	sim_grads_norm = 0.0021
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5330
	data_grads_norm = 3.8529
	new_data_grads_norm = 4.6841
	old_data_grads_norm = 5.2761
	sim_grads_norm = -0.0116
-- Starting training on experience 188 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4900
	data_grads_norm = 4.5357
	new_data_grads_norm = 7.0541
	old_data_grads_norm = 5.4042
	sim_grads_norm = 0.0568
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2125
	data_grads_norm = 3.9600
	new_data_grads_norm = 5.8253
	old_data_grads_norm = 5.0427
	sim_grads_norm = 0.0423
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3066
	data_grads_norm = 4.0560
	new_data_grads_norm = 5.6517
	old_data_grads_norm = 4.0926
	sim_grads_norm = -0.0205
-- Starting training on experience 189 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0217
	data_grads_norm = 3.4338
	new_data_grads_norm = 5.3435
	old_data_grads_norm = 4.5936
	sim_grads_norm = -0.0003
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0857
	data_grads_norm = 3.7052
	new_data_grads_norm = 5.1814
	old_data_grads_norm = 5.0458
	sim_grads_norm = -0.0585
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8454
	data_grads_norm = 4.0655
	new_data_grads_norm = 6.1902
	old_data_grads_norm = 4.6407
	sim_grads_norm = 0.0528
-- Starting training on experience 190 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3056
	data_grads_norm = 4.3123
	new_data_grads_norm = 5.7600
	old_data_grads_norm = 6.0660
	sim_grads_norm = 0.0014
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1917
	data_grads_norm = 3.7212
	new_data_grads_norm = 6.1398
	old_data_grads_norm = 4.4522
	sim_grads_norm = 0.0245
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0969
	data_grads_norm = 4.1830
	new_data_grads_norm = 6.2874
	old_data_grads_norm = 4.8583
	sim_grads_norm = 0.0137
-- Starting training on experience 191 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4492
	data_grads_norm = 4.6242
	new_data_grads_norm = 7.2436
	old_data_grads_norm = 5.4268
	sim_grads_norm = -0.0049
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3582
	data_grads_norm = 4.2130
	new_data_grads_norm = 6.8313
	old_data_grads_norm = 3.8038
	sim_grads_norm = 0.0284
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1813
	data_grads_norm = 4.1194
	new_data_grads_norm = 6.7052
	old_data_grads_norm = 3.6603
	sim_grads_norm = 0.0471
-- Starting training on experience 192 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6220
	data_grads_norm = 2.8711
	new_data_grads_norm = 5.3481
	old_data_grads_norm = 2.3227
	sim_grads_norm = 0.0025
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4021
	data_grads_norm = 4.5785
	new_data_grads_norm = 5.7764
	old_data_grads_norm = 6.0741
	sim_grads_norm = 0.0277
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3277
	data_grads_norm = 4.8967
	new_data_grads_norm = 5.1858
	old_data_grads_norm = 6.8288
	sim_grads_norm = -0.0065
-- Starting training on experience 193 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2694
	data_grads_norm = 3.9743
	new_data_grads_norm = 6.6379
	old_data_grads_norm = 5.2978
	sim_grads_norm = -0.0197
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4942
	data_grads_norm = 4.5669
	new_data_grads_norm = 6.3436
	old_data_grads_norm = 5.0929
	sim_grads_norm = -0.0203
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4498
	data_grads_norm = 3.7916
	new_data_grads_norm = 6.3217
	old_data_grads_norm = 3.9491
	sim_grads_norm = 0.0183
-- Starting training on experience 194 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6330
	data_grads_norm = 4.2418
	new_data_grads_norm = 6.0550
	old_data_grads_norm = 5.0947
	sim_grads_norm = -0.0366
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5836
	data_grads_norm = 4.3714
	new_data_grads_norm = 6.2043
	old_data_grads_norm = 5.5391
	sim_grads_norm = -0.0182
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5851
	data_grads_norm = 4.2399
	new_data_grads_norm = 5.7915
	old_data_grads_norm = 5.3234
	sim_grads_norm = -0.0503
-- Starting training on experience 195 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8167
	data_grads_norm = 4.7082
	new_data_grads_norm = 5.6423
	old_data_grads_norm = 6.6379
	sim_grads_norm = 0.0597
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4228
	data_grads_norm = 3.8578
	new_data_grads_norm = 5.2675
	old_data_grads_norm = 5.4431
	sim_grads_norm = 0.0150
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7395
	data_grads_norm = 4.6172
	new_data_grads_norm = 5.9327
	old_data_grads_norm = 6.3919
	sim_grads_norm = 0.0250
-- Starting training on experience 196 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6373
	data_grads_norm = 4.5239
	new_data_grads_norm = 6.4636
	old_data_grads_norm = 6.7868
	sim_grads_norm = -0.0274
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0906
	data_grads_norm = 3.8085
	new_data_grads_norm = 6.1350
	old_data_grads_norm = 4.2380
	sim_grads_norm = 0.1484
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1045
	data_grads_norm = 4.0991
	new_data_grads_norm = 5.8409
	old_data_grads_norm = 5.4560
	sim_grads_norm = 0.0041
-- Starting training on experience 197 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3290
	data_grads_norm = 4.4513
	new_data_grads_norm = 5.7925
	old_data_grads_norm = 5.8597
	sim_grads_norm = -0.0100
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9551
	data_grads_norm = 3.8992
	new_data_grads_norm = 5.3251
	old_data_grads_norm = 4.9944
	sim_grads_norm = 0.0223
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4396
	data_grads_norm = 4.4867
	new_data_grads_norm = 5.9301
	old_data_grads_norm = 6.2406
	sim_grads_norm = 0.0545
-- Starting training on experience 198 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3743
	data_grads_norm = 4.1315
	new_data_grads_norm = 6.8586
	old_data_grads_norm = 4.2975
	sim_grads_norm = 0.0240
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3577
	data_grads_norm = 3.9097
	new_data_grads_norm = 6.6556
	old_data_grads_norm = 4.2712
	sim_grads_norm = -0.0017
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2871
	data_grads_norm = 4.3726
	new_data_grads_norm = 6.5585
	old_data_grads_norm = 4.8421
	sim_grads_norm = -0.0055
-- Starting training on experience 199 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2584
	data_grads_norm = 5.1674
	new_data_grads_norm = 7.1622
	old_data_grads_norm = 5.6503
	sim_grads_norm = -0.0082
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7800
	data_grads_norm = 4.2483
	new_data_grads_norm = 7.2735
	old_data_grads_norm = 5.1087
	sim_grads_norm = 0.0512
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7629
	data_grads_norm = 4.3879
	new_data_grads_norm = 6.8098
	old_data_grads_norm = 5.1485
	sim_grads_norm = -0.0364
-- Starting training on experience 200 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9421
	data_grads_norm = 3.8754
	new_data_grads_norm = 5.9161
	old_data_grads_norm = 4.1448
	sim_grads_norm = -0.0039
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1958
	data_grads_norm = 4.3646
	new_data_grads_norm = 6.0389
	old_data_grads_norm = 6.2892
	sim_grads_norm = -0.0215
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1092
	data_grads_norm = 3.9376
	new_data_grads_norm = 5.7576
	old_data_grads_norm = 4.3982
	sim_grads_norm = 0.0414
-- Starting training on experience 201 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2485
	data_grads_norm = 4.0628
	new_data_grads_norm = 5.1915
	old_data_grads_norm = 5.9408
	sim_grads_norm = -0.0083
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0108
	data_grads_norm = 4.0818
	new_data_grads_norm = 4.7897
	old_data_grads_norm = 5.6869
	sim_grads_norm = 0.0484
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0696
	data_grads_norm = 4.0219
	new_data_grads_norm = 5.5073
	old_data_grads_norm = 5.5348
	sim_grads_norm = 0.0331
-- Starting training on experience 202 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3262
	data_grads_norm = 4.3729
	new_data_grads_norm = 6.8227
	old_data_grads_norm = 6.7929
	sim_grads_norm = -0.0485
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4340
	data_grads_norm = 4.4329
	new_data_grads_norm = 6.8605
	old_data_grads_norm = 4.9242
	sim_grads_norm = 0.0018
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1500
	data_grads_norm = 4.2515
	new_data_grads_norm = 6.3168
	old_data_grads_norm = 4.3700
	sim_grads_norm = -0.0103
-- Starting training on experience 203 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0786
	data_grads_norm = 4.3300
	new_data_grads_norm = 6.3244
	old_data_grads_norm = 5.7773
	sim_grads_norm = 0.0734
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4381
	data_grads_norm = 4.2943
	new_data_grads_norm = 6.6048
	old_data_grads_norm = 5.5145
	sim_grads_norm = -0.0282
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4195
	data_grads_norm = 4.8834
	new_data_grads_norm = 7.1403
	old_data_grads_norm = 5.5811
	sim_grads_norm = -0.0412
-- Starting training on experience 204 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7483
	data_grads_norm = 4.3725
	new_data_grads_norm = 6.0785
	old_data_grads_norm = 4.8306
	sim_grads_norm = 0.0510
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6313
	data_grads_norm = 4.4991
	new_data_grads_norm = 6.0833
	old_data_grads_norm = 6.0699
	sim_grads_norm = -0.0081
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8955
	data_grads_norm = 4.2315
	new_data_grads_norm = 6.6499
	old_data_grads_norm = 4.1659
	sim_grads_norm = 0.0282
-- Starting training on experience 205 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4124
	data_grads_norm = 4.7821
	new_data_grads_norm = 5.9456
	old_data_grads_norm = 6.0515
	sim_grads_norm = 0.0016
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9328
	data_grads_norm = 3.8839
	new_data_grads_norm = 5.9047
	old_data_grads_norm = 3.1139
	sim_grads_norm = -0.0403
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6633
	data_grads_norm = 4.4937
	new_data_grads_norm = 6.2092
	old_data_grads_norm = 5.1049
	sim_grads_norm = 0.0071
-- Starting training on experience 206 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2702
	data_grads_norm = 2.9352
	new_data_grads_norm = 4.3589
	old_data_grads_norm = 3.3056
	sim_grads_norm = -0.0279
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4881
	data_grads_norm = 3.1397
	new_data_grads_norm = 4.8654
	old_data_grads_norm = 5.0527
	sim_grads_norm = 0.0021
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5674
	data_grads_norm = 3.0278
	new_data_grads_norm = 5.2310
	old_data_grads_norm = 3.9539
	sim_grads_norm = -0.0073
-- Starting training on experience 207 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1304
	data_grads_norm = 3.7553
	new_data_grads_norm = 5.2098
	old_data_grads_norm = 5.0897
	sim_grads_norm = -0.0134
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2999
	data_grads_norm = 3.8168
	new_data_grads_norm = 5.4954
	old_data_grads_norm = 5.0505
	sim_grads_norm = 0.0413
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6240
	data_grads_norm = 2.9967
	new_data_grads_norm = 5.2744
	old_data_grads_norm = 2.3806
	sim_grads_norm = -0.0255
-- Starting training on experience 208 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0791
	data_grads_norm = 3.8432
	new_data_grads_norm = 5.5397
	old_data_grads_norm = 5.6105
	sim_grads_norm = 0.0298
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2625
	data_grads_norm = 3.3811
	new_data_grads_norm = 5.8521
	old_data_grads_norm = 3.1545
	sim_grads_norm = 0.1301
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9981
	data_grads_norm = 3.3446
	new_data_grads_norm = 5.3141
	old_data_grads_norm = 3.6720
	sim_grads_norm = 0.0487
-- Starting training on experience 209 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9734
	data_grads_norm = 3.7896
	new_data_grads_norm = 6.2926
	old_data_grads_norm = 5.5953
	sim_grads_norm = -0.0301
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0338
	data_grads_norm = 3.8355
	new_data_grads_norm = 5.8410
	old_data_grads_norm = 4.6858
	sim_grads_norm = -0.0094
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9102
	data_grads_norm = 3.5491
	new_data_grads_norm = 5.7070
	old_data_grads_norm = 3.9716
	sim_grads_norm = -0.0175
-- Starting training on experience 210 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2871
	data_grads_norm = 4.2888
	new_data_grads_norm = 5.8782
	old_data_grads_norm = 6.5758
	sim_grads_norm = -0.0000
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9743
	data_grads_norm = 3.6752
	new_data_grads_norm = 5.6080
	old_data_grads_norm = 5.1048
	sim_grads_norm = -0.0009
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8834
	data_grads_norm = 3.8696
	new_data_grads_norm = 5.1547
	old_data_grads_norm = 5.1041
	sim_grads_norm = 0.0164
-- Starting training on experience 211 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4629
	data_grads_norm = 4.2685
	new_data_grads_norm = 6.1107
	old_data_grads_norm = 4.8932
	sim_grads_norm = -0.0032
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0214
	data_grads_norm = 4.8639
	new_data_grads_norm = 6.9714
	old_data_grads_norm = 5.7131
	sim_grads_norm = 0.0684
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2835
	data_grads_norm = 4.6684
	new_data_grads_norm = 6.3222
	old_data_grads_norm = 5.5712
	sim_grads_norm = 0.0676
-- Starting training on experience 212 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5347
	data_grads_norm = 4.1089
	new_data_grads_norm = 4.8398
	old_data_grads_norm = 6.0992
	sim_grads_norm = -0.0333
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9467
	data_grads_norm = 3.6308
	new_data_grads_norm = 5.3494
	old_data_grads_norm = 3.9466
	sim_grads_norm = 0.0412
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4275
	data_grads_norm = 4.5298
	new_data_grads_norm = 5.7293
	old_data_grads_norm = 6.4265
	sim_grads_norm = 0.0037
-- Starting training on experience 213 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3684
	data_grads_norm = 4.0769
	new_data_grads_norm = 6.1476
	old_data_grads_norm = 4.4093
	sim_grads_norm = -0.0287
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6572
	data_grads_norm = 4.5730
	new_data_grads_norm = 6.8609
	old_data_grads_norm = 6.9694
	sim_grads_norm = -0.0438
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1354
	data_grads_norm = 3.8688
	new_data_grads_norm = 6.8094
	old_data_grads_norm = 3.5667
	sim_grads_norm = 0.0127
-- Starting training on experience 214 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0818
	data_grads_norm = 3.6329
	new_data_grads_norm = 6.3201
	old_data_grads_norm = 3.2109
	sim_grads_norm = 0.0229
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9810
	data_grads_norm = 3.7950
	new_data_grads_norm = 5.7849
	old_data_grads_norm = 4.8651
	sim_grads_norm = -0.0228
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5816
	data_grads_norm = 4.1950
	new_data_grads_norm = 6.0110
	old_data_grads_norm = 5.7916
	sim_grads_norm = -0.0247
-- Starting training on experience 215 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1366
	data_grads_norm = 4.3395
	new_data_grads_norm = 6.1724
	old_data_grads_norm = 5.0340
	sim_grads_norm = 0.0182
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6954
	data_grads_norm = 4.1629
	new_data_grads_norm = 6.0158
	old_data_grads_norm = 4.7365
	sim_grads_norm = 0.0962
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2977
	data_grads_norm = 4.0736
	new_data_grads_norm = 5.8871
	old_data_grads_norm = 6.7023
	sim_grads_norm = -0.0298
-- Starting training on experience 216 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7523
	data_grads_norm = 3.2589
	new_data_grads_norm = 5.0884
	old_data_grads_norm = 3.8682
	sim_grads_norm = -0.0106
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7274
	data_grads_norm = 3.2024
	new_data_grads_norm = 5.3243
	old_data_grads_norm = 3.4668
	sim_grads_norm = 0.0777
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4384
	data_grads_norm = 4.7509
	new_data_grads_norm = 5.1782
	old_data_grads_norm = 6.5866
	sim_grads_norm = 0.0430
-- Starting training on experience 217 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0059
	data_grads_norm = 3.5866
	new_data_grads_norm = 5.1820
	old_data_grads_norm = 4.3165
	sim_grads_norm = 0.0836
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1754
	data_grads_norm = 3.8889
	new_data_grads_norm = 4.8948
	old_data_grads_norm = 6.2921
	sim_grads_norm = 0.0070
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3014
	data_grads_norm = 3.9585
	new_data_grads_norm = 4.7586
	old_data_grads_norm = 5.2247
	sim_grads_norm = 0.0147
-- Starting training on experience 218 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8813
	data_grads_norm = 5.0639
	new_data_grads_norm = 7.7072
	old_data_grads_norm = 5.5954
	sim_grads_norm = 0.0269
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2293
	data_grads_norm = 4.5642
	new_data_grads_norm = 7.1165
	old_data_grads_norm = 5.2501
	sim_grads_norm = -0.0144
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9667
	data_grads_norm = 4.8189
	new_data_grads_norm = 7.3266
	old_data_grads_norm = 4.9241
	sim_grads_norm = 0.0090
-- Starting training on experience 219 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8175
	data_grads_norm = 3.2557
	new_data_grads_norm = 5.1904
	old_data_grads_norm = 4.6638
	sim_grads_norm = 0.0376
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5561
	data_grads_norm = 3.4100
	new_data_grads_norm = 4.9727
	old_data_grads_norm = 4.3391
	sim_grads_norm = -0.0610
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1436
	data_grads_norm = 4.0433
	new_data_grads_norm = 5.0085
	old_data_grads_norm = 6.5187
	sim_grads_norm = -0.0090
-- Starting training on experience 220 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8296
	data_grads_norm = 3.5027
	new_data_grads_norm = 5.8412
	old_data_grads_norm = 3.8844
	sim_grads_norm = -0.0382
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8102
	data_grads_norm = 4.1065
	new_data_grads_norm = 6.6839
	old_data_grads_norm = 5.1504
	sim_grads_norm = 0.0200
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5665
	data_grads_norm = 4.8251
	new_data_grads_norm = 6.8210
	old_data_grads_norm = 6.3074
	sim_grads_norm = -0.0257
-- Starting training on experience 221 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0232
	data_grads_norm = 3.5912
	new_data_grads_norm = 5.6618
	old_data_grads_norm = 4.5075
	sim_grads_norm = 0.0023
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1963
	data_grads_norm = 3.6963
	new_data_grads_norm = 6.4828
	old_data_grads_norm = 3.8703
	sim_grads_norm = -0.0490
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6607
	data_grads_norm = 4.2441
	new_data_grads_norm = 5.7861
	old_data_grads_norm = 4.5075
	sim_grads_norm = 0.0257
-- Starting training on experience 222 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2462
	data_grads_norm = 4.2307
	new_data_grads_norm = 6.7807
	old_data_grads_norm = 5.0509
	sim_grads_norm = 0.0131
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4747
	data_grads_norm = 4.3336
	new_data_grads_norm = 7.0054
	old_data_grads_norm = 5.7069
	sim_grads_norm = -0.0072
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1316
	data_grads_norm = 4.3475
	new_data_grads_norm = 6.5786
	old_data_grads_norm = 4.7639
	sim_grads_norm = 0.0259
-- Starting training on experience 223 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6084
	data_grads_norm = 4.1268
	new_data_grads_norm = 6.1758
	old_data_grads_norm = 4.2044
	sim_grads_norm = 0.0003
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7658
	data_grads_norm = 4.0585
	new_data_grads_norm = 6.5073
	old_data_grads_norm = 4.6052
	sim_grads_norm = -0.0128
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8379
	data_grads_norm = 4.0954
	new_data_grads_norm = 5.8222
	old_data_grads_norm = 4.9613
	sim_grads_norm = -0.0481
-- Starting training on experience 224 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4391
	data_grads_norm = 4.2687
	new_data_grads_norm = 6.9878
	old_data_grads_norm = 3.9240
	sim_grads_norm = 0.0262
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2219
	data_grads_norm = 4.0594
	new_data_grads_norm = 6.5349
	old_data_grads_norm = 5.1843
	sim_grads_norm = -0.0094
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2434
	data_grads_norm = 3.7950
	new_data_grads_norm = 6.4537
	old_data_grads_norm = 4.6958
	sim_grads_norm = -0.0221
-- Starting training on experience 225 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2075
	data_grads_norm = 3.9541
	new_data_grads_norm = 5.6522
	old_data_grads_norm = 3.9127
	sim_grads_norm = 0.0433
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2254
	data_grads_norm = 3.6142
	new_data_grads_norm = 6.1169
	old_data_grads_norm = 4.4677
	sim_grads_norm = -0.0121
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9893
	data_grads_norm = 4.0463
	new_data_grads_norm = 5.7159
	old_data_grads_norm = 5.6221
	sim_grads_norm = 0.0283
-- Starting training on experience 226 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7402
	data_grads_norm = 4.3191
	new_data_grads_norm = 5.9821
	old_data_grads_norm = 6.1128
	sim_grads_norm = -0.0118
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1163
	data_grads_norm = 3.6961
	new_data_grads_norm = 5.9045
	old_data_grads_norm = 5.3787
	sim_grads_norm = 0.0443
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7188
	data_grads_norm = 3.1750
	new_data_grads_norm = 5.2785
	old_data_grads_norm = 5.1294
	sim_grads_norm = 0.0039
-- Starting training on experience 227 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0279
	data_grads_norm = 3.9018
	new_data_grads_norm = 5.2888
	old_data_grads_norm = 5.4213
	sim_grads_norm = -0.0470
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9031
	data_grads_norm = 3.4943
	new_data_grads_norm = 4.9758
	old_data_grads_norm = 5.1871
	sim_grads_norm = -0.0213
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2463
	data_grads_norm = 4.1574
	new_data_grads_norm = 6.0639
	old_data_grads_norm = 5.5101
	sim_grads_norm = 0.0171
-- Starting training on experience 228 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5628
	data_grads_norm = 3.8221
	new_data_grads_norm = 5.7428
	old_data_grads_norm = 4.6360
	sim_grads_norm = -0.0178
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6787
	data_grads_norm = 4.4162
	new_data_grads_norm = 5.8314
	old_data_grads_norm = 5.6478
	sim_grads_norm = 0.0556
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4485
	data_grads_norm = 4.1534
	new_data_grads_norm = 6.1246
	old_data_grads_norm = 4.6410
	sim_grads_norm = 0.0019
-- Starting training on experience 229 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1640
	data_grads_norm = 3.7997
	new_data_grads_norm = 6.3474
	old_data_grads_norm = 5.2835
	sim_grads_norm = 0.0007
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2740
	data_grads_norm = 4.3627
	new_data_grads_norm = 7.3293
	old_data_grads_norm = 4.0329
	sim_grads_norm = 0.0053
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5493
	data_grads_norm = 4.7975
	new_data_grads_norm = 6.9670
	old_data_grads_norm = 5.8345
	sim_grads_norm = 0.1451
-- Starting training on experience 230 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7731
	data_grads_norm = 3.7633
	new_data_grads_norm = 6.2493
	old_data_grads_norm = 5.0771
	sim_grads_norm = -0.0152
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7184
	data_grads_norm = 4.4884
	new_data_grads_norm = 6.0310
	old_data_grads_norm = 5.7803
	sim_grads_norm = -0.0144
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0785
	data_grads_norm = 3.8138
	new_data_grads_norm = 6.7009
	old_data_grads_norm = 3.4191
	sim_grads_norm = 0.0763
-- Starting training on experience 231 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9710
	data_grads_norm = 4.3338
	new_data_grads_norm = 5.7255
	old_data_grads_norm = 5.6907
	sim_grads_norm = -0.0335
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5612
	data_grads_norm = 4.1974
	new_data_grads_norm = 5.9077
	old_data_grads_norm = 5.5196
	sim_grads_norm = 0.0122
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4343
	data_grads_norm = 4.5575
	new_data_grads_norm = 6.5828
	old_data_grads_norm = 5.1804
	sim_grads_norm = -0.0136
-- Starting training on experience 232 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7266
	data_grads_norm = 3.5666
	new_data_grads_norm = 6.4361
	old_data_grads_norm = 4.0867
	sim_grads_norm = -0.0260
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9785
	data_grads_norm = 4.1019
	new_data_grads_norm = 5.9968
	old_data_grads_norm = 5.5583
	sim_grads_norm = -0.0124
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5227
	data_grads_norm = 3.5400
	new_data_grads_norm = 6.4586
	old_data_grads_norm = 3.8824
	sim_grads_norm = 0.0348
-- Starting training on experience 233 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2056
	data_grads_norm = 4.1945
	new_data_grads_norm = 6.0001
	old_data_grads_norm = 5.4782
	sim_grads_norm = -0.0328
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6666
	data_grads_norm = 4.4000
	new_data_grads_norm = 6.0181
	old_data_grads_norm = 6.0671
	sim_grads_norm = 0.0513
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8776
	data_grads_norm = 3.8809
	new_data_grads_norm = 6.3229
	old_data_grads_norm = 4.3241
	sim_grads_norm = -0.0027
-- Starting training on experience 234 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2400
	data_grads_norm = 4.1365
	new_data_grads_norm = 6.2023
	old_data_grads_norm = 4.6316
	sim_grads_norm = 0.0596
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7638
	data_grads_norm = 3.8247
	new_data_grads_norm = 6.3033
	old_data_grads_norm = 4.9141
	sim_grads_norm = 0.0180
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1414
	data_grads_norm = 4.3638
	new_data_grads_norm = 6.7020
	old_data_grads_norm = 5.9037
	sim_grads_norm = -0.0591
-- Starting training on experience 235 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8878
	data_grads_norm = 4.3413
	new_data_grads_norm = 6.6743
	old_data_grads_norm = 5.5607
	sim_grads_norm = 0.0095
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5334
	data_grads_norm = 4.5401
	new_data_grads_norm = 6.3489
	old_data_grads_norm = 5.4155
	sim_grads_norm = -0.0255
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2145
	data_grads_norm = 4.2149
	new_data_grads_norm = 6.1979
	old_data_grads_norm = 5.6297
	sim_grads_norm = -0.0143
-- Starting training on experience 236 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2505
	data_grads_norm = 3.9193
	new_data_grads_norm = 6.2126
	old_data_grads_norm = 3.9298
	sim_grads_norm = 0.0087
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0868
	data_grads_norm = 4.0685
	new_data_grads_norm = 6.3854
	old_data_grads_norm = 5.1283
	sim_grads_norm = 0.0091
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4620
	data_grads_norm = 5.6416
	new_data_grads_norm = 6.3345
	old_data_grads_norm = 7.7904
	sim_grads_norm = 0.0286
-- Starting training on experience 237 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
-- >> End of training phase << --
-- >> Start of eval phase << --
-- Starting eval on experience 0 (Task 0) from test stream --
> Eval on experience 0 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp000 = 3.7043
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.2780
	mb_index = 3332
	time = 906.4767
-- Starting eval on experience 1 (Task 0) from test stream --
> Eval on experience 1 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp001 = 3.2825
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.3420
-- Starting eval on experience 2 (Task 0) from test stream --
> Eval on experience 2 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp002 = 3.8868
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.2540
-- Starting eval on experience 3 (Task 0) from test stream --
> Eval on experience 3 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp003 = 2.5148
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.4980
-- Starting eval on experience 4 (Task 0) from test stream --
> Eval on experience 4 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp004 = 4.2374
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.2240
-- Starting eval on experience 5 (Task 0) from test stream --
> Eval on experience 5 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp005 = 3.2479
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.3500
-- Starting eval on experience 6 (Task 0) from test stream --
> Eval on experience 6 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp006 = 2.9929
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp006 = 0.3340
-- Starting eval on experience 7 (Task 0) from test stream --
> Eval on experience 7 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp007 = 3.2134
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp007 = 0.4060
-- Starting eval on experience 8 (Task 0) from test stream --
> Eval on experience 8 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp008 = 3.5486
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp008 = 0.3060
-- Starting eval on experience 9 (Task 0) from test stream --
> Eval on experience 9 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp009 = 3.2419
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp009 = 0.3600
-- Starting eval on experience 10 (Task 0) from test stream --
> Eval on experience 10 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp010 = 3.1734
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp010 = 0.2520
-- Starting eval on experience 11 (Task 0) from test stream --
> Eval on experience 11 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp011 = 2.7672
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp011 = 0.3320
-- Starting eval on experience 12 (Task 0) from test stream --
> Eval on experience 12 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp012 = 4.0813
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp012 = 0.1200
-- Starting eval on experience 13 (Task 0) from test stream --
> Eval on experience 13 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp013 = 3.9891
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp013 = 0.1240
-- >> End of eval phase << --
	CumulativeAccuracy/eval_phase/test_stream/Exp000 = 0.6980
	CumulativeAccuracy/eval_phase/test_stream/Exp001 = 0.6540
	CumulativeAccuracy/eval_phase/test_stream/Exp002 = 0.5627
	CumulativeAccuracy/eval_phase/test_stream/Exp003 = 0.5375
	CumulativeAccuracy/eval_phase/test_stream/Exp004 = 0.4920
	CumulativeAccuracy/eval_phase/test_stream/Exp005 = 0.4617
	CumulativeAccuracy/eval_phase/test_stream/Exp006 = 0.4169
	CumulativeAccuracy/eval_phase/test_stream/Exp007 = 0.3837
	CumulativeAccuracy/eval_phase/test_stream/Exp008 = 0.3664
	CumulativeAccuracy/eval_phase/test_stream/Exp009 = 0.3614
	CumulativeAccuracy/eval_phase/test_stream/Exp010 = 0.3362
	CumulativeAccuracy/eval_phase/test_stream/Exp011 = 0.3325
	CumulativeAccuracy/eval_phase/test_stream/Exp012 = 0.3126
	CumulativeAccuracy/eval_phase/test_stream/Exp013 = 0.2986
	Loss_Stream/eval_phase/test_stream/Task000 = 3.4201
	Top1_Acc_Stream/eval_phase/test_stream/Task000 = 0.2986
-- >> Start of training phase << --
-- Starting training on experience 0 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5411
	data_grads_norm = 5.1970
	new_data_grads_norm = 7.1062
	old_data_grads_norm = 5.1332
	sim_grads_norm = -0.0064
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.8581
	data_grads_norm = 4.8577
	new_data_grads_norm = 6.8813
	old_data_grads_norm = 5.0737
	sim_grads_norm = -0.0113
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1975
	data_grads_norm = 4.6363
	new_data_grads_norm = 6.4521
	old_data_grads_norm = 5.3259
	sim_grads_norm = 0.0206
-- Starting training on experience 1 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0907
	data_grads_norm = 4.4420
	new_data_grads_norm = 6.4473
	old_data_grads_norm = 5.9504
	sim_grads_norm = -0.0230
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2265
	data_grads_norm = 4.6036
	new_data_grads_norm = 6.6744
	old_data_grads_norm = 4.7731
	sim_grads_norm = -0.0048
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.7287
	data_grads_norm = 4.7093
	new_data_grads_norm = 6.1538
	old_data_grads_norm = 6.0331
	sim_grads_norm = -0.0115
-- Starting training on experience 2 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2983
	data_grads_norm = 4.2127
	new_data_grads_norm = 6.6184
	old_data_grads_norm = 5.4497
	sim_grads_norm = -0.0189
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.8261
	data_grads_norm = 4.9868
	new_data_grads_norm = 6.6881
	old_data_grads_norm = 7.0271
	sim_grads_norm = 0.0190
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5629
	data_grads_norm = 4.5709
	new_data_grads_norm = 6.5967
	old_data_grads_norm = 6.0790
	sim_grads_norm = 0.0111
-- Starting training on experience 3 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.2777
	data_grads_norm = 5.3907
	new_data_grads_norm = 6.8473
	old_data_grads_norm = 6.9249
	sim_grads_norm = -0.0211
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.7414
	data_grads_norm = 4.6652
	new_data_grads_norm = 6.6240
	old_data_grads_norm = 5.7046
	sim_grads_norm = 0.1072
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5421
	data_grads_norm = 4.3023
	new_data_grads_norm = 6.3359
	old_data_grads_norm = 5.1976
	sim_grads_norm = -0.0106
-- Starting training on experience 4 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4328
	data_grads_norm = 4.2640
	new_data_grads_norm = 6.8064
	old_data_grads_norm = 4.5218
	sim_grads_norm = 0.0498
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.7161
	data_grads_norm = 4.6136
	new_data_grads_norm = 6.4279
	old_data_grads_norm = 5.5136
	sim_grads_norm = 0.0918
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8577
	data_grads_norm = 3.6454
	new_data_grads_norm = 5.8969
	old_data_grads_norm = 5.0749
	sim_grads_norm = 0.0177
-- Starting training on experience 5 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.8761
	data_grads_norm = 4.5161
	new_data_grads_norm = 6.2258
	old_data_grads_norm = 6.2182
	sim_grads_norm = 0.1130
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9917
	data_grads_norm = 3.9232
	new_data_grads_norm = 5.7555
	old_data_grads_norm = 4.8434
	sim_grads_norm = 0.0434
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1647
	data_grads_norm = 4.4229
	new_data_grads_norm = 6.5057
	old_data_grads_norm = 5.9612
	sim_grads_norm = -0.0034
-- Starting training on experience 6 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5625
	data_grads_norm = 3.9949
	new_data_grads_norm = 5.8050
	old_data_grads_norm = 5.8240
	sim_grads_norm = -0.0152
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3852
	data_grads_norm = 4.6314
	new_data_grads_norm = 6.7884
	old_data_grads_norm = 6.9965
	sim_grads_norm = 0.0126
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0633
	data_grads_norm = 3.4859
	new_data_grads_norm = 5.7743
	old_data_grads_norm = 3.8636
	sim_grads_norm = 0.0356
-- Starting training on experience 7 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0656
	data_grads_norm = 4.5681
	new_data_grads_norm = 5.8976
	old_data_grads_norm = 6.2317
	sim_grads_norm = 0.0170
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5073
	data_grads_norm = 4.3700
	new_data_grads_norm = 7.0651
	old_data_grads_norm = 4.6671
	sim_grads_norm = 0.0560
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4463
	data_grads_norm = 4.3212
	new_data_grads_norm = 6.5293
	old_data_grads_norm = 4.8880
	sim_grads_norm = 0.0052
-- Starting training on experience 8 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9269
	data_grads_norm = 4.7467
	new_data_grads_norm = 5.2618
	old_data_grads_norm = 6.7737
	sim_grads_norm = -0.0010
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1601
	data_grads_norm = 3.6025
	new_data_grads_norm = 4.9908
	old_data_grads_norm = 4.4556
	sim_grads_norm = 0.0206
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3778
	data_grads_norm = 4.3030
	new_data_grads_norm = 5.6309
	old_data_grads_norm = 5.8249
	sim_grads_norm = 0.1878
-- Starting training on experience 9 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.0994
	data_grads_norm = 5.5198
	new_data_grads_norm = 8.6102
	old_data_grads_norm = 6.1221
	sim_grads_norm = 0.0212
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.8664
	data_grads_norm = 4.7963
	new_data_grads_norm = 7.0832
	old_data_grads_norm = 5.0835
	sim_grads_norm = 0.0214
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3654
	data_grads_norm = 4.8041
	new_data_grads_norm = 7.8096
	old_data_grads_norm = 7.2410
	sim_grads_norm = 0.0181
-- Starting training on experience 10 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0124
	data_grads_norm = 4.2445
	new_data_grads_norm = 7.1303
	old_data_grads_norm = 5.7647
	sim_grads_norm = -0.0014
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6639
	data_grads_norm = 3.8128
	new_data_grads_norm = 5.8487
	old_data_grads_norm = 5.1387
	sim_grads_norm = 0.0302
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9419
	data_grads_norm = 4.2296
	new_data_grads_norm = 6.1004
	old_data_grads_norm = 5.7350
	sim_grads_norm = -0.0002
-- Starting training on experience 11 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.0386
	data_grads_norm = 4.4256
	new_data_grads_norm = 6.8487
	old_data_grads_norm = 4.7128
	sim_grads_norm = 0.0880
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3846
	data_grads_norm = 4.6439
	new_data_grads_norm = 6.9900
	old_data_grads_norm = 4.8149
	sim_grads_norm = 0.0142
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2651
	data_grads_norm = 4.0227
	new_data_grads_norm = 6.6760
	old_data_grads_norm = 4.2389
	sim_grads_norm = 0.0099
-- Starting training on experience 12 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.9707
	data_grads_norm = 5.1209
	new_data_grads_norm = 7.6945
	old_data_grads_norm = 5.9173
	sim_grads_norm = 0.0227
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.0150
	data_grads_norm = 5.0330
	new_data_grads_norm = 7.0665
	old_data_grads_norm = 5.2418
	sim_grads_norm = 0.0661
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2391
	data_grads_norm = 4.5150
	new_data_grads_norm = 6.8794
	old_data_grads_norm = 4.5049
	sim_grads_norm = 0.0105
-- Starting training on experience 13 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.0268
	data_grads_norm = 4.3472
	new_data_grads_norm = 6.3497
	old_data_grads_norm = 5.9614
	sim_grads_norm = 0.0139
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5265
	data_grads_norm = 4.3175
	new_data_grads_norm = 6.0905
	old_data_grads_norm = 5.5130
	sim_grads_norm = -0.0223
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6719
	data_grads_norm = 4.2487
	new_data_grads_norm = 5.8931
	old_data_grads_norm = 5.4183
	sim_grads_norm = 0.0104
-- Starting training on experience 14 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4198
	data_grads_norm = 4.0291
	new_data_grads_norm = 6.3090
	old_data_grads_norm = 4.1405
	sim_grads_norm = 0.1172
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7925
	data_grads_norm = 4.6384
	new_data_grads_norm = 6.2495
	old_data_grads_norm = 6.8961
	sim_grads_norm = 0.0432
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7903
	data_grads_norm = 4.5429
	new_data_grads_norm = 6.7878
	old_data_grads_norm = 4.9186
	sim_grads_norm = 0.0396
-- Starting training on experience 15 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7827
	data_grads_norm = 3.9434
	new_data_grads_norm = 5.5777
	old_data_grads_norm = 4.9032
	sim_grads_norm = 0.0063
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6823
	data_grads_norm = 4.1411
	new_data_grads_norm = 5.3498
	old_data_grads_norm = 5.2919
	sim_grads_norm = 0.0152
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0724
	data_grads_norm = 4.6429
	new_data_grads_norm = 5.8755
	old_data_grads_norm = 6.4194
	sim_grads_norm = -0.0266
-- Starting training on experience 16 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8646
	data_grads_norm = 3.8684
	new_data_grads_norm = 5.1146
	old_data_grads_norm = 4.7054
	sim_grads_norm = 0.0693
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8766
	data_grads_norm = 4.4484
	new_data_grads_norm = 5.6586
	old_data_grads_norm = 5.2184
	sim_grads_norm = -0.0412
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8032
	data_grads_norm = 4.4956
	new_data_grads_norm = 5.6052
	old_data_grads_norm = 6.8792
	sim_grads_norm = -0.0116
-- Starting training on experience 17 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4813
	data_grads_norm = 3.9437
	new_data_grads_norm = 5.4693
	old_data_grads_norm = 4.4709
	sim_grads_norm = 0.0346
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0273
	data_grads_norm = 3.6557
	new_data_grads_norm = 5.4533
	old_data_grads_norm = 4.9065
	sim_grads_norm = -0.0291
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3403
	data_grads_norm = 3.8934
	new_data_grads_norm = 5.8396
	old_data_grads_norm = 4.4301
	sim_grads_norm = 0.0689
-- Starting training on experience 18 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5368
	data_grads_norm = 3.7017
	new_data_grads_norm = 5.2921
	old_data_grads_norm = 5.2684
	sim_grads_norm = -0.0342
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6663
	data_grads_norm = 4.0954
	new_data_grads_norm = 5.0776
	old_data_grads_norm = 5.5806
	sim_grads_norm = -0.0317
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4914
	data_grads_norm = 4.7137
	new_data_grads_norm = 5.6938
	old_data_grads_norm = 5.7805
	sim_grads_norm = 0.0587
-- Starting training on experience 19 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1788
	data_grads_norm = 3.5328
	new_data_grads_norm = 5.6939
	old_data_grads_norm = 3.8551
	sim_grads_norm = -0.0193
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3718
	data_grads_norm = 3.8106
	new_data_grads_norm = 5.7208
	old_data_grads_norm = 4.7971
	sim_grads_norm = -0.0090
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6217
	data_grads_norm = 4.3131
	new_data_grads_norm = 5.7651
	old_data_grads_norm = 6.0053
	sim_grads_norm = 0.0075
-- Starting training on experience 20 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1714
	data_grads_norm = 4.7793
	new_data_grads_norm = 6.2023
	old_data_grads_norm = 5.7932
	sim_grads_norm = 0.0372
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5289
	data_grads_norm = 4.3357
	new_data_grads_norm = 6.3128
	old_data_grads_norm = 5.4020
	sim_grads_norm = -0.0050
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7289
	data_grads_norm = 4.2873
	new_data_grads_norm = 5.5054
	old_data_grads_norm = 5.8563
	sim_grads_norm = 0.0230
-- Starting training on experience 21 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9855
	data_grads_norm = 3.9862
	new_data_grads_norm = 6.2783
	old_data_grads_norm = 4.9586
	sim_grads_norm = 0.0099
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4305
	data_grads_norm = 4.4513
	new_data_grads_norm = 6.4289
	old_data_grads_norm = 6.4995
	sim_grads_norm = 0.0210
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9672
	data_grads_norm = 3.6944
	new_data_grads_norm = 5.9750
	old_data_grads_norm = 3.9548
	sim_grads_norm = -0.0075
-- Starting training on experience 22 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4450
	data_grads_norm = 3.2935
	new_data_grads_norm = 5.3798
	old_data_grads_norm = 3.7048
	sim_grads_norm = 0.0117
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9804
	data_grads_norm = 3.7661
	new_data_grads_norm = 5.9312
	old_data_grads_norm = 5.1963
	sim_grads_norm = 0.0421
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3125
	data_grads_norm = 3.2071
	new_data_grads_norm = 5.5610
	old_data_grads_norm = 4.2198
	sim_grads_norm = -0.0370
-- Starting training on experience 23 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8333
	data_grads_norm = 4.2116
	new_data_grads_norm = 6.4055
	old_data_grads_norm = 5.0474
	sim_grads_norm = -0.0350
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1145
	data_grads_norm = 4.6284
	new_data_grads_norm = 6.6863
	old_data_grads_norm = 5.7191
	sim_grads_norm = 0.0011
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7191
	data_grads_norm = 4.3941
	new_data_grads_norm = 6.6925
	old_data_grads_norm = 5.6871
	sim_grads_norm = 0.0259
-- Starting training on experience 24 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1348
	data_grads_norm = 3.2313
	new_data_grads_norm = 5.2109
	old_data_grads_norm = 3.4835
	sim_grads_norm = -0.0321
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5034
	data_grads_norm = 4.2833
	new_data_grads_norm = 5.5636
	old_data_grads_norm = 6.6867
	sim_grads_norm = -0.0205
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2450
	data_grads_norm = 4.0618
	new_data_grads_norm = 5.6586
	old_data_grads_norm = 5.0378
	sim_grads_norm = 0.0046
-- Starting training on experience 25 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0033
	data_grads_norm = 3.7283
	new_data_grads_norm = 5.8863
	old_data_grads_norm = 4.0301
	sim_grads_norm = 0.0278
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7198
	data_grads_norm = 3.8530
	new_data_grads_norm = 6.0647
	old_data_grads_norm = 4.2436
	sim_grads_norm = -0.0053
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0914
	data_grads_norm = 4.6076
	new_data_grads_norm = 6.8649
	old_data_grads_norm = 5.2865
	sim_grads_norm = 0.0040
-- Starting training on experience 26 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3487
	data_grads_norm = 4.2363
	new_data_grads_norm = 5.8773
	old_data_grads_norm = 6.0566
	sim_grads_norm = 0.0096
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5772
	data_grads_norm = 4.6913
	new_data_grads_norm = 5.5140
	old_data_grads_norm = 7.0015
	sim_grads_norm = 0.0947
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1049
	data_grads_norm = 3.8694
	new_data_grads_norm = 5.6449
	old_data_grads_norm = 4.3062
	sim_grads_norm = -0.0538
-- Starting training on experience 27 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2940
	data_grads_norm = 4.3517
	new_data_grads_norm = 6.0316
	old_data_grads_norm = 5.8583
	sim_grads_norm = -0.0359
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6163
	data_grads_norm = 4.5648
	new_data_grads_norm = 6.3861
	old_data_grads_norm = 6.5556
	sim_grads_norm = -0.0235
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3985
	data_grads_norm = 3.9166
	new_data_grads_norm = 6.3290
	old_data_grads_norm = 5.2932
	sim_grads_norm = 0.0547
-- Starting training on experience 28 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6905
	data_grads_norm = 4.3404
	new_data_grads_norm = 5.8727
	old_data_grads_norm = 5.3169
	sim_grads_norm = 0.0065
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0713
	data_grads_norm = 4.4774
	new_data_grads_norm = 6.6115
	old_data_grads_norm = 4.6073
	sim_grads_norm = 0.0714
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3459
	data_grads_norm = 4.0963
	new_data_grads_norm = 6.3234
	old_data_grads_norm = 5.2770
	sim_grads_norm = -0.0200
-- Starting training on experience 29 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9348
	data_grads_norm = 3.9606
	new_data_grads_norm = 6.0421
	old_data_grads_norm = 5.4224
	sim_grads_norm = -0.0251
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3122
	data_grads_norm = 4.5593
	new_data_grads_norm = 6.0982
	old_data_grads_norm = 5.1168
	sim_grads_norm = 0.0369
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9007
	data_grads_norm = 4.1363
	new_data_grads_norm = 6.5514
	old_data_grads_norm = 4.3146
	sim_grads_norm = -0.0205
-- Starting training on experience 30 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5982
	data_grads_norm = 4.3351
	new_data_grads_norm = 6.2296
	old_data_grads_norm = 5.2200
	sim_grads_norm = 0.0156
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4385
	data_grads_norm = 4.1868
	new_data_grads_norm = 6.0135
	old_data_grads_norm = 4.6715
	sim_grads_norm = 0.0752
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4985
	data_grads_norm = 3.9573
	new_data_grads_norm = 5.5213
	old_data_grads_norm = 5.1325
	sim_grads_norm = -0.0121
-- Starting training on experience 31 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6688
	data_grads_norm = 5.7987
	new_data_grads_norm = 6.4642
	old_data_grads_norm = 8.3822
	sim_grads_norm = -0.0226
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0426
	data_grads_norm = 4.0633
	new_data_grads_norm = 6.3663
	old_data_grads_norm = 4.7586
	sim_grads_norm = -0.0109
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5749
	data_grads_norm = 4.5505
	new_data_grads_norm = 6.9495
	old_data_grads_norm = 5.5637
	sim_grads_norm = -0.0102
-- Starting training on experience 32 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3679
	data_grads_norm = 4.1382
	new_data_grads_norm = 5.2641
	old_data_grads_norm = 6.1054
	sim_grads_norm = 0.0600
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1645
	data_grads_norm = 4.2259
	new_data_grads_norm = 5.1616
	old_data_grads_norm = 6.5228
	sim_grads_norm = 0.0003
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2273
	data_grads_norm = 3.9178
	new_data_grads_norm = 5.1766
	old_data_grads_norm = 5.2296
	sim_grads_norm = -0.0129
-- Starting training on experience 33 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3487
	data_grads_norm = 4.1074
	new_data_grads_norm = 5.3181
	old_data_grads_norm = 5.0767
	sim_grads_norm = 0.0570
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7260
	data_grads_norm = 4.0168
	new_data_grads_norm = 5.2871
	old_data_grads_norm = 5.1252
	sim_grads_norm = 0.0175
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0018
	data_grads_norm = 3.6239
	new_data_grads_norm = 4.9301
	old_data_grads_norm = 5.6596
	sim_grads_norm = -0.0132
-- Starting training on experience 34 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9812
	data_grads_norm = 3.6898
	new_data_grads_norm = 6.1712
	old_data_grads_norm = 4.3576
	sim_grads_norm = -0.0418
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4294
	data_grads_norm = 4.1311
	new_data_grads_norm = 6.7273
	old_data_grads_norm = 4.7654
	sim_grads_norm = -0.0079
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2134
	data_grads_norm = 4.2689
	new_data_grads_norm = 6.5571
	old_data_grads_norm = 4.7967
	sim_grads_norm = 0.0213
-- Starting training on experience 35 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1962
	data_grads_norm = 4.5403
	new_data_grads_norm = 6.1454
	old_data_grads_norm = 5.2929
	sim_grads_norm = 0.0056
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7871
	data_grads_norm = 3.9294
	new_data_grads_norm = 6.1064
	old_data_grads_norm = 4.2098
	sim_grads_norm = 0.0508
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1822
	data_grads_norm = 4.5853
	new_data_grads_norm = 6.4600
	old_data_grads_norm = 6.5831
	sim_grads_norm = -0.0260
-- Starting training on experience 36 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1467
	data_grads_norm = 4.4741
	new_data_grads_norm = 5.5647
	old_data_grads_norm = 6.9465
	sim_grads_norm = -0.0263
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9003
	data_grads_norm = 3.7831
	new_data_grads_norm = 5.8074
	old_data_grads_norm = 4.6002
	sim_grads_norm = -0.0079
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6433
	data_grads_norm = 3.4720
	new_data_grads_norm = 5.8067
	old_data_grads_norm = 5.2916
	sim_grads_norm = -0.0101
-- Starting training on experience 37 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2475
	data_grads_norm = 4.3909
	new_data_grads_norm = 6.7026
	old_data_grads_norm = 5.1379
	sim_grads_norm = 0.0404
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1217
	data_grads_norm = 4.1669
	new_data_grads_norm = 6.9278
	old_data_grads_norm = 4.8825
	sim_grads_norm = -0.0397
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9245
	data_grads_norm = 3.6824
	new_data_grads_norm = 6.6805
	old_data_grads_norm = 4.5775
	sim_grads_norm = 0.0426
-- Starting training on experience 38 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7437
	data_grads_norm = 4.0634
	new_data_grads_norm = 5.8866
	old_data_grads_norm = 5.1109
	sim_grads_norm = 0.0233
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0783
	data_grads_norm = 4.6323
	new_data_grads_norm = 6.2315
	old_data_grads_norm = 5.3975
	sim_grads_norm = 0.0751
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8872
	data_grads_norm = 4.4973
	new_data_grads_norm = 5.6113
	old_data_grads_norm = 6.2530
	sim_grads_norm = 0.0160
-- Starting training on experience 39 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0557
	data_grads_norm = 4.8803
	new_data_grads_norm = 6.1995
	old_data_grads_norm = 6.7058
	sim_grads_norm = 0.0218
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8122
	data_grads_norm = 4.3216
	new_data_grads_norm = 5.9245
	old_data_grads_norm = 5.4982
	sim_grads_norm = -0.0050
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1042
	data_grads_norm = 4.6011
	new_data_grads_norm = 6.1596
	old_data_grads_norm = 5.6566
	sim_grads_norm = 0.0129
-- Starting training on experience 40 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8243
	data_grads_norm = 3.8729
	new_data_grads_norm = 5.8199
	old_data_grads_norm = 5.6278
	sim_grads_norm = -0.0600
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5475
	data_grads_norm = 4.5821
	new_data_grads_norm = 6.3664
	old_data_grads_norm = 4.9509
	sim_grads_norm = -0.0358
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6870
	data_grads_norm = 3.9244
	new_data_grads_norm = 6.0509
	old_data_grads_norm = 4.7926
	sim_grads_norm = -0.0017
-- Starting training on experience 41 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0022
	data_grads_norm = 4.4090
	new_data_grads_norm = 6.8641
	old_data_grads_norm = 4.4369
	sim_grads_norm = 0.0198
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0716
	data_grads_norm = 4.1651
	new_data_grads_norm = 5.5886
	old_data_grads_norm = 4.8246
	sim_grads_norm = 0.0085
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8198
	data_grads_norm = 4.0234
	new_data_grads_norm = 6.2609
	old_data_grads_norm = 3.8898
	sim_grads_norm = 0.1076
-- Starting training on experience 42 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9979
	data_grads_norm = 3.0486
	new_data_grads_norm = 5.0827
	old_data_grads_norm = 4.0339
	sim_grads_norm = -0.0037
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5124
	data_grads_norm = 4.0271
	new_data_grads_norm = 5.7271
	old_data_grads_norm = 5.8668
	sim_grads_norm = -0.0002
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1003
	data_grads_norm = 3.6032
	new_data_grads_norm = 5.6798
	old_data_grads_norm = 4.0643
	sim_grads_norm = -0.0275
-- Starting training on experience 43 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3891
	data_grads_norm = 4.2091
	new_data_grads_norm = 6.0128
	old_data_grads_norm = 4.8800
	sim_grads_norm = 0.0560
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1838
	data_grads_norm = 4.0295
	new_data_grads_norm = 6.1997
	old_data_grads_norm = 4.6148
	sim_grads_norm = -0.0499
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3190
	data_grads_norm = 4.0173
	new_data_grads_norm = 6.3452
	old_data_grads_norm = 4.7191
	sim_grads_norm = 0.0569
-- Starting training on experience 44 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3437
	data_grads_norm = 4.0801
	new_data_grads_norm = 6.6829
	old_data_grads_norm = 3.3939
	sim_grads_norm = 0.0008
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2898
	data_grads_norm = 4.3737
	new_data_grads_norm = 7.1322
	old_data_grads_norm = 5.3226
	sim_grads_norm = 0.0235
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5765
	data_grads_norm = 5.2012
	new_data_grads_norm = 6.8101
	old_data_grads_norm = 6.1843
	sim_grads_norm = 0.0262
-- Starting training on experience 45 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5087
	data_grads_norm = 3.9807
	new_data_grads_norm = 6.3622
	old_data_grads_norm = 3.8477
	sim_grads_norm = -0.0152
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6976
	data_grads_norm = 4.5939
	new_data_grads_norm = 6.6689
	old_data_grads_norm = 5.6003
	sim_grads_norm = 0.0120
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8245
	data_grads_norm = 4.0503
	new_data_grads_norm = 6.2001
	old_data_grads_norm = 4.8438
	sim_grads_norm = -0.0347
-- Starting training on experience 46 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9226
	data_grads_norm = 4.3527
	new_data_grads_norm = 5.8614
	old_data_grads_norm = 5.5746
	sim_grads_norm = 0.0056
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6960
	data_grads_norm = 3.9551
	new_data_grads_norm = 6.2447
	old_data_grads_norm = 4.5051
	sim_grads_norm = -0.0315
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7019
	data_grads_norm = 4.1354
	new_data_grads_norm = 6.1779
	old_data_grads_norm = 4.6981
	sim_grads_norm = -0.0252
-- Starting training on experience 47 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8121
	data_grads_norm = 4.1331
	new_data_grads_norm = 6.4523
	old_data_grads_norm = 4.6865
	sim_grads_norm = -0.0082
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1350
	data_grads_norm = 4.2761
	new_data_grads_norm = 5.7173
	old_data_grads_norm = 6.0013
	sim_grads_norm = 0.1141
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0995
	data_grads_norm = 4.2817
	new_data_grads_norm = 5.7239
	old_data_grads_norm = 6.5392
	sim_grads_norm = -0.0166
-- Starting training on experience 48 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6961
	data_grads_norm = 4.1688
	new_data_grads_norm = 6.1930
	old_data_grads_norm = 5.6553
	sim_grads_norm = 0.0378
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7427
	data_grads_norm = 3.8747
	new_data_grads_norm = 6.4092
	old_data_grads_norm = 4.1456
	sim_grads_norm = -0.0251
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6480
	data_grads_norm = 4.2050
	new_data_grads_norm = 5.9552
	old_data_grads_norm = 4.9415
	sim_grads_norm = -0.0323
-- Starting training on experience 49 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5013
	data_grads_norm = 3.9460
	new_data_grads_norm = 5.6820
	old_data_grads_norm = 5.4060
	sim_grads_norm = -0.0196
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1680
	data_grads_norm = 4.4717
	new_data_grads_norm = 6.1855
	old_data_grads_norm = 6.1373
	sim_grads_norm = 0.0853
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3321
	data_grads_norm = 5.2620
	new_data_grads_norm = 6.3854
	old_data_grads_norm = 8.0328
	sim_grads_norm = -0.0257
-- Starting training on experience 50 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0360
	data_grads_norm = 5.4045
	new_data_grads_norm = 6.5819
	old_data_grads_norm = 7.1261
	sim_grads_norm = 0.1183
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1104
	data_grads_norm = 4.0660
	new_data_grads_norm = 5.9408
	old_data_grads_norm = 4.9862
	sim_grads_norm = -0.0295
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1240
	data_grads_norm = 4.4403
	new_data_grads_norm = 6.6995
	old_data_grads_norm = 5.1401
	sim_grads_norm = -0.0359
-- Starting training on experience 51 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9201
	data_grads_norm = 4.0896
	new_data_grads_norm = 6.0747
	old_data_grads_norm = 5.3019
	sim_grads_norm = -0.0064
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7170
	data_grads_norm = 4.3293
	new_data_grads_norm = 5.9677
	old_data_grads_norm = 6.6987
	sim_grads_norm = 0.0570
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6968
	data_grads_norm = 3.9472
	new_data_grads_norm = 6.1180
	old_data_grads_norm = 4.7599
	sim_grads_norm = 0.0309
-- Starting training on experience 52 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6145
	data_grads_norm = 3.8761
	new_data_grads_norm = 5.3950
	old_data_grads_norm = 4.6711
	sim_grads_norm = -0.0011
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9184
	data_grads_norm = 4.0210
	new_data_grads_norm = 5.8586
	old_data_grads_norm = 5.0301
	sim_grads_norm = 0.0007
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7580
	data_grads_norm = 4.2156
	new_data_grads_norm = 6.2508
	old_data_grads_norm = 4.9825
	sim_grads_norm = -0.0072
-- Starting training on experience 53 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5711
	data_grads_norm = 4.3712
	new_data_grads_norm = 6.9055
	old_data_grads_norm = 6.1717
	sim_grads_norm = 0.0211
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7944
	data_grads_norm = 4.6012
	new_data_grads_norm = 6.2084
	old_data_grads_norm = 7.0526
	sim_grads_norm = 0.0491
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3034
	data_grads_norm = 3.2572
	new_data_grads_norm = 6.3059
	old_data_grads_norm = 4.0505
	sim_grads_norm = 0.0023
-- Starting training on experience 54 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2928
	data_grads_norm = 3.6129
	new_data_grads_norm = 5.6586
	old_data_grads_norm = 5.0747
	sim_grads_norm = -0.0514
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9652
	data_grads_norm = 4.7088
	new_data_grads_norm = 6.6134
	old_data_grads_norm = 6.5235
	sim_grads_norm = 0.0248
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7477
	data_grads_norm = 4.5401
	new_data_grads_norm = 6.2148
	old_data_grads_norm = 5.4757
	sim_grads_norm = -0.0179
-- Starting training on experience 55 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8554
	data_grads_norm = 4.1786
	new_data_grads_norm = 6.2490
	old_data_grads_norm = 5.4322
	sim_grads_norm = -0.0218
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7608
	data_grads_norm = 4.1914
	new_data_grads_norm = 6.6117
	old_data_grads_norm = 4.2079
	sim_grads_norm = 0.1034
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7631
	data_grads_norm = 4.5698
	new_data_grads_norm = 6.7578
	old_data_grads_norm = 6.0650
	sim_grads_norm = 0.0213
-- Starting training on experience 56 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4140
	data_grads_norm = 4.3760
	new_data_grads_norm = 6.4429
	old_data_grads_norm = 5.4249
	sim_grads_norm = 0.0523
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5397
	data_grads_norm = 3.4770
	new_data_grads_norm = 5.8645
	old_data_grads_norm = 2.5191
	sim_grads_norm = -0.0104
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9823
	data_grads_norm = 4.1431
	new_data_grads_norm = 6.3047
	old_data_grads_norm = 4.8411
	sim_grads_norm = -0.0268
-- Starting training on experience 57 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5545
	data_grads_norm = 3.9152
	new_data_grads_norm = 5.8231
	old_data_grads_norm = 5.5493
	sim_grads_norm = -0.0110
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9382
	data_grads_norm = 4.3204
	new_data_grads_norm = 5.8197
	old_data_grads_norm = 5.7378
	sim_grads_norm = 0.0455
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9155
	data_grads_norm = 3.0013
	new_data_grads_norm = 5.4935
	old_data_grads_norm = 3.6637
	sim_grads_norm = 0.0016
-- Starting training on experience 58 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4726
	data_grads_norm = 3.9549
	new_data_grads_norm = 6.3637
	old_data_grads_norm = 3.5145
	sim_grads_norm = 0.0316
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0946
	data_grads_norm = 4.3326
	new_data_grads_norm = 6.2166
	old_data_grads_norm = 6.4317
	sim_grads_norm = 0.0305
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3636
	data_grads_norm = 3.8445
	new_data_grads_norm = 6.3876
	old_data_grads_norm = 4.5776
	sim_grads_norm = -0.0127
-- Starting training on experience 59 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4068
	data_grads_norm = 4.5855
	new_data_grads_norm = 6.6845
	old_data_grads_norm = 6.0754
	sim_grads_norm = -0.0012
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9867
	data_grads_norm = 4.3100
	new_data_grads_norm = 6.2207
	old_data_grads_norm = 4.7656
	sim_grads_norm = 0.1185
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1471
	data_grads_norm = 4.3685
	new_data_grads_norm = 6.8532
	old_data_grads_norm = 4.1819
	sim_grads_norm = -0.0167
-- Starting training on experience 60 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7935
	data_grads_norm = 3.9337
	new_data_grads_norm = 5.5201
	old_data_grads_norm = 5.5955
	sim_grads_norm = -0.0661
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8047
	data_grads_norm = 4.1034
	new_data_grads_norm = 6.1283
	old_data_grads_norm = 4.4631
	sim_grads_norm = -0.0077
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0532
	data_grads_norm = 4.1897
	new_data_grads_norm = 6.1746
	old_data_grads_norm = 5.5310
	sim_grads_norm = 0.0318
-- Starting training on experience 61 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7735
	data_grads_norm = 4.2697
	new_data_grads_norm = 6.0589
	old_data_grads_norm = 5.7580
	sim_grads_norm = 0.0565
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6275
	data_grads_norm = 3.9760
	new_data_grads_norm = 5.9363
	old_data_grads_norm = 4.0617
	sim_grads_norm = 0.0731
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6115
	data_grads_norm = 3.5424
	new_data_grads_norm = 5.5540
	old_data_grads_norm = 4.1098
	sim_grads_norm = -0.0450
-- Starting training on experience 62 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3007
	data_grads_norm = 3.3683
	new_data_grads_norm = 5.4323
	old_data_grads_norm = 4.1993
	sim_grads_norm = -0.0331
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5613
	data_grads_norm = 3.6816
	new_data_grads_norm = 6.6939
	old_data_grads_norm = 3.2295
	sim_grads_norm = -0.0280
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5360
	data_grads_norm = 3.8061
	new_data_grads_norm = 5.8520
	old_data_grads_norm = 3.8754
	sim_grads_norm = -0.0212
-- Starting training on experience 63 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7215
	data_grads_norm = 4.2275
	new_data_grads_norm = 6.1546
	old_data_grads_norm = 4.6099
	sim_grads_norm = 0.0703
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4425
	data_grads_norm = 4.3167
	new_data_grads_norm = 5.5191
	old_data_grads_norm = 4.8632
	sim_grads_norm = -0.0760
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9862
	data_grads_norm = 4.6736
	new_data_grads_norm = 5.9708
	old_data_grads_norm = 6.1926
	sim_grads_norm = 0.0523
-- Starting training on experience 64 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2878
	data_grads_norm = 4.3662
	new_data_grads_norm = 6.5610
	old_data_grads_norm = 5.8786
	sim_grads_norm = 0.0832
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7797
	data_grads_norm = 4.1510
	new_data_grads_norm = 6.3467
	old_data_grads_norm = 5.3393
	sim_grads_norm = -0.0200
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1637
	data_grads_norm = 4.8777
	new_data_grads_norm = 7.0756
	old_data_grads_norm = 6.6444
	sim_grads_norm = 0.0074
-- Starting training on experience 65 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5679
	data_grads_norm = 4.1017
	new_data_grads_norm = 5.7816
	old_data_grads_norm = 4.7100
	sim_grads_norm = 0.0128
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2355
	data_grads_norm = 4.8049
	new_data_grads_norm = 5.9581
	old_data_grads_norm = 6.5620
	sim_grads_norm = 0.0875
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2454
	data_grads_norm = 4.2064
	new_data_grads_norm = 5.5188
	old_data_grads_norm = 6.1864
	sim_grads_norm = -0.0117
-- Starting training on experience 66 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8792
	data_grads_norm = 4.3902
	new_data_grads_norm = 6.8737
	old_data_grads_norm = 5.8117
	sim_grads_norm = 0.0259
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8001
	data_grads_norm = 4.1917
	new_data_grads_norm = 6.0929
	old_data_grads_norm = 5.8477
	sim_grads_norm = -0.0171
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6437
	data_grads_norm = 3.9929
	new_data_grads_norm = 6.2552
	old_data_grads_norm = 4.9508
	sim_grads_norm = 0.0045
-- Starting training on experience 67 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2987
	data_grads_norm = 3.8079
	new_data_grads_norm = 5.7298
	old_data_grads_norm = 5.3311
	sim_grads_norm = -0.0680
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5985
	data_grads_norm = 4.1784
	new_data_grads_norm = 6.1495
	old_data_grads_norm = 6.0644
	sim_grads_norm = -0.0030
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9011
	data_grads_norm = 4.0955
	new_data_grads_norm = 5.8766
	old_data_grads_norm = 5.0952
	sim_grads_norm = 0.0625
-- Starting training on experience 68 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5135
	data_grads_norm = 3.8897
	new_data_grads_norm = 6.3027
	old_data_grads_norm = 5.0328
	sim_grads_norm = 0.0141
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9939
	data_grads_norm = 4.4211
	new_data_grads_norm = 6.4129
	old_data_grads_norm = 5.9107
	sim_grads_norm = -0.0099
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7597
	data_grads_norm = 4.3310
	new_data_grads_norm = 5.9211
	old_data_grads_norm = 5.2812
	sim_grads_norm = 0.0086
-- Starting training on experience 69 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3894
	data_grads_norm = 3.7168
	new_data_grads_norm = 5.8033
	old_data_grads_norm = 4.4055
	sim_grads_norm = -0.0114
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7017
	data_grads_norm = 3.7360
	new_data_grads_norm = 5.2235
	old_data_grads_norm = 4.5238
	sim_grads_norm = 0.1429
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6368
	data_grads_norm = 4.0159
	new_data_grads_norm = 5.9173
	old_data_grads_norm = 5.8460
	sim_grads_norm = -0.0265
-- Starting training on experience 70 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9172
	data_grads_norm = 4.9903
	new_data_grads_norm = 5.5620
	old_data_grads_norm = 7.3005
	sim_grads_norm = 0.0107
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5297
	data_grads_norm = 3.6135
	new_data_grads_norm = 6.2074
	old_data_grads_norm = 3.4635
	sim_grads_norm = -0.0304
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4983
	data_grads_norm = 4.2366
	new_data_grads_norm = 6.0650
	old_data_grads_norm = 4.9150
	sim_grads_norm = 0.0692
-- Starting training on experience 71 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4919
	data_grads_norm = 3.6738
	new_data_grads_norm = 5.1903
	old_data_grads_norm = 5.1229
	sim_grads_norm = 0.0038
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6263
	data_grads_norm = 3.8665
	new_data_grads_norm = 5.7730
	old_data_grads_norm = 4.6127
	sim_grads_norm = 0.1344
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5196
	data_grads_norm = 4.1354
	new_data_grads_norm = 4.8620
	old_data_grads_norm = 6.2584
	sim_grads_norm = 0.0104
-- Starting training on experience 72 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7506
	data_grads_norm = 4.6205
	new_data_grads_norm = 6.8108
	old_data_grads_norm = 5.7980
	sim_grads_norm = -0.0327
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2298
	data_grads_norm = 4.2031
	new_data_grads_norm = 7.8136
	old_data_grads_norm = 3.3549
	sim_grads_norm = -0.0556
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3431
	data_grads_norm = 3.7355
	new_data_grads_norm = 6.6299
	old_data_grads_norm = 4.0327
	sim_grads_norm = -0.0089
-- Starting training on experience 73 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7704
	data_grads_norm = 5.3886
	new_data_grads_norm = 6.7494
	old_data_grads_norm = 5.7304
	sim_grads_norm = -0.0006
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4799
	data_grads_norm = 4.1190
	new_data_grads_norm = 6.4870
	old_data_grads_norm = 5.7066
	sim_grads_norm = 0.0518
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0658
	data_grads_norm = 4.3741
	new_data_grads_norm = 6.6754
	old_data_grads_norm = 5.7636
	sim_grads_norm = -0.0355
-- Starting training on experience 74 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6953
	data_grads_norm = 4.1565
	new_data_grads_norm = 5.1177
	old_data_grads_norm = 6.9003
	sim_grads_norm = -0.0117
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4472
	data_grads_norm = 3.3963
	new_data_grads_norm = 5.0593
	old_data_grads_norm = 4.7832
	sim_grads_norm = 0.0100
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4615
	data_grads_norm = 4.0703
	new_data_grads_norm = 5.3098
	old_data_grads_norm = 4.9020
	sim_grads_norm = 0.0252
-- Starting training on experience 75 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8254
	data_grads_norm = 4.2676
	new_data_grads_norm = 5.8096
	old_data_grads_norm = 5.2059
	sim_grads_norm = 0.0615
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0193
	data_grads_norm = 2.7739
	new_data_grads_norm = 5.3834
	old_data_grads_norm = 4.1022
	sim_grads_norm = -0.0757
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2813
	data_grads_norm = 3.4204
	new_data_grads_norm = 5.4359
	old_data_grads_norm = 4.0143
	sim_grads_norm = -0.0222
-- Starting training on experience 76 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4748
	data_grads_norm = 4.4190
	new_data_grads_norm = 5.0970
	old_data_grads_norm = 6.6642
	sim_grads_norm = 0.0106
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2023
	data_grads_norm = 3.7010
	new_data_grads_norm = 4.9577
	old_data_grads_norm = 5.7109
	sim_grads_norm = -0.0156
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6570
	data_grads_norm = 4.3209
	new_data_grads_norm = 5.5412
	old_data_grads_norm = 6.3381
	sim_grads_norm = 0.0058
-- Starting training on experience 77 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1275
	data_grads_norm = 4.6146
	new_data_grads_norm = 7.2689
	old_data_grads_norm = 5.6790
	sim_grads_norm = 0.0126
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0106
	data_grads_norm = 4.7087
	new_data_grads_norm = 6.8317
	old_data_grads_norm = 5.7523
	sim_grads_norm = 0.0081
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1355
	data_grads_norm = 5.1532
	new_data_grads_norm = 8.4198
	old_data_grads_norm = 5.8802
	sim_grads_norm = -0.0044
-- Starting training on experience 78 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6585
	data_grads_norm = 4.6268
	new_data_grads_norm = 5.7343
	old_data_grads_norm = 5.8056
	sim_grads_norm = 0.0081
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1081
	data_grads_norm = 4.4689
	new_data_grads_norm = 5.4727
	old_data_grads_norm = 6.4528
	sim_grads_norm = 0.0124
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3602
	data_grads_norm = 3.5204
	new_data_grads_norm = 5.2018
	old_data_grads_norm = 4.2930
	sim_grads_norm = 0.0120
-- Starting training on experience 79 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1466
	data_grads_norm = 4.5861
	new_data_grads_norm = 6.7410
	old_data_grads_norm = 5.7100
	sim_grads_norm = 0.0676
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7302
	data_grads_norm = 4.4041
	new_data_grads_norm = 6.4735
	old_data_grads_norm = 5.8777
	sim_grads_norm = -0.0343
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0580
	data_grads_norm = 4.5491
	new_data_grads_norm = 6.8211
	old_data_grads_norm = 6.4686
	sim_grads_norm = 0.0010
-- Starting training on experience 80 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4980
	data_grads_norm = 4.2195
	new_data_grads_norm = 6.2474
	old_data_grads_norm = 5.1523
	sim_grads_norm = -0.0048
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9386
	data_grads_norm = 4.7220
	new_data_grads_norm = 6.6690
	old_data_grads_norm = 6.3832
	sim_grads_norm = -0.0032
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6221
	data_grads_norm = 3.9887
	new_data_grads_norm = 6.1273
	old_data_grads_norm = 4.5345
	sim_grads_norm = 0.0207
-- Starting training on experience 81 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3279
	data_grads_norm = 4.5281
	new_data_grads_norm = 6.3088
	old_data_grads_norm = 5.2715
	sim_grads_norm = 0.0957
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5839
	data_grads_norm = 4.0668
	new_data_grads_norm = 6.0764
	old_data_grads_norm = 4.8427
	sim_grads_norm = -0.0215
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7048
	data_grads_norm = 4.2078
	new_data_grads_norm = 6.0834
	old_data_grads_norm = 4.6523
	sim_grads_norm = 0.0342
-- Starting training on experience 82 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4182
	data_grads_norm = 3.8675
	new_data_grads_norm = 5.7009
	old_data_grads_norm = 4.1489
	sim_grads_norm = 0.0314
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7051
	data_grads_norm = 3.2134
	new_data_grads_norm = 4.5932
	old_data_grads_norm = 4.1773
	sim_grads_norm = -0.0187
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1750
	data_grads_norm = 3.6592
	new_data_grads_norm = 4.8766
	old_data_grads_norm = 5.7277
	sim_grads_norm = -0.0394
-- Starting training on experience 83 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0515
	data_grads_norm = 3.7474
	new_data_grads_norm = 5.0501
	old_data_grads_norm = 4.1955
	sim_grads_norm = -0.0035
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9375
	data_grads_norm = 3.4020
	new_data_grads_norm = 5.0074
	old_data_grads_norm = 3.7395
	sim_grads_norm = 0.0568
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7990
	data_grads_norm = 3.4764
	new_data_grads_norm = 5.5972
	old_data_grads_norm = 4.7227
	sim_grads_norm = -0.0314
-- Starting training on experience 84 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0115
	data_grads_norm = 3.5225
	new_data_grads_norm = 5.2334
	old_data_grads_norm = 3.1305
	sim_grads_norm = -0.0123
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1043
	data_grads_norm = 4.5007
	new_data_grads_norm = 6.5965
	old_data_grads_norm = 6.0231
	sim_grads_norm = 0.0215
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0736
	data_grads_norm = 3.3827
	new_data_grads_norm = 5.7204
	old_data_grads_norm = 4.2253
	sim_grads_norm = -0.0431
-- Starting training on experience 85 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9718
	data_grads_norm = 3.8206
	new_data_grads_norm = 6.2056
	old_data_grads_norm = 3.9643
	sim_grads_norm = -0.0027
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0893
	data_grads_norm = 3.9333
	new_data_grads_norm = 5.4654
	old_data_grads_norm = 3.7718
	sim_grads_norm = 0.0268
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9687
	data_grads_norm = 3.7603
	new_data_grads_norm = 5.3739
	old_data_grads_norm = 4.0152
	sim_grads_norm = -0.0123
-- Starting training on experience 86 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6668
	data_grads_norm = 5.1191
	new_data_grads_norm = 6.5603
	old_data_grads_norm = 6.7361
	sim_grads_norm = -0.0150
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1073
	data_grads_norm = 4.1653
	new_data_grads_norm = 6.6521
	old_data_grads_norm = 3.8152
	sim_grads_norm = 0.0078
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2624
	data_grads_norm = 4.1314
	new_data_grads_norm = 6.4028
	old_data_grads_norm = 5.3808
	sim_grads_norm = 0.0071
-- Starting training on experience 87 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0637
	data_grads_norm = 3.7476
	new_data_grads_norm = 6.0939
	old_data_grads_norm = 4.7604
	sim_grads_norm = 0.0068
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9200
	data_grads_norm = 3.5852
	new_data_grads_norm = 5.7532
	old_data_grads_norm = 3.5659
	sim_grads_norm = -0.0108
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2494
	data_grads_norm = 3.8388
	new_data_grads_norm = 5.7349
	old_data_grads_norm = 4.7568
	sim_grads_norm = -0.0574
-- Starting training on experience 88 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2030
	data_grads_norm = 3.7941
	new_data_grads_norm = 6.2617
	old_data_grads_norm = 5.1079
	sim_grads_norm = 0.0399
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3559
	data_grads_norm = 4.0570
	new_data_grads_norm = 6.0699
	old_data_grads_norm = 5.1597
	sim_grads_norm = 0.0099
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4467
	data_grads_norm = 4.4658
	new_data_grads_norm = 5.9055
	old_data_grads_norm = 6.1336
	sim_grads_norm = -0.0075
-- Starting training on experience 89 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0484
	data_grads_norm = 4.2269
	new_data_grads_norm = 5.9964
	old_data_grads_norm = 6.0152
	sim_grads_norm = 0.0014
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8082
	data_grads_norm = 3.8561
	new_data_grads_norm = 5.7981
	old_data_grads_norm = 4.7972
	sim_grads_norm = 0.0127
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4178
	data_grads_norm = 4.4823
	new_data_grads_norm = 6.4343
	old_data_grads_norm = 7.4003
	sim_grads_norm = 0.0279
-- Starting training on experience 90 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7977
	data_grads_norm = 3.8817
	new_data_grads_norm = 5.4265
	old_data_grads_norm = 5.4484
	sim_grads_norm = 0.0177
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3854
	data_grads_norm = 3.8596
	new_data_grads_norm = 5.2856
	old_data_grads_norm = 5.1039
	sim_grads_norm = 0.0406
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4570
	data_grads_norm = 3.6985
	new_data_grads_norm = 5.6272
	old_data_grads_norm = 3.8521
	sim_grads_norm = 0.1258
-- Starting training on experience 91 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6150
	data_grads_norm = 4.8779
	new_data_grads_norm = 5.4167
	old_data_grads_norm = 7.3188
	sim_grads_norm = 0.0139
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2939
	data_grads_norm = 3.8375
	new_data_grads_norm = 6.2890
	old_data_grads_norm = 4.9752
	sim_grads_norm = 0.0069
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0264
	data_grads_norm = 3.6826
	new_data_grads_norm = 5.1574
	old_data_grads_norm = 5.5128
	sim_grads_norm = -0.0340
-- Starting training on experience 92 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4131
	data_grads_norm = 4.3173
	new_data_grads_norm = 6.6815
	old_data_grads_norm = 5.1595
	sim_grads_norm = -0.0058
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4933
	data_grads_norm = 4.6028
	new_data_grads_norm = 7.4024
	old_data_grads_norm = 4.7502
	sim_grads_norm = 0.0148
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6459
	data_grads_norm = 4.7587
	new_data_grads_norm = 6.9797
	old_data_grads_norm = 4.5180
	sim_grads_norm = -0.0204
-- Starting training on experience 93 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4064
	data_grads_norm = 4.1340
	new_data_grads_norm = 5.5346
	old_data_grads_norm = 4.6574
	sim_grads_norm = 0.1061
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2219
	data_grads_norm = 4.4610
	new_data_grads_norm = 5.1996
	old_data_grads_norm = 6.6495
	sim_grads_norm = 0.1302
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9270
	data_grads_norm = 3.8625
	new_data_grads_norm = 5.1393
	old_data_grads_norm = 5.0605
	sim_grads_norm = -0.0079
-- Starting training on experience 94 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8889
	data_grads_norm = 4.7665
	new_data_grads_norm = 5.8943
	old_data_grads_norm = 7.0099
	sim_grads_norm = 0.0131
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5620
	data_grads_norm = 4.5179
	new_data_grads_norm = 6.7184
	old_data_grads_norm = 4.9557
	sim_grads_norm = 0.0466
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2024
	data_grads_norm = 3.8175
	new_data_grads_norm = 6.1931
	old_data_grads_norm = 5.0372
	sim_grads_norm = -0.0131
-- Starting training on experience 95 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4490
	data_grads_norm = 4.2256
	new_data_grads_norm = 6.2877
	old_data_grads_norm = 6.5354
	sim_grads_norm = -0.0078
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7319
	data_grads_norm = 4.2171
	new_data_grads_norm = 5.8491
	old_data_grads_norm = 5.9261
	sim_grads_norm = 0.1288
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1244
	data_grads_norm = 4.3324
	new_data_grads_norm = 6.9842
	old_data_grads_norm = 4.6386
	sim_grads_norm = 0.0681
-- Starting training on experience 96 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2475
	data_grads_norm = 4.0545
	new_data_grads_norm = 5.8204
	old_data_grads_norm = 5.0905
	sim_grads_norm = -0.0121
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9833
	data_grads_norm = 3.6878
	new_data_grads_norm = 5.5161
	old_data_grads_norm = 4.9002
	sim_grads_norm = 0.0155
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3890
	data_grads_norm = 3.8472
	new_data_grads_norm = 5.9406
	old_data_grads_norm = 5.3640
	sim_grads_norm = 0.0336
-- Starting training on experience 97 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9266
	data_grads_norm = 3.4688
	new_data_grads_norm = 5.1257
	old_data_grads_norm = 4.8152
	sim_grads_norm = -0.0139
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8936
	data_grads_norm = 3.5646
	new_data_grads_norm = 4.8777
	old_data_grads_norm = 4.1954
	sim_grads_norm = -0.0263
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4064
	data_grads_norm = 4.1843
	new_data_grads_norm = 5.6283
	old_data_grads_norm = 6.4514
	sim_grads_norm = 0.0250
-- Starting training on experience 98 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8302
	data_grads_norm = 4.2866
	new_data_grads_norm = 6.2808
	old_data_grads_norm = 5.7578
	sim_grads_norm = 0.0419
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5142
	data_grads_norm = 3.9515
	new_data_grads_norm = 5.6749
	old_data_grads_norm = 4.6788
	sim_grads_norm = 0.0436
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7131
	data_grads_norm = 4.1967
	new_data_grads_norm = 5.1443
	old_data_grads_norm = 6.5339
	sim_grads_norm = 0.0112
-- Starting training on experience 99 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1066
	data_grads_norm = 3.9610
	new_data_grads_norm = 5.8730
	old_data_grads_norm = 4.9735
	sim_grads_norm = -0.0392
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8576
	data_grads_norm = 3.6337
	new_data_grads_norm = 5.7345
	old_data_grads_norm = 3.8478
	sim_grads_norm = -0.0418
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0892
	data_grads_norm = 4.1822
	new_data_grads_norm = 5.8459
	old_data_grads_norm = 5.5209
	sim_grads_norm = -0.0058
-- Starting training on experience 100 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0268
	data_grads_norm = 3.8506
	new_data_grads_norm = 4.7196
	old_data_grads_norm = 6.7789
	sim_grads_norm = 0.0246
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8140
	data_grads_norm = 5.1753
	new_data_grads_norm = 4.9412
	old_data_grads_norm = 8.2031
	sim_grads_norm = 0.0423
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9685
	data_grads_norm = 3.0170
	new_data_grads_norm = 4.3697
	old_data_grads_norm = 3.7264
	sim_grads_norm = -0.0299
-- Starting training on experience 101 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8911
	data_grads_norm = 4.4892
	new_data_grads_norm = 5.6221
	old_data_grads_norm = 6.6569
	sim_grads_norm = 0.0551
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9528
	data_grads_norm = 3.9960
	new_data_grads_norm = 6.2216
	old_data_grads_norm = 5.2750
	sim_grads_norm = -0.0034
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9482
	data_grads_norm = 3.9897
	new_data_grads_norm = 6.0062
	old_data_grads_norm = 4.6557
	sim_grads_norm = -0.0079
-- Starting training on experience 102 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0784
	data_grads_norm = 4.0226
	new_data_grads_norm = 7.0665
	old_data_grads_norm = 4.2489
	sim_grads_norm = 0.0126
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7069
	data_grads_norm = 4.6123
	new_data_grads_norm = 6.3432
	old_data_grads_norm = 4.9604
	sim_grads_norm = 0.0729
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3441
	data_grads_norm = 4.4957
	new_data_grads_norm = 6.8356
	old_data_grads_norm = 5.5035
	sim_grads_norm = 0.0018
-- Starting training on experience 103 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2037
	data_grads_norm = 4.6878
	new_data_grads_norm = 6.9632
	old_data_grads_norm = 5.0764
	sim_grads_norm = 0.0059
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5094
	data_grads_norm = 4.6054
	new_data_grads_norm = 6.9402
	old_data_grads_norm = 5.3795
	sim_grads_norm = 0.0196
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5235
	data_grads_norm = 4.5291
	new_data_grads_norm = 7.3007
	old_data_grads_norm = 4.6097
	sim_grads_norm = 0.0613
-- Starting training on experience 104 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4639
	data_grads_norm = 4.1200
	new_data_grads_norm = 5.8309
	old_data_grads_norm = 5.6658
	sim_grads_norm = -0.0396
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1467
	data_grads_norm = 3.9404
	new_data_grads_norm = 5.8011
	old_data_grads_norm = 4.7616
	sim_grads_norm = -0.0143
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2986
	data_grads_norm = 4.1562
	new_data_grads_norm = 5.8279
	old_data_grads_norm = 6.2858
	sim_grads_norm = 0.0201
-- Starting training on experience 105 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8841
	data_grads_norm = 4.1055
	new_data_grads_norm = 5.5800
	old_data_grads_norm = 5.1643
	sim_grads_norm = -0.0583
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4182
	data_grads_norm = 2.8521
	new_data_grads_norm = 5.2760
	old_data_grads_norm = 2.5253
	sim_grads_norm = -0.0505
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8671
	data_grads_norm = 3.5640
	new_data_grads_norm = 5.2840
	old_data_grads_norm = 4.8105
	sim_grads_norm = -0.0303
-- Starting training on experience 106 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5879
	data_grads_norm = 4.0759
	new_data_grads_norm = 5.6788
	old_data_grads_norm = 5.4543
	sim_grads_norm = -0.0302
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2283
	data_grads_norm = 4.0045
	new_data_grads_norm = 6.2648
	old_data_grads_norm = 4.9306
	sim_grads_norm = 0.0044
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7251
	data_grads_norm = 4.2717
	new_data_grads_norm = 6.2718
	old_data_grads_norm = 5.5077
	sim_grads_norm = -0.0096
-- Starting training on experience 107 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4141
	data_grads_norm = 4.4337
	new_data_grads_norm = 5.8396
	old_data_grads_norm = 5.7800
	sim_grads_norm = -0.0268
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0716
	data_grads_norm = 3.9574
	new_data_grads_norm = 6.0839
	old_data_grads_norm = 5.6628
	sim_grads_norm = -0.0125
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5221
	data_grads_norm = 4.2573
	new_data_grads_norm = 5.8081
	old_data_grads_norm = 5.1033
	sim_grads_norm = 0.0002
-- Starting training on experience 108 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9284
	data_grads_norm = 4.0602
	new_data_grads_norm = 5.9383
	old_data_grads_norm = 4.8135
	sim_grads_norm = 0.0551
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9003
	data_grads_norm = 4.3463
	new_data_grads_norm = 6.3894
	old_data_grads_norm = 5.2344
	sim_grads_norm = 0.0135
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5585
	data_grads_norm = 4.2095
	new_data_grads_norm = 6.2382
	old_data_grads_norm = 5.7456
	sim_grads_norm = 0.0381
-- Starting training on experience 109 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2758
	data_grads_norm = 3.6808
	new_data_grads_norm = 5.3603
	old_data_grads_norm = 4.9904
	sim_grads_norm = -0.0075
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8127
	data_grads_norm = 3.1066
	new_data_grads_norm = 5.4424
	old_data_grads_norm = 3.3889
	sim_grads_norm = -0.0623
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4342
	data_grads_norm = 3.9581
	new_data_grads_norm = 5.8861
	old_data_grads_norm = 5.5038
	sim_grads_norm = 0.0133
-- Starting training on experience 110 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7571
	data_grads_norm = 4.5706
	new_data_grads_norm = 6.0982
	old_data_grads_norm = 6.6584
	sim_grads_norm = 0.0256
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4790
	data_grads_norm = 3.9468
	new_data_grads_norm = 5.9167
	old_data_grads_norm = 5.4515
	sim_grads_norm = 0.0055
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3090
	data_grads_norm = 4.0892
	new_data_grads_norm = 5.9318
	old_data_grads_norm = 5.5152
	sim_grads_norm = -0.0144
-- Starting training on experience 111 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6412
	data_grads_norm = 4.5223
	new_data_grads_norm = 6.6193
	old_data_grads_norm = 5.5497
	sim_grads_norm = -0.0226
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0879
	data_grads_norm = 4.9086
	new_data_grads_norm = 6.3689
	old_data_grads_norm = 6.2446
	sim_grads_norm = 0.0972
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4521
	data_grads_norm = 4.0373
	new_data_grads_norm = 6.4025
	old_data_grads_norm = 4.8183
	sim_grads_norm = -0.0375
-- Starting training on experience 112 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4379
	data_grads_norm = 3.7103
	new_data_grads_norm = 5.5389
	old_data_grads_norm = 4.7798
	sim_grads_norm = -0.0276
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8233
	data_grads_norm = 4.0927
	new_data_grads_norm = 5.5327
	old_data_grads_norm = 5.4594
	sim_grads_norm = -0.0145
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7976
	data_grads_norm = 4.2052
	new_data_grads_norm = 6.0018
	old_data_grads_norm = 5.2963
	sim_grads_norm = -0.0372
-- Starting training on experience 113 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9327
	data_grads_norm = 4.0751
	new_data_grads_norm = 6.3629
	old_data_grads_norm = 4.7626
	sim_grads_norm = -0.0108
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5108
	data_grads_norm = 3.6213
	new_data_grads_norm = 6.2837
	old_data_grads_norm = 4.7853
	sim_grads_norm = 0.0070
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0394
	data_grads_norm = 4.1821
	new_data_grads_norm = 6.6055
	old_data_grads_norm = 4.6197
	sim_grads_norm = -0.0019
-- Starting training on experience 114 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3635
	data_grads_norm = 3.6649
	new_data_grads_norm = 5.2257
	old_data_grads_norm = 5.8464
	sim_grads_norm = -0.0057
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5395
	data_grads_norm = 3.8583
	new_data_grads_norm = 5.8362
	old_data_grads_norm = 4.1588
	sim_grads_norm = 0.0312
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9762
	data_grads_norm = 3.2957
	new_data_grads_norm = 5.0324
	old_data_grads_norm = 3.8463
	sim_grads_norm = -0.0164
-- Starting training on experience 115 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7948
	data_grads_norm = 4.4052
	new_data_grads_norm = 6.2528
	old_data_grads_norm = 4.6383
	sim_grads_norm = 0.0341
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4249
	data_grads_norm = 3.8790
	new_data_grads_norm = 6.0138
	old_data_grads_norm = 4.4548
	sim_grads_norm = 0.1163
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6113
	data_grads_norm = 4.3181
	new_data_grads_norm = 6.1432
	old_data_grads_norm = 5.4961
	sim_grads_norm = -0.0090
-- Starting training on experience 116 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7057
	data_grads_norm = 4.3640
	new_data_grads_norm = 6.6014
	old_data_grads_norm = 5.5852
	sim_grads_norm = -0.0177
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8975
	data_grads_norm = 4.7274
	new_data_grads_norm = 6.3076
	old_data_grads_norm = 5.8586
	sim_grads_norm = 0.0621
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5151
	data_grads_norm = 4.8626
	new_data_grads_norm = 6.4109
	old_data_grads_norm = 5.7257
	sim_grads_norm = 0.0054
-- Starting training on experience 117 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1349
	data_grads_norm = 4.3792
	new_data_grads_norm = 6.7014
	old_data_grads_norm = 4.7076
	sim_grads_norm = -0.0076
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9287
	data_grads_norm = 4.3511
	new_data_grads_norm = 6.8537
	old_data_grads_norm = 3.9297
	sim_grads_norm = 0.0170
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5710
	data_grads_norm = 4.7946
	new_data_grads_norm = 6.8520
	old_data_grads_norm = 5.5885
	sim_grads_norm = 0.0044
-- Starting training on experience 118 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1931
	data_grads_norm = 3.4636
	new_data_grads_norm = 5.6234
	old_data_grads_norm = 3.6953
	sim_grads_norm = 0.0161
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3004
	data_grads_norm = 3.4360
	new_data_grads_norm = 6.2651
	old_data_grads_norm = 3.5045
	sim_grads_norm = -0.0194
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7544
	data_grads_norm = 4.0076
	new_data_grads_norm = 5.7600
	old_data_grads_norm = 4.0532
	sim_grads_norm = 0.0172
-- Starting training on experience 119 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5309
	data_grads_norm = 4.1857
	new_data_grads_norm = 6.9379
	old_data_grads_norm = 4.2946
	sim_grads_norm = 0.0309
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4962
	data_grads_norm = 4.3265
	new_data_grads_norm = 6.1544
	old_data_grads_norm = 5.3599
	sim_grads_norm = 0.0909
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0269
	data_grads_norm = 4.0198
	new_data_grads_norm = 5.9261
	old_data_grads_norm = 5.4645
	sim_grads_norm = -0.0034
-- Starting training on experience 120 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8429
	data_grads_norm = 4.5452
	new_data_grads_norm = 6.2789
	old_data_grads_norm = 5.8816
	sim_grads_norm = -0.0103
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5110
	data_grads_norm = 4.5543
	new_data_grads_norm = 6.9030
	old_data_grads_norm = 5.6805
	sim_grads_norm = -0.0060
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3211
	data_grads_norm = 3.8870
	new_data_grads_norm = 6.1363
	old_data_grads_norm = 4.4890
	sim_grads_norm = 0.0317
-- Starting training on experience 121 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8966
	data_grads_norm = 4.9070
	new_data_grads_norm = 6.0149
	old_data_grads_norm = 6.5644
	sim_grads_norm = 0.0528
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4020
	data_grads_norm = 4.1576
	new_data_grads_norm = 6.6756
	old_data_grads_norm = 6.3296
	sim_grads_norm = -0.0194
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4679
	data_grads_norm = 3.9246
	new_data_grads_norm = 6.4370
	old_data_grads_norm = 3.9946
	sim_grads_norm = -0.0099
-- Starting training on experience 122 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5088
	data_grads_norm = 3.6435
	new_data_grads_norm = 6.4087
	old_data_grads_norm = 4.3495
	sim_grads_norm = -0.0054
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9121
	data_grads_norm = 4.5144
	new_data_grads_norm = 6.7811
	old_data_grads_norm = 4.9810
	sim_grads_norm = 0.0720
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7403
	data_grads_norm = 4.0736
	new_data_grads_norm = 6.6536
	old_data_grads_norm = 4.7966
	sim_grads_norm = 0.0221
-- Starting training on experience 123 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4417
	data_grads_norm = 4.0976
	new_data_grads_norm = 5.3341
	old_data_grads_norm = 5.1341
	sim_grads_norm = -0.0188
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1390
	data_grads_norm = 3.7664
	new_data_grads_norm = 5.5675
	old_data_grads_norm = 4.4211
	sim_grads_norm = 0.0234
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2315
	data_grads_norm = 4.1589
	new_data_grads_norm = 5.7388
	old_data_grads_norm = 5.7957
	sim_grads_norm = -0.0295
-- Starting training on experience 124 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8690
	data_grads_norm = 3.5511
	new_data_grads_norm = 5.5636
	old_data_grads_norm = 4.6514
	sim_grads_norm = -0.0062
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9287
	data_grads_norm = 3.7746
	new_data_grads_norm = 5.1628
	old_data_grads_norm = 5.3363
	sim_grads_norm = -0.0522
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7055
	data_grads_norm = 5.2807
	new_data_grads_norm = 5.5465
	old_data_grads_norm = 7.8614
	sim_grads_norm = 0.0770
-- Starting training on experience 125 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6990
	data_grads_norm = 3.6694
	new_data_grads_norm = 5.5790
	old_data_grads_norm = 3.8984
	sim_grads_norm = -0.0237
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0337
	data_grads_norm = 3.9833
	new_data_grads_norm = 5.5262
	old_data_grads_norm = 4.7215
	sim_grads_norm = 0.0893
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0321
	data_grads_norm = 3.9469
	new_data_grads_norm = 6.5505
	old_data_grads_norm = 4.9047
	sim_grads_norm = 0.0276
-- Starting training on experience 126 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2455
	data_grads_norm = 4.0592
	new_data_grads_norm = 5.5398
	old_data_grads_norm = 6.1726
	sim_grads_norm = -0.0117
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0832
	data_grads_norm = 4.1236
	new_data_grads_norm = 5.7685
	old_data_grads_norm = 5.4468
	sim_grads_norm = -0.0091
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4213
	data_grads_norm = 4.1217
	new_data_grads_norm = 6.4531
	old_data_grads_norm = 4.7020
	sim_grads_norm = 0.0337
-- Starting training on experience 127 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8674
	data_grads_norm = 4.1176
	new_data_grads_norm = 5.7830
	old_data_grads_norm = 5.0172
	sim_grads_norm = 0.0231
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6072
	data_grads_norm = 3.3722
	new_data_grads_norm = 5.0825
	old_data_grads_norm = 4.3947
	sim_grads_norm = 0.0106
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4692
	data_grads_norm = 3.3025
	new_data_grads_norm = 5.5410
	old_data_grads_norm = 3.2570
	sim_grads_norm = -0.0071
-- Starting training on experience 128 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8066
	data_grads_norm = 4.5300
	new_data_grads_norm = 6.1583
	old_data_grads_norm = 5.4794
	sim_grads_norm = 0.0699
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6135
	data_grads_norm = 3.9032
	new_data_grads_norm = 6.6985
	old_data_grads_norm = 4.9946
	sim_grads_norm = -0.0466
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9314
	data_grads_norm = 4.6806
	new_data_grads_norm = 6.1536
	old_data_grads_norm = 7.4236
	sim_grads_norm = 0.0322
-- Starting training on experience 129 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0081
	data_grads_norm = 3.4098
	new_data_grads_norm = 5.7437
	old_data_grads_norm = 3.2013
	sim_grads_norm = -0.0333
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9951
	data_grads_norm = 3.7095
	new_data_grads_norm = 5.8823
	old_data_grads_norm = 4.8155
	sim_grads_norm = -0.0143
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5082
	data_grads_norm = 4.2813
	new_data_grads_norm = 6.1984
	old_data_grads_norm = 5.9419
	sim_grads_norm = -0.0828
-- Starting training on experience 130 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9183
	data_grads_norm = 4.6691
	new_data_grads_norm = 5.6821
	old_data_grads_norm = 7.4406
	sim_grads_norm = -0.0088
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5234
	data_grads_norm = 4.1395
	new_data_grads_norm = 6.1754
	old_data_grads_norm = 5.3275
	sim_grads_norm = 0.0045
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6196
	data_grads_norm = 3.7929
	new_data_grads_norm = 5.5121
	old_data_grads_norm = 5.4857
	sim_grads_norm = 0.0216
-- Starting training on experience 131 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2316
	data_grads_norm = 4.3993
	new_data_grads_norm = 6.6375
	old_data_grads_norm = 3.9973
	sim_grads_norm = -0.0088
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5995
	data_grads_norm = 4.5939
	new_data_grads_norm = 6.9209
	old_data_grads_norm = 4.4024
	sim_grads_norm = 0.0401
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9588
	data_grads_norm = 4.8749
	new_data_grads_norm = 7.8735
	old_data_grads_norm = 5.3507
	sim_grads_norm = 0.0302
-- Starting training on experience 132 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0158
	data_grads_norm = 4.6560
	new_data_grads_norm = 5.7073
	old_data_grads_norm = 6.5110
	sim_grads_norm = 0.0156
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6054
	data_grads_norm = 4.0299
	new_data_grads_norm = 5.3939
	old_data_grads_norm = 5.8077
	sim_grads_norm = -0.0170
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4881
	data_grads_norm = 4.0655
	new_data_grads_norm = 5.7325
	old_data_grads_norm = 6.0917
	sim_grads_norm = 0.0285
-- Starting training on experience 133 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7477
	data_grads_norm = 5.1010
	new_data_grads_norm = 8.3671
	old_data_grads_norm = 3.9074
	sim_grads_norm = 0.0139
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6397
	data_grads_norm = 4.3291
	new_data_grads_norm = 7.3415
	old_data_grads_norm = 5.2985
	sim_grads_norm = 0.0255
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6573
	data_grads_norm = 4.6280
	new_data_grads_norm = 7.4420
	old_data_grads_norm = 5.0642
	sim_grads_norm = 0.0293
-- Starting training on experience 134 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1529
	data_grads_norm = 3.8679
	new_data_grads_norm = 5.9106
	old_data_grads_norm = 4.9303
	sim_grads_norm = -0.0092
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4117
	data_grads_norm = 4.0612
	new_data_grads_norm = 5.7592
	old_data_grads_norm = 4.5323
	sim_grads_norm = 0.0288
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5949
	data_grads_norm = 4.5801
	new_data_grads_norm = 6.2885
	old_data_grads_norm = 5.8314
	sim_grads_norm = 0.0139
-- Starting training on experience 135 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9911
	data_grads_norm = 3.5343
	new_data_grads_norm = 5.5597
	old_data_grads_norm = 3.7417
	sim_grads_norm = 0.0297
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0194
	data_grads_norm = 3.5524
	new_data_grads_norm = 5.5183
	old_data_grads_norm = 3.6149
	sim_grads_norm = 0.0005
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1562
	data_grads_norm = 3.6847
	new_data_grads_norm = 5.5738
	old_data_grads_norm = 4.1134
	sim_grads_norm = 0.0236
-- Starting training on experience 136 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2826
	data_grads_norm = 4.0374
	new_data_grads_norm = 6.0277
	old_data_grads_norm = 4.9665
	sim_grads_norm = -0.0270
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1137
	data_grads_norm = 3.9759
	new_data_grads_norm = 5.4528
	old_data_grads_norm = 6.1139
	sim_grads_norm = -0.0009
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1801
	data_grads_norm = 3.9734
	new_data_grads_norm = 5.7941
	old_data_grads_norm = 5.0567
	sim_grads_norm = -0.0070
-- Starting training on experience 137 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9495
	data_grads_norm = 3.5086
	new_data_grads_norm = 6.5157
	old_data_grads_norm = 3.5262
	sim_grads_norm = 0.0033
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6137
	data_grads_norm = 4.7433
	new_data_grads_norm = 6.3111
	old_data_grads_norm = 5.7644
	sim_grads_norm = -0.0093
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1149
	data_grads_norm = 4.9178
	new_data_grads_norm = 6.6287
	old_data_grads_norm = 6.3743
	sim_grads_norm = 0.0328
-- Starting training on experience 138 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8729
	data_grads_norm = 4.6338
	new_data_grads_norm = 6.4094
	old_data_grads_norm = 6.5617
	sim_grads_norm = 0.0283
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7198
	data_grads_norm = 4.1320
	new_data_grads_norm = 6.6268
	old_data_grads_norm = 4.6946
	sim_grads_norm = 0.0092
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3170
	data_grads_norm = 4.6149
	new_data_grads_norm = 6.4733
	old_data_grads_norm = 5.7379
	sim_grads_norm = 0.0566
-- Starting training on experience 139 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2834
	data_grads_norm = 3.4447
	new_data_grads_norm = 5.2484
	old_data_grads_norm = 4.6991
	sim_grads_norm = 0.0035
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4305
	data_grads_norm = 4.5084
	new_data_grads_norm = 6.2403
	old_data_grads_norm = 7.0365
	sim_grads_norm = 0.0014
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5677
	data_grads_norm = 4.2255
	new_data_grads_norm = 5.7507
	old_data_grads_norm = 4.8095
	sim_grads_norm = 0.0530
-- Starting training on experience 140 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4446
	data_grads_norm = 4.8097
	new_data_grads_norm = 6.2762
	old_data_grads_norm = 7.0385
	sim_grads_norm = -0.0026
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4780
	data_grads_norm = 4.1008
	new_data_grads_norm = 5.8849
	old_data_grads_norm = 5.1392
	sim_grads_norm = -0.0237
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6371
	data_grads_norm = 4.6885
	new_data_grads_norm = 6.5476
	old_data_grads_norm = 6.8308
	sim_grads_norm = 0.0180
-- Starting training on experience 141 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1281
	data_grads_norm = 4.1047
	new_data_grads_norm = 5.6947
	old_data_grads_norm = 4.3917
	sim_grads_norm = -0.0122
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1330
	data_grads_norm = 3.7463
	new_data_grads_norm = 5.8437
	old_data_grads_norm = 5.0590
	sim_grads_norm = -0.0139
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6692
	data_grads_norm = 4.8287
	new_data_grads_norm = 5.7391
	old_data_grads_norm = 6.7622
	sim_grads_norm = -0.0401
-- Starting training on experience 142 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1129
	data_grads_norm = 4.3586
	new_data_grads_norm = 6.8041
	old_data_grads_norm = 4.4172
	sim_grads_norm = 0.1046
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0891
	data_grads_norm = 3.6484
	new_data_grads_norm = 5.5526
	old_data_grads_norm = 4.3094
	sim_grads_norm = -0.0028
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8554
	data_grads_norm = 4.2594
	new_data_grads_norm = 6.0784
	old_data_grads_norm = 5.6069
	sim_grads_norm = 0.0913
-- Starting training on experience 143 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1833
	data_grads_norm = 3.7809
	new_data_grads_norm = 5.2134
	old_data_grads_norm = 4.9819
	sim_grads_norm = -0.0193
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7925
	data_grads_norm = 4.4309
	new_data_grads_norm = 5.3422
	old_data_grads_norm = 6.1281
	sim_grads_norm = -0.0023
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6700
	data_grads_norm = 4.4656
	new_data_grads_norm = 5.8846
	old_data_grads_norm = 4.8970
	sim_grads_norm = 0.0001
-- Starting training on experience 144 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3651
	data_grads_norm = 4.4197
	new_data_grads_norm = 6.4308
	old_data_grads_norm = 5.1016
	sim_grads_norm = 0.0132
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5135
	data_grads_norm = 4.3453
	new_data_grads_norm = 6.4463
	old_data_grads_norm = 4.6407
	sim_grads_norm = 0.0387
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2430
	data_grads_norm = 4.0645
	new_data_grads_norm = 6.1148
	old_data_grads_norm = 4.3704
	sim_grads_norm = 0.0023
-- Starting training on experience 145 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9259
	data_grads_norm = 4.2756
	new_data_grads_norm = 6.7138
	old_data_grads_norm = 5.9531
	sim_grads_norm = 0.0267
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0839
	data_grads_norm = 4.2502
	new_data_grads_norm = 6.2158
	old_data_grads_norm = 5.7141
	sim_grads_norm = -0.0247
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8210
	data_grads_norm = 3.5714
	new_data_grads_norm = 6.5785
	old_data_grads_norm = 3.9248
	sim_grads_norm = -0.0263
-- Starting training on experience 146 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4717
	data_grads_norm = 4.3342
	new_data_grads_norm = 5.8409
	old_data_grads_norm = 5.8914
	sim_grads_norm = 0.0121
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7813
	data_grads_norm = 5.1351
	new_data_grads_norm = 6.5582
	old_data_grads_norm = 7.0559
	sim_grads_norm = 0.0393
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2376
	data_grads_norm = 3.8518
	new_data_grads_norm = 5.7872
	old_data_grads_norm = 4.3143
	sim_grads_norm = 0.0025
-- Starting training on experience 147 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4092
	data_grads_norm = 4.6761
	new_data_grads_norm = 6.7325
	old_data_grads_norm = 6.5646
	sim_grads_norm = -0.0117
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0656
	data_grads_norm = 3.9062
	new_data_grads_norm = 7.7364
	old_data_grads_norm = 2.5626
	sim_grads_norm = -0.0174
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5573
	data_grads_norm = 4.8953
	new_data_grads_norm = 7.6300
	old_data_grads_norm = 5.3085
	sim_grads_norm = 0.0114
-- Starting training on experience 148 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1976
	data_grads_norm = 4.6135
	new_data_grads_norm = 6.2268
	old_data_grads_norm = 5.8577
	sim_grads_norm = -0.0120
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9019
	data_grads_norm = 4.1861
	new_data_grads_norm = 5.7420
	old_data_grads_norm = 5.0730
	sim_grads_norm = -0.0056
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6801
	data_grads_norm = 4.9913
	new_data_grads_norm = 6.9470
	old_data_grads_norm = 6.0027
	sim_grads_norm = 0.0996
-- Starting training on experience 149 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1906
	data_grads_norm = 4.1341
	new_data_grads_norm = 6.5884
	old_data_grads_norm = 4.6337
	sim_grads_norm = -0.0120
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4688
	data_grads_norm = 5.3811
	new_data_grads_norm = 6.8316
	old_data_grads_norm = 7.3838
	sim_grads_norm = 0.0838
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3764
	data_grads_norm = 4.9345
	new_data_grads_norm = 6.3568
	old_data_grads_norm = 6.9759
	sim_grads_norm = 0.0408
-- Starting training on experience 150 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5558
	data_grads_norm = 4.7533
	new_data_grads_norm = 6.7112
	old_data_grads_norm = 5.9987
	sim_grads_norm = 0.0169
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2955
	data_grads_norm = 4.1882
	new_data_grads_norm = 6.9249
	old_data_grads_norm = 5.6991
	sim_grads_norm = 0.0119
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6989
	data_grads_norm = 4.8720
	new_data_grads_norm = 6.1395
	old_data_grads_norm = 6.3064
	sim_grads_norm = 0.0075
-- Starting training on experience 151 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7237
	data_grads_norm = 3.9660
	new_data_grads_norm = 5.8723
	old_data_grads_norm = 5.2716
	sim_grads_norm = 0.0035
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9527
	data_grads_norm = 4.4665
	new_data_grads_norm = 6.4742
	old_data_grads_norm = 5.9029
	sim_grads_norm = 0.0626
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3948
	data_grads_norm = 3.9697
	new_data_grads_norm = 5.6632
	old_data_grads_norm = 5.6551
	sim_grads_norm = 0.0401
-- Starting training on experience 152 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2980
	data_grads_norm = 4.2361
	new_data_grads_norm = 6.0307
	old_data_grads_norm = 6.3737
	sim_grads_norm = -0.0017
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0292
	data_grads_norm = 3.5493
	new_data_grads_norm = 6.0483
	old_data_grads_norm = 3.7683
	sim_grads_norm = -0.0093
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3536
	data_grads_norm = 3.9713
	new_data_grads_norm = 6.2414
	old_data_grads_norm = 5.0760
	sim_grads_norm = -0.0164
-- Starting training on experience 153 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9173
	data_grads_norm = 3.7507
	new_data_grads_norm = 5.3937
	old_data_grads_norm = 5.0669
	sim_grads_norm = 0.0375
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5822
	data_grads_norm = 3.5662
	new_data_grads_norm = 5.8240
	old_data_grads_norm = 4.8744
	sim_grads_norm = 0.0111
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0646
	data_grads_norm = 4.2725
	new_data_grads_norm = 5.2462
	old_data_grads_norm = 5.3230
	sim_grads_norm = 0.0196
-- Starting training on experience 154 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7020
	data_grads_norm = 5.0097
	new_data_grads_norm = 7.4565
	old_data_grads_norm = 6.3369
	sim_grads_norm = 0.0620
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6410
	data_grads_norm = 5.3909
	new_data_grads_norm = 7.4592
	old_data_grads_norm = 6.7394
	sim_grads_norm = 0.0396
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1880
	data_grads_norm = 4.6223
	new_data_grads_norm = 7.4821
	old_data_grads_norm = 5.9682
	sim_grads_norm = -0.0026
-- Starting training on experience 155 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3731
	data_grads_norm = 4.4588
	new_data_grads_norm = 5.5112
	old_data_grads_norm = 5.6300
	sim_grads_norm = -0.0352
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3931
	data_grads_norm = 4.6137
	new_data_grads_norm = 6.2476
	old_data_grads_norm = 6.0529
	sim_grads_norm = 0.0169
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9687
	data_grads_norm = 4.1634
	new_data_grads_norm = 5.7683
	old_data_grads_norm = 4.5269
	sim_grads_norm = 0.0413
-- Starting training on experience 156 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0247
	data_grads_norm = 4.6884
	new_data_grads_norm = 6.5595
	old_data_grads_norm = 6.8614
	sim_grads_norm = -0.0141
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7896
	data_grads_norm = 4.4845
	new_data_grads_norm = 6.9066
	old_data_grads_norm = 5.9042
	sim_grads_norm = 0.0427
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9605
	data_grads_norm = 4.2032
	new_data_grads_norm = 6.3874
	old_data_grads_norm = 5.0088
	sim_grads_norm = -0.0486
-- Starting training on experience 157 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9146
	data_grads_norm = 4.2300
	new_data_grads_norm = 6.1530
	old_data_grads_norm = 6.0859
	sim_grads_norm = 0.0573
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6801
	data_grads_norm = 4.8962
	new_data_grads_norm = 6.8959
	old_data_grads_norm = 6.0471
	sim_grads_norm = 0.0516
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2724
	data_grads_norm = 5.3601
	new_data_grads_norm = 6.4193
	old_data_grads_norm = 6.9812
	sim_grads_norm = -0.0086
-- Starting training on experience 158 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2660
	data_grads_norm = 3.9538
	new_data_grads_norm = 6.2626
	old_data_grads_norm = 4.9180
	sim_grads_norm = -0.0291
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6920
	data_grads_norm = 4.5844
	new_data_grads_norm = 6.9126
	old_data_grads_norm = 5.2526
	sim_grads_norm = -0.0296
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4151
	data_grads_norm = 4.1911
	new_data_grads_norm = 6.8169
	old_data_grads_norm = 5.4562
	sim_grads_norm = -0.0030
-- Starting training on experience 159 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0748
	data_grads_norm = 3.2736
	new_data_grads_norm = 5.7099
	old_data_grads_norm = 3.7936
	sim_grads_norm = -0.0166
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4062
	data_grads_norm = 4.7800
	new_data_grads_norm = 4.7187
	old_data_grads_norm = 7.8648
	sim_grads_norm = 0.0174
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9622
	data_grads_norm = 3.4457
	new_data_grads_norm = 5.4424
	old_data_grads_norm = 3.6326
	sim_grads_norm = -0.0986
-- Starting training on experience 160 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1439
	data_grads_norm = 4.4730
	new_data_grads_norm = 7.4870
	old_data_grads_norm = 5.7168
	sim_grads_norm = 0.0275
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4130
	data_grads_norm = 4.2359
	new_data_grads_norm = 6.7873
	old_data_grads_norm = 5.4224
	sim_grads_norm = -0.0228
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2211
	data_grads_norm = 4.0075
	new_data_grads_norm = 6.5377
	old_data_grads_norm = 5.9523
	sim_grads_norm = 0.0030
-- Starting training on experience 161 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1238
	data_grads_norm = 4.5924
	new_data_grads_norm = 7.2862
	old_data_grads_norm = 6.5299
	sim_grads_norm = -0.0290
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3670
	data_grads_norm = 5.3177
	new_data_grads_norm = 7.6033
	old_data_grads_norm = 7.5970
	sim_grads_norm = -0.0222
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0063
	data_grads_norm = 4.3325
	new_data_grads_norm = 6.8907
	old_data_grads_norm = 4.8252
	sim_grads_norm = 0.0008
-- Starting training on experience 162 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0377
	data_grads_norm = 4.8509
	new_data_grads_norm = 6.2763
	old_data_grads_norm = 5.5098
	sim_grads_norm = 0.0460
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8139
	data_grads_norm = 4.5841
	new_data_grads_norm = 6.5706
	old_data_grads_norm = 6.7586
	sim_grads_norm = -0.0323
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1504
	data_grads_norm = 4.7197
	new_data_grads_norm = 7.2981
	old_data_grads_norm = 4.9283
	sim_grads_norm = 0.0358
-- Starting training on experience 163 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4558
	data_grads_norm = 4.5300
	new_data_grads_norm = 6.5590
	old_data_grads_norm = 5.0620
	sim_grads_norm = -0.0291
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6612
	data_grads_norm = 4.0803
	new_data_grads_norm = 6.6904
	old_data_grads_norm = 4.0254
	sim_grads_norm = -0.0094
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7967
	data_grads_norm = 4.5720
	new_data_grads_norm = 6.9345
	old_data_grads_norm = 4.4950
	sim_grads_norm = 0.0799
-- Starting training on experience 164 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9314
	data_grads_norm = 4.9698
	new_data_grads_norm = 5.4276
	old_data_grads_norm = 7.8310
	sim_grads_norm = 0.0013
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6035
	data_grads_norm = 4.4273
	new_data_grads_norm = 5.9247
	old_data_grads_norm = 5.5411
	sim_grads_norm = 0.1875
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0093
	data_grads_norm = 3.7593
	new_data_grads_norm = 5.3290
	old_data_grads_norm = 5.0167
	sim_grads_norm = 0.0556
-- Starting training on experience 165 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2865
	data_grads_norm = 4.5520
	new_data_grads_norm = 6.1609
	old_data_grads_norm = 5.8535
	sim_grads_norm = 0.0604
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0193
	data_grads_norm = 4.1979
	new_data_grads_norm = 5.5274
	old_data_grads_norm = 6.2242
	sim_grads_norm = 0.0416
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0745
	data_grads_norm = 4.2030
	new_data_grads_norm = 5.5817
	old_data_grads_norm = 5.6728
	sim_grads_norm = 0.0943
-- Starting training on experience 166 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0065
	data_grads_norm = 4.3679
	new_data_grads_norm = 6.0113
	old_data_grads_norm = 5.9462
	sim_grads_norm = 0.0298
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8751
	data_grads_norm = 3.4336
	new_data_grads_norm = 5.1847
	old_data_grads_norm = 5.2819
	sim_grads_norm = -0.0602
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0292
	data_grads_norm = 3.5825
	new_data_grads_norm = 5.4306
	old_data_grads_norm = 4.4063
	sim_grads_norm = 0.0343
-- Starting training on experience 167 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1394
	data_grads_norm = 4.6569
	new_data_grads_norm = 6.8054
	old_data_grads_norm = 6.5514
	sim_grads_norm = -0.0012
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6843
	data_grads_norm = 3.7917
	new_data_grads_norm = 5.2969
	old_data_grads_norm = 6.1639
	sim_grads_norm = -0.0175
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5490
	data_grads_norm = 3.3417
	new_data_grads_norm = 6.4495
	old_data_grads_norm = 2.4670
	sim_grads_norm = -0.0776
-- Starting training on experience 168 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2281
	data_grads_norm = 3.3733
	new_data_grads_norm = 5.4606
	old_data_grads_norm = 4.0097
	sim_grads_norm = -0.0260
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8281
	data_grads_norm = 4.0646
	new_data_grads_norm = 6.2678
	old_data_grads_norm = 6.7461
	sim_grads_norm = -0.0224
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3135
	data_grads_norm = 4.0076
	new_data_grads_norm = 5.5790
	old_data_grads_norm = 5.3997
	sim_grads_norm = -0.0021
-- Starting training on experience 169 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3065
	data_grads_norm = 3.9378
	new_data_grads_norm = 5.3762
	old_data_grads_norm = 5.8192
	sim_grads_norm = -0.0192
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0130
	data_grads_norm = 4.1759
	new_data_grads_norm = 5.6294
	old_data_grads_norm = 5.4982
	sim_grads_norm = -0.0080
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6648
	data_grads_norm = 4.1554
	new_data_grads_norm = 5.5232
	old_data_grads_norm = 4.1590
	sim_grads_norm = -0.0259
-- Starting training on experience 170 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9820
	data_grads_norm = 3.4411
	new_data_grads_norm = 5.8172
	old_data_grads_norm = 4.4669
	sim_grads_norm = -0.0208
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3227
	data_grads_norm = 3.8116
	new_data_grads_norm = 6.1126
	old_data_grads_norm = 4.8212
	sim_grads_norm = -0.0186
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2037
	data_grads_norm = 3.7418
	new_data_grads_norm = 6.2360
	old_data_grads_norm = 5.5158
	sim_grads_norm = 0.0154
-- Starting training on experience 171 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3539
	data_grads_norm = 4.3319
	new_data_grads_norm = 6.8929
	old_data_grads_norm = 4.0295
	sim_grads_norm = 0.0577
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6516
	data_grads_norm = 4.8044
	new_data_grads_norm = 7.3307
	old_data_grads_norm = 5.5757
	sim_grads_norm = 0.0161
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2626
	data_grads_norm = 4.3423
	new_data_grads_norm = 6.8715
	old_data_grads_norm = 3.5878
	sim_grads_norm = 0.0243
-- Starting training on experience 172 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1700
	data_grads_norm = 4.5964
	new_data_grads_norm = 5.7228
	old_data_grads_norm = 5.6870
	sim_grads_norm = 0.0567
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2177
	data_grads_norm = 3.6862
	new_data_grads_norm = 6.0715
	old_data_grads_norm = 5.5976
	sim_grads_norm = 0.0051
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4345
	data_grads_norm = 3.9201
	new_data_grads_norm = 5.8163
	old_data_grads_norm = 5.6770
	sim_grads_norm = 0.0707
-- Starting training on experience 173 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6381
	data_grads_norm = 3.9429
	new_data_grads_norm = 5.7226
	old_data_grads_norm = 5.1972
	sim_grads_norm = -0.0102
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2344
	data_grads_norm = 4.4006
	new_data_grads_norm = 5.7771
	old_data_grads_norm = 6.1536
	sim_grads_norm = -0.0199
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0264
	data_grads_norm = 4.5022
	new_data_grads_norm = 6.5357
	old_data_grads_norm = 6.1208
	sim_grads_norm = -0.0069
-- Starting training on experience 174 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4475
	data_grads_norm = 4.2086
	new_data_grads_norm = 6.3856
	old_data_grads_norm = 4.7707
	sim_grads_norm = 0.0696
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4379
	data_grads_norm = 4.2888
	new_data_grads_norm = 6.5295
	old_data_grads_norm = 5.3448
	sim_grads_norm = 0.0237
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1482
	data_grads_norm = 3.7930
	new_data_grads_norm = 6.9489
	old_data_grads_norm = 3.8397
	sim_grads_norm = 0.0132
-- Starting training on experience 175 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9074
	data_grads_norm = 4.0105
	new_data_grads_norm = 6.3600
	old_data_grads_norm = 5.4932
	sim_grads_norm = -0.0141
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2258
	data_grads_norm = 4.1179
	new_data_grads_norm = 6.9253
	old_data_grads_norm = 5.4814
	sim_grads_norm = -0.0206
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9227
	data_grads_norm = 4.0299
	new_data_grads_norm = 6.7962
	old_data_grads_norm = 5.0969
	sim_grads_norm = -0.0307
-- Starting training on experience 176 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7676
	data_grads_norm = 3.9573
	new_data_grads_norm = 5.8874
	old_data_grads_norm = 5.3273
	sim_grads_norm = 0.0655
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9602
	data_grads_norm = 4.2364
	new_data_grads_norm = 5.1665
	old_data_grads_norm = 6.5682
	sim_grads_norm = 0.0096
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5393
	data_grads_norm = 3.2763
	new_data_grads_norm = 5.6867
	old_data_grads_norm = 3.8424
	sim_grads_norm = -0.0130
-- Starting training on experience 177 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2228
	data_grads_norm = 4.7897
	new_data_grads_norm = 7.0043
	old_data_grads_norm = 5.1391
	sim_grads_norm = 0.0425
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4290
	data_grads_norm = 4.0111
	new_data_grads_norm = 6.1338
	old_data_grads_norm = 4.4206
	sim_grads_norm = -0.0136
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8660
	data_grads_norm = 4.0223
	new_data_grads_norm = 6.3537
	old_data_grads_norm = 4.2982
	sim_grads_norm = -0.0286
-- Starting training on experience 178 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6318
	data_grads_norm = 4.6705
	new_data_grads_norm = 5.9998
	old_data_grads_norm = 6.2658
	sim_grads_norm = 0.0111
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4263
	data_grads_norm = 3.2529
	new_data_grads_norm = 5.8563
	old_data_grads_norm = 4.4907
	sim_grads_norm = -0.0198
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7259
	data_grads_norm = 3.7723
	new_data_grads_norm = 6.1665
	old_data_grads_norm = 4.6071
	sim_grads_norm = 0.0157
-- Starting training on experience 179 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4501
	data_grads_norm = 5.0707
	new_data_grads_norm = 7.4853
	old_data_grads_norm = 5.2788
	sim_grads_norm = -0.0038
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7740
	data_grads_norm = 4.4607
	new_data_grads_norm = 7.0592
	old_data_grads_norm = 4.4694
	sim_grads_norm = -0.0200
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2562
	data_grads_norm = 4.6530
	new_data_grads_norm = 6.7954
	old_data_grads_norm = 4.6033
	sim_grads_norm = 0.0335
-- Starting training on experience 180 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8702
	data_grads_norm = 3.8379
	new_data_grads_norm = 5.4589
	old_data_grads_norm = 5.3827
	sim_grads_norm = 0.0063
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7739
	data_grads_norm = 3.9384
	new_data_grads_norm = 5.5316
	old_data_grads_norm = 6.0143
	sim_grads_norm = -0.0237
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8050
	data_grads_norm = 4.1946
	new_data_grads_norm = 6.1730
	old_data_grads_norm = 5.5165
	sim_grads_norm = -0.0525
-- Starting training on experience 181 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4731
	data_grads_norm = 4.7038
	new_data_grads_norm = 7.9132
	old_data_grads_norm = 5.0799
	sim_grads_norm = 0.0217
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3678
	data_grads_norm = 4.5930
	new_data_grads_norm = 7.6087
	old_data_grads_norm = 5.7742
	sim_grads_norm = 0.0164
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0942
	data_grads_norm = 5.2107
	new_data_grads_norm = 7.2098
	old_data_grads_norm = 6.8433
	sim_grads_norm = 0.0699
-- Starting training on experience 182 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4107
	data_grads_norm = 3.6312
	new_data_grads_norm = 5.8722
	old_data_grads_norm = 3.3914
	sim_grads_norm = -0.0088
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5013
	data_grads_norm = 3.5081
	new_data_grads_norm = 5.5835
	old_data_grads_norm = 4.6331
	sim_grads_norm = 0.0024
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4152
	data_grads_norm = 3.5701
	new_data_grads_norm = 5.8771
	old_data_grads_norm = 3.7199
	sim_grads_norm = -0.0040
-- Starting training on experience 183 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7896
	data_grads_norm = 5.9027
	new_data_grads_norm = 8.9567
	old_data_grads_norm = 5.0940
	sim_grads_norm = -0.0013
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8390
	data_grads_norm = 5.2010
	new_data_grads_norm = 8.5568
	old_data_grads_norm = 4.8175
	sim_grads_norm = 0.0535
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8529
	data_grads_norm = 5.3533
	new_data_grads_norm = 7.4947
	old_data_grads_norm = 5.5344
	sim_grads_norm = 0.0325
-- Starting training on experience 184 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8095
	data_grads_norm = 3.8649
	new_data_grads_norm = 5.4921
	old_data_grads_norm = 4.2863
	sim_grads_norm = -0.0106
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2922
	data_grads_norm = 4.6018
	new_data_grads_norm = 5.5045
	old_data_grads_norm = 6.1015
	sim_grads_norm = 0.1284
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6178
	data_grads_norm = 3.7350
	new_data_grads_norm = 5.2398
	old_data_grads_norm = 4.7885
	sim_grads_norm = -0.0083
-- Starting training on experience 185 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2365
	data_grads_norm = 4.2048
	new_data_grads_norm = 7.0573
	old_data_grads_norm = 5.0935
	sim_grads_norm = -0.0207
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3698
	data_grads_norm = 4.3168
	new_data_grads_norm = 6.7677
	old_data_grads_norm = 5.8298
	sim_grads_norm = -0.0238
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2166
	data_grads_norm = 3.9667
	new_data_grads_norm = 6.1456
	old_data_grads_norm = 4.6630
	sim_grads_norm = -0.0153
-- Starting training on experience 186 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4657
	data_grads_norm = 4.4494
	new_data_grads_norm = 6.0161
	old_data_grads_norm = 5.9990
	sim_grads_norm = 0.0893
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8247
	data_grads_norm = 4.1055
	new_data_grads_norm = 6.2050
	old_data_grads_norm = 4.9421
	sim_grads_norm = 0.0162
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0238
	data_grads_norm = 4.3884
	new_data_grads_norm = 5.6872
	old_data_grads_norm = 5.3919
	sim_grads_norm = 0.0277
-- Starting training on experience 187 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2876
	data_grads_norm = 5.5817
	new_data_grads_norm = 7.1000
	old_data_grads_norm = 7.7640
	sim_grads_norm = 0.0300
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7107
	data_grads_norm = 4.4622
	new_data_grads_norm = 6.7887
	old_data_grads_norm = 5.0646
	sim_grads_norm = 0.0248
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9013
	data_grads_norm = 4.8727
	new_data_grads_norm = 6.4403
	old_data_grads_norm = 6.0858
	sim_grads_norm = 0.1079
-- Starting training on experience 188 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0104
	data_grads_norm = 3.7113
	new_data_grads_norm = 5.1076
	old_data_grads_norm = 4.7916
	sim_grads_norm = 0.0623
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5076
	data_grads_norm = 3.2871
	new_data_grads_norm = 6.0450
	old_data_grads_norm = 4.3078
	sim_grads_norm = -0.0356
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3117
	data_grads_norm = 4.4418
	new_data_grads_norm = 5.8823
	old_data_grads_norm = 5.3912
	sim_grads_norm = 0.0389
-- Starting training on experience 189 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3363
	data_grads_norm = 4.2679
	new_data_grads_norm = 5.6258
	old_data_grads_norm = 5.8954
	sim_grads_norm = -0.0185
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2496
	data_grads_norm = 4.4198
	new_data_grads_norm = 6.1222
	old_data_grads_norm = 6.6092
	sim_grads_norm = -0.0045
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3070
	data_grads_norm = 4.2227
	new_data_grads_norm = 6.8514
	old_data_grads_norm = 4.8607
	sim_grads_norm = -0.0181
-- Starting training on experience 190 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3155
	data_grads_norm = 4.3087
	new_data_grads_norm = 5.3665
	old_data_grads_norm = 6.7131
	sim_grads_norm = 0.0394
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9394
	data_grads_norm = 3.3615
	new_data_grads_norm = 5.7026
	old_data_grads_norm = 4.8656
	sim_grads_norm = -0.0130
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0042
	data_grads_norm = 4.1364
	new_data_grads_norm = 5.7625
	old_data_grads_norm = 5.5758
	sim_grads_norm = -0.0145
-- Starting training on experience 191 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0367
	data_grads_norm = 4.3672
	new_data_grads_norm = 6.0313
	old_data_grads_norm = 5.5572
	sim_grads_norm = 0.0739
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0025
	data_grads_norm = 4.5534
	new_data_grads_norm = 6.4054
	old_data_grads_norm = 5.6576
	sim_grads_norm = 0.0954
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9040
	data_grads_norm = 3.8594
	new_data_grads_norm = 5.4111
	old_data_grads_norm = 4.4334
	sim_grads_norm = 0.0413
-- Starting training on experience 192 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9177
	data_grads_norm = 3.3516
	new_data_grads_norm = 5.6966
	old_data_grads_norm = 4.5099
	sim_grads_norm = 0.0151
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3647
	data_grads_norm = 4.2318
	new_data_grads_norm = 6.4576
	old_data_grads_norm = 5.0069
	sim_grads_norm = -0.0064
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3092
	data_grads_norm = 4.7581
	new_data_grads_norm = 6.5395
	old_data_grads_norm = 6.9788
	sim_grads_norm = 0.0110
-- Starting training on experience 193 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8914
	data_grads_norm = 3.8220
	new_data_grads_norm = 4.4857
	old_data_grads_norm = 7.1213
	sim_grads_norm = -0.0211
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3803
	data_grads_norm = 4.6695
	new_data_grads_norm = 4.8810
	old_data_grads_norm = 7.5542
	sim_grads_norm = 0.0158
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3385
	data_grads_norm = 2.8086
	new_data_grads_norm = 4.6289
	old_data_grads_norm = 4.3003
	sim_grads_norm = -0.0218
-- Starting training on experience 194 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9777
	data_grads_norm = 4.7900
	new_data_grads_norm = 5.9407
	old_data_grads_norm = 6.6523
	sim_grads_norm = -0.0266
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8331
	data_grads_norm = 4.3570
	new_data_grads_norm = 6.4316
	old_data_grads_norm = 5.2336
	sim_grads_norm = 0.0122
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0500
	data_grads_norm = 4.3415
	new_data_grads_norm = 5.9032
	old_data_grads_norm = 6.3102
	sim_grads_norm = -0.0445
-- Starting training on experience 195 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0988
	data_grads_norm = 3.7774
	new_data_grads_norm = 6.4880
	old_data_grads_norm = 3.8454
	sim_grads_norm = 0.0736
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4330
	data_grads_norm = 4.4889
	new_data_grads_norm = 6.3993
	old_data_grads_norm = 5.9671
	sim_grads_norm = -0.0216
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2259
	data_grads_norm = 3.9483
	new_data_grads_norm = 6.2273
	old_data_grads_norm = 4.6979
	sim_grads_norm = -0.0111
-- Starting training on experience 196 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0361
	data_grads_norm = 3.5905
	new_data_grads_norm = 6.1935
	old_data_grads_norm = 4.2927
	sim_grads_norm = 0.0405
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3521
	data_grads_norm = 4.0468
	new_data_grads_norm = 6.0337
	old_data_grads_norm = 4.2224
	sim_grads_norm = 0.0586
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3473
	data_grads_norm = 4.5971
	new_data_grads_norm = 6.2901
	old_data_grads_norm = 4.2707
	sim_grads_norm = 0.0063
-- Starting training on experience 197 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5722
	data_grads_norm = 4.4342
	new_data_grads_norm = 6.4117
	old_data_grads_norm = 5.6880
	sim_grads_norm = 0.0380
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3272
	data_grads_norm = 4.8423
	new_data_grads_norm = 6.8172
	old_data_grads_norm = 6.3303
	sim_grads_norm = 0.0056
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1631
	data_grads_norm = 4.6681
	new_data_grads_norm = 6.4132
	old_data_grads_norm = 6.2999
	sim_grads_norm = 0.0036
-- Starting training on experience 198 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9945
	data_grads_norm = 4.3207
	new_data_grads_norm = 6.3989
	old_data_grads_norm = 4.4342
	sim_grads_norm = 0.0645
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2000
	data_grads_norm = 4.8076
	new_data_grads_norm = 7.0437
	old_data_grads_norm = 5.4579
	sim_grads_norm = 0.0253
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5250
	data_grads_norm = 3.8044
	new_data_grads_norm = 6.9705
	old_data_grads_norm = 4.6413
	sim_grads_norm = -0.0274
-- Starting training on experience 199 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3984
	data_grads_norm = 5.1348
	new_data_grads_norm = 7.7061
	old_data_grads_norm = 5.9195
	sim_grads_norm = 0.0128
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1143
	data_grads_norm = 4.1532
	new_data_grads_norm = 6.8128
	old_data_grads_norm = 5.6428
	sim_grads_norm = 0.0617
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7786
	data_grads_norm = 4.3138
	new_data_grads_norm = 6.7662
	old_data_grads_norm = 4.1839
	sim_grads_norm = 0.0045
-- Starting training on experience 200 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8507
	data_grads_norm = 4.3000
	new_data_grads_norm = 5.8272
	old_data_grads_norm = 5.9873
	sim_grads_norm = 0.0137
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6413
	data_grads_norm = 3.5702
	new_data_grads_norm = 5.0560
	old_data_grads_norm = 5.8728
	sim_grads_norm = -0.0531
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8687
	data_grads_norm = 3.9835
	new_data_grads_norm = 5.4286
	old_data_grads_norm = 6.2383
	sim_grads_norm = -0.0355
-- Starting training on experience 201 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8294
	data_grads_norm = 5.0580
	new_data_grads_norm = 6.8334
	old_data_grads_norm = 7.4698
	sim_grads_norm = 0.0350
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6308
	data_grads_norm = 5.0950
	new_data_grads_norm = 6.9531
	old_data_grads_norm = 7.1487
	sim_grads_norm = 0.0204
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6613
	data_grads_norm = 3.5032
	new_data_grads_norm = 6.3456
	old_data_grads_norm = 3.4927
	sim_grads_norm = -0.0403
-- Starting training on experience 202 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1951
	data_grads_norm = 3.9305
	new_data_grads_norm = 6.3974
	old_data_grads_norm = 5.1206
	sim_grads_norm = 0.0756
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3168
	data_grads_norm = 4.2891
	new_data_grads_norm = 6.8340
	old_data_grads_norm = 4.6643
	sim_grads_norm = 0.0300
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3676
	data_grads_norm = 4.4063
	new_data_grads_norm = 6.7446
	old_data_grads_norm = 5.5551
	sim_grads_norm = 0.0168
-- Starting training on experience 203 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5668
	data_grads_norm = 4.1947
	new_data_grads_norm = 5.7084
	old_data_grads_norm = 7.1076
	sim_grads_norm = 0.0526
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8583
	data_grads_norm = 3.4870
	new_data_grads_norm = 5.3306
	old_data_grads_norm = 5.3342
	sim_grads_norm = -0.0077
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2879
	data_grads_norm = 4.3159
	new_data_grads_norm = 5.5691
	old_data_grads_norm = 5.2144
	sim_grads_norm = 0.0415
-- Starting training on experience 204 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9392
	data_grads_norm = 4.4414
	new_data_grads_norm = 6.6863
	old_data_grads_norm = 5.3900
	sim_grads_norm = -0.0164
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2128
	data_grads_norm = 4.1498
	new_data_grads_norm = 7.0574
	old_data_grads_norm = 3.2133
	sim_grads_norm = 0.0132
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1179
	data_grads_norm = 4.0524
	new_data_grads_norm = 6.4247
	old_data_grads_norm = 5.8406
	sim_grads_norm = 0.0484
-- Starting training on experience 205 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1376
	data_grads_norm = 5.4983
	new_data_grads_norm = 6.8336
	old_data_grads_norm = 8.9104
	sim_grads_norm = -0.0248
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5293
	data_grads_norm = 4.1797
	new_data_grads_norm = 7.1759
	old_data_grads_norm = 4.5612
	sim_grads_norm = -0.0127
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5286
	data_grads_norm = 5.2674
	new_data_grads_norm = 6.5004
	old_data_grads_norm = 7.7601
	sim_grads_norm = 0.0732
-- Starting training on experience 206 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7020
	data_grads_norm = 3.5298
	new_data_grads_norm = 5.9361
	old_data_grads_norm = 4.5064
	sim_grads_norm = -0.0344
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4154
	data_grads_norm = 4.5645
	new_data_grads_norm = 5.8221
	old_data_grads_norm = 6.8350
	sim_grads_norm = -0.0042
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3431
	data_grads_norm = 4.5964
	new_data_grads_norm = 6.2565
	old_data_grads_norm = 6.1635
	sim_grads_norm = 0.0216
-- Starting training on experience 207 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5163
	data_grads_norm = 4.3899
	new_data_grads_norm = 6.2175
	old_data_grads_norm = 6.1016
	sim_grads_norm = 0.0571
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0983
	data_grads_norm = 4.2549
	new_data_grads_norm = 5.8579
	old_data_grads_norm = 5.2756
	sim_grads_norm = -0.0355
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1477
	data_grads_norm = 4.4481
	new_data_grads_norm = 5.9564
	old_data_grads_norm = 5.8012
	sim_grads_norm = 0.0341
-- Starting training on experience 208 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9574
	data_grads_norm = 3.9267
	new_data_grads_norm = 6.3442
	old_data_grads_norm = 5.7708
	sim_grads_norm = 0.0276
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7754
	data_grads_norm = 3.6981
	new_data_grads_norm = 5.6692
	old_data_grads_norm = 5.1406
	sim_grads_norm = 0.0321
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1507
	data_grads_norm = 3.8312
	new_data_grads_norm = 5.5739
	old_data_grads_norm = 4.8762
	sim_grads_norm = 0.0094
-- Starting training on experience 209 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3987
	data_grads_norm = 4.4139
	new_data_grads_norm = 5.6131
	old_data_grads_norm = 6.2398
	sim_grads_norm = 0.0188
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0841
	data_grads_norm = 3.5328
	new_data_grads_norm = 5.1604
	old_data_grads_norm = 6.0735
	sim_grads_norm = -0.0474
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2460
	data_grads_norm = 3.4975
	new_data_grads_norm = 5.7136
	old_data_grads_norm = 3.7166
	sim_grads_norm = -0.0291
-- Starting training on experience 210 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4904
	data_grads_norm = 4.7111
	new_data_grads_norm = 6.6757
	old_data_grads_norm = 6.9282
	sim_grads_norm = 0.0238
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7530
	data_grads_norm = 4.2812
	new_data_grads_norm = 6.4549
	old_data_grads_norm = 5.6131
	sim_grads_norm = 0.0034
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8169
	data_grads_norm = 3.7836
	new_data_grads_norm = 6.2822
	old_data_grads_norm = 3.9277
	sim_grads_norm = 0.1237
-- Starting training on experience 211 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5217
	data_grads_norm = 3.1159
	new_data_grads_norm = 5.9239
	old_data_grads_norm = 2.8147
	sim_grads_norm = -0.0056
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7655
	data_grads_norm = 3.6260
	new_data_grads_norm = 5.7070
	old_data_grads_norm = 5.2315
	sim_grads_norm = -0.0456
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9066
	data_grads_norm = 3.7754
	new_data_grads_norm = 6.1399
	old_data_grads_norm = 4.6085
	sim_grads_norm = -0.0138
-- Starting training on experience 212 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4381
	data_grads_norm = 3.4694
	new_data_grads_norm = 5.3417
	old_data_grads_norm = 4.3585
	sim_grads_norm = -0.0576
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3113
	data_grads_norm = 3.2219
	new_data_grads_norm = 5.4476
	old_data_grads_norm = 3.1939
	sim_grads_norm = -0.0286
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6448
	data_grads_norm = 3.8147
	new_data_grads_norm = 4.9376
	old_data_grads_norm = 5.0129
	sim_grads_norm = -0.0338
-- Starting training on experience 213 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9668
	data_grads_norm = 4.5182
	new_data_grads_norm = 6.5430
	old_data_grads_norm = 4.7393
	sim_grads_norm = 0.0558
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9074
	data_grads_norm = 4.3135
	new_data_grads_norm = 5.4321
	old_data_grads_norm = 7.1595
	sim_grads_norm = -0.0388
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8357
	data_grads_norm = 4.2850
	new_data_grads_norm = 6.4893
	old_data_grads_norm = 6.4905
	sim_grads_norm = -0.0336
-- Starting training on experience 214 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6075
	data_grads_norm = 3.8681
	new_data_grads_norm = 5.9209
	old_data_grads_norm = 3.7329
	sim_grads_norm = -0.0331
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0058
	data_grads_norm = 4.2225
	new_data_grads_norm = 6.3357
	old_data_grads_norm = 5.9814
	sim_grads_norm = 0.0345
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7205
	data_grads_norm = 3.9354
	new_data_grads_norm = 5.6454
	old_data_grads_norm = 5.8791
	sim_grads_norm = -0.0397
-- Starting training on experience 215 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6508
	data_grads_norm = 5.3056
	new_data_grads_norm = 6.5831
	old_data_grads_norm = 7.3073
	sim_grads_norm = -0.0168
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2002
	data_grads_norm = 4.3341
	new_data_grads_norm = 6.4437
	old_data_grads_norm = 5.2720
	sim_grads_norm = 0.0041
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1903
	data_grads_norm = 3.6662
	new_data_grads_norm = 6.3965
	old_data_grads_norm = 3.3896
	sim_grads_norm = 0.0142
-- Starting training on experience 216 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2807
	data_grads_norm = 3.9928
	new_data_grads_norm = 5.6621
	old_data_grads_norm = 5.8956
	sim_grads_norm = -0.0139
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4903
	data_grads_norm = 4.6560
	new_data_grads_norm = 5.3908
	old_data_grads_norm = 7.5251
	sim_grads_norm = 0.0086
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7512
	data_grads_norm = 5.3407
	new_data_grads_norm = 7.3656
	old_data_grads_norm = 6.9152
	sim_grads_norm = -0.0118
-- Starting training on experience 217 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7037
	data_grads_norm = 4.1096
	new_data_grads_norm = 6.4502
	old_data_grads_norm = 5.0460
	sim_grads_norm = -0.0220
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2966
	data_grads_norm = 4.3353
	new_data_grads_norm = 7.2622
	old_data_grads_norm = 5.0687
	sim_grads_norm = 0.0317
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4098
	data_grads_norm = 4.2774
	new_data_grads_norm = 6.8588
	old_data_grads_norm = 5.4887
	sim_grads_norm = -0.0038
-- Starting training on experience 218 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1119
	data_grads_norm = 4.1683
	new_data_grads_norm = 5.9442
	old_data_grads_norm = 5.8899
	sim_grads_norm = 0.0325
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8212
	data_grads_norm = 3.3116
	new_data_grads_norm = 5.4974
	old_data_grads_norm = 3.9137
	sim_grads_norm = -0.0836
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7058
	data_grads_norm = 4.5457
	new_data_grads_norm = 5.7499
	old_data_grads_norm = 6.8105
	sim_grads_norm = -0.0200
-- Starting training on experience 219 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5909
	data_grads_norm = 4.6481
	new_data_grads_norm = 6.5385
	old_data_grads_norm = 6.6149
	sim_grads_norm = -0.0253
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0481
	data_grads_norm = 4.5051
	new_data_grads_norm = 5.8190
	old_data_grads_norm = 6.9005
	sim_grads_norm = -0.0158
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1912
	data_grads_norm = 4.2640
	new_data_grads_norm = 7.0702
	old_data_grads_norm = 4.7516
	sim_grads_norm = 0.0270
-- Starting training on experience 220 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7520
	data_grads_norm = 3.5706
	new_data_grads_norm = 5.6011
	old_data_grads_norm = 3.5922
	sim_grads_norm = 0.0956
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8659
	data_grads_norm = 3.5612
	new_data_grads_norm = 6.0263
	old_data_grads_norm = 3.7604
	sim_grads_norm = -0.0131
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4761
	data_grads_norm = 4.7040
	new_data_grads_norm = 6.0130
	old_data_grads_norm = 6.5972
	sim_grads_norm = 0.0078
-- Starting training on experience 221 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4924
	data_grads_norm = 4.4887
	new_data_grads_norm = 6.6600
	old_data_grads_norm = 5.3204
	sim_grads_norm = 0.1054
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4692
	data_grads_norm = 4.2722
	new_data_grads_norm = 7.3903
	old_data_grads_norm = 4.6080
	sim_grads_norm = 0.0537
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0785
	data_grads_norm = 4.3777
	new_data_grads_norm = 6.7211
	old_data_grads_norm = 5.4122
	sim_grads_norm = -0.0235
-- Starting training on experience 222 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0728
	data_grads_norm = 4.1866
	new_data_grads_norm = 5.8132
	old_data_grads_norm = 5.2830
	sim_grads_norm = 0.0049
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9736
	data_grads_norm = 4.3574
	new_data_grads_norm = 6.7640
	old_data_grads_norm = 5.6887
	sim_grads_norm = -0.0164
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4593
	data_grads_norm = 4.3031
	new_data_grads_norm = 6.3138
	old_data_grads_norm = 6.6380
	sim_grads_norm = 0.0019
-- Starting training on experience 223 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3769
	data_grads_norm = 4.4192
	new_data_grads_norm = 6.4048
	old_data_grads_norm = 5.0330
	sim_grads_norm = -0.0156
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2208
	data_grads_norm = 4.0602
	new_data_grads_norm = 6.6733
	old_data_grads_norm = 4.3635
	sim_grads_norm = -0.0295
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0940
	data_grads_norm = 4.1106
	new_data_grads_norm = 6.6757
	old_data_grads_norm = 3.8373
	sim_grads_norm = 0.0128
-- Starting training on experience 224 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0343
	data_grads_norm = 3.9339
	new_data_grads_norm = 6.8352
	old_data_grads_norm = 3.6019
	sim_grads_norm = -0.0033
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2643
	data_grads_norm = 4.1173
	new_data_grads_norm = 5.8396
	old_data_grads_norm = 5.7327
	sim_grads_norm = -0.0044
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4821
	data_grads_norm = 4.0746
	new_data_grads_norm = 5.8796
	old_data_grads_norm = 5.1129
	sim_grads_norm = 0.0354
-- Starting training on experience 225 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3859
	data_grads_norm = 4.6142
	new_data_grads_norm = 6.6631
	old_data_grads_norm = 5.8856
	sim_grads_norm = 0.0095
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5281
	data_grads_norm = 4.0543
	new_data_grads_norm = 6.6555
	old_data_grads_norm = 4.8159
	sim_grads_norm = 0.0477
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2711
	data_grads_norm = 4.3608
	new_data_grads_norm = 7.0343
	old_data_grads_norm = 6.6513
	sim_grads_norm = -0.0309
-- Starting training on experience 226 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9341
	data_grads_norm = 4.2016
	new_data_grads_norm = 6.0396
	old_data_grads_norm = 5.6485
	sim_grads_norm = -0.0121
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4995
	data_grads_norm = 3.5700
	new_data_grads_norm = 6.5149
	old_data_grads_norm = 4.6813
	sim_grads_norm = -0.0190
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6163
	data_grads_norm = 3.5771
	new_data_grads_norm = 6.0463
	old_data_grads_norm = 3.7344
	sim_grads_norm = -0.0117
-- Starting training on experience 227 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3417
	data_grads_norm = 4.7174
	new_data_grads_norm = 6.3308
	old_data_grads_norm = 7.4026
	sim_grads_norm = 0.0163
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7093
	data_grads_norm = 4.0577
	new_data_grads_norm = 6.4488
	old_data_grads_norm = 5.7571
	sim_grads_norm = -0.0005
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8899
	data_grads_norm = 4.1051
	new_data_grads_norm = 7.0026
	old_data_grads_norm = 4.9515
	sim_grads_norm = 0.0096
-- Starting training on experience 228 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7727
	data_grads_norm = 3.8343
	new_data_grads_norm = 6.3073
	old_data_grads_norm = 5.3529
	sim_grads_norm = -0.0256
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0507
	data_grads_norm = 4.3046
	new_data_grads_norm = 6.2141
	old_data_grads_norm = 7.2984
	sim_grads_norm = -0.0095
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4144
	data_grads_norm = 4.5215
	new_data_grads_norm = 5.7704
	old_data_grads_norm = 6.1596
	sim_grads_norm = 0.0483
-- Starting training on experience 229 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3500
	data_grads_norm = 4.3599
	new_data_grads_norm = 6.7474
	old_data_grads_norm = 4.8563
	sim_grads_norm = 0.0168
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1586
	data_grads_norm = 4.6298
	new_data_grads_norm = 6.8762
	old_data_grads_norm = 5.2828
	sim_grads_norm = 0.0298
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0820
	data_grads_norm = 3.7369
	new_data_grads_norm = 6.8467
	old_data_grads_norm = 4.7045
	sim_grads_norm = -0.0371
-- Starting training on experience 230 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9135
	data_grads_norm = 5.0292
	new_data_grads_norm = 6.2008
	old_data_grads_norm = 8.1972
	sim_grads_norm = -0.0079
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0121
	data_grads_norm = 4.1087
	new_data_grads_norm = 5.9857
	old_data_grads_norm = 4.5894
	sim_grads_norm = 0.0464
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5872
	data_grads_norm = 4.4795
	new_data_grads_norm = 6.4262
	old_data_grads_norm = 6.1685
	sim_grads_norm = 0.0275
-- Starting training on experience 231 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9877
	data_grads_norm = 4.9005
	new_data_grads_norm = 6.5466
	old_data_grads_norm = 5.9507
	sim_grads_norm = -0.0259
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6479
	data_grads_norm = 4.5379
	new_data_grads_norm = 6.7822
	old_data_grads_norm = 6.6584
	sim_grads_norm = 0.0079
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6172
	data_grads_norm = 4.2933
	new_data_grads_norm = 5.8522
	old_data_grads_norm = 4.6378
	sim_grads_norm = 0.0842
-- Starting training on experience 232 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1173
	data_grads_norm = 3.6646
	new_data_grads_norm = 6.1071
	old_data_grads_norm = 4.9259
	sim_grads_norm = 0.0696
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0236
	data_grads_norm = 3.7853
	new_data_grads_norm = 5.8273
	old_data_grads_norm = 5.0289
	sim_grads_norm = 0.0528
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9615
	data_grads_norm = 3.4106
	new_data_grads_norm = 5.8712
	old_data_grads_norm = 3.8335
	sim_grads_norm = -0.0158
-- Starting training on experience 233 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1025
	data_grads_norm = 4.0066
	new_data_grads_norm = 6.8296
	old_data_grads_norm = 5.7474
	sim_grads_norm = -0.0557
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2995
	data_grads_norm = 4.6808
	new_data_grads_norm = 6.4202
	old_data_grads_norm = 5.2207
	sim_grads_norm = -0.0214
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1609
	data_grads_norm = 4.0496
	new_data_grads_norm = 6.9719
	old_data_grads_norm = 4.1319
	sim_grads_norm = -0.0252
-- Starting training on experience 234 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8348
	data_grads_norm = 4.9713
	new_data_grads_norm = 7.4078
	old_data_grads_norm = 4.8338
	sim_grads_norm = 0.0186
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0858
	data_grads_norm = 4.0022
	new_data_grads_norm = 6.7067
	old_data_grads_norm = 4.2056
	sim_grads_norm = -0.0344
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3088
	data_grads_norm = 4.8032
	new_data_grads_norm = 6.7775
	old_data_grads_norm = 6.1211
	sim_grads_norm = 0.0009
-- Starting training on experience 235 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0418
	data_grads_norm = 4.4564
	new_data_grads_norm = 6.4751
	old_data_grads_norm = 5.5742
	sim_grads_norm = -0.0055
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0982
	data_grads_norm = 4.3873
	new_data_grads_norm = 6.5628
	old_data_grads_norm = 5.3508
	sim_grads_norm = 0.0075
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8802
	data_grads_norm = 4.5803
	new_data_grads_norm = 6.2157
	old_data_grads_norm = 7.1666
	sim_grads_norm = -0.0353
-- Starting training on experience 236 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6811
	data_grads_norm = 4.4613
	new_data_grads_norm = 7.3626
	old_data_grads_norm = 4.9279
	sim_grads_norm = 0.0060
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0945
	data_grads_norm = 5.3440
	new_data_grads_norm = 7.2445
	old_data_grads_norm = 6.9274
	sim_grads_norm = 0.0340
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5906
	data_grads_norm = 4.6574
	new_data_grads_norm = 8.3320
	old_data_grads_norm = 5.5102
	sim_grads_norm = 0.0051
-- Starting training on experience 237 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
-- >> End of training phase << --
-- >> Start of eval phase << --
-- Starting eval on experience 0 (Task 0) from test stream --
> Eval on experience 0 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp000 = 3.3002
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.2600
	mb_index = 3570
	time = 1017.6992
-- Starting eval on experience 1 (Task 0) from test stream --
> Eval on experience 1 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp001 = 2.5732
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.4620
-- Starting eval on experience 2 (Task 0) from test stream --
> Eval on experience 2 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp002 = 3.9618
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.2780
-- Starting eval on experience 3 (Task 0) from test stream --
> Eval on experience 3 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp003 = 3.5140
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.3520
-- Starting eval on experience 4 (Task 0) from test stream --
> Eval on experience 4 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp004 = 4.0955
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.2760
-- Starting eval on experience 5 (Task 0) from test stream --
> Eval on experience 5 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp005 = 3.4991
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.3220
-- Starting eval on experience 6 (Task 0) from test stream --
> Eval on experience 6 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp006 = 3.3574
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp006 = 0.3200
-- Starting eval on experience 7 (Task 0) from test stream --
> Eval on experience 7 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp007 = 3.6398
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp007 = 0.3500
-- Starting eval on experience 8 (Task 0) from test stream --
> Eval on experience 8 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp008 = 3.0269
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp008 = 0.3220
-- Starting eval on experience 9 (Task 0) from test stream --
> Eval on experience 9 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp009 = 3.4872
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp009 = 0.2880
-- Starting eval on experience 10 (Task 0) from test stream --
> Eval on experience 10 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp010 = 3.5556
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp010 = 0.2080
-- Starting eval on experience 11 (Task 0) from test stream --
> Eval on experience 11 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp011 = 2.5842
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp011 = 0.3960
-- Starting eval on experience 12 (Task 0) from test stream --
> Eval on experience 12 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp012 = 3.5842
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp012 = 0.1560
-- Starting eval on experience 13 (Task 0) from test stream --
> Eval on experience 13 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp013 = 2.6277
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp013 = 0.3160
-- Starting eval on experience 14 (Task 0) from test stream --
> Eval on experience 14 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp014 = 3.1703
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp014 = 0.1440
-- >> End of eval phase << --
	CumulativeAccuracy/eval_phase/test_stream/Exp000 = 0.7480
	CumulativeAccuracy/eval_phase/test_stream/Exp001 = 0.6970
	CumulativeAccuracy/eval_phase/test_stream/Exp002 = 0.5813
	CumulativeAccuracy/eval_phase/test_stream/Exp003 = 0.5445
	CumulativeAccuracy/eval_phase/test_stream/Exp004 = 0.4920
	CumulativeAccuracy/eval_phase/test_stream/Exp005 = 0.4593
	CumulativeAccuracy/eval_phase/test_stream/Exp006 = 0.4331
	CumulativeAccuracy/eval_phase/test_stream/Exp007 = 0.4150
	CumulativeAccuracy/eval_phase/test_stream/Exp008 = 0.3960
	CumulativeAccuracy/eval_phase/test_stream/Exp009 = 0.3864
	CumulativeAccuracy/eval_phase/test_stream/Exp010 = 0.3598
	CumulativeAccuracy/eval_phase/test_stream/Exp011 = 0.3522
	CumulativeAccuracy/eval_phase/test_stream/Exp012 = 0.3272
	CumulativeAccuracy/eval_phase/test_stream/Exp013 = 0.3109
	CumulativeAccuracy/eval_phase/test_stream/Exp014 = 0.2967
	Loss_Stream/eval_phase/test_stream/Task000 = 3.3318
	Top1_Acc_Stream/eval_phase/test_stream/Task000 = 0.2967
-- >> Start of training phase << --
-- Starting training on experience 0 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.2982
	data_grads_norm = 5.4917
	new_data_grads_norm = 6.6674
	old_data_grads_norm = 6.7882
	sim_grads_norm = -0.0654
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.7637
	data_grads_norm = 4.5570
	new_data_grads_norm = 6.6642
	old_data_grads_norm = 4.7453
	sim_grads_norm = 0.0228
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.9852
	data_grads_norm = 5.2749
	new_data_grads_norm = 6.9625
	old_data_grads_norm = 6.4618
	sim_grads_norm = 0.0333
-- Starting training on experience 1 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.1461
	data_grads_norm = 5.2179
	new_data_grads_norm = 7.7887
	old_data_grads_norm = 5.6296
	sim_grads_norm = 0.0272
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.8226
	data_grads_norm = 5.0683
	new_data_grads_norm = 7.5580
	old_data_grads_norm = 5.3774
	sim_grads_norm = 0.0026
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.0441
	data_grads_norm = 4.9066
	new_data_grads_norm = 7.0610
	old_data_grads_norm = 5.7238
	sim_grads_norm = -0.0039
-- Starting training on experience 2 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.9307
	data_grads_norm = 4.7828
	new_data_grads_norm = 7.1538
	old_data_grads_norm = 5.2642
	sim_grads_norm = 0.1564
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2686
	data_grads_norm = 4.5355
	new_data_grads_norm = 6.9449
	old_data_grads_norm = 5.0305
	sim_grads_norm = -0.0019
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1291
	data_grads_norm = 4.3861
	new_data_grads_norm = 7.0290
	old_data_grads_norm = 3.8281
	sim_grads_norm = 0.0060
-- Starting training on experience 3 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6029
	data_grads_norm = 4.4921
	new_data_grads_norm = 6.8121
	old_data_grads_norm = 4.5078
	sim_grads_norm = 0.0137
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.8349
	data_grads_norm = 4.5270
	new_data_grads_norm = 6.4947
	old_data_grads_norm = 5.0816
	sim_grads_norm = 0.0155
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.4198
	data_grads_norm = 5.4975
	new_data_grads_norm = 7.5467
	old_data_grads_norm = 6.2090
	sim_grads_norm = 0.0072
-- Starting training on experience 4 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.9779
	data_grads_norm = 5.1751
	new_data_grads_norm = 7.2487
	old_data_grads_norm = 6.0521
	sim_grads_norm = 0.0024
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.3675
	data_grads_norm = 6.1524
	new_data_grads_norm = 7.0164
	old_data_grads_norm = 7.5034
	sim_grads_norm = -0.0023
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.2256
	data_grads_norm = 5.4703
	new_data_grads_norm = 8.0066
	old_data_grads_norm = 5.3598
	sim_grads_norm = -0.0162
-- Starting training on experience 5 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4986
	data_grads_norm = 4.3448
	new_data_grads_norm = 6.6123
	old_data_grads_norm = 4.7679
	sim_grads_norm = 0.0634
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.1188
	data_grads_norm = 4.8870
	new_data_grads_norm = 6.7082
	old_data_grads_norm = 6.3088
	sim_grads_norm = 0.0408
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2716
	data_grads_norm = 3.9622
	new_data_grads_norm = 6.0361
	old_data_grads_norm = 3.4559
	sim_grads_norm = -0.0133
-- Starting training on experience 6 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.0642
	data_grads_norm = 4.6174
	new_data_grads_norm = 6.3386
	old_data_grads_norm = 4.7368
	sim_grads_norm = -0.0108
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.3248
	data_grads_norm = 4.9450
	new_data_grads_norm = 6.1813
	old_data_grads_norm = 4.4001
	sim_grads_norm = 0.0245
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.7484
	data_grads_norm = 4.3871
	new_data_grads_norm = 6.7382
	old_data_grads_norm = 3.2052
	sim_grads_norm = -0.0123
-- Starting training on experience 7 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.8818
	data_grads_norm = 4.9150
	new_data_grads_norm = 6.7624
	old_data_grads_norm = 4.7614
	sim_grads_norm = 0.0314
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3704
	data_grads_norm = 4.8202
	new_data_grads_norm = 7.6716
	old_data_grads_norm = 4.3726
	sim_grads_norm = 0.0039
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.2777
	data_grads_norm = 5.2539
	new_data_grads_norm = 6.8307
	old_data_grads_norm = 6.0559
	sim_grads_norm = 0.0159
-- Starting training on experience 8 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5667
	data_grads_norm = 4.6297
	new_data_grads_norm = 7.7699
	old_data_grads_norm = 5.6049
	sim_grads_norm = 0.0508
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.7010
	data_grads_norm = 4.5934
	new_data_grads_norm = 6.7845
	old_data_grads_norm = 6.3752
	sim_grads_norm = 0.0041
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4163
	data_grads_norm = 4.6255
	new_data_grads_norm = 7.5884
	old_data_grads_norm = 5.1318
	sim_grads_norm = -0.0693
-- Starting training on experience 9 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6936
	data_grads_norm = 4.5442
	new_data_grads_norm = 5.9837
	old_data_grads_norm = 5.9405
	sim_grads_norm = 0.0631
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.7619
	data_grads_norm = 4.9250
	new_data_grads_norm = 6.2515
	old_data_grads_norm = 6.2083
	sim_grads_norm = 0.0472
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6113
	data_grads_norm = 4.6496
	new_data_grads_norm = 6.6728
	old_data_grads_norm = 4.4756
	sim_grads_norm = 0.1126
-- Starting training on experience 10 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.8527
	data_grads_norm = 5.0505
	new_data_grads_norm = 7.3631
	old_data_grads_norm = 6.7537
	sim_grads_norm = 0.0260
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6679
	data_grads_norm = 4.4119
	new_data_grads_norm = 6.6143
	old_data_grads_norm = 5.5279
	sim_grads_norm = 0.0177
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2989
	data_grads_norm = 4.4804
	new_data_grads_norm = 7.2891
	old_data_grads_norm = 4.1099
	sim_grads_norm = 0.0392
-- Starting training on experience 11 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.7526
	data_grads_norm = 5.7457
	new_data_grads_norm = 6.6497
	old_data_grads_norm = 6.5102
	sim_grads_norm = 0.0533
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1981
	data_grads_norm = 4.5650
	new_data_grads_norm = 6.9278
	old_data_grads_norm = 4.1623
	sim_grads_norm = -0.0009
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3695
	data_grads_norm = 4.5543
	new_data_grads_norm = 6.5031
	old_data_grads_norm = 4.5530
	sim_grads_norm = 0.0420
-- Starting training on experience 12 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9559
	data_grads_norm = 4.0508
	new_data_grads_norm = 6.5270
	old_data_grads_norm = 3.4041
	sim_grads_norm = -0.0286
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6861
	data_grads_norm = 4.0484
	new_data_grads_norm = 6.5749
	old_data_grads_norm = 4.9643
	sim_grads_norm = 0.0091
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7856
	data_grads_norm = 4.5077
	new_data_grads_norm = 6.5109
	old_data_grads_norm = 5.5455
	sim_grads_norm = -0.0125
-- Starting training on experience 13 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8609
	data_grads_norm = 4.2498
	new_data_grads_norm = 6.5851
	old_data_grads_norm = 5.0756
	sim_grads_norm = 0.0322
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1589
	data_grads_norm = 4.8029
	new_data_grads_norm = 6.3919
	old_data_grads_norm = 5.6558
	sim_grads_norm = 0.0157
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4850
	data_grads_norm = 4.6755
	new_data_grads_norm = 6.2397
	old_data_grads_norm = 7.7394
	sim_grads_norm = -0.0229
-- Starting training on experience 14 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4498
	data_grads_norm = 5.4722
	new_data_grads_norm = 7.1094
	old_data_grads_norm = 6.9450
	sim_grads_norm = 0.0405
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7026
	data_grads_norm = 4.3252
	new_data_grads_norm = 7.3167
	old_data_grads_norm = 4.0961
	sim_grads_norm = -0.0232
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6806
	data_grads_norm = 4.2020
	new_data_grads_norm = 6.8601
	old_data_grads_norm = 3.5090
	sim_grads_norm = -0.0089
-- Starting training on experience 15 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5127
	data_grads_norm = 5.1214
	new_data_grads_norm = 6.7341
	old_data_grads_norm = 6.4700
	sim_grads_norm = 0.0196
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2715
	data_grads_norm = 5.3017
	new_data_grads_norm = 6.8404
	old_data_grads_norm = 6.5009
	sim_grads_norm = 0.0612
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2169
	data_grads_norm = 5.0336
	new_data_grads_norm = 6.3905
	old_data_grads_norm = 6.7275
	sim_grads_norm = 0.0203
-- Starting training on experience 16 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7775
	data_grads_norm = 4.5641
	new_data_grads_norm = 6.6071
	old_data_grads_norm = 5.9986
	sim_grads_norm = 0.0196
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7673
	data_grads_norm = 4.4962
	new_data_grads_norm = 6.0199
	old_data_grads_norm = 4.5809
	sim_grads_norm = 0.0354
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4046
	data_grads_norm = 4.0521
	new_data_grads_norm = 5.7788
	old_data_grads_norm = 4.7587
	sim_grads_norm = 0.0116
-- Starting training on experience 17 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6174
	data_grads_norm = 4.0435
	new_data_grads_norm = 5.8143
	old_data_grads_norm = 5.0690
	sim_grads_norm = 0.0306
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6932
	data_grads_norm = 4.0849
	new_data_grads_norm = 5.9762
	old_data_grads_norm = 4.7937
	sim_grads_norm = 0.0661
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6105
	data_grads_norm = 4.3495
	new_data_grads_norm = 6.9149
	old_data_grads_norm = 5.6640
	sim_grads_norm = -0.0516
-- Starting training on experience 18 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1929
	data_grads_norm = 4.0168
	new_data_grads_norm = 5.4066
	old_data_grads_norm = 6.0767
	sim_grads_norm = -0.0057
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8227
	data_grads_norm = 4.4968
	new_data_grads_norm = 5.8783
	old_data_grads_norm = 5.9544
	sim_grads_norm = 0.0464
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0502
	data_grads_norm = 3.9711
	new_data_grads_norm = 5.5800
	old_data_grads_norm = 5.1171
	sim_grads_norm = -0.0115
-- Starting training on experience 19 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2176
	data_grads_norm = 4.3967
	new_data_grads_norm = 6.8823
	old_data_grads_norm = 4.3559
	sim_grads_norm = 0.0093
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1525
	data_grads_norm = 4.3125
	new_data_grads_norm = 6.8392
	old_data_grads_norm = 3.4805
	sim_grads_norm = -0.0248
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7876
	data_grads_norm = 5.3271
	new_data_grads_norm = 6.5506
	old_data_grads_norm = 4.9235
	sim_grads_norm = 0.0163
-- Starting training on experience 20 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.8403
	data_grads_norm = 4.8788
	new_data_grads_norm = 6.1192
	old_data_grads_norm = 7.3004
	sim_grads_norm = 0.0940
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6790
	data_grads_norm = 4.2377
	new_data_grads_norm = 6.1228
	old_data_grads_norm = 4.5697
	sim_grads_norm = -0.0061
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0528
	data_grads_norm = 4.1828
	new_data_grads_norm = 5.7269
	old_data_grads_norm = 5.1307
	sim_grads_norm = -0.0115
-- Starting training on experience 21 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1985
	data_grads_norm = 3.3979
	new_data_grads_norm = 5.0392
	old_data_grads_norm = 4.1652
	sim_grads_norm = 0.0163
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2562
	data_grads_norm = 4.1109
	new_data_grads_norm = 4.9511
	old_data_grads_norm = 5.8022
	sim_grads_norm = -0.0362
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0243
	data_grads_norm = 4.8967
	new_data_grads_norm = 5.7098
	old_data_grads_norm = 7.3898
	sim_grads_norm = 0.0587
-- Starting training on experience 22 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5588
	data_grads_norm = 4.7092
	new_data_grads_norm = 6.6710
	old_data_grads_norm = 6.2596
	sim_grads_norm = 0.0322
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3692
	data_grads_norm = 4.4737
	new_data_grads_norm = 6.6763
	old_data_grads_norm = 5.8558
	sim_grads_norm = 0.0102
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3944
	data_grads_norm = 4.4815
	new_data_grads_norm = 6.3270
	old_data_grads_norm = 6.0640
	sim_grads_norm = 0.0076
-- Starting training on experience 23 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7948
	data_grads_norm = 4.4663
	new_data_grads_norm = 5.2949
	old_data_grads_norm = 6.2561
	sim_grads_norm = 0.0190
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6952
	data_grads_norm = 4.3574
	new_data_grads_norm = 5.4452
	old_data_grads_norm = 5.3472
	sim_grads_norm = 0.0236
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0279
	data_grads_norm = 3.6780
	new_data_grads_norm = 5.0507
	old_data_grads_norm = 6.0642
	sim_grads_norm = -0.0071
-- Starting training on experience 24 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0834
	data_grads_norm = 4.7302
	new_data_grads_norm = 6.0607
	old_data_grads_norm = 5.7511
	sim_grads_norm = 0.0587
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0588
	data_grads_norm = 4.8519
	new_data_grads_norm = 6.2054
	old_data_grads_norm = 6.7208
	sim_grads_norm = -0.0423
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9010
	data_grads_norm = 4.5862
	new_data_grads_norm = 6.9820
	old_data_grads_norm = 6.2955
	sim_grads_norm = -0.0106
-- Starting training on experience 25 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4092
	data_grads_norm = 5.1881
	new_data_grads_norm = 7.2833
	old_data_grads_norm = 5.8862
	sim_grads_norm = 0.0108
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5652
	data_grads_norm = 4.2295
	new_data_grads_norm = 6.8249
	old_data_grads_norm = 3.6645
	sim_grads_norm = 0.1416
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8225
	data_grads_norm = 4.6364
	new_data_grads_norm = 6.9764
	old_data_grads_norm = 6.5135
	sim_grads_norm = -0.0144
-- Starting training on experience 26 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6814
	data_grads_norm = 5.0279
	new_data_grads_norm = 7.3725
	old_data_grads_norm = 7.5077
	sim_grads_norm = -0.0390
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5892
	data_grads_norm = 4.5920
	new_data_grads_norm = 7.3379
	old_data_grads_norm = 3.9872
	sim_grads_norm = -0.0056
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5036
	data_grads_norm = 4.8635
	new_data_grads_norm = 7.0032
	old_data_grads_norm = 5.9200
	sim_grads_norm = 0.0010
-- Starting training on experience 27 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8255
	data_grads_norm = 4.7223
	new_data_grads_norm = 6.8857
	old_data_grads_norm = 4.5709
	sim_grads_norm = 0.0531
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8396
	data_grads_norm = 4.0444
	new_data_grads_norm = 5.8433
	old_data_grads_norm = 5.1107
	sim_grads_norm = -0.0085
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9409
	data_grads_norm = 4.2854
	new_data_grads_norm = 6.1137
	old_data_grads_norm = 5.8389
	sim_grads_norm = 0.0437
-- Starting training on experience 28 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7412
	data_grads_norm = 3.6305
	new_data_grads_norm = 5.4355
	old_data_grads_norm = 3.4638
	sim_grads_norm = 0.0012
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3113
	data_grads_norm = 4.2766
	new_data_grads_norm = 6.1358
	old_data_grads_norm = 5.3375
	sim_grads_norm = 0.0250
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1397
	data_grads_norm = 3.6982
	new_data_grads_norm = 5.5287
	old_data_grads_norm = 4.6070
	sim_grads_norm = 0.0103
-- Starting training on experience 29 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1054
	data_grads_norm = 5.1666
	new_data_grads_norm = 6.6543
	old_data_grads_norm = 6.1998
	sim_grads_norm = 0.0110
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5539
	data_grads_norm = 4.6789
	new_data_grads_norm = 6.1642
	old_data_grads_norm = 6.3304
	sim_grads_norm = 0.0042
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4032
	data_grads_norm = 4.4216
	new_data_grads_norm = 6.1091
	old_data_grads_norm = 4.7142
	sim_grads_norm = 0.0445
-- Starting training on experience 30 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5724
	data_grads_norm = 4.6867
	new_data_grads_norm = 7.2645
	old_data_grads_norm = 3.8176
	sim_grads_norm = 0.0496
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3991
	data_grads_norm = 4.3678
	new_data_grads_norm = 7.2082
	old_data_grads_norm = 4.0541
	sim_grads_norm = 0.0408
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3803
	data_grads_norm = 4.6659
	new_data_grads_norm = 7.0572
	old_data_grads_norm = 4.3479
	sim_grads_norm = 0.0450
-- Starting training on experience 31 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2727
	data_grads_norm = 4.5888
	new_data_grads_norm = 6.0223
	old_data_grads_norm = 5.9524
	sim_grads_norm = 0.0285
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9352
	data_grads_norm = 4.5380
	new_data_grads_norm = 6.3110
	old_data_grads_norm = 6.4191
	sim_grads_norm = 0.0007
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9227
	data_grads_norm = 4.3472
	new_data_grads_norm = 6.6382
	old_data_grads_norm = 6.3740
	sim_grads_norm = 0.0207
-- Starting training on experience 32 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9329
	data_grads_norm = 4.2620
	new_data_grads_norm = 6.9033
	old_data_grads_norm = 4.6391
	sim_grads_norm = 0.0312
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8882
	data_grads_norm = 4.0480
	new_data_grads_norm = 6.6326
	old_data_grads_norm = 5.5216
	sim_grads_norm = 0.0331
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0728
	data_grads_norm = 4.5142
	new_data_grads_norm = 7.6177
	old_data_grads_norm = 4.2665
	sim_grads_norm = 0.0633
-- Starting training on experience 33 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2294
	data_grads_norm = 4.1894
	new_data_grads_norm = 5.4185
	old_data_grads_norm = 6.3456
	sim_grads_norm = 0.0345
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5631
	data_grads_norm = 4.0386
	new_data_grads_norm = 5.2353
	old_data_grads_norm = 5.5124
	sim_grads_norm = -0.0134
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2009
	data_grads_norm = 4.1425
	new_data_grads_norm = 5.5777
	old_data_grads_norm = 5.4792
	sim_grads_norm = -0.0122
-- Starting training on experience 34 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0833
	data_grads_norm = 4.1193
	new_data_grads_norm = 7.1426
	old_data_grads_norm = 5.2224
	sim_grads_norm = 0.0071
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9533
	data_grads_norm = 4.2019
	new_data_grads_norm = 6.8690
	old_data_grads_norm = 5.6311
	sim_grads_norm = 0.0306
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9123
	data_grads_norm = 3.9202
	new_data_grads_norm = 6.7566
	old_data_grads_norm = 3.2629
	sim_grads_norm = -0.0499
-- Starting training on experience 35 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1240
	data_grads_norm = 4.6083
	new_data_grads_norm = 6.6705
	old_data_grads_norm = 5.7976
	sim_grads_norm = 0.0376
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5635
	data_grads_norm = 3.7927
	new_data_grads_norm = 6.7085
	old_data_grads_norm = 4.7062
	sim_grads_norm = -0.0045
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2518
	data_grads_norm = 4.5356
	new_data_grads_norm = 5.9511
	old_data_grads_norm = 4.8977
	sim_grads_norm = 0.0075
-- Starting training on experience 36 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9304
	data_grads_norm = 4.3819
	new_data_grads_norm = 5.9197
	old_data_grads_norm = 5.4062
	sim_grads_norm = 0.0420
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2561
	data_grads_norm = 4.2822
	new_data_grads_norm = 5.9339
	old_data_grads_norm = 5.1578
	sim_grads_norm = -0.0083
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3336
	data_grads_norm = 4.8350
	new_data_grads_norm = 5.6006
	old_data_grads_norm = 6.7686
	sim_grads_norm = -0.0088
-- Starting training on experience 37 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0463
	data_grads_norm = 4.1001
	new_data_grads_norm = 6.0930
	old_data_grads_norm = 4.0749
	sim_grads_norm = 0.0508
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3764
	data_grads_norm = 4.5186
	new_data_grads_norm = 5.4817
	old_data_grads_norm = 5.8516
	sim_grads_norm = 0.0593
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8087
	data_grads_norm = 3.5902
	new_data_grads_norm = 5.4425
	old_data_grads_norm = 3.6833
	sim_grads_norm = -0.0252
-- Starting training on experience 38 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8482
	data_grads_norm = 4.2202
	new_data_grads_norm = 7.3177
	old_data_grads_norm = 3.8459
	sim_grads_norm = 0.0125
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2721
	data_grads_norm = 4.6170
	new_data_grads_norm = 6.8089
	old_data_grads_norm = 6.1310
	sim_grads_norm = 0.0306
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3080
	data_grads_norm = 4.5772
	new_data_grads_norm = 6.7736
	old_data_grads_norm = 5.2781
	sim_grads_norm = -0.0072
-- Starting training on experience 39 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3565
	data_grads_norm = 3.6688
	new_data_grads_norm = 6.2804
	old_data_grads_norm = 4.9928
	sim_grads_norm = -0.0077
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1285
	data_grads_norm = 4.6945
	new_data_grads_norm = 5.6836
	old_data_grads_norm = 7.3325
	sim_grads_norm = 0.0504
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3688
	data_grads_norm = 3.8520
	new_data_grads_norm = 7.0331
	old_data_grads_norm = 5.2046
	sim_grads_norm = 0.0416
-- Starting training on experience 40 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1076
	data_grads_norm = 5.1451
	new_data_grads_norm = 7.6516
	old_data_grads_norm = 5.5200
	sim_grads_norm = 0.0045
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1108
	data_grads_norm = 5.0554
	new_data_grads_norm = 6.8731
	old_data_grads_norm = 5.1642
	sim_grads_norm = -0.0172
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2223
	data_grads_norm = 4.7092
	new_data_grads_norm = 6.2008
	old_data_grads_norm = 5.5779
	sim_grads_norm = 0.0370
-- Starting training on experience 41 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3440
	data_grads_norm = 4.2576
	new_data_grads_norm = 5.8810
	old_data_grads_norm = 5.7104
	sim_grads_norm = -0.0270
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3922
	data_grads_norm = 4.6137
	new_data_grads_norm = 6.6561
	old_data_grads_norm = 4.0994
	sim_grads_norm = 0.0013
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3727
	data_grads_norm = 4.0956
	new_data_grads_norm = 6.5878
	old_data_grads_norm = 5.1064
	sim_grads_norm = -0.0243
-- Starting training on experience 42 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4887
	data_grads_norm = 4.5743
	new_data_grads_norm = 5.5954
	old_data_grads_norm = 6.4695
	sim_grads_norm = 0.0262
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1293
	data_grads_norm = 4.5074
	new_data_grads_norm = 5.9568
	old_data_grads_norm = 6.3384
	sim_grads_norm = 0.0207
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1831
	data_grads_norm = 4.2170
	new_data_grads_norm = 5.8848
	old_data_grads_norm = 5.1019
	sim_grads_norm = 0.0018
-- Starting training on experience 43 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9407
	data_grads_norm = 4.4119
	new_data_grads_norm = 7.0501
	old_data_grads_norm = 5.4477
	sim_grads_norm = 0.0391
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6845
	data_grads_norm = 4.1809
	new_data_grads_norm = 7.0940
	old_data_grads_norm = 4.5529
	sim_grads_norm = -0.0112
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1703
	data_grads_norm = 4.5167
	new_data_grads_norm = 7.0594
	old_data_grads_norm = 5.8357
	sim_grads_norm = 0.0360
-- Starting training on experience 44 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5634
	data_grads_norm = 4.3386
	new_data_grads_norm = 7.0167
	old_data_grads_norm = 4.5226
	sim_grads_norm = 0.1022
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7987
	data_grads_norm = 4.0972
	new_data_grads_norm = 6.2910
	old_data_grads_norm = 4.8773
	sim_grads_norm = -0.0008
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4127
	data_grads_norm = 4.7808
	new_data_grads_norm = 7.0754
	old_data_grads_norm = 5.5955
	sim_grads_norm = -0.0034
-- Starting training on experience 45 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4226
	data_grads_norm = 3.6981
	new_data_grads_norm = 6.0015
	old_data_grads_norm = 3.6447
	sim_grads_norm = 0.0194
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6902
	data_grads_norm = 4.4880
	new_data_grads_norm = 6.0005
	old_data_grads_norm = 6.0315
	sim_grads_norm = 0.0283
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6657
	data_grads_norm = 3.9111
	new_data_grads_norm = 6.1573
	old_data_grads_norm = 4.5645
	sim_grads_norm = 0.0057
-- Starting training on experience 46 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8358
	data_grads_norm = 4.1856
	new_data_grads_norm = 6.7758
	old_data_grads_norm = 5.0758
	sim_grads_norm = -0.0115
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2213
	data_grads_norm = 4.2431
	new_data_grads_norm = 6.8204
	old_data_grads_norm = 5.3822
	sim_grads_norm = -0.0224
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2770
	data_grads_norm = 4.1331
	new_data_grads_norm = 6.7400
	old_data_grads_norm = 4.1356
	sim_grads_norm = -0.0013
-- Starting training on experience 47 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8336
	data_grads_norm = 4.4230
	new_data_grads_norm = 6.9153
	old_data_grads_norm = 4.6243
	sim_grads_norm = 0.0116
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7196
	data_grads_norm = 4.3703
	new_data_grads_norm = 6.0406
	old_data_grads_norm = 5.3517
	sim_grads_norm = 0.0268
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3403
	data_grads_norm = 3.6833
	new_data_grads_norm = 6.2238
	old_data_grads_norm = 4.2730
	sim_grads_norm = 0.0103
-- Starting training on experience 48 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1208
	data_grads_norm = 4.0900
	new_data_grads_norm = 5.5943
	old_data_grads_norm = 5.2306
	sim_grads_norm = 0.1114
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0099
	data_grads_norm = 4.2399
	new_data_grads_norm = 5.8635
	old_data_grads_norm = 5.8537
	sim_grads_norm = 0.0146
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5327
	data_grads_norm = 3.6359
	new_data_grads_norm = 5.7214
	old_data_grads_norm = 4.2175
	sim_grads_norm = -0.0136
-- Starting training on experience 49 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0851
	data_grads_norm = 4.4046
	new_data_grads_norm = 5.5025
	old_data_grads_norm = 7.6305
	sim_grads_norm = 0.0195
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9010
	data_grads_norm = 4.2992
	new_data_grads_norm = 6.5553
	old_data_grads_norm = 5.4144
	sim_grads_norm = 0.0744
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5900
	data_grads_norm = 4.1012
	new_data_grads_norm = 5.6744
	old_data_grads_norm = 6.2772
	sim_grads_norm = 0.0640
-- Starting training on experience 50 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4953
	data_grads_norm = 4.3818
	new_data_grads_norm = 5.6703
	old_data_grads_norm = 5.0589
	sim_grads_norm = -0.0043
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7277
	data_grads_norm = 3.9839
	new_data_grads_norm = 7.0712
	old_data_grads_norm = 5.9576
	sim_grads_norm = -0.0089
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6298
	data_grads_norm = 5.2444
	new_data_grads_norm = 6.9480
	old_data_grads_norm = 6.1644
	sim_grads_norm = 0.0067
-- Starting training on experience 51 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4024
	data_grads_norm = 3.6823
	new_data_grads_norm = 5.2814
	old_data_grads_norm = 4.6868
	sim_grads_norm = 0.0029
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8125
	data_grads_norm = 5.1345
	new_data_grads_norm = 6.2562
	old_data_grads_norm = 6.7560
	sim_grads_norm = -0.0069
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8601
	data_grads_norm = 5.1533
	new_data_grads_norm = 6.3531
	old_data_grads_norm = 6.3204
	sim_grads_norm = -0.0313
-- Starting training on experience 52 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1730
	data_grads_norm = 5.2190
	new_data_grads_norm = 6.6872
	old_data_grads_norm = 6.0504
	sim_grads_norm = 0.0065
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5745
	data_grads_norm = 3.7231
	new_data_grads_norm = 6.1442
	old_data_grads_norm = 4.9885
	sim_grads_norm = -0.0114
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4832
	data_grads_norm = 4.6950
	new_data_grads_norm = 7.1471
	old_data_grads_norm = 4.5202
	sim_grads_norm = 0.0162
-- Starting training on experience 53 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9161
	data_grads_norm = 4.2662
	new_data_grads_norm = 7.3420
	old_data_grads_norm = 4.2542
	sim_grads_norm = -0.0282
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2082
	data_grads_norm = 6.0764
	new_data_grads_norm = 7.5432
	old_data_grads_norm = 8.4920
	sim_grads_norm = 0.0852
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0290
	data_grads_norm = 4.2753
	new_data_grads_norm = 6.3472
	old_data_grads_norm = 4.1369
	sim_grads_norm = -0.0368
-- Starting training on experience 54 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1315
	data_grads_norm = 4.6777
	new_data_grads_norm = 7.1967
	old_data_grads_norm = 5.0382
	sim_grads_norm = 0.0247
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3937
	data_grads_norm = 5.0263
	new_data_grads_norm = 6.6822
	old_data_grads_norm = 6.4109
	sim_grads_norm = -0.0203
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6832
	data_grads_norm = 4.0610
	new_data_grads_norm = 6.3908
	old_data_grads_norm = 3.4257
	sim_grads_norm = 0.0253
-- Starting training on experience 55 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8831
	data_grads_norm = 4.6996
	new_data_grads_norm = 7.4883
	old_data_grads_norm = 6.4218
	sim_grads_norm = -0.0039
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5360
	data_grads_norm = 4.6593
	new_data_grads_norm = 6.3879
	old_data_grads_norm = 5.5159
	sim_grads_norm = 0.0593
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8716
	data_grads_norm = 4.6091
	new_data_grads_norm = 6.6801
	old_data_grads_norm = 6.0863
	sim_grads_norm = -0.0000
-- Starting training on experience 56 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8933
	data_grads_norm = 4.0125
	new_data_grads_norm = 7.0700
	old_data_grads_norm = 4.9205
	sim_grads_norm = 0.0317
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6028
	data_grads_norm = 4.0670
	new_data_grads_norm = 7.1706
	old_data_grads_norm = 4.4328
	sim_grads_norm = 0.0224
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7648
	data_grads_norm = 4.0896
	new_data_grads_norm = 6.7937
	old_data_grads_norm = 5.8763
	sim_grads_norm = 0.0109
-- Starting training on experience 57 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2443
	data_grads_norm = 4.7430
	new_data_grads_norm = 6.6613
	old_data_grads_norm = 5.7951
	sim_grads_norm = 0.0086
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7923
	data_grads_norm = 4.3714
	new_data_grads_norm = 6.7637
	old_data_grads_norm = 5.6491
	sim_grads_norm = 0.0326
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8175
	data_grads_norm = 4.8446
	new_data_grads_norm = 7.4821
	old_data_grads_norm = 4.8986
	sim_grads_norm = 0.0814
-- Starting training on experience 58 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9101
	data_grads_norm = 2.8674
	new_data_grads_norm = 6.7673
	old_data_grads_norm = 3.5912
	sim_grads_norm = -0.0132
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0290
	data_grads_norm = 4.5822
	new_data_grads_norm = 6.7565
	old_data_grads_norm = 5.5795
	sim_grads_norm = -0.0085
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5576
	data_grads_norm = 4.1114
	new_data_grads_norm = 6.0575
	old_data_grads_norm = 5.4764
	sim_grads_norm = 0.0891
-- Starting training on experience 59 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3982
	data_grads_norm = 4.0205
	new_data_grads_norm = 6.4487
	old_data_grads_norm = 4.4755
	sim_grads_norm = -0.0107
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9590
	data_grads_norm = 3.7960
	new_data_grads_norm = 6.2755
	old_data_grads_norm = 4.5982
	sim_grads_norm = -0.0181
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2790
	data_grads_norm = 3.8416
	new_data_grads_norm = 6.2321
	old_data_grads_norm = 3.5953
	sim_grads_norm = 0.0726
-- Starting training on experience 60 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4981
	data_grads_norm = 4.3985
	new_data_grads_norm = 7.6175
	old_data_grads_norm = 4.5915
	sim_grads_norm = -0.0863
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4787
	data_grads_norm = 4.8933
	new_data_grads_norm = 7.2126
	old_data_grads_norm = 5.6906
	sim_grads_norm = 0.0076
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8745
	data_grads_norm = 5.0318
	new_data_grads_norm = 7.2813
	old_data_grads_norm = 6.7497
	sim_grads_norm = -0.0149
-- Starting training on experience 61 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3167
	data_grads_norm = 3.5413
	new_data_grads_norm = 5.8899
	old_data_grads_norm = 4.2184
	sim_grads_norm = 0.0232
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2600
	data_grads_norm = 3.7258
	new_data_grads_norm = 5.5443
	old_data_grads_norm = 5.4419
	sim_grads_norm = -0.0404
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7169
	data_grads_norm = 4.7527
	new_data_grads_norm = 6.7659
	old_data_grads_norm = 5.8681
	sim_grads_norm = -0.0110
-- Starting training on experience 62 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7424
	data_grads_norm = 4.7719
	new_data_grads_norm = 6.9925
	old_data_grads_norm = 5.5007
	sim_grads_norm = 0.0049
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0091
	data_grads_norm = 4.4848
	new_data_grads_norm = 6.9722
	old_data_grads_norm = 5.3365
	sim_grads_norm = -0.0159
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6638
	data_grads_norm = 4.4083
	new_data_grads_norm = 6.3868
	old_data_grads_norm = 4.4746
	sim_grads_norm = 0.0027
-- Starting training on experience 63 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8967
	data_grads_norm = 5.0627
	new_data_grads_norm = 7.6103
	old_data_grads_norm = 4.5482
	sim_grads_norm = 0.0259
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8286
	data_grads_norm = 4.5028
	new_data_grads_norm = 6.6552
	old_data_grads_norm = 6.2772
	sim_grads_norm = -0.0523
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6493
	data_grads_norm = 4.3503
	new_data_grads_norm = 6.0610
	old_data_grads_norm = 4.8299
	sim_grads_norm = 0.1273
-- Starting training on experience 64 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2259
	data_grads_norm = 4.8758
	new_data_grads_norm = 6.9367
	old_data_grads_norm = 5.5571
	sim_grads_norm = -0.0017
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2278
	data_grads_norm = 4.8132
	new_data_grads_norm = 6.8298
	old_data_grads_norm = 6.0745
	sim_grads_norm = 0.0814
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8776
	data_grads_norm = 4.3877
	new_data_grads_norm = 6.8730
	old_data_grads_norm = 4.7124
	sim_grads_norm = 0.0027
-- Starting training on experience 65 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1275
	data_grads_norm = 5.2925
	new_data_grads_norm = 6.7210
	old_data_grads_norm = 7.6193
	sim_grads_norm = -0.0015
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0071
	data_grads_norm = 3.5718
	new_data_grads_norm = 6.0503
	old_data_grads_norm = 3.6416
	sim_grads_norm = -0.0117
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3580
	data_grads_norm = 4.2180
	new_data_grads_norm = 5.6670
	old_data_grads_norm = 5.2158
	sim_grads_norm = -0.0318
-- Starting training on experience 66 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0719
	data_grads_norm = 4.6749
	new_data_grads_norm = 6.7843
	old_data_grads_norm = 4.8828
	sim_grads_norm = 0.0734
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7853
	data_grads_norm = 4.9460
	new_data_grads_norm = 6.9100
	old_data_grads_norm = 5.9349
	sim_grads_norm = 0.2025
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8681
	data_grads_norm = 3.6696
	new_data_grads_norm = 5.7138
	old_data_grads_norm = 4.1005
	sim_grads_norm = -0.0124
-- Starting training on experience 67 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2947
	data_grads_norm = 3.6857
	new_data_grads_norm = 4.8029
	old_data_grads_norm = 5.1412
	sim_grads_norm = -0.0029
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8684
	data_grads_norm = 3.3883
	new_data_grads_norm = 4.8344
	old_data_grads_norm = 4.2736
	sim_grads_norm = 0.0022
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8455
	data_grads_norm = 3.2313
	new_data_grads_norm = 4.8850
	old_data_grads_norm = 4.6467
	sim_grads_norm = -0.0434
-- Starting training on experience 68 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7443
	data_grads_norm = 4.0464
	new_data_grads_norm = 5.3481
	old_data_grads_norm = 4.9052
	sim_grads_norm = 0.0048
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2518
	data_grads_norm = 3.8194
	new_data_grads_norm = 5.1753
	old_data_grads_norm = 3.4349
	sim_grads_norm = -0.0171
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3562
	data_grads_norm = 3.5635
	new_data_grads_norm = 5.2235
	old_data_grads_norm = 4.3115
	sim_grads_norm = -0.0285
-- Starting training on experience 69 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0511
	data_grads_norm = 3.8889
	new_data_grads_norm = 6.1881
	old_data_grads_norm = 3.6265
	sim_grads_norm = 0.0409
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2596
	data_grads_norm = 4.4320
	new_data_grads_norm = 6.0732
	old_data_grads_norm = 4.7421
	sim_grads_norm = -0.0360
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8527
	data_grads_norm = 4.2930
	new_data_grads_norm = 6.0516
	old_data_grads_norm = 3.9608
	sim_grads_norm = -0.0164
-- Starting training on experience 70 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0303
	data_grads_norm = 3.2054
	new_data_grads_norm = 6.2656
	old_data_grads_norm = 2.8962
	sim_grads_norm = 0.0117
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0097
	data_grads_norm = 3.3439
	new_data_grads_norm = 6.2370
	old_data_grads_norm = 4.6868
	sim_grads_norm = -0.0222
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2892
	data_grads_norm = 4.2275
	new_data_grads_norm = 6.8240
	old_data_grads_norm = 6.6314
	sim_grads_norm = -0.0381
-- Starting training on experience 71 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3278
	data_grads_norm = 3.8451
	new_data_grads_norm = 6.7350
	old_data_grads_norm = 4.6467
	sim_grads_norm = 0.0126
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9198
	data_grads_norm = 5.2393
	new_data_grads_norm = 7.4477
	old_data_grads_norm = 6.1021
	sim_grads_norm = 0.0694
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1289
	data_grads_norm = 3.5937
	new_data_grads_norm = 7.3102
	old_data_grads_norm = 3.9070
	sim_grads_norm = -0.0439
-- Starting training on experience 72 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9131
	data_grads_norm = 4.5747
	new_data_grads_norm = 5.9322
	old_data_grads_norm = 5.2487
	sim_grads_norm = 0.0539
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1075
	data_grads_norm = 3.7061
	new_data_grads_norm = 5.6848
	old_data_grads_norm = 4.7179
	sim_grads_norm = -0.0114
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2658
	data_grads_norm = 4.1859
	new_data_grads_norm = 5.1106
	old_data_grads_norm = 5.6367
	sim_grads_norm = -0.0015
-- Starting training on experience 73 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4646
	data_grads_norm = 4.0918
	new_data_grads_norm = 6.1880
	old_data_grads_norm = 5.2310
	sim_grads_norm = -0.0145
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0464
	data_grads_norm = 3.4772
	new_data_grads_norm = 5.7056
	old_data_grads_norm = 4.7552
	sim_grads_norm = -0.0558
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3921
	data_grads_norm = 4.4644
	new_data_grads_norm = 6.0552
	old_data_grads_norm = 6.7762
	sim_grads_norm = -0.0075
-- Starting training on experience 74 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0421
	data_grads_norm = 4.6703
	new_data_grads_norm = 6.0110
	old_data_grads_norm = 6.4390
	sim_grads_norm = 0.0050
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7418
	data_grads_norm = 4.7265
	new_data_grads_norm = 6.1541
	old_data_grads_norm = 5.6101
	sim_grads_norm = 0.0179
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3293
	data_grads_norm = 3.7352
	new_data_grads_norm = 5.7344
	old_data_grads_norm = 4.7977
	sim_grads_norm = -0.0079
-- Starting training on experience 75 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6095
	data_grads_norm = 4.1754
	new_data_grads_norm = 5.5823
	old_data_grads_norm = 5.1988
	sim_grads_norm = 0.0758
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5101
	data_grads_norm = 3.5904
	new_data_grads_norm = 5.8731
	old_data_grads_norm = 3.1002
	sim_grads_norm = 0.0360
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4662
	data_grads_norm = 4.6730
	new_data_grads_norm = 5.5212
	old_data_grads_norm = 6.5926
	sim_grads_norm = 0.0189
-- Starting training on experience 76 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5493
	data_grads_norm = 4.5909
	new_data_grads_norm = 7.0093
	old_data_grads_norm = 6.0278
	sim_grads_norm = -0.0104
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6923
	data_grads_norm = 5.3878
	new_data_grads_norm = 7.1695
	old_data_grads_norm = 5.6325
	sim_grads_norm = 0.0377
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3592
	data_grads_norm = 4.1188
	new_data_grads_norm = 6.1252
	old_data_grads_norm = 3.9306
	sim_grads_norm = -0.0430
-- Starting training on experience 77 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3209
	data_grads_norm = 4.5700
	new_data_grads_norm = 6.5463
	old_data_grads_norm = 5.1161
	sim_grads_norm = 0.0138
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6704
	data_grads_norm = 4.7967
	new_data_grads_norm = 6.3383
	old_data_grads_norm = 5.2027
	sim_grads_norm = -0.0164
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8190
	data_grads_norm = 3.2522
	new_data_grads_norm = 6.0804
	old_data_grads_norm = 2.9196
	sim_grads_norm = -0.0672
-- Starting training on experience 78 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2954
	data_grads_norm = 4.5287
	new_data_grads_norm = 6.5180
	old_data_grads_norm = 5.3114
	sim_grads_norm = -0.0056
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1307
	data_grads_norm = 4.1545
	new_data_grads_norm = 5.9827
	old_data_grads_norm = 4.3578
	sim_grads_norm = 0.0861
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1178
	data_grads_norm = 4.2880
	new_data_grads_norm = 6.0801
	old_data_grads_norm = 4.8847
	sim_grads_norm = 0.0181
-- Starting training on experience 79 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6840
	data_grads_norm = 4.5533
	new_data_grads_norm = 6.8451
	old_data_grads_norm = 5.3295
	sim_grads_norm = -0.0553
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8916
	data_grads_norm = 4.8761
	new_data_grads_norm = 6.0555
	old_data_grads_norm = 5.2725
	sim_grads_norm = 0.0394
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3036
	data_grads_norm = 4.5182
	new_data_grads_norm = 7.6418
	old_data_grads_norm = 5.4985
	sim_grads_norm = -0.0133
-- Starting training on experience 80 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3742
	data_grads_norm = 4.0954
	new_data_grads_norm = 6.2079
	old_data_grads_norm = 5.1630
	sim_grads_norm = 0.0072
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7078
	data_grads_norm = 4.6954
	new_data_grads_norm = 6.5185
	old_data_grads_norm = 5.8930
	sim_grads_norm = 0.0512
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0239
	data_grads_norm = 4.0016
	new_data_grads_norm = 6.0600
	old_data_grads_norm = 4.7822
	sim_grads_norm = -0.0135
-- Starting training on experience 81 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1953
	data_grads_norm = 4.0957
	new_data_grads_norm = 6.4488
	old_data_grads_norm = 5.7703
	sim_grads_norm = -0.0216
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9401
	data_grads_norm = 3.5431
	new_data_grads_norm = 5.7430
	old_data_grads_norm = 4.9528
	sim_grads_norm = -0.0482
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8750
	data_grads_norm = 5.3076
	new_data_grads_norm = 6.2333
	old_data_grads_norm = 6.3539
	sim_grads_norm = 0.0076
-- Starting training on experience 82 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6558
	data_grads_norm = 4.8267
	new_data_grads_norm = 7.6366
	old_data_grads_norm = 5.7701
	sim_grads_norm = 0.0035
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6601
	data_grads_norm = 4.9571
	new_data_grads_norm = 6.9992
	old_data_grads_norm = 5.4271
	sim_grads_norm = -0.0219
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1957
	data_grads_norm = 5.1419
	new_data_grads_norm = 7.3014
	old_data_grads_norm = 6.0077
	sim_grads_norm = 0.0615
-- Starting training on experience 83 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0516
	data_grads_norm = 4.9216
	new_data_grads_norm = 6.4833
	old_data_grads_norm = 6.5928
	sim_grads_norm = 0.0860
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1812
	data_grads_norm = 4.3187
	new_data_grads_norm = 5.8750
	old_data_grads_norm = 6.3383
	sim_grads_norm = 0.0025
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0256
	data_grads_norm = 3.8084
	new_data_grads_norm = 5.6568
	old_data_grads_norm = 3.9199
	sim_grads_norm = 0.0041
-- Starting training on experience 84 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0432
	data_grads_norm = 4.1774
	new_data_grads_norm = 5.4381
	old_data_grads_norm = 5.8882
	sim_grads_norm = 0.1050
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4836
	data_grads_norm = 3.7639
	new_data_grads_norm = 5.4786
	old_data_grads_norm = 4.3917
	sim_grads_norm = 0.0034
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9418
	data_grads_norm = 4.2625
	new_data_grads_norm = 5.2897
	old_data_grads_norm = 6.0116
	sim_grads_norm = -0.0402
-- Starting training on experience 85 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6137
	data_grads_norm = 3.0735
	new_data_grads_norm = 5.2742
	old_data_grads_norm = 3.2660
	sim_grads_norm = -0.0078
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2292
	data_grads_norm = 4.2191
	new_data_grads_norm = 4.7499
	old_data_grads_norm = 6.4669
	sim_grads_norm = 0.0364
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1394
	data_grads_norm = 4.1483
	new_data_grads_norm = 5.3821
	old_data_grads_norm = 6.4634
	sim_grads_norm = -0.0066
-- Starting training on experience 86 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0014
	data_grads_norm = 3.4747
	new_data_grads_norm = 5.1266
	old_data_grads_norm = 5.7378
	sim_grads_norm = -0.0031
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0368
	data_grads_norm = 4.6731
	new_data_grads_norm = 5.3728
	old_data_grads_norm = 7.0572
	sim_grads_norm = 0.0283
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4555
	data_grads_norm = 3.9230
	new_data_grads_norm = 5.6804
	old_data_grads_norm = 5.8202
	sim_grads_norm = 0.0318
-- Starting training on experience 87 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2090
	data_grads_norm = 4.0826
	new_data_grads_norm = 5.8020
	old_data_grads_norm = 5.9320
	sim_grads_norm = 0.0180
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9290
	data_grads_norm = 3.9679
	new_data_grads_norm = 5.1747
	old_data_grads_norm = 5.1444
	sim_grads_norm = -0.0052
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8795
	data_grads_norm = 3.8905
	new_data_grads_norm = 4.8298
	old_data_grads_norm = 6.1413
	sim_grads_norm = -0.0212
-- Starting training on experience 88 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2300
	data_grads_norm = 3.8574
	new_data_grads_norm = 5.6875
	old_data_grads_norm = 4.4798
	sim_grads_norm = 0.0230
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4226
	data_grads_norm = 4.1801
	new_data_grads_norm = 5.7640
	old_data_grads_norm = 6.1263
	sim_grads_norm = 0.0560
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2409
	data_grads_norm = 3.9583
	new_data_grads_norm = 5.3707
	old_data_grads_norm = 5.9634
	sim_grads_norm = 0.0207
-- Starting training on experience 89 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0750
	data_grads_norm = 4.1127
	new_data_grads_norm = 6.2802
	old_data_grads_norm = 6.8764
	sim_grads_norm = 0.0046
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4396
	data_grads_norm = 4.4953
	new_data_grads_norm = 6.3557
	old_data_grads_norm = 5.2869
	sim_grads_norm = 0.0284
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4684
	data_grads_norm = 4.7802
	new_data_grads_norm = 5.6386
	old_data_grads_norm = 6.9893
	sim_grads_norm = 0.0521
-- Starting training on experience 90 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0918
	data_grads_norm = 4.1752
	new_data_grads_norm = 5.9251
	old_data_grads_norm = 6.3312
	sim_grads_norm = 0.0372
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2817
	data_grads_norm = 3.8399
	new_data_grads_norm = 6.0605
	old_data_grads_norm = 3.8692
	sim_grads_norm = 0.0455
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1469
	data_grads_norm = 3.6982
	new_data_grads_norm = 6.0793
	old_data_grads_norm = 5.5562
	sim_grads_norm = -0.0276
-- Starting training on experience 91 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6536
	data_grads_norm = 4.6981
	new_data_grads_norm = 7.1583
	old_data_grads_norm = 5.7116
	sim_grads_norm = -0.0097
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6997
	data_grads_norm = 3.8993
	new_data_grads_norm = 6.2807
	old_data_grads_norm = 4.1923
	sim_grads_norm = 0.1003
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8786
	data_grads_norm = 4.6135
	new_data_grads_norm = 6.4702
	old_data_grads_norm = 6.2470
	sim_grads_norm = -0.0047
-- Starting training on experience 92 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3116
	data_grads_norm = 4.6883
	new_data_grads_norm = 6.6968
	old_data_grads_norm = 6.0231
	sim_grads_norm = 0.0323
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1949
	data_grads_norm = 3.7521
	new_data_grads_norm = 6.6891
	old_data_grads_norm = 4.2132
	sim_grads_norm = 0.0220
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1252
	data_grads_norm = 3.7242
	new_data_grads_norm = 6.3200
	old_data_grads_norm = 4.8413
	sim_grads_norm = 0.0179
-- Starting training on experience 93 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4457
	data_grads_norm = 4.2621
	new_data_grads_norm = 5.9545
	old_data_grads_norm = 5.8637
	sim_grads_norm = -0.0169
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2845
	data_grads_norm = 4.3424
	new_data_grads_norm = 5.8092
	old_data_grads_norm = 3.9539
	sim_grads_norm = -0.0139
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2316
	data_grads_norm = 4.0378
	new_data_grads_norm = 6.8265
	old_data_grads_norm = 3.6281
	sim_grads_norm = 0.0127
-- Starting training on experience 94 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1602
	data_grads_norm = 3.7587
	new_data_grads_norm = 6.0385
	old_data_grads_norm = 3.8731
	sim_grads_norm = 0.0580
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0104
	data_grads_norm = 4.0087
	new_data_grads_norm = 6.7172
	old_data_grads_norm = 5.1504
	sim_grads_norm = -0.0072
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1017
	data_grads_norm = 4.1178
	new_data_grads_norm = 7.1875
	old_data_grads_norm = 4.9172
	sim_grads_norm = -0.0336
-- Starting training on experience 95 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8818
	data_grads_norm = 3.7401
	new_data_grads_norm = 5.3191
	old_data_grads_norm = 5.1639
	sim_grads_norm = 0.0044
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7701
	data_grads_norm = 3.6053
	new_data_grads_norm = 5.4609
	old_data_grads_norm = 5.1634
	sim_grads_norm = -0.0450
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6093
	data_grads_norm = 4.9743
	new_data_grads_norm = 5.3271
	old_data_grads_norm = 7.3797
	sim_grads_norm = 0.0197
-- Starting training on experience 96 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3124
	data_grads_norm = 4.0473
	new_data_grads_norm = 6.3273
	old_data_grads_norm = 4.6328
	sim_grads_norm = 0.0142
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2334
	data_grads_norm = 4.3271
	new_data_grads_norm = 5.8034
	old_data_grads_norm = 6.8400
	sim_grads_norm = 0.0004
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3799
	data_grads_norm = 4.3807
	new_data_grads_norm = 6.8764
	old_data_grads_norm = 4.6231
	sim_grads_norm = 0.0588
-- Starting training on experience 97 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4053
	data_grads_norm = 4.8463
	new_data_grads_norm = 6.9528
	old_data_grads_norm = 5.9135
	sim_grads_norm = -0.0250
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5200
	data_grads_norm = 4.9456
	new_data_grads_norm = 7.4321
	old_data_grads_norm = 5.7081
	sim_grads_norm = 0.0052
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3948
	data_grads_norm = 4.8202
	new_data_grads_norm = 7.7198
	old_data_grads_norm = 4.3985
	sim_grads_norm = -0.0254
-- Starting training on experience 98 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5412
	data_grads_norm = 4.6118
	new_data_grads_norm = 6.4038
	old_data_grads_norm = 5.3294
	sim_grads_norm = -0.0315
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2051
	data_grads_norm = 3.9082
	new_data_grads_norm = 6.9093
	old_data_grads_norm = 3.8681
	sim_grads_norm = -0.0250
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3457
	data_grads_norm = 4.2626
	new_data_grads_norm = 6.6961
	old_data_grads_norm = 4.4385
	sim_grads_norm = 0.0139
-- Starting training on experience 99 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8320
	data_grads_norm = 5.0823
	new_data_grads_norm = 6.7274
	old_data_grads_norm = 5.9419
	sim_grads_norm = -0.0062
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3691
	data_grads_norm = 4.2263
	new_data_grads_norm = 7.5725
	old_data_grads_norm = 4.8904
	sim_grads_norm = 0.0222
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8111
	data_grads_norm = 4.8747
	new_data_grads_norm = 7.0730
	old_data_grads_norm = 5.3025
	sim_grads_norm = 0.0101
-- Starting training on experience 100 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5721
	data_grads_norm = 5.0717
	new_data_grads_norm = 6.4967
	old_data_grads_norm = 6.8333
	sim_grads_norm = -0.0328
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4703
	data_grads_norm = 4.5008
	new_data_grads_norm = 6.3367
	old_data_grads_norm = 5.7885
	sim_grads_norm = -0.0016
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8519
	data_grads_norm = 5.6435
	new_data_grads_norm = 6.6151
	old_data_grads_norm = 8.2237
	sim_grads_norm = 0.0404
-- Starting training on experience 101 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8845
	data_grads_norm = 3.4663
	new_data_grads_norm = 5.6783
	old_data_grads_norm = 4.1307
	sim_grads_norm = 0.0226
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3218
	data_grads_norm = 4.2783
	new_data_grads_norm = 5.8128
	old_data_grads_norm = 4.7603
	sim_grads_norm = 0.0058
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7129
	data_grads_norm = 4.6255
	new_data_grads_norm = 5.9865
	old_data_grads_norm = 6.8496
	sim_grads_norm = 0.0639
-- Starting training on experience 102 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5747
	data_grads_norm = 3.0126
	new_data_grads_norm = 6.1208
	old_data_grads_norm = 3.6754
	sim_grads_norm = 0.0421
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3893
	data_grads_norm = 4.8321
	new_data_grads_norm = 6.3210
	old_data_grads_norm = 5.7773
	sim_grads_norm = 0.0593
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3749
	data_grads_norm = 4.7052
	new_data_grads_norm = 6.8872
	old_data_grads_norm = 6.3732
	sim_grads_norm = -0.0482
-- Starting training on experience 103 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1559
	data_grads_norm = 4.5002
	new_data_grads_norm = 5.6088
	old_data_grads_norm = 5.9776
	sim_grads_norm = 0.0034
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0856
	data_grads_norm = 3.3874
	new_data_grads_norm = 5.6376
	old_data_grads_norm = 3.3136
	sim_grads_norm = -0.0347
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1779
	data_grads_norm = 4.0621
	new_data_grads_norm = 5.2668
	old_data_grads_norm = 5.3188
	sim_grads_norm = 0.0072
-- Starting training on experience 104 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1406
	data_grads_norm = 4.1043
	new_data_grads_norm = 6.3658
	old_data_grads_norm = 3.9420
	sim_grads_norm = -0.0241
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4868
	data_grads_norm = 4.6891
	new_data_grads_norm = 6.7340
	old_data_grads_norm = 6.1004
	sim_grads_norm = 0.0026
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0952
	data_grads_norm = 3.9879
	new_data_grads_norm = 6.4214
	old_data_grads_norm = 4.1946
	sim_grads_norm = 0.0124
-- Starting training on experience 105 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2691
	data_grads_norm = 4.2229
	new_data_grads_norm = 5.8477
	old_data_grads_norm = 5.0522
	sim_grads_norm = 0.0662
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7644
	data_grads_norm = 3.6776
	new_data_grads_norm = 5.0627
	old_data_grads_norm = 5.9779
	sim_grads_norm = -0.0394
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3509
	data_grads_norm = 3.2021
	new_data_grads_norm = 5.8931
	old_data_grads_norm = 3.9708
	sim_grads_norm = -0.0235
-- Starting training on experience 106 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6254
	data_grads_norm = 4.5059
	new_data_grads_norm = 5.5600
	old_data_grads_norm = 6.5913
	sim_grads_norm = 0.0126
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1907
	data_grads_norm = 4.2017
	new_data_grads_norm = 5.6822
	old_data_grads_norm = 5.9401
	sim_grads_norm = -0.0404
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0761
	data_grads_norm = 4.0347
	new_data_grads_norm = 5.6485
	old_data_grads_norm = 5.1669
	sim_grads_norm = -0.0503
-- Starting training on experience 107 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5406
	data_grads_norm = 3.9172
	new_data_grads_norm = 6.1185
	old_data_grads_norm = 4.7262
	sim_grads_norm = -0.0584
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6377
	data_grads_norm = 3.8035
	new_data_grads_norm = 5.9013
	old_data_grads_norm = 4.4280
	sim_grads_norm = 0.0828
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6277
	data_grads_norm = 4.1160
	new_data_grads_norm = 6.0528
	old_data_grads_norm = 4.7436
	sim_grads_norm = 0.0887
-- Starting training on experience 108 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6956
	data_grads_norm = 4.5707
	new_data_grads_norm = 6.8452
	old_data_grads_norm = 5.6007
	sim_grads_norm = 0.0145
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5779
	data_grads_norm = 4.6372
	new_data_grads_norm = 5.9764
	old_data_grads_norm = 4.8179
	sim_grads_norm = -0.0408
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8757
	data_grads_norm = 4.5164
	new_data_grads_norm = 6.4034
	old_data_grads_norm = 5.8158
	sim_grads_norm = -0.0056
-- Starting training on experience 109 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7091
	data_grads_norm = 3.9234
	new_data_grads_norm = 6.2285
	old_data_grads_norm = 4.9404
	sim_grads_norm = -0.0119
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9705
	data_grads_norm = 3.9349
	new_data_grads_norm = 6.2917
	old_data_grads_norm = 4.3674
	sim_grads_norm = -0.0383
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8070
	data_grads_norm = 4.2163
	new_data_grads_norm = 6.7650
	old_data_grads_norm = 4.3319
	sim_grads_norm = -0.0208
-- Starting training on experience 110 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2824
	data_grads_norm = 4.9826
	new_data_grads_norm = 7.0257
	old_data_grads_norm = 7.1629
	sim_grads_norm = 0.0446
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3314
	data_grads_norm = 4.0501
	new_data_grads_norm = 6.6040
	old_data_grads_norm = 5.0598
	sim_grads_norm = 0.0026
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2429
	data_grads_norm = 4.2158
	new_data_grads_norm = 6.5117
	old_data_grads_norm = 6.2965
	sim_grads_norm = -0.0162
-- Starting training on experience 111 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9491
	data_grads_norm = 5.8729
	new_data_grads_norm = 6.9848
	old_data_grads_norm = 7.6913
	sim_grads_norm = -0.0012
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3963
	data_grads_norm = 5.0857
	new_data_grads_norm = 6.8675
	old_data_grads_norm = 6.0916
	sim_grads_norm = 0.0186
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8233
	data_grads_norm = 3.9153
	new_data_grads_norm = 6.8241
	old_data_grads_norm = 4.2555
	sim_grads_norm = 0.0207
-- Starting training on experience 112 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7923
	data_grads_norm = 4.7522
	new_data_grads_norm = 7.4369
	old_data_grads_norm = 5.3646
	sim_grads_norm = 0.0247
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0390
	data_grads_norm = 4.7691
	new_data_grads_norm = 7.5833
	old_data_grads_norm = 4.6993
	sim_grads_norm = 0.0842
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5988
	data_grads_norm = 4.4211
	new_data_grads_norm = 7.2269
	old_data_grads_norm = 4.6696
	sim_grads_norm = 0.0493
-- Starting training on experience 113 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8534
	data_grads_norm = 4.9945
	new_data_grads_norm = 6.2234
	old_data_grads_norm = 6.6046
	sim_grads_norm = 0.0040
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5807
	data_grads_norm = 4.5955
	new_data_grads_norm = 6.7495
	old_data_grads_norm = 6.1671
	sim_grads_norm = -0.0196
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7626
	data_grads_norm = 4.8332
	new_data_grads_norm = 6.5181
	old_data_grads_norm = 5.3478
	sim_grads_norm = 0.0038
-- Starting training on experience 114 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0792
	data_grads_norm = 4.6093
	new_data_grads_norm = 6.4091
	old_data_grads_norm = 5.3268
	sim_grads_norm = -0.0477
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2066
	data_grads_norm = 4.3227
	new_data_grads_norm = 6.5038
	old_data_grads_norm = 4.9105
	sim_grads_norm = 0.0189
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3027
	data_grads_norm = 4.5206
	new_data_grads_norm = 7.0715
	old_data_grads_norm = 3.8585
	sim_grads_norm = 0.0714
-- Starting training on experience 115 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8466
	data_grads_norm = 5.0919
	new_data_grads_norm = 5.3542
	old_data_grads_norm = 8.2642
	sim_grads_norm = -0.0019
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5045
	data_grads_norm = 4.4610
	new_data_grads_norm = 6.0362
	old_data_grads_norm = 6.2281
	sim_grads_norm = -0.0200
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1898
	data_grads_norm = 3.9770
	new_data_grads_norm = 5.4428
	old_data_grads_norm = 5.5269
	sim_grads_norm = 0.0034
-- Starting training on experience 116 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0164
	data_grads_norm = 3.9697
	new_data_grads_norm = 6.0321
	old_data_grads_norm = 6.3468
	sim_grads_norm = 0.0246
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3790
	data_grads_norm = 4.1885
	new_data_grads_norm = 6.6528
	old_data_grads_norm = 5.0325
	sim_grads_norm = -0.0379
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8661
	data_grads_norm = 5.6065
	new_data_grads_norm = 7.5204
	old_data_grads_norm = 8.4901
	sim_grads_norm = 0.0324
-- Starting training on experience 117 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2756
	data_grads_norm = 4.1936
	new_data_grads_norm = 6.1055
	old_data_grads_norm = 6.1174
	sim_grads_norm = 0.1177
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7186
	data_grads_norm = 3.6286
	new_data_grads_norm = 6.4207
	old_data_grads_norm = 3.5064
	sim_grads_norm = -0.0085
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0863
	data_grads_norm = 4.0025
	new_data_grads_norm = 6.9355
	old_data_grads_norm = 4.2787
	sim_grads_norm = 0.0535
-- Starting training on experience 118 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3688
	data_grads_norm = 4.5853
	new_data_grads_norm = 7.8555
	old_data_grads_norm = 5.0821
	sim_grads_norm = 0.0098
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1421
	data_grads_norm = 4.2183
	new_data_grads_norm = 7.4349
	old_data_grads_norm = 5.0386
	sim_grads_norm = -0.0595
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6662
	data_grads_norm = 4.9017
	new_data_grads_norm = 7.4849
	old_data_grads_norm = 7.1418
	sim_grads_norm = 0.0306
-- Starting training on experience 119 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0277
	data_grads_norm = 3.9090
	new_data_grads_norm = 5.3905
	old_data_grads_norm = 6.7729
	sim_grads_norm = 0.0041
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7161
	data_grads_norm = 4.8267
	new_data_grads_norm = 5.7474
	old_data_grads_norm = 7.3610
	sim_grads_norm = 0.0175
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7405
	data_grads_norm = 3.4257
	new_data_grads_norm = 5.4571
	old_data_grads_norm = 4.6451
	sim_grads_norm = -0.0245
-- Starting training on experience 120 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9685
	data_grads_norm = 4.3290
	new_data_grads_norm = 6.3878
	old_data_grads_norm = 5.5314
	sim_grads_norm = 0.0349
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1236
	data_grads_norm = 4.3432
	new_data_grads_norm = 5.4237
	old_data_grads_norm = 7.1869
	sim_grads_norm = -0.0315
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8303
	data_grads_norm = 4.1117
	new_data_grads_norm = 5.8570
	old_data_grads_norm = 4.3915
	sim_grads_norm = -0.0263
-- Starting training on experience 121 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4521
	data_grads_norm = 3.8592
	new_data_grads_norm = 5.2824
	old_data_grads_norm = 5.4234
	sim_grads_norm = 0.0680
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2360
	data_grads_norm = 4.0014
	new_data_grads_norm = 5.3070
	old_data_grads_norm = 5.6679
	sim_grads_norm = 0.0718
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8165
	data_grads_norm = 3.5103
	new_data_grads_norm = 6.0593
	old_data_grads_norm = 4.5376
	sim_grads_norm = 0.0070
-- Starting training on experience 122 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3869
	data_grads_norm = 4.5900
	new_data_grads_norm = 6.5782
	old_data_grads_norm = 6.0691
	sim_grads_norm = 0.0333
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5337
	data_grads_norm = 4.7672
	new_data_grads_norm = 6.3125
	old_data_grads_norm = 5.8319
	sim_grads_norm = 0.0149
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1590
	data_grads_norm = 4.4000
	new_data_grads_norm = 6.3705
	old_data_grads_norm = 5.2371
	sim_grads_norm = 0.0120
-- Starting training on experience 123 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6183
	data_grads_norm = 4.8921
	new_data_grads_norm = 5.6486
	old_data_grads_norm = 7.0799
	sim_grads_norm = -0.0044
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9118
	data_grads_norm = 3.5708
	new_data_grads_norm = 6.2525
	old_data_grads_norm = 4.7630
	sim_grads_norm = -0.0364
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7192
	data_grads_norm = 5.2724
	new_data_grads_norm = 6.7253
	old_data_grads_norm = 5.9877
	sim_grads_norm = 0.0493
-- Starting training on experience 124 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4165
	data_grads_norm = 4.1306
	new_data_grads_norm = 5.6432
	old_data_grads_norm = 5.3271
	sim_grads_norm = -0.0170
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1057
	data_grads_norm = 4.0745
	new_data_grads_norm = 5.7740
	old_data_grads_norm = 3.9523
	sim_grads_norm = -0.0073
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1123
	data_grads_norm = 4.3529
	new_data_grads_norm = 5.6037
	old_data_grads_norm = 7.1416
	sim_grads_norm = 0.0168
-- Starting training on experience 125 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5465
	data_grads_norm = 4.6030
	new_data_grads_norm = 7.6742
	old_data_grads_norm = 5.3274
	sim_grads_norm = 0.0084
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0210
	data_grads_norm = 5.3690
	new_data_grads_norm = 8.0741
	old_data_grads_norm = 5.2722
	sim_grads_norm = 0.1425
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8001
	data_grads_norm = 5.1501
	new_data_grads_norm = 7.7923
	old_data_grads_norm = 5.8439
	sim_grads_norm = -0.0053
-- Starting training on experience 126 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6917
	data_grads_norm = 3.9032
	new_data_grads_norm = 6.7445
	old_data_grads_norm = 4.8719
	sim_grads_norm = -0.0415
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8728
	data_grads_norm = 4.4370
	new_data_grads_norm = 5.3740
	old_data_grads_norm = 6.6059
	sim_grads_norm = -0.0070
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2323
	data_grads_norm = 4.1439
	new_data_grads_norm = 5.5976
	old_data_grads_norm = 4.8019
	sim_grads_norm = 0.0707
-- Starting training on experience 127 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5089
	data_grads_norm = 4.6181
	new_data_grads_norm = 7.5723
	old_data_grads_norm = 5.5797
	sim_grads_norm = 0.0383
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6326
	data_grads_norm = 4.9033
	new_data_grads_norm = 6.9930
	old_data_grads_norm = 6.6412
	sim_grads_norm = 0.0294
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9238
	data_grads_norm = 3.9237
	new_data_grads_norm = 7.6759
	old_data_grads_norm = 4.1857
	sim_grads_norm = -0.0127
-- Starting training on experience 128 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5935
	data_grads_norm = 4.3609
	new_data_grads_norm = 7.1735
	old_data_grads_norm = 5.1689
	sim_grads_norm = -0.0134
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8046
	data_grads_norm = 5.1439
	new_data_grads_norm = 7.9323
	old_data_grads_norm = 5.9394
	sim_grads_norm = -0.0063
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0128
	data_grads_norm = 4.8636
	new_data_grads_norm = 7.8100
	old_data_grads_norm = 5.1504
	sim_grads_norm = 0.0027
-- Starting training on experience 129 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9630
	data_grads_norm = 4.0158
	new_data_grads_norm = 6.4017
	old_data_grads_norm = 3.3573
	sim_grads_norm = -0.0003
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3502
	data_grads_norm = 4.2660
	new_data_grads_norm = 6.7840
	old_data_grads_norm = 5.3859
	sim_grads_norm = 0.0583
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7141
	data_grads_norm = 4.7185
	new_data_grads_norm = 5.9935
	old_data_grads_norm = 7.1473
	sim_grads_norm = 0.0422
-- Starting training on experience 130 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0604
	data_grads_norm = 4.5529
	new_data_grads_norm = 7.8940
	old_data_grads_norm = 4.2767
	sim_grads_norm = -0.0124
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4440
	data_grads_norm = 4.6508
	new_data_grads_norm = 7.4208
	old_data_grads_norm = 4.1349
	sim_grads_norm = 0.0260
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1227
	data_grads_norm = 4.3894
	new_data_grads_norm = 7.3703
	old_data_grads_norm = 4.0347
	sim_grads_norm = -0.0082
-- Starting training on experience 131 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0070
	data_grads_norm = 3.7501
	new_data_grads_norm = 7.0829
	old_data_grads_norm = 4.4874
	sim_grads_norm = -0.0382
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1702
	data_grads_norm = 4.1872
	new_data_grads_norm = 7.2060
	old_data_grads_norm = 5.0375
	sim_grads_norm = -0.0438
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4065
	data_grads_norm = 4.3098
	new_data_grads_norm = 6.8245
	old_data_grads_norm = 5.4104
	sim_grads_norm = -0.0556
-- Starting training on experience 132 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4739
	data_grads_norm = 4.4767
	new_data_grads_norm = 6.3558
	old_data_grads_norm = 5.8881
	sim_grads_norm = 0.0425
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2069
	data_grads_norm = 3.9780
	new_data_grads_norm = 5.7183
	old_data_grads_norm = 5.3055
	sim_grads_norm = -0.0078
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9767
	data_grads_norm = 3.4288
	new_data_grads_norm = 5.9254
	old_data_grads_norm = 3.4309
	sim_grads_norm = 0.0046
-- Starting training on experience 133 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8880
	data_grads_norm = 4.5007
	new_data_grads_norm = 7.2835
	old_data_grads_norm = 5.6242
	sim_grads_norm = -0.0199
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5741
	data_grads_norm = 4.2915
	new_data_grads_norm = 7.1291
	old_data_grads_norm = 4.2323
	sim_grads_norm = -0.0131
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5788
	data_grads_norm = 5.0153
	new_data_grads_norm = 6.9041
	old_data_grads_norm = 5.8913
	sim_grads_norm = 0.0235
-- Starting training on experience 134 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2030
	data_grads_norm = 3.9015
	new_data_grads_norm = 6.0010
	old_data_grads_norm = 3.8168
	sim_grads_norm = 0.0104
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0474
	data_grads_norm = 3.8376
	new_data_grads_norm = 6.3194
	old_data_grads_norm = 3.7981
	sim_grads_norm = -0.0292
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2914
	data_grads_norm = 4.3399
	new_data_grads_norm = 6.3832
	old_data_grads_norm = 6.0622
	sim_grads_norm = -0.0015
-- Starting training on experience 135 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4232
	data_grads_norm = 3.8787
	new_data_grads_norm = 6.9976
	old_data_grads_norm = 3.3059
	sim_grads_norm = -0.0283
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4553
	data_grads_norm = 4.3088
	new_data_grads_norm = 6.8064
	old_data_grads_norm = 6.2737
	sim_grads_norm = 0.0208
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3745
	data_grads_norm = 4.0307
	new_data_grads_norm = 5.7917
	old_data_grads_norm = 5.5780
	sim_grads_norm = -0.0024
-- Starting training on experience 136 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4807
	data_grads_norm = 4.7879
	new_data_grads_norm = 7.4365
	old_data_grads_norm = 4.7872
	sim_grads_norm = -0.0009
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2101
	data_grads_norm = 4.1077
	new_data_grads_norm = 6.3444
	old_data_grads_norm = 4.2247
	sim_grads_norm = 0.0467
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7231
	data_grads_norm = 4.4551
	new_data_grads_norm = 6.4027
	old_data_grads_norm = 5.2957
	sim_grads_norm = 0.0345
-- Starting training on experience 137 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8013
	data_grads_norm = 4.0821
	new_data_grads_norm = 6.2705
	old_data_grads_norm = 4.9402
	sim_grads_norm = 0.0183
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1815
	data_grads_norm = 3.7102
	new_data_grads_norm = 6.3103
	old_data_grads_norm = 3.7082
	sim_grads_norm = 0.0169
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7831
	data_grads_norm = 4.7475
	new_data_grads_norm = 6.4952
	old_data_grads_norm = 6.5507
	sim_grads_norm = -0.0008
-- Starting training on experience 138 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6701
	data_grads_norm = 4.7776
	new_data_grads_norm = 7.1025
	old_data_grads_norm = 5.0943
	sim_grads_norm = 0.0890
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6950
	data_grads_norm = 3.9266
	new_data_grads_norm = 7.5948
	old_data_grads_norm = 3.6349
	sim_grads_norm = -0.0583
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0472
	data_grads_norm = 4.8984
	new_data_grads_norm = 8.1723
	old_data_grads_norm = 5.0322
	sim_grads_norm = 0.1099
-- Starting training on experience 139 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8980
	data_grads_norm = 3.6465
	new_data_grads_norm = 6.6757
	old_data_grads_norm = 4.5089
	sim_grads_norm = -0.0157
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1046
	data_grads_norm = 3.9073
	new_data_grads_norm = 6.9658
	old_data_grads_norm = 5.3019
	sim_grads_norm = 0.0321
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5472
	data_grads_norm = 4.4283
	new_data_grads_norm = 6.8866
	old_data_grads_norm = 5.8297
	sim_grads_norm = 0.0276
-- Starting training on experience 140 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2087
	data_grads_norm = 4.2289
	new_data_grads_norm = 6.0368
	old_data_grads_norm = 4.1764
	sim_grads_norm = 0.0014
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2016
	data_grads_norm = 4.9264
	new_data_grads_norm = 6.1801
	old_data_grads_norm = 7.4317
	sim_grads_norm = 0.0228
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3699
	data_grads_norm = 4.3577
	new_data_grads_norm = 6.0610
	old_data_grads_norm = 5.5924
	sim_grads_norm = -0.0192
-- Starting training on experience 141 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9542
	data_grads_norm = 3.8284
	new_data_grads_norm = 6.1456
	old_data_grads_norm = 4.7239
	sim_grads_norm = 0.0259
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9418
	data_grads_norm = 4.1942
	new_data_grads_norm = 6.4856
	old_data_grads_norm = 4.8206
	sim_grads_norm = 0.0424
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4072
	data_grads_norm = 4.4981
	new_data_grads_norm = 6.6118
	old_data_grads_norm = 5.9947
	sim_grads_norm = 0.0177
-- Starting training on experience 142 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1705
	data_grads_norm = 4.5642
	new_data_grads_norm = 6.3098
	old_data_grads_norm = 5.5431
	sim_grads_norm = -0.0159
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3457
	data_grads_norm = 4.6193
	new_data_grads_norm = 6.3315
	old_data_grads_norm = 4.6915
	sim_grads_norm = 0.1558
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8268
	data_grads_norm = 4.2940
	new_data_grads_norm = 6.2881
	old_data_grads_norm = 5.2391
	sim_grads_norm = 0.0290
-- Starting training on experience 143 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6121
	data_grads_norm = 3.3683
	new_data_grads_norm = 5.4400
	old_data_grads_norm = 3.3189
	sim_grads_norm = -0.0335
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9076
	data_grads_norm = 3.7989
	new_data_grads_norm = 5.7581
	old_data_grads_norm = 5.0220
	sim_grads_norm = -0.0466
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0339
	data_grads_norm = 4.4684
	new_data_grads_norm = 6.7058
	old_data_grads_norm = 5.9267
	sim_grads_norm = -0.0185
-- Starting training on experience 144 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2638
	data_grads_norm = 4.2001
	new_data_grads_norm = 7.1468
	old_data_grads_norm = 3.8432
	sim_grads_norm = 0.0053
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3815
	data_grads_norm = 4.7304
	new_data_grads_norm = 6.6775
	old_data_grads_norm = 6.6584
	sim_grads_norm = -0.0052
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9211
	data_grads_norm = 3.8984
	new_data_grads_norm = 7.6818
	old_data_grads_norm = 3.9225
	sim_grads_norm = 0.0158
-- Starting training on experience 145 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9251
	data_grads_norm = 4.3359
	new_data_grads_norm = 6.7715
	old_data_grads_norm = 6.8999
	sim_grads_norm = -0.0058
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0733
	data_grads_norm = 4.2612
	new_data_grads_norm = 6.6814
	old_data_grads_norm = 5.5059
	sim_grads_norm = 0.0500
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4251
	data_grads_norm = 4.5903
	new_data_grads_norm = 6.5447
	old_data_grads_norm = 5.7805
	sim_grads_norm = -0.0462
-- Starting training on experience 146 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7329
	data_grads_norm = 3.8906
	new_data_grads_norm = 5.7776
	old_data_grads_norm = 5.4762
	sim_grads_norm = 0.0022
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8604
	data_grads_norm = 4.1701
	new_data_grads_norm = 6.1545
	old_data_grads_norm = 5.4547
	sim_grads_norm = -0.0304
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5389
	data_grads_norm = 3.3996
	new_data_grads_norm = 6.0442
	old_data_grads_norm = 4.4645
	sim_grads_norm = -0.0482
-- Starting training on experience 147 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7741
	data_grads_norm = 4.4105
	new_data_grads_norm = 6.6565
	old_data_grads_norm = 5.6132
	sim_grads_norm = 0.0233
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4048
	data_grads_norm = 4.9265
	new_data_grads_norm = 6.7222
	old_data_grads_norm = 7.2862
	sim_grads_norm = 0.0586
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9152
	data_grads_norm = 4.9195
	new_data_grads_norm = 6.2480
	old_data_grads_norm = 6.8020
	sim_grads_norm = 0.0028
-- Starting training on experience 148 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1339
	data_grads_norm = 4.7711
	new_data_grads_norm = 7.3805
	old_data_grads_norm = 5.0328
	sim_grads_norm = 0.0187
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5885
	data_grads_norm = 5.0554
	new_data_grads_norm = 7.5974
	old_data_grads_norm = 5.2623
	sim_grads_norm = -0.0192
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1430
	data_grads_norm = 4.5957
	new_data_grads_norm = 7.5233
	old_data_grads_norm = 4.9294
	sim_grads_norm = -0.0210
-- Starting training on experience 149 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3482
	data_grads_norm = 4.6554
	new_data_grads_norm = 6.0905
	old_data_grads_norm = 6.3487
	sim_grads_norm = 0.1128
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8157
	data_grads_norm = 3.7168
	new_data_grads_norm = 6.4210
	old_data_grads_norm = 3.6384
	sim_grads_norm = 0.0385
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0397
	data_grads_norm = 3.9990
	new_data_grads_norm = 5.2849
	old_data_grads_norm = 5.4117
	sim_grads_norm = -0.0044
-- Starting training on experience 150 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8819
	data_grads_norm = 4.3014
	new_data_grads_norm = 6.9657
	old_data_grads_norm = 6.5216
	sim_grads_norm = -0.0041
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4096
	data_grads_norm = 5.2161
	new_data_grads_norm = 7.2327
	old_data_grads_norm = 6.4956
	sim_grads_norm = -0.0383
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2133
	data_grads_norm = 4.6869
	new_data_grads_norm = 7.0532
	old_data_grads_norm = 6.0757
	sim_grads_norm = -0.0190
-- Starting training on experience 151 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3676
	data_grads_norm = 5.3155
	new_data_grads_norm = 7.7239
	old_data_grads_norm = 5.8852
	sim_grads_norm = 0.0010
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1176
	data_grads_norm = 4.2135
	new_data_grads_norm = 7.8562
	old_data_grads_norm = 2.7581
	sim_grads_norm = -0.0080
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6687
	data_grads_norm = 5.0705
	new_data_grads_norm = 7.5654
	old_data_grads_norm = 6.2561
	sim_grads_norm = 0.0407
-- Starting training on experience 152 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3653
	data_grads_norm = 4.8098
	new_data_grads_norm = 7.0304
	old_data_grads_norm = 3.6598
	sim_grads_norm = -0.0086
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3984
	data_grads_norm = 4.6229
	new_data_grads_norm = 7.0344
	old_data_grads_norm = 4.4329
	sim_grads_norm = 0.0002
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8478
	data_grads_norm = 5.0832
	new_data_grads_norm = 7.0936
	old_data_grads_norm = 4.6210
	sim_grads_norm = 0.0766
-- Starting training on experience 153 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2336
	data_grads_norm = 4.4988
	new_data_grads_norm = 5.6812
	old_data_grads_norm = 6.6439
	sim_grads_norm = 0.0000
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4147
	data_grads_norm = 4.7006
	new_data_grads_norm = 5.3557
	old_data_grads_norm = 5.9986
	sim_grads_norm = -0.0034
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0775
	data_grads_norm = 4.5912
	new_data_grads_norm = 5.7533
	old_data_grads_norm = 6.7301
	sim_grads_norm = 0.0655
-- Starting training on experience 154 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4296
	data_grads_norm = 4.6395
	new_data_grads_norm = 6.8296
	old_data_grads_norm = 5.2690
	sim_grads_norm = 0.1135
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0024
	data_grads_norm = 3.7761
	new_data_grads_norm = 5.4214
	old_data_grads_norm = 4.7890
	sim_grads_norm = -0.0058
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1623
	data_grads_norm = 4.6127
	new_data_grads_norm = 6.1933
	old_data_grads_norm = 8.3203
	sim_grads_norm = -0.0016
-- Starting training on experience 155 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9050
	data_grads_norm = 4.3754
	new_data_grads_norm = 6.1007
	old_data_grads_norm = 7.3884
	sim_grads_norm = 0.0338
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6224
	data_grads_norm = 3.6769
	new_data_grads_norm = 4.7360
	old_data_grads_norm = 5.5270
	sim_grads_norm = -0.0442
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7669
	data_grads_norm = 3.5400
	new_data_grads_norm = 5.5638
	old_data_grads_norm = 4.5763
	sim_grads_norm = 0.0068
-- Starting training on experience 156 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2479
	data_grads_norm = 4.2461
	new_data_grads_norm = 6.2902
	old_data_grads_norm = 5.9460
	sim_grads_norm = -0.0356
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2148
	data_grads_norm = 3.8800
	new_data_grads_norm = 6.0477
	old_data_grads_norm = 3.7997
	sim_grads_norm = 0.0114
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4395
	data_grads_norm = 4.2796
	new_data_grads_norm = 6.7600
	old_data_grads_norm = 5.4497
	sim_grads_norm = 0.0067
-- Starting training on experience 157 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1566
	data_grads_norm = 4.1919
	new_data_grads_norm = 5.8934
	old_data_grads_norm = 4.7895
	sim_grads_norm = 0.0490
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5942
	data_grads_norm = 3.6076
	new_data_grads_norm = 5.8041
	old_data_grads_norm = 4.2500
	sim_grads_norm = 0.0240
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8095
	data_grads_norm = 4.1862
	new_data_grads_norm = 6.0627
	old_data_grads_norm = 5.6474
	sim_grads_norm = 0.0592
-- Starting training on experience 158 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2175
	data_grads_norm = 4.2197
	new_data_grads_norm = 6.9739
	old_data_grads_norm = 4.4447
	sim_grads_norm = 0.0041
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5773
	data_grads_norm = 5.3470
	new_data_grads_norm = 7.9756
	old_data_grads_norm = 6.2030
	sim_grads_norm = -0.0076
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6336
	data_grads_norm = 5.0422
	new_data_grads_norm = 7.5088
	old_data_grads_norm = 6.5672
	sim_grads_norm = 0.0236
-- Starting training on experience 159 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3772
	data_grads_norm = 4.1157
	new_data_grads_norm = 5.9035
	old_data_grads_norm = 6.1030
	sim_grads_norm = 0.0001
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3785
	data_grads_norm = 4.3835
	new_data_grads_norm = 6.2100
	old_data_grads_norm = 5.2312
	sim_grads_norm = -0.0177
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5917
	data_grads_norm = 4.4822
	new_data_grads_norm = 6.4318
	old_data_grads_norm = 5.4353
	sim_grads_norm = -0.0060
-- Starting training on experience 160 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3758
	data_grads_norm = 4.3164
	new_data_grads_norm = 6.2007
	old_data_grads_norm = 4.0453
	sim_grads_norm = 0.0661
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2311
	data_grads_norm = 4.7821
	new_data_grads_norm = 6.6271
	old_data_grads_norm = 4.6702
	sim_grads_norm = -0.0231
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6851
	data_grads_norm = 4.4760
	new_data_grads_norm = 5.3442
	old_data_grads_norm = 6.3987
	sim_grads_norm = 0.0481
-- Starting training on experience 161 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1429
	data_grads_norm = 4.6978
	new_data_grads_norm = 6.7705
	old_data_grads_norm = 4.2550
	sim_grads_norm = 0.0172
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6531
	data_grads_norm = 4.6096
	new_data_grads_norm = 6.2863
	old_data_grads_norm = 6.4449
	sim_grads_norm = -0.0218
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0556
	data_grads_norm = 5.1843
	new_data_grads_norm = 7.1060
	old_data_grads_norm = 6.3718
	sim_grads_norm = 0.0034
-- Starting training on experience 162 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4728
	data_grads_norm = 6.0502
	new_data_grads_norm = 7.4573
	old_data_grads_norm = 8.9925
	sim_grads_norm = -0.0087
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8062
	data_grads_norm = 5.4985
	new_data_grads_norm = 8.3073
	old_data_grads_norm = 6.2806
	sim_grads_norm = 0.0067
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5531
	data_grads_norm = 5.1161
	new_data_grads_norm = 8.3704
	old_data_grads_norm = 5.1724
	sim_grads_norm = 0.0080
-- Starting training on experience 163 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5715
	data_grads_norm = 4.5117
	new_data_grads_norm = 7.2344
	old_data_grads_norm = 5.4357
	sim_grads_norm = 0.0224
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6735
	data_grads_norm = 3.3104
	new_data_grads_norm = 6.2181
	old_data_grads_norm = 3.3626
	sim_grads_norm = 0.0066
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2553
	data_grads_norm = 4.2914
	new_data_grads_norm = 6.4857
	old_data_grads_norm = 5.8097
	sim_grads_norm = -0.0296
-- Starting training on experience 164 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3019
	data_grads_norm = 5.3917
	new_data_grads_norm = 6.7607
	old_data_grads_norm = 7.4636
	sim_grads_norm = 0.0346
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1624
	data_grads_norm = 4.1894
	new_data_grads_norm = 6.1895
	old_data_grads_norm = 5.4112
	sim_grads_norm = -0.0179
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0009
	data_grads_norm = 3.8165
	new_data_grads_norm = 6.5805
	old_data_grads_norm = 6.1745
	sim_grads_norm = -0.0110
-- Starting training on experience 165 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0469
	data_grads_norm = 4.3256
	new_data_grads_norm = 6.8015
	old_data_grads_norm = 5.8704
	sim_grads_norm = -0.0052
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1720
	data_grads_norm = 4.0270
	new_data_grads_norm = 6.4413
	old_data_grads_norm = 4.5389
	sim_grads_norm = -0.0209
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7813
	data_grads_norm = 4.5239
	new_data_grads_norm = 6.6452
	old_data_grads_norm = 5.8296
	sim_grads_norm = 0.0841
-- Starting training on experience 166 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7866
	data_grads_norm = 4.8478
	new_data_grads_norm = 7.5925
	old_data_grads_norm = 5.9657
	sim_grads_norm = 0.0186
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9985
	data_grads_norm = 3.9315
	new_data_grads_norm = 6.6028
	old_data_grads_norm = 4.0077
	sim_grads_norm = -0.0292
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6315
	data_grads_norm = 4.8348
	new_data_grads_norm = 6.7529
	old_data_grads_norm = 6.9468
	sim_grads_norm = -0.0038
-- Starting training on experience 167 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9039
	data_grads_norm = 3.9121
	new_data_grads_norm = 6.3032
	old_data_grads_norm = 4.5092
	sim_grads_norm = -0.0192
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7886
	data_grads_norm = 3.3883
	new_data_grads_norm = 5.7328
	old_data_grads_norm = 2.8840
	sim_grads_norm = -0.0462
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3640
	data_grads_norm = 4.2142
	new_data_grads_norm = 5.8218
	old_data_grads_norm = 6.3455
	sim_grads_norm = 0.0712
-- Starting training on experience 168 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2910
	data_grads_norm = 4.5615
	new_data_grads_norm = 7.2165
	old_data_grads_norm = 3.9704
	sim_grads_norm = 0.1301
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6835
	data_grads_norm = 3.5086
	new_data_grads_norm = 5.7460
	old_data_grads_norm = 5.2411
	sim_grads_norm = 0.0072
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9307
	data_grads_norm = 4.2374
	new_data_grads_norm = 6.3452
	old_data_grads_norm = 5.7762
	sim_grads_norm = 0.0719
-- Starting training on experience 169 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8372
	data_grads_norm = 3.8430
	new_data_grads_norm = 6.7493
	old_data_grads_norm = 3.3767
	sim_grads_norm = 0.0002
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7620
	data_grads_norm = 5.1587
	new_data_grads_norm = 6.9495
	old_data_grads_norm = 6.4811
	sim_grads_norm = 0.0379
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2335
	data_grads_norm = 4.7188
	new_data_grads_norm = 6.5032
	old_data_grads_norm = 6.9057
	sim_grads_norm = -0.0197
-- Starting training on experience 170 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0807
	data_grads_norm = 4.9323
	new_data_grads_norm = 8.0025
	old_data_grads_norm = 5.5444
	sim_grads_norm = 0.0207
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9222
	data_grads_norm = 4.0161
	new_data_grads_norm = 7.6692
	old_data_grads_norm = 4.7522
	sim_grads_norm = 0.0292
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1349
	data_grads_norm = 4.4595
	new_data_grads_norm = 7.3938
	old_data_grads_norm = 5.2633
	sim_grads_norm = -0.0392
-- Starting training on experience 171 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9198
	data_grads_norm = 4.3088
	new_data_grads_norm = 7.3605
	old_data_grads_norm = 4.9681
	sim_grads_norm = -0.0195
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7824
	data_grads_norm = 4.6490
	new_data_grads_norm = 7.3075
	old_data_grads_norm = 5.2586
	sim_grads_norm = -0.0181
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4071
	data_grads_norm = 4.1824
	new_data_grads_norm = 7.4892
	old_data_grads_norm = 6.3733
	sim_grads_norm = -0.0516
-- Starting training on experience 172 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1432
	data_grads_norm = 5.3703
	new_data_grads_norm = 6.6369
	old_data_grads_norm = 7.6993
	sim_grads_norm = -0.0147
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0691
	data_grads_norm = 3.8415
	new_data_grads_norm = 6.7056
	old_data_grads_norm = 3.7889
	sim_grads_norm = -0.0001
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2253
	data_grads_norm = 4.5362
	new_data_grads_norm = 6.0680
	old_data_grads_norm = 6.3957
	sim_grads_norm = -0.0236
-- Starting training on experience 173 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8194
	data_grads_norm = 3.6216
	new_data_grads_norm = 5.5433
	old_data_grads_norm = 4.3926
	sim_grads_norm = 0.0181
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3624
	data_grads_norm = 3.8520
	new_data_grads_norm = 5.6211
	old_data_grads_norm = 4.8094
	sim_grads_norm = 0.0625
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3544
	data_grads_norm = 4.0519
	new_data_grads_norm = 5.2322
	old_data_grads_norm = 5.7651
	sim_grads_norm = -0.0337
-- Starting training on experience 174 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3797
	data_grads_norm = 4.4510
	new_data_grads_norm = 6.6323
	old_data_grads_norm = 6.5013
	sim_grads_norm = 0.0124
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4273
	data_grads_norm = 4.7745
	new_data_grads_norm = 6.0224
	old_data_grads_norm = 6.1406
	sim_grads_norm = 0.0218
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5221
	data_grads_norm = 4.4537
	new_data_grads_norm = 6.7189
	old_data_grads_norm = 6.8401
	sim_grads_norm = 0.0366
-- Starting training on experience 175 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7481
	data_grads_norm = 3.8242
	new_data_grads_norm = 6.2472
	old_data_grads_norm = 4.9823
	sim_grads_norm = -0.0655
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8388
	data_grads_norm = 5.2249
	new_data_grads_norm = 7.0689
	old_data_grads_norm = 7.5992
	sim_grads_norm = -0.0254
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3046
	data_grads_norm = 4.7969
	new_data_grads_norm = 6.7417
	old_data_grads_norm = 4.9494
	sim_grads_norm = -0.0457
-- Starting training on experience 176 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7462
	data_grads_norm = 4.4023
	new_data_grads_norm = 7.4332
	old_data_grads_norm = 5.2164
	sim_grads_norm = -0.0083
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3742
	data_grads_norm = 3.9749
	new_data_grads_norm = 7.4456
	old_data_grads_norm = 4.2579
	sim_grads_norm = -0.0234
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3428
	data_grads_norm = 4.3527
	new_data_grads_norm = 6.7025
	old_data_grads_norm = 5.3032
	sim_grads_norm = -0.0123
-- Starting training on experience 177 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7488
	data_grads_norm = 4.0369
	new_data_grads_norm = 6.2528
	old_data_grads_norm = 5.3498
	sim_grads_norm = -0.0039
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9368
	data_grads_norm = 4.0874
	new_data_grads_norm = 6.5474
	old_data_grads_norm = 4.3109
	sim_grads_norm = -0.0114
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8724
	data_grads_norm = 3.8681
	new_data_grads_norm = 6.4611
	old_data_grads_norm = 4.3826
	sim_grads_norm = 0.0003
-- Starting training on experience 178 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6082
	data_grads_norm = 4.9399
	new_data_grads_norm = 6.8120
	old_data_grads_norm = 6.2294
	sim_grads_norm = 0.0293
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8065
	data_grads_norm = 3.5621
	new_data_grads_norm = 5.8887
	old_data_grads_norm = 5.7321
	sim_grads_norm = -0.0154
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0790
	data_grads_norm = 4.4833
	new_data_grads_norm = 6.8711
	old_data_grads_norm = 5.9691
	sim_grads_norm = 0.0157
-- Starting training on experience 179 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5138
	data_grads_norm = 4.5263
	new_data_grads_norm = 6.7091
	old_data_grads_norm = 5.0308
	sim_grads_norm = 0.0316
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8180
	data_grads_norm = 4.9629
	new_data_grads_norm = 6.9791
	old_data_grads_norm = 5.6734
	sim_grads_norm = -0.0010
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4146
	data_grads_norm = 4.6144
	new_data_grads_norm = 6.8635
	old_data_grads_norm = 5.1336
	sim_grads_norm = -0.0194
-- Starting training on experience 180 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6118
	data_grads_norm = 4.1532
	new_data_grads_norm = 7.4204
	old_data_grads_norm = 3.6075
	sim_grads_norm = -0.0069
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7764
	data_grads_norm = 4.2677
	new_data_grads_norm = 8.1762
	old_data_grads_norm = 4.3759
	sim_grads_norm = 0.0235
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6773
	data_grads_norm = 5.0821
	new_data_grads_norm = 7.2627
	old_data_grads_norm = 6.8192
	sim_grads_norm = 0.0118
-- Starting training on experience 181 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8215
	data_grads_norm = 4.1402
	new_data_grads_norm = 6.6154
	old_data_grads_norm = 5.5271
	sim_grads_norm = 0.0339
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8543
	data_grads_norm = 4.5235
	new_data_grads_norm = 6.5440
	old_data_grads_norm = 6.5563
	sim_grads_norm = -0.0095
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8608
	data_grads_norm = 4.8073
	new_data_grads_norm = 6.9057
	old_data_grads_norm = 6.0780
	sim_grads_norm = -0.0198
-- Starting training on experience 182 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2542
	data_grads_norm = 4.2461
	new_data_grads_norm = 6.2489
	old_data_grads_norm = 5.2429
	sim_grads_norm = -0.0252
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1744
	data_grads_norm = 3.9044
	new_data_grads_norm = 6.0363
	old_data_grads_norm = 4.3698
	sim_grads_norm = -0.0088
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5049
	data_grads_norm = 4.5087
	new_data_grads_norm = 6.5200
	old_data_grads_norm = 3.5702
	sim_grads_norm = 0.0803
-- Starting training on experience 183 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5389
	data_grads_norm = 4.2354
	new_data_grads_norm = 6.2707
	old_data_grads_norm = 6.1478
	sim_grads_norm = -0.0150
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5704
	data_grads_norm = 4.5558
	new_data_grads_norm = 6.5658
	old_data_grads_norm = 5.3164
	sim_grads_norm = 0.0629
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3232
	data_grads_norm = 4.4177
	new_data_grads_norm = 6.8666
	old_data_grads_norm = 4.4736
	sim_grads_norm = 0.0043
-- Starting training on experience 184 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4577
	data_grads_norm = 4.0797
	new_data_grads_norm = 6.3383
	old_data_grads_norm = 4.4835
	sim_grads_norm = 0.0381
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4772
	data_grads_norm = 4.5083
	new_data_grads_norm = 6.6846
	old_data_grads_norm = 6.3353
	sim_grads_norm = -0.0781
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0474
	data_grads_norm = 4.5120
	new_data_grads_norm = 7.1095
	old_data_grads_norm = 6.1710
	sim_grads_norm = -0.0087
-- Starting training on experience 185 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2303
	data_grads_norm = 4.5129
	new_data_grads_norm = 6.9266
	old_data_grads_norm = 5.2619
	sim_grads_norm = 0.0617
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7358
	data_grads_norm = 4.4442
	new_data_grads_norm = 6.8031
	old_data_grads_norm = 6.4790
	sim_grads_norm = -0.0118
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4013
	data_grads_norm = 4.9066
	new_data_grads_norm = 7.2410
	old_data_grads_norm = 6.2923
	sim_grads_norm = 0.1283
-- Starting training on experience 186 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8556
	data_grads_norm = 5.0621
	new_data_grads_norm = 7.6417
	old_data_grads_norm = 6.7758
	sim_grads_norm = 0.0460
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5378
	data_grads_norm = 4.8617
	new_data_grads_norm = 7.5090
	old_data_grads_norm = 6.5252
	sim_grads_norm = 0.0106
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1408
	data_grads_norm = 4.5804
	new_data_grads_norm = 7.4356
	old_data_grads_norm = 5.1534
	sim_grads_norm = -0.0176
-- Starting training on experience 187 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6061
	data_grads_norm = 4.8316
	new_data_grads_norm = 6.7273
	old_data_grads_norm = 5.1577
	sim_grads_norm = 0.0362
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5462
	data_grads_norm = 5.6271
	new_data_grads_norm = 7.0443
	old_data_grads_norm = 6.8460
	sim_grads_norm = 0.0657
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7453
	data_grads_norm = 4.9618
	new_data_grads_norm = 7.2571
	old_data_grads_norm = 6.4436
	sim_grads_norm = -0.0278
-- Starting training on experience 188 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7629
	data_grads_norm = 5.4103
	new_data_grads_norm = 6.5584
	old_data_grads_norm = 6.8834
	sim_grads_norm = 0.0637
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2275
	data_grads_norm = 4.2044
	new_data_grads_norm = 5.5948
	old_data_grads_norm = 5.7734
	sim_grads_norm = -0.0298
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5898
	data_grads_norm = 3.4979
	new_data_grads_norm = 6.3839
	old_data_grads_norm = 2.3818
	sim_grads_norm = -0.0003
-- Starting training on experience 189 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5350
	data_grads_norm = 4.4103
	new_data_grads_norm = 6.6751
	old_data_grads_norm = 5.7176
	sim_grads_norm = -0.0316
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3482
	data_grads_norm = 3.8412
	new_data_grads_norm = 5.9465
	old_data_grads_norm = 4.5621
	sim_grads_norm = 0.0578
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2498
	data_grads_norm = 4.3124
	new_data_grads_norm = 5.8836
	old_data_grads_norm = 5.5056
	sim_grads_norm = -0.0044
-- Starting training on experience 190 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1645
	data_grads_norm = 4.1200
	new_data_grads_norm = 6.5072
	old_data_grads_norm = 4.8558
	sim_grads_norm = 0.0263
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7219
	data_grads_norm = 5.5283
	new_data_grads_norm = 6.1884
	old_data_grads_norm = 8.5516
	sim_grads_norm = 0.0928
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1077
	data_grads_norm = 4.5109
	new_data_grads_norm = 6.3160
	old_data_grads_norm = 5.1411
	sim_grads_norm = 0.0141
-- Starting training on experience 191 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3403
	data_grads_norm = 4.7255
	new_data_grads_norm = 6.1465
	old_data_grads_norm = 5.8464
	sim_grads_norm = 0.0298
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2708
	data_grads_norm = 4.9630
	new_data_grads_norm = 6.8095
	old_data_grads_norm = 5.7865
	sim_grads_norm = -0.0015
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0477
	data_grads_norm = 4.0599
	new_data_grads_norm = 6.2256
	old_data_grads_norm = 2.9031
	sim_grads_norm = 0.0108
-- Starting training on experience 192 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6672
	data_grads_norm = 5.0495
	new_data_grads_norm = 8.8068
	old_data_grads_norm = 6.0835
	sim_grads_norm = -0.0067
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4668
	data_grads_norm = 4.7524
	new_data_grads_norm = 7.5847
	old_data_grads_norm = 6.2439
	sim_grads_norm = -0.0182
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1289
	data_grads_norm = 4.5141
	new_data_grads_norm = 7.7341
	old_data_grads_norm = 5.5575
	sim_grads_norm = -0.0295
-- Starting training on experience 193 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4565
	data_grads_norm = 4.8309
	new_data_grads_norm = 6.0229
	old_data_grads_norm = 6.2912
	sim_grads_norm = 0.0398
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1963
	data_grads_norm = 4.3357
	new_data_grads_norm = 5.6150
	old_data_grads_norm = 5.9520
	sim_grads_norm = -0.0454
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2693
	data_grads_norm = 4.1257
	new_data_grads_norm = 5.8510
	old_data_grads_norm = 5.8943
	sim_grads_norm = 0.0129
-- Starting training on experience 194 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8698
	data_grads_norm = 4.2948
	new_data_grads_norm = 6.2297
	old_data_grads_norm = 5.1087
	sim_grads_norm = -0.0364
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7278
	data_grads_norm = 4.5120
	new_data_grads_norm = 6.9152
	old_data_grads_norm = 5.2672
	sim_grads_norm = 0.0860
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3283
	data_grads_norm = 4.6006
	new_data_grads_norm = 6.7628
	old_data_grads_norm = 5.6347
	sim_grads_norm = 0.0344
-- Starting training on experience 195 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8981
	data_grads_norm = 4.6556
	new_data_grads_norm = 7.0490
	old_data_grads_norm = 5.1718
	sim_grads_norm = 0.0136
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5347
	data_grads_norm = 3.4740
	new_data_grads_norm = 6.0699
	old_data_grads_norm = 4.1312
	sim_grads_norm = -0.0231
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9369
	data_grads_norm = 4.3954
	new_data_grads_norm = 6.2787
	old_data_grads_norm = 5.5002
	sim_grads_norm = -0.0054
-- Starting training on experience 196 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1562
	data_grads_norm = 5.9454
	new_data_grads_norm = 7.3236
	old_data_grads_norm = 7.6911
	sim_grads_norm = 0.0464
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8607
	data_grads_norm = 5.7061
	new_data_grads_norm = 8.2342
	old_data_grads_norm = 6.8653
	sim_grads_norm = 0.0173
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7696
	data_grads_norm = 4.8992
	new_data_grads_norm = 7.7092
	old_data_grads_norm = 5.0787
	sim_grads_norm = -0.0089
-- Starting training on experience 197 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0050
	data_grads_norm = 4.1798
	new_data_grads_norm = 6.1948
	old_data_grads_norm = 5.4867
	sim_grads_norm = 0.1021
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7409
	data_grads_norm = 3.4068
	new_data_grads_norm = 5.7439
	old_data_grads_norm = 5.0519
	sim_grads_norm = -0.0425
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7977
	data_grads_norm = 4.1290
	new_data_grads_norm = 6.0222
	old_data_grads_norm = 4.8683
	sim_grads_norm = -0.0381
-- Starting training on experience 198 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1814
	data_grads_norm = 4.4199
	new_data_grads_norm = 6.5120
	old_data_grads_norm = 5.9333
	sim_grads_norm = 0.0520
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7574
	data_grads_norm = 4.5200
	new_data_grads_norm = 6.9470
	old_data_grads_norm = 3.5178
	sim_grads_norm = -0.0536
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9767
	data_grads_norm = 4.4476
	new_data_grads_norm = 6.6982
	old_data_grads_norm = 6.4314
	sim_grads_norm = -0.0134
-- Starting training on experience 199 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7649
	data_grads_norm = 3.5835
	new_data_grads_norm = 5.7934
	old_data_grads_norm = 4.6417
	sim_grads_norm = 0.0184
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7959
	data_grads_norm = 3.3243
	new_data_grads_norm = 6.0404
	old_data_grads_norm = 3.0905
	sim_grads_norm = -0.0902
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2029
	data_grads_norm = 3.6298
	new_data_grads_norm = 5.8020
	old_data_grads_norm = 4.5269
	sim_grads_norm = -0.0093
-- Starting training on experience 200 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8522
	data_grads_norm = 4.1032
	new_data_grads_norm = 6.4770
	old_data_grads_norm = 4.6592
	sim_grads_norm = -0.0001
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0627
	data_grads_norm = 4.5415
	new_data_grads_norm = 6.6194
	old_data_grads_norm = 2.8663
	sim_grads_norm = 0.0425
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0905
	data_grads_norm = 4.2494
	new_data_grads_norm = 6.2309
	old_data_grads_norm = 6.4309
	sim_grads_norm = -0.0156
-- Starting training on experience 201 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9859
	data_grads_norm = 4.6660
	new_data_grads_norm = 7.6064
	old_data_grads_norm = 5.6133
	sim_grads_norm = -0.0329
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4274
	data_grads_norm = 5.1159
	new_data_grads_norm = 7.7432
	old_data_grads_norm = 7.2865
	sim_grads_norm = -0.0069
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8001
	data_grads_norm = 4.1846
	new_data_grads_norm = 7.4961
	old_data_grads_norm = 5.0144
	sim_grads_norm = -0.0470
-- Starting training on experience 202 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8088
	data_grads_norm = 5.4610
	new_data_grads_norm = 6.5786
	old_data_grads_norm = 9.0477
	sim_grads_norm = -0.0070
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8702
	data_grads_norm = 5.4094
	new_data_grads_norm = 7.1258
	old_data_grads_norm = 7.4018
	sim_grads_norm = 0.0364
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5753
	data_grads_norm = 4.6382
	new_data_grads_norm = 6.2389
	old_data_grads_norm = 5.9247
	sim_grads_norm = 0.0041
-- Starting training on experience 203 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3979
	data_grads_norm = 4.3099
	new_data_grads_norm = 6.8013
	old_data_grads_norm = 5.6547
	sim_grads_norm = 0.0028
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0957
	data_grads_norm = 4.3943
	new_data_grads_norm = 7.2725
	old_data_grads_norm = 4.9529
	sim_grads_norm = -0.0238
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8876
	data_grads_norm = 4.9950
	new_data_grads_norm = 7.3368
	old_data_grads_norm = 5.6006
	sim_grads_norm = 0.0948
-- Starting training on experience 204 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4059
	data_grads_norm = 3.8201
	new_data_grads_norm = 6.5534
	old_data_grads_norm = 4.8578
	sim_grads_norm = 0.0353
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4486
	data_grads_norm = 4.4621
	new_data_grads_norm = 7.3830
	old_data_grads_norm = 4.0613
	sim_grads_norm = 0.0451
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9612
	data_grads_norm = 3.5096
	new_data_grads_norm = 6.6689
	old_data_grads_norm = 3.6399
	sim_grads_norm = -0.0018
-- Starting training on experience 205 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6104
	data_grads_norm = 4.8915
	new_data_grads_norm = 7.4032
	old_data_grads_norm = 5.4786
	sim_grads_norm = -0.0170
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5630
	data_grads_norm = 4.5572
	new_data_grads_norm = 7.3824
	old_data_grads_norm = 6.1301
	sim_grads_norm = 0.0109
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5272
	data_grads_norm = 4.9317
	new_data_grads_norm = 7.9037
	old_data_grads_norm = 5.9369
	sim_grads_norm = 0.0098
-- Starting training on experience 206 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4215
	data_grads_norm = 4.3611
	new_data_grads_norm = 6.4650
	old_data_grads_norm = 4.6740
	sim_grads_norm = 0.0024
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4632
	data_grads_norm = 4.8999
	new_data_grads_norm = 6.5982
	old_data_grads_norm = 6.6124
	sim_grads_norm = 0.0106
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8008
	data_grads_norm = 3.3636
	new_data_grads_norm = 6.3378
	old_data_grads_norm = 3.2232
	sim_grads_norm = -0.0002
-- Starting training on experience 207 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5434
	data_grads_norm = 4.7250
	new_data_grads_norm = 6.5630
	old_data_grads_norm = 5.3305
	sim_grads_norm = -0.0069
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2112
	data_grads_norm = 4.0147
	new_data_grads_norm = 7.2225
	old_data_grads_norm = 3.6737
	sim_grads_norm = -0.0263
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1018
	data_grads_norm = 4.2082
	new_data_grads_norm = 6.5901
	old_data_grads_norm = 4.6093
	sim_grads_norm = -0.0198
-- Starting training on experience 208 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9691
	data_grads_norm = 4.0388
	new_data_grads_norm = 6.6403
	old_data_grads_norm = 5.2036
	sim_grads_norm = 0.0374
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9606
	data_grads_norm = 5.1372
	new_data_grads_norm = 6.7990
	old_data_grads_norm = 6.3309
	sim_grads_norm = 0.0760
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0021
	data_grads_norm = 3.9923
	new_data_grads_norm = 6.3053
	old_data_grads_norm = 4.2585
	sim_grads_norm = 0.0234
-- Starting training on experience 209 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9165
	data_grads_norm = 4.0025
	new_data_grads_norm = 5.9893
	old_data_grads_norm = 4.5942
	sim_grads_norm = -0.0284
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3078
	data_grads_norm = 4.8097
	new_data_grads_norm = 6.2233
	old_data_grads_norm = 7.5302
	sim_grads_norm = 0.0164
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9134
	data_grads_norm = 4.0331
	new_data_grads_norm = 6.1520
	old_data_grads_norm = 5.9898
	sim_grads_norm = 0.0227
-- Starting training on experience 210 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9087
	data_grads_norm = 4.3927
	new_data_grads_norm = 6.5266
	old_data_grads_norm = 5.3704
	sim_grads_norm = 0.0275
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8970
	data_grads_norm = 4.0472
	new_data_grads_norm = 5.8008
	old_data_grads_norm = 5.3942
	sim_grads_norm = 0.0039
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6069
	data_grads_norm = 3.8192
	new_data_grads_norm = 6.2061
	old_data_grads_norm = 4.4843
	sim_grads_norm = -0.0271
-- Starting training on experience 211 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5145
	data_grads_norm = 4.1956
	new_data_grads_norm = 5.9720
	old_data_grads_norm = 4.0723
	sim_grads_norm = -0.0119
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6232
	data_grads_norm = 4.3936
	new_data_grads_norm = 7.4128
	old_data_grads_norm = 4.5091
	sim_grads_norm = -0.0633
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6578
	data_grads_norm = 4.5954
	new_data_grads_norm = 6.6210
	old_data_grads_norm = 5.4056
	sim_grads_norm = 0.0222
-- Starting training on experience 212 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6905
	data_grads_norm = 4.1435
	new_data_grads_norm = 7.6063
	old_data_grads_norm = 3.6156
	sim_grads_norm = 0.0279
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5758
	data_grads_norm = 4.8646
	new_data_grads_norm = 7.4869
	old_data_grads_norm = 4.9471
	sim_grads_norm = 0.0484
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6513
	data_grads_norm = 3.6926
	new_data_grads_norm = 6.2780
	old_data_grads_norm = 4.1800
	sim_grads_norm = 0.0979
-- Starting training on experience 213 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3190
	data_grads_norm = 4.9329
	new_data_grads_norm = 6.6325
	old_data_grads_norm = 6.8582
	sim_grads_norm = 0.0516
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4093
	data_grads_norm = 3.6412
	new_data_grads_norm = 6.3284
	old_data_grads_norm = 3.3955
	sim_grads_norm = 0.0469
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6161
	data_grads_norm = 3.5649
	new_data_grads_norm = 6.9092
	old_data_grads_norm = 4.7005
	sim_grads_norm = -0.0140
-- Starting training on experience 214 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2312
	data_grads_norm = 4.8649
	new_data_grads_norm = 8.0764
	old_data_grads_norm = 3.4079
	sim_grads_norm = 0.0830
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3051
	data_grads_norm = 5.0438
	new_data_grads_norm = 7.8680
	old_data_grads_norm = 5.6441
	sim_grads_norm = -0.0495
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5312
	data_grads_norm = 5.7163
	new_data_grads_norm = 7.6073
	old_data_grads_norm = 6.7947
	sim_grads_norm = 0.0208
-- Starting training on experience 215 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1052
	data_grads_norm = 4.4958
	new_data_grads_norm = 7.0093
	old_data_grads_norm = 5.1114
	sim_grads_norm = -0.0187
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0161
	data_grads_norm = 4.6098
	new_data_grads_norm = 6.8178
	old_data_grads_norm = 6.3264
	sim_grads_norm = 0.0191
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9682
	data_grads_norm = 4.5348
	new_data_grads_norm = 7.3519
	old_data_grads_norm = 3.6840
	sim_grads_norm = 0.0261
-- Starting training on experience 216 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8657
	data_grads_norm = 3.4867
	new_data_grads_norm = 6.4174
	old_data_grads_norm = 3.5761
	sim_grads_norm = -0.0247
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7931
	data_grads_norm = 4.4269
	new_data_grads_norm = 5.8316
	old_data_grads_norm = 5.6346
	sim_grads_norm = -0.0082
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0994
	data_grads_norm = 4.6314
	new_data_grads_norm = 6.0731
	old_data_grads_norm = 6.5344
	sim_grads_norm = 0.0425
-- Starting training on experience 217 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2241
	data_grads_norm = 4.3464
	new_data_grads_norm = 6.0742
	old_data_grads_norm = 5.6225
	sim_grads_norm = 0.0514
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0460
	data_grads_norm = 3.7374
	new_data_grads_norm = 5.7472
	old_data_grads_norm = 4.7490
	sim_grads_norm = 0.0776
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9716
	data_grads_norm = 4.1163
	new_data_grads_norm = 5.1502
	old_data_grads_norm = 5.5072
	sim_grads_norm = 0.0089
-- Starting training on experience 218 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1218
	data_grads_norm = 4.2565
	new_data_grads_norm = 5.9910
	old_data_grads_norm = 5.2229
	sim_grads_norm = -0.0240
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5823
	data_grads_norm = 4.1402
	new_data_grads_norm = 6.2499
	old_data_grads_norm = 5.3625
	sim_grads_norm = -0.0107
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5476
	data_grads_norm = 4.5310
	new_data_grads_norm = 6.8219
	old_data_grads_norm = 6.4726
	sim_grads_norm = -0.0023
-- Starting training on experience 219 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8417
	data_grads_norm = 3.7730
	new_data_grads_norm = 7.0218
	old_data_grads_norm = 3.9546
	sim_grads_norm = 0.0330
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2706
	data_grads_norm = 5.1910
	new_data_grads_norm = 7.3823
	old_data_grads_norm = 6.4380
	sim_grads_norm = 0.0060
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0262
	data_grads_norm = 3.9119
	new_data_grads_norm = 7.0291
	old_data_grads_norm = 3.8432
	sim_grads_norm = 0.1060
-- Starting training on experience 220 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0622
	data_grads_norm = 4.2442
	new_data_grads_norm = 7.5464
	old_data_grads_norm = 4.0129
	sim_grads_norm = -0.0020
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7640
	data_grads_norm = 5.6999
	new_data_grads_norm = 7.0796
	old_data_grads_norm = 8.0487
	sim_grads_norm = 0.1168
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1159
	data_grads_norm = 4.8044
	new_data_grads_norm = 6.0927
	old_data_grads_norm = 6.6241
	sim_grads_norm = 0.0355
-- Starting training on experience 221 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6590
	data_grads_norm = 4.6247
	new_data_grads_norm = 7.2865
	old_data_grads_norm = 6.5093
	sim_grads_norm = -0.0641
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7300
	data_grads_norm = 5.3743
	new_data_grads_norm = 8.0443
	old_data_grads_norm = 5.0702
	sim_grads_norm = -0.0136
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8671
	data_grads_norm = 4.7857
	new_data_grads_norm = 7.0866
	old_data_grads_norm = 5.5430
	sim_grads_norm = 0.0643
-- Starting training on experience 222 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6882
	data_grads_norm = 4.2415
	new_data_grads_norm = 6.6584
	old_data_grads_norm = 3.2875
	sim_grads_norm = -0.0485
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8597
	data_grads_norm = 5.2730
	new_data_grads_norm = 7.6486
	old_data_grads_norm = 6.8294
	sim_grads_norm = -0.0268
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6588
	data_grads_norm = 5.7500
	new_data_grads_norm = 7.5297
	old_data_grads_norm = 7.6870
	sim_grads_norm = -0.0156
-- Starting training on experience 223 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2170
	data_grads_norm = 4.8077
	new_data_grads_norm = 7.0921
	old_data_grads_norm = 5.1886
	sim_grads_norm = 0.0608
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1052
	data_grads_norm = 4.6192
	new_data_grads_norm = 6.6794
	old_data_grads_norm = 5.2347
	sim_grads_norm = 0.0149
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5619
	data_grads_norm = 3.8954
	new_data_grads_norm = 6.6549
	old_data_grads_norm = 5.6356
	sim_grads_norm = -0.0360
-- Starting training on experience 224 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7754
	data_grads_norm = 4.1980
	new_data_grads_norm = 7.2847
	old_data_grads_norm = 4.0508
	sim_grads_norm = 0.0019
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0978
	data_grads_norm = 4.9620
	new_data_grads_norm = 7.4375
	old_data_grads_norm = 6.3220
	sim_grads_norm = 0.0771
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8236
	data_grads_norm = 3.9377
	new_data_grads_norm = 7.3463
	old_data_grads_norm = 2.7929
	sim_grads_norm = 0.0214
-- Starting training on experience 225 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1322
	data_grads_norm = 4.2976
	new_data_grads_norm = 7.1249
	old_data_grads_norm = 4.5577
	sim_grads_norm = 0.0033
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3526
	data_grads_norm = 4.9407
	new_data_grads_norm = 7.3915
	old_data_grads_norm = 6.2853
	sim_grads_norm = -0.0274
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3855
	data_grads_norm = 5.0973
	new_data_grads_norm = 6.7493
	old_data_grads_norm = 6.9016
	sim_grads_norm = -0.0048
-- Starting training on experience 226 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0274
	data_grads_norm = 3.8076
	new_data_grads_norm = 5.7640
	old_data_grads_norm = 5.9330
	sim_grads_norm = 0.0064
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9589
	data_grads_norm = 3.6371
	new_data_grads_norm = 5.6259
	old_data_grads_norm = 5.3137
	sim_grads_norm = -0.0158
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1102
	data_grads_norm = 4.4905
	new_data_grads_norm = 6.9325
	old_data_grads_norm = 5.2968
	sim_grads_norm = 0.0043
-- Starting training on experience 227 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6411
	data_grads_norm = 3.9010
	new_data_grads_norm = 6.3325
	old_data_grads_norm = 3.9917
	sim_grads_norm = 0.0195
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3729
	data_grads_norm = 3.6328
	new_data_grads_norm = 7.9808
	old_data_grads_norm = 3.8089
	sim_grads_norm = -0.0442
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0446
	data_grads_norm = 4.5313
	new_data_grads_norm = 7.9605
	old_data_grads_norm = 5.2748
	sim_grads_norm = 0.0063
-- Starting training on experience 228 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6042
	data_grads_norm = 4.0668
	new_data_grads_norm = 6.9722
	old_data_grads_norm = 5.0813
	sim_grads_norm = 0.0075
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0836
	data_grads_norm = 5.3467
	new_data_grads_norm = 7.1395
	old_data_grads_norm = 6.0758
	sim_grads_norm = 0.0799
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9834
	data_grads_norm = 5.0606
	new_data_grads_norm = 6.5940
	old_data_grads_norm = 6.6877
	sim_grads_norm = 0.1053
-- Starting training on experience 229 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6278
	data_grads_norm = 4.1647
	new_data_grads_norm = 6.9059
	old_data_grads_norm = 6.2287
	sim_grads_norm = -0.0322
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9109
	data_grads_norm = 4.2272
	new_data_grads_norm = 7.8731
	old_data_grads_norm = 4.8225
	sim_grads_norm = 0.0518
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7157
	data_grads_norm = 4.2722
	new_data_grads_norm = 8.1836
	old_data_grads_norm = 4.7752
	sim_grads_norm = 0.0368
-- Starting training on experience 230 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5249
	data_grads_norm = 4.0511
	new_data_grads_norm = 5.3616
	old_data_grads_norm = 6.7894
	sim_grads_norm = -0.0019
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4398
	data_grads_norm = 4.0269
	new_data_grads_norm = 6.6036
	old_data_grads_norm = 4.6353
	sim_grads_norm = -0.0152
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6170
	data_grads_norm = 3.6323
	new_data_grads_norm = 6.0528
	old_data_grads_norm = 3.6776
	sim_grads_norm = 0.0480
-- Starting training on experience 231 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6744
	data_grads_norm = 4.3373
	new_data_grads_norm = 6.8177
	old_data_grads_norm = 4.8368
	sim_grads_norm = 0.0229
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0405
	data_grads_norm = 5.0045
	new_data_grads_norm = 6.8840
	old_data_grads_norm = 5.2136
	sim_grads_norm = -0.0178
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9894
	data_grads_norm = 4.8719
	new_data_grads_norm = 6.9413
	old_data_grads_norm = 6.3635
	sim_grads_norm = 0.0108
-- Starting training on experience 232 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7332
	data_grads_norm = 3.8338
	new_data_grads_norm = 6.2592
	old_data_grads_norm = 4.5065
	sim_grads_norm = -0.0009
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6433
	data_grads_norm = 4.2510
	new_data_grads_norm = 6.2759
	old_data_grads_norm = 5.0219
	sim_grads_norm = 0.0116
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6097
	data_grads_norm = 4.0024
	new_data_grads_norm = 6.6225
	old_data_grads_norm = 3.0816
	sim_grads_norm = 0.1250
-- Starting training on experience 233 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6409
	data_grads_norm = 3.9904
	new_data_grads_norm = 6.1369
	old_data_grads_norm = 3.6792
	sim_grads_norm = 0.0066
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7607
	data_grads_norm = 5.0103
	new_data_grads_norm = 7.6896
	old_data_grads_norm = 6.4456
	sim_grads_norm = 0.0254
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9856
	data_grads_norm = 4.5774
	new_data_grads_norm = 5.8450
	old_data_grads_norm = 5.0657
	sim_grads_norm = -0.0046
-- Starting training on experience 234 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9609
	data_grads_norm = 4.7355
	new_data_grads_norm = 6.0202
	old_data_grads_norm = 6.4721
	sim_grads_norm = -0.0112
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6200
	data_grads_norm = 4.5710
	new_data_grads_norm = 7.0484
	old_data_grads_norm = 4.9252
	sim_grads_norm = -0.0264
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7085
	data_grads_norm = 4.3260
	new_data_grads_norm = 6.1500
	old_data_grads_norm = 5.2086
	sim_grads_norm = -0.0107
-- Starting training on experience 235 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8701
	data_grads_norm = 4.4755
	new_data_grads_norm = 6.6997
	old_data_grads_norm = 4.5342
	sim_grads_norm = 0.0345
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7825
	data_grads_norm = 4.3941
	new_data_grads_norm = 6.2865
	old_data_grads_norm = 4.8812
	sim_grads_norm = -0.0410
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0188
	data_grads_norm = 4.1898
	new_data_grads_norm = 6.3190
	old_data_grads_norm = 5.5005
	sim_grads_norm = -0.0277
-- Starting training on experience 236 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3078
	data_grads_norm = 4.6614
	new_data_grads_norm = 8.0756
	old_data_grads_norm = 5.0480
	sim_grads_norm = -0.0076
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4566
	data_grads_norm = 4.3467
	new_data_grads_norm = 7.9347
	old_data_grads_norm = 5.3818
	sim_grads_norm = 0.0130
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0392
	data_grads_norm = 4.9941
	new_data_grads_norm = 7.2796
	old_data_grads_norm = 6.0866
	sim_grads_norm = 0.0049
-- Starting training on experience 237 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
-- >> End of training phase << --
-- >> Start of eval phase << --
-- Starting eval on experience 0 (Task 0) from test stream --
> Eval on experience 0 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp000 = 3.8923
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.2760
	mb_index = 3808
	time = 1135.5355
-- Starting eval on experience 1 (Task 0) from test stream --
> Eval on experience 1 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp001 = 2.7383
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.4840
-- Starting eval on experience 2 (Task 0) from test stream --
> Eval on experience 2 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp002 = 4.3544
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.3320
-- Starting eval on experience 3 (Task 0) from test stream --
> Eval on experience 3 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp003 = 3.2767
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.4580
-- Starting eval on experience 4 (Task 0) from test stream --
> Eval on experience 4 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp004 = 5.1144
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.1800
-- Starting eval on experience 5 (Task 0) from test stream --
> Eval on experience 5 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp005 = 3.8165
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.3480
-- Starting eval on experience 6 (Task 0) from test stream --
> Eval on experience 6 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp006 = 3.8640
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp006 = 0.2820
-- Starting eval on experience 7 (Task 0) from test stream --
> Eval on experience 7 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp007 = 4.3451
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp007 = 0.3040
-- Starting eval on experience 8 (Task 0) from test stream --
> Eval on experience 8 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp008 = 4.0240
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp008 = 0.2480
-- Starting eval on experience 9 (Task 0) from test stream --
> Eval on experience 9 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp009 = 3.7093
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp009 = 0.2880
-- Starting eval on experience 10 (Task 0) from test stream --
> Eval on experience 10 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp010 = 4.2453
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp010 = 0.2020
-- Starting eval on experience 11 (Task 0) from test stream --
> Eval on experience 11 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp011 = 2.3018
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp011 = 0.4680
-- Starting eval on experience 12 (Task 0) from test stream --
> Eval on experience 12 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp012 = 4.3811
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp012 = 0.1700
-- Starting eval on experience 13 (Task 0) from test stream --
> Eval on experience 13 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp013 = 3.6073
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp013 = 0.2600
-- Starting eval on experience 14 (Task 0) from test stream --
> Eval on experience 14 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp014 = 3.6394
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp014 = 0.1860
-- Starting eval on experience 15 (Task 0) from test stream --
> Eval on experience 15 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp015 = 3.8727
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp015 = 0.1460
-- >> End of eval phase << --
	CumulativeAccuracy/eval_phase/test_stream/Exp000 = 0.7000
	CumulativeAccuracy/eval_phase/test_stream/Exp001 = 0.6670
	CumulativeAccuracy/eval_phase/test_stream/Exp002 = 0.5753
	CumulativeAccuracy/eval_phase/test_stream/Exp003 = 0.5480
	CumulativeAccuracy/eval_phase/test_stream/Exp004 = 0.4956
	CumulativeAccuracy/eval_phase/test_stream/Exp005 = 0.4687
	CumulativeAccuracy/eval_phase/test_stream/Exp006 = 0.4340
	CumulativeAccuracy/eval_phase/test_stream/Exp007 = 0.4123
	CumulativeAccuracy/eval_phase/test_stream/Exp008 = 0.3927
	CumulativeAccuracy/eval_phase/test_stream/Exp009 = 0.3772
	CumulativeAccuracy/eval_phase/test_stream/Exp010 = 0.3564
	CumulativeAccuracy/eval_phase/test_stream/Exp011 = 0.3465
	CumulativeAccuracy/eval_phase/test_stream/Exp012 = 0.3218
	CumulativeAccuracy/eval_phase/test_stream/Exp013 = 0.3133
	CumulativeAccuracy/eval_phase/test_stream/Exp014 = 0.3019
	CumulativeAccuracy/eval_phase/test_stream/Exp015 = 0.2895
	Loss_Stream/eval_phase/test_stream/Task000 = 3.8239
	Top1_Acc_Stream/eval_phase/test_stream/Task000 = 0.2895
-- >> Start of training phase << --
-- Starting training on experience 0 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5420
	data_grads_norm = 4.6340
	new_data_grads_norm = 6.4874
	old_data_grads_norm = 5.7282
	sim_grads_norm = 0.0227
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5879
	data_grads_norm = 4.7032
	new_data_grads_norm = 7.0317
	old_data_grads_norm = 4.9323
	sim_grads_norm = -0.0090
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.8641
	data_grads_norm = 5.0863
	new_data_grads_norm = 6.8024
	old_data_grads_norm = 6.1559
	sim_grads_norm = 0.0012
-- Starting training on experience 1 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.3621
	data_grads_norm = 5.7969
	new_data_grads_norm = 8.9593
	old_data_grads_norm = 6.6294
	sim_grads_norm = 0.0667
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.8577
	data_grads_norm = 4.9018
	new_data_grads_norm = 8.1398
	old_data_grads_norm = 4.1302
	sim_grads_norm = -0.0135
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.2351
	data_grads_norm = 5.3834
	new_data_grads_norm = 6.9333
	old_data_grads_norm = 7.9776
	sim_grads_norm = -0.0254
-- Starting training on experience 2 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3225
	data_grads_norm = 4.0365
	new_data_grads_norm = 7.0404
	old_data_grads_norm = 3.2764
	sim_grads_norm = -0.0001
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.9022
	data_grads_norm = 4.5128
	new_data_grads_norm = 6.8257
	old_data_grads_norm = 5.6468
	sim_grads_norm = 0.0923
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.1152
	data_grads_norm = 5.1620
	new_data_grads_norm = 7.3956
	old_data_grads_norm = 7.3152
	sim_grads_norm = -0.0184
-- Starting training on experience 3 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.7865
	data_grads_norm = 4.8508
	new_data_grads_norm = 6.8641
	old_data_grads_norm = 6.8588
	sim_grads_norm = -0.0014
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.8279
	data_grads_norm = 4.4440
	new_data_grads_norm = 6.8304
	old_data_grads_norm = 4.5546
	sim_grads_norm = 0.0101
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.9435
	data_grads_norm = 4.7323
	new_data_grads_norm = 7.1631
	old_data_grads_norm = 4.0743
	sim_grads_norm = 0.0098
-- Starting training on experience 4 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.5349
	data_grads_norm = 5.5692
	new_data_grads_norm = 6.1700
	old_data_grads_norm = 8.7078
	sim_grads_norm = 0.0050
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6657
	data_grads_norm = 4.3844
	new_data_grads_norm = 6.3301
	old_data_grads_norm = 4.5582
	sim_grads_norm = 0.0065
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.2219
	data_grads_norm = 5.5302
	new_data_grads_norm = 7.0412
	old_data_grads_norm = 7.9190
	sim_grads_norm = -0.0004
-- Starting training on experience 5 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6301
	data_grads_norm = 4.4887
	new_data_grads_norm = 7.6564
	old_data_grads_norm = 3.4637
	sim_grads_norm = -0.0023
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6813
	data_grads_norm = 4.8445
	new_data_grads_norm = 7.3233
	old_data_grads_norm = 5.2127
	sim_grads_norm = 0.0002
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.2743
	data_grads_norm = 5.4075
	new_data_grads_norm = 7.9875
	old_data_grads_norm = 7.7889
	sim_grads_norm = 0.0587
-- Starting training on experience 6 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5411
	data_grads_norm = 4.4933
	new_data_grads_norm = 7.5017
	old_data_grads_norm = 3.7694
	sim_grads_norm = 0.0013
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5274
	data_grads_norm = 4.5523
	new_data_grads_norm = 7.2012
	old_data_grads_norm = 3.6408
	sim_grads_norm = -0.0098
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.8685
	data_grads_norm = 4.6299
	new_data_grads_norm = 7.0944
	old_data_grads_norm = 5.9121
	sim_grads_norm = 0.0178
-- Starting training on experience 7 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.8878
	data_grads_norm = 5.4625
	new_data_grads_norm = 7.5184
	old_data_grads_norm = 6.8354
	sim_grads_norm = 0.0201
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.5142
	data_grads_norm = 4.6588
	new_data_grads_norm = 7.7520
	old_data_grads_norm = 4.6166
	sim_grads_norm = 0.0656
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.1382
	data_grads_norm = 5.2870
	new_data_grads_norm = 7.4861
	old_data_grads_norm = 5.5800
	sim_grads_norm = -0.0058
-- Starting training on experience 8 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.0434
	data_grads_norm = 5.2632
	new_data_grads_norm = 7.9607
	old_data_grads_norm = 6.1217
	sim_grads_norm = 0.0118
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.9803
	data_grads_norm = 4.8514
	new_data_grads_norm = 6.9893
	old_data_grads_norm = 6.6101
	sim_grads_norm = 0.0117
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3858
	data_grads_norm = 4.3412
	new_data_grads_norm = 6.9098
	old_data_grads_norm = 4.2280
	sim_grads_norm = -0.0007
-- Starting training on experience 9 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.0705
	data_grads_norm = 4.8172
	new_data_grads_norm = 6.9102
	old_data_grads_norm = 6.6980
	sim_grads_norm = 0.0403
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.0097
	data_grads_norm = 5.3877
	new_data_grads_norm = 7.7875
	old_data_grads_norm = 4.7699
	sim_grads_norm = -0.0007
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.0212
	data_grads_norm = 4.6159
	new_data_grads_norm = 6.9419
	old_data_grads_norm = 4.7740
	sim_grads_norm = 0.0200
-- Starting training on experience 10 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.7616
	data_grads_norm = 4.7382
	new_data_grads_norm = 7.4242
	old_data_grads_norm = 5.7471
	sim_grads_norm = -0.0091
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3446
	data_grads_norm = 5.3204
	new_data_grads_norm = 6.7963
	old_data_grads_norm = 7.8934
	sim_grads_norm = -0.0468
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6885
	data_grads_norm = 4.8286
	new_data_grads_norm = 6.9677
	old_data_grads_norm = 5.3639
	sim_grads_norm = 0.0993
-- Starting training on experience 11 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3946
	data_grads_norm = 4.6650
	new_data_grads_norm = 5.5747
	old_data_grads_norm = 7.1925
	sim_grads_norm = 0.0108
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2789
	data_grads_norm = 4.6317
	new_data_grads_norm = 6.2522
	old_data_grads_norm = 5.8523
	sim_grads_norm = 0.0599
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5293
	data_grads_norm = 4.1673
	new_data_grads_norm = 5.8228
	old_data_grads_norm = 4.6352
	sim_grads_norm = -0.0121
-- Starting training on experience 12 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.1215
	data_grads_norm = 5.3044
	new_data_grads_norm = 7.0758
	old_data_grads_norm = 6.0411
	sim_grads_norm = 0.0547
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2394
	data_grads_norm = 4.2775
	new_data_grads_norm = 6.6683
	old_data_grads_norm = 4.8607
	sim_grads_norm = 0.0152
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3828
	data_grads_norm = 4.4728
	new_data_grads_norm = 6.5625
	old_data_grads_norm = 6.0399
	sim_grads_norm = -0.0029
-- Starting training on experience 13 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0848
	data_grads_norm = 4.6616
	new_data_grads_norm = 7.2875
	old_data_grads_norm = 5.9277
	sim_grads_norm = 0.0058
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2899
	data_grads_norm = 4.7590
	new_data_grads_norm = 7.0748
	old_data_grads_norm = 5.5720
	sim_grads_norm = -0.0013
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0900
	data_grads_norm = 4.9150
	new_data_grads_norm = 6.7667
	old_data_grads_norm = 6.1176
	sim_grads_norm = 0.0235
-- Starting training on experience 14 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4975
	data_grads_norm = 4.8035
	new_data_grads_norm = 6.5785
	old_data_grads_norm = 4.6303
	sim_grads_norm = 0.0096
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4233
	data_grads_norm = 4.8644
	new_data_grads_norm = 6.4183
	old_data_grads_norm = 5.1178
	sim_grads_norm = 0.0167
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4470
	data_grads_norm = 4.7733
	new_data_grads_norm = 6.9221
	old_data_grads_norm = 6.9353
	sim_grads_norm = -0.0386
-- Starting training on experience 15 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.8380
	data_grads_norm = 5.0050
	new_data_grads_norm = 7.0947
	old_data_grads_norm = 5.4566
	sim_grads_norm = 0.0449
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2530
	data_grads_norm = 4.4369
	new_data_grads_norm = 7.1362
	old_data_grads_norm = 4.1454
	sim_grads_norm = 0.0059
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1418
	data_grads_norm = 4.5399
	new_data_grads_norm = 7.0715
	old_data_grads_norm = 5.4502
	sim_grads_norm = 0.0039
-- Starting training on experience 16 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1350
	data_grads_norm = 4.8783
	new_data_grads_norm = 6.3162
	old_data_grads_norm = 6.8991
	sim_grads_norm = 0.0237
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9910
	data_grads_norm = 4.6554
	new_data_grads_norm = 7.0699
	old_data_grads_norm = 4.8395
	sim_grads_norm = 0.0069
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6598
	data_grads_norm = 5.3177
	new_data_grads_norm = 6.7812
	old_data_grads_norm = 6.9859
	sim_grads_norm = 0.0003
-- Starting training on experience 17 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.7408
	data_grads_norm = 5.3502
	new_data_grads_norm = 7.5202
	old_data_grads_norm = 6.2589
	sim_grads_norm = 0.0721
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.5154
	data_grads_norm = 5.7681
	new_data_grads_norm = 7.8451
	old_data_grads_norm = 6.6224
	sim_grads_norm = 0.1009
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8733
	data_grads_norm = 4.9747
	new_data_grads_norm = 7.1966
	old_data_grads_norm = 5.6408
	sim_grads_norm = 0.0469
-- Starting training on experience 18 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5722
	data_grads_norm = 4.2432
	new_data_grads_norm = 6.0002
	old_data_grads_norm = 4.6276
	sim_grads_norm = 0.1112
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1498
	data_grads_norm = 4.5749
	new_data_grads_norm = 6.5759
	old_data_grads_norm = 5.7188
	sim_grads_norm = -0.0015
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6236
	data_grads_norm = 3.9775
	new_data_grads_norm = 6.6242
	old_data_grads_norm = 4.5265
	sim_grads_norm = 0.0064
-- Starting training on experience 19 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9188
	data_grads_norm = 4.7339
	new_data_grads_norm = 7.1252
	old_data_grads_norm = 5.1288
	sim_grads_norm = -0.0042
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5826
	data_grads_norm = 4.6900
	new_data_grads_norm = 7.3655
	old_data_grads_norm = 5.0754
	sim_grads_norm = 0.0407
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7221
	data_grads_norm = 5.0968
	new_data_grads_norm = 7.6744
	old_data_grads_norm = 5.8490
	sim_grads_norm = 0.0210
-- Starting training on experience 20 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0770
	data_grads_norm = 4.9742
	new_data_grads_norm = 7.6599
	old_data_grads_norm = 4.6689
	sim_grads_norm = 0.0286
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6958
	data_grads_norm = 5.1555
	new_data_grads_norm = 7.1756
	old_data_grads_norm = 7.4603
	sim_grads_norm = 0.0231
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3286
	data_grads_norm = 4.2823
	new_data_grads_norm = 7.0905
	old_data_grads_norm = 5.5596
	sim_grads_norm = 0.0137
-- Starting training on experience 21 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4304
	data_grads_norm = 4.4782
	new_data_grads_norm = 7.3641
	old_data_grads_norm = 4.4088
	sim_grads_norm = 0.0076
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5009
	data_grads_norm = 4.4067
	new_data_grads_norm = 6.1075
	old_data_grads_norm = 5.4949
	sim_grads_norm = -0.0101
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8981
	data_grads_norm = 4.6681
	new_data_grads_norm = 6.1031
	old_data_grads_norm = 6.0135
	sim_grads_norm = 0.0295
-- Starting training on experience 22 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1083
	data_grads_norm = 4.6924
	new_data_grads_norm = 6.2016
	old_data_grads_norm = 6.1602
	sim_grads_norm = 0.0568
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5806
	data_grads_norm = 4.8467
	new_data_grads_norm = 6.6756
	old_data_grads_norm = 4.5354
	sim_grads_norm = 0.0009
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2936
	data_grads_norm = 4.4203
	new_data_grads_norm = 6.5748
	old_data_grads_norm = 4.3003
	sim_grads_norm = 0.0432
-- Starting training on experience 23 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1640
	data_grads_norm = 4.3200
	new_data_grads_norm = 6.7528
	old_data_grads_norm = 3.6960
	sim_grads_norm = -0.0053
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2361
	data_grads_norm = 4.4894
	new_data_grads_norm = 7.5840
	old_data_grads_norm = 4.5557
	sim_grads_norm = -0.0271
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5926
	data_grads_norm = 4.6225
	new_data_grads_norm = 6.8488
	old_data_grads_norm = 5.7509
	sim_grads_norm = 0.0514
-- Starting training on experience 24 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5672
	data_grads_norm = 4.8226
	new_data_grads_norm = 7.2189
	old_data_grads_norm = 4.5739
	sim_grads_norm = 0.0280
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9912
	data_grads_norm = 4.3659
	new_data_grads_norm = 6.9367
	old_data_grads_norm = 5.8058
	sim_grads_norm = 0.0096
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6659
	data_grads_norm = 4.8240
	new_data_grads_norm = 6.9141
	old_data_grads_norm = 5.2196
	sim_grads_norm = 0.0014
-- Starting training on experience 25 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7575
	data_grads_norm = 3.9431
	new_data_grads_norm = 6.9443
	old_data_grads_norm = 4.4722
	sim_grads_norm = -0.0064
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9027
	data_grads_norm = 3.9020
	new_data_grads_norm = 6.3812
	old_data_grads_norm = 4.0560
	sim_grads_norm = -0.0334
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6573
	data_grads_norm = 4.5863
	new_data_grads_norm = 6.7180
	old_data_grads_norm = 5.5429
	sim_grads_norm = 0.0524
-- Starting training on experience 26 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9786
	data_grads_norm = 4.1244
	new_data_grads_norm = 6.2097
	old_data_grads_norm = 7.0929
	sim_grads_norm = 0.0029
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9195
	data_grads_norm = 4.8252
	new_data_grads_norm = 6.3291
	old_data_grads_norm = 5.8351
	sim_grads_norm = -0.0157
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6801
	data_grads_norm = 4.7086
	new_data_grads_norm = 6.2240
	old_data_grads_norm = 5.4348
	sim_grads_norm = 0.0061
-- Starting training on experience 27 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1920
	data_grads_norm = 3.7372
	new_data_grads_norm = 5.6446
	old_data_grads_norm = 3.6151
	sim_grads_norm = 0.0469
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9154
	data_grads_norm = 3.7053
	new_data_grads_norm = 5.9696
	old_data_grads_norm = 3.6311
	sim_grads_norm = -0.0484
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0966
	data_grads_norm = 4.3728
	new_data_grads_norm = 6.3624
	old_data_grads_norm = 5.6625
	sim_grads_norm = 0.0111
-- Starting training on experience 28 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5052
	data_grads_norm = 4.9187
	new_data_grads_norm = 6.6583
	old_data_grads_norm = 5.4626
	sim_grads_norm = 0.0476
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5230
	data_grads_norm = 4.7096
	new_data_grads_norm = 6.9442
	old_data_grads_norm = 5.5283
	sim_grads_norm = -0.0089
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7079
	data_grads_norm = 5.2760
	new_data_grads_norm = 6.8598
	old_data_grads_norm = 7.3341
	sim_grads_norm = -0.0152
-- Starting training on experience 29 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9962
	data_grads_norm = 5.0954
	new_data_grads_norm = 7.8336
	old_data_grads_norm = 4.7468
	sim_grads_norm = 0.1184
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9479
	data_grads_norm = 4.7835
	new_data_grads_norm = 7.7780
	old_data_grads_norm = 5.8273
	sim_grads_norm = -0.0017
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3071
	data_grads_norm = 5.4298
	new_data_grads_norm = 7.9079
	old_data_grads_norm = 6.6638
	sim_grads_norm = -0.0105
-- Starting training on experience 30 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1350
	data_grads_norm = 4.9996
	new_data_grads_norm = 6.5365
	old_data_grads_norm = 5.6924
	sim_grads_norm = 0.0047
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0538
	data_grads_norm = 5.5585
	new_data_grads_norm = 7.2237
	old_data_grads_norm = 7.3623
	sim_grads_norm = 0.0530
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8958
	data_grads_norm = 4.1552
	new_data_grads_norm = 7.0664
	old_data_grads_norm = 3.3660
	sim_grads_norm = -0.0026
-- Starting training on experience 31 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3269
	data_grads_norm = 4.5983
	new_data_grads_norm = 6.7361
	old_data_grads_norm = 5.0813
	sim_grads_norm = 0.0059
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9859
	data_grads_norm = 4.0451
	new_data_grads_norm = 6.2501
	old_data_grads_norm = 4.5504
	sim_grads_norm = 0.0871
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7768
	data_grads_norm = 3.7814
	new_data_grads_norm = 6.0397
	old_data_grads_norm = 4.2811
	sim_grads_norm = -0.0055
-- Starting training on experience 32 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0103
	data_grads_norm = 4.2893
	new_data_grads_norm = 7.0027
	old_data_grads_norm = 4.8167
	sim_grads_norm = 0.0741
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5425
	data_grads_norm = 4.3778
	new_data_grads_norm = 6.9885
	old_data_grads_norm = 5.5580
	sim_grads_norm = 0.0144
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7068
	data_grads_norm = 4.0651
	new_data_grads_norm = 6.7401
	old_data_grads_norm = 4.6427
	sim_grads_norm = -0.0214
-- Starting training on experience 33 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5412
	data_grads_norm = 3.7979
	new_data_grads_norm = 6.5655
	old_data_grads_norm = 4.9501
	sim_grads_norm = 0.0022
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4646
	data_grads_norm = 4.8089
	new_data_grads_norm = 6.0202
	old_data_grads_norm = 7.3247
	sim_grads_norm = 0.0128
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4556
	data_grads_norm = 3.6364
	new_data_grads_norm = 6.4171
	old_data_grads_norm = 3.2947
	sim_grads_norm = -0.0200
-- Starting training on experience 34 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6284
	data_grads_norm = 4.0535
	new_data_grads_norm = 7.1529
	old_data_grads_norm = 4.0231
	sim_grads_norm = 0.0197
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8132
	data_grads_norm = 4.5287
	new_data_grads_norm = 7.2243
	old_data_grads_norm = 4.9019
	sim_grads_norm = -0.0075
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7425
	data_grads_norm = 4.0926
	new_data_grads_norm = 7.5753
	old_data_grads_norm = 4.0350
	sim_grads_norm = 0.0383
-- Starting training on experience 35 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6320
	data_grads_norm = 3.6300
	new_data_grads_norm = 6.2682
	old_data_grads_norm = 4.3092
	sim_grads_norm = 0.0387
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8546
	data_grads_norm = 4.0512
	new_data_grads_norm = 6.3641
	old_data_grads_norm = 5.3550
	sim_grads_norm = -0.0237
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6021
	data_grads_norm = 3.3615
	new_data_grads_norm = 6.1528
	old_data_grads_norm = 3.4835
	sim_grads_norm = 0.0041
-- Starting training on experience 36 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2694
	data_grads_norm = 3.2457
	new_data_grads_norm = 5.7824
	old_data_grads_norm = 3.1403
	sim_grads_norm = -0.0037
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6804
	data_grads_norm = 4.0862
	new_data_grads_norm = 5.7624
	old_data_grads_norm = 5.7031
	sim_grads_norm = 0.0190
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4252
	data_grads_norm = 4.2154
	new_data_grads_norm = 5.0182
	old_data_grads_norm = 5.7520
	sim_grads_norm = 0.0434
-- Starting training on experience 37 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5684
	data_grads_norm = 4.9034
	new_data_grads_norm = 7.9284
	old_data_grads_norm = 5.0958
	sim_grads_norm = -0.0062
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9465
	data_grads_norm = 4.6803
	new_data_grads_norm = 6.6793
	old_data_grads_norm = 5.1620
	sim_grads_norm = 0.0354
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9033
	data_grads_norm = 4.8768
	new_data_grads_norm = 6.9878
	old_data_grads_norm = 6.0857
	sim_grads_norm = 0.0795
-- Starting training on experience 38 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7654
	data_grads_norm = 4.9014
	new_data_grads_norm = 6.7342
	old_data_grads_norm = 5.4117
	sim_grads_norm = 0.0432
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5316
	data_grads_norm = 4.7582
	new_data_grads_norm = 5.9101
	old_data_grads_norm = 5.2949
	sim_grads_norm = -0.0333
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4871
	data_grads_norm = 4.2091
	new_data_grads_norm = 6.2249
	old_data_grads_norm = 4.0148
	sim_grads_norm = -0.0162
-- Starting training on experience 39 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0105
	data_grads_norm = 4.8911
	new_data_grads_norm = 6.5727
	old_data_grads_norm = 5.1032
	sim_grads_norm = 0.0737
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1253
	data_grads_norm = 4.9986
	new_data_grads_norm = 6.3985
	old_data_grads_norm = 5.4978
	sim_grads_norm = 0.0239
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7115
	data_grads_norm = 4.4322
	new_data_grads_norm = 5.9386
	old_data_grads_norm = 5.9869
	sim_grads_norm = -0.0335
-- Starting training on experience 40 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4520
	data_grads_norm = 3.8261
	new_data_grads_norm = 6.0248
	old_data_grads_norm = 4.6256
	sim_grads_norm = -0.0049
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5833
	data_grads_norm = 4.0757
	new_data_grads_norm = 5.9958
	old_data_grads_norm = 5.0570
	sim_grads_norm = 0.0334
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6862
	data_grads_norm = 4.0188
	new_data_grads_norm = 5.2837
	old_data_grads_norm = 6.0327
	sim_grads_norm = -0.0029
-- Starting training on experience 41 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9242
	data_grads_norm = 4.4692
	new_data_grads_norm = 6.9710
	old_data_grads_norm = 4.9306
	sim_grads_norm = 0.0352
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4070
	data_grads_norm = 4.0454
	new_data_grads_norm = 6.7092
	old_data_grads_norm = 4.0425
	sim_grads_norm = -0.0028
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7568
	data_grads_norm = 4.3192
	new_data_grads_norm = 6.8830
	old_data_grads_norm = 5.4244
	sim_grads_norm = 0.0476
-- Starting training on experience 42 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3970
	data_grads_norm = 4.6694
	new_data_grads_norm = 5.8711
	old_data_grads_norm = 4.3106
	sim_grads_norm = 0.0416
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4688
	data_grads_norm = 4.9312
	new_data_grads_norm = 6.7835
	old_data_grads_norm = 4.5346
	sim_grads_norm = 0.0093
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4485
	data_grads_norm = 4.7449
	new_data_grads_norm = 6.1138
	old_data_grads_norm = 6.3296
	sim_grads_norm = -0.0118
-- Starting training on experience 43 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3781
	data_grads_norm = 4.1739
	new_data_grads_norm = 6.8526
	old_data_grads_norm = 3.4884
	sim_grads_norm = 0.0136
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7904
	data_grads_norm = 4.1168
	new_data_grads_norm = 6.0519
	old_data_grads_norm = 6.4579
	sim_grads_norm = 0.0213
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8281
	data_grads_norm = 4.9352
	new_data_grads_norm = 6.4955
	old_data_grads_norm = 6.3269
	sim_grads_norm = 0.0370
-- Starting training on experience 44 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4391
	data_grads_norm = 3.7896
	new_data_grads_norm = 5.0540
	old_data_grads_norm = 4.1893
	sim_grads_norm = 0.0385
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1012
	data_grads_norm = 4.1240
	new_data_grads_norm = 5.7763
	old_data_grads_norm = 6.1129
	sim_grads_norm = -0.0215
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6094
	data_grads_norm = 3.8938
	new_data_grads_norm = 5.3412
	old_data_grads_norm = 4.4418
	sim_grads_norm = 0.0633
-- Starting training on experience 45 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7915
	data_grads_norm = 4.8294
	new_data_grads_norm = 6.3979
	old_data_grads_norm = 5.5676
	sim_grads_norm = -0.0326
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1816
	data_grads_norm = 4.8367
	new_data_grads_norm = 7.2388
	old_data_grads_norm = 5.0285
	sim_grads_norm = 0.1073
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8695
	data_grads_norm = 4.6667
	new_data_grads_norm = 6.6591
	old_data_grads_norm = 6.4093
	sim_grads_norm = -0.0682
-- Starting training on experience 46 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2739
	data_grads_norm = 4.0614
	new_data_grads_norm = 5.9968
	old_data_grads_norm = 5.2062
	sim_grads_norm = 0.0033
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2644
	data_grads_norm = 4.3556
	new_data_grads_norm = 6.8662
	old_data_grads_norm = 5.6889
	sim_grads_norm = -0.0033
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2655
	data_grads_norm = 3.9986
	new_data_grads_norm = 6.4476
	old_data_grads_norm = 4.1896
	sim_grads_norm = 0.0614
-- Starting training on experience 47 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7946
	data_grads_norm = 4.7040
	new_data_grads_norm = 5.7166
	old_data_grads_norm = 7.1886
	sim_grads_norm = 0.0515
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4057
	data_grads_norm = 4.2470
	new_data_grads_norm = 5.4224
	old_data_grads_norm = 5.8552
	sim_grads_norm = -0.0174
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6916
	data_grads_norm = 4.4180
	new_data_grads_norm = 6.1934
	old_data_grads_norm = 5.4691
	sim_grads_norm = 0.0037
-- Starting training on experience 48 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7989
	data_grads_norm = 4.2198
	new_data_grads_norm = 6.8242
	old_data_grads_norm = 4.5615
	sim_grads_norm = -0.0118
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9437
	data_grads_norm = 4.4219
	new_data_grads_norm = 6.7743
	old_data_grads_norm = 6.5094
	sim_grads_norm = 0.0041
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8988
	data_grads_norm = 4.8965
	new_data_grads_norm = 7.0061
	old_data_grads_norm = 6.4497
	sim_grads_norm = 0.0442
-- Starting training on experience 49 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3841
	data_grads_norm = 4.2863
	new_data_grads_norm = 6.3589
	old_data_grads_norm = 5.7237
	sim_grads_norm = 0.0372
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3835
	data_grads_norm = 3.9513
	new_data_grads_norm = 5.3715
	old_data_grads_norm = 5.5024
	sim_grads_norm = -0.0194
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3343
	data_grads_norm = 4.1663
	new_data_grads_norm = 5.5867
	old_data_grads_norm = 5.4760
	sim_grads_norm = -0.0219
-- Starting training on experience 50 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1684
	data_grads_norm = 4.2441
	new_data_grads_norm = 5.9682
	old_data_grads_norm = 5.2310
	sim_grads_norm = -0.0184
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3046
	data_grads_norm = 4.0388
	new_data_grads_norm = 5.7371
	old_data_grads_norm = 5.7194
	sim_grads_norm = 0.0284
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1846
	data_grads_norm = 3.9567
	new_data_grads_norm = 5.3915
	old_data_grads_norm = 6.0598
	sim_grads_norm = -0.0254
-- Starting training on experience 51 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9970
	data_grads_norm = 4.0282
	new_data_grads_norm = 5.9632
	old_data_grads_norm = 4.1605
	sim_grads_norm = -0.0123
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8978
	data_grads_norm = 4.6706
	new_data_grads_norm = 7.1103
	old_data_grads_norm = 5.6278
	sim_grads_norm = -0.0085
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4896
	data_grads_norm = 4.6842
	new_data_grads_norm = 8.0089
	old_data_grads_norm = 5.4594
	sim_grads_norm = 0.0034
-- Starting training on experience 52 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1482
	data_grads_norm = 4.2823
	new_data_grads_norm = 5.5433
	old_data_grads_norm = 4.0384
	sim_grads_norm = 0.0204
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7070
	data_grads_norm = 4.9443
	new_data_grads_norm = 6.9385
	old_data_grads_norm = 5.2742
	sim_grads_norm = 0.0568
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4580
	data_grads_norm = 4.1211
	new_data_grads_norm = 5.3614
	old_data_grads_norm = 4.5819
	sim_grads_norm = 0.0196
-- Starting training on experience 53 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7113
	data_grads_norm = 4.6649
	new_data_grads_norm = 7.1553
	old_data_grads_norm = 5.3612
	sim_grads_norm = 0.0318
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6402
	data_grads_norm = 4.4701
	new_data_grads_norm = 6.7286
	old_data_grads_norm = 6.0644
	sim_grads_norm = 0.0004
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5676
	data_grads_norm = 4.2703
	new_data_grads_norm = 6.8407
	old_data_grads_norm = 4.0927
	sim_grads_norm = -0.0200
-- Starting training on experience 54 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5491
	data_grads_norm = 4.5535
	new_data_grads_norm = 6.5622
	old_data_grads_norm = 4.8964
	sim_grads_norm = -0.0333
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4130
	data_grads_norm = 4.1881
	new_data_grads_norm = 5.5587
	old_data_grads_norm = 5.2461
	sim_grads_norm = -0.0162
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4135
	data_grads_norm = 4.1752
	new_data_grads_norm = 6.0186
	old_data_grads_norm = 5.0671
	sim_grads_norm = 0.0177
-- Starting training on experience 55 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2542
	data_grads_norm = 4.0334
	new_data_grads_norm = 7.1423
	old_data_grads_norm = 5.0791
	sim_grads_norm = 0.0192
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3239
	data_grads_norm = 4.4072
	new_data_grads_norm = 6.3482
	old_data_grads_norm = 5.4805
	sim_grads_norm = 0.0021
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1395
	data_grads_norm = 4.9603
	new_data_grads_norm = 6.3909
	old_data_grads_norm = 5.4754
	sim_grads_norm = 0.0341
-- Starting training on experience 56 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8987
	data_grads_norm = 4.3472
	new_data_grads_norm = 5.9604
	old_data_grads_norm = 5.6661
	sim_grads_norm = -0.0172
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1508
	data_grads_norm = 3.6995
	new_data_grads_norm = 6.5241
	old_data_grads_norm = 4.1090
	sim_grads_norm = -0.0295
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8402
	data_grads_norm = 3.4362
	new_data_grads_norm = 6.3126
	old_data_grads_norm = 3.6024
	sim_grads_norm = 0.0110
-- Starting training on experience 57 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4073
	data_grads_norm = 4.1184
	new_data_grads_norm = 6.7932
	old_data_grads_norm = 4.3183
	sim_grads_norm = -0.0033
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5642
	data_grads_norm = 4.4871
	new_data_grads_norm = 6.6633
	old_data_grads_norm = 4.0470
	sim_grads_norm = 0.0233
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2634
	data_grads_norm = 4.5197
	new_data_grads_norm = 6.4098
	old_data_grads_norm = 5.0711
	sim_grads_norm = -0.0065
-- Starting training on experience 58 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8954
	data_grads_norm = 5.0378
	new_data_grads_norm = 7.5605
	old_data_grads_norm = 6.0946
	sim_grads_norm = -0.0047
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8410
	data_grads_norm = 4.8369
	new_data_grads_norm = 7.4414
	old_data_grads_norm = 7.0536
	sim_grads_norm = 0.0052
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0344
	data_grads_norm = 4.9891
	new_data_grads_norm = 7.4242
	old_data_grads_norm = 5.7759
	sim_grads_norm = 0.0391
-- Starting training on experience 59 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0263
	data_grads_norm = 4.7343
	new_data_grads_norm = 6.5415
	old_data_grads_norm = 4.4564
	sim_grads_norm = 0.0120
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0838
	data_grads_norm = 4.3806
	new_data_grads_norm = 5.9379
	old_data_grads_norm = 4.0914
	sim_grads_norm = 0.0400
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8265
	data_grads_norm = 4.0498
	new_data_grads_norm = 5.6166
	old_data_grads_norm = 5.5197
	sim_grads_norm = -0.0071
-- Starting training on experience 60 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1804
	data_grads_norm = 4.3124
	new_data_grads_norm = 5.5693
	old_data_grads_norm = 4.6005
	sim_grads_norm = 0.0644
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4254
	data_grads_norm = 4.5416
	new_data_grads_norm = 5.7326
	old_data_grads_norm = 5.7764
	sim_grads_norm = -0.0071
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9207
	data_grads_norm = 3.7482
	new_data_grads_norm = 5.5175
	old_data_grads_norm = 4.4568
	sim_grads_norm = -0.0390
-- Starting training on experience 61 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9826
	data_grads_norm = 4.4320
	new_data_grads_norm = 6.3691
	old_data_grads_norm = 4.4805
	sim_grads_norm = -0.0179
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4950
	data_grads_norm = 4.5211
	new_data_grads_norm = 6.4084
	old_data_grads_norm = 5.8768
	sim_grads_norm = 0.0086
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1663
	data_grads_norm = 4.4241
	new_data_grads_norm = 6.3802
	old_data_grads_norm = 5.1036
	sim_grads_norm = -0.0200
-- Starting training on experience 62 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2187
	data_grads_norm = 4.6182
	new_data_grads_norm = 7.5719
	old_data_grads_norm = 4.0172
	sim_grads_norm = -0.0169
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8416
	data_grads_norm = 5.0038
	new_data_grads_norm = 6.5844
	old_data_grads_norm = 5.8272
	sim_grads_norm = 0.0401
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4733
	data_grads_norm = 4.8119
	new_data_grads_norm = 6.6418
	old_data_grads_norm = 4.7411
	sim_grads_norm = 0.1112
-- Starting training on experience 63 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6645
	data_grads_norm = 4.1841
	new_data_grads_norm = 6.1448
	old_data_grads_norm = 4.4068
	sim_grads_norm = -0.0342
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4476
	data_grads_norm = 4.4075
	new_data_grads_norm = 5.9611
	old_data_grads_norm = 5.8818
	sim_grads_norm = -0.0021
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6400
	data_grads_norm = 4.5518
	new_data_grads_norm = 5.8734
	old_data_grads_norm = 7.6178
	sim_grads_norm = 0.0209
-- Starting training on experience 64 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8517
	data_grads_norm = 4.8508
	new_data_grads_norm = 5.4462
	old_data_grads_norm = 7.7047
	sim_grads_norm = -0.0510
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1738
	data_grads_norm = 4.2900
	new_data_grads_norm = 5.5702
	old_data_grads_norm = 4.8276
	sim_grads_norm = 0.0698
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0481
	data_grads_norm = 4.1122
	new_data_grads_norm = 5.9184
	old_data_grads_norm = 5.1765
	sim_grads_norm = -0.0676
-- Starting training on experience 65 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5452
	data_grads_norm = 4.6396
	new_data_grads_norm = 5.6313
	old_data_grads_norm = 6.3896
	sim_grads_norm = -0.0018
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4257
	data_grads_norm = 4.5488
	new_data_grads_norm = 6.2143
	old_data_grads_norm = 6.2230
	sim_grads_norm = 0.0197
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5849
	data_grads_norm = 4.3752
	new_data_grads_norm = 6.5689
	old_data_grads_norm = 6.0979
	sim_grads_norm = 0.0134
-- Starting training on experience 66 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2779
	data_grads_norm = 4.6317
	new_data_grads_norm = 6.7024
	old_data_grads_norm = 6.7447
	sim_grads_norm = -0.0524
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4539
	data_grads_norm = 4.4893
	new_data_grads_norm = 6.4546
	old_data_grads_norm = 5.7721
	sim_grads_norm = 0.0711
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4446
	data_grads_norm = 4.2043
	new_data_grads_norm = 6.1215
	old_data_grads_norm = 5.8827
	sim_grads_norm = 0.0658
-- Starting training on experience 67 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6782
	data_grads_norm = 4.5963
	new_data_grads_norm = 6.9025
	old_data_grads_norm = 5.3547
	sim_grads_norm = -0.0007
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4742
	data_grads_norm = 4.6003
	new_data_grads_norm = 7.1927
	old_data_grads_norm = 5.6036
	sim_grads_norm = -0.0016
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1310
	data_grads_norm = 4.3702
	new_data_grads_norm = 6.5190
	old_data_grads_norm = 4.6294
	sim_grads_norm = -0.0055
-- Starting training on experience 68 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2864
	data_grads_norm = 4.0351
	new_data_grads_norm = 6.5810
	old_data_grads_norm = 4.3047
	sim_grads_norm = -0.0162
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5727
	data_grads_norm = 4.3627
	new_data_grads_norm = 6.9984
	old_data_grads_norm = 5.1687
	sim_grads_norm = -0.0091
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1948
	data_grads_norm = 3.7350
	new_data_grads_norm = 6.7934
	old_data_grads_norm = 3.8663
	sim_grads_norm = -0.0209
-- Starting training on experience 69 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3078
	data_grads_norm = 3.7946
	new_data_grads_norm = 6.2516
	old_data_grads_norm = 3.5256
	sim_grads_norm = 0.0727
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2754
	data_grads_norm = 4.0168
	new_data_grads_norm = 5.0127
	old_data_grads_norm = 5.8001
	sim_grads_norm = -0.0028
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3362
	data_grads_norm = 3.7660
	new_data_grads_norm = 5.4849
	old_data_grads_norm = 5.6621
	sim_grads_norm = 0.0195
-- Starting training on experience 70 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1783
	data_grads_norm = 4.1376
	new_data_grads_norm = 6.3091
	old_data_grads_norm = 4.8524
	sim_grads_norm = -0.0286
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9118
	data_grads_norm = 4.9242
	new_data_grads_norm = 6.4322
	old_data_grads_norm = 6.2848
	sim_grads_norm = 0.0366
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8391
	data_grads_norm = 5.1499
	new_data_grads_norm = 6.6001
	old_data_grads_norm = 7.0103
	sim_grads_norm = 0.0193
-- Starting training on experience 71 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7079
	data_grads_norm = 3.4559
	new_data_grads_norm = 5.1652
	old_data_grads_norm = 4.9796
	sim_grads_norm = -0.0199
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4794
	data_grads_norm = 4.9895
	new_data_grads_norm = 6.4166
	old_data_grads_norm = 6.8519
	sim_grads_norm = 0.0781
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0130
	data_grads_norm = 4.2387
	new_data_grads_norm = 5.6606
	old_data_grads_norm = 5.1014
	sim_grads_norm = -0.0246
-- Starting training on experience 72 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3634
	data_grads_norm = 4.3520
	new_data_grads_norm = 5.9452
	old_data_grads_norm = 4.9708
	sim_grads_norm = -0.0325
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6731
	data_grads_norm = 5.1458
	new_data_grads_norm = 6.4915
	old_data_grads_norm = 6.9635
	sim_grads_norm = -0.0314
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0166
	data_grads_norm = 4.7244
	new_data_grads_norm = 6.0748
	old_data_grads_norm = 6.2734
	sim_grads_norm = 0.0436
-- Starting training on experience 73 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8624
	data_grads_norm = 4.7288
	new_data_grads_norm = 6.5275
	old_data_grads_norm = 5.9065
	sim_grads_norm = 0.0494
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6063
	data_grads_norm = 4.0858
	new_data_grads_norm = 6.4018
	old_data_grads_norm = 4.1283
	sim_grads_norm = 0.0038
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7517
	data_grads_norm = 4.2400
	new_data_grads_norm = 6.9096
	old_data_grads_norm = 4.6626
	sim_grads_norm = -0.0055
-- Starting training on experience 74 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0509
	data_grads_norm = 3.8327
	new_data_grads_norm = 6.5052
	old_data_grads_norm = 4.0288
	sim_grads_norm = -0.0437
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1168
	data_grads_norm = 5.5755
	new_data_grads_norm = 7.2709
	old_data_grads_norm = 7.3807
	sim_grads_norm = -0.0237
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1495
	data_grads_norm = 5.2670
	new_data_grads_norm = 7.8837
	old_data_grads_norm = 6.4071
	sim_grads_norm = 0.0374
-- Starting training on experience 75 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6120
	data_grads_norm = 4.0386
	new_data_grads_norm = 6.0090
	old_data_grads_norm = 5.6208
	sim_grads_norm = -0.0244
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2835
	data_grads_norm = 4.2234
	new_data_grads_norm = 6.8227
	old_data_grads_norm = 5.6180
	sim_grads_norm = 0.0271
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3339
	data_grads_norm = 4.8155
	new_data_grads_norm = 6.2757
	old_data_grads_norm = 6.2385
	sim_grads_norm = -0.0105
-- Starting training on experience 76 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4639
	data_grads_norm = 4.2978
	new_data_grads_norm = 5.5596
	old_data_grads_norm = 5.9582
	sim_grads_norm = 0.0364
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7287
	data_grads_norm = 3.1433
	new_data_grads_norm = 5.1619
	old_data_grads_norm = 4.1906
	sim_grads_norm = -0.0549
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9994
	data_grads_norm = 3.7121
	new_data_grads_norm = 6.2314
	old_data_grads_norm = 4.7276
	sim_grads_norm = 0.0132
-- Starting training on experience 77 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1972
	data_grads_norm = 4.0550
	new_data_grads_norm = 6.8412
	old_data_grads_norm = 4.9500
	sim_grads_norm = -0.0287
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2352
	data_grads_norm = 3.9706
	new_data_grads_norm = 5.8677
	old_data_grads_norm = 6.2944
	sim_grads_norm = -0.0448
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4814
	data_grads_norm = 4.4376
	new_data_grads_norm = 6.4573
	old_data_grads_norm = 4.6377
	sim_grads_norm = 0.0896
-- Starting training on experience 78 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0746
	data_grads_norm = 3.8675
	new_data_grads_norm = 5.2381
	old_data_grads_norm = 4.9422
	sim_grads_norm = 0.0057
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9546
	data_grads_norm = 3.4141
	new_data_grads_norm = 5.2623
	old_data_grads_norm = 5.0053
	sim_grads_norm = 0.0538
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9655
	data_grads_norm = 3.6665
	new_data_grads_norm = 4.9339
	old_data_grads_norm = 4.9858
	sim_grads_norm = -0.0153
-- Starting training on experience 79 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4051
	data_grads_norm = 4.6198
	new_data_grads_norm = 5.7417
	old_data_grads_norm = 6.2110
	sim_grads_norm = 0.0562
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4776
	data_grads_norm = 4.6365
	new_data_grads_norm = 6.4659
	old_data_grads_norm = 5.8845
	sim_grads_norm = -0.0017
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5160
	data_grads_norm = 4.6209
	new_data_grads_norm = 5.6834
	old_data_grads_norm = 6.2007
	sim_grads_norm = 0.0007
-- Starting training on experience 80 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1280
	data_grads_norm = 3.9596
	new_data_grads_norm = 6.4754
	old_data_grads_norm = 3.6691
	sim_grads_norm = 0.0398
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0927
	data_grads_norm = 4.0021
	new_data_grads_norm = 6.9866
	old_data_grads_norm = 6.2007
	sim_grads_norm = 0.0030
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2868
	data_grads_norm = 4.2563
	new_data_grads_norm = 6.7849
	old_data_grads_norm = 4.5436
	sim_grads_norm = -0.0131
-- Starting training on experience 81 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9145
	data_grads_norm = 4.1480
	new_data_grads_norm = 6.3780
	old_data_grads_norm = 3.5447
	sim_grads_norm = 0.0386
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7071
	data_grads_norm = 3.4188
	new_data_grads_norm = 4.9258
	old_data_grads_norm = 3.6864
	sim_grads_norm = -0.0246
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6374
	data_grads_norm = 4.9083
	new_data_grads_norm = 5.6142
	old_data_grads_norm = 6.8620
	sim_grads_norm = 0.0383
-- Starting training on experience 82 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4108
	data_grads_norm = 4.7578
	new_data_grads_norm = 7.1988
	old_data_grads_norm = 6.3945
	sim_grads_norm = 0.0435
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2567
	data_grads_norm = 4.7284
	new_data_grads_norm = 7.0988
	old_data_grads_norm = 6.0136
	sim_grads_norm = 0.0237
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0208
	data_grads_norm = 3.9977
	new_data_grads_norm = 6.2618
	old_data_grads_norm = 5.6409
	sim_grads_norm = -0.0032
-- Starting training on experience 83 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4374
	data_grads_norm = 3.9997
	new_data_grads_norm = 6.0518
	old_data_grads_norm = 5.2438
	sim_grads_norm = -0.0085
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0972
	data_grads_norm = 4.0561
	new_data_grads_norm = 6.5747
	old_data_grads_norm = 4.4667
	sim_grads_norm = -0.0247
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8616
	data_grads_norm = 4.3189
	new_data_grads_norm = 6.7411
	old_data_grads_norm = 5.1045
	sim_grads_norm = -0.0072
-- Starting training on experience 84 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2862
	data_grads_norm = 4.5120
	new_data_grads_norm = 6.4882
	old_data_grads_norm = 5.9318
	sim_grads_norm = -0.0057
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4149
	data_grads_norm = 4.6957
	new_data_grads_norm = 6.1049
	old_data_grads_norm = 6.1593
	sim_grads_norm = -0.0132
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4416
	data_grads_norm = 4.3866
	new_data_grads_norm = 5.5633
	old_data_grads_norm = 7.2343
	sim_grads_norm = 0.0463
-- Starting training on experience 85 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0924
	data_grads_norm = 4.0719
	new_data_grads_norm = 7.5613
	old_data_grads_norm = 3.4553
	sim_grads_norm = -0.0073
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0489
	data_grads_norm = 3.8034
	new_data_grads_norm = 6.8325
	old_data_grads_norm = 4.6187
	sim_grads_norm = -0.0202
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6344
	data_grads_norm = 4.5841
	new_data_grads_norm = 6.7061
	old_data_grads_norm = 6.3687
	sim_grads_norm = 0.0189
-- Starting training on experience 86 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2973
	data_grads_norm = 4.1838
	new_data_grads_norm = 6.3892
	old_data_grads_norm = 4.1079
	sim_grads_norm = 0.0101
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0298
	data_grads_norm = 3.6641
	new_data_grads_norm = 6.3932
	old_data_grads_norm = 3.9731
	sim_grads_norm = 0.0760
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3864
	data_grads_norm = 4.1339
	new_data_grads_norm = 5.5992
	old_data_grads_norm = 5.4234
	sim_grads_norm = -0.0244
-- Starting training on experience 87 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1203
	data_grads_norm = 3.7925
	new_data_grads_norm = 5.7893
	old_data_grads_norm = 5.8506
	sim_grads_norm = -0.0583
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3763
	data_grads_norm = 4.3875
	new_data_grads_norm = 6.6543
	old_data_grads_norm = 5.0697
	sim_grads_norm = 0.0455
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9436
	data_grads_norm = 4.0783
	new_data_grads_norm = 6.1280
	old_data_grads_norm = 3.2347
	sim_grads_norm = 0.1708
-- Starting training on experience 88 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9852
	data_grads_norm = 4.4194
	new_data_grads_norm = 6.4113
	old_data_grads_norm = 4.8968
	sim_grads_norm = -0.0282
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2311
	data_grads_norm = 4.3634
	new_data_grads_norm = 6.1055
	old_data_grads_norm = 6.1986
	sim_grads_norm = 0.0184
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7102
	data_grads_norm = 3.8859
	new_data_grads_norm = 5.2928
	old_data_grads_norm = 5.7800
	sim_grads_norm = -0.0482
-- Starting training on experience 89 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9040
	data_grads_norm = 3.9771
	new_data_grads_norm = 5.5873
	old_data_grads_norm = 5.9717
	sim_grads_norm = 0.0876
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7817
	data_grads_norm = 5.0621
	new_data_grads_norm = 5.8260
	old_data_grads_norm = 7.6091
	sim_grads_norm = -0.0299
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7562
	data_grads_norm = 4.0278
	new_data_grads_norm = 6.2091
	old_data_grads_norm = 5.1369
	sim_grads_norm = 0.0061
-- Starting training on experience 90 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1525
	data_grads_norm = 3.9743
	new_data_grads_norm = 6.4420
	old_data_grads_norm = 3.5969
	sim_grads_norm = 0.0183
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5000
	data_grads_norm = 4.4453
	new_data_grads_norm = 6.3355
	old_data_grads_norm = 5.9408
	sim_grads_norm = -0.0065
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4318
	data_grads_norm = 4.7340
	new_data_grads_norm = 7.0099
	old_data_grads_norm = 5.9043
	sim_grads_norm = -0.0228
-- Starting training on experience 91 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2553
	data_grads_norm = 4.7664
	new_data_grads_norm = 6.4878
	old_data_grads_norm = 6.0333
	sim_grads_norm = 0.0650
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9799
	data_grads_norm = 3.6756
	new_data_grads_norm = 5.4993
	old_data_grads_norm = 4.0481
	sim_grads_norm = 0.0553
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6991
	data_grads_norm = 4.5455
	new_data_grads_norm = 5.8606
	old_data_grads_norm = 7.2377
	sim_grads_norm = -0.0406
-- Starting training on experience 92 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5080
	data_grads_norm = 4.5532
	new_data_grads_norm = 6.2217
	old_data_grads_norm = 6.9148
	sim_grads_norm = -0.0099
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0873
	data_grads_norm = 3.8692
	new_data_grads_norm = 6.1086
	old_data_grads_norm = 5.7874
	sim_grads_norm = -0.0164
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0299
	data_grads_norm = 3.7880
	new_data_grads_norm = 5.8841
	old_data_grads_norm = 5.2912
	sim_grads_norm = -0.0210
-- Starting training on experience 93 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4973
	data_grads_norm = 4.7910
	new_data_grads_norm = 6.8061
	old_data_grads_norm = 7.0545
	sim_grads_norm = -0.0131
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8972
	data_grads_norm = 4.6656
	new_data_grads_norm = 7.2272
	old_data_grads_norm = 4.5964
	sim_grads_norm = 0.0983
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1734
	data_grads_norm = 3.9606
	new_data_grads_norm = 6.6212
	old_data_grads_norm = 3.8291
	sim_grads_norm = -0.0222
-- Starting training on experience 94 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8731
	data_grads_norm = 3.9192
	new_data_grads_norm = 6.3716
	old_data_grads_norm = 3.9620
	sim_grads_norm = 0.0009
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1337
	data_grads_norm = 4.3787
	new_data_grads_norm = 5.9744
	old_data_grads_norm = 5.5533
	sim_grads_norm = -0.0037
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2319
	data_grads_norm = 4.5325
	new_data_grads_norm = 6.6453
	old_data_grads_norm = 5.0957
	sim_grads_norm = 0.0607
-- Starting training on experience 95 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2872
	data_grads_norm = 4.1567
	new_data_grads_norm = 6.2747
	old_data_grads_norm = 4.8093
	sim_grads_norm = 0.0010
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3137
	data_grads_norm = 4.6118
	new_data_grads_norm = 6.7906
	old_data_grads_norm = 5.0840
	sim_grads_norm = 0.0749
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4266
	data_grads_norm = 4.4819
	new_data_grads_norm = 6.8799
	old_data_grads_norm = 4.8154
	sim_grads_norm = 0.0186
-- Starting training on experience 96 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4903
	data_grads_norm = 4.0786
	new_data_grads_norm = 5.6159
	old_data_grads_norm = 4.8594
	sim_grads_norm = 0.0943
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1726
	data_grads_norm = 4.4969
	new_data_grads_norm = 6.3542
	old_data_grads_norm = 4.4913
	sim_grads_norm = -0.0312
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0283
	data_grads_norm = 3.9501
	new_data_grads_norm = 6.4479
	old_data_grads_norm = 4.5014
	sim_grads_norm = -0.0122
-- Starting training on experience 97 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6954
	data_grads_norm = 3.8690
	new_data_grads_norm = 6.1732
	old_data_grads_norm = 4.7288
	sim_grads_norm = -0.0314
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9448
	data_grads_norm = 4.4973
	new_data_grads_norm = 6.1592
	old_data_grads_norm = 4.8043
	sim_grads_norm = 0.0094
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1507
	data_grads_norm = 4.4938
	new_data_grads_norm = 7.7208
	old_data_grads_norm = 6.1578
	sim_grads_norm = -0.0655
-- Starting training on experience 98 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4119
	data_grads_norm = 4.7769
	new_data_grads_norm = 6.4420
	old_data_grads_norm = 6.0522
	sim_grads_norm = 0.0172
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5258
	data_grads_norm = 4.4050
	new_data_grads_norm = 6.8860
	old_data_grads_norm = 5.3975
	sim_grads_norm = 0.0186
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1627
	data_grads_norm = 4.1314
	new_data_grads_norm = 6.5171
	old_data_grads_norm = 4.3691
	sim_grads_norm = 0.0069
-- Starting training on experience 99 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2894
	data_grads_norm = 4.4727
	new_data_grads_norm = 6.2282
	old_data_grads_norm = 6.8060
	sim_grads_norm = 0.0105
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0264
	data_grads_norm = 3.9962
	new_data_grads_norm = 5.8183
	old_data_grads_norm = 5.6249
	sim_grads_norm = -0.0492
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9774
	data_grads_norm = 3.6969
	new_data_grads_norm = 6.1582
	old_data_grads_norm = 4.9356
	sim_grads_norm = 0.0108
-- Starting training on experience 100 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3851
	data_grads_norm = 4.7742
	new_data_grads_norm = 7.1898
	old_data_grads_norm = 6.0882
	sim_grads_norm = -0.0173
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8895
	data_grads_norm = 4.7268
	new_data_grads_norm = 6.8753
	old_data_grads_norm = 6.2174
	sim_grads_norm = -0.0244
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2750
	data_grads_norm = 4.6556
	new_data_grads_norm = 7.1735
	old_data_grads_norm = 5.9785
	sim_grads_norm = -0.0311
-- Starting training on experience 101 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8930
	data_grads_norm = 4.8364
	new_data_grads_norm = 6.9723
	old_data_grads_norm = 5.7958
	sim_grads_norm = -0.0194
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7641
	data_grads_norm = 4.2451
	new_data_grads_norm = 7.2141
	old_data_grads_norm = 4.0680
	sim_grads_norm = 0.0432
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3717
	data_grads_norm = 3.9194
	new_data_grads_norm = 6.2937
	old_data_grads_norm = 4.7116
	sim_grads_norm = -0.0340
-- Starting training on experience 102 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3284
	data_grads_norm = 4.8430
	new_data_grads_norm = 6.9756
	old_data_grads_norm = 5.7051
	sim_grads_norm = 0.0397
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0503
	data_grads_norm = 5.2497
	new_data_grads_norm = 7.6342
	old_data_grads_norm = 5.7238
	sim_grads_norm = 0.0287
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3101
	data_grads_norm = 4.5788
	new_data_grads_norm = 7.4993
	old_data_grads_norm = 6.2461
	sim_grads_norm = 0.0130
-- Starting training on experience 103 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2493
	data_grads_norm = 4.2278
	new_data_grads_norm = 5.9650
	old_data_grads_norm = 4.3123
	sim_grads_norm = -0.0156
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9942
	data_grads_norm = 4.0034
	new_data_grads_norm = 6.5881
	old_data_grads_norm = 4.0375
	sim_grads_norm = 0.0505
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3133
	data_grads_norm = 4.7232
	new_data_grads_norm = 6.4015
	old_data_grads_norm = 5.5914
	sim_grads_norm = 0.0227
-- Starting training on experience 104 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8105
	data_grads_norm = 3.6641
	new_data_grads_norm = 5.2418
	old_data_grads_norm = 4.5268
	sim_grads_norm = -0.0116
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1507
	data_grads_norm = 3.9840
	new_data_grads_norm = 5.3673
	old_data_grads_norm = 4.9484
	sim_grads_norm = -0.0050
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1705
	data_grads_norm = 3.9963
	new_data_grads_norm = 5.3175
	old_data_grads_norm = 5.8309
	sim_grads_norm = 0.0394
-- Starting training on experience 105 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7313
	data_grads_norm = 3.4196
	new_data_grads_norm = 6.5244
	old_data_grads_norm = 3.5176
	sim_grads_norm = -0.0139
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0958
	data_grads_norm = 4.7499
	new_data_grads_norm = 6.4291
	old_data_grads_norm = 6.9421
	sim_grads_norm = -0.0006
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1477
	data_grads_norm = 4.8905
	new_data_grads_norm = 6.4089
	old_data_grads_norm = 6.2570
	sim_grads_norm = -0.0119
-- Starting training on experience 106 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5104
	data_grads_norm = 4.9776
	new_data_grads_norm = 7.2556
	old_data_grads_norm = 6.2236
	sim_grads_norm = -0.0080
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9617
	data_grads_norm = 4.1872
	new_data_grads_norm = 5.7724
	old_data_grads_norm = 4.6501
	sim_grads_norm = 0.0037
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9502
	data_grads_norm = 4.9635
	new_data_grads_norm = 6.4716
	old_data_grads_norm = 6.0663
	sim_grads_norm = 0.0671
-- Starting training on experience 107 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8528
	data_grads_norm = 3.6059
	new_data_grads_norm = 5.7729
	old_data_grads_norm = 2.4699
	sim_grads_norm = 0.1000
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7680
	data_grads_norm = 3.2472
	new_data_grads_norm = 5.6845
	old_data_grads_norm = 4.4805
	sim_grads_norm = -0.0317
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8584
	data_grads_norm = 3.9801
	new_data_grads_norm = 6.9410
	old_data_grads_norm = 5.3267
	sim_grads_norm = -0.0133
-- Starting training on experience 108 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1572
	data_grads_norm = 3.8031
	new_data_grads_norm = 5.0142
	old_data_grads_norm = 4.4025
	sim_grads_norm = 0.1089
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9373
	data_grads_norm = 4.3654
	new_data_grads_norm = 4.8389
	old_data_grads_norm = 6.5311
	sim_grads_norm = -0.0130
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9334
	data_grads_norm = 3.5775
	new_data_grads_norm = 4.7880
	old_data_grads_norm = 5.1448
	sim_grads_norm = 0.0255
-- Starting training on experience 109 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4458
	data_grads_norm = 4.6621
	new_data_grads_norm = 6.6994
	old_data_grads_norm = 5.2901
	sim_grads_norm = 0.0218
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5254
	data_grads_norm = 4.8652
	new_data_grads_norm = 6.3608
	old_data_grads_norm = 7.5919
	sim_grads_norm = 0.0357
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6516
	data_grads_norm = 3.8279
	new_data_grads_norm = 5.7620
	old_data_grads_norm = 4.5525
	sim_grads_norm = -0.0410
-- Starting training on experience 110 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5458
	data_grads_norm = 3.3108
	new_data_grads_norm = 4.4226
	old_data_grads_norm = 4.1008
	sim_grads_norm = 0.0437
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7261
	data_grads_norm = 3.9594
	new_data_grads_norm = 4.8856
	old_data_grads_norm = 4.9440
	sim_grads_norm = -0.0076
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6851
	data_grads_norm = 3.2345
	new_data_grads_norm = 5.4485
	old_data_grads_norm = 3.5124
	sim_grads_norm = 0.0087
-- Starting training on experience 111 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4455
	data_grads_norm = 3.1338
	new_data_grads_norm = 5.5401
	old_data_grads_norm = 2.7966
	sim_grads_norm = 0.0257
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4539
	data_grads_norm = 4.0241
	new_data_grads_norm = 6.8894
	old_data_grads_norm = 6.0859
	sim_grads_norm = -0.0151
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7991
	data_grads_norm = 3.8825
	new_data_grads_norm = 6.3541
	old_data_grads_norm = 4.1188
	sim_grads_norm = -0.0554
-- Starting training on experience 112 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2034
	data_grads_norm = 4.3682
	new_data_grads_norm = 6.2302
	old_data_grads_norm = 6.8523
	sim_grads_norm = 0.0183
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1475
	data_grads_norm = 3.8187
	new_data_grads_norm = 5.8595
	old_data_grads_norm = 5.8745
	sim_grads_norm = -0.0123
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3667
	data_grads_norm = 3.9627
	new_data_grads_norm = 6.9432
	old_data_grads_norm = 4.2297
	sim_grads_norm = -0.0443
-- Starting training on experience 113 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4890
	data_grads_norm = 4.9991
	new_data_grads_norm = 6.6738
	old_data_grads_norm = 5.9046
	sim_grads_norm = 0.0108
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8997
	data_grads_norm = 4.2732
	new_data_grads_norm = 6.6625
	old_data_grads_norm = 4.8195
	sim_grads_norm = 0.0010
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3701
	data_grads_norm = 4.6139
	new_data_grads_norm = 7.2067
	old_data_grads_norm = 3.3995
	sim_grads_norm = 0.0790
-- Starting training on experience 114 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4864
	data_grads_norm = 4.5804
	new_data_grads_norm = 6.5926
	old_data_grads_norm = 6.1069
	sim_grads_norm = 0.0400
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4215
	data_grads_norm = 4.9631
	new_data_grads_norm = 6.5454
	old_data_grads_norm = 6.2145
	sim_grads_norm = -0.0257
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5223
	data_grads_norm = 5.0220
	new_data_grads_norm = 7.3881
	old_data_grads_norm = 5.3533
	sim_grads_norm = 0.0242
-- Starting training on experience 115 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5940
	data_grads_norm = 4.9356
	new_data_grads_norm = 7.3576
	old_data_grads_norm = 5.8321
	sim_grads_norm = 0.0154
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2987
	data_grads_norm = 4.2953
	new_data_grads_norm = 6.7517
	old_data_grads_norm = 4.7134
	sim_grads_norm = 0.0197
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8839
	data_grads_norm = 4.7554
	new_data_grads_norm = 6.7154
	old_data_grads_norm = 6.0410
	sim_grads_norm = 0.0082
-- Starting training on experience 116 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9443
	data_grads_norm = 4.1007
	new_data_grads_norm = 6.5422
	old_data_grads_norm = 6.2929
	sim_grads_norm = -0.0370
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9523
	data_grads_norm = 4.1989
	new_data_grads_norm = 6.3310
	old_data_grads_norm = 5.3316
	sim_grads_norm = -0.0280
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3280
	data_grads_norm = 4.2631
	new_data_grads_norm = 6.6182
	old_data_grads_norm = 4.5022
	sim_grads_norm = -0.0145
-- Starting training on experience 117 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4619
	data_grads_norm = 4.4979
	new_data_grads_norm = 6.0526
	old_data_grads_norm = 5.7071
	sim_grads_norm = -0.0112
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6383
	data_grads_norm = 4.0596
	new_data_grads_norm = 6.3926
	old_data_grads_norm = 3.8750
	sim_grads_norm = -0.0088
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9527
	data_grads_norm = 4.7203
	new_data_grads_norm = 6.5363
	old_data_grads_norm = 5.8297
	sim_grads_norm = -0.0079
-- Starting training on experience 118 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4846
	data_grads_norm = 4.5718
	new_data_grads_norm = 7.4429
	old_data_grads_norm = 3.6574
	sim_grads_norm = -0.0154
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3144
	data_grads_norm = 4.1899
	new_data_grads_norm = 6.8853
	old_data_grads_norm = 2.9243
	sim_grads_norm = -0.0257
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5747
	data_grads_norm = 4.5965
	new_data_grads_norm = 7.0644
	old_data_grads_norm = 4.3290
	sim_grads_norm = 0.0046
-- Starting training on experience 119 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4787
	data_grads_norm = 4.2203
	new_data_grads_norm = 6.4992
	old_data_grads_norm = 5.7170
	sim_grads_norm = -0.0162
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8798
	data_grads_norm = 3.5843
	new_data_grads_norm = 6.2735
	old_data_grads_norm = 2.8121
	sim_grads_norm = 0.0059
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6835
	data_grads_norm = 5.1754
	new_data_grads_norm = 6.6915
	old_data_grads_norm = 5.7633
	sim_grads_norm = 0.0134
-- Starting training on experience 120 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2544
	data_grads_norm = 3.9181
	new_data_grads_norm = 6.3864
	old_data_grads_norm = 4.0742
	sim_grads_norm = 0.0196
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2078
	data_grads_norm = 3.9549
	new_data_grads_norm = 6.5161
	old_data_grads_norm = 4.8614
	sim_grads_norm = -0.0057
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3020
	data_grads_norm = 4.6482
	new_data_grads_norm = 7.0210
	old_data_grads_norm = 5.3850
	sim_grads_norm = -0.0073
-- Starting training on experience 121 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5921
	data_grads_norm = 5.0779
	new_data_grads_norm = 8.6561
	old_data_grads_norm = 4.8806
	sim_grads_norm = 0.0289
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5994
	data_grads_norm = 4.8022
	new_data_grads_norm = 7.7888
	old_data_grads_norm = 5.2126
	sim_grads_norm = 0.0240
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9519
	data_grads_norm = 5.2703
	new_data_grads_norm = 6.6994
	old_data_grads_norm = 7.9642
	sim_grads_norm = 0.0315
-- Starting training on experience 122 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0541
	data_grads_norm = 4.9911
	new_data_grads_norm = 6.2400
	old_data_grads_norm = 6.7619
	sim_grads_norm = 0.0712
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3092
	data_grads_norm = 4.3068
	new_data_grads_norm = 6.1057
	old_data_grads_norm = 4.6391
	sim_grads_norm = 0.0358
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0632
	data_grads_norm = 3.8539
	new_data_grads_norm = 5.8692
	old_data_grads_norm = 5.0496
	sim_grads_norm = -0.0289
-- Starting training on experience 123 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4207
	data_grads_norm = 4.9398
	new_data_grads_norm = 6.7385
	old_data_grads_norm = 4.9038
	sim_grads_norm = -0.0091
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6345
	data_grads_norm = 5.0016
	new_data_grads_norm = 6.2983
	old_data_grads_norm = 6.4870
	sim_grads_norm = 0.0552
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4370
	data_grads_norm = 4.4595
	new_data_grads_norm = 6.3932
	old_data_grads_norm = 6.8845
	sim_grads_norm = -0.0182
-- Starting training on experience 124 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9857
	data_grads_norm = 4.3050
	new_data_grads_norm = 6.9036
	old_data_grads_norm = 4.4813
	sim_grads_norm = -0.0265
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2857
	data_grads_norm = 4.5698
	new_data_grads_norm = 6.9153
	old_data_grads_norm = 4.9953
	sim_grads_norm = 0.0172
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2865
	data_grads_norm = 4.4342
	new_data_grads_norm = 6.7209
	old_data_grads_norm = 4.2247
	sim_grads_norm = 0.0519
-- Starting training on experience 125 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4945
	data_grads_norm = 4.8922
	new_data_grads_norm = 6.3512
	old_data_grads_norm = 7.3044
	sim_grads_norm = 0.0188
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5669
	data_grads_norm = 5.0993
	new_data_grads_norm = 6.2965
	old_data_grads_norm = 6.1569
	sim_grads_norm = 0.0068
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2518
	data_grads_norm = 4.7697
	new_data_grads_norm = 6.6151
	old_data_grads_norm = 8.8954
	sim_grads_norm = 0.0247
-- Starting training on experience 126 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0304
	data_grads_norm = 4.0034
	new_data_grads_norm = 6.2677
	old_data_grads_norm = 5.1150
	sim_grads_norm = 0.0338
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2236
	data_grads_norm = 4.7444
	new_data_grads_norm = 6.1039
	old_data_grads_norm = 6.2885
	sim_grads_norm = 0.0419
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3744
	data_grads_norm = 4.7712
	new_data_grads_norm = 6.7582
	old_data_grads_norm = 5.8713
	sim_grads_norm = -0.0236
-- Starting training on experience 127 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6743
	data_grads_norm = 3.6749
	new_data_grads_norm = 5.8143
	old_data_grads_norm = 4.5905
	sim_grads_norm = -0.0035
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8157
	data_grads_norm = 4.0938
	new_data_grads_norm = 5.2776
	old_data_grads_norm = 4.7306
	sim_grads_norm = 0.0835
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2262
	data_grads_norm = 4.7204
	new_data_grads_norm = 5.8010
	old_data_grads_norm = 6.6018
	sim_grads_norm = -0.0205
-- Starting training on experience 128 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0321
	data_grads_norm = 3.6902
	new_data_grads_norm = 5.8048
	old_data_grads_norm = 4.0961
	sim_grads_norm = 0.0043
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2911
	data_grads_norm = 4.1580
	new_data_grads_norm = 6.2095
	old_data_grads_norm = 4.7971
	sim_grads_norm = 0.0047
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0629
	data_grads_norm = 4.1093
	new_data_grads_norm = 5.8369
	old_data_grads_norm = 4.4835
	sim_grads_norm = -0.0131
-- Starting training on experience 129 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0253
	data_grads_norm = 3.8497
	new_data_grads_norm = 5.7723
	old_data_grads_norm = 4.5252
	sim_grads_norm = -0.0106
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1073
	data_grads_norm = 3.9349
	new_data_grads_norm = 5.5390
	old_data_grads_norm = 4.6063
	sim_grads_norm = 0.0228
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3196
	data_grads_norm = 4.7319
	new_data_grads_norm = 6.4272
	old_data_grads_norm = 5.9222
	sim_grads_norm = -0.0204
-- Starting training on experience 130 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9921
	data_grads_norm = 3.7039
	new_data_grads_norm = 6.9127
	old_data_grads_norm = 4.8769
	sim_grads_norm = -0.0258
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4879
	data_grads_norm = 4.8074
	new_data_grads_norm = 6.6474
	old_data_grads_norm = 5.3496
	sim_grads_norm = -0.0266
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4873
	data_grads_norm = 4.5693
	new_data_grads_norm = 7.2548
	old_data_grads_norm = 5.4754
	sim_grads_norm = -0.0272
-- Starting training on experience 131 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8538
	data_grads_norm = 5.3617
	new_data_grads_norm = 6.5300
	old_data_grads_norm = 8.0809
	sim_grads_norm = 0.0098
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0990
	data_grads_norm = 3.6399
	new_data_grads_norm = 6.1653
	old_data_grads_norm = 3.6665
	sim_grads_norm = -0.0369
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8929
	data_grads_norm = 4.3331
	new_data_grads_norm = 6.1188
	old_data_grads_norm = 5.4296
	sim_grads_norm = 0.0752
-- Starting training on experience 132 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1408
	data_grads_norm = 4.0184
	new_data_grads_norm = 6.8522
	old_data_grads_norm = 4.4079
	sim_grads_norm = 0.0374
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1781
	data_grads_norm = 4.3887
	new_data_grads_norm = 6.7419
	old_data_grads_norm = 6.1269
	sim_grads_norm = 0.0304
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7702
	data_grads_norm = 4.7272
	new_data_grads_norm = 6.8110
	old_data_grads_norm = 5.8233
	sim_grads_norm = 0.0723
-- Starting training on experience 133 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4263
	data_grads_norm = 3.5156
	new_data_grads_norm = 6.5070
	old_data_grads_norm = 2.3621
	sim_grads_norm = -0.0126
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8754
	data_grads_norm = 4.4117
	new_data_grads_norm = 6.7089
	old_data_grads_norm = 4.6261
	sim_grads_norm = 0.0341
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6906
	data_grads_norm = 4.1529
	new_data_grads_norm = 6.8549
	old_data_grads_norm = 4.2563
	sim_grads_norm = 0.0394
-- Starting training on experience 134 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5995
	data_grads_norm = 3.1833
	new_data_grads_norm = 5.6566
	old_data_grads_norm = 3.2936
	sim_grads_norm = -0.0280
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7937
	data_grads_norm = 3.5825
	new_data_grads_norm = 5.5026
	old_data_grads_norm = 4.1161
	sim_grads_norm = -0.0351
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8523
	data_grads_norm = 3.8046
	new_data_grads_norm = 5.8227
	old_data_grads_norm = 5.2700
	sim_grads_norm = -0.0021
-- Starting training on experience 135 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9575
	data_grads_norm = 4.4088
	new_data_grads_norm = 5.6411
	old_data_grads_norm = 5.5274
	sim_grads_norm = -0.0014
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1858
	data_grads_norm = 4.3300
	new_data_grads_norm = 6.9991
	old_data_grads_norm = 4.3227
	sim_grads_norm = 0.0073
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1344
	data_grads_norm = 4.8923
	new_data_grads_norm = 6.6486
	old_data_grads_norm = 5.8820
	sim_grads_norm = 0.0127
-- Starting training on experience 136 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4793
	data_grads_norm = 4.2018
	new_data_grads_norm = 7.3576
	old_data_grads_norm = 4.7461
	sim_grads_norm = -0.0008
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0571
	data_grads_norm = 4.5604
	new_data_grads_norm = 7.6849
	old_data_grads_norm = 5.4674
	sim_grads_norm = 0.0180
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6582
	data_grads_norm = 4.8348
	new_data_grads_norm = 7.8284
	old_data_grads_norm = 5.3795
	sim_grads_norm = 0.0434
-- Starting training on experience 137 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0857
	data_grads_norm = 4.2783
	new_data_grads_norm = 6.6666
	old_data_grads_norm = 4.2995
	sim_grads_norm = -0.0019
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2332
	data_grads_norm = 4.1774
	new_data_grads_norm = 6.7759
	old_data_grads_norm = 4.8483
	sim_grads_norm = 0.0000
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5352
	data_grads_norm = 4.0922
	new_data_grads_norm = 6.6150
	old_data_grads_norm = 4.2443
	sim_grads_norm = -0.0188
-- Starting training on experience 138 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5390
	data_grads_norm = 5.1001
	new_data_grads_norm = 6.8755
	old_data_grads_norm = 7.0424
	sim_grads_norm = -0.0151
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4916
	data_grads_norm = 5.2960
	new_data_grads_norm = 7.1342
	old_data_grads_norm = 5.1223
	sim_grads_norm = 0.0422
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5097
	data_grads_norm = 4.8920
	new_data_grads_norm = 7.1213
	old_data_grads_norm = 5.8534
	sim_grads_norm = -0.0112
-- Starting training on experience 139 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6483
	data_grads_norm = 3.7049
	new_data_grads_norm = 6.8479
	old_data_grads_norm = 3.7000
	sim_grads_norm = -0.0171
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4680
	data_grads_norm = 5.3102
	new_data_grads_norm = 6.9419
	old_data_grads_norm = 7.7812
	sim_grads_norm = 0.0679
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6317
	data_grads_norm = 3.7400
	new_data_grads_norm = 5.7285
	old_data_grads_norm = 5.1292
	sim_grads_norm = 0.0135
-- Starting training on experience 140 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3809
	data_grads_norm = 4.8637
	new_data_grads_norm = 7.4109
	old_data_grads_norm = 6.4754
	sim_grads_norm = 0.0016
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3089
	data_grads_norm = 4.8059
	new_data_grads_norm = 8.1035
	old_data_grads_norm = 6.3158
	sim_grads_norm = -0.0116
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2412
	data_grads_norm = 5.0068
	new_data_grads_norm = 8.2479
	old_data_grads_norm = 5.8562
	sim_grads_norm = -0.0126
-- Starting training on experience 141 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3180
	data_grads_norm = 5.1895
	new_data_grads_norm = 7.5585
	old_data_grads_norm = 5.3603
	sim_grads_norm = 0.0169
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6591
	data_grads_norm = 5.5125
	new_data_grads_norm = 6.8520
	old_data_grads_norm = 7.4281
	sim_grads_norm = 0.0164
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6137
	data_grads_norm = 4.3991
	new_data_grads_norm = 6.6836
	old_data_grads_norm = 4.3123
	sim_grads_norm = 0.0420
-- Starting training on experience 142 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4237
	data_grads_norm = 4.8367
	new_data_grads_norm = 7.9694
	old_data_grads_norm = 6.2364
	sim_grads_norm = 0.0406
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2603
	data_grads_norm = 4.4218
	new_data_grads_norm = 7.6596
	old_data_grads_norm = 4.8514
	sim_grads_norm = 0.0579
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4538
	data_grads_norm = 5.0785
	new_data_grads_norm = 7.5435
	old_data_grads_norm = 6.2681
	sim_grads_norm = -0.0088
-- Starting training on experience 143 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7512
	data_grads_norm = 4.6837
	new_data_grads_norm = 6.1119
	old_data_grads_norm = 6.7343
	sim_grads_norm = 0.0236
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4357
	data_grads_norm = 4.6504
	new_data_grads_norm = 7.2848
	old_data_grads_norm = 5.0781
	sim_grads_norm = 0.0090
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4853
	data_grads_norm = 4.5660
	new_data_grads_norm = 6.9409
	old_data_grads_norm = 5.5107
	sim_grads_norm = -0.0278
-- Starting training on experience 144 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9025
	data_grads_norm = 4.8144
	new_data_grads_norm = 6.7720
	old_data_grads_norm = 5.5393
	sim_grads_norm = -0.0325
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1462
	data_grads_norm = 4.7757
	new_data_grads_norm = 7.4720
	old_data_grads_norm = 4.6155
	sim_grads_norm = -0.0088
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4314
	data_grads_norm = 4.7246
	new_data_grads_norm = 7.5627
	old_data_grads_norm = 5.9600
	sim_grads_norm = -0.0347
-- Starting training on experience 145 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6766
	data_grads_norm = 5.5233
	new_data_grads_norm = 7.7079
	old_data_grads_norm = 4.5181
	sim_grads_norm = -0.0047
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1813
	data_grads_norm = 5.4739
	new_data_grads_norm = 7.8201
	old_data_grads_norm = 5.5829
	sim_grads_norm = 0.0309
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6210
	data_grads_norm = 5.3426
	new_data_grads_norm = 6.8830
	old_data_grads_norm = 6.6696
	sim_grads_norm = -0.0173
-- Starting training on experience 146 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4826
	data_grads_norm = 5.0969
	new_data_grads_norm = 7.5561
	old_data_grads_norm = 5.0183
	sim_grads_norm = -0.0717
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5359
	data_grads_norm = 4.9676
	new_data_grads_norm = 7.0178
	old_data_grads_norm = 6.1525
	sim_grads_norm = -0.0018
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2630
	data_grads_norm = 4.7935
	new_data_grads_norm = 7.0280
	old_data_grads_norm = 5.8834
	sim_grads_norm = -0.0247
-- Starting training on experience 147 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6737
	data_grads_norm = 3.6925
	new_data_grads_norm = 5.9593
	old_data_grads_norm = 3.4819
	sim_grads_norm = -0.0203
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7881
	data_grads_norm = 3.7890
	new_data_grads_norm = 6.1253
	old_data_grads_norm = 4.9653
	sim_grads_norm = -0.0618
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9499
	data_grads_norm = 4.2158
	new_data_grads_norm = 6.6980
	old_data_grads_norm = 4.2393
	sim_grads_norm = -0.0262
-- Starting training on experience 148 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5390
	data_grads_norm = 4.8825
	new_data_grads_norm = 8.1909
	old_data_grads_norm = 6.1150
	sim_grads_norm = 0.0006
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2543
	data_grads_norm = 4.7241
	new_data_grads_norm = 7.7050
	old_data_grads_norm = 5.6646
	sim_grads_norm = -0.0007
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5808
	data_grads_norm = 4.7500
	new_data_grads_norm = 7.0511
	old_data_grads_norm = 5.8381
	sim_grads_norm = -0.0085
-- Starting training on experience 149 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3188
	data_grads_norm = 3.9790
	new_data_grads_norm = 6.2639
	old_data_grads_norm = 4.4419
	sim_grads_norm = 0.0427
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4731
	data_grads_norm = 4.6128
	new_data_grads_norm = 5.7471
	old_data_grads_norm = 6.9723
	sim_grads_norm = -0.0101
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4889
	data_grads_norm = 4.6109
	new_data_grads_norm = 6.2123
	old_data_grads_norm = 5.8903
	sim_grads_norm = 0.0542
-- Starting training on experience 150 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1436
	data_grads_norm = 3.9774
	new_data_grads_norm = 6.4204
	old_data_grads_norm = 5.2560
	sim_grads_norm = 0.0018
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3537
	data_grads_norm = 4.1211
	new_data_grads_norm = 5.6470
	old_data_grads_norm = 4.9024
	sim_grads_norm = 0.0615
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2434
	data_grads_norm = 4.1523
	new_data_grads_norm = 6.2105
	old_data_grads_norm = 5.2210
	sim_grads_norm = 0.0823
-- Starting training on experience 151 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1576
	data_grads_norm = 4.2374
	new_data_grads_norm = 5.8631
	old_data_grads_norm = 5.4855
	sim_grads_norm = 0.0260
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0606
	data_grads_norm = 3.9105
	new_data_grads_norm = 5.7676
	old_data_grads_norm = 5.2702
	sim_grads_norm = -0.0462
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9897
	data_grads_norm = 3.7007
	new_data_grads_norm = 6.5800
	old_data_grads_norm = 3.2491
	sim_grads_norm = -0.0229
-- Starting training on experience 152 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8407
	data_grads_norm = 3.7621
	new_data_grads_norm = 6.6044
	old_data_grads_norm = 2.3528
	sim_grads_norm = -0.0090
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3315
	data_grads_norm = 4.2815
	new_data_grads_norm = 6.5595
	old_data_grads_norm = 4.3737
	sim_grads_norm = -0.0456
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5241
	data_grads_norm = 4.8888
	new_data_grads_norm = 7.4836
	old_data_grads_norm = 5.6016
	sim_grads_norm = 0.0067
-- Starting training on experience 153 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4928
	data_grads_norm = 4.8819
	new_data_grads_norm = 7.3670
	old_data_grads_norm = 6.0928
	sim_grads_norm = -0.0129
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9130
	data_grads_norm = 3.8031
	new_data_grads_norm = 7.0223
	old_data_grads_norm = 4.8562
	sim_grads_norm = 0.0101
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3071
	data_grads_norm = 5.3017
	new_data_grads_norm = 6.9971
	old_data_grads_norm = 6.1855
	sim_grads_norm = 0.0148
-- Starting training on experience 154 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8137
	data_grads_norm = 4.4065
	new_data_grads_norm = 6.2190
	old_data_grads_norm = 4.6686
	sim_grads_norm = 0.0172
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1830
	data_grads_norm = 4.4846
	new_data_grads_norm = 7.3426
	old_data_grads_norm = 5.2954
	sim_grads_norm = -0.0129
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2871
	data_grads_norm = 4.3750
	new_data_grads_norm = 6.5604
	old_data_grads_norm = 5.6205
	sim_grads_norm = -0.0138
-- Starting training on experience 155 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4570
	data_grads_norm = 4.3061
	new_data_grads_norm = 7.0857
	old_data_grads_norm = 4.2523
	sim_grads_norm = -0.0419
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8148
	data_grads_norm = 4.7087
	new_data_grads_norm = 6.7530
	old_data_grads_norm = 6.0850
	sim_grads_norm = -0.0012
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4923
	data_grads_norm = 4.6678
	new_data_grads_norm = 6.5420
	old_data_grads_norm = 6.7733
	sim_grads_norm = 0.0028
-- Starting training on experience 156 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2780
	data_grads_norm = 4.1931
	new_data_grads_norm = 6.4200
	old_data_grads_norm = 4.6572
	sim_grads_norm = 0.0274
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6827
	data_grads_norm = 4.7845
	new_data_grads_norm = 6.7950
	old_data_grads_norm = 5.4813
	sim_grads_norm = 0.0050
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6344
	data_grads_norm = 4.4620
	new_data_grads_norm = 7.0686
	old_data_grads_norm = 5.1320
	sim_grads_norm = 0.0902
-- Starting training on experience 157 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1633
	data_grads_norm = 4.6223
	new_data_grads_norm = 7.7113
	old_data_grads_norm = 6.2437
	sim_grads_norm = 0.0448
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4316
	data_grads_norm = 4.9983
	new_data_grads_norm = 6.9837
	old_data_grads_norm = 6.9995
	sim_grads_norm = 0.0725
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1258
	data_grads_norm = 4.6960
	new_data_grads_norm = 8.2987
	old_data_grads_norm = 6.2649
	sim_grads_norm = 0.0365
-- Starting training on experience 158 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9013
	data_grads_norm = 3.5793
	new_data_grads_norm = 5.4176
	old_data_grads_norm = 4.1698
	sim_grads_norm = 0.0176
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9889
	data_grads_norm = 4.0800
	new_data_grads_norm = 5.5950
	old_data_grads_norm = 5.1616
	sim_grads_norm = 0.0250
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4960
	data_grads_norm = 4.5178
	new_data_grads_norm = 5.4940
	old_data_grads_norm = 6.9231
	sim_grads_norm = 0.0446
-- Starting training on experience 159 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1364
	data_grads_norm = 4.0202
	new_data_grads_norm = 6.7222
	old_data_grads_norm = 5.4282
	sim_grads_norm = 0.0240
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2311
	data_grads_norm = 4.3049
	new_data_grads_norm = 6.5219
	old_data_grads_norm = 6.4584
	sim_grads_norm = 0.0957
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0430
	data_grads_norm = 4.2612
	new_data_grads_norm = 6.0447
	old_data_grads_norm = 5.6017
	sim_grads_norm = -0.0375
-- Starting training on experience 160 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8837
	data_grads_norm = 5.2214
	new_data_grads_norm = 6.5605
	old_data_grads_norm = 6.4793
	sim_grads_norm = -0.0287
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3059
	data_grads_norm = 4.3653
	new_data_grads_norm = 6.4435
	old_data_grads_norm = 7.1724
	sim_grads_norm = 0.0088
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4779
	data_grads_norm = 4.5808
	new_data_grads_norm = 7.1873
	old_data_grads_norm = 5.5399
	sim_grads_norm = 0.0405
-- Starting training on experience 161 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2680
	data_grads_norm = 4.7088
	new_data_grads_norm = 7.0867
	old_data_grads_norm = 5.1964
	sim_grads_norm = -0.0020
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6066
	data_grads_norm = 5.3515
	new_data_grads_norm = 6.5299
	old_data_grads_norm = 7.2913
	sim_grads_norm = 0.0036
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3937
	data_grads_norm = 4.8963
	new_data_grads_norm = 6.0996
	old_data_grads_norm = 6.0158
	sim_grads_norm = 0.0845
-- Starting training on experience 162 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8932
	data_grads_norm = 4.5657
	new_data_grads_norm = 5.8252
	old_data_grads_norm = 7.0699
	sim_grads_norm = 0.0213
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0184
	data_grads_norm = 4.4277
	new_data_grads_norm = 5.7429
	old_data_grads_norm = 5.5404
	sim_grads_norm = 0.0091
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8622
	data_grads_norm = 3.8132
	new_data_grads_norm = 5.6041
	old_data_grads_norm = 4.3803
	sim_grads_norm = -0.0217
-- Starting training on experience 163 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0833
	data_grads_norm = 4.0089
	new_data_grads_norm = 6.5386
	old_data_grads_norm = 4.1727
	sim_grads_norm = -0.0425
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2739
	data_grads_norm = 4.6908
	new_data_grads_norm = 6.9278
	old_data_grads_norm = 6.8569
	sim_grads_norm = 0.0183
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3280
	data_grads_norm = 4.7261
	new_data_grads_norm = 7.2792
	old_data_grads_norm = 5.4326
	sim_grads_norm = -0.0274
-- Starting training on experience 164 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8011
	data_grads_norm = 5.3488
	new_data_grads_norm = 6.3344
	old_data_grads_norm = 6.7209
	sim_grads_norm = 0.0296
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1565
	data_grads_norm = 4.1541
	new_data_grads_norm = 5.9653
	old_data_grads_norm = 3.8444
	sim_grads_norm = 0.0044
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8900
	data_grads_norm = 4.9552
	new_data_grads_norm = 6.0584
	old_data_grads_norm = 5.8913
	sim_grads_norm = 0.0616
-- Starting training on experience 165 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7522
	data_grads_norm = 4.0169
	new_data_grads_norm = 6.0738
	old_data_grads_norm = 6.3094
	sim_grads_norm = 0.0178
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0347
	data_grads_norm = 4.1906
	new_data_grads_norm = 6.3139
	old_data_grads_norm = 4.2249
	sim_grads_norm = 0.0837
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6960
	data_grads_norm = 3.6234
	new_data_grads_norm = 5.3980
	old_data_grads_norm = 4.4367
	sim_grads_norm = -0.0276
-- Starting training on experience 166 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8375
	data_grads_norm = 4.0729
	new_data_grads_norm = 5.8288
	old_data_grads_norm = 4.2614
	sim_grads_norm = -0.0269
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1805
	data_grads_norm = 4.5811
	new_data_grads_norm = 6.3224
	old_data_grads_norm = 5.7062
	sim_grads_norm = 0.0094
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0561
	data_grads_norm = 4.7281
	new_data_grads_norm = 6.2417
	old_data_grads_norm = 6.6059
	sim_grads_norm = -0.0037
-- Starting training on experience 167 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0890
	data_grads_norm = 4.2836
	new_data_grads_norm = 6.7942
	old_data_grads_norm = 4.8408
	sim_grads_norm = -0.0058
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9952
	data_grads_norm = 4.4529
	new_data_grads_norm = 6.6116
	old_data_grads_norm = 6.5165
	sim_grads_norm = -0.0334
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1614
	data_grads_norm = 4.6115
	new_data_grads_norm = 6.3149
	old_data_grads_norm = 6.5544
	sim_grads_norm = 0.1515
-- Starting training on experience 168 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0870
	data_grads_norm = 4.0104
	new_data_grads_norm = 5.6872
	old_data_grads_norm = 4.3445
	sim_grads_norm = 0.0628
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6024
	data_grads_norm = 5.5795
	new_data_grads_norm = 5.8788
	old_data_grads_norm = 8.2577
	sim_grads_norm = -0.0287
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5524
	data_grads_norm = 3.5003
	new_data_grads_norm = 5.4343
	old_data_grads_norm = 2.9779
	sim_grads_norm = 0.1276
-- Starting training on experience 169 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6775
	data_grads_norm = 4.7639
	new_data_grads_norm = 6.0650
	old_data_grads_norm = 6.4594
	sim_grads_norm = -0.0300
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3531
	data_grads_norm = 4.3507
	new_data_grads_norm = 6.8725
	old_data_grads_norm = 3.1879
	sim_grads_norm = 0.0705
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8839
	data_grads_norm = 4.5355
	new_data_grads_norm = 5.5918
	old_data_grads_norm = 6.8673
	sim_grads_norm = -0.0184
-- Starting training on experience 170 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5906
	data_grads_norm = 3.9415
	new_data_grads_norm = 5.5623
	old_data_grads_norm = 4.7417
	sim_grads_norm = -0.0102
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9108
	data_grads_norm = 4.1174
	new_data_grads_norm = 4.9996
	old_data_grads_norm = 4.3351
	sim_grads_norm = -0.0363
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6597
	data_grads_norm = 3.8418
	new_data_grads_norm = 6.1099
	old_data_grads_norm = 4.0191
	sim_grads_norm = 0.0047
-- Starting training on experience 171 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7763
	data_grads_norm = 4.5861
	new_data_grads_norm = 6.9538
	old_data_grads_norm = 6.2486
	sim_grads_norm = 0.0009
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5698
	data_grads_norm = 4.1861
	new_data_grads_norm = 7.0607
	old_data_grads_norm = 5.4392
	sim_grads_norm = -0.0046
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1738
	data_grads_norm = 4.3288
	new_data_grads_norm = 6.9484
	old_data_grads_norm = 5.3947
	sim_grads_norm = 0.0195
-- Starting training on experience 172 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5939
	data_grads_norm = 3.6507
	new_data_grads_norm = 5.5196
	old_data_grads_norm = 4.9838
	sim_grads_norm = -0.0045
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2261
	data_grads_norm = 4.0970
	new_data_grads_norm = 5.7851
	old_data_grads_norm = 5.8236
	sim_grads_norm = 0.0210
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1588
	data_grads_norm = 4.4564
	new_data_grads_norm = 5.1229
	old_data_grads_norm = 5.8778
	sim_grads_norm = 0.1052
-- Starting training on experience 173 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3172
	data_grads_norm = 4.5361
	new_data_grads_norm = 5.9111
	old_data_grads_norm = 5.2346
	sim_grads_norm = 0.0262
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8124
	data_grads_norm = 5.1624
	new_data_grads_norm = 6.2988
	old_data_grads_norm = 6.8235
	sim_grads_norm = 0.0778
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6542
	data_grads_norm = 3.6886
	new_data_grads_norm = 5.9150
	old_data_grads_norm = 5.1807
	sim_grads_norm = -0.0144
-- Starting training on experience 174 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5600
	data_grads_norm = 3.3080
	new_data_grads_norm = 5.7827
	old_data_grads_norm = 3.7607
	sim_grads_norm = 0.0210
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6717
	data_grads_norm = 3.8876
	new_data_grads_norm = 5.8038
	old_data_grads_norm = 5.8521
	sim_grads_norm = -0.0108
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3925
	data_grads_norm = 3.6332
	new_data_grads_norm = 5.7827
	old_data_grads_norm = 5.8824
	sim_grads_norm = -0.0516
-- Starting training on experience 175 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2345
	data_grads_norm = 4.5622
	new_data_grads_norm = 5.6505
	old_data_grads_norm = 7.2006
	sim_grads_norm = 0.0629
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0439
	data_grads_norm = 4.5486
	new_data_grads_norm = 5.6098
	old_data_grads_norm = 5.9330
	sim_grads_norm = 0.0415
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1354
	data_grads_norm = 4.4617
	new_data_grads_norm = 5.7557
	old_data_grads_norm = 6.4370
	sim_grads_norm = 0.0244
-- Starting training on experience 176 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6448
	data_grads_norm = 3.6912
	new_data_grads_norm = 5.8652
	old_data_grads_norm = 5.8546
	sim_grads_norm = -0.0512
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9046
	data_grads_norm = 4.1675
	new_data_grads_norm = 6.4459
	old_data_grads_norm = 4.9143
	sim_grads_norm = 0.0072
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5988
	data_grads_norm = 3.9595
	new_data_grads_norm = 6.6424
	old_data_grads_norm = 4.2275
	sim_grads_norm = -0.0221
-- Starting training on experience 177 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0057
	data_grads_norm = 4.6993
	new_data_grads_norm = 7.1726
	old_data_grads_norm = 5.2426
	sim_grads_norm = 0.0482
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8258
	data_grads_norm = 4.5682
	new_data_grads_norm = 7.5819
	old_data_grads_norm = 5.3402
	sim_grads_norm = -0.0105
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4350
	data_grads_norm = 3.8946
	new_data_grads_norm = 6.3753
	old_data_grads_norm = 3.9256
	sim_grads_norm = -0.0084
-- Starting training on experience 178 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8643
	data_grads_norm = 3.7708
	new_data_grads_norm = 5.8480
	old_data_grads_norm = 4.9407
	sim_grads_norm = -0.0300
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9984
	data_grads_norm = 4.5177
	new_data_grads_norm = 6.0721
	old_data_grads_norm = 3.8258
	sim_grads_norm = 0.0101
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3657
	data_grads_norm = 4.5276
	new_data_grads_norm = 5.2582
	old_data_grads_norm = 6.9942
	sim_grads_norm = -0.0489
-- Starting training on experience 179 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6105
	data_grads_norm = 3.9603
	new_data_grads_norm = 5.5194
	old_data_grads_norm = 4.8583
	sim_grads_norm = 0.0406
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3459
	data_grads_norm = 3.8404
	new_data_grads_norm = 5.6154
	old_data_grads_norm = 4.4980
	sim_grads_norm = -0.0524
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3377
	data_grads_norm = 3.2295
	new_data_grads_norm = 5.4876
	old_data_grads_norm = 3.7909
	sim_grads_norm = -0.0111
-- Starting training on experience 180 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7203
	data_grads_norm = 3.9871
	new_data_grads_norm = 5.8884
	old_data_grads_norm = 4.4279
	sim_grads_norm = -0.0031
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0585
	data_grads_norm = 4.3881
	new_data_grads_norm = 5.8755
	old_data_grads_norm = 4.9146
	sim_grads_norm = 0.0596
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5222
	data_grads_norm = 3.8771
	new_data_grads_norm = 6.2050
	old_data_grads_norm = 5.5547
	sim_grads_norm = -0.0551
-- Starting training on experience 181 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5611
	data_grads_norm = 3.6773
	new_data_grads_norm = 6.1299
	old_data_grads_norm = 4.1904
	sim_grads_norm = -0.0324
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5634
	data_grads_norm = 4.5028
	new_data_grads_norm = 6.8610
	old_data_grads_norm = 6.3443
	sim_grads_norm = 0.0276
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4813
	data_grads_norm = 4.0591
	new_data_grads_norm = 5.3554
	old_data_grads_norm = 4.0615
	sim_grads_norm = -0.0177
-- Starting training on experience 182 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6873
	data_grads_norm = 4.4424
	new_data_grads_norm = 6.9800
	old_data_grads_norm = 5.6921
	sim_grads_norm = -0.0368
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3049
	data_grads_norm = 4.4399
	new_data_grads_norm = 8.2744
	old_data_grads_norm = 4.2776
	sim_grads_norm = -0.0418
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1018
	data_grads_norm = 4.7442
	new_data_grads_norm = 8.2854
	old_data_grads_norm = 6.5866
	sim_grads_norm = -0.0130
-- Starting training on experience 183 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0610
	data_grads_norm = 4.4176
	new_data_grads_norm = 7.1454
	old_data_grads_norm = 5.2413
	sim_grads_norm = -0.0109
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2461
	data_grads_norm = 4.4425
	new_data_grads_norm = 6.9877
	old_data_grads_norm = 4.8893
	sim_grads_norm = -0.0276
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7010
	data_grads_norm = 5.0856
	new_data_grads_norm = 6.9154
	old_data_grads_norm = 5.4524
	sim_grads_norm = 0.0637
-- Starting training on experience 184 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2378
	data_grads_norm = 4.0335
	new_data_grads_norm = 6.3169
	old_data_grads_norm = 5.6073
	sim_grads_norm = -0.0228
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5523
	data_grads_norm = 4.7036
	new_data_grads_norm = 6.8087
	old_data_grads_norm = 5.4667
	sim_grads_norm = 0.0203
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0662
	data_grads_norm = 3.8365
	new_data_grads_norm = 6.0555
	old_data_grads_norm = 4.2437
	sim_grads_norm = 0.0357
-- Starting training on experience 185 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3019
	data_grads_norm = 4.7606
	new_data_grads_norm = 6.0451
	old_data_grads_norm = 6.9261
	sim_grads_norm = -0.0307
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5987
	data_grads_norm = 4.6365
	new_data_grads_norm = 6.5599
	old_data_grads_norm = 7.5598
	sim_grads_norm = -0.0364
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2843
	data_grads_norm = 4.3527
	new_data_grads_norm = 6.0230
	old_data_grads_norm = 6.7026
	sim_grads_norm = -0.0346
-- Starting training on experience 186 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0276
	data_grads_norm = 5.2650
	new_data_grads_norm = 7.9076
	old_data_grads_norm = 6.1048
	sim_grads_norm = 0.0289
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5889
	data_grads_norm = 5.3835
	new_data_grads_norm = 8.0015
	old_data_grads_norm = 6.6627
	sim_grads_norm = 0.0114
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8626
	data_grads_norm = 5.1090
	new_data_grads_norm = 7.7031
	old_data_grads_norm = 6.1080
	sim_grads_norm = 0.0156
-- Starting training on experience 187 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5022
	data_grads_norm = 4.3494
	new_data_grads_norm = 5.9141
	old_data_grads_norm = 6.9527
	sim_grads_norm = 0.0140
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7844
	data_grads_norm = 4.7388
	new_data_grads_norm = 7.0199
	old_data_grads_norm = 5.4139
	sim_grads_norm = 0.0461
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6567
	data_grads_norm = 4.3794
	new_data_grads_norm = 6.5313
	old_data_grads_norm = 5.0772
	sim_grads_norm = -0.0242
-- Starting training on experience 188 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9968
	data_grads_norm = 4.5022
	new_data_grads_norm = 6.4505
	old_data_grads_norm = 5.3061
	sim_grads_norm = 0.0106
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6525
	data_grads_norm = 3.5502
	new_data_grads_norm = 5.7116
	old_data_grads_norm = 3.7448
	sim_grads_norm = 0.0180
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6025
	data_grads_norm = 3.7793
	new_data_grads_norm = 5.8295
	old_data_grads_norm = 5.3380
	sim_grads_norm = -0.0561
-- Starting training on experience 189 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2961
	data_grads_norm = 4.7858
	new_data_grads_norm = 6.9179
	old_data_grads_norm = 4.6007
	sim_grads_norm = 0.0740
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6320
	data_grads_norm = 5.1745
	new_data_grads_norm = 7.5587
	old_data_grads_norm = 5.8351
	sim_grads_norm = 0.0125
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0108
	data_grads_norm = 4.3841
	new_data_grads_norm = 6.4130
	old_data_grads_norm = 5.0389
	sim_grads_norm = -0.0207
-- Starting training on experience 190 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0523
	data_grads_norm = 4.4893
	new_data_grads_norm = 6.3415
	old_data_grads_norm = 5.7233
	sim_grads_norm = 0.0023
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8731
	data_grads_norm = 3.9631
	new_data_grads_norm = 5.8447
	old_data_grads_norm = 4.2386
	sim_grads_norm = -0.0741
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2243
	data_grads_norm = 4.7106
	new_data_grads_norm = 7.1646
	old_data_grads_norm = 5.0556
	sim_grads_norm = -0.0302
-- Starting training on experience 191 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3406
	data_grads_norm = 4.8956
	new_data_grads_norm = 6.9058
	old_data_grads_norm = 6.0132
	sim_grads_norm = 0.0800
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9296
	data_grads_norm = 4.4489
	new_data_grads_norm = 8.0516
	old_data_grads_norm = 5.6296
	sim_grads_norm = -0.0234
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9928
	data_grads_norm = 4.3095
	new_data_grads_norm = 6.3685
	old_data_grads_norm = 5.7714
	sim_grads_norm = -0.0155
-- Starting training on experience 192 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9153
	data_grads_norm = 4.6587
	new_data_grads_norm = 7.1007
	old_data_grads_norm = 5.1667
	sim_grads_norm = 0.0016
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7653
	data_grads_norm = 4.0837
	new_data_grads_norm = 6.1165
	old_data_grads_norm = 6.4344
	sim_grads_norm = 0.0089
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0944
	data_grads_norm = 4.9076
	new_data_grads_norm = 6.8313
	old_data_grads_norm = 6.9086
	sim_grads_norm = 0.0092
-- Starting training on experience 193 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0612
	data_grads_norm = 4.4538
	new_data_grads_norm = 6.0523
	old_data_grads_norm = 4.6677
	sim_grads_norm = 0.0681
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1233
	data_grads_norm = 4.8862
	new_data_grads_norm = 4.7160
	old_data_grads_norm = 7.0835
	sim_grads_norm = 0.0195
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7955
	data_grads_norm = 3.7546
	new_data_grads_norm = 5.9208
	old_data_grads_norm = 5.0559
	sim_grads_norm = -0.0146
-- Starting training on experience 194 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4445
	data_grads_norm = 5.7546
	new_data_grads_norm = 8.0981
	old_data_grads_norm = 6.6464
	sim_grads_norm = -0.0212
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7614
	data_grads_norm = 3.8358
	new_data_grads_norm = 7.2455
	old_data_grads_norm = 3.8881
	sim_grads_norm = -0.0032
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1261
	data_grads_norm = 4.9602
	new_data_grads_norm = 6.5391
	old_data_grads_norm = 5.2683
	sim_grads_norm = 0.1321
-- Starting training on experience 195 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7188
	data_grads_norm = 5.5459
	new_data_grads_norm = 7.2936
	old_data_grads_norm = 6.4804
	sim_grads_norm = 0.0108
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5710
	data_grads_norm = 4.7366
	new_data_grads_norm = 7.7703
	old_data_grads_norm = 5.8210
	sim_grads_norm = 0.0583
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1972
	data_grads_norm = 4.1752
	new_data_grads_norm = 6.8924
	old_data_grads_norm = 5.2380
	sim_grads_norm = 0.0705
-- Starting training on experience 196 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3865
	data_grads_norm = 3.3482
	new_data_grads_norm = 5.4192
	old_data_grads_norm = 4.0251
	sim_grads_norm = 0.0427
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4369
	data_grads_norm = 3.6726
	new_data_grads_norm = 5.6144
	old_data_grads_norm = 5.4141
	sim_grads_norm = -0.0065
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4573
	data_grads_norm = 4.0333
	new_data_grads_norm = 6.7746
	old_data_grads_norm = 5.7468
	sim_grads_norm = -0.0222
-- Starting training on experience 197 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8719
	data_grads_norm = 3.8148
	new_data_grads_norm = 5.2718
	old_data_grads_norm = 4.2668
	sim_grads_norm = -0.0264
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1186
	data_grads_norm = 3.9427
	new_data_grads_norm = 5.7657
	old_data_grads_norm = 5.3945
	sim_grads_norm = 0.0341
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2724
	data_grads_norm = 5.1093
	new_data_grads_norm = 5.4009
	old_data_grads_norm = 7.7407
	sim_grads_norm = 0.0471
-- Starting training on experience 198 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7262
	data_grads_norm = 3.5886
	new_data_grads_norm = 6.7595
	old_data_grads_norm = 3.3880
	sim_grads_norm = 0.0099
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4821
	data_grads_norm = 5.1447
	new_data_grads_norm = 7.5900
	old_data_grads_norm = 5.8135
	sim_grads_norm = 0.0026
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0911
	data_grads_norm = 3.8985
	new_data_grads_norm = 6.5916
	old_data_grads_norm = 3.6707
	sim_grads_norm = 0.0838
-- Starting training on experience 199 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7513
	data_grads_norm = 4.1320
	new_data_grads_norm = 5.4197
	old_data_grads_norm = 6.8674
	sim_grads_norm = -0.0013
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5812
	data_grads_norm = 3.3763
	new_data_grads_norm = 5.7750
	old_data_grads_norm = 4.4580
	sim_grads_norm = 0.0714
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9245
	data_grads_norm = 3.5678
	new_data_grads_norm = 5.1527
	old_data_grads_norm = 4.6984
	sim_grads_norm = -0.0074
-- Starting training on experience 200 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0753
	data_grads_norm = 4.0910
	new_data_grads_norm = 6.9456
	old_data_grads_norm = 5.0415
	sim_grads_norm = 0.0109
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3612
	data_grads_norm = 4.1516
	new_data_grads_norm = 6.1981
	old_data_grads_norm = 4.6457
	sim_grads_norm = 0.0559
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1450
	data_grads_norm = 4.3741
	new_data_grads_norm = 6.3885
	old_data_grads_norm = 5.9951
	sim_grads_norm = -0.0083
-- Starting training on experience 201 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0728
	data_grads_norm = 4.0802
	new_data_grads_norm = 6.7001
	old_data_grads_norm = 5.1138
	sim_grads_norm = 0.0093
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7567
	data_grads_norm = 4.1293
	new_data_grads_norm = 6.6782
	old_data_grads_norm = 4.2883
	sim_grads_norm = -0.0275
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3167
	data_grads_norm = 4.9216
	new_data_grads_norm = 7.7754
	old_data_grads_norm = 5.8582
	sim_grads_norm = -0.0285
-- Starting training on experience 202 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1830
	data_grads_norm = 4.2088
	new_data_grads_norm = 6.0749
	old_data_grads_norm = 4.3835
	sim_grads_norm = 0.0023
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1192
	data_grads_norm = 4.1945
	new_data_grads_norm = 6.1285
	old_data_grads_norm = 6.0262
	sim_grads_norm = 0.0249
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2928
	data_grads_norm = 4.9148
	new_data_grads_norm = 6.6009
	old_data_grads_norm = 5.7606
	sim_grads_norm = 0.0467
-- Starting training on experience 203 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8119
	data_grads_norm = 4.4258
	new_data_grads_norm = 6.1522
	old_data_grads_norm = 5.9961
	sim_grads_norm = 0.0050
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3286
	data_grads_norm = 3.6833
	new_data_grads_norm = 5.8716
	old_data_grads_norm = 4.1858
	sim_grads_norm = -0.0204
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2782
	data_grads_norm = 3.6748
	new_data_grads_norm = 5.7703
	old_data_grads_norm = 4.0087
	sim_grads_norm = 0.0077
-- Starting training on experience 204 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0289
	data_grads_norm = 5.0651
	new_data_grads_norm = 7.7427
	old_data_grads_norm = 5.1759
	sim_grads_norm = 0.0142
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7498
	data_grads_norm = 5.0491
	new_data_grads_norm = 7.5268
	old_data_grads_norm = 6.3515
	sim_grads_norm = 0.0020
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8694
	data_grads_norm = 4.8792
	new_data_grads_norm = 6.9888
	old_data_grads_norm = 6.2504
	sim_grads_norm = 0.0004
-- Starting training on experience 205 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6262
	data_grads_norm = 4.4214
	new_data_grads_norm = 6.3585
	old_data_grads_norm = 4.8373
	sim_grads_norm = -0.0247
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1190
	data_grads_norm = 4.2815
	new_data_grads_norm = 6.5650
	old_data_grads_norm = 8.4081
	sim_grads_norm = 0.0099
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8238
	data_grads_norm = 3.7477
	new_data_grads_norm = 6.4532
	old_data_grads_norm = 4.2579
	sim_grads_norm = 0.0172
-- Starting training on experience 206 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0870
	data_grads_norm = 5.3156
	new_data_grads_norm = 7.8365
	old_data_grads_norm = 6.1352
	sim_grads_norm = 0.0390
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1033
	data_grads_norm = 5.0905
	new_data_grads_norm = 7.2210
	old_data_grads_norm = 6.7936
	sim_grads_norm = 0.0021
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7586
	data_grads_norm = 4.5729
	new_data_grads_norm = 7.8428
	old_data_grads_norm = 4.6261
	sim_grads_norm = -0.0021
-- Starting training on experience 207 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2439
	data_grads_norm = 5.0063
	new_data_grads_norm = 6.2870
	old_data_grads_norm = 5.7611
	sim_grads_norm = -0.0040
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4038
	data_grads_norm = 5.5433
	new_data_grads_norm = 8.1119
	old_data_grads_norm = 5.7036
	sim_grads_norm = 0.0243
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7000
	data_grads_norm = 4.5741
	new_data_grads_norm = 6.8639
	old_data_grads_norm = 6.9722
	sim_grads_norm = 0.0031
-- Starting training on experience 208 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1814
	data_grads_norm = 4.3207
	new_data_grads_norm = 5.7923
	old_data_grads_norm = 4.5697
	sim_grads_norm = 0.0432
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1110
	data_grads_norm = 4.5048
	new_data_grads_norm = 6.0122
	old_data_grads_norm = 6.0555
	sim_grads_norm = 0.0609
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9585
	data_grads_norm = 4.4989
	new_data_grads_norm = 6.0712
	old_data_grads_norm = 5.9359
	sim_grads_norm = 0.0266
-- Starting training on experience 209 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8348
	data_grads_norm = 4.6212
	new_data_grads_norm = 5.9975
	old_data_grads_norm = 7.1045
	sim_grads_norm = -0.0033
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9422
	data_grads_norm = 4.2966
	new_data_grads_norm = 5.8827
	old_data_grads_norm = 6.1848
	sim_grads_norm = -0.0088
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0158
	data_grads_norm = 4.3945
	new_data_grads_norm = 6.0522
	old_data_grads_norm = 5.8433
	sim_grads_norm = 0.0092
-- Starting training on experience 210 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4053
	data_grads_norm = 5.2593
	new_data_grads_norm = 7.5052
	old_data_grads_norm = 6.8273
	sim_grads_norm = 0.0522
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8068
	data_grads_norm = 5.3907
	new_data_grads_norm = 7.1653
	old_data_grads_norm = 6.2064
	sim_grads_norm = 0.0607
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0975
	data_grads_norm = 4.7175
	new_data_grads_norm = 7.6537
	old_data_grads_norm = 5.4702
	sim_grads_norm = 0.0075
-- Starting training on experience 211 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6176
	data_grads_norm = 5.3874
	new_data_grads_norm = 6.8426
	old_data_grads_norm = 7.3473
	sim_grads_norm = -0.0112
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5235
	data_grads_norm = 4.6010
	new_data_grads_norm = 6.5024
	old_data_grads_norm = 6.7712
	sim_grads_norm = 0.0123
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9107
	data_grads_norm = 4.5198
	new_data_grads_norm = 6.5615
	old_data_grads_norm = 5.6593
	sim_grads_norm = 0.0027
-- Starting training on experience 212 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8874
	data_grads_norm = 3.8231
	new_data_grads_norm = 5.5091
	old_data_grads_norm = 4.1903
	sim_grads_norm = -0.0146
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1079
	data_grads_norm = 4.4441
	new_data_grads_norm = 5.8575
	old_data_grads_norm = 6.2530
	sim_grads_norm = -0.0295
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9888
	data_grads_norm = 4.0651
	new_data_grads_norm = 6.2557
	old_data_grads_norm = 4.9933
	sim_grads_norm = -0.0091
-- Starting training on experience 213 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3271
	data_grads_norm = 4.6542
	new_data_grads_norm = 7.3340
	old_data_grads_norm = 4.9957
	sim_grads_norm = 0.0579
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9435
	data_grads_norm = 4.3769
	new_data_grads_norm = 7.3553
	old_data_grads_norm = 4.5746
	sim_grads_norm = -0.0127
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7906
	data_grads_norm = 3.9300
	new_data_grads_norm = 7.0148
	old_data_grads_norm = 5.0478
	sim_grads_norm = -0.0473
-- Starting training on experience 214 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4960
	data_grads_norm = 3.2684
	new_data_grads_norm = 5.8228
	old_data_grads_norm = 3.0401
	sim_grads_norm = -0.0124
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0160
	data_grads_norm = 4.3204
	new_data_grads_norm = 5.5683
	old_data_grads_norm = 5.8228
	sim_grads_norm = -0.0172
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6879
	data_grads_norm = 3.4491
	new_data_grads_norm = 6.1138
	old_data_grads_norm = 2.6359
	sim_grads_norm = 0.0520
-- Starting training on experience 215 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3517
	data_grads_norm = 4.4202
	new_data_grads_norm = 6.4479
	old_data_grads_norm = 5.7474
	sim_grads_norm = 0.0505
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1701
	data_grads_norm = 4.3426
	new_data_grads_norm = 6.2058
	old_data_grads_norm = 5.5209
	sim_grads_norm = 0.0017
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5765
	data_grads_norm = 4.7594
	new_data_grads_norm = 5.9496
	old_data_grads_norm = 6.7925
	sim_grads_norm = 0.0619
-- Starting training on experience 216 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8073
	data_grads_norm = 4.7229
	new_data_grads_norm = 7.3162
	old_data_grads_norm = 5.7830
	sim_grads_norm = 0.0387
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2110
	data_grads_norm = 4.8084
	new_data_grads_norm = 6.9435
	old_data_grads_norm = 6.7755
	sim_grads_norm = 0.0623
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1373
	data_grads_norm = 4.0631
	new_data_grads_norm = 6.5595
	old_data_grads_norm = 4.8652
	sim_grads_norm = -0.0078
-- Starting training on experience 217 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6308
	data_grads_norm = 4.2058
	new_data_grads_norm = 6.6334
	old_data_grads_norm = 5.7098
	sim_grads_norm = 0.0138
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2352
	data_grads_norm = 5.4486
	new_data_grads_norm = 7.3935
	old_data_grads_norm = 7.7213
	sim_grads_norm = -0.0090
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4905
	data_grads_norm = 4.4232
	new_data_grads_norm = 7.1264
	old_data_grads_norm = 5.3592
	sim_grads_norm = 0.0281
-- Starting training on experience 218 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9289
	data_grads_norm = 4.5220
	new_data_grads_norm = 6.6924
	old_data_grads_norm = 5.8199
	sim_grads_norm = -0.0112
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9543
	data_grads_norm = 4.4479
	new_data_grads_norm = 6.5180
	old_data_grads_norm = 5.0734
	sim_grads_norm = -0.0072
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2008
	data_grads_norm = 4.8244
	new_data_grads_norm = 7.0888
	old_data_grads_norm = 4.8021
	sim_grads_norm = 0.0353
-- Starting training on experience 219 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3800
	data_grads_norm = 5.0428
	new_data_grads_norm = 7.4426
	old_data_grads_norm = 5.7239
	sim_grads_norm = 0.0076
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3165
	data_grads_norm = 5.1569
	new_data_grads_norm = 7.5537
	old_data_grads_norm = 6.0488
	sim_grads_norm = 0.0124
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3452
	data_grads_norm = 5.0865
	new_data_grads_norm = 7.9516
	old_data_grads_norm = 5.0823
	sim_grads_norm = -0.0030
-- Starting training on experience 220 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9622
	data_grads_norm = 4.1219
	new_data_grads_norm = 6.2714
	old_data_grads_norm = 5.6122
	sim_grads_norm = 0.0548
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5115
	data_grads_norm = 4.1358
	new_data_grads_norm = 6.7880
	old_data_grads_norm = 5.6908
	sim_grads_norm = -0.0124
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9536
	data_grads_norm = 5.3295
	new_data_grads_norm = 6.0605
	old_data_grads_norm = 7.5483
	sim_grads_norm = 0.0373
-- Starting training on experience 221 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7427
	data_grads_norm = 4.6982
	new_data_grads_norm = 5.6639
	old_data_grads_norm = 5.8756
	sim_grads_norm = -0.0142
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2669
	data_grads_norm = 4.7671
	new_data_grads_norm = 5.0704
	old_data_grads_norm = 8.0877
	sim_grads_norm = -0.0320
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5646
	data_grads_norm = 3.4319
	new_data_grads_norm = 5.9277
	old_data_grads_norm = 3.9030
	sim_grads_norm = -0.0087
-- Starting training on experience 222 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8442
	data_grads_norm = 4.6363
	new_data_grads_norm = 5.5320
	old_data_grads_norm = 6.3833
	sim_grads_norm = -0.0161
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6305
	data_grads_norm = 3.8439
	new_data_grads_norm = 5.7951
	old_data_grads_norm = 4.2183
	sim_grads_norm = -0.0322
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2168
	data_grads_norm = 5.1439
	new_data_grads_norm = 5.9674
	old_data_grads_norm = 6.6503
	sim_grads_norm = 0.0456
-- Starting training on experience 223 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2728
	data_grads_norm = 4.8393
	new_data_grads_norm = 7.1727
	old_data_grads_norm = 6.2047
	sim_grads_norm = -0.0098
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1577
	data_grads_norm = 4.4648
	new_data_grads_norm = 6.5697
	old_data_grads_norm = 5.5132
	sim_grads_norm = 0.0134
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2933
	data_grads_norm = 5.4230
	new_data_grads_norm = 6.4803
	old_data_grads_norm = 5.5663
	sim_grads_norm = 0.0006
-- Starting training on experience 224 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8400
	data_grads_norm = 3.9685
	new_data_grads_norm = 7.2368
	old_data_grads_norm = 3.4870
	sim_grads_norm = -0.0071
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7624
	data_grads_norm = 4.5539
	new_data_grads_norm = 7.3725
	old_data_grads_norm = 6.6185
	sim_grads_norm = 0.0101
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0549
	data_grads_norm = 4.3105
	new_data_grads_norm = 6.3343
	old_data_grads_norm = 4.8828
	sim_grads_norm = 0.0822
-- Starting training on experience 225 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1114
	data_grads_norm = 5.0089
	new_data_grads_norm = 7.9655
	old_data_grads_norm = 6.1262
	sim_grads_norm = -0.0098
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2946
	data_grads_norm = 5.3827
	new_data_grads_norm = 8.0708
	old_data_grads_norm = 5.3273
	sim_grads_norm = -0.0054
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0444
	data_grads_norm = 4.9637
	new_data_grads_norm = 7.8262
	old_data_grads_norm = 6.2035
	sim_grads_norm = -0.0267
-- Starting training on experience 226 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1882
	data_grads_norm = 4.7503
	new_data_grads_norm = 6.7419
	old_data_grads_norm = 5.2181
	sim_grads_norm = -0.0299
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1732
	data_grads_norm = 4.7908
	new_data_grads_norm = 6.8814
	old_data_grads_norm = 6.1849
	sim_grads_norm = 0.0472
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3267
	data_grads_norm = 4.5408
	new_data_grads_norm = 6.6833
	old_data_grads_norm = 5.4165
	sim_grads_norm = 0.0221
-- Starting training on experience 227 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7820
	data_grads_norm = 3.6692
	new_data_grads_norm = 6.2717
	old_data_grads_norm = 4.4435
	sim_grads_norm = -0.0698
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6063
	data_grads_norm = 6.1249
	new_data_grads_norm = 6.8420
	old_data_grads_norm = 8.0288
	sim_grads_norm = 0.0119
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2785
	data_grads_norm = 4.2730
	new_data_grads_norm = 6.3482
	old_data_grads_norm = 5.4373
	sim_grads_norm = 0.0434
-- Starting training on experience 228 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8654
	data_grads_norm = 4.1141
	new_data_grads_norm = 6.5026
	old_data_grads_norm = 4.8100
	sim_grads_norm = -0.0288
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8570
	data_grads_norm = 4.4769
	new_data_grads_norm = 7.1496
	old_data_grads_norm = 2.9363
	sim_grads_norm = 0.0006
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4635
	data_grads_norm = 5.0878
	new_data_grads_norm = 7.5271
	old_data_grads_norm = 6.1726
	sim_grads_norm = 0.0155
-- Starting training on experience 229 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9349
	data_grads_norm = 4.2703
	new_data_grads_norm = 6.2983
	old_data_grads_norm = 5.7238
	sim_grads_norm = 0.0227
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2680
	data_grads_norm = 4.2549
	new_data_grads_norm = 6.1874
	old_data_grads_norm = 4.9042
	sim_grads_norm = 0.0047
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2433
	data_grads_norm = 4.4656
	new_data_grads_norm = 5.7718
	old_data_grads_norm = 5.0143
	sim_grads_norm = 0.0711
-- Starting training on experience 230 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0527
	data_grads_norm = 4.9820
	new_data_grads_norm = 7.0971
	old_data_grads_norm = 5.7314
	sim_grads_norm = 0.0869
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9776
	data_grads_norm = 4.6734
	new_data_grads_norm = 6.6711
	old_data_grads_norm = 6.9574
	sim_grads_norm = -0.0277
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9292
	data_grads_norm = 4.3479
	new_data_grads_norm = 6.2119
	old_data_grads_norm = 6.1693
	sim_grads_norm = -0.0209
-- Starting training on experience 231 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2977
	data_grads_norm = 4.5329
	new_data_grads_norm = 7.4013
	old_data_grads_norm = 5.5522
	sim_grads_norm = 0.0289
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9224
	data_grads_norm = 4.6558
	new_data_grads_norm = 7.4727
	old_data_grads_norm = 4.8612
	sim_grads_norm = -0.0204
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0352
	data_grads_norm = 4.6033
	new_data_grads_norm = 7.0019
	old_data_grads_norm = 4.7301
	sim_grads_norm = -0.0229
-- Starting training on experience 232 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4194
	data_grads_norm = 4.9792
	new_data_grads_norm = 7.5759
	old_data_grads_norm = 4.4036
	sim_grads_norm = -0.0153
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8519
	data_grads_norm = 5.8954
	new_data_grads_norm = 7.1470
	old_data_grads_norm = 7.6363
	sim_grads_norm = 0.0032
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3493
	data_grads_norm = 4.4682
	new_data_grads_norm = 7.3554
	old_data_grads_norm = 4.6020
	sim_grads_norm = -0.0080
-- Starting training on experience 233 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1738
	data_grads_norm = 4.9629
	new_data_grads_norm = 7.9150
	old_data_grads_norm = 5.7299
	sim_grads_norm = -0.0374
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4742
	data_grads_norm = 4.9094
	new_data_grads_norm = 8.4299
	old_data_grads_norm = 5.0697
	sim_grads_norm = -0.0072
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2159
	data_grads_norm = 5.0005
	new_data_grads_norm = 7.8726
	old_data_grads_norm = 6.5714
	sim_grads_norm = -0.0027
-- Starting training on experience 234 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5999
	data_grads_norm = 4.4371
	new_data_grads_norm = 6.4452
	old_data_grads_norm = 5.5970
	sim_grads_norm = 0.0599
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6046
	data_grads_norm = 5.2920
	new_data_grads_norm = 7.0692
	old_data_grads_norm = 7.1889
	sim_grads_norm = -0.0148
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8936
	data_grads_norm = 4.0898
	new_data_grads_norm = 6.5266
	old_data_grads_norm = 6.7730
	sim_grads_norm = -0.0205
-- Starting training on experience 235 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8556
	data_grads_norm = 3.7134
	new_data_grads_norm = 6.4308
	old_data_grads_norm = 5.1018
	sim_grads_norm = -0.0192
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0366
	data_grads_norm = 4.2692
	new_data_grads_norm = 6.7572
	old_data_grads_norm = 3.9093
	sim_grads_norm = -0.0013
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1320
	data_grads_norm = 4.0737
	new_data_grads_norm = 6.5229
	old_data_grads_norm = 4.2912
	sim_grads_norm = 0.0033
-- Starting training on experience 236 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1322
	data_grads_norm = 4.3858
	new_data_grads_norm = 7.4818
	old_data_grads_norm = 3.5975
	sim_grads_norm = 0.0173
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0126
	data_grads_norm = 4.7276
	new_data_grads_norm = 6.7920
	old_data_grads_norm = 3.8743
	sim_grads_norm = 0.0001
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3731
	data_grads_norm = 4.7742
	new_data_grads_norm = 6.8939
	old_data_grads_norm = 6.1186
	sim_grads_norm = 0.0151
-- Starting training on experience 237 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
-- >> End of training phase << --
-- >> Start of eval phase << --
-- Starting eval on experience 0 (Task 0) from test stream --
> Eval on experience 0 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp000 = 4.0874
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.2120
	mb_index = 4046
	time = 1260.8599
-- Starting eval on experience 1 (Task 0) from test stream --
> Eval on experience 1 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp001 = 4.0347
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.3160
-- Starting eval on experience 2 (Task 0) from test stream --
> Eval on experience 2 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp002 = 4.1726
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.2880
-- Starting eval on experience 3 (Task 0) from test stream --
> Eval on experience 3 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp003 = 3.5255
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.3760
-- Starting eval on experience 4 (Task 0) from test stream --
> Eval on experience 4 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp004 = 5.3536
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.1280
-- Starting eval on experience 5 (Task 0) from test stream --
> Eval on experience 5 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp005 = 3.4744
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.3680
-- Starting eval on experience 6 (Task 0) from test stream --
> Eval on experience 6 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp006 = 4.2942
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp006 = 0.2480
-- Starting eval on experience 7 (Task 0) from test stream --
> Eval on experience 7 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp007 = 4.7125
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp007 = 0.2760
-- Starting eval on experience 8 (Task 0) from test stream --
> Eval on experience 8 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp008 = 3.5230
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp008 = 0.3740
-- Starting eval on experience 9 (Task 0) from test stream --
> Eval on experience 9 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp009 = 3.0033
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp009 = 0.3260
-- Starting eval on experience 10 (Task 0) from test stream --
> Eval on experience 10 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp010 = 4.2015
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp010 = 0.1600
-- Starting eval on experience 11 (Task 0) from test stream --
> Eval on experience 11 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp011 = 2.6900
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp011 = 0.4440
-- Starting eval on experience 12 (Task 0) from test stream --
> Eval on experience 12 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp012 = 4.0093
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp012 = 0.1780
-- Starting eval on experience 13 (Task 0) from test stream --
> Eval on experience 13 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp013 = 3.3836
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp013 = 0.2440
-- Starting eval on experience 14 (Task 0) from test stream --
> Eval on experience 14 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp014 = 3.4605
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp014 = 0.2360
-- Starting eval on experience 15 (Task 0) from test stream --
> Eval on experience 15 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp015 = 3.3625
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp015 = 0.2660
-- Starting eval on experience 16 (Task 0) from test stream --
> Eval on experience 16 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp016 = 3.9484
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp016 = 0.0840
-- >> End of eval phase << --
	CumulativeAccuracy/eval_phase/test_stream/Exp000 = 0.6780
	CumulativeAccuracy/eval_phase/test_stream/Exp001 = 0.6280
	CumulativeAccuracy/eval_phase/test_stream/Exp002 = 0.5420
	CumulativeAccuracy/eval_phase/test_stream/Exp003 = 0.5140
	CumulativeAccuracy/eval_phase/test_stream/Exp004 = 0.4704
	CumulativeAccuracy/eval_phase/test_stream/Exp005 = 0.4407
	CumulativeAccuracy/eval_phase/test_stream/Exp006 = 0.4049
	CumulativeAccuracy/eval_phase/test_stream/Exp007 = 0.3875
	CumulativeAccuracy/eval_phase/test_stream/Exp008 = 0.3727
	CumulativeAccuracy/eval_phase/test_stream/Exp009 = 0.3596
	CumulativeAccuracy/eval_phase/test_stream/Exp010 = 0.3409
	CumulativeAccuracy/eval_phase/test_stream/Exp011 = 0.3357
	CumulativeAccuracy/eval_phase/test_stream/Exp012 = 0.3140
	CumulativeAccuracy/eval_phase/test_stream/Exp013 = 0.3021
	CumulativeAccuracy/eval_phase/test_stream/Exp014 = 0.2889
	CumulativeAccuracy/eval_phase/test_stream/Exp015 = 0.2781
	CumulativeAccuracy/eval_phase/test_stream/Exp016 = 0.2661
	Loss_Stream/eval_phase/test_stream/Task000 = 3.8375
	Top1_Acc_Stream/eval_phase/test_stream/Task000 = 0.2661
-- >> Start of training phase << --
-- Starting training on experience 0 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.9196
	data_grads_norm = 5.2630
	new_data_grads_norm = 7.7631
	old_data_grads_norm = 5.1255
	sim_grads_norm = 0.0015
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.2000
	data_grads_norm = 5.2769
	new_data_grads_norm = 7.6739
	old_data_grads_norm = 6.4807
	sim_grads_norm = 0.0258
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5373
	data_grads_norm = 4.6615
	new_data_grads_norm = 6.4268
	old_data_grads_norm = 5.0675
	sim_grads_norm = -0.0064
-- Starting training on experience 1 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.1193
	data_grads_norm = 4.9257
	new_data_grads_norm = 8.0642
	old_data_grads_norm = 4.6509
	sim_grads_norm = -0.0034
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.3451
	data_grads_norm = 5.3528
	new_data_grads_norm = 7.1428
	old_data_grads_norm = 5.6265
	sim_grads_norm = 0.0120
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.1622
	data_grads_norm = 5.1543
	new_data_grads_norm = 6.5472
	old_data_grads_norm = 4.9944
	sim_grads_norm = 0.0121
-- Starting training on experience 2 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4201
	data_grads_norm = 4.1255
	new_data_grads_norm = 6.6566
	old_data_grads_norm = 5.1853
	sim_grads_norm = -0.0006
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.7479
	data_grads_norm = 4.3297
	new_data_grads_norm = 6.6120
	old_data_grads_norm = 4.9374
	sim_grads_norm = 0.0445
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5617
	data_grads_norm = 5.0011
	new_data_grads_norm = 6.8248
	old_data_grads_norm = 7.0833
	sim_grads_norm = -0.0023
-- Starting training on experience 3 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.7504
	data_grads_norm = 5.3536
	new_data_grads_norm = 7.1874
	old_data_grads_norm = 6.7891
	sim_grads_norm = 0.0026
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.7489
	data_grads_norm = 4.9228
	new_data_grads_norm = 6.8715
	old_data_grads_norm = 5.9267
	sim_grads_norm = 0.0297
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3937
	data_grads_norm = 5.1582
	new_data_grads_norm = 6.9717
	old_data_grads_norm = 6.0982
	sim_grads_norm = 0.0085
-- Starting training on experience 4 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.3015
	data_grads_norm = 5.2135
	new_data_grads_norm = 8.5047
	old_data_grads_norm = 5.9998
	sim_grads_norm = -0.0130
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.2997
	data_grads_norm = 5.2757
	new_data_grads_norm = 8.0027
	old_data_grads_norm = 5.7402
	sim_grads_norm = 0.0181
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.1770
	data_grads_norm = 4.8127
	new_data_grads_norm = 8.1628
	old_data_grads_norm = 5.6845
	sim_grads_norm = 0.0539
-- Starting training on experience 5 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.7793
	data_grads_norm = 5.3868
	new_data_grads_norm = 6.0933
	old_data_grads_norm = 8.2805
	sim_grads_norm = 0.0070
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.2282
	data_grads_norm = 4.6761
	new_data_grads_norm = 6.8215
	old_data_grads_norm = 4.7253
	sim_grads_norm = 0.0780
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4166
	data_grads_norm = 3.7603
	new_data_grads_norm = 5.8304
	old_data_grads_norm = 4.9775
	sim_grads_norm = 0.0027
-- Starting training on experience 6 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.7346
	data_grads_norm = 5.5351
	new_data_grads_norm = 7.1076
	old_data_grads_norm = 6.8880
	sim_grads_norm = 0.0172
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5809
	data_grads_norm = 4.5987
	new_data_grads_norm = 7.0682
	old_data_grads_norm = 4.7328
	sim_grads_norm = 0.0178
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.9300
	data_grads_norm = 4.9257
	new_data_grads_norm = 6.9246
	old_data_grads_norm = 5.6043
	sim_grads_norm = 0.0751
-- Starting training on experience 7 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1960
	data_grads_norm = 4.9294
	new_data_grads_norm = 7.0918
	old_data_grads_norm = 4.1998
	sim_grads_norm = 0.0174
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1851
	data_grads_norm = 4.1257
	new_data_grads_norm = 6.6763
	old_data_grads_norm = 3.7850
	sim_grads_norm = 0.0073
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6114
	data_grads_norm = 5.0878
	new_data_grads_norm = 6.8861
	old_data_grads_norm = 6.5578
	sim_grads_norm = 0.0347
-- Starting training on experience 8 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9162
	data_grads_norm = 4.4294
	new_data_grads_norm = 7.5057
	old_data_grads_norm = 5.6281
	sim_grads_norm = 0.0011
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4328
	data_grads_norm = 5.1222
	new_data_grads_norm = 8.0453
	old_data_grads_norm = 5.0999
	sim_grads_norm = 0.0113
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3683
	data_grads_norm = 5.3477
	new_data_grads_norm = 7.8056
	old_data_grads_norm = 6.5508
	sim_grads_norm = -0.0042
-- Starting training on experience 9 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6832
	data_grads_norm = 4.5472
	new_data_grads_norm = 6.0812
	old_data_grads_norm = 5.6517
	sim_grads_norm = 0.0068
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9903
	data_grads_norm = 3.9229
	new_data_grads_norm = 6.3345
	old_data_grads_norm = 4.5952
	sim_grads_norm = -0.0025
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.8610
	data_grads_norm = 5.1037
	new_data_grads_norm = 6.5178
	old_data_grads_norm = 6.3138
	sim_grads_norm = 0.0276
-- Starting training on experience 10 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.1720
	data_grads_norm = 5.2398
	new_data_grads_norm = 8.2750
	old_data_grads_norm = 4.9708
	sim_grads_norm = 0.0090
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.0492
	data_grads_norm = 5.7714
	new_data_grads_norm = 7.5226
	old_data_grads_norm = 6.3017
	sim_grads_norm = 0.0162
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.2733
	data_grads_norm = 5.8084
	new_data_grads_norm = 7.8486
	old_data_grads_norm = 6.5397
	sim_grads_norm = 0.0277
-- Starting training on experience 11 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3994
	data_grads_norm = 4.7529
	new_data_grads_norm = 8.4467
	old_data_grads_norm = 4.0813
	sim_grads_norm = 0.0023
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5420
	data_grads_norm = 4.9198
	new_data_grads_norm = 8.3194
	old_data_grads_norm = 5.3757
	sim_grads_norm = -0.0094
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6695
	data_grads_norm = 5.1126
	new_data_grads_norm = 8.5296
	old_data_grads_norm = 5.6912
	sim_grads_norm = -0.0189
-- Starting training on experience 12 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0210
	data_grads_norm = 4.5596
	new_data_grads_norm = 6.6677
	old_data_grads_norm = 6.5101
	sim_grads_norm = 0.0015
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3074
	data_grads_norm = 4.5473
	new_data_grads_norm = 6.7943
	old_data_grads_norm = 4.7866
	sim_grads_norm = 0.0349
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.8470
	data_grads_norm = 4.9856
	new_data_grads_norm = 6.1770
	old_data_grads_norm = 6.8598
	sim_grads_norm = 0.0766
-- Starting training on experience 13 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2921
	data_grads_norm = 4.8863
	new_data_grads_norm = 6.9168
	old_data_grads_norm = 6.3939
	sim_grads_norm = -0.0162
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3839
	data_grads_norm = 4.3433
	new_data_grads_norm = 7.1844
	old_data_grads_norm = 4.9787
	sim_grads_norm = 0.0405
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5364
	data_grads_norm = 4.7043
	new_data_grads_norm = 7.2265
	old_data_grads_norm = 5.5287
	sim_grads_norm = 0.0627
-- Starting training on experience 14 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8936
	data_grads_norm = 4.3293
	new_data_grads_norm = 6.5117
	old_data_grads_norm = 3.2536
	sim_grads_norm = 0.0599
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8079
	data_grads_norm = 4.2318
	new_data_grads_norm = 6.0687
	old_data_grads_norm = 4.6662
	sim_grads_norm = 0.0092
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7303
	data_grads_norm = 4.0509
	new_data_grads_norm = 5.8329
	old_data_grads_norm = 4.5487
	sim_grads_norm = 0.0023
-- Starting training on experience 15 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8138
	data_grads_norm = 3.8257
	new_data_grads_norm = 6.3357
	old_data_grads_norm = 4.2779
	sim_grads_norm = 0.0054
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9329
	data_grads_norm = 4.0115
	new_data_grads_norm = 6.6939
	old_data_grads_norm = 5.1795
	sim_grads_norm = -0.0335
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2167
	data_grads_norm = 5.3626
	new_data_grads_norm = 6.5499
	old_data_grads_norm = 6.2649
	sim_grads_norm = 0.0122
-- Starting training on experience 16 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4952
	data_grads_norm = 4.2603
	new_data_grads_norm = 7.4581
	old_data_grads_norm = 4.9054
	sim_grads_norm = -0.0039
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7039
	data_grads_norm = 4.3631
	new_data_grads_norm = 6.6660
	old_data_grads_norm = 5.5973
	sim_grads_norm = 0.0462
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1933
	data_grads_norm = 3.8581
	new_data_grads_norm = 6.5776
	old_data_grads_norm = 6.2432
	sim_grads_norm = -0.0047
-- Starting training on experience 17 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8299
	data_grads_norm = 4.9087
	new_data_grads_norm = 8.6340
	old_data_grads_norm = 3.3710
	sim_grads_norm = 0.0854
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0345
	data_grads_norm = 6.1465
	new_data_grads_norm = 9.0962
	old_data_grads_norm = 7.7807
	sim_grads_norm = 0.0469
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2802
	data_grads_norm = 5.6649
	new_data_grads_norm = 8.5024
	old_data_grads_norm = 6.6411
	sim_grads_norm = 0.0206
-- Starting training on experience 18 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6841
	data_grads_norm = 5.6494
	new_data_grads_norm = 7.3203
	old_data_grads_norm = 6.4113
	sim_grads_norm = 0.0196
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9999
	data_grads_norm = 4.7053
	new_data_grads_norm = 6.7874
	old_data_grads_norm = 5.6539
	sim_grads_norm = 0.0706
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3454
	data_grads_norm = 4.7186
	new_data_grads_norm = 6.8359
	old_data_grads_norm = 5.6355
	sim_grads_norm = 0.0296
-- Starting training on experience 19 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1450
	data_grads_norm = 5.1259
	new_data_grads_norm = 7.5859
	old_data_grads_norm = 6.7233
	sim_grads_norm = -0.0059
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7845
	data_grads_norm = 4.1882
	new_data_grads_norm = 7.5323
	old_data_grads_norm = 5.2477
	sim_grads_norm = 0.0244
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9463
	data_grads_norm = 4.2884
	new_data_grads_norm = 7.4212
	old_data_grads_norm = 3.7249
	sim_grads_norm = 0.0421
-- Starting training on experience 20 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5893
	data_grads_norm = 4.3770
	new_data_grads_norm = 6.4314
	old_data_grads_norm = 5.6792
	sim_grads_norm = 0.0128
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5580
	data_grads_norm = 4.2441
	new_data_grads_norm = 6.5090
	old_data_grads_norm = 4.7556
	sim_grads_norm = -0.0120
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6315
	data_grads_norm = 4.4399
	new_data_grads_norm = 6.6439
	old_data_grads_norm = 5.3839
	sim_grads_norm = 0.0147
-- Starting training on experience 21 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9974
	data_grads_norm = 3.7662
	new_data_grads_norm = 6.1702
	old_data_grads_norm = 4.3566
	sim_grads_norm = -0.0185
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6578
	data_grads_norm = 4.8433
	new_data_grads_norm = 6.4491
	old_data_grads_norm = 6.3747
	sim_grads_norm = 0.0269
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2336
	data_grads_norm = 4.2076
	new_data_grads_norm = 6.7600
	old_data_grads_norm = 3.5434
	sim_grads_norm = -0.0147
-- Starting training on experience 22 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1284
	data_grads_norm = 4.7144
	new_data_grads_norm = 7.3191
	old_data_grads_norm = 5.5525
	sim_grads_norm = 0.0071
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1257
	data_grads_norm = 4.2114
	new_data_grads_norm = 6.7090
	old_data_grads_norm = 3.9074
	sim_grads_norm = -0.0313
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1467
	data_grads_norm = 4.0539
	new_data_grads_norm = 6.7420
	old_data_grads_norm = 4.9902
	sim_grads_norm = 0.0083
-- Starting training on experience 23 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8819
	data_grads_norm = 5.4048
	new_data_grads_norm = 7.4956
	old_data_grads_norm = 6.4524
	sim_grads_norm = -0.0035
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4385
	data_grads_norm = 4.6169
	new_data_grads_norm = 7.5245
	old_data_grads_norm = 4.7124
	sim_grads_norm = 0.0405
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0469
	data_grads_norm = 4.4307
	new_data_grads_norm = 6.9104
	old_data_grads_norm = 5.1685
	sim_grads_norm = 0.0588
-- Starting training on experience 24 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1716
	data_grads_norm = 3.9281
	new_data_grads_norm = 5.3468
	old_data_grads_norm = 5.4139
	sim_grads_norm = 0.0098
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1938
	data_grads_norm = 4.2712
	new_data_grads_norm = 5.3378
	old_data_grads_norm = 6.5451
	sim_grads_norm = 0.0592
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8102
	data_grads_norm = 3.1954
	new_data_grads_norm = 6.4188
	old_data_grads_norm = 3.7281
	sim_grads_norm = -0.0209
-- Starting training on experience 25 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3457
	data_grads_norm = 4.6861
	new_data_grads_norm = 6.7900
	old_data_grads_norm = 6.1334
	sim_grads_norm = 0.0054
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1219
	data_grads_norm = 4.4719
	new_data_grads_norm = 7.2148
	old_data_grads_norm = 5.1029
	sim_grads_norm = -0.0088
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8675
	data_grads_norm = 3.5611
	new_data_grads_norm = 6.2407
	old_data_grads_norm = 3.8767
	sim_grads_norm = 0.0771
-- Starting training on experience 26 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5438
	data_grads_norm = 3.7880
	new_data_grads_norm = 6.5659
	old_data_grads_norm = 3.5737
	sim_grads_norm = 0.0160
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9225
	data_grads_norm = 4.8931
	new_data_grads_norm = 7.4715
	old_data_grads_norm = 4.7528
	sim_grads_norm = 0.1070
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3070
	data_grads_norm = 4.1114
	new_data_grads_norm = 6.5133
	old_data_grads_norm = 3.9835
	sim_grads_norm = -0.0036
-- Starting training on experience 27 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5903
	data_grads_norm = 3.7067
	new_data_grads_norm = 6.2307
	old_data_grads_norm = 3.6313
	sim_grads_norm = -0.0087
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2981
	data_grads_norm = 4.6108
	new_data_grads_norm = 6.1334
	old_data_grads_norm = 6.9186
	sim_grads_norm = -0.0403
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3232
	data_grads_norm = 4.1869
	new_data_grads_norm = 6.2927
	old_data_grads_norm = 4.6196
	sim_grads_norm = 0.0824
-- Starting training on experience 28 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0319
	data_grads_norm = 4.1421
	new_data_grads_norm = 6.7931
	old_data_grads_norm = 3.8430
	sim_grads_norm = 0.0212
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5269
	data_grads_norm = 4.5410
	new_data_grads_norm = 5.8288
	old_data_grads_norm = 5.9340
	sim_grads_norm = -0.0065
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6470
	data_grads_norm = 4.8011
	new_data_grads_norm = 5.9443
	old_data_grads_norm = 6.1391
	sim_grads_norm = 0.0468
-- Starting training on experience 29 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0530
	data_grads_norm = 4.3143
	new_data_grads_norm = 5.6734
	old_data_grads_norm = 6.4032
	sim_grads_norm = 0.0702
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9218
	data_grads_norm = 4.7922
	new_data_grads_norm = 5.9376
	old_data_grads_norm = 6.4600
	sim_grads_norm = 0.0653
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6296
	data_grads_norm = 3.7360
	new_data_grads_norm = 6.0629
	old_data_grads_norm = 4.5859
	sim_grads_norm = -0.0247
-- Starting training on experience 30 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9315
	data_grads_norm = 3.8564
	new_data_grads_norm = 5.6737
	old_data_grads_norm = 4.1470
	sim_grads_norm = 0.0802
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8382
	data_grads_norm = 3.8309
	new_data_grads_norm = 5.9245
	old_data_grads_norm = 4.0520
	sim_grads_norm = 0.0498
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4553
	data_grads_norm = 3.0977
	new_data_grads_norm = 5.3034
	old_data_grads_norm = 3.0151
	sim_grads_norm = 0.0294
-- Starting training on experience 31 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8906
	data_grads_norm = 4.3791
	new_data_grads_norm = 5.9376
	old_data_grads_norm = 6.2220
	sim_grads_norm = -0.0077
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8152
	data_grads_norm = 4.2771
	new_data_grads_norm = 5.6728
	old_data_grads_norm = 4.9693
	sim_grads_norm = 0.0033
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8876
	data_grads_norm = 4.2680
	new_data_grads_norm = 6.0352
	old_data_grads_norm = 5.3799
	sim_grads_norm = -0.0119
-- Starting training on experience 32 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5610
	data_grads_norm = 3.9665
	new_data_grads_norm = 6.1285
	old_data_grads_norm = 5.5038
	sim_grads_norm = -0.0056
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5560
	data_grads_norm = 3.9101
	new_data_grads_norm = 6.9000
	old_data_grads_norm = 5.2271
	sim_grads_norm = -0.0084
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2171
	data_grads_norm = 4.8703
	new_data_grads_norm = 6.2171
	old_data_grads_norm = 6.1035
	sim_grads_norm = -0.0426
-- Starting training on experience 33 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2418
	data_grads_norm = 4.8914
	new_data_grads_norm = 5.8259
	old_data_grads_norm = 6.9820
	sim_grads_norm = 0.0460
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0423
	data_grads_norm = 4.1724
	new_data_grads_norm = 6.5523
	old_data_grads_norm = 5.3713
	sim_grads_norm = -0.0315
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8594
	data_grads_norm = 4.2763
	new_data_grads_norm = 6.7582
	old_data_grads_norm = 4.4026
	sim_grads_norm = 0.0052
-- Starting training on experience 34 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0090
	data_grads_norm = 4.2019
	new_data_grads_norm = 6.8202
	old_data_grads_norm = 3.3709
	sim_grads_norm = 0.0685
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8895
	data_grads_norm = 4.1282
	new_data_grads_norm = 6.5120
	old_data_grads_norm = 4.8668
	sim_grads_norm = -0.0456
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0116
	data_grads_norm = 4.4550
	new_data_grads_norm = 6.0912
	old_data_grads_norm = 5.7149
	sim_grads_norm = -0.0042
-- Starting training on experience 35 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9550
	data_grads_norm = 4.2448
	new_data_grads_norm = 6.5950
	old_data_grads_norm = 5.6363
	sim_grads_norm = 0.0226
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8918
	data_grads_norm = 4.4827
	new_data_grads_norm = 7.1557
	old_data_grads_norm = 4.6385
	sim_grads_norm = -0.0375
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7670
	data_grads_norm = 4.2710
	new_data_grads_norm = 7.9619
	old_data_grads_norm = 4.8024
	sim_grads_norm = 0.0049
-- Starting training on experience 36 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4250
	data_grads_norm = 4.1631
	new_data_grads_norm = 7.2350
	old_data_grads_norm = 2.7900
	sim_grads_norm = -0.0208
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6119
	data_grads_norm = 4.3338
	new_data_grads_norm = 5.9566
	old_data_grads_norm = 5.0988
	sim_grads_norm = -0.0255
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2083
	data_grads_norm = 3.4048
	new_data_grads_norm = 6.3883
	old_data_grads_norm = 3.0825
	sim_grads_norm = 0.0381
-- Starting training on experience 37 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0442
	data_grads_norm = 4.4014
	new_data_grads_norm = 5.4967
	old_data_grads_norm = 5.9562
	sim_grads_norm = 0.0419
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4118
	data_grads_norm = 3.7563
	new_data_grads_norm = 4.9640
	old_data_grads_norm = 5.6635
	sim_grads_norm = -0.0259
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4738
	data_grads_norm = 3.7239
	new_data_grads_norm = 5.4722
	old_data_grads_norm = 4.5342
	sim_grads_norm = -0.0088
-- Starting training on experience 38 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4643
	data_grads_norm = 4.8436
	new_data_grads_norm = 7.3103
	old_data_grads_norm = 5.0967
	sim_grads_norm = 0.0447
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0664
	data_grads_norm = 4.2559
	new_data_grads_norm = 6.7648
	old_data_grads_norm = 4.9848
	sim_grads_norm = 0.0082
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9365
	data_grads_norm = 4.5264
	new_data_grads_norm = 7.5741
	old_data_grads_norm = 4.4183
	sim_grads_norm = -0.0249
-- Starting training on experience 39 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4304
	data_grads_norm = 3.6584
	new_data_grads_norm = 5.5980
	old_data_grads_norm = 4.7974
	sim_grads_norm = -0.0221
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3836
	data_grads_norm = 4.1217
	new_data_grads_norm = 6.4995
	old_data_grads_norm = 5.9840
	sim_grads_norm = 0.0037
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8783
	data_grads_norm = 4.4738
	new_data_grads_norm = 5.6683
	old_data_grads_norm = 6.3025
	sim_grads_norm = -0.0135
-- Starting training on experience 40 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0275
	data_grads_norm = 4.8594
	new_data_grads_norm = 5.6844
	old_data_grads_norm = 6.5739
	sim_grads_norm = -0.0339
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7078
	data_grads_norm = 4.3259
	new_data_grads_norm = 5.7896
	old_data_grads_norm = 6.0960
	sim_grads_norm = -0.0070
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0263
	data_grads_norm = 4.6140
	new_data_grads_norm = 6.3398
	old_data_grads_norm = 5.7435
	sim_grads_norm = 0.0746
-- Starting training on experience 41 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6879
	data_grads_norm = 4.0233
	new_data_grads_norm = 5.5688
	old_data_grads_norm = 6.2364
	sim_grads_norm = 0.0274
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5686
	data_grads_norm = 4.7787
	new_data_grads_norm = 6.5884
	old_data_grads_norm = 5.8025
	sim_grads_norm = -0.0095
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6055
	data_grads_norm = 3.9771
	new_data_grads_norm = 5.9727
	old_data_grads_norm = 3.7900
	sim_grads_norm = 0.0951
-- Starting training on experience 42 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5270
	data_grads_norm = 3.6921
	new_data_grads_norm = 5.4088
	old_data_grads_norm = 4.4241
	sim_grads_norm = 0.0034
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7201
	data_grads_norm = 4.2181
	new_data_grads_norm = 6.1473
	old_data_grads_norm = 5.5121
	sim_grads_norm = 0.0829
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4313
	data_grads_norm = 3.9619
	new_data_grads_norm = 5.2596
	old_data_grads_norm = 5.2660
	sim_grads_norm = -0.0098
-- Starting training on experience 43 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9174
	data_grads_norm = 4.8020
	new_data_grads_norm = 6.7136
	old_data_grads_norm = 6.5387
	sim_grads_norm = -0.0146
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6342
	data_grads_norm = 3.8481
	new_data_grads_norm = 7.1476
	old_data_grads_norm = 3.2748
	sim_grads_norm = 0.0116
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9749
	data_grads_norm = 3.0599
	new_data_grads_norm = 5.4784
	old_data_grads_norm = 4.8558
	sim_grads_norm = -0.0236
-- Starting training on experience 44 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7641
	data_grads_norm = 4.7732
	new_data_grads_norm = 7.7387
	old_data_grads_norm = 5.6808
	sim_grads_norm = 0.0144
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8832
	data_grads_norm = 4.5811
	new_data_grads_norm = 7.4169
	old_data_grads_norm = 5.5265
	sim_grads_norm = -0.0119
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2139
	data_grads_norm = 5.3425
	new_data_grads_norm = 7.9184
	old_data_grads_norm = 6.7060
	sim_grads_norm = 0.0168
-- Starting training on experience 45 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0635
	data_grads_norm = 4.3399
	new_data_grads_norm = 6.8120
	old_data_grads_norm = 4.1627
	sim_grads_norm = 0.0608
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7750
	data_grads_norm = 4.6520
	new_data_grads_norm = 7.3353
	old_data_grads_norm = 4.7569
	sim_grads_norm = 0.0065
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5167
	data_grads_norm = 5.9049
	new_data_grads_norm = 8.1397
	old_data_grads_norm = 5.7897
	sim_grads_norm = -0.0020
-- Starting training on experience 46 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4264
	data_grads_norm = 3.9121
	new_data_grads_norm = 6.6662
	old_data_grads_norm = 4.3853
	sim_grads_norm = -0.0217
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0162
	data_grads_norm = 4.7095
	new_data_grads_norm = 7.1585
	old_data_grads_norm = 5.6227
	sim_grads_norm = -0.0330
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7996
	data_grads_norm = 4.6221
	new_data_grads_norm = 7.5028
	old_data_grads_norm = 4.7936
	sim_grads_norm = 0.0082
-- Starting training on experience 47 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6815
	data_grads_norm = 4.2599
	new_data_grads_norm = 6.2743
	old_data_grads_norm = 5.3702
	sim_grads_norm = -0.0317
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9338
	data_grads_norm = 4.5058
	new_data_grads_norm = 7.0202
	old_data_grads_norm = 5.9345
	sim_grads_norm = -0.0264
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4878
	data_grads_norm = 3.5238
	new_data_grads_norm = 6.5781
	old_data_grads_norm = 5.0639
	sim_grads_norm = 0.0022
-- Starting training on experience 48 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0004
	data_grads_norm = 4.5278
	new_data_grads_norm = 6.6043
	old_data_grads_norm = 5.2135
	sim_grads_norm = 0.0126
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8357
	data_grads_norm = 4.1998
	new_data_grads_norm = 6.6443
	old_data_grads_norm = 6.2373
	sim_grads_norm = 0.0234
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0514
	data_grads_norm = 4.2250
	new_data_grads_norm = 7.0867
	old_data_grads_norm = 4.9156
	sim_grads_norm = 0.0164
-- Starting training on experience 49 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8573
	data_grads_norm = 5.2254
	new_data_grads_norm = 6.9886
	old_data_grads_norm = 6.1869
	sim_grads_norm = 0.0445
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7256
	data_grads_norm = 4.6566
	new_data_grads_norm = 7.0714
	old_data_grads_norm = 5.0356
	sim_grads_norm = -0.0277
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5108
	data_grads_norm = 4.0438
	new_data_grads_norm = 6.6135
	old_data_grads_norm = 4.4446
	sim_grads_norm = 0.0415
-- Starting training on experience 50 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5302
	data_grads_norm = 4.1731
	new_data_grads_norm = 6.9707
	old_data_grads_norm = 6.2926
	sim_grads_norm = 0.0251
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2051
	data_grads_norm = 3.4830
	new_data_grads_norm = 6.0670
	old_data_grads_norm = 6.2875
	sim_grads_norm = -0.0057
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9317
	data_grads_norm = 4.1453
	new_data_grads_norm = 7.6474
	old_data_grads_norm = 4.2456
	sim_grads_norm = 0.0196
-- Starting training on experience 51 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3625
	data_grads_norm = 5.7020
	new_data_grads_norm = 8.3732
	old_data_grads_norm = 8.2233
	sim_grads_norm = 0.0455
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6818
	data_grads_norm = 4.8151
	new_data_grads_norm = 7.8334
	old_data_grads_norm = 5.0331
	sim_grads_norm = 0.0106
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4597
	data_grads_norm = 5.4817
	new_data_grads_norm = 8.1346
	old_data_grads_norm = 5.5026
	sim_grads_norm = 0.0250
-- Starting training on experience 52 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7314
	data_grads_norm = 4.5673
	new_data_grads_norm = 6.5845
	old_data_grads_norm = 6.2141
	sim_grads_norm = -0.0170
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7720
	data_grads_norm = 4.8100
	new_data_grads_norm = 6.7882
	old_data_grads_norm = 6.1422
	sim_grads_norm = -0.0282
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5988
	data_grads_norm = 4.5368
	new_data_grads_norm = 6.9268
	old_data_grads_norm = 5.6674
	sim_grads_norm = 0.0055
-- Starting training on experience 53 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8957
	data_grads_norm = 5.4779
	new_data_grads_norm = 7.9471
	old_data_grads_norm = 7.0054
	sim_grads_norm = 0.0149
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4161
	data_grads_norm = 4.4637
	new_data_grads_norm = 7.1965
	old_data_grads_norm = 2.1481
	sim_grads_norm = -0.0267
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5143
	data_grads_norm = 5.3410
	new_data_grads_norm = 7.6379
	old_data_grads_norm = 6.0912
	sim_grads_norm = 0.0218
-- Starting training on experience 54 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2634
	data_grads_norm = 4.3678
	new_data_grads_norm = 6.3645
	old_data_grads_norm = 5.2751
	sim_grads_norm = 0.0098
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7429
	data_grads_norm = 4.1170
	new_data_grads_norm = 7.0871
	old_data_grads_norm = 4.2561
	sim_grads_norm = -0.0412
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9216
	data_grads_norm = 4.0971
	new_data_grads_norm = 7.2299
	old_data_grads_norm = 3.7024
	sim_grads_norm = -0.0084
-- Starting training on experience 55 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4880
	data_grads_norm = 3.7667
	new_data_grads_norm = 6.5480
	old_data_grads_norm = 4.6541
	sim_grads_norm = -0.0358
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9499
	data_grads_norm = 4.5883
	new_data_grads_norm = 7.1762
	old_data_grads_norm = 4.7117
	sim_grads_norm = 0.0437
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8583
	data_grads_norm = 4.4428
	new_data_grads_norm = 6.3991
	old_data_grads_norm = 4.9451
	sim_grads_norm = 0.0146
-- Starting training on experience 56 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2184
	data_grads_norm = 5.6880
	new_data_grads_norm = 7.7586
	old_data_grads_norm = 6.9880
	sim_grads_norm = 0.0456
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5092
	data_grads_norm = 4.8077
	new_data_grads_norm = 7.0407
	old_data_grads_norm = 5.7111
	sim_grads_norm = -0.0122
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3444
	data_grads_norm = 4.1064
	new_data_grads_norm = 6.3931
	old_data_grads_norm = 5.1537
	sim_grads_norm = -0.0385
-- Starting training on experience 57 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7163
	data_grads_norm = 4.3666
	new_data_grads_norm = 7.2904
	old_data_grads_norm = 6.6801
	sim_grads_norm = 0.0108
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3211
	data_grads_norm = 4.1192
	new_data_grads_norm = 5.9530
	old_data_grads_norm = 5.3009
	sim_grads_norm = -0.0235
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9607
	data_grads_norm = 5.3624
	new_data_grads_norm = 6.7607
	old_data_grads_norm = 7.1480
	sim_grads_norm = 0.0180
-- Starting training on experience 58 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9956
	data_grads_norm = 4.3535
	new_data_grads_norm = 6.1551
	old_data_grads_norm = 5.0221
	sim_grads_norm = 0.0152
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0569
	data_grads_norm = 4.9004
	new_data_grads_norm = 6.7648
	old_data_grads_norm = 5.5466
	sim_grads_norm = 0.0473
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9110
	data_grads_norm = 4.5967
	new_data_grads_norm = 6.5002
	old_data_grads_norm = 7.3319
	sim_grads_norm = -0.0430
-- Starting training on experience 59 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3147
	data_grads_norm = 4.6025
	new_data_grads_norm = 5.7779
	old_data_grads_norm = 5.6313
	sim_grads_norm = -0.0252
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3576
	data_grads_norm = 4.0999
	new_data_grads_norm = 6.5373
	old_data_grads_norm = 4.1489
	sim_grads_norm = 0.0164
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1822
	data_grads_norm = 4.3939
	new_data_grads_norm = 5.9524
	old_data_grads_norm = 6.1509
	sim_grads_norm = -0.0019
-- Starting training on experience 60 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8320
	data_grads_norm = 3.1719
	new_data_grads_norm = 6.5458
	old_data_grads_norm = 3.1913
	sim_grads_norm = 0.0110
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5526
	data_grads_norm = 4.3019
	new_data_grads_norm = 6.7069
	old_data_grads_norm = 5.2515
	sim_grads_norm = -0.0224
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6171
	data_grads_norm = 4.8040
	new_data_grads_norm = 6.7724
	old_data_grads_norm = 5.6307
	sim_grads_norm = 0.0626
-- Starting training on experience 61 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6558
	data_grads_norm = 4.8749
	new_data_grads_norm = 6.8086
	old_data_grads_norm = 6.0689
	sim_grads_norm = 0.0259
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5425
	data_grads_norm = 4.3081
	new_data_grads_norm = 7.5172
	old_data_grads_norm = 5.9981
	sim_grads_norm = 0.0322
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5241
	data_grads_norm = 4.0291
	new_data_grads_norm = 7.1217
	old_data_grads_norm = 4.7838
	sim_grads_norm = 0.0334
-- Starting training on experience 62 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0633
	data_grads_norm = 5.1865
	new_data_grads_norm = 7.8388
	old_data_grads_norm = 4.9071
	sim_grads_norm = 0.1205
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5466
	data_grads_norm = 4.7966
	new_data_grads_norm = 7.8876
	old_data_grads_norm = 4.7092
	sim_grads_norm = 0.0465
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1362
	data_grads_norm = 4.6804
	new_data_grads_norm = 6.7184
	old_data_grads_norm = 6.1609
	sim_grads_norm = 0.0093
-- Starting training on experience 63 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3433
	data_grads_norm = 4.1668
	new_data_grads_norm = 5.8955
	old_data_grads_norm = 5.3941
	sim_grads_norm = -0.0408
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6952
	data_grads_norm = 5.0865
	new_data_grads_norm = 7.9608
	old_data_grads_norm = 4.9653
	sim_grads_norm = 0.0156
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2348
	data_grads_norm = 3.6643
	new_data_grads_norm = 7.0707
	old_data_grads_norm = 2.7229
	sim_grads_norm = -0.0191
-- Starting training on experience 64 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5052
	data_grads_norm = 4.4817
	new_data_grads_norm = 6.4986
	old_data_grads_norm = 4.5474
	sim_grads_norm = -0.0007
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6159
	data_grads_norm = 4.5258
	new_data_grads_norm = 7.0093
	old_data_grads_norm = 4.4478
	sim_grads_norm = 0.0403
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2019
	data_grads_norm = 3.9629
	new_data_grads_norm = 6.0656
	old_data_grads_norm = 3.6259
	sim_grads_norm = -0.0059
-- Starting training on experience 65 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2475
	data_grads_norm = 4.5516
	new_data_grads_norm = 5.7096
	old_data_grads_norm = 5.0660
	sim_grads_norm = -0.0365
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0271
	data_grads_norm = 3.6159
	new_data_grads_norm = 5.5388
	old_data_grads_norm = 5.0182
	sim_grads_norm = -0.0165
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2746
	data_grads_norm = 4.5914
	new_data_grads_norm = 5.8527
	old_data_grads_norm = 6.7381
	sim_grads_norm = 0.0112
-- Starting training on experience 66 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2332
	data_grads_norm = 3.6386
	new_data_grads_norm = 5.5471
	old_data_grads_norm = 4.3670
	sim_grads_norm = -0.0257
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6136
	data_grads_norm = 3.9896
	new_data_grads_norm = 5.9014
	old_data_grads_norm = 6.1162
	sim_grads_norm = -0.0062
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4777
	data_grads_norm = 3.9597
	new_data_grads_norm = 5.8220
	old_data_grads_norm = 5.8057
	sim_grads_norm = -0.0071
-- Starting training on experience 67 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7299
	data_grads_norm = 5.0615
	new_data_grads_norm = 6.6100
	old_data_grads_norm = 7.0055
	sim_grads_norm = -0.0254
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0329
	data_grads_norm = 5.1314
	new_data_grads_norm = 6.1984
	old_data_grads_norm = 6.3194
	sim_grads_norm = 0.0430
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5274
	data_grads_norm = 4.3615
	new_data_grads_norm = 7.0482
	old_data_grads_norm = 6.1371
	sim_grads_norm = 0.0188
-- Starting training on experience 68 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7035
	data_grads_norm = 4.1601
	new_data_grads_norm = 6.2330
	old_data_grads_norm = 5.0597
	sim_grads_norm = 0.0134
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3428
	data_grads_norm = 4.0896
	new_data_grads_norm = 6.8296
	old_data_grads_norm = 3.4062
	sim_grads_norm = -0.0065
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3401
	data_grads_norm = 5.4287
	new_data_grads_norm = 7.2072
	old_data_grads_norm = 7.0649
	sim_grads_norm = 0.0146
-- Starting training on experience 69 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2219
	data_grads_norm = 3.6968
	new_data_grads_norm = 6.6841
	old_data_grads_norm = 5.5265
	sim_grads_norm = 0.0167
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5624
	data_grads_norm = 4.2484
	new_data_grads_norm = 6.6617
	old_data_grads_norm = 3.6774
	sim_grads_norm = -0.0405
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3790
	data_grads_norm = 4.3716
	new_data_grads_norm = 6.5406
	old_data_grads_norm = 6.1975
	sim_grads_norm = -0.0262
-- Starting training on experience 70 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5032
	data_grads_norm = 3.8092
	new_data_grads_norm = 6.1016
	old_data_grads_norm = 4.9343
	sim_grads_norm = -0.0041
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7854
	data_grads_norm = 4.1526
	new_data_grads_norm = 5.8792
	old_data_grads_norm = 5.5126
	sim_grads_norm = -0.0342
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5002
	data_grads_norm = 3.8237
	new_data_grads_norm = 6.5310
	old_data_grads_norm = 3.7839
	sim_grads_norm = -0.0045
-- Starting training on experience 71 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7687
	data_grads_norm = 4.3258
	new_data_grads_norm = 6.2001
	old_data_grads_norm = 4.9568
	sim_grads_norm = 0.0777
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5368
	data_grads_norm = 4.2533
	new_data_grads_norm = 5.7703
	old_data_grads_norm = 5.3833
	sim_grads_norm = -0.0294
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6700
	data_grads_norm = 4.2857
	new_data_grads_norm = 6.6324
	old_data_grads_norm = 5.0227
	sim_grads_norm = -0.0053
-- Starting training on experience 72 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6773
	data_grads_norm = 4.4559
	new_data_grads_norm = 6.9919
	old_data_grads_norm = 3.7449
	sim_grads_norm = 0.1000
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8480
	data_grads_norm = 5.0438
	new_data_grads_norm = 8.5498
	old_data_grads_norm = 5.8786
	sim_grads_norm = -0.0265
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9488
	data_grads_norm = 5.1733
	new_data_grads_norm = 7.5528
	old_data_grads_norm = 6.2437
	sim_grads_norm = -0.0010
-- Starting training on experience 73 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0168
	data_grads_norm = 4.6692
	new_data_grads_norm = 7.0660
	old_data_grads_norm = 4.6089
	sim_grads_norm = 0.0017
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7761
	data_grads_norm = 5.2876
	new_data_grads_norm = 7.5916
	old_data_grads_norm = 6.3533
	sim_grads_norm = 0.0429
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6009
	data_grads_norm = 4.2283
	new_data_grads_norm = 6.9601
	old_data_grads_norm = 4.6263
	sim_grads_norm = -0.0202
-- Starting training on experience 74 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4316
	data_grads_norm = 4.0806
	new_data_grads_norm = 5.5867
	old_data_grads_norm = 5.3183
	sim_grads_norm = -0.0183
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4770
	data_grads_norm = 3.7108
	new_data_grads_norm = 6.4499
	old_data_grads_norm = 3.4530
	sim_grads_norm = 0.0808
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4328
	data_grads_norm = 4.1355
	new_data_grads_norm = 6.1473
	old_data_grads_norm = 5.1679
	sim_grads_norm = -0.0142
-- Starting training on experience 75 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4687
	data_grads_norm = 3.8224
	new_data_grads_norm = 6.2113
	old_data_grads_norm = 3.7915
	sim_grads_norm = 0.0593
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1292
	data_grads_norm = 3.9220
	new_data_grads_norm = 6.0978
	old_data_grads_norm = 5.2274
	sim_grads_norm = -0.0108
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9739
	data_grads_norm = 5.4102
	new_data_grads_norm = 6.5595
	old_data_grads_norm = 8.3436
	sim_grads_norm = 0.0103
-- Starting training on experience 76 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7057
	data_grads_norm = 4.5143
	new_data_grads_norm = 5.2621
	old_data_grads_norm = 6.3113
	sim_grads_norm = 0.0005
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7889
	data_grads_norm = 4.3116
	new_data_grads_norm = 5.8716
	old_data_grads_norm = 6.6487
	sim_grads_norm = -0.0115
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9880
	data_grads_norm = 4.9516
	new_data_grads_norm = 6.8355
	old_data_grads_norm = 6.8891
	sim_grads_norm = 0.0188
-- Starting training on experience 77 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7783
	data_grads_norm = 4.9227
	new_data_grads_norm = 6.2712
	old_data_grads_norm = 7.4157
	sim_grads_norm = 0.0446
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7030
	data_grads_norm = 4.2901
	new_data_grads_norm = 6.5561
	old_data_grads_norm = 5.6529
	sim_grads_norm = 0.0216
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6198
	data_grads_norm = 4.2087
	new_data_grads_norm = 6.4431
	old_data_grads_norm = 4.1612
	sim_grads_norm = -0.0068
-- Starting training on experience 78 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5987
	data_grads_norm = 4.5375
	new_data_grads_norm = 5.7783
	old_data_grads_norm = 5.3291
	sim_grads_norm = -0.0140
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3054
	data_grads_norm = 4.0775
	new_data_grads_norm = 6.0066
	old_data_grads_norm = 5.7788
	sim_grads_norm = -0.0280
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7714
	data_grads_norm = 4.6497
	new_data_grads_norm = 6.0700
	old_data_grads_norm = 5.9192
	sim_grads_norm = 0.0279
-- Starting training on experience 79 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3197
	data_grads_norm = 3.9517
	new_data_grads_norm = 6.5156
	old_data_grads_norm = 5.3943
	sim_grads_norm = -0.0488
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3325
	data_grads_norm = 3.9807
	new_data_grads_norm = 5.8833
	old_data_grads_norm = 4.0278
	sim_grads_norm = -0.0107
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5033
	data_grads_norm = 4.3716
	new_data_grads_norm = 6.2268
	old_data_grads_norm = 7.8834
	sim_grads_norm = 0.0035
-- Starting training on experience 80 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8028
	data_grads_norm = 4.9858
	new_data_grads_norm = 7.4881
	old_data_grads_norm = 5.3287
	sim_grads_norm = 0.0699
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7113
	data_grads_norm = 4.8455
	new_data_grads_norm = 7.5712
	old_data_grads_norm = 4.4752
	sim_grads_norm = 0.0186
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5057
	data_grads_norm = 5.1438
	new_data_grads_norm = 7.4244
	old_data_grads_norm = 7.1052
	sim_grads_norm = -0.0185
-- Starting training on experience 81 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2970
	data_grads_norm = 5.0395
	new_data_grads_norm = 5.9993
	old_data_grads_norm = 8.8908
	sim_grads_norm = 0.0223
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4726
	data_grads_norm = 4.5786
	new_data_grads_norm = 6.0940
	old_data_grads_norm = 5.8616
	sim_grads_norm = 0.0614
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4754
	data_grads_norm = 3.9835
	new_data_grads_norm = 6.0705
	old_data_grads_norm = 4.9732
	sim_grads_norm = 0.0257
-- Starting training on experience 82 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4307
	data_grads_norm = 4.3409
	new_data_grads_norm = 6.4839
	old_data_grads_norm = 4.7362
	sim_grads_norm = 0.0042
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4314
	data_grads_norm = 4.5155
	new_data_grads_norm = 7.0563
	old_data_grads_norm = 4.2637
	sim_grads_norm = -0.0133
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6424
	data_grads_norm = 4.5557
	new_data_grads_norm = 6.3096
	old_data_grads_norm = 7.1632
	sim_grads_norm = -0.0121
-- Starting training on experience 83 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8970
	data_grads_norm = 4.6015
	new_data_grads_norm = 6.0197
	old_data_grads_norm = 5.5865
	sim_grads_norm = 0.0038
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0918
	data_grads_norm = 3.5973
	new_data_grads_norm = 5.3477
	old_data_grads_norm = 3.4939
	sim_grads_norm = -0.0616
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6420
	data_grads_norm = 4.5960
	new_data_grads_norm = 7.0899
	old_data_grads_norm = 4.7486
	sim_grads_norm = 0.0255
-- Starting training on experience 84 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4892
	data_grads_norm = 4.6355
	new_data_grads_norm = 6.8759
	old_data_grads_norm = 4.5586
	sim_grads_norm = 0.0497
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1446
	data_grads_norm = 4.1702
	new_data_grads_norm = 5.9880
	old_data_grads_norm = 5.4595
	sim_grads_norm = -0.0114
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1251
	data_grads_norm = 4.2238
	new_data_grads_norm = 6.7771
	old_data_grads_norm = 4.5397
	sim_grads_norm = -0.0330
-- Starting training on experience 85 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9271
	data_grads_norm = 3.9343
	new_data_grads_norm = 5.6818
	old_data_grads_norm = 5.7341
	sim_grads_norm = -0.0224
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0788
	data_grads_norm = 3.6655
	new_data_grads_norm = 5.3082
	old_data_grads_norm = 4.8276
	sim_grads_norm = 0.0125
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9890
	data_grads_norm = 3.4590
	new_data_grads_norm = 5.8891
	old_data_grads_norm = 3.4880
	sim_grads_norm = -0.0062
-- Starting training on experience 86 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0018
	data_grads_norm = 4.9375
	new_data_grads_norm = 7.7434
	old_data_grads_norm = 5.4387
	sim_grads_norm = 0.0048
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5230
	data_grads_norm = 4.6044
	new_data_grads_norm = 7.7430
	old_data_grads_norm = 3.9710
	sim_grads_norm = -0.0001
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2289
	data_grads_norm = 3.5426
	new_data_grads_norm = 6.6582
	old_data_grads_norm = 4.3511
	sim_grads_norm = 0.0255
-- Starting training on experience 87 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5379
	data_grads_norm = 4.2893
	new_data_grads_norm = 6.1207
	old_data_grads_norm = 5.6611
	sim_grads_norm = -0.0394
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7876
	data_grads_norm = 4.6831
	new_data_grads_norm = 6.4273
	old_data_grads_norm = 5.7503
	sim_grads_norm = 0.0788
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3847
	data_grads_norm = 4.0459
	new_data_grads_norm = 5.8661
	old_data_grads_norm = 4.0565
	sim_grads_norm = 0.0894
-- Starting training on experience 88 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0718
	data_grads_norm = 4.0457
	new_data_grads_norm = 7.1235
	old_data_grads_norm = 3.9740
	sim_grads_norm = 0.0059
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4882
	data_grads_norm = 4.6706
	new_data_grads_norm = 8.2219
	old_data_grads_norm = 3.4833
	sim_grads_norm = -0.0125
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2250
	data_grads_norm = 4.6793
	new_data_grads_norm = 7.5796
	old_data_grads_norm = 4.9606
	sim_grads_norm = -0.0174
-- Starting training on experience 89 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2667
	data_grads_norm = 4.1118
	new_data_grads_norm = 6.5995
	old_data_grads_norm = 5.7977
	sim_grads_norm = 0.0061
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0405
	data_grads_norm = 5.1374
	new_data_grads_norm = 7.3074
	old_data_grads_norm = 4.7924
	sim_grads_norm = 0.0579
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1216
	data_grads_norm = 4.4100
	new_data_grads_norm = 6.5152
	old_data_grads_norm = 7.4682
	sim_grads_norm = -0.0164
-- Starting training on experience 90 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4743
	data_grads_norm = 4.5832
	new_data_grads_norm = 7.0610
	old_data_grads_norm = 6.4447
	sim_grads_norm = -0.0255
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7671
	data_grads_norm = 5.2689
	new_data_grads_norm = 8.5394
	old_data_grads_norm = 5.6467
	sim_grads_norm = -0.0120
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2665
	data_grads_norm = 4.4871
	new_data_grads_norm = 8.2246
	old_data_grads_norm = 3.8348
	sim_grads_norm = 0.0098
-- Starting training on experience 91 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6295
	data_grads_norm = 4.9534
	new_data_grads_norm = 6.8569
	old_data_grads_norm = 6.6630
	sim_grads_norm = 0.0081
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7298
	data_grads_norm = 4.5721
	new_data_grads_norm = 6.4677
	old_data_grads_norm = 5.5246
	sim_grads_norm = -0.0233
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3116
	data_grads_norm = 4.7195
	new_data_grads_norm = 6.7413
	old_data_grads_norm = 6.0588
	sim_grads_norm = -0.0071
-- Starting training on experience 92 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5298
	data_grads_norm = 4.7937
	new_data_grads_norm = 7.1386
	old_data_grads_norm = 6.7115
	sim_grads_norm = -0.0241
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1639
	data_grads_norm = 4.0072
	new_data_grads_norm = 6.9144
	old_data_grads_norm = 4.8519
	sim_grads_norm = -0.0186
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6424
	data_grads_norm = 4.6518
	new_data_grads_norm = 6.9079
	old_data_grads_norm = 5.6578
	sim_grads_norm = 0.0270
-- Starting training on experience 93 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6338
	data_grads_norm = 5.3893
	new_data_grads_norm = 7.1475
	old_data_grads_norm = 5.5300
	sim_grads_norm = -0.0280
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9898
	data_grads_norm = 5.6126
	new_data_grads_norm = 6.6512
	old_data_grads_norm = 8.1019
	sim_grads_norm = 0.0559
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2313
	data_grads_norm = 5.3249
	new_data_grads_norm = 7.2646
	old_data_grads_norm = 6.2486
	sim_grads_norm = 0.1224
-- Starting training on experience 94 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3628
	data_grads_norm = 3.9267
	new_data_grads_norm = 7.0980
	old_data_grads_norm = 5.4880
	sim_grads_norm = -0.0042
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8703
	data_grads_norm = 4.6767
	new_data_grads_norm = 6.3831
	old_data_grads_norm = 5.7095
	sim_grads_norm = 0.0405
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3628
	data_grads_norm = 4.6331
	new_data_grads_norm = 7.2122
	old_data_grads_norm = 5.8859
	sim_grads_norm = -0.0156
-- Starting training on experience 95 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5625
	data_grads_norm = 4.7348
	new_data_grads_norm = 7.9590
	old_data_grads_norm = 4.4122
	sim_grads_norm = 0.0034
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5604
	data_grads_norm = 4.7210
	new_data_grads_norm = 7.6699
	old_data_grads_norm = 6.2271
	sim_grads_norm = 0.0098
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6861
	data_grads_norm = 5.3920
	new_data_grads_norm = 6.6145
	old_data_grads_norm = 6.9567
	sim_grads_norm = 0.0148
-- Starting training on experience 96 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5410
	data_grads_norm = 4.3051
	new_data_grads_norm = 6.5041
	old_data_grads_norm = 4.7839
	sim_grads_norm = -0.0064
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8709
	data_grads_norm = 4.3092
	new_data_grads_norm = 6.2143
	old_data_grads_norm = 4.0188
	sim_grads_norm = -0.0238
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9811
	data_grads_norm = 4.6253
	new_data_grads_norm = 6.0976
	old_data_grads_norm = 4.7753
	sim_grads_norm = 0.0224
-- Starting training on experience 97 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7002
	data_grads_norm = 4.7550
	new_data_grads_norm = 7.0971
	old_data_grads_norm = 5.3697
	sim_grads_norm = -0.0042
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2263
	data_grads_norm = 4.9365
	new_data_grads_norm = 7.8154
	old_data_grads_norm = 5.4676
	sim_grads_norm = 0.0007
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5033
	data_grads_norm = 3.7779
	new_data_grads_norm = 5.9889
	old_data_grads_norm = 4.8213
	sim_grads_norm = 0.0217
-- Starting training on experience 98 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7968
	data_grads_norm = 4.8345
	new_data_grads_norm = 7.3765
	old_data_grads_norm = 4.7878
	sim_grads_norm = 0.0455
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6732
	data_grads_norm = 5.1086
	new_data_grads_norm = 7.7000
	old_data_grads_norm = 6.9067
	sim_grads_norm = -0.0146
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0537
	data_grads_norm = 4.0544
	new_data_grads_norm = 6.8443
	old_data_grads_norm = 3.3072
	sim_grads_norm = -0.0203
-- Starting training on experience 99 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6475
	data_grads_norm = 3.9152
	new_data_grads_norm = 6.1182
	old_data_grads_norm = 5.2539
	sim_grads_norm = 0.0136
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9759
	data_grads_norm = 3.6745
	new_data_grads_norm = 7.0582
	old_data_grads_norm = 2.8349
	sim_grads_norm = -0.0032
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7828
	data_grads_norm = 4.7809
	new_data_grads_norm = 6.9331
	old_data_grads_norm = 7.2865
	sim_grads_norm = 0.0009
-- Starting training on experience 100 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3958
	data_grads_norm = 4.2896
	new_data_grads_norm = 6.0556
	old_data_grads_norm = 5.1563
	sim_grads_norm = 0.0147
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1644
	data_grads_norm = 3.9984
	new_data_grads_norm = 6.5915
	old_data_grads_norm = 6.2793
	sim_grads_norm = 0.0078
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3985
	data_grads_norm = 4.4781
	new_data_grads_norm = 6.2873
	old_data_grads_norm = 5.4267
	sim_grads_norm = 0.0208
-- Starting training on experience 101 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5848
	data_grads_norm = 5.3797
	new_data_grads_norm = 7.6935
	old_data_grads_norm = 6.2222
	sim_grads_norm = -0.0252
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5573
	data_grads_norm = 5.0145
	new_data_grads_norm = 6.8571
	old_data_grads_norm = 4.8300
	sim_grads_norm = -0.0153
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7414
	data_grads_norm = 5.1379
	new_data_grads_norm = 7.8048
	old_data_grads_norm = 4.7378
	sim_grads_norm = -0.0692
-- Starting training on experience 102 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2780
	data_grads_norm = 4.5099
	new_data_grads_norm = 6.1009
	old_data_grads_norm = 4.1616
	sim_grads_norm = 0.0023
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4124
	data_grads_norm = 4.4718
	new_data_grads_norm = 6.8825
	old_data_grads_norm = 5.3074
	sim_grads_norm = -0.0352
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4885
	data_grads_norm = 4.0484
	new_data_grads_norm = 6.0212
	old_data_grads_norm = 5.0319
	sim_grads_norm = -0.0070
-- Starting training on experience 103 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9886
	data_grads_norm = 3.1933
	new_data_grads_norm = 5.8970
	old_data_grads_norm = 3.5764
	sim_grads_norm = 0.0796
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6809
	data_grads_norm = 4.2636
	new_data_grads_norm = 5.7026
	old_data_grads_norm = 6.3239
	sim_grads_norm = 0.0122
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3759
	data_grads_norm = 4.2183
	new_data_grads_norm = 6.0435
	old_data_grads_norm = 6.1656
	sim_grads_norm = -0.0402
-- Starting training on experience 104 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1995
	data_grads_norm = 4.0548
	new_data_grads_norm = 6.4885
	old_data_grads_norm = 4.1170
	sim_grads_norm = -0.0109
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9969
	data_grads_norm = 4.9347
	new_data_grads_norm = 6.9911
	old_data_grads_norm = 6.6527
	sim_grads_norm = -0.0239
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4498
	data_grads_norm = 5.0509
	new_data_grads_norm = 7.2501
	old_data_grads_norm = 6.3311
	sim_grads_norm = 0.0182
-- Starting training on experience 105 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5432
	data_grads_norm = 4.7441
	new_data_grads_norm = 6.9797
	old_data_grads_norm = 6.1589
	sim_grads_norm = -0.0148
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8867
	data_grads_norm = 5.1101
	new_data_grads_norm = 7.1412
	old_data_grads_norm = 6.2225
	sim_grads_norm = 0.0626
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7416
	data_grads_norm = 4.9260
	new_data_grads_norm = 7.2660
	old_data_grads_norm = 6.8615
	sim_grads_norm = -0.0132
-- Starting training on experience 106 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1966
	data_grads_norm = 4.1993
	new_data_grads_norm = 6.3431
	old_data_grads_norm = 5.1587
	sim_grads_norm = -0.0071
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2189
	data_grads_norm = 3.9245
	new_data_grads_norm = 5.4790
	old_data_grads_norm = 5.6531
	sim_grads_norm = 0.0331
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5479
	data_grads_norm = 4.6518
	new_data_grads_norm = 5.9746
	old_data_grads_norm = 7.3270
	sim_grads_norm = 0.0076
-- Starting training on experience 107 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5352
	data_grads_norm = 4.8454
	new_data_grads_norm = 7.0834
	old_data_grads_norm = 4.0558
	sim_grads_norm = -0.0305
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4660
	data_grads_norm = 4.1668
	new_data_grads_norm = 6.7950
	old_data_grads_norm = 5.5066
	sim_grads_norm = -0.0290
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1487
	data_grads_norm = 5.1070
	new_data_grads_norm = 7.5145
	old_data_grads_norm = 6.7901
	sim_grads_norm = -0.0085
-- Starting training on experience 108 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9111
	data_grads_norm = 3.4410
	new_data_grads_norm = 7.1393
	old_data_grads_norm = 3.5222
	sim_grads_norm = 0.0039
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1490
	data_grads_norm = 5.7505
	new_data_grads_norm = 6.3535
	old_data_grads_norm = 8.2442
	sim_grads_norm = 0.0188
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0902
	data_grads_norm = 4.6813
	new_data_grads_norm = 5.6532
	old_data_grads_norm = 6.6133
	sim_grads_norm = -0.0114
-- Starting training on experience 109 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3422
	data_grads_norm = 4.1844
	new_data_grads_norm = 5.9544
	old_data_grads_norm = 7.0729
	sim_grads_norm = 0.0077
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0797
	data_grads_norm = 3.3617
	new_data_grads_norm = 6.0323
	old_data_grads_norm = 2.9193
	sim_grads_norm = 0.0081
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4567
	data_grads_norm = 4.1541
	new_data_grads_norm = 5.7796
	old_data_grads_norm = 5.4804
	sim_grads_norm = -0.0145
-- Starting training on experience 110 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6748
	data_grads_norm = 5.1777
	new_data_grads_norm = 7.6320
	old_data_grads_norm = 6.0766
	sim_grads_norm = 0.0100
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2976
	data_grads_norm = 4.7437
	new_data_grads_norm = 8.6102
	old_data_grads_norm = 4.7286
	sim_grads_norm = -0.0267
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4823
	data_grads_norm = 4.9320
	new_data_grads_norm = 7.9431
	old_data_grads_norm = 6.0101
	sim_grads_norm = 0.0037
-- Starting training on experience 111 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3405
	data_grads_norm = 4.1469
	new_data_grads_norm = 6.7565
	old_data_grads_norm = 6.0050
	sim_grads_norm = 0.0064
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4061
	data_grads_norm = 3.4903
	new_data_grads_norm = 6.6011
	old_data_grads_norm = 3.9955
	sim_grads_norm = 0.0293
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4581
	data_grads_norm = 4.8653
	new_data_grads_norm = 7.8215
	old_data_grads_norm = 5.2410
	sim_grads_norm = -0.0072
-- Starting training on experience 112 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1790
	data_grads_norm = 4.3256
	new_data_grads_norm = 6.2884
	old_data_grads_norm = 5.0811
	sim_grads_norm = 0.0051
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4864
	data_grads_norm = 4.4119
	new_data_grads_norm = 6.0399
	old_data_grads_norm = 5.8129
	sim_grads_norm = 0.0019
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0340
	data_grads_norm = 4.0079
	new_data_grads_norm = 5.7155
	old_data_grads_norm = 6.7385
	sim_grads_norm = -0.0192
-- Starting training on experience 113 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4787
	data_grads_norm = 4.0038
	new_data_grads_norm = 5.6797
	old_data_grads_norm = 5.0562
	sim_grads_norm = 0.0552
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1697
	data_grads_norm = 3.6707
	new_data_grads_norm = 5.9223
	old_data_grads_norm = 3.7291
	sim_grads_norm = -0.0068
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3073
	data_grads_norm = 3.9032
	new_data_grads_norm = 5.9965
	old_data_grads_norm = 4.4250
	sim_grads_norm = 0.0086
-- Starting training on experience 114 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1335
	data_grads_norm = 4.5799
	new_data_grads_norm = 6.0333
	old_data_grads_norm = 6.4865
	sim_grads_norm = -0.0167
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5513
	data_grads_norm = 4.5619
	new_data_grads_norm = 6.5690
	old_data_grads_norm = 6.1959
	sim_grads_norm = -0.0165
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2410
	data_grads_norm = 5.4293
	new_data_grads_norm = 6.8065
	old_data_grads_norm = 7.1676
	sim_grads_norm = 0.0881
-- Starting training on experience 115 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9491
	data_grads_norm = 4.5773
	new_data_grads_norm = 5.1398
	old_data_grads_norm = 6.8542
	sim_grads_norm = 0.0056
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4678
	data_grads_norm = 4.8114
	new_data_grads_norm = 6.1858
	old_data_grads_norm = 5.3199
	sim_grads_norm = 0.0460
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2003
	data_grads_norm = 4.2226
	new_data_grads_norm = 6.7073
	old_data_grads_norm = 5.9324
	sim_grads_norm = 0.0056
-- Starting training on experience 116 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8207
	data_grads_norm = 3.3463
	new_data_grads_norm = 6.0087
	old_data_grads_norm = 3.7059
	sim_grads_norm = -0.0070
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4472
	data_grads_norm = 4.6005
	new_data_grads_norm = 6.4706
	old_data_grads_norm = 7.3315
	sim_grads_norm = 0.0488
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1058
	data_grads_norm = 3.9499
	new_data_grads_norm = 5.2773
	old_data_grads_norm = 6.3799
	sim_grads_norm = -0.0187
-- Starting training on experience 117 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1090
	data_grads_norm = 4.8469
	new_data_grads_norm = 8.0315
	old_data_grads_norm = 5.6470
	sim_grads_norm = -0.0424
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1389
	data_grads_norm = 4.2454
	new_data_grads_norm = 7.9989
	old_data_grads_norm = 3.1548
	sim_grads_norm = -0.0366
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4983
	data_grads_norm = 4.8799
	new_data_grads_norm = 8.3980
	old_data_grads_norm = 6.5257
	sim_grads_norm = 0.0455
-- Starting training on experience 118 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8466
	data_grads_norm = 3.6251
	new_data_grads_norm = 5.3969
	old_data_grads_norm = 5.0898
	sim_grads_norm = -0.0397
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2173
	data_grads_norm = 3.8760
	new_data_grads_norm = 5.6510
	old_data_grads_norm = 5.8968
	sim_grads_norm = 0.0082
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0113
	data_grads_norm = 3.6975
	new_data_grads_norm = 6.3047
	old_data_grads_norm = 3.8443
	sim_grads_norm = 0.0890
-- Starting training on experience 119 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2994
	data_grads_norm = 4.9452
	new_data_grads_norm = 8.2246
	old_data_grads_norm = 5.8964
	sim_grads_norm = -0.0245
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2170
	data_grads_norm = 4.8209
	new_data_grads_norm = 8.1092
	old_data_grads_norm = 4.8604
	sim_grads_norm = 0.0320
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2431
	data_grads_norm = 4.5251
	new_data_grads_norm = 8.3609
	old_data_grads_norm = 3.9566
	sim_grads_norm = -0.0037
-- Starting training on experience 120 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0448
	data_grads_norm = 3.8727
	new_data_grads_norm = 6.0283
	old_data_grads_norm = 5.3844
	sim_grads_norm = -0.0423
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7633
	data_grads_norm = 3.8660
	new_data_grads_norm = 7.4845
	old_data_grads_norm = 4.9672
	sim_grads_norm = -0.0505
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0600
	data_grads_norm = 4.1893
	new_data_grads_norm = 6.3524
	old_data_grads_norm = 5.3741
	sim_grads_norm = -0.0082
-- Starting training on experience 121 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3917
	data_grads_norm = 4.6121
	new_data_grads_norm = 6.7700
	old_data_grads_norm = 6.0512
	sim_grads_norm = 0.0335
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1089
	data_grads_norm = 4.5094
	new_data_grads_norm = 7.0099
	old_data_grads_norm = 4.2851
	sim_grads_norm = 0.0240
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0434
	data_grads_norm = 4.2251
	new_data_grads_norm = 6.2625
	old_data_grads_norm = 5.9245
	sim_grads_norm = -0.0275
-- Starting training on experience 122 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0940
	data_grads_norm = 4.8494
	new_data_grads_norm = 7.2697
	old_data_grads_norm = 5.3435
	sim_grads_norm = 0.0009
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2422
	data_grads_norm = 5.1558
	new_data_grads_norm = 7.5780
	old_data_grads_norm = 5.9030
	sim_grads_norm = -0.0182
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2579
	data_grads_norm = 4.6272
	new_data_grads_norm = 6.8530
	old_data_grads_norm = 6.3500
	sim_grads_norm = 0.0149
-- Starting training on experience 123 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8345
	data_grads_norm = 3.4920
	new_data_grads_norm = 5.8661
	old_data_grads_norm = 3.4359
	sim_grads_norm = -0.0096
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1098
	data_grads_norm = 3.7052
	new_data_grads_norm = 6.2885
	old_data_grads_norm = 3.3162
	sim_grads_norm = -0.0433
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6838
	data_grads_norm = 4.4572
	new_data_grads_norm = 6.4631
	old_data_grads_norm = 5.3950
	sim_grads_norm = 0.0825
-- Starting training on experience 124 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1324
	data_grads_norm = 3.7486
	new_data_grads_norm = 6.2925
	old_data_grads_norm = 4.9675
	sim_grads_norm = -0.0316
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0898
	data_grads_norm = 4.0986
	new_data_grads_norm = 7.0373
	old_data_grads_norm = 5.2969
	sim_grads_norm = -0.0388
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4642
	data_grads_norm = 4.1358
	new_data_grads_norm = 6.9522
	old_data_grads_norm = 5.6268
	sim_grads_norm = -0.0225
-- Starting training on experience 125 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9016
	data_grads_norm = 3.8599
	new_data_grads_norm = 6.1906
	old_data_grads_norm = 6.3172
	sim_grads_norm = -0.0059
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0672
	data_grads_norm = 4.9546
	new_data_grads_norm = 5.8743
	old_data_grads_norm = 6.8861
	sim_grads_norm = -0.0238
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4556
	data_grads_norm = 5.3529
	new_data_grads_norm = 6.7400
	old_data_grads_norm = 6.3326
	sim_grads_norm = 0.0608
-- Starting training on experience 126 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0816
	data_grads_norm = 3.8327
	new_data_grads_norm = 6.7742
	old_data_grads_norm = 4.6077
	sim_grads_norm = -0.0167
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0861
	data_grads_norm = 3.7872
	new_data_grads_norm = 6.4864
	old_data_grads_norm = 3.8545
	sim_grads_norm = -0.0173
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0429
	data_grads_norm = 3.8559
	new_data_grads_norm = 5.9891
	old_data_grads_norm = 5.0051
	sim_grads_norm = -0.0117
-- Starting training on experience 127 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3082
	data_grads_norm = 4.6409
	new_data_grads_norm = 5.8510
	old_data_grads_norm = 6.8880
	sim_grads_norm = 0.0312
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0018
	data_grads_norm = 4.3882
	new_data_grads_norm = 5.9616
	old_data_grads_norm = 6.0605
	sim_grads_norm = -0.0231
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1050
	data_grads_norm = 3.8074
	new_data_grads_norm = 5.9134
	old_data_grads_norm = 5.2707
	sim_grads_norm = -0.0094
-- Starting training on experience 128 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3462
	data_grads_norm = 4.3249
	new_data_grads_norm = 6.6001
	old_data_grads_norm = 6.1702
	sim_grads_norm = -0.0304
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6237
	data_grads_norm = 4.2828
	new_data_grads_norm = 7.1644
	old_data_grads_norm = 5.2241
	sim_grads_norm = -0.0199
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9382
	data_grads_norm = 4.7684
	new_data_grads_norm = 6.8477
	old_data_grads_norm = 5.2269
	sim_grads_norm = 0.0059
-- Starting training on experience 129 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6484
	data_grads_norm = 5.0564
	new_data_grads_norm = 7.2760
	old_data_grads_norm = 5.9882
	sim_grads_norm = -0.0086
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6690
	data_grads_norm = 4.5550
	new_data_grads_norm = 7.2452
	old_data_grads_norm = 5.4220
	sim_grads_norm = 0.0439
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1654
	data_grads_norm = 3.9113
	new_data_grads_norm = 5.6600
	old_data_grads_norm = 5.2936
	sim_grads_norm = -0.0181
-- Starting training on experience 130 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3752
	data_grads_norm = 4.4438
	new_data_grads_norm = 6.3706
	old_data_grads_norm = 5.6110
	sim_grads_norm = 0.0329
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3229
	data_grads_norm = 4.4549
	new_data_grads_norm = 6.4889
	old_data_grads_norm = 5.1231
	sim_grads_norm = 0.1345
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0912
	data_grads_norm = 4.3478
	new_data_grads_norm = 6.3879
	old_data_grads_norm = 3.9457
	sim_grads_norm = 0.0744
-- Starting training on experience 131 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1206
	data_grads_norm = 5.0519
	new_data_grads_norm = 5.9208
	old_data_grads_norm = 5.9155
	sim_grads_norm = -0.0038
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3754
	data_grads_norm = 5.0658
	new_data_grads_norm = 6.8748
	old_data_grads_norm = 6.2552
	sim_grads_norm = 0.0116
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9320
	data_grads_norm = 4.2060
	new_data_grads_norm = 6.5959
	old_data_grads_norm = 4.9815
	sim_grads_norm = 0.0355
-- Starting training on experience 132 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2012
	data_grads_norm = 4.8439
	new_data_grads_norm = 5.3487
	old_data_grads_norm = 7.4829
	sim_grads_norm = 0.0122
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8798
	data_grads_norm = 4.6629
	new_data_grads_norm = 4.8784
	old_data_grads_norm = 6.9704
	sim_grads_norm = 0.0388
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8023
	data_grads_norm = 4.1099
	new_data_grads_norm = 5.4468
	old_data_grads_norm = 6.0726
	sim_grads_norm = -0.0102
-- Starting training on experience 133 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1607
	data_grads_norm = 4.3624
	new_data_grads_norm = 7.1829
	old_data_grads_norm = 5.6623
	sim_grads_norm = -0.0311
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1678
	data_grads_norm = 4.0880
	new_data_grads_norm = 6.8103
	old_data_grads_norm = 4.1695
	sim_grads_norm = 0.0204
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2696
	data_grads_norm = 4.8067
	new_data_grads_norm = 7.0481
	old_data_grads_norm = 6.2929
	sim_grads_norm = 0.0254
-- Starting training on experience 134 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6531
	data_grads_norm = 5.3702
	new_data_grads_norm = 8.4785
	old_data_grads_norm = 6.0860
	sim_grads_norm = 0.0079
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3483
	data_grads_norm = 4.0910
	new_data_grads_norm = 7.8148
	old_data_grads_norm = 4.2307
	sim_grads_norm = 0.0040
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5630
	data_grads_norm = 5.1805
	new_data_grads_norm = 8.7515
	old_data_grads_norm = 5.6009
	sim_grads_norm = -0.0003
-- Starting training on experience 135 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2858
	data_grads_norm = 4.2948
	new_data_grads_norm = 6.9576
	old_data_grads_norm = 5.8469
	sim_grads_norm = 0.0483
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0670
	data_grads_norm = 3.7640
	new_data_grads_norm = 7.4577
	old_data_grads_norm = 4.0003
	sim_grads_norm = -0.0413
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4118
	data_grads_norm = 4.3899
	new_data_grads_norm = 6.7966
	old_data_grads_norm = 5.7077
	sim_grads_norm = -0.0103
-- Starting training on experience 136 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0977
	data_grads_norm = 4.5562
	new_data_grads_norm = 6.4411
	old_data_grads_norm = 5.8681
	sim_grads_norm = 0.0660
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4405
	data_grads_norm = 3.6889
	new_data_grads_norm = 5.5634
	old_data_grads_norm = 5.1662
	sim_grads_norm = 0.0572
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4013
	data_grads_norm = 3.6000
	new_data_grads_norm = 5.0091
	old_data_grads_norm = 4.7753
	sim_grads_norm = -0.0154
-- Starting training on experience 137 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7626
	data_grads_norm = 4.8555
	new_data_grads_norm = 7.2233
	old_data_grads_norm = 6.3421
	sim_grads_norm = 0.0023
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3323
	data_grads_norm = 4.1366
	new_data_grads_norm = 7.2872
	old_data_grads_norm = 4.1222
	sim_grads_norm = 0.0142
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5772
	data_grads_norm = 4.5162
	new_data_grads_norm = 7.1723
	old_data_grads_norm = 5.7722
	sim_grads_norm = -0.0191
-- Starting training on experience 138 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1921
	data_grads_norm = 3.7443
	new_data_grads_norm = 6.0975
	old_data_grads_norm = 5.1774
	sim_grads_norm = -0.0300
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1191
	data_grads_norm = 4.3221
	new_data_grads_norm = 6.8030
	old_data_grads_norm = 5.0515
	sim_grads_norm = -0.0223
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0088
	data_grads_norm = 3.3440
	new_data_grads_norm = 6.1492
	old_data_grads_norm = 3.4927
	sim_grads_norm = -0.0118
-- Starting training on experience 139 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9925
	data_grads_norm = 5.2577
	new_data_grads_norm = 6.5403
	old_data_grads_norm = 7.0847
	sim_grads_norm = -0.0114
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4415
	data_grads_norm = 5.2423
	new_data_grads_norm = 7.5249
	old_data_grads_norm = 6.2917
	sim_grads_norm = -0.0374
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2723
	data_grads_norm = 4.9773
	new_data_grads_norm = 7.1854
	old_data_grads_norm = 6.7621
	sim_grads_norm = 0.0747
-- Starting training on experience 140 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7599
	data_grads_norm = 3.7385
	new_data_grads_norm = 5.4315
	old_data_grads_norm = 5.7852
	sim_grads_norm = 0.0023
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2540
	data_grads_norm = 4.2192
	new_data_grads_norm = 6.0719
	old_data_grads_norm = 4.9848
	sim_grads_norm = 0.0319
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6833
	data_grads_norm = 3.4610
	new_data_grads_norm = 5.5715
	old_data_grads_norm = 5.0057
	sim_grads_norm = -0.0370
-- Starting training on experience 141 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2243
	data_grads_norm = 4.2938
	new_data_grads_norm = 6.3857
	old_data_grads_norm = 5.3303
	sim_grads_norm = -0.0449
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0533
	data_grads_norm = 4.1028
	new_data_grads_norm = 6.4420
	old_data_grads_norm = 4.1405
	sim_grads_norm = 0.0658
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8508
	data_grads_norm = 4.0868
	new_data_grads_norm = 7.5121
	old_data_grads_norm = 3.4874
	sim_grads_norm = 0.0406
-- Starting training on experience 142 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1778
	data_grads_norm = 4.8494
	new_data_grads_norm = 7.6701
	old_data_grads_norm = 5.1882
	sim_grads_norm = -0.0298
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8976
	data_grads_norm = 5.6558
	new_data_grads_norm = 8.3758
	old_data_grads_norm = 6.8267
	sim_grads_norm = 0.0233
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1888
	data_grads_norm = 5.7845
	new_data_grads_norm = 7.4685
	old_data_grads_norm = 8.2386
	sim_grads_norm = 0.0364
-- Starting training on experience 143 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6279
	data_grads_norm = 4.3190
	new_data_grads_norm = 6.2720
	old_data_grads_norm = 7.2450
	sim_grads_norm = 0.0242
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1051
	data_grads_norm = 5.0175
	new_data_grads_norm = 6.3824
	old_data_grads_norm = 7.0754
	sim_grads_norm = 0.0014
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4725
	data_grads_norm = 4.8918
	new_data_grads_norm = 6.8509
	old_data_grads_norm = 5.6879
	sim_grads_norm = -0.0411
-- Starting training on experience 144 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4250
	data_grads_norm = 4.8274
	new_data_grads_norm = 6.4430
	old_data_grads_norm = 5.8616
	sim_grads_norm = -0.0155
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1656
	data_grads_norm = 4.1195
	new_data_grads_norm = 7.4623
	old_data_grads_norm = 3.2154
	sim_grads_norm = -0.0343
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0661
	data_grads_norm = 4.0441
	new_data_grads_norm = 6.8107
	old_data_grads_norm = 4.7335
	sim_grads_norm = -0.0120
-- Starting training on experience 145 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2225
	data_grads_norm = 3.8824
	new_data_grads_norm = 6.0303
	old_data_grads_norm = 3.5250
	sim_grads_norm = -0.0278
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3132
	data_grads_norm = 4.2862
	new_data_grads_norm = 6.3286
	old_data_grads_norm = 5.7159
	sim_grads_norm = 0.0582
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8416
	data_grads_norm = 3.9993
	new_data_grads_norm = 6.1880
	old_data_grads_norm = 5.1578
	sim_grads_norm = -0.0165
-- Starting training on experience 146 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8972
	data_grads_norm = 5.7867
	new_data_grads_norm = 6.6594
	old_data_grads_norm = 8.5905
	sim_grads_norm = 0.0298
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1896
	data_grads_norm = 4.0000
	new_data_grads_norm = 6.8476
	old_data_grads_norm = 3.0472
	sim_grads_norm = 0.0983
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1922
	data_grads_norm = 4.8338
	new_data_grads_norm = 6.9337
	old_data_grads_norm = 5.6185
	sim_grads_norm = 0.0045
-- Starting training on experience 147 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9290
	data_grads_norm = 3.8676
	new_data_grads_norm = 6.0492
	old_data_grads_norm = 6.6278
	sim_grads_norm = -0.0636
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7283
	data_grads_norm = 3.9042
	new_data_grads_norm = 5.6828
	old_data_grads_norm = 4.5539
	sim_grads_norm = -0.0195
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1126
	data_grads_norm = 4.5969
	new_data_grads_norm = 5.9662
	old_data_grads_norm = 4.6744
	sim_grads_norm = -0.0197
-- Starting training on experience 148 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3639
	data_grads_norm = 5.1049
	new_data_grads_norm = 7.1831
	old_data_grads_norm = 5.8839
	sim_grads_norm = -0.0262
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9244
	data_grads_norm = 5.8804
	new_data_grads_norm = 9.0211
	old_data_grads_norm = 5.4644
	sim_grads_norm = 0.0243
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5416
	data_grads_norm = 5.1695
	new_data_grads_norm = 7.8658
	old_data_grads_norm = 5.9450
	sim_grads_norm = -0.0023
-- Starting training on experience 149 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2653
	data_grads_norm = 4.7688
	new_data_grads_norm = 8.1179
	old_data_grads_norm = 5.7956
	sim_grads_norm = 0.0229
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0453
	data_grads_norm = 3.8630
	new_data_grads_norm = 6.7817
	old_data_grads_norm = 5.0118
	sim_grads_norm = 0.0071
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2672
	data_grads_norm = 4.6692
	new_data_grads_norm = 7.1276
	old_data_grads_norm = 6.3886
	sim_grads_norm = 0.0491
-- Starting training on experience 150 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9935
	data_grads_norm = 4.6834
	new_data_grads_norm = 6.5779
	old_data_grads_norm = 6.7922
	sim_grads_norm = 0.0070
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1678
	data_grads_norm = 3.1289
	new_data_grads_norm = 5.9028
	old_data_grads_norm = 2.8351
	sim_grads_norm = -0.0080
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2812
	data_grads_norm = 3.8394
	new_data_grads_norm = 6.4149
	old_data_grads_norm = 4.7813
	sim_grads_norm = 0.0020
-- Starting training on experience 151 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1195
	data_grads_norm = 4.5328
	new_data_grads_norm = 6.2022
	old_data_grads_norm = 6.2442
	sim_grads_norm = -0.0233
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5101
	data_grads_norm = 4.7254
	new_data_grads_norm = 7.1551
	old_data_grads_norm = 5.9254
	sim_grads_norm = -0.0156
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3440
	data_grads_norm = 4.4100
	new_data_grads_norm = 7.7623
	old_data_grads_norm = 3.8997
	sim_grads_norm = 0.0091
-- Starting training on experience 152 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2413
	data_grads_norm = 4.0496
	new_data_grads_norm = 6.5923
	old_data_grads_norm = 5.0530
	sim_grads_norm = 0.0204
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6432
	data_grads_norm = 4.8064
	new_data_grads_norm = 7.2404
	old_data_grads_norm = 5.5657
	sim_grads_norm = 0.0325
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4225
	data_grads_norm = 4.0410
	new_data_grads_norm = 6.3159
	old_data_grads_norm = 5.7904
	sim_grads_norm = -0.0193
-- Starting training on experience 153 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0285
	data_grads_norm = 5.4636
	new_data_grads_norm = 7.8483
	old_data_grads_norm = 6.8376
	sim_grads_norm = 0.0110
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4068
	data_grads_norm = 4.4364
	new_data_grads_norm = 7.5760
	old_data_grads_norm = 2.5251
	sim_grads_norm = 0.0105
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0306
	data_grads_norm = 5.1490
	new_data_grads_norm = 8.1425
	old_data_grads_norm = 6.5503
	sim_grads_norm = -0.0163
-- Starting training on experience 154 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3926
	data_grads_norm = 3.9522
	new_data_grads_norm = 6.5659
	old_data_grads_norm = 5.2980
	sim_grads_norm = -0.0107
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3448
	data_grads_norm = 4.0217
	new_data_grads_norm = 6.4540
	old_data_grads_norm = 3.7376
	sim_grads_norm = -0.0104
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5989
	data_grads_norm = 4.6094
	new_data_grads_norm = 6.7073
	old_data_grads_norm = 5.5082
	sim_grads_norm = 0.0027
-- Starting training on experience 155 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2213
	data_grads_norm = 4.0335
	new_data_grads_norm = 6.4016
	old_data_grads_norm = 6.1119
	sim_grads_norm = 0.0095
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6612
	data_grads_norm = 4.1056
	new_data_grads_norm = 6.9657
	old_data_grads_norm = 4.8761
	sim_grads_norm = 0.0099
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5227
	data_grads_norm = 4.5939
	new_data_grads_norm = 7.2657
	old_data_grads_norm = 4.5276
	sim_grads_norm = 0.0160
-- Starting training on experience 156 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3805
	data_grads_norm = 5.7793
	new_data_grads_norm = 7.9457
	old_data_grads_norm = 6.1759
	sim_grads_norm = 0.0075
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6073
	data_grads_norm = 4.7034
	new_data_grads_norm = 7.8893
	old_data_grads_norm = 5.7235
	sim_grads_norm = -0.0223
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9322
	data_grads_norm = 4.9803
	new_data_grads_norm = 8.0423
	old_data_grads_norm = 4.6024
	sim_grads_norm = 0.0611
-- Starting training on experience 157 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3613
	data_grads_norm = 6.0051
	new_data_grads_norm = 8.3342
	old_data_grads_norm = 5.9235
	sim_grads_norm = 0.0197
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2908
	data_grads_norm = 6.4527
	new_data_grads_norm = 8.0445
	old_data_grads_norm = 9.0543
	sim_grads_norm = -0.0139
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9366
	data_grads_norm = 5.7651
	new_data_grads_norm = 8.8108
	old_data_grads_norm = 4.3117
	sim_grads_norm = 0.0063
-- Starting training on experience 158 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9964
	data_grads_norm = 5.3151
	new_data_grads_norm = 8.0131
	old_data_grads_norm = 6.0815
	sim_grads_norm = 0.0173
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5760
	data_grads_norm = 5.2700
	new_data_grads_norm = 7.7254
	old_data_grads_norm = 5.3197
	sim_grads_norm = 0.0597
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6927
	data_grads_norm = 5.3859
	new_data_grads_norm = 7.2338
	old_data_grads_norm = 6.6989
	sim_grads_norm = 0.0049
-- Starting training on experience 159 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3675
	data_grads_norm = 3.7315
	new_data_grads_norm = 5.9466
	old_data_grads_norm = 5.3812
	sim_grads_norm = 0.0055
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5166
	data_grads_norm = 3.4937
	new_data_grads_norm = 6.2685
	old_data_grads_norm = 4.2765
	sim_grads_norm = -0.0088
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5325
	data_grads_norm = 5.0768
	new_data_grads_norm = 8.2418
	old_data_grads_norm = 4.9004
	sim_grads_norm = 0.0177
-- Starting training on experience 160 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0724
	data_grads_norm = 5.2507
	new_data_grads_norm = 7.8123
	old_data_grads_norm = 7.2426
	sim_grads_norm = -0.0160
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3141
	data_grads_norm = 4.6340
	new_data_grads_norm = 7.3200
	old_data_grads_norm = 6.3704
	sim_grads_norm = -0.0109
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9960
	data_grads_norm = 5.1061
	new_data_grads_norm = 7.9634
	old_data_grads_norm = 5.7808
	sim_grads_norm = 0.0013
-- Starting training on experience 161 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5598
	data_grads_norm = 5.2538
	new_data_grads_norm = 6.6841
	old_data_grads_norm = 7.5770
	sim_grads_norm = 0.0034
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1524
	data_grads_norm = 4.2172
	new_data_grads_norm = 6.2057
	old_data_grads_norm = 6.1698
	sim_grads_norm = 0.0022
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9713
	data_grads_norm = 3.7780
	new_data_grads_norm = 6.0772
	old_data_grads_norm = 3.9979
	sim_grads_norm = 0.0079
-- Starting training on experience 162 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0060
	data_grads_norm = 5.1349
	new_data_grads_norm = 7.7323
	old_data_grads_norm = 6.8971
	sim_grads_norm = 0.0248
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1776
	data_grads_norm = 5.7354
	new_data_grads_norm = 7.8955
	old_data_grads_norm = 6.8909
	sim_grads_norm = -0.0407
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0393
	data_grads_norm = 4.2598
	new_data_grads_norm = 8.4571
	old_data_grads_norm = 2.6552
	sim_grads_norm = -0.0446
-- Starting training on experience 163 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0460
	data_grads_norm = 4.5995
	new_data_grads_norm = 5.6289
	old_data_grads_norm = 5.4829
	sim_grads_norm = 0.0092
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2081
	data_grads_norm = 4.6221
	new_data_grads_norm = 6.0587
	old_data_grads_norm = 6.2090
	sim_grads_norm = 0.0181
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7816
	data_grads_norm = 3.6524
	new_data_grads_norm = 5.9911
	old_data_grads_norm = 5.1772
	sim_grads_norm = -0.0217
-- Starting training on experience 164 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8668
	data_grads_norm = 3.7601
	new_data_grads_norm = 7.2202
	old_data_grads_norm = 3.3530
	sim_grads_norm = -0.0298
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3395
	data_grads_norm = 4.8178
	new_data_grads_norm = 7.3108
	old_data_grads_norm = 6.1749
	sim_grads_norm = 0.0303
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2153
	data_grads_norm = 4.5654
	new_data_grads_norm = 8.2349
	old_data_grads_norm = 5.2709
	sim_grads_norm = -0.0406
-- Starting training on experience 165 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5867
	data_grads_norm = 4.9488
	new_data_grads_norm = 7.1548
	old_data_grads_norm = 5.3270
	sim_grads_norm = 0.0076
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5502
	data_grads_norm = 4.5037
	new_data_grads_norm = 7.2078
	old_data_grads_norm = 3.7302
	sim_grads_norm = 0.1387
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5141
	data_grads_norm = 5.5342
	new_data_grads_norm = 6.8806
	old_data_grads_norm = 6.9481
	sim_grads_norm = 0.0170
-- Starting training on experience 166 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0749
	data_grads_norm = 4.0830
	new_data_grads_norm = 6.2116
	old_data_grads_norm = 6.0173
	sim_grads_norm = -0.0076
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2585
	data_grads_norm = 4.1373
	new_data_grads_norm = 6.3768
	old_data_grads_norm = 4.8045
	sim_grads_norm = 0.0330
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1800
	data_grads_norm = 4.8618
	new_data_grads_norm = 6.5590
	old_data_grads_norm = 4.8956
	sim_grads_norm = -0.0093
-- Starting training on experience 167 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5572
	data_grads_norm = 4.8312
	new_data_grads_norm = 7.2789
	old_data_grads_norm = 5.1992
	sim_grads_norm = -0.0275
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3877
	data_grads_norm = 4.0860
	new_data_grads_norm = 6.3669
	old_data_grads_norm = 4.2121
	sim_grads_norm = 0.0588
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7636
	data_grads_norm = 5.0841
	new_data_grads_norm = 6.4785
	old_data_grads_norm = 6.8856
	sim_grads_norm = 0.0112
-- Starting training on experience 168 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9277
	data_grads_norm = 4.1794
	new_data_grads_norm = 6.4678
	old_data_grads_norm = 4.4237
	sim_grads_norm = 0.0012
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1382
	data_grads_norm = 4.5974
	new_data_grads_norm = 7.0237
	old_data_grads_norm = 5.4901
	sim_grads_norm = -0.0285
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8413
	data_grads_norm = 3.7829
	new_data_grads_norm = 6.7165
	old_data_grads_norm = 3.4237
	sim_grads_norm = 0.0189
-- Starting training on experience 169 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5614
	data_grads_norm = 5.0760
	new_data_grads_norm = 7.0186
	old_data_grads_norm = 6.6063
	sim_grads_norm = 0.0521
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3733
	data_grads_norm = 4.3924
	new_data_grads_norm = 6.9255
	old_data_grads_norm = 4.6308
	sim_grads_norm = 0.0216
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0434
	data_grads_norm = 4.6216
	new_data_grads_norm = 7.1841
	old_data_grads_norm = 6.0984
	sim_grads_norm = 0.0132
-- Starting training on experience 170 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4130
	data_grads_norm = 4.5290
	new_data_grads_norm = 6.8507
	old_data_grads_norm = 6.1293
	sim_grads_norm = 0.0102
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4349
	data_grads_norm = 3.4444
	new_data_grads_norm = 6.1358
	old_data_grads_norm = 3.7873
	sim_grads_norm = -0.0429
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6740
	data_grads_norm = 4.1789
	new_data_grads_norm = 6.1428
	old_data_grads_norm = 6.1708
	sim_grads_norm = 0.0032
-- Starting training on experience 171 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6663
	data_grads_norm = 4.7406
	new_data_grads_norm = 6.7143
	old_data_grads_norm = 5.2803
	sim_grads_norm = -0.0064
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1312
	data_grads_norm = 5.4457
	new_data_grads_norm = 7.3177
	old_data_grads_norm = 6.4050
	sim_grads_norm = 0.0124
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5687
	data_grads_norm = 4.6768
	new_data_grads_norm = 7.9087
	old_data_grads_norm = 5.0714
	sim_grads_norm = 0.0262
-- Starting training on experience 172 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0536
	data_grads_norm = 4.0221
	new_data_grads_norm = 6.5353
	old_data_grads_norm = 3.4336
	sim_grads_norm = -0.0025
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5002
	data_grads_norm = 4.9042
	new_data_grads_norm = 7.1774
	old_data_grads_norm = 6.7201
	sim_grads_norm = -0.0052
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0609
	data_grads_norm = 4.2455
	new_data_grads_norm = 6.4295
	old_data_grads_norm = 5.2901
	sim_grads_norm = 0.0438
-- Starting training on experience 173 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1560
	data_grads_norm = 4.5870
	new_data_grads_norm = 7.1119
	old_data_grads_norm = 5.1273
	sim_grads_norm = 0.0035
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1275
	data_grads_norm = 4.3040
	new_data_grads_norm = 6.8620
	old_data_grads_norm = 5.4111
	sim_grads_norm = -0.0502
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0646
	data_grads_norm = 4.3018
	new_data_grads_norm = 7.1689
	old_data_grads_norm = 4.3623
	sim_grads_norm = -0.0323
-- Starting training on experience 174 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6077
	data_grads_norm = 5.2891
	new_data_grads_norm = 7.8367
	old_data_grads_norm = 6.0045
	sim_grads_norm = -0.0078
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1767
	data_grads_norm = 4.9446
	new_data_grads_norm = 7.9756
	old_data_grads_norm = 5.3762
	sim_grads_norm = 0.0003
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6691
	data_grads_norm = 5.5146
	new_data_grads_norm = 7.4204
	old_data_grads_norm = 6.5743
	sim_grads_norm = 0.1326
-- Starting training on experience 175 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4257
	data_grads_norm = 5.7622
	new_data_grads_norm = 8.8079
	old_data_grads_norm = 5.3970
	sim_grads_norm = -0.0114
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3204
	data_grads_norm = 5.3351
	new_data_grads_norm = 9.3666
	old_data_grads_norm = 5.2223
	sim_grads_norm = -0.0256
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2167
	data_grads_norm = 4.7568
	new_data_grads_norm = 7.5898
	old_data_grads_norm = 5.6984
	sim_grads_norm = -0.0036
-- Starting training on experience 176 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7401
	data_grads_norm = 4.0169
	new_data_grads_norm = 6.1036
	old_data_grads_norm = 5.4364
	sim_grads_norm = -0.0467
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5374
	data_grads_norm = 5.1726
	new_data_grads_norm = 8.7592
	old_data_grads_norm = 6.2653
	sim_grads_norm = 0.0661
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1776
	data_grads_norm = 4.7536
	new_data_grads_norm = 7.7421
	old_data_grads_norm = 5.2860
	sim_grads_norm = -0.0142
-- Starting training on experience 177 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9472
	data_grads_norm = 4.5741
	new_data_grads_norm = 6.6471
	old_data_grads_norm = 5.6317
	sim_grads_norm = 0.0115
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1772
	data_grads_norm = 4.9231
	new_data_grads_norm = 7.3160
	old_data_grads_norm = 5.9915
	sim_grads_norm = 0.0131
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9595
	data_grads_norm = 4.6242
	new_data_grads_norm = 6.7763
	old_data_grads_norm = 5.0232
	sim_grads_norm = 0.0545
-- Starting training on experience 178 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4338
	data_grads_norm = 5.1554
	new_data_grads_norm = 9.4211
	old_data_grads_norm = 3.7219
	sim_grads_norm = -0.0385
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6525
	data_grads_norm = 6.0052
	new_data_grads_norm = 10.6064
	old_data_grads_norm = 6.6288
	sim_grads_norm = 0.0002
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4772
	data_grads_norm = 5.5056
	new_data_grads_norm = 9.8758
	old_data_grads_norm = 3.2194
	sim_grads_norm = 0.1374
-- Starting training on experience 179 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1303
	data_grads_norm = 4.6395
	new_data_grads_norm = 6.8942
	old_data_grads_norm = 6.8103
	sim_grads_norm = 0.0107
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9549
	data_grads_norm = 4.3752
	new_data_grads_norm = 6.8753
	old_data_grads_norm = 6.1091
	sim_grads_norm = 0.0124
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4843
	data_grads_norm = 5.0700
	new_data_grads_norm = 7.5281
	old_data_grads_norm = 5.7145
	sim_grads_norm = 0.1267
-- Starting training on experience 180 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1618
	data_grads_norm = 5.0934
	new_data_grads_norm = 6.2962
	old_data_grads_norm = 6.4080
	sim_grads_norm = 0.0246
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9286
	data_grads_norm = 4.6150
	new_data_grads_norm = 6.4424
	old_data_grads_norm = 6.0908
	sim_grads_norm = 0.0316
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8570
	data_grads_norm = 4.4452
	new_data_grads_norm = 6.1646
	old_data_grads_norm = 5.1823
	sim_grads_norm = 0.0884
-- Starting training on experience 181 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8223
	data_grads_norm = 3.6591
	new_data_grads_norm = 5.4666
	old_data_grads_norm = 4.1975
	sim_grads_norm = -0.0188
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8009
	data_grads_norm = 3.6035
	new_data_grads_norm = 5.3508
	old_data_grads_norm = 4.6215
	sim_grads_norm = -0.0054
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6587
	data_grads_norm = 3.9148
	new_data_grads_norm = 5.8082
	old_data_grads_norm = 4.9390
	sim_grads_norm = -0.0024
-- Starting training on experience 182 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0339
	data_grads_norm = 4.9702
	new_data_grads_norm = 7.7081
	old_data_grads_norm = 6.0224
	sim_grads_norm = -0.0048
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0849
	data_grads_norm = 4.1577
	new_data_grads_norm = 7.6699
	old_data_grads_norm = 4.0133
	sim_grads_norm = 0.0362
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9006
	data_grads_norm = 4.7551
	new_data_grads_norm = 6.9312
	old_data_grads_norm = 5.8331
	sim_grads_norm = -0.0369
-- Starting training on experience 183 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6653
	data_grads_norm = 4.0706
	new_data_grads_norm = 6.4715
	old_data_grads_norm = 2.9078
	sim_grads_norm = 0.0208
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8274
	data_grads_norm = 4.4718
	new_data_grads_norm = 7.3143
	old_data_grads_norm = 5.7512
	sim_grads_norm = 0.0675
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7238
	data_grads_norm = 4.1874
	new_data_grads_norm = 6.2478
	old_data_grads_norm = 5.7491
	sim_grads_norm = -0.0111
-- Starting training on experience 184 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0479
	data_grads_norm = 4.6697
	new_data_grads_norm = 7.4325
	old_data_grads_norm = 4.4832
	sim_grads_norm = 0.0241
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4990
	data_grads_norm = 5.1009
	new_data_grads_norm = 7.4512
	old_data_grads_norm = 5.5842
	sim_grads_norm = -0.0165
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1461
	data_grads_norm = 4.4139
	new_data_grads_norm = 8.4372
	old_data_grads_norm = 4.3304
	sim_grads_norm = -0.0049
-- Starting training on experience 185 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2010
	data_grads_norm = 4.9716
	new_data_grads_norm = 6.9315
	old_data_grads_norm = 6.0579
	sim_grads_norm = -0.0084
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0339
	data_grads_norm = 4.0321
	new_data_grads_norm = 7.9628
	old_data_grads_norm = 2.9281
	sim_grads_norm = -0.0081
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5634
	data_grads_norm = 4.8787
	new_data_grads_norm = 7.2871
	old_data_grads_norm = 6.4091
	sim_grads_norm = -0.0262
-- Starting training on experience 186 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3870
	data_grads_norm = 4.6782
	new_data_grads_norm = 8.3402
	old_data_grads_norm = 4.7577
	sim_grads_norm = -0.0093
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6485
	data_grads_norm = 5.2245
	new_data_grads_norm = 9.3635
	old_data_grads_norm = 6.2475
	sim_grads_norm = 0.0402
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8551
	data_grads_norm = 4.9937
	new_data_grads_norm = 8.2197
	old_data_grads_norm = 4.6073
	sim_grads_norm = -0.0003
-- Starting training on experience 187 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9583
	data_grads_norm = 4.1575
	new_data_grads_norm = 6.9856
	old_data_grads_norm = 3.6508
	sim_grads_norm = 0.0273
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2935
	data_grads_norm = 5.4587
	new_data_grads_norm = 8.1094
	old_data_grads_norm = 6.1034
	sim_grads_norm = -0.0036
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4619
	data_grads_norm = 5.0011
	new_data_grads_norm = 7.5386
	old_data_grads_norm = 5.4565
	sim_grads_norm = -0.0023
-- Starting training on experience 188 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2126
	data_grads_norm = 5.1479
	new_data_grads_norm = 5.7087
	old_data_grads_norm = 6.6482
	sim_grads_norm = -0.0299
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0130
	data_grads_norm = 4.5904
	new_data_grads_norm = 5.9056
	old_data_grads_norm = 5.8248
	sim_grads_norm = 0.0484
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3714
	data_grads_norm = 4.8538
	new_data_grads_norm = 6.2577
	old_data_grads_norm = 5.6190
	sim_grads_norm = 0.0009
-- Starting training on experience 189 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5258
	data_grads_norm = 5.9741
	new_data_grads_norm = 9.4844
	old_data_grads_norm = 6.3626
	sim_grads_norm = 0.0134
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7881
	data_grads_norm = 6.0393
	new_data_grads_norm = 9.6195
	old_data_grads_norm = 6.5282
	sim_grads_norm = 0.0383
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6459
	data_grads_norm = 6.0320
	new_data_grads_norm = 8.9024
	old_data_grads_norm = 7.3078
	sim_grads_norm = -0.0158
-- Starting training on experience 190 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8734
	data_grads_norm = 4.1150
	new_data_grads_norm = 5.8739
	old_data_grads_norm = 5.5958
	sim_grads_norm = 0.0490
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8952
	data_grads_norm = 3.7215
	new_data_grads_norm = 5.3950
	old_data_grads_norm = 4.8649
	sim_grads_norm = -0.0181
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2535
	data_grads_norm = 4.5649
	new_data_grads_norm = 5.7253
	old_data_grads_norm = 6.7019
	sim_grads_norm = -0.0113
-- Starting training on experience 191 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4068
	data_grads_norm = 5.7856
	new_data_grads_norm = 8.0947
	old_data_grads_norm = 6.8744
	sim_grads_norm = 0.0005
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3990
	data_grads_norm = 4.6714
	new_data_grads_norm = 7.8640
	old_data_grads_norm = 5.8437
	sim_grads_norm = 0.0124
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4366
	data_grads_norm = 5.7009
	new_data_grads_norm = 8.6718
	old_data_grads_norm = 7.0338
	sim_grads_norm = -0.0022
-- Starting training on experience 192 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0141
	data_grads_norm = 4.0537
	new_data_grads_norm = 5.8828
	old_data_grads_norm = 5.1947
	sim_grads_norm = 0.0165
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1624
	data_grads_norm = 4.3429
	new_data_grads_norm = 5.7884
	old_data_grads_norm = 5.9279
	sim_grads_norm = 0.0191
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7814
	data_grads_norm = 4.0278
	new_data_grads_norm = 5.5608
	old_data_grads_norm = 4.0723
	sim_grads_norm = -0.0202
-- Starting training on experience 193 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0807
	data_grads_norm = 4.3435
	new_data_grads_norm = 7.4597
	old_data_grads_norm = 3.8984
	sim_grads_norm = -0.0245
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4799
	data_grads_norm = 6.2141
	new_data_grads_norm = 8.2427
	old_data_grads_norm = 7.7663
	sim_grads_norm = 0.0122
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9540
	data_grads_norm = 4.8530
	new_data_grads_norm = 7.0551
	old_data_grads_norm = 6.7071
	sim_grads_norm = 0.0345
-- Starting training on experience 194 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1004
	data_grads_norm = 3.8444
	new_data_grads_norm = 6.7670
	old_data_grads_norm = 4.3248
	sim_grads_norm = -0.0312
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8305
	data_grads_norm = 5.3837
	new_data_grads_norm = 7.4209
	old_data_grads_norm = 6.2139
	sim_grads_norm = 0.0683
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0013
	data_grads_norm = 4.1608
	new_data_grads_norm = 6.7838
	old_data_grads_norm = 4.2116
	sim_grads_norm = 0.0504
-- Starting training on experience 195 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9694
	data_grads_norm = 4.5211
	new_data_grads_norm = 8.8847
	old_data_grads_norm = 6.2393
	sim_grads_norm = -0.0170
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2286
	data_grads_norm = 5.2176
	new_data_grads_norm = 7.1922
	old_data_grads_norm = 6.7515
	sim_grads_norm = -0.0066
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6064
	data_grads_norm = 3.9101
	new_data_grads_norm = 6.8748
	old_data_grads_norm = 4.7588
	sim_grads_norm = -0.0218
-- Starting training on experience 196 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9060
	data_grads_norm = 3.7829
	new_data_grads_norm = 7.7375
	old_data_grads_norm = 1.8364
	sim_grads_norm = -0.0086
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8535
	data_grads_norm = 5.2369
	new_data_grads_norm = 6.5973
	old_data_grads_norm = 7.6144
	sim_grads_norm = -0.0530
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1760
	data_grads_norm = 4.1870
	new_data_grads_norm = 7.5231
	old_data_grads_norm = 2.7072
	sim_grads_norm = 0.0567
-- Starting training on experience 197 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4805
	data_grads_norm = 4.4701
	new_data_grads_norm = 7.1004
	old_data_grads_norm = 5.2475
	sim_grads_norm = 0.0225
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0789
	data_grads_norm = 4.6059
	new_data_grads_norm = 7.3494
	old_data_grads_norm = 4.3647
	sim_grads_norm = -0.0084
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1534
	data_grads_norm = 5.1680
	new_data_grads_norm = 7.6713
	old_data_grads_norm = 4.7601
	sim_grads_norm = 0.0413
-- Starting training on experience 198 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7667
	data_grads_norm = 4.0789
	new_data_grads_norm = 7.3226
	old_data_grads_norm = 4.9548
	sim_grads_norm = -0.0087
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4342
	data_grads_norm = 4.4651
	new_data_grads_norm = 7.4210
	old_data_grads_norm = 4.7464
	sim_grads_norm = 0.0084
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0680
	data_grads_norm = 4.3849
	new_data_grads_norm = 6.6938
	old_data_grads_norm = 5.1937
	sim_grads_norm = 0.0525
-- Starting training on experience 199 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1338
	data_grads_norm = 4.3787
	new_data_grads_norm = 5.7449
	old_data_grads_norm = 6.0249
	sim_grads_norm = 0.0444
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8819
	data_grads_norm = 4.2694
	new_data_grads_norm = 7.3896
	old_data_grads_norm = 4.0301
	sim_grads_norm = 0.0333
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3476
	data_grads_norm = 4.3269
	new_data_grads_norm = 6.7899
	old_data_grads_norm = 5.3021
	sim_grads_norm = -0.0136
-- Starting training on experience 200 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3755
	data_grads_norm = 4.5489
	new_data_grads_norm = 6.3192
	old_data_grads_norm = 6.5595
	sim_grads_norm = -0.0208
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9192
	data_grads_norm = 5.4272
	new_data_grads_norm = 6.6471
	old_data_grads_norm = 7.8546
	sim_grads_norm = -0.0360
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9116
	data_grads_norm = 5.6699
	new_data_grads_norm = 7.0320
	old_data_grads_norm = 5.4253
	sim_grads_norm = 0.0162
-- Starting training on experience 201 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2310
	data_grads_norm = 4.4642
	new_data_grads_norm = 6.8783
	old_data_grads_norm = 4.7263
	sim_grads_norm = 0.0138
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1282
	data_grads_norm = 4.4525
	new_data_grads_norm = 6.4167
	old_data_grads_norm = 6.2513
	sim_grads_norm = 0.0963
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1671
	data_grads_norm = 4.2153
	new_data_grads_norm = 5.9568
	old_data_grads_norm = 5.8338
	sim_grads_norm = -0.0278
-- Starting training on experience 202 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0686
	data_grads_norm = 3.7328
	new_data_grads_norm = 6.8997
	old_data_grads_norm = 3.6760
	sim_grads_norm = 0.0097
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7430
	data_grads_norm = 5.5933
	new_data_grads_norm = 6.9454
	old_data_grads_norm = 8.1617
	sim_grads_norm = -0.0196
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6542
	data_grads_norm = 5.1125
	new_data_grads_norm = 6.6400
	old_data_grads_norm = 6.5693
	sim_grads_norm = 0.0947
-- Starting training on experience 203 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1821
	data_grads_norm = 4.3002
	new_data_grads_norm = 6.5350
	old_data_grads_norm = 4.4232
	sim_grads_norm = 0.0281
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7635
	data_grads_norm = 4.0601
	new_data_grads_norm = 7.1058
	old_data_grads_norm = 7.2414
	sim_grads_norm = -0.0095
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0038
	data_grads_norm = 4.3281
	new_data_grads_norm = 7.1935
	old_data_grads_norm = 4.2375
	sim_grads_norm = -0.0024
-- Starting training on experience 204 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1332
	data_grads_norm = 5.0618
	new_data_grads_norm = 7.6199
	old_data_grads_norm = 7.1062
	sim_grads_norm = -0.0221
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0045
	data_grads_norm = 4.6827
	new_data_grads_norm = 8.2508
	old_data_grads_norm = 6.2711
	sim_grads_norm = -0.0346
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1996
	data_grads_norm = 5.4347
	new_data_grads_norm = 7.6417
	old_data_grads_norm = 4.5591
	sim_grads_norm = 0.0203
-- Starting training on experience 205 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0971
	data_grads_norm = 4.0923
	new_data_grads_norm = 7.6622
	old_data_grads_norm = 5.3536
	sim_grads_norm = 0.0171
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7215
	data_grads_norm = 4.7019
	new_data_grads_norm = 6.3251
	old_data_grads_norm = 5.7823
	sim_grads_norm = 0.0933
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1653
	data_grads_norm = 4.6379
	new_data_grads_norm = 6.1416
	old_data_grads_norm = 6.2426
	sim_grads_norm = 0.0219
-- Starting training on experience 206 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5458
	data_grads_norm = 5.6855
	new_data_grads_norm = 6.6994
	old_data_grads_norm = 7.5964
	sim_grads_norm = 0.0259
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2439
	data_grads_norm = 4.1684
	new_data_grads_norm = 6.4658
	old_data_grads_norm = 5.2028
	sim_grads_norm = 0.0198
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0023
	data_grads_norm = 3.8334
	new_data_grads_norm = 5.7584
	old_data_grads_norm = 5.6321
	sim_grads_norm = 0.0112
-- Starting training on experience 207 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6474
	data_grads_norm = 3.7626
	new_data_grads_norm = 6.3471
	old_data_grads_norm = 2.9797
	sim_grads_norm = 0.0350
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1104
	data_grads_norm = 4.8189
	new_data_grads_norm = 6.4930
	old_data_grads_norm = 7.2082
	sim_grads_norm = 0.0133
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0700
	data_grads_norm = 3.9467
	new_data_grads_norm = 6.2358
	old_data_grads_norm = 4.4414
	sim_grads_norm = -0.0176
-- Starting training on experience 208 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3999
	data_grads_norm = 3.8210
	new_data_grads_norm = 7.3918
	old_data_grads_norm = 3.7967
	sim_grads_norm = -0.0296
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6010
	data_grads_norm = 4.2571
	new_data_grads_norm = 7.1426
	old_data_grads_norm = 5.0103
	sim_grads_norm = 0.0147
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7646
	data_grads_norm = 4.4473
	new_data_grads_norm = 6.7042
	old_data_grads_norm = 4.5664
	sim_grads_norm = -0.0331
-- Starting training on experience 209 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2958
	data_grads_norm = 4.0187
	new_data_grads_norm = 5.9852
	old_data_grads_norm = 5.0912
	sim_grads_norm = 0.0176
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3475
	data_grads_norm = 4.3914
	new_data_grads_norm = 6.0081
	old_data_grads_norm = 5.2954
	sim_grads_norm = 0.1070
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7322
	data_grads_norm = 3.8033
	new_data_grads_norm = 5.3268
	old_data_grads_norm = 4.2245
	sim_grads_norm = -0.0091
-- Starting training on experience 210 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0028
	data_grads_norm = 4.2007
	new_data_grads_norm = 6.9276
	old_data_grads_norm = 5.0836
	sim_grads_norm = 0.0249
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9074
	data_grads_norm = 3.9836
	new_data_grads_norm = 7.1033
	old_data_grads_norm = 4.3743
	sim_grads_norm = 0.0106
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9510
	data_grads_norm = 4.2744
	new_data_grads_norm = 6.2854
	old_data_grads_norm = 6.2482
	sim_grads_norm = -0.0523
-- Starting training on experience 211 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1209
	data_grads_norm = 4.6266
	new_data_grads_norm = 7.5910
	old_data_grads_norm = 4.9181
	sim_grads_norm = 0.0116
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1064
	data_grads_norm = 4.3632
	new_data_grads_norm = 6.5465
	old_data_grads_norm = 6.1973
	sim_grads_norm = 0.0085
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9564
	data_grads_norm = 4.0728
	new_data_grads_norm = 7.0670
	old_data_grads_norm = 4.6682
	sim_grads_norm = -0.0359
-- Starting training on experience 212 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5113
	data_grads_norm = 4.8210
	new_data_grads_norm = 6.1505
	old_data_grads_norm = 6.9866
	sim_grads_norm = -0.0141
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4828
	data_grads_norm = 4.8953
	new_data_grads_norm = 6.2087
	old_data_grads_norm = 6.4406
	sim_grads_norm = 0.0067
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8590
	data_grads_norm = 4.7958
	new_data_grads_norm = 5.9944
	old_data_grads_norm = 6.5236
	sim_grads_norm = 0.0005
-- Starting training on experience 213 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9753
	data_grads_norm = 3.9130
	new_data_grads_norm = 6.8858
	old_data_grads_norm = 5.3877
	sim_grads_norm = -0.0213
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9371
	data_grads_norm = 3.8630
	new_data_grads_norm = 6.8741
	old_data_grads_norm = 4.1834
	sim_grads_norm = 0.0204
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1510
	data_grads_norm = 4.2043
	new_data_grads_norm = 6.3177
	old_data_grads_norm = 5.1276
	sim_grads_norm = -0.0081
-- Starting training on experience 214 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0745
	data_grads_norm = 5.1481
	new_data_grads_norm = 7.1242
	old_data_grads_norm = 5.9755
	sim_grads_norm = 0.0853
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3379
	data_grads_norm = 4.3210
	new_data_grads_norm = 7.4674
	old_data_grads_norm = 5.8694
	sim_grads_norm = 0.0109
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8514
	data_grads_norm = 5.0531
	new_data_grads_norm = 7.9886
	old_data_grads_norm = 5.3095
	sim_grads_norm = 0.0075
-- Starting training on experience 215 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2641
	data_grads_norm = 4.8432
	new_data_grads_norm = 7.6439
	old_data_grads_norm = 4.8392
	sim_grads_norm = 0.0733
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1177
	data_grads_norm = 4.6847
	new_data_grads_norm = 6.6553
	old_data_grads_norm = 7.7745
	sim_grads_norm = 0.0071
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1532
	data_grads_norm = 4.6638
	new_data_grads_norm = 7.1071
	old_data_grads_norm = 5.1918
	sim_grads_norm = 0.0017
-- Starting training on experience 216 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8043
	data_grads_norm = 5.4578
	new_data_grads_norm = 7.8613
	old_data_grads_norm = 6.9453
	sim_grads_norm = -0.0458
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4751
	data_grads_norm = 4.8127
	new_data_grads_norm = 7.1127
	old_data_grads_norm = 5.4273
	sim_grads_norm = 0.0051
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2828
	data_grads_norm = 4.8897
	new_data_grads_norm = 6.6086
	old_data_grads_norm = 5.8520
	sim_grads_norm = 0.0003
-- Starting training on experience 217 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1183
	data_grads_norm = 3.9653
	new_data_grads_norm = 7.0776
	old_data_grads_norm = 4.5206
	sim_grads_norm = -0.0040
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6934
	data_grads_norm = 5.2866
	new_data_grads_norm = 6.5478
	old_data_grads_norm = 7.2113
	sim_grads_norm = -0.0045
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1827
	data_grads_norm = 4.9145
	new_data_grads_norm = 6.9466
	old_data_grads_norm = 6.5229
	sim_grads_norm = -0.0213
-- Starting training on experience 218 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1877
	data_grads_norm = 4.9871
	new_data_grads_norm = 6.7487
	old_data_grads_norm = 5.8409
	sim_grads_norm = 0.0032
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6816
	data_grads_norm = 5.1294
	new_data_grads_norm = 7.2326
	old_data_grads_norm = 5.9045
	sim_grads_norm = 0.1148
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2383
	data_grads_norm = 5.2664
	new_data_grads_norm = 7.7875
	old_data_grads_norm = 6.4224
	sim_grads_norm = -0.0059
-- Starting training on experience 219 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2544
	data_grads_norm = 4.6384
	new_data_grads_norm = 6.9219
	old_data_grads_norm = 6.0842
	sim_grads_norm = 0.0084
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8469
	data_grads_norm = 3.8678
	new_data_grads_norm = 7.4180
	old_data_grads_norm = 2.2086
	sim_grads_norm = -0.0224
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1337
	data_grads_norm = 4.1082
	new_data_grads_norm = 6.6643
	old_data_grads_norm = 4.0924
	sim_grads_norm = -0.0203
-- Starting training on experience 220 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5045
	data_grads_norm = 4.9758
	new_data_grads_norm = 7.3324
	old_data_grads_norm = 5.7914
	sim_grads_norm = -0.0237
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7995
	data_grads_norm = 5.0395
	new_data_grads_norm = 7.3405
	old_data_grads_norm = 5.1065
	sim_grads_norm = -0.0056
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5234
	data_grads_norm = 5.3397
	new_data_grads_norm = 7.4938
	old_data_grads_norm = 7.1004
	sim_grads_norm = 0.0011
-- Starting training on experience 221 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1085
	data_grads_norm = 4.2807
	new_data_grads_norm = 5.9622
	old_data_grads_norm = 5.5321
	sim_grads_norm = 0.0016
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4909
	data_grads_norm = 4.6898
	new_data_grads_norm = 6.2164
	old_data_grads_norm = 6.5313
	sim_grads_norm = -0.0058
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4299
	data_grads_norm = 4.8013
	new_data_grads_norm = 6.6342
	old_data_grads_norm = 6.8976
	sim_grads_norm = -0.0095
-- Starting training on experience 222 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4323
	data_grads_norm = 5.8751
	new_data_grads_norm = 7.6004
	old_data_grads_norm = 9.5672
	sim_grads_norm = 0.0238
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3407
	data_grads_norm = 4.8436
	new_data_grads_norm = 7.6485
	old_data_grads_norm = 4.8090
	sim_grads_norm = 0.0436
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4659
	data_grads_norm = 4.5640
	new_data_grads_norm = 7.7470
	old_data_grads_norm = 5.2191
	sim_grads_norm = 0.0069
-- Starting training on experience 223 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3210
	data_grads_norm = 5.0283
	new_data_grads_norm = 6.4526
	old_data_grads_norm = 5.5119
	sim_grads_norm = 0.0062
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5918
	data_grads_norm = 4.2311
	new_data_grads_norm = 6.0348
	old_data_grads_norm = 4.3973
	sim_grads_norm = -0.0013
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7386
	data_grads_norm = 4.5182
	new_data_grads_norm = 5.9950
	old_data_grads_norm = 4.7881
	sim_grads_norm = -0.0103
-- Starting training on experience 224 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2943
	data_grads_norm = 5.1675
	new_data_grads_norm = 8.0734
	old_data_grads_norm = 7.8485
	sim_grads_norm = -0.0157
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9582
	data_grads_norm = 4.5362
	new_data_grads_norm = 7.5761
	old_data_grads_norm = 5.1962
	sim_grads_norm = 0.0066
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1746
	data_grads_norm = 5.3372
	new_data_grads_norm = 7.7776
	old_data_grads_norm = 4.4410
	sim_grads_norm = -0.0145
-- Starting training on experience 225 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2137
	data_grads_norm = 4.2437
	new_data_grads_norm = 8.1489
	old_data_grads_norm = 3.9424
	sim_grads_norm = -0.0137
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8289
	data_grads_norm = 5.1737
	new_data_grads_norm = 8.1979
	old_data_grads_norm = 6.7238
	sim_grads_norm = -0.0096
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9802
	data_grads_norm = 5.3073
	new_data_grads_norm = 7.9110
	old_data_grads_norm = 6.9321
	sim_grads_norm = -0.0009
-- Starting training on experience 226 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6948
	data_grads_norm = 5.1381
	new_data_grads_norm = 8.2647
	old_data_grads_norm = 6.4059
	sim_grads_norm = 0.0196
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3755
	data_grads_norm = 5.0706
	new_data_grads_norm = 8.2300
	old_data_grads_norm = 6.4918
	sim_grads_norm = 0.0276
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4537
	data_grads_norm = 4.9003
	new_data_grads_norm = 7.5495
	old_data_grads_norm = 5.0472
	sim_grads_norm = 0.0383
-- Starting training on experience 227 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4124
	data_grads_norm = 4.7004
	new_data_grads_norm = 8.4771
	old_data_grads_norm = 4.9520
	sim_grads_norm = -0.0967
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9165
	data_grads_norm = 4.7780
	new_data_grads_norm = 8.6042
	old_data_grads_norm = 4.8854
	sim_grads_norm = -0.0109
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6107
	data_grads_norm = 4.6041
	new_data_grads_norm = 8.3698
	old_data_grads_norm = 4.5482
	sim_grads_norm = -0.0276
-- Starting training on experience 228 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0350
	data_grads_norm = 4.2207
	new_data_grads_norm = 8.0616
	old_data_grads_norm = 4.6286
	sim_grads_norm = 0.0192
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0753
	data_grads_norm = 4.1114
	new_data_grads_norm = 7.6879
	old_data_grads_norm = 4.5798
	sim_grads_norm = 0.0103
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4708
	data_grads_norm = 4.5098
	new_data_grads_norm = 6.4856
	old_data_grads_norm = 4.9804
	sim_grads_norm = -0.0073
-- Starting training on experience 229 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0699
	data_grads_norm = 4.6360
	new_data_grads_norm = 5.8357
	old_data_grads_norm = 5.9287
	sim_grads_norm = -0.0001
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4737
	data_grads_norm = 4.6167
	new_data_grads_norm = 6.5804
	old_data_grads_norm = 6.4597
	sim_grads_norm = 0.0139
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4661
	data_grads_norm = 5.1507
	new_data_grads_norm = 6.8110
	old_data_grads_norm = 6.2827
	sim_grads_norm = 0.0036
-- Starting training on experience 230 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8072
	data_grads_norm = 4.7642
	new_data_grads_norm = 7.3306
	old_data_grads_norm = 4.9623
	sim_grads_norm = 0.0500
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0801
	data_grads_norm = 4.3058
	new_data_grads_norm = 7.1999
	old_data_grads_norm = 4.8133
	sim_grads_norm = 0.0110
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4676
	data_grads_norm = 5.1557
	new_data_grads_norm = 7.2702
	old_data_grads_norm = 6.1392
	sim_grads_norm = -0.0240
-- Starting training on experience 231 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0379
	data_grads_norm = 4.1787
	new_data_grads_norm = 7.0890
	old_data_grads_norm = 5.3566
	sim_grads_norm = -0.0150
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2397
	data_grads_norm = 4.2641
	new_data_grads_norm = 6.8674
	old_data_grads_norm = 6.6398
	sim_grads_norm = -0.0158
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2707
	data_grads_norm = 4.9467
	new_data_grads_norm = 7.2925
	old_data_grads_norm = 4.4623
	sim_grads_norm = 0.0012
-- Starting training on experience 232 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5207
	data_grads_norm = 4.6765
	new_data_grads_norm = 7.7191
	old_data_grads_norm = 5.2658
	sim_grads_norm = 0.0117
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3646
	data_grads_norm = 4.7631
	new_data_grads_norm = 8.0298
	old_data_grads_norm = 6.3841
	sim_grads_norm = -0.0168
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2192
	data_grads_norm = 4.5307
	new_data_grads_norm = 8.1247
	old_data_grads_norm = 5.2046
	sim_grads_norm = -0.0295
-- Starting training on experience 233 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3262
	data_grads_norm = 4.1586
	new_data_grads_norm = 6.7124
	old_data_grads_norm = 6.4213
	sim_grads_norm = 0.0154
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1475
	data_grads_norm = 4.5849
	new_data_grads_norm = 6.8960
	old_data_grads_norm = 7.5560
	sim_grads_norm = 0.0101
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5158
	data_grads_norm = 4.4491
	new_data_grads_norm = 7.3798
	old_data_grads_norm = 6.0424
	sim_grads_norm = 0.0108
-- Starting training on experience 234 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3535
	data_grads_norm = 5.2089
	new_data_grads_norm = 7.1873
	old_data_grads_norm = 7.5284
	sim_grads_norm = 0.0437
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4515
	data_grads_norm = 4.9968
	new_data_grads_norm = 7.1233
	old_data_grads_norm = 6.5386
	sim_grads_norm = -0.0237
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3391
	data_grads_norm = 4.5057
	new_data_grads_norm = 7.1455
	old_data_grads_norm = 3.5487
	sim_grads_norm = 0.0870
-- Starting training on experience 235 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8884
	data_grads_norm = 3.9680
	new_data_grads_norm = 6.4552
	old_data_grads_norm = 5.4732
	sim_grads_norm = 0.0019
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3137
	data_grads_norm = 4.9386
	new_data_grads_norm = 6.7939
	old_data_grads_norm = 7.4692
	sim_grads_norm = 0.0366
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2997
	data_grads_norm = 4.8643
	new_data_grads_norm = 6.9057
	old_data_grads_norm = 5.9705
	sim_grads_norm = -0.0193
-- Starting training on experience 236 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6518
	data_grads_norm = 4.8202
	new_data_grads_norm = 7.6708
	old_data_grads_norm = 6.5035
	sim_grads_norm = 0.0001
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9937
	data_grads_norm = 5.3229
	new_data_grads_norm = 7.3465
	old_data_grads_norm = 6.5897
	sim_grads_norm = 0.0414
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6378
	data_grads_norm = 4.8321
	new_data_grads_norm = 7.7027
	old_data_grads_norm = 6.3980
	sim_grads_norm = -0.0073
-- Starting training on experience 237 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
-- >> End of training phase << --
-- >> Start of eval phase << --
-- Starting eval on experience 0 (Task 0) from test stream --
> Eval on experience 0 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp000 = 4.3921
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.2620
	mb_index = 4284
	time = 1393.3108
-- Starting eval on experience 1 (Task 0) from test stream --
> Eval on experience 1 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp001 = 2.4160
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.5420
-- Starting eval on experience 2 (Task 0) from test stream --
> Eval on experience 2 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp002 = 4.0309
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.3220
-- Starting eval on experience 3 (Task 0) from test stream --
> Eval on experience 3 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp003 = 3.3290
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.4260
-- Starting eval on experience 4 (Task 0) from test stream --
> Eval on experience 4 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp004 = 5.6842
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.1480
-- Starting eval on experience 5 (Task 0) from test stream --
> Eval on experience 5 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp005 = 3.7318
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.3720
-- Starting eval on experience 6 (Task 0) from test stream --
> Eval on experience 6 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp006 = 4.6796
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp006 = 0.1880
-- Starting eval on experience 7 (Task 0) from test stream --
> Eval on experience 7 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp007 = 4.1146
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp007 = 0.3500
-- Starting eval on experience 8 (Task 0) from test stream --
> Eval on experience 8 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp008 = 4.3435
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp008 = 0.3000
-- Starting eval on experience 9 (Task 0) from test stream --
> Eval on experience 9 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp009 = 3.3732
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp009 = 0.3260
-- Starting eval on experience 10 (Task 0) from test stream --
> Eval on experience 10 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp010 = 4.7337
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp010 = 0.2060
-- Starting eval on experience 11 (Task 0) from test stream --
> Eval on experience 11 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp011 = 3.7092
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp011 = 0.3340
-- Starting eval on experience 12 (Task 0) from test stream --
> Eval on experience 12 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp012 = 4.9597
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp012 = 0.1080
-- Starting eval on experience 13 (Task 0) from test stream --
> Eval on experience 13 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp013 = 3.4871
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp013 = 0.3140
-- Starting eval on experience 14 (Task 0) from test stream --
> Eval on experience 14 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp014 = 3.2488
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp014 = 0.3080
-- Starting eval on experience 15 (Task 0) from test stream --
> Eval on experience 15 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp015 = 2.8965
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp015 = 0.3180
-- Starting eval on experience 16 (Task 0) from test stream --
> Eval on experience 16 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp016 = 3.0762
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp016 = 0.2460
-- Starting eval on experience 17 (Task 0) from test stream --
> Eval on experience 17 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp017 = 4.2131
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp017 = 0.0620
-- >> End of eval phase << --
	CumulativeAccuracy/eval_phase/test_stream/Exp000 = 0.7460
	CumulativeAccuracy/eval_phase/test_stream/Exp001 = 0.6970
	CumulativeAccuracy/eval_phase/test_stream/Exp002 = 0.5833
	CumulativeAccuracy/eval_phase/test_stream/Exp003 = 0.5655
	CumulativeAccuracy/eval_phase/test_stream/Exp004 = 0.5136
	CumulativeAccuracy/eval_phase/test_stream/Exp005 = 0.4813
	CumulativeAccuracy/eval_phase/test_stream/Exp006 = 0.4391
	CumulativeAccuracy/eval_phase/test_stream/Exp007 = 0.4190
	CumulativeAccuracy/eval_phase/test_stream/Exp008 = 0.3993
	CumulativeAccuracy/eval_phase/test_stream/Exp009 = 0.3896
	CumulativeAccuracy/eval_phase/test_stream/Exp010 = 0.3680
	CumulativeAccuracy/eval_phase/test_stream/Exp011 = 0.3637
	CumulativeAccuracy/eval_phase/test_stream/Exp012 = 0.3415
	CumulativeAccuracy/eval_phase/test_stream/Exp013 = 0.3299
	CumulativeAccuracy/eval_phase/test_stream/Exp014 = 0.3167
	CumulativeAccuracy/eval_phase/test_stream/Exp015 = 0.3104
	CumulativeAccuracy/eval_phase/test_stream/Exp016 = 0.2984
	CumulativeAccuracy/eval_phase/test_stream/Exp017 = 0.2851
	Loss_Stream/eval_phase/test_stream/Task000 = 3.9122
	Top1_Acc_Stream/eval_phase/test_stream/Task000 = 0.2851
-- >> Start of training phase << --
-- Starting training on experience 0 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.1168
	data_grads_norm = 5.3921
	new_data_grads_norm = 8.9101
	old_data_grads_norm = 5.9792
	sim_grads_norm = -0.0139
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.7133
	data_grads_norm = 5.2807
	new_data_grads_norm = 7.5719
	old_data_grads_norm = 5.3723
	sim_grads_norm = -0.0022
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.0306
	data_grads_norm = 5.1295
	new_data_grads_norm = 7.5031
	old_data_grads_norm = 4.9994
	sim_grads_norm = -0.0086
-- Starting training on experience 1 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6501
	data_grads_norm = 4.4421
	new_data_grads_norm = 7.0405
	old_data_grads_norm = 2.8783
	sim_grads_norm = 0.0074
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.2162
	data_grads_norm = 4.9771
	new_data_grads_norm = 7.5732
	old_data_grads_norm = 6.0908
	sim_grads_norm = -0.0260
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.8669
	data_grads_norm = 4.7025
	new_data_grads_norm = 7.4737
	old_data_grads_norm = 4.5838
	sim_grads_norm = 0.0197
-- Starting training on experience 2 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3664
	data_grads_norm = 4.5264
	new_data_grads_norm = 7.9206
	old_data_grads_norm = 4.3367
	sim_grads_norm = -0.0054
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.9644
	data_grads_norm = 5.0832
	new_data_grads_norm = 8.4616
	old_data_grads_norm = 4.5304
	sim_grads_norm = 0.0292
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.7610
	data_grads_norm = 5.1275
	new_data_grads_norm = 7.2864
	old_data_grads_norm = 6.5026
	sim_grads_norm = -0.0040
-- Starting training on experience 3 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.1136
	data_grads_norm = 5.3170
	new_data_grads_norm = 7.1280
	old_data_grads_norm = 6.3552
	sim_grads_norm = 0.0240
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6912
	data_grads_norm = 4.7250
	new_data_grads_norm = 7.8478
	old_data_grads_norm = 4.0959
	sim_grads_norm = 0.0581
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.0683
	data_grads_norm = 6.0285
	new_data_grads_norm = 7.3350
	old_data_grads_norm = 8.4566
	sim_grads_norm = 0.0188
-- Starting training on experience 4 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4122
	data_grads_norm = 4.7094
	new_data_grads_norm = 6.7806
	old_data_grads_norm = 4.1414
	sim_grads_norm = -0.0228
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.1514
	data_grads_norm = 5.9322
	new_data_grads_norm = 7.3252
	old_data_grads_norm = 8.2166
	sim_grads_norm = 0.0053
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6718
	data_grads_norm = 4.9201
	new_data_grads_norm = 7.4346
	old_data_grads_norm = 6.7856
	sim_grads_norm = 0.0009
-- Starting training on experience 5 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6714
	data_grads_norm = 4.6381
	new_data_grads_norm = 6.7678
	old_data_grads_norm = 6.2313
	sim_grads_norm = 0.0149
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.7035
	data_grads_norm = 4.4055
	new_data_grads_norm = 7.0350
	old_data_grads_norm = 4.3516
	sim_grads_norm = 0.0375
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3515
	data_grads_norm = 4.4893
	new_data_grads_norm = 7.5856
	old_data_grads_norm = 5.5017
	sim_grads_norm = -0.0138
-- Starting training on experience 6 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.8796
	data_grads_norm = 4.7158
	new_data_grads_norm = 7.1338
	old_data_grads_norm = 2.5437
	sim_grads_norm = 0.1489
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.7325
	data_grads_norm = 5.2530
	new_data_grads_norm = 6.8995
	old_data_grads_norm = 7.9612
	sim_grads_norm = -0.0100
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.1981
	data_grads_norm = 5.1567
	new_data_grads_norm = 7.1969
	old_data_grads_norm = 7.4072
	sim_grads_norm = -0.0302
-- Starting training on experience 7 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.7929
	data_grads_norm = 5.6359
	new_data_grads_norm = 8.1234
	old_data_grads_norm = 4.1367
	sim_grads_norm = 0.0120
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4945
	data_grads_norm = 4.7846
	new_data_grads_norm = 8.3729
	old_data_grads_norm = 3.8251
	sim_grads_norm = 0.0345
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.1794
	data_grads_norm = 5.0185
	new_data_grads_norm = 7.1089
	old_data_grads_norm = 5.6541
	sim_grads_norm = 0.0039
-- Starting training on experience 8 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.7930
	data_grads_norm = 5.6496
	new_data_grads_norm = 7.3819
	old_data_grads_norm = 5.9937
	sim_grads_norm = 0.0399
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2451
	data_grads_norm = 4.5087
	new_data_grads_norm = 7.6738
	old_data_grads_norm = 4.3599
	sim_grads_norm = 0.0012
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3076
	data_grads_norm = 5.3074
	new_data_grads_norm = 8.4292
	old_data_grads_norm = 4.7643
	sim_grads_norm = 0.0249
-- Starting training on experience 9 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.9651
	data_grads_norm = 5.9285
	new_data_grads_norm = 7.6209
	old_data_grads_norm = 6.4663
	sim_grads_norm = 0.0152
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.3104
	data_grads_norm = 5.4034
	new_data_grads_norm = 7.7719
	old_data_grads_norm = 6.0187
	sim_grads_norm = 0.0432
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.5378
	data_grads_norm = 5.8124
	new_data_grads_norm = 8.1033
	old_data_grads_norm = 5.9919
	sim_grads_norm = 0.1272
-- Starting training on experience 10 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.7785
	data_grads_norm = 5.1116
	new_data_grads_norm = 8.4789
	old_data_grads_norm = 5.3214
	sim_grads_norm = -0.0259
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6683
	data_grads_norm = 4.5692
	new_data_grads_norm = 8.6986
	old_data_grads_norm = 3.8370
	sim_grads_norm = 0.1118
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1429
	data_grads_norm = 4.4273
	new_data_grads_norm = 7.3536
	old_data_grads_norm = 4.9205
	sim_grads_norm = -0.0114
-- Starting training on experience 11 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.1216
	data_grads_norm = 5.2812
	new_data_grads_norm = 7.0528
	old_data_grads_norm = 5.4868
	sim_grads_norm = 0.0045
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.4076
	data_grads_norm = 5.0236
	new_data_grads_norm = 7.7291
	old_data_grads_norm = 4.7157
	sim_grads_norm = 0.0124
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4124
	data_grads_norm = 3.9805
	new_data_grads_norm = 6.8588
	old_data_grads_norm = 5.1912
	sim_grads_norm = 0.0102
-- Starting training on experience 12 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.3277
	data_grads_norm = 5.6575
	new_data_grads_norm = 7.6141
	old_data_grads_norm = 6.1736
	sim_grads_norm = 0.1533
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2584
	data_grads_norm = 4.8149
	new_data_grads_norm = 7.4038
	old_data_grads_norm = 4.8402
	sim_grads_norm = -0.0198
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3745
	data_grads_norm = 4.6780
	new_data_grads_norm = 7.9504
	old_data_grads_norm = 4.2345
	sim_grads_norm = 0.0016
-- Starting training on experience 13 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4597
	data_grads_norm = 5.0233
	new_data_grads_norm = 7.0930
	old_data_grads_norm = 5.8133
	sim_grads_norm = 0.0050
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0332
	data_grads_norm = 4.1387
	new_data_grads_norm = 6.5832
	old_data_grads_norm = 4.0131
	sim_grads_norm = 0.0310
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1638
	data_grads_norm = 4.2343
	new_data_grads_norm = 6.7452
	old_data_grads_norm = 5.2519
	sim_grads_norm = 0.0212
-- Starting training on experience 14 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3484
	data_grads_norm = 4.6549
	new_data_grads_norm = 6.6454
	old_data_grads_norm = 6.0124
	sim_grads_norm = 0.0028
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5626
	data_grads_norm = 4.5582
	new_data_grads_norm = 6.3713
	old_data_grads_norm = 4.9887
	sim_grads_norm = 0.0197
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7922
	data_grads_norm = 3.7116
	new_data_grads_norm = 6.1624
	old_data_grads_norm = 3.6963
	sim_grads_norm = 0.0104
-- Starting training on experience 15 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2336
	data_grads_norm = 4.5796
	new_data_grads_norm = 7.0903
	old_data_grads_norm = 4.4683
	sim_grads_norm = 0.0865
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3487
	data_grads_norm = 4.8262
	new_data_grads_norm = 6.9701
	old_data_grads_norm = 5.5274
	sim_grads_norm = -0.0067
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.1280
	data_grads_norm = 4.9965
	new_data_grads_norm = 6.4825
	old_data_grads_norm = 7.8754
	sim_grads_norm = 0.0489
-- Starting training on experience 16 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1641
	data_grads_norm = 4.7832
	new_data_grads_norm = 7.3727
	old_data_grads_norm = 5.2719
	sim_grads_norm = 0.0086
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1593
	data_grads_norm = 4.6586
	new_data_grads_norm = 7.0356
	old_data_grads_norm = 5.4877
	sim_grads_norm = -0.0181
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6613
	data_grads_norm = 5.2516
	new_data_grads_norm = 8.0171
	old_data_grads_norm = 5.5945
	sim_grads_norm = 0.0035
-- Starting training on experience 17 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7306
	data_grads_norm = 4.6573
	new_data_grads_norm = 9.1007
	old_data_grads_norm = 4.6878
	sim_grads_norm = -0.0105
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.7999
	data_grads_norm = 6.1232
	new_data_grads_norm = 8.9443
	old_data_grads_norm = 7.3763
	sim_grads_norm = 0.0538
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5756
	data_grads_norm = 6.0364
	new_data_grads_norm = 7.6605
	old_data_grads_norm = 8.5357
	sim_grads_norm = 0.0275
-- Starting training on experience 18 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3035
	data_grads_norm = 4.2151
	new_data_grads_norm = 6.4812
	old_data_grads_norm = 4.5936
	sim_grads_norm = 0.0001
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3081
	data_grads_norm = 4.9904
	new_data_grads_norm = 7.2359
	old_data_grads_norm = 5.0692
	sim_grads_norm = 0.1547
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0424
	data_grads_norm = 4.2620
	new_data_grads_norm = 8.3259
	old_data_grads_norm = 3.3649
	sim_grads_norm = -0.0053
-- Starting training on experience 19 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3376
	data_grads_norm = 4.1440
	new_data_grads_norm = 7.0781
	old_data_grads_norm = 4.5342
	sim_grads_norm = 0.1101
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1082
	data_grads_norm = 4.4513
	new_data_grads_norm = 7.2598
	old_data_grads_norm = 5.2130
	sim_grads_norm = -0.0286
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2758
	data_grads_norm = 5.0289
	new_data_grads_norm = 6.7371
	old_data_grads_norm = 6.1613
	sim_grads_norm = -0.0436
-- Starting training on experience 20 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9706
	data_grads_norm = 4.7833
	new_data_grads_norm = 7.5483
	old_data_grads_norm = 5.6924
	sim_grads_norm = 0.0110
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0899
	data_grads_norm = 5.0505
	new_data_grads_norm = 8.6613
	old_data_grads_norm = 5.3729
	sim_grads_norm = 0.0038
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1718
	data_grads_norm = 5.5328
	new_data_grads_norm = 7.5733
	old_data_grads_norm = 6.1360
	sim_grads_norm = 0.0357
-- Starting training on experience 21 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2342
	data_grads_norm = 4.2952
	new_data_grads_norm = 5.9735
	old_data_grads_norm = 5.3327
	sim_grads_norm = 0.0053
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5488
	data_grads_norm = 4.3492
	new_data_grads_norm = 6.3426
	old_data_grads_norm = 5.0810
	sim_grads_norm = 0.0370
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8827
	data_grads_norm = 3.5478
	new_data_grads_norm = 5.8337
	old_data_grads_norm = 4.6364
	sim_grads_norm = -0.0188
-- Starting training on experience 22 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6001
	data_grads_norm = 4.3442
	new_data_grads_norm = 6.6638
	old_data_grads_norm = 5.5765
	sim_grads_norm = 0.0155
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7848
	data_grads_norm = 4.8839
	new_data_grads_norm = 7.1037
	old_data_grads_norm = 5.1800
	sim_grads_norm = 0.0070
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1961
	data_grads_norm = 4.5904
	new_data_grads_norm = 7.2723
	old_data_grads_norm = 6.6551
	sim_grads_norm = 0.0139
-- Starting training on experience 23 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1372
	data_grads_norm = 6.0187
	new_data_grads_norm = 8.9942
	old_data_grads_norm = 6.7752
	sim_grads_norm = -0.0074
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0082
	data_grads_norm = 5.9468
	new_data_grads_norm = 9.5999
	old_data_grads_norm = 4.9889
	sim_grads_norm = -0.0037
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3927
	data_grads_norm = 6.2076
	new_data_grads_norm = 7.9565
	old_data_grads_norm = 6.3738
	sim_grads_norm = -0.0080
-- Starting training on experience 24 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0012
	data_grads_norm = 4.0087
	new_data_grads_norm = 6.7497
	old_data_grads_norm = 3.9748
	sim_grads_norm = 0.0152
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6900
	data_grads_norm = 5.0420
	new_data_grads_norm = 7.6942
	old_data_grads_norm = 4.4658
	sim_grads_norm = 0.0839
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0757
	data_grads_norm = 4.4874
	new_data_grads_norm = 7.4332
	old_data_grads_norm = 5.6193
	sim_grads_norm = -0.0055
-- Starting training on experience 25 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7212
	data_grads_norm = 5.3029
	new_data_grads_norm = 7.9257
	old_data_grads_norm = 6.4443
	sim_grads_norm = -0.0173
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6826
	data_grads_norm = 4.9191
	new_data_grads_norm = 9.1933
	old_data_grads_norm = 3.4653
	sim_grads_norm = 0.0211
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0852
	data_grads_norm = 5.2164
	new_data_grads_norm = 8.6073
	old_data_grads_norm = 4.1368
	sim_grads_norm = 0.0767
-- Starting training on experience 26 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1948
	data_grads_norm = 4.6476
	new_data_grads_norm = 7.1293
	old_data_grads_norm = 4.3664
	sim_grads_norm = 0.0209
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2038
	data_grads_norm = 4.7274
	new_data_grads_norm = 6.9995
	old_data_grads_norm = 4.7632
	sim_grads_norm = -0.0229
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1450
	data_grads_norm = 4.5566
	new_data_grads_norm = 7.0423
	old_data_grads_norm = 5.0528
	sim_grads_norm = 0.0067
-- Starting training on experience 27 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5812
	data_grads_norm = 5.9672
	new_data_grads_norm = 7.6266
	old_data_grads_norm = 6.5200
	sim_grads_norm = 0.0517
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6609
	data_grads_norm = 5.2079
	new_data_grads_norm = 8.1669
	old_data_grads_norm = 4.8695
	sim_grads_norm = -0.0141
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3576
	data_grads_norm = 5.6014
	new_data_grads_norm = 7.1754
	old_data_grads_norm = 6.2654
	sim_grads_norm = 0.0557
-- Starting training on experience 28 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9908
	data_grads_norm = 4.4241
	new_data_grads_norm = 6.1468
	old_data_grads_norm = 7.1878
	sim_grads_norm = 0.0646
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0182
	data_grads_norm = 4.9715
	new_data_grads_norm = 6.0694
	old_data_grads_norm = 6.2238
	sim_grads_norm = 0.0226
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9808
	data_grads_norm = 4.8982
	new_data_grads_norm = 6.0137
	old_data_grads_norm = 7.1882
	sim_grads_norm = 0.0014
-- Starting training on experience 29 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0278
	data_grads_norm = 4.4335
	new_data_grads_norm = 6.6914
	old_data_grads_norm = 4.7889
	sim_grads_norm = 0.0324
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0585
	data_grads_norm = 4.1315
	new_data_grads_norm = 5.9968
	old_data_grads_norm = 5.5320
	sim_grads_norm = 0.0133
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2517
	data_grads_norm = 4.4411
	new_data_grads_norm = 6.5743
	old_data_grads_norm = 5.8783
	sim_grads_norm = 0.0550
-- Starting training on experience 30 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0453
	data_grads_norm = 5.0204
	new_data_grads_norm = 7.3873
	old_data_grads_norm = 5.6122
	sim_grads_norm = 0.0181
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7568
	data_grads_norm = 4.7006
	new_data_grads_norm = 6.7124
	old_data_grads_norm = 4.4639
	sim_grads_norm = 0.0193
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8046
	data_grads_norm = 4.2861
	new_data_grads_norm = 7.1099
	old_data_grads_norm = 4.1326
	sim_grads_norm = 0.0314
-- Starting training on experience 31 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7861
	data_grads_norm = 3.5882
	new_data_grads_norm = 5.5588
	old_data_grads_norm = 5.1364
	sim_grads_norm = -0.0088
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1643
	data_grads_norm = 4.2485
	new_data_grads_norm = 6.5173
	old_data_grads_norm = 5.6180
	sim_grads_norm = 0.0142
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4908
	data_grads_norm = 4.6687
	new_data_grads_norm = 6.3981
	old_data_grads_norm = 6.1376
	sim_grads_norm = 0.0141
-- Starting training on experience 32 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5762
	data_grads_norm = 4.9369
	new_data_grads_norm = 8.0189
	old_data_grads_norm = 5.7405
	sim_grads_norm = 0.0633
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9562
	data_grads_norm = 4.6302
	new_data_grads_norm = 6.9702
	old_data_grads_norm = 5.9716
	sim_grads_norm = 0.0092
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6961
	data_grads_norm = 5.1122
	new_data_grads_norm = 7.1579
	old_data_grads_norm = 7.2054
	sim_grads_norm = 0.0242
-- Starting training on experience 33 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9767
	data_grads_norm = 5.3602
	new_data_grads_norm = 7.3357
	old_data_grads_norm = 6.7011
	sim_grads_norm = 0.0204
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1312
	data_grads_norm = 5.0591
	new_data_grads_norm = 5.9548
	old_data_grads_norm = 8.1759
	sim_grads_norm = 0.0269
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1400
	data_grads_norm = 4.7366
	new_data_grads_norm = 6.2051
	old_data_grads_norm = 6.3605
	sim_grads_norm = -0.0365
-- Starting training on experience 34 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8936
	data_grads_norm = 4.9373
	new_data_grads_norm = 6.3285
	old_data_grads_norm = 8.1810
	sim_grads_norm = 0.0470
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2027
	data_grads_norm = 4.6811
	new_data_grads_norm = 6.8839
	old_data_grads_norm = 6.4348
	sim_grads_norm = 0.0116
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4712
	data_grads_norm = 3.7865
	new_data_grads_norm = 6.2917
	old_data_grads_norm = 3.6653
	sim_grads_norm = 0.0771
-- Starting training on experience 35 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5832
	data_grads_norm = 4.3127
	new_data_grads_norm = 6.5619
	old_data_grads_norm = 4.8761
	sim_grads_norm = -0.0113
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1108
	data_grads_norm = 5.0988
	new_data_grads_norm = 5.8713
	old_data_grads_norm = 7.9734
	sim_grads_norm = 0.0019
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6090
	data_grads_norm = 4.5087
	new_data_grads_norm = 6.2813
	old_data_grads_norm = 4.9840
	sim_grads_norm = -0.0010
-- Starting training on experience 36 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4344
	data_grads_norm = 3.9699
	new_data_grads_norm = 7.1996
	old_data_grads_norm = 5.1318
	sim_grads_norm = 0.0010
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2326
	data_grads_norm = 3.6523
	new_data_grads_norm = 7.3619
	old_data_grads_norm = 2.4286
	sim_grads_norm = -0.0201
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4004
	data_grads_norm = 3.7493
	new_data_grads_norm = 6.4204
	old_data_grads_norm = 4.9890
	sim_grads_norm = -0.0276
-- Starting training on experience 37 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8034
	data_grads_norm = 4.3287
	new_data_grads_norm = 6.8604
	old_data_grads_norm = 3.9585
	sim_grads_norm = 0.0926
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3138
	data_grads_norm = 3.5810
	new_data_grads_norm = 6.7741
	old_data_grads_norm = 4.2366
	sim_grads_norm = 0.0132
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4419
	data_grads_norm = 3.4784
	new_data_grads_norm = 6.4798
	old_data_grads_norm = 3.9923
	sim_grads_norm = 0.0034
-- Starting training on experience 38 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5632
	data_grads_norm = 4.8954
	new_data_grads_norm = 6.2791
	old_data_grads_norm = 7.9528
	sim_grads_norm = 0.0017
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7806
	data_grads_norm = 4.8293
	new_data_grads_norm = 6.7482
	old_data_grads_norm = 6.5363
	sim_grads_norm = -0.0189
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3496
	data_grads_norm = 3.8105
	new_data_grads_norm = 6.3726
	old_data_grads_norm = 3.6900
	sim_grads_norm = 0.0625
-- Starting training on experience 39 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7291
	data_grads_norm = 4.2419
	new_data_grads_norm = 7.2142
	old_data_grads_norm = 4.1105
	sim_grads_norm = 0.0252
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6470
	data_grads_norm = 4.3950
	new_data_grads_norm = 6.4963
	old_data_grads_norm = 6.6007
	sim_grads_norm = 0.0183
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3147
	data_grads_norm = 5.1985
	new_data_grads_norm = 6.3995
	old_data_grads_norm = 7.3127
	sim_grads_norm = 0.0248
-- Starting training on experience 40 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7820
	data_grads_norm = 4.8135
	new_data_grads_norm = 6.2824
	old_data_grads_norm = 6.9147
	sim_grads_norm = -0.0046
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6607
	data_grads_norm = 4.4561
	new_data_grads_norm = 6.9059
	old_data_grads_norm = 4.8571
	sim_grads_norm = 0.0420
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6616
	data_grads_norm = 4.3928
	new_data_grads_norm = 6.2883
	old_data_grads_norm = 6.9347
	sim_grads_norm = 0.0067
-- Starting training on experience 41 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0647
	data_grads_norm = 3.7807
	new_data_grads_norm = 6.6857
	old_data_grads_norm = 5.1327
	sim_grads_norm = 0.0014
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7114
	data_grads_norm = 4.2438
	new_data_grads_norm = 7.0627
	old_data_grads_norm = 4.8015
	sim_grads_norm = -0.0376
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5791
	data_grads_norm = 3.9311
	new_data_grads_norm = 6.8011
	old_data_grads_norm = 4.5001
	sim_grads_norm = 0.0128
-- Starting training on experience 42 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6073
	data_grads_norm = 4.5524
	new_data_grads_norm = 5.7117
	old_data_grads_norm = 5.8912
	sim_grads_norm = 0.0204
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4301
	data_grads_norm = 3.6605
	new_data_grads_norm = 5.5115
	old_data_grads_norm = 3.9294
	sim_grads_norm = 0.0272
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5775
	data_grads_norm = 3.9597
	new_data_grads_norm = 5.3672
	old_data_grads_norm = 5.1214
	sim_grads_norm = -0.0179
-- Starting training on experience 43 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9970
	data_grads_norm = 3.4227
	new_data_grads_norm = 6.0091
	old_data_grads_norm = 4.3096
	sim_grads_norm = -0.0163
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2302
	data_grads_norm = 3.9426
	new_data_grads_norm = 7.1561
	old_data_grads_norm = 2.8039
	sim_grads_norm = -0.0488
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3671
	data_grads_norm = 4.0403
	new_data_grads_norm = 6.6419
	old_data_grads_norm = 3.6693
	sim_grads_norm = 0.0371
-- Starting training on experience 44 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4762
	data_grads_norm = 4.2045
	new_data_grads_norm = 5.8111
	old_data_grads_norm = 5.0040
	sim_grads_norm = -0.0104
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7027
	data_grads_norm = 4.6725
	new_data_grads_norm = 6.1854
	old_data_grads_norm = 5.2879
	sim_grads_norm = -0.0080
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8554
	data_grads_norm = 4.5561
	new_data_grads_norm = 6.9160
	old_data_grads_norm = 5.2960
	sim_grads_norm = -0.0045
-- Starting training on experience 45 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4800
	data_grads_norm = 4.1267
	new_data_grads_norm = 6.3834
	old_data_grads_norm = 4.6413
	sim_grads_norm = -0.0071
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3180
	data_grads_norm = 4.0401
	new_data_grads_norm = 6.3046
	old_data_grads_norm = 4.6711
	sim_grads_norm = 0.0023
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4438
	data_grads_norm = 4.5268
	new_data_grads_norm = 7.4314
	old_data_grads_norm = 5.0448
	sim_grads_norm = -0.0121
-- Starting training on experience 46 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6951
	data_grads_norm = 4.1778
	new_data_grads_norm = 6.8705
	old_data_grads_norm = 4.7145
	sim_grads_norm = 0.0632
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6500
	data_grads_norm = 4.9297
	new_data_grads_norm = 6.9622
	old_data_grads_norm = 4.6915
	sim_grads_norm = -0.0036
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4942
	data_grads_norm = 5.2235
	new_data_grads_norm = 6.8076
	old_data_grads_norm = 7.4337
	sim_grads_norm = 0.0030
-- Starting training on experience 47 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5133
	data_grads_norm = 4.8182
	new_data_grads_norm = 6.1628
	old_data_grads_norm = 5.7020
	sim_grads_norm = -0.0089
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1676
	data_grads_norm = 3.5841
	new_data_grads_norm = 6.6888
	old_data_grads_norm = 4.2528
	sim_grads_norm = -0.0037
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9863
	data_grads_norm = 4.3307
	new_data_grads_norm = 6.4292
	old_data_grads_norm = 5.4228
	sim_grads_norm = 0.0467
-- Starting training on experience 48 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9478
	data_grads_norm = 4.3769
	new_data_grads_norm = 6.7134
	old_data_grads_norm = 6.4435
	sim_grads_norm = 0.0852
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6134
	data_grads_norm = 4.2110
	new_data_grads_norm = 6.5614
	old_data_grads_norm = 6.0921
	sim_grads_norm = -0.0028
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6202
	data_grads_norm = 5.1165
	new_data_grads_norm = 7.0990
	old_data_grads_norm = 7.7749
	sim_grads_norm = -0.0035
-- Starting training on experience 49 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2749
	data_grads_norm = 4.5145
	new_data_grads_norm = 8.0581
	old_data_grads_norm = 4.0910
	sim_grads_norm = -0.0131
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4787
	data_grads_norm = 4.5879
	new_data_grads_norm = 6.4622
	old_data_grads_norm = 5.6579
	sim_grads_norm = 0.0287
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7082
	data_grads_norm = 5.1488
	new_data_grads_norm = 7.6868
	old_data_grads_norm = 6.9002
	sim_grads_norm = 0.0120
-- Starting training on experience 50 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8929
	data_grads_norm = 4.6664
	new_data_grads_norm = 5.8772
	old_data_grads_norm = 6.5823
	sim_grads_norm = 0.0219
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5877
	data_grads_norm = 4.0365
	new_data_grads_norm = 5.8864
	old_data_grads_norm = 5.4619
	sim_grads_norm = 0.0381
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2447
	data_grads_norm = 3.4826
	new_data_grads_norm = 5.7743
	old_data_grads_norm = 3.4550
	sim_grads_norm = 0.0044
-- Starting training on experience 51 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9477
	data_grads_norm = 5.2383
	new_data_grads_norm = 8.0924
	old_data_grads_norm = 7.1279
	sim_grads_norm = -0.0400
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6927
	data_grads_norm = 4.7567
	new_data_grads_norm = 7.4764
	old_data_grads_norm = 6.7608
	sim_grads_norm = 0.0210
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2914
	data_grads_norm = 5.7076
	new_data_grads_norm = 7.6161
	old_data_grads_norm = 7.8128
	sim_grads_norm = -0.0180
-- Starting training on experience 52 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7662
	data_grads_norm = 5.5878
	new_data_grads_norm = 7.7138
	old_data_grads_norm = 7.5807
	sim_grads_norm = -0.0358
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0337
	data_grads_norm = 5.3571
	new_data_grads_norm = 7.8264
	old_data_grads_norm = 6.2093
	sim_grads_norm = 0.0253
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5135
	data_grads_norm = 5.1278
	new_data_grads_norm = 7.7702
	old_data_grads_norm = 5.5563
	sim_grads_norm = 0.0135
-- Starting training on experience 53 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2085
	data_grads_norm = 4.2228
	new_data_grads_norm = 7.7656
	old_data_grads_norm = 4.7664
	sim_grads_norm = -0.0296
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5660
	data_grads_norm = 5.2459
	new_data_grads_norm = 7.6773
	old_data_grads_norm = 6.1072
	sim_grads_norm = 0.0090
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8808
	data_grads_norm = 4.6874
	new_data_grads_norm = 7.2048
	old_data_grads_norm = 5.3864
	sim_grads_norm = -0.0344
-- Starting training on experience 54 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7944
	data_grads_norm = 4.4443
	new_data_grads_norm = 6.0439
	old_data_grads_norm = 4.7340
	sim_grads_norm = 0.0432
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8330
	data_grads_norm = 4.6296
	new_data_grads_norm = 6.4884
	old_data_grads_norm = 5.9373
	sim_grads_norm = -0.0024
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3363
	data_grads_norm = 3.6356
	new_data_grads_norm = 6.5990
	old_data_grads_norm = 3.5861
	sim_grads_norm = -0.0143
-- Starting training on experience 55 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4211
	data_grads_norm = 4.5858
	new_data_grads_norm = 7.3718
	old_data_grads_norm = 2.6240
	sim_grads_norm = 0.0140
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6997
	data_grads_norm = 4.4088
	new_data_grads_norm = 6.4524
	old_data_grads_norm = 4.0232
	sim_grads_norm = -0.0012
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4694
	data_grads_norm = 4.2471
	new_data_grads_norm = 6.9341
	old_data_grads_norm = 5.6173
	sim_grads_norm = -0.0175
-- Starting training on experience 56 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1984
	data_grads_norm = 4.4960
	new_data_grads_norm = 6.7753
	old_data_grads_norm = 5.5564
	sim_grads_norm = -0.0145
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6748
	data_grads_norm = 4.5194
	new_data_grads_norm = 6.8050
	old_data_grads_norm = 6.2237
	sim_grads_norm = 0.0081
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4796
	data_grads_norm = 4.3202
	new_data_grads_norm = 6.6983
	old_data_grads_norm = 4.1866
	sim_grads_norm = 0.0898
-- Starting training on experience 57 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3741
	data_grads_norm = 4.7300
	new_data_grads_norm = 8.0387
	old_data_grads_norm = 5.0826
	sim_grads_norm = -0.0089
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6548
	data_grads_norm = 4.4159
	new_data_grads_norm = 7.5252
	old_data_grads_norm = 5.7751
	sim_grads_norm = -0.0144
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5136
	data_grads_norm = 4.7374
	new_data_grads_norm = 8.3506
	old_data_grads_norm = 4.4228
	sim_grads_norm = 0.0122
-- Starting training on experience 58 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3073
	data_grads_norm = 4.6488
	new_data_grads_norm = 7.7888
	old_data_grads_norm = 4.8321
	sim_grads_norm = -0.0268
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5465
	data_grads_norm = 5.1329
	new_data_grads_norm = 7.8467
	old_data_grads_norm = 6.4564
	sim_grads_norm = -0.0038
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4985
	data_grads_norm = 4.4744
	new_data_grads_norm = 6.9246
	old_data_grads_norm = 5.3905
	sim_grads_norm = 0.0439
-- Starting training on experience 59 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9058
	data_grads_norm = 4.7703
	new_data_grads_norm = 6.6917
	old_data_grads_norm = 5.8990
	sim_grads_norm = -0.0058
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8639
	data_grads_norm = 4.7130
	new_data_grads_norm = 6.8294
	old_data_grads_norm = 4.7166
	sim_grads_norm = 0.1115
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5164
	data_grads_norm = 4.2955
	new_data_grads_norm = 6.9203
	old_data_grads_norm = 5.6042
	sim_grads_norm = -0.0076
-- Starting training on experience 60 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2194
	data_grads_norm = 4.0516
	new_data_grads_norm = 6.2196
	old_data_grads_norm = 5.2621
	sim_grads_norm = 0.0571
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5096
	data_grads_norm = 4.9008
	new_data_grads_norm = 7.0591
	old_data_grads_norm = 5.4868
	sim_grads_norm = -0.0094
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9794
	data_grads_norm = 3.2541
	new_data_grads_norm = 6.3238
	old_data_grads_norm = 2.9934
	sim_grads_norm = -0.0279
-- Starting training on experience 61 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8024
	data_grads_norm = 5.1696
	new_data_grads_norm = 7.0328
	old_data_grads_norm = 6.4007
	sim_grads_norm = 0.0327
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7615
	data_grads_norm = 5.0361
	new_data_grads_norm = 6.6973
	old_data_grads_norm = 6.3233
	sim_grads_norm = -0.0015
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2321
	data_grads_norm = 4.3968
	new_data_grads_norm = 6.3735
	old_data_grads_norm = 4.5415
	sim_grads_norm = 0.0422
-- Starting training on experience 62 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5277
	data_grads_norm = 4.7674
	new_data_grads_norm = 6.6205
	old_data_grads_norm = 6.9018
	sim_grads_norm = 0.0682
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5588
	data_grads_norm = 4.4287
	new_data_grads_norm = 8.0950
	old_data_grads_norm = 4.1822
	sim_grads_norm = 0.0739
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2637
	data_grads_norm = 4.0149
	new_data_grads_norm = 7.4058
	old_data_grads_norm = 4.6755
	sim_grads_norm = -0.0063
-- Starting training on experience 63 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9038
	data_grads_norm = 5.2780
	new_data_grads_norm = 7.2229
	old_data_grads_norm = 5.9101
	sim_grads_norm = -0.0108
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9015
	data_grads_norm = 4.6072
	new_data_grads_norm = 6.7954
	old_data_grads_norm = 5.9066
	sim_grads_norm = 0.0083
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3423
	data_grads_norm = 3.6740
	new_data_grads_norm = 6.5037
	old_data_grads_norm = 3.8314
	sim_grads_norm = -0.0431
-- Starting training on experience 64 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6408
	data_grads_norm = 4.8377
	new_data_grads_norm = 8.3535
	old_data_grads_norm = 3.8819
	sim_grads_norm = -0.0391
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0637
	data_grads_norm = 5.6379
	new_data_grads_norm = 9.5197
	old_data_grads_norm = 4.5574
	sim_grads_norm = 0.0272
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6746
	data_grads_norm = 5.4725
	new_data_grads_norm = 9.7092
	old_data_grads_norm = 4.5542
	sim_grads_norm = -0.0154
-- Starting training on experience 65 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1475
	data_grads_norm = 3.7694
	new_data_grads_norm = 5.9746
	old_data_grads_norm = 4.9300
	sim_grads_norm = 0.0385
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7932
	data_grads_norm = 4.6508
	new_data_grads_norm = 6.2331
	old_data_grads_norm = 6.6777
	sim_grads_norm = 0.0733
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1482
	data_grads_norm = 3.8722
	new_data_grads_norm = 6.6872
	old_data_grads_norm = 4.2041
	sim_grads_norm = -0.0067
-- Starting training on experience 66 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3736
	data_grads_norm = 4.1576
	new_data_grads_norm = 6.0675
	old_data_grads_norm = 5.3868
	sim_grads_norm = -0.0185
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0155
	data_grads_norm = 4.0250
	new_data_grads_norm = 6.3097
	old_data_grads_norm = 6.8934
	sim_grads_norm = 0.0101
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8811
	data_grads_norm = 3.5063
	new_data_grads_norm = 5.8108
	old_data_grads_norm = 3.8414
	sim_grads_norm = -0.0310
-- Starting training on experience 67 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7713
	data_grads_norm = 6.1401
	new_data_grads_norm = 8.1917
	old_data_grads_norm = 6.9527
	sim_grads_norm = 0.0120
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1470
	data_grads_norm = 5.1161
	new_data_grads_norm = 9.4454
	old_data_grads_norm = 6.1349
	sim_grads_norm = 0.0091
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5656
	data_grads_norm = 5.5685
	new_data_grads_norm = 9.7824
	old_data_grads_norm = 4.0019
	sim_grads_norm = 0.0731
-- Starting training on experience 68 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5522
	data_grads_norm = 4.4704
	new_data_grads_norm = 7.2134
	old_data_grads_norm = 4.2327
	sim_grads_norm = -0.0155
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7051
	data_grads_norm = 4.5756
	new_data_grads_norm = 7.9355
	old_data_grads_norm = 4.3525
	sim_grads_norm = 0.0894
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2124
	data_grads_norm = 3.5780
	new_data_grads_norm = 6.6003
	old_data_grads_norm = 3.6874
	sim_grads_norm = 0.0779
-- Starting training on experience 69 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0317
	data_grads_norm = 3.9229
	new_data_grads_norm = 7.2327
	old_data_grads_norm = 4.4506
	sim_grads_norm = 0.0170
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8256
	data_grads_norm = 4.1818
	new_data_grads_norm = 6.8396
	old_data_grads_norm = 3.2113
	sim_grads_norm = 0.0150
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2445
	data_grads_norm = 4.5693
	new_data_grads_norm = 7.6124
	old_data_grads_norm = 6.3376
	sim_grads_norm = -0.0209
-- Starting training on experience 70 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9286
	data_grads_norm = 5.4987
	new_data_grads_norm = 6.1102
	old_data_grads_norm = 7.5266
	sim_grads_norm = 0.0137
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2271
	data_grads_norm = 3.7329
	new_data_grads_norm = 6.2868
	old_data_grads_norm = 4.7339
	sim_grads_norm = 0.0221
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4569
	data_grads_norm = 4.1144
	new_data_grads_norm = 5.8682
	old_data_grads_norm = 5.5495
	sim_grads_norm = -0.0171
-- Starting training on experience 71 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4090
	data_grads_norm = 4.4500
	new_data_grads_norm = 6.0527
	old_data_grads_norm = 6.2201
	sim_grads_norm = 0.0392
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0838
	data_grads_norm = 4.1736
	new_data_grads_norm = 6.9919
	old_data_grads_norm = 3.5139
	sim_grads_norm = 0.0041
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1913
	data_grads_norm = 4.2107
	new_data_grads_norm = 5.8192
	old_data_grads_norm = 5.3697
	sim_grads_norm = 0.0164
-- Starting training on experience 72 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9626
	data_grads_norm = 4.5911
	new_data_grads_norm = 7.3944
	old_data_grads_norm = 4.4903
	sim_grads_norm = 0.0369
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2184
	data_grads_norm = 4.7797
	new_data_grads_norm = 8.0970
	old_data_grads_norm = 4.6118
	sim_grads_norm = -0.0657
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1081
	data_grads_norm = 4.2453
	new_data_grads_norm = 7.3318
	old_data_grads_norm = 4.2202
	sim_grads_norm = 0.0230
-- Starting training on experience 73 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2320
	data_grads_norm = 4.6365
	new_data_grads_norm = 5.9335
	old_data_grads_norm = 6.8659
	sim_grads_norm = -0.0163
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3519
	data_grads_norm = 3.9910
	new_data_grads_norm = 5.8827
	old_data_grads_norm = 3.8041
	sim_grads_norm = 0.0172
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6875
	data_grads_norm = 4.7347
	new_data_grads_norm = 6.6840
	old_data_grads_norm = 6.6000
	sim_grads_norm = -0.0188
-- Starting training on experience 74 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0994
	data_grads_norm = 4.0009
	new_data_grads_norm = 6.4134
	old_data_grads_norm = 5.1088
	sim_grads_norm = -0.0108
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4010
	data_grads_norm = 4.9348
	new_data_grads_norm = 7.1929
	old_data_grads_norm = 4.8039
	sim_grads_norm = -0.0109
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2004
	data_grads_norm = 4.5919
	new_data_grads_norm = 7.9294
	old_data_grads_norm = 6.4723
	sim_grads_norm = -0.0411
-- Starting training on experience 75 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3950
	data_grads_norm = 4.5013
	new_data_grads_norm = 7.8491
	old_data_grads_norm = 4.6176
	sim_grads_norm = 0.0034
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1412
	data_grads_norm = 4.2553
	new_data_grads_norm = 7.3918
	old_data_grads_norm = 3.8413
	sim_grads_norm = -0.0368
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7633
	data_grads_norm = 4.7889
	new_data_grads_norm = 7.1268
	old_data_grads_norm = 5.2905
	sim_grads_norm = 0.1415
-- Starting training on experience 76 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2773
	data_grads_norm = 4.4681
	new_data_grads_norm = 6.9840
	old_data_grads_norm = 5.7639
	sim_grads_norm = -0.0276
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9562
	data_grads_norm = 3.5442
	new_data_grads_norm = 6.5299
	old_data_grads_norm = 5.6852
	sim_grads_norm = -0.0630
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3051
	data_grads_norm = 4.0675
	new_data_grads_norm = 6.8329
	old_data_grads_norm = 3.4492
	sim_grads_norm = -0.0062
-- Starting training on experience 77 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1048
	data_grads_norm = 6.1032
	new_data_grads_norm = 6.3727
	old_data_grads_norm = 6.0073
	sim_grads_norm = 0.0184
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8389
	data_grads_norm = 3.7837
	new_data_grads_norm = 6.8873
	old_data_grads_norm = 3.5167
	sim_grads_norm = -0.0022
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8407
	data_grads_norm = 4.5039
	new_data_grads_norm = 7.8490
	old_data_grads_norm = 4.1061
	sim_grads_norm = 0.0081
-- Starting training on experience 78 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6449
	data_grads_norm = 5.0994
	new_data_grads_norm = 6.8903
	old_data_grads_norm = 6.8285
	sim_grads_norm = 0.0237
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2701
	data_grads_norm = 4.3008
	new_data_grads_norm = 6.5034
	old_data_grads_norm = 4.9842
	sim_grads_norm = 0.0555
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5706
	data_grads_norm = 4.7902
	new_data_grads_norm = 6.2578
	old_data_grads_norm = 8.0310
	sim_grads_norm = -0.0284
-- Starting training on experience 79 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5785
	data_grads_norm = 4.6264
	new_data_grads_norm = 6.9431
	old_data_grads_norm = 5.7391
	sim_grads_norm = 0.0155
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8090
	data_grads_norm = 3.8343
	new_data_grads_norm = 7.0402
	old_data_grads_norm = 5.4654
	sim_grads_norm = 0.0065
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4134
	data_grads_norm = 4.7808
	new_data_grads_norm = 6.5365
	old_data_grads_norm = 5.7227
	sim_grads_norm = 0.0085
-- Starting training on experience 80 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5175
	data_grads_norm = 5.0519
	new_data_grads_norm = 7.9841
	old_data_grads_norm = 5.2576
	sim_grads_norm = 0.0770
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1803
	data_grads_norm = 4.3673
	new_data_grads_norm = 7.4179
	old_data_grads_norm = 4.0927
	sim_grads_norm = -0.0032
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0195
	data_grads_norm = 4.3235
	new_data_grads_norm = 7.3445
	old_data_grads_norm = 3.9965
	sim_grads_norm = -0.0125
-- Starting training on experience 81 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8650
	data_grads_norm = 3.9296
	new_data_grads_norm = 7.3669
	old_data_grads_norm = 4.0995
	sim_grads_norm = -0.0168
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8667
	data_grads_norm = 5.6319
	new_data_grads_norm = 7.5333
	old_data_grads_norm = 7.6217
	sim_grads_norm = -0.0144
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4731
	data_grads_norm = 4.8151
	new_data_grads_norm = 7.6516
	old_data_grads_norm = 5.0005
	sim_grads_norm = 0.0564
-- Starting training on experience 82 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8617
	data_grads_norm = 3.6106
	new_data_grads_norm = 6.6707
	old_data_grads_norm = 4.3095
	sim_grads_norm = -0.0027
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5733
	data_grads_norm = 4.4061
	new_data_grads_norm = 6.7526
	old_data_grads_norm = 5.1579
	sim_grads_norm = 0.0256
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3226
	data_grads_norm = 4.6278
	new_data_grads_norm = 6.4712
	old_data_grads_norm = 6.2575
	sim_grads_norm = 0.0336
-- Starting training on experience 83 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1594
	data_grads_norm = 4.2820
	new_data_grads_norm = 8.1901
	old_data_grads_norm = 5.8221
	sim_grads_norm = -0.0205
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4038
	data_grads_norm = 5.4137
	new_data_grads_norm = 8.3683
	old_data_grads_norm = 8.4144
	sim_grads_norm = 0.0192
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3938
	data_grads_norm = 5.1165
	new_data_grads_norm = 6.8361
	old_data_grads_norm = 6.4290
	sim_grads_norm = 0.0037
-- Starting training on experience 84 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0280
	data_grads_norm = 3.8572
	new_data_grads_norm = 6.0431
	old_data_grads_norm = 6.0456
	sim_grads_norm = -0.0274
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9982
	data_grads_norm = 3.8157
	new_data_grads_norm = 7.0777
	old_data_grads_norm = 4.5656
	sim_grads_norm = -0.0134
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0358
	data_grads_norm = 4.1831
	new_data_grads_norm = 6.0011
	old_data_grads_norm = 4.5222
	sim_grads_norm = -0.0223
-- Starting training on experience 85 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1029
	data_grads_norm = 3.7922
	new_data_grads_norm = 5.0846
	old_data_grads_norm = 5.0657
	sim_grads_norm = 0.0099
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9184
	data_grads_norm = 3.7287
	new_data_grads_norm = 6.0705
	old_data_grads_norm = 5.0043
	sim_grads_norm = 0.0124
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8883
	data_grads_norm = 3.6708
	new_data_grads_norm = 4.7581
	old_data_grads_norm = 5.9014
	sim_grads_norm = -0.0138
-- Starting training on experience 86 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4289
	data_grads_norm = 4.4758
	new_data_grads_norm = 5.9020
	old_data_grads_norm = 6.0820
	sim_grads_norm = -0.0332
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2962
	data_grads_norm = 4.7660
	new_data_grads_norm = 6.0301
	old_data_grads_norm = 6.3446
	sim_grads_norm = -0.0461
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9567
	data_grads_norm = 3.8682
	new_data_grads_norm = 6.3659
	old_data_grads_norm = 4.7583
	sim_grads_norm = -0.0185
-- Starting training on experience 87 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5909
	data_grads_norm = 4.1770
	new_data_grads_norm = 6.7170
	old_data_grads_norm = 5.7598
	sim_grads_norm = 0.0141
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5836
	data_grads_norm = 4.8806
	new_data_grads_norm = 6.4964
	old_data_grads_norm = 6.8801
	sim_grads_norm = 0.0163
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3835
	data_grads_norm = 4.4076
	new_data_grads_norm = 6.2005
	old_data_grads_norm = 4.9414
	sim_grads_norm = -0.0267
-- Starting training on experience 88 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8903
	data_grads_norm = 4.7753
	new_data_grads_norm = 8.2068
	old_data_grads_norm = 5.1416
	sim_grads_norm = 0.0449
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6950
	data_grads_norm = 4.9586
	new_data_grads_norm = 6.2998
	old_data_grads_norm = 6.6312
	sim_grads_norm = -0.0546
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4690
	data_grads_norm = 4.2503
	new_data_grads_norm = 8.0968
	old_data_grads_norm = 6.2168
	sim_grads_norm = -0.0208
-- Starting training on experience 89 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7186
	data_grads_norm = 4.6012
	new_data_grads_norm = 6.8151
	old_data_grads_norm = 5.4627
	sim_grads_norm = 0.0119
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5259
	data_grads_norm = 4.5078
	new_data_grads_norm = 6.7836
	old_data_grads_norm = 6.0009
	sim_grads_norm = 0.0095
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7529
	data_grads_norm = 4.8395
	new_data_grads_norm = 5.9051
	old_data_grads_norm = 6.8545
	sim_grads_norm = -0.0150
-- Starting training on experience 90 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7959
	data_grads_norm = 5.2661
	new_data_grads_norm = 7.8724
	old_data_grads_norm = 7.0257
	sim_grads_norm = 0.0482
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5270
	data_grads_norm = 5.8269
	new_data_grads_norm = 7.0589
	old_data_grads_norm = 7.6004
	sim_grads_norm = 0.0039
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0034
	data_grads_norm = 3.8224
	new_data_grads_norm = 6.9088
	old_data_grads_norm = 4.1564
	sim_grads_norm = -0.0050
-- Starting training on experience 91 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7264
	data_grads_norm = 4.7462
	new_data_grads_norm = 6.5514
	old_data_grads_norm = 6.6090
	sim_grads_norm = -0.0009
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5149
	data_grads_norm = 3.7101
	new_data_grads_norm = 7.3347
	old_data_grads_norm = 3.6827
	sim_grads_norm = -0.0005
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9662
	data_grads_norm = 5.1930
	new_data_grads_norm = 6.5877
	old_data_grads_norm = 7.7315
	sim_grads_norm = -0.0161
-- Starting training on experience 92 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4853
	data_grads_norm = 4.2622
	new_data_grads_norm = 6.5640
	old_data_grads_norm = 5.2178
	sim_grads_norm = 0.0350
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2951
	data_grads_norm = 4.5198
	new_data_grads_norm = 6.3238
	old_data_grads_norm = 6.5737
	sim_grads_norm = 0.0270
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3666
	data_grads_norm = 3.9688
	new_data_grads_norm = 5.9161
	old_data_grads_norm = 5.7793
	sim_grads_norm = 0.0019
-- Starting training on experience 93 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3154
	data_grads_norm = 4.5763
	new_data_grads_norm = 6.6529
	old_data_grads_norm = 7.5527
	sim_grads_norm = -0.0209
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4403
	data_grads_norm = 4.7460
	new_data_grads_norm = 6.7364
	old_data_grads_norm = 5.4030
	sim_grads_norm = -0.0121
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6013
	data_grads_norm = 5.6028
	new_data_grads_norm = 6.2903
	old_data_grads_norm = 8.4393
	sim_grads_norm = -0.0037
-- Starting training on experience 94 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0751
	data_grads_norm = 3.4839
	new_data_grads_norm = 6.2834
	old_data_grads_norm = 2.8501
	sim_grads_norm = 0.0015
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6670
	data_grads_norm = 5.0361
	new_data_grads_norm = 6.4980
	old_data_grads_norm = 6.7213
	sim_grads_norm = 0.0002
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0515
	data_grads_norm = 4.0426
	new_data_grads_norm = 6.1696
	old_data_grads_norm = 5.2303
	sim_grads_norm = -0.0046
-- Starting training on experience 95 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7460
	data_grads_norm = 5.8209
	new_data_grads_norm = 7.1936
	old_data_grads_norm = 6.6165
	sim_grads_norm = 0.0406
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2816
	data_grads_norm = 4.4553
	new_data_grads_norm = 7.4072
	old_data_grads_norm = 5.7145
	sim_grads_norm = -0.0099
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6424
	data_grads_norm = 4.5647
	new_data_grads_norm = 7.4006
	old_data_grads_norm = 5.9472
	sim_grads_norm = 0.0182
-- Starting training on experience 96 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4236
	data_grads_norm = 4.7635
	new_data_grads_norm = 7.7647
	old_data_grads_norm = 5.9617
	sim_grads_norm = 0.0089
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3041
	data_grads_norm = 4.3943
	new_data_grads_norm = 7.5058
	old_data_grads_norm = 6.1014
	sim_grads_norm = 0.0163
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8177
	data_grads_norm = 4.8225
	new_data_grads_norm = 7.9340
	old_data_grads_norm = 6.0510
	sim_grads_norm = 0.0034
-- Starting training on experience 97 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6886
	data_grads_norm = 4.6167
	new_data_grads_norm = 6.2646
	old_data_grads_norm = 6.1180
	sim_grads_norm = 0.0126
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8814
	data_grads_norm = 4.9480
	new_data_grads_norm = 7.0125
	old_data_grads_norm = 6.2905
	sim_grads_norm = 0.0836
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2741
	data_grads_norm = 4.3234
	new_data_grads_norm = 6.8304
	old_data_grads_norm = 5.3684
	sim_grads_norm = -0.0168
-- Starting training on experience 98 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3402
	data_grads_norm = 4.4545
	new_data_grads_norm = 7.3440
	old_data_grads_norm = 5.8386
	sim_grads_norm = -0.0198
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6106
	data_grads_norm = 5.3978
	new_data_grads_norm = 7.9731
	old_data_grads_norm = 6.6313
	sim_grads_norm = -0.0061
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6759
	data_grads_norm = 4.8928
	new_data_grads_norm = 8.1383
	old_data_grads_norm = 6.5632
	sim_grads_norm = 0.0076
-- Starting training on experience 99 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5345
	data_grads_norm = 4.0789
	new_data_grads_norm = 7.3426
	old_data_grads_norm = 4.7062
	sim_grads_norm = 0.0764
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3428
	data_grads_norm = 4.4456
	new_data_grads_norm = 7.4437
	old_data_grads_norm = 7.7845
	sim_grads_norm = 0.0125
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4798
	data_grads_norm = 4.4680
	new_data_grads_norm = 7.1926
	old_data_grads_norm = 6.1438
	sim_grads_norm = 0.0023
-- Starting training on experience 100 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4531
	data_grads_norm = 5.7203
	new_data_grads_norm = 8.5748
	old_data_grads_norm = 6.3923
	sim_grads_norm = -0.0105
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7311
	data_grads_norm = 5.6651
	new_data_grads_norm = 8.2642
	old_data_grads_norm = 7.7215
	sim_grads_norm = 0.0331
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7488
	data_grads_norm = 4.5593
	new_data_grads_norm = 7.9228
	old_data_grads_norm = 4.2233
	sim_grads_norm = -0.0219
-- Starting training on experience 101 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5266
	data_grads_norm = 4.2139
	new_data_grads_norm = 6.2754
	old_data_grads_norm = 4.0891
	sim_grads_norm = 0.0429
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4333
	data_grads_norm = 3.9667
	new_data_grads_norm = 6.0188
	old_data_grads_norm = 6.0101
	sim_grads_norm = -0.0086
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6196
	data_grads_norm = 4.0953
	new_data_grads_norm = 6.3658
	old_data_grads_norm = 4.1543
	sim_grads_norm = 0.0574
-- Starting training on experience 102 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4392
	data_grads_norm = 4.1080
	new_data_grads_norm = 6.7791
	old_data_grads_norm = 4.9876
	sim_grads_norm = 0.0036
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3001
	data_grads_norm = 4.5014
	new_data_grads_norm = 7.1484
	old_data_grads_norm = 4.9153
	sim_grads_norm = 0.0007
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9736
	data_grads_norm = 5.1011
	new_data_grads_norm = 6.5393
	old_data_grads_norm = 6.1843
	sim_grads_norm = 0.0363
-- Starting training on experience 103 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7683
	data_grads_norm = 5.3193
	new_data_grads_norm = 6.4068
	old_data_grads_norm = 6.7616
	sim_grads_norm = 0.0066
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1478
	data_grads_norm = 4.0614
	new_data_grads_norm = 6.2774
	old_data_grads_norm = 4.8246
	sim_grads_norm = -0.0200
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9933
	data_grads_norm = 3.9288
	new_data_grads_norm = 6.8161
	old_data_grads_norm = 3.5411
	sim_grads_norm = -0.0106
-- Starting training on experience 104 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1257
	data_grads_norm = 3.6935
	new_data_grads_norm = 6.2112
	old_data_grads_norm = 3.8710
	sim_grads_norm = 0.0644
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9556
	data_grads_norm = 5.2991
	new_data_grads_norm = 6.0887
	old_data_grads_norm = 7.5948
	sim_grads_norm = 0.0299
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9505
	data_grads_norm = 3.4635
	new_data_grads_norm = 6.3328
	old_data_grads_norm = 3.5693
	sim_grads_norm = -0.0113
-- Starting training on experience 105 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9522
	data_grads_norm = 5.3894
	new_data_grads_norm = 7.4922
	old_data_grads_norm = 7.3058
	sim_grads_norm = -0.0009
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0632
	data_grads_norm = 4.1690
	new_data_grads_norm = 7.2073
	old_data_grads_norm = 5.2565
	sim_grads_norm = -0.0141
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5268
	data_grads_norm = 5.3394
	new_data_grads_norm = 6.9447
	old_data_grads_norm = 7.0359
	sim_grads_norm = 0.0119
-- Starting training on experience 106 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8791
	data_grads_norm = 3.9337
	new_data_grads_norm = 7.5906
	old_data_grads_norm = 6.1010
	sim_grads_norm = -0.0532
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7551
	data_grads_norm = 5.3874
	new_data_grads_norm = 8.2077
	old_data_grads_norm = 6.3872
	sim_grads_norm = -0.0127
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0895
	data_grads_norm = 4.2588
	new_data_grads_norm = 7.3515
	old_data_grads_norm = 4.3179
	sim_grads_norm = -0.0178
-- Starting training on experience 107 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0398
	data_grads_norm = 5.0395
	new_data_grads_norm = 7.4844
	old_data_grads_norm = 6.6446
	sim_grads_norm = -0.0222
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6570
	data_grads_norm = 4.5288
	new_data_grads_norm = 7.9999
	old_data_grads_norm = 3.9477
	sim_grads_norm = -0.0037
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8504
	data_grads_norm = 5.0167
	new_data_grads_norm = 7.6110
	old_data_grads_norm = 6.5270
	sim_grads_norm = -0.0246
-- Starting training on experience 108 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5341
	data_grads_norm = 4.9864
	new_data_grads_norm = 7.1561
	old_data_grads_norm = 5.8337
	sim_grads_norm = 0.0045
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2386
	data_grads_norm = 4.6848
	new_data_grads_norm = 6.9267
	old_data_grads_norm = 4.3473
	sim_grads_norm = 0.0529
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4626
	data_grads_norm = 4.6838
	new_data_grads_norm = 7.4726
	old_data_grads_norm = 4.5195
	sim_grads_norm = -0.0160
-- Starting training on experience 109 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4955
	data_grads_norm = 4.3231
	new_data_grads_norm = 6.6232
	old_data_grads_norm = 4.9079
	sim_grads_norm = 0.0042
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4215
	data_grads_norm = 4.3384
	new_data_grads_norm = 6.4054
	old_data_grads_norm = 4.9132
	sim_grads_norm = -0.0373
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5709
	data_grads_norm = 4.2687
	new_data_grads_norm = 6.3858
	old_data_grads_norm = 5.6712
	sim_grads_norm = 0.0504
-- Starting training on experience 110 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4013
	data_grads_norm = 4.4744
	new_data_grads_norm = 7.7053
	old_data_grads_norm = 4.5602
	sim_grads_norm = 0.0142
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5994
	data_grads_norm = 5.2298
	new_data_grads_norm = 8.2767
	old_data_grads_norm = 6.2997
	sim_grads_norm = -0.0095
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2595
	data_grads_norm = 4.1273
	new_data_grads_norm = 7.7097
	old_data_grads_norm = 3.8830
	sim_grads_norm = -0.0379
-- Starting training on experience 111 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5070
	data_grads_norm = 4.7022
	new_data_grads_norm = 9.5610
	old_data_grads_norm = 3.4146
	sim_grads_norm = 0.0201
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8143
	data_grads_norm = 5.2107
	new_data_grads_norm = 8.3388
	old_data_grads_norm = 5.5775
	sim_grads_norm = -0.0127
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6887
	data_grads_norm = 4.9812
	new_data_grads_norm = 7.9186
	old_data_grads_norm = 4.1235
	sim_grads_norm = -0.0145
-- Starting training on experience 112 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4164
	data_grads_norm = 4.7763
	new_data_grads_norm = 7.8550
	old_data_grads_norm = 4.3136
	sim_grads_norm = -0.0012
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4057
	data_grads_norm = 4.7544
	new_data_grads_norm = 7.3440
	old_data_grads_norm = 3.7550
	sim_grads_norm = 0.0008
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5604
	data_grads_norm = 4.8747
	new_data_grads_norm = 6.8985
	old_data_grads_norm = 5.3861
	sim_grads_norm = 0.0201
-- Starting training on experience 113 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1422
	data_grads_norm = 4.3579
	new_data_grads_norm = 7.3924
	old_data_grads_norm = 4.1977
	sim_grads_norm = 0.0004
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1429
	data_grads_norm = 4.3455
	new_data_grads_norm = 7.2083
	old_data_grads_norm = 5.4454
	sim_grads_norm = 0.0002
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1957
	data_grads_norm = 5.1127
	new_data_grads_norm = 8.1276
	old_data_grads_norm = 4.6977
	sim_grads_norm = 0.0071
-- Starting training on experience 114 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4910
	data_grads_norm = 4.5572
	new_data_grads_norm = 7.4883
	old_data_grads_norm = 5.8713
	sim_grads_norm = 0.0495
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3995
	data_grads_norm = 4.8351
	new_data_grads_norm = 6.9012
	old_data_grads_norm = 6.1318
	sim_grads_norm = -0.0068
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3672
	data_grads_norm = 4.3430
	new_data_grads_norm = 7.0724
	old_data_grads_norm = 6.8162
	sim_grads_norm = -0.0042
-- Starting training on experience 115 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9544
	data_grads_norm = 4.6288
	new_data_grads_norm = 6.9174
	old_data_grads_norm = 4.9487
	sim_grads_norm = 0.0800
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3747
	data_grads_norm = 4.2715
	new_data_grads_norm = 7.2277
	old_data_grads_norm = 5.4486
	sim_grads_norm = -0.0172
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3551
	data_grads_norm = 4.2144
	new_data_grads_norm = 7.2724
	old_data_grads_norm = 4.3153
	sim_grads_norm = 0.0253
-- Starting training on experience 116 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3500
	data_grads_norm = 5.1513
	new_data_grads_norm = 9.2598
	old_data_grads_norm = 4.2245
	sim_grads_norm = -0.0334
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0446
	data_grads_norm = 4.7677
	new_data_grads_norm = 9.8329
	old_data_grads_norm = 4.4587
	sim_grads_norm = -0.0134
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5705
	data_grads_norm = 5.0384
	new_data_grads_norm = 8.8650
	old_data_grads_norm = 6.0081
	sim_grads_norm = 0.0464
-- Starting training on experience 117 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3608
	data_grads_norm = 3.9274
	new_data_grads_norm = 6.9503
	old_data_grads_norm = 4.1663
	sim_grads_norm = -0.0381
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8761
	data_grads_norm = 5.3039
	new_data_grads_norm = 8.2376
	old_data_grads_norm = 5.2413
	sim_grads_norm = -0.0162
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6317
	data_grads_norm = 5.6553
	new_data_grads_norm = 7.8590
	old_data_grads_norm = 7.8737
	sim_grads_norm = -0.0235
-- Starting training on experience 118 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8086
	data_grads_norm = 5.6578
	new_data_grads_norm = 7.5924
	old_data_grads_norm = 7.0880
	sim_grads_norm = -0.0222
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0069
	data_grads_norm = 5.6374
	new_data_grads_norm = 7.6556
	old_data_grads_norm = 5.9835
	sim_grads_norm = 0.0050
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7061
	data_grads_norm = 5.2734
	new_data_grads_norm = 7.5860
	old_data_grads_norm = 5.4653
	sim_grads_norm = -0.0143
-- Starting training on experience 119 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1878
	data_grads_norm = 4.9957
	new_data_grads_norm = 7.8892
	old_data_grads_norm = 5.8684
	sim_grads_norm = -0.0071
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6502
	data_grads_norm = 5.1893
	new_data_grads_norm = 7.8284
	old_data_grads_norm = 7.1580
	sim_grads_norm = 0.0183
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5601
	data_grads_norm = 4.6713
	new_data_grads_norm = 8.1170
	old_data_grads_norm = 5.7146
	sim_grads_norm = -0.0142
-- Starting training on experience 120 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6123
	data_grads_norm = 5.0501
	new_data_grads_norm = 7.0111
	old_data_grads_norm = 5.5380
	sim_grads_norm = 0.0038
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9180
	data_grads_norm = 3.6516
	new_data_grads_norm = 6.8137
	old_data_grads_norm = 4.0319
	sim_grads_norm = 0.0221
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1849
	data_grads_norm = 4.6187
	new_data_grads_norm = 6.3320
	old_data_grads_norm = 6.2471
	sim_grads_norm = 0.0311
-- Starting training on experience 121 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6882
	data_grads_norm = 4.4011
	new_data_grads_norm = 5.8909
	old_data_grads_norm = 6.5290
	sim_grads_norm = -0.0029
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0063
	data_grads_norm = 4.0100
	new_data_grads_norm = 6.5255
	old_data_grads_norm = 4.9609
	sim_grads_norm = 0.0342
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1270
	data_grads_norm = 3.8862
	new_data_grads_norm = 6.0740
	old_data_grads_norm = 4.8139
	sim_grads_norm = -0.0423
-- Starting training on experience 122 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0301
	data_grads_norm = 3.5696
	new_data_grads_norm = 7.5888
	old_data_grads_norm = 4.2600
	sim_grads_norm = -0.0028
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3420
	data_grads_norm = 4.1649
	new_data_grads_norm = 7.2366
	old_data_grads_norm = 4.7014
	sim_grads_norm = -0.0251
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4307
	data_grads_norm = 4.5882
	new_data_grads_norm = 7.2050
	old_data_grads_norm = 5.0814
	sim_grads_norm = -0.0107
-- Starting training on experience 123 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3513
	data_grads_norm = 5.1034
	new_data_grads_norm = 7.5028
	old_data_grads_norm = 6.4271
	sim_grads_norm = 0.0018
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9568
	data_grads_norm = 5.2354
	new_data_grads_norm = 7.9479
	old_data_grads_norm = 4.4913
	sim_grads_norm = 0.1695
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9611
	data_grads_norm = 3.9917
	new_data_grads_norm = 7.8923
	old_data_grads_norm = 3.6625
	sim_grads_norm = -0.0588
-- Starting training on experience 124 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5407
	data_grads_norm = 4.8545
	new_data_grads_norm = 5.9801
	old_data_grads_norm = 6.7979
	sim_grads_norm = -0.0244
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5813
	data_grads_norm = 4.0065
	new_data_grads_norm = 6.6659
	old_data_grads_norm = 4.1023
	sim_grads_norm = -0.0178
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5646
	data_grads_norm = 4.6373
	new_data_grads_norm = 6.8810
	old_data_grads_norm = 4.9289
	sim_grads_norm = -0.0015
-- Starting training on experience 125 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1061
	data_grads_norm = 4.4530
	new_data_grads_norm = 6.8505
	old_data_grads_norm = 6.2210
	sim_grads_norm = -0.0014
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4734
	data_grads_norm = 4.6398
	new_data_grads_norm = 7.8088
	old_data_grads_norm = 5.1126
	sim_grads_norm = -0.0091
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3363
	data_grads_norm = 4.3902
	new_data_grads_norm = 8.1284
	old_data_grads_norm = 2.7574
	sim_grads_norm = -0.0070
-- Starting training on experience 126 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4809
	data_grads_norm = 5.8769
	new_data_grads_norm = 6.9051
	old_data_grads_norm = 6.9603
	sim_grads_norm = 0.0032
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7211
	data_grads_norm = 5.2699
	new_data_grads_norm = 6.4783
	old_data_grads_norm = 4.8712
	sim_grads_norm = 0.3096
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6587
	data_grads_norm = 4.0390
	new_data_grads_norm = 6.1503
	old_data_grads_norm = 4.1637
	sim_grads_norm = -0.0820
-- Starting training on experience 127 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2320
	data_grads_norm = 4.3261
	new_data_grads_norm = 6.8156
	old_data_grads_norm = 5.5396
	sim_grads_norm = -0.0178
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0444
	data_grads_norm = 4.5163
	new_data_grads_norm = 7.0794
	old_data_grads_norm = 4.5414
	sim_grads_norm = 0.0316
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2455
	data_grads_norm = 5.0350
	new_data_grads_norm = 6.7327
	old_data_grads_norm = 7.2485
	sim_grads_norm = 0.0269
-- Starting training on experience 128 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9481
	data_grads_norm = 4.6077
	new_data_grads_norm = 6.7291
	old_data_grads_norm = 6.2627
	sim_grads_norm = 0.0942
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0352
	data_grads_norm = 4.1944
	new_data_grads_norm = 6.1267
	old_data_grads_norm = 6.0425
	sim_grads_norm = -0.0220
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3793
	data_grads_norm = 4.1345
	new_data_grads_norm = 6.3622
	old_data_grads_norm = 4.6058
	sim_grads_norm = -0.0312
-- Starting training on experience 129 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6309
	data_grads_norm = 4.8906
	new_data_grads_norm = 7.5016
	old_data_grads_norm = 5.4685
	sim_grads_norm = -0.0131
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2780
	data_grads_norm = 4.3706
	new_data_grads_norm = 7.1863
	old_data_grads_norm = 5.9440
	sim_grads_norm = -0.0018
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5661
	data_grads_norm = 4.9811
	new_data_grads_norm = 7.1996
	old_data_grads_norm = 7.2852
	sim_grads_norm = -0.0134
-- Starting training on experience 130 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7716
	data_grads_norm = 5.3363
	new_data_grads_norm = 7.6081
	old_data_grads_norm = 6.5950
	sim_grads_norm = -0.0059
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2480
	data_grads_norm = 4.3623
	new_data_grads_norm = 6.9594
	old_data_grads_norm = 4.2931
	sim_grads_norm = 0.0005
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5913
	data_grads_norm = 5.0309
	new_data_grads_norm = 8.2955
	old_data_grads_norm = 5.0375
	sim_grads_norm = 0.0130
-- Starting training on experience 131 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7374
	data_grads_norm = 3.1672
	new_data_grads_norm = 6.3867
	old_data_grads_norm = 1.8143
	sim_grads_norm = -0.0304
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8192
	data_grads_norm = 3.4672
	new_data_grads_norm = 6.4048
	old_data_grads_norm = 2.9005
	sim_grads_norm = -0.0026
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4101
	data_grads_norm = 4.5465
	new_data_grads_norm = 6.1273
	old_data_grads_norm = 5.2370
	sim_grads_norm = 0.0329
-- Starting training on experience 132 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9704
	data_grads_norm = 4.0962
	new_data_grads_norm = 6.2381
	old_data_grads_norm = 3.6292
	sim_grads_norm = -0.0006
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2519
	data_grads_norm = 4.3253
	new_data_grads_norm = 6.2155
	old_data_grads_norm = 6.5016
	sim_grads_norm = 0.0008
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4876
	data_grads_norm = 5.0519
	new_data_grads_norm = 6.6022
	old_data_grads_norm = 6.0942
	sim_grads_norm = 0.0780
-- Starting training on experience 133 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8532
	data_grads_norm = 3.9813
	new_data_grads_norm = 6.9842
	old_data_grads_norm = 3.9609
	sim_grads_norm = -0.0048
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6842
	data_grads_norm = 3.7352
	new_data_grads_norm = 6.6113
	old_data_grads_norm = 3.6692
	sim_grads_norm = -0.0295
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1639
	data_grads_norm = 4.2429
	new_data_grads_norm = 6.8375
	old_data_grads_norm = 4.6821
	sim_grads_norm = 0.0211
-- Starting training on experience 134 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9527
	data_grads_norm = 5.0831
	new_data_grads_norm = 7.6093
	old_data_grads_norm = 5.2990
	sim_grads_norm = 0.0133
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0563
	data_grads_norm = 5.2404
	new_data_grads_norm = 7.8274
	old_data_grads_norm = 6.6282
	sim_grads_norm = -0.0524
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5245
	data_grads_norm = 4.7477
	new_data_grads_norm = 7.8954
	old_data_grads_norm = 3.8155
	sim_grads_norm = -0.0077
-- Starting training on experience 135 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0930
	data_grads_norm = 4.2860
	new_data_grads_norm = 7.5862
	old_data_grads_norm = 3.9556
	sim_grads_norm = -0.0296
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1113
	data_grads_norm = 4.7957
	new_data_grads_norm = 7.0137
	old_data_grads_norm = 5.8624
	sim_grads_norm = 0.0259
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2923
	data_grads_norm = 4.2776
	new_data_grads_norm = 7.3358
	old_data_grads_norm = 4.3728
	sim_grads_norm = 0.0400
-- Starting training on experience 136 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1783
	data_grads_norm = 3.5513
	new_data_grads_norm = 6.6449
	old_data_grads_norm = 2.1251
	sim_grads_norm = 0.0027
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1444
	data_grads_norm = 4.8085
	new_data_grads_norm = 6.5996
	old_data_grads_norm = 6.1761
	sim_grads_norm = -0.0255
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3646
	data_grads_norm = 4.3470
	new_data_grads_norm = 7.6451
	old_data_grads_norm = 3.9552
	sim_grads_norm = -0.0153
-- Starting training on experience 137 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4712
	data_grads_norm = 4.9822
	new_data_grads_norm = 7.9256
	old_data_grads_norm = 7.8445
	sim_grads_norm = 0.0007
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2956
	data_grads_norm = 4.5917
	new_data_grads_norm = 8.2004
	old_data_grads_norm = 6.9754
	sim_grads_norm = -0.0309
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9610
	data_grads_norm = 3.5943
	new_data_grads_norm = 7.6780
	old_data_grads_norm = 3.3526
	sim_grads_norm = -0.0055
-- Starting training on experience 138 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2980
	data_grads_norm = 5.1449
	new_data_grads_norm = 9.2728
	old_data_grads_norm = 4.7443
	sim_grads_norm = 0.0470
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8389
	data_grads_norm = 5.5314
	new_data_grads_norm = 8.5698
	old_data_grads_norm = 4.7074
	sim_grads_norm = -0.0346
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4520
	data_grads_norm = 5.0983
	new_data_grads_norm = 8.4358
	old_data_grads_norm = 5.2013
	sim_grads_norm = 0.0038
-- Starting training on experience 139 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9012
	data_grads_norm = 3.7867
	new_data_grads_norm = 6.2468
	old_data_grads_norm = 5.1993
	sim_grads_norm = -0.0134
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4662
	data_grads_norm = 4.1597
	new_data_grads_norm = 6.9176
	old_data_grads_norm = 4.3087
	sim_grads_norm = 0.0124
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2248
	data_grads_norm = 4.2745
	new_data_grads_norm = 6.0678
	old_data_grads_norm = 5.4791
	sim_grads_norm = 0.0515
-- Starting training on experience 140 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2507
	data_grads_norm = 4.7705
	new_data_grads_norm = 7.5551
	old_data_grads_norm = 6.7734
	sim_grads_norm = 0.0507
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1319
	data_grads_norm = 4.6447
	new_data_grads_norm = 6.4928
	old_data_grads_norm = 5.9348
	sim_grads_norm = 0.0091
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3283
	data_grads_norm = 4.6877
	new_data_grads_norm = 7.7286
	old_data_grads_norm = 5.1862
	sim_grads_norm = 0.0254
-- Starting training on experience 141 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4631
	data_grads_norm = 5.4323
	new_data_grads_norm = 7.6452
	old_data_grads_norm = 7.8097
	sim_grads_norm = 0.0003
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6151
	data_grads_norm = 5.0057
	new_data_grads_norm = 7.7711
	old_data_grads_norm = 5.2850
	sim_grads_norm = 0.0285
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2167
	data_grads_norm = 4.3204
	new_data_grads_norm = 7.4391
	old_data_grads_norm = 5.0490
	sim_grads_norm = 0.0027
-- Starting training on experience 142 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4199
	data_grads_norm = 5.5418
	new_data_grads_norm = 7.6926
	old_data_grads_norm = 6.3501
	sim_grads_norm = 0.0424
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1042
	data_grads_norm = 4.8335
	new_data_grads_norm = 8.7822
	old_data_grads_norm = 4.4300
	sim_grads_norm = 0.0002
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2124
	data_grads_norm = 4.3229
	new_data_grads_norm = 7.4472
	old_data_grads_norm = 4.5650
	sim_grads_norm = 0.0442
-- Starting training on experience 143 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3640
	data_grads_norm = 4.4723
	new_data_grads_norm = 6.5394
	old_data_grads_norm = 4.7873
	sim_grads_norm = -0.0297
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6865
	data_grads_norm = 4.2952
	new_data_grads_norm = 6.8750
	old_data_grads_norm = 6.1285
	sim_grads_norm = 0.0585
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2639
	data_grads_norm = 4.4466
	new_data_grads_norm = 7.6924
	old_data_grads_norm = 5.1414
	sim_grads_norm = -0.0058
-- Starting training on experience 144 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6733
	data_grads_norm = 4.6347
	new_data_grads_norm = 8.2885
	old_data_grads_norm = 4.2360
	sim_grads_norm = -0.0003
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2996
	data_grads_norm = 4.2419
	new_data_grads_norm = 7.2889
	old_data_grads_norm = 6.1665
	sim_grads_norm = 0.0047
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3608
	data_grads_norm = 4.2279
	new_data_grads_norm = 7.0838
	old_data_grads_norm = 5.2644
	sim_grads_norm = 0.0082
-- Starting training on experience 145 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8869
	data_grads_norm = 4.2726
	new_data_grads_norm = 7.2196
	old_data_grads_norm = 4.3075
	sim_grads_norm = 0.0030
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1689
	data_grads_norm = 5.4125
	new_data_grads_norm = 8.1551
	old_data_grads_norm = 6.3055
	sim_grads_norm = 0.0286
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3115
	data_grads_norm = 4.7046
	new_data_grads_norm = 7.7084
	old_data_grads_norm = 5.5996
	sim_grads_norm = -0.0095
-- Starting training on experience 146 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9637
	data_grads_norm = 4.4092
	new_data_grads_norm = 6.9945
	old_data_grads_norm = 7.7798
	sim_grads_norm = -0.0307
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2150
	data_grads_norm = 4.5280
	new_data_grads_norm = 7.5011
	old_data_grads_norm = 5.6577
	sim_grads_norm = -0.0286
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8866
	data_grads_norm = 4.1105
	new_data_grads_norm = 7.5673
	old_data_grads_norm = 4.3336
	sim_grads_norm = -0.0115
-- Starting training on experience 147 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5475
	data_grads_norm = 4.8419
	new_data_grads_norm = 8.3307
	old_data_grads_norm = 6.5143
	sim_grads_norm = -0.0008
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3560
	data_grads_norm = 4.4145
	new_data_grads_norm = 7.6560
	old_data_grads_norm = 4.7571
	sim_grads_norm = -0.0170
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9415
	data_grads_norm = 5.2102
	new_data_grads_norm = 7.9940
	old_data_grads_norm = 7.8507
	sim_grads_norm = -0.0150
-- Starting training on experience 148 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7391
	data_grads_norm = 5.4134
	new_data_grads_norm = 7.1458
	old_data_grads_norm = 7.2406
	sim_grads_norm = 0.0325
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4405
	data_grads_norm = 4.8706
	new_data_grads_norm = 7.4415
	old_data_grads_norm = 6.3182
	sim_grads_norm = -0.0130
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4680
	data_grads_norm = 4.5373
	new_data_grads_norm = 6.9864
	old_data_grads_norm = 7.1013
	sim_grads_norm = 0.0379
-- Starting training on experience 149 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8626
	data_grads_norm = 5.2780
	new_data_grads_norm = 7.5563
	old_data_grads_norm = 7.0999
	sim_grads_norm = 0.0345
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3997
	data_grads_norm = 4.4884
	new_data_grads_norm = 6.7787
	old_data_grads_norm = 5.1739
	sim_grads_norm = -0.0143
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6308
	data_grads_norm = 4.5300
	new_data_grads_norm = 7.0571
	old_data_grads_norm = 5.7904
	sim_grads_norm = 0.0313
-- Starting training on experience 150 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8969
	data_grads_norm = 4.7918
	new_data_grads_norm = 5.7797
	old_data_grads_norm = 5.6260
	sim_grads_norm = -0.0032
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1837
	data_grads_norm = 5.3538
	new_data_grads_norm = 7.0746
	old_data_grads_norm = 6.5883
	sim_grads_norm = 0.0028
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2324
	data_grads_norm = 4.4159
	new_data_grads_norm = 6.4156
	old_data_grads_norm = 5.2646
	sim_grads_norm = 0.0188
-- Starting training on experience 151 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0675
	data_grads_norm = 5.0468
	new_data_grads_norm = 6.6104
	old_data_grads_norm = 7.7883
	sim_grads_norm = 0.0012
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7079
	data_grads_norm = 5.4500
	new_data_grads_norm = 6.3072
	old_data_grads_norm = 6.9480
	sim_grads_norm = 0.1006
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7605
	data_grads_norm = 4.2715
	new_data_grads_norm = 6.4369
	old_data_grads_norm = 3.9290
	sim_grads_norm = 0.0129
-- Starting training on experience 152 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5184
	data_grads_norm = 4.8602
	new_data_grads_norm = 7.1872
	old_data_grads_norm = 4.3915
	sim_grads_norm = -0.0019
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3888
	data_grads_norm = 5.5944
	new_data_grads_norm = 7.3728
	old_data_grads_norm = 9.1789
	sim_grads_norm = 0.0029
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5232
	data_grads_norm = 5.1041
	new_data_grads_norm = 6.8312
	old_data_grads_norm = 6.1717
	sim_grads_norm = 0.0315
-- Starting training on experience 153 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2409
	data_grads_norm = 4.7063
	new_data_grads_norm = 7.4371
	old_data_grads_norm = 6.1777
	sim_grads_norm = 0.0012
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0278
	data_grads_norm = 4.1456
	new_data_grads_norm = 7.0315
	old_data_grads_norm = 3.5427
	sim_grads_norm = -0.0209
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6863
	data_grads_norm = 5.1334
	new_data_grads_norm = 7.4870
	old_data_grads_norm = 5.1611
	sim_grads_norm = 0.0634
-- Starting training on experience 154 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1752
	data_grads_norm = 3.8760
	new_data_grads_norm = 6.3044
	old_data_grads_norm = 5.1753
	sim_grads_norm = -0.0392
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1273
	data_grads_norm = 5.0177
	new_data_grads_norm = 7.2785
	old_data_grads_norm = 6.4953
	sim_grads_norm = -0.0057
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8490
	data_grads_norm = 3.6996
	new_data_grads_norm = 6.6791
	old_data_grads_norm = 3.3213
	sim_grads_norm = -0.0126
-- Starting training on experience 155 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0308
	data_grads_norm = 4.0086
	new_data_grads_norm = 7.1924
	old_data_grads_norm = 3.5562
	sim_grads_norm = 0.0381
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4878
	data_grads_norm = 5.3311
	new_data_grads_norm = 6.6763
	old_data_grads_norm = 5.7387
	sim_grads_norm = -0.0086
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0481
	data_grads_norm = 4.1255
	new_data_grads_norm = 6.3392
	old_data_grads_norm = 4.7138
	sim_grads_norm = 0.0265
-- Starting training on experience 156 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1167
	data_grads_norm = 4.0349
	new_data_grads_norm = 6.7350
	old_data_grads_norm = 5.9615
	sim_grads_norm = -0.0149
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5438
	data_grads_norm = 5.0748
	new_data_grads_norm = 5.9660
	old_data_grads_norm = 6.7601
	sim_grads_norm = -0.0065
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7959
	data_grads_norm = 3.4992
	new_data_grads_norm = 6.3960
	old_data_grads_norm = 5.0511
	sim_grads_norm = -0.0085
-- Starting training on experience 157 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2623
	data_grads_norm = 5.4133
	new_data_grads_norm = 7.4291
	old_data_grads_norm = 6.9160
	sim_grads_norm = 0.0299
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5473
	data_grads_norm = 5.6611
	new_data_grads_norm = 6.9279
	old_data_grads_norm = 6.7475
	sim_grads_norm = 0.0192
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4847
	data_grads_norm = 3.5267
	new_data_grads_norm = 6.4440
	old_data_grads_norm = 4.6223
	sim_grads_norm = -0.0264
-- Starting training on experience 158 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3818
	data_grads_norm = 4.2483
	new_data_grads_norm = 6.3212
	old_data_grads_norm = 5.4684
	sim_grads_norm = -0.0258
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3893
	data_grads_norm = 4.2965
	new_data_grads_norm = 6.2663
	old_data_grads_norm = 6.9313
	sim_grads_norm = -0.0199
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1657
	data_grads_norm = 4.5056
	new_data_grads_norm = 7.0506
	old_data_grads_norm = 5.6514
	sim_grads_norm = -0.0059
-- Starting training on experience 159 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7597
	data_grads_norm = 4.7044
	new_data_grads_norm = 7.2854
	old_data_grads_norm = 6.4215
	sim_grads_norm = -0.0178
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7390
	data_grads_norm = 4.0557
	new_data_grads_norm = 7.2430
	old_data_grads_norm = 4.6338
	sim_grads_norm = 0.0275
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9920
	data_grads_norm = 4.1879
	new_data_grads_norm = 7.2179
	old_data_grads_norm = 3.3446
	sim_grads_norm = -0.0014
-- Starting training on experience 160 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4684
	data_grads_norm = 4.7210
	new_data_grads_norm = 7.6144
	old_data_grads_norm = 6.8098
	sim_grads_norm = 0.0077
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0019
	data_grads_norm = 5.8879
	new_data_grads_norm = 7.2252
	old_data_grads_norm = 6.6609
	sim_grads_norm = 0.0774
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2733
	data_grads_norm = 4.7009
	new_data_grads_norm = 6.4695
	old_data_grads_norm = 6.1649
	sim_grads_norm = -0.0298
-- Starting training on experience 161 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1715
	data_grads_norm = 4.4169
	new_data_grads_norm = 6.2881
	old_data_grads_norm = 6.3811
	sim_grads_norm = -0.0105
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8454
	data_grads_norm = 3.7040
	new_data_grads_norm = 7.2282
	old_data_grads_norm = 3.7390
	sim_grads_norm = 0.0072
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8218
	data_grads_norm = 5.1223
	new_data_grads_norm = 6.8112
	old_data_grads_norm = 6.0084
	sim_grads_norm = 0.0157
-- Starting training on experience 162 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2963
	data_grads_norm = 5.0339
	new_data_grads_norm = 7.2627
	old_data_grads_norm = 5.2308
	sim_grads_norm = -0.0023
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8049
	data_grads_norm = 4.8789
	new_data_grads_norm = 7.5893
	old_data_grads_norm = 5.6441
	sim_grads_norm = 0.0135
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3122
	data_grads_norm = 4.1099
	new_data_grads_norm = 7.4838
	old_data_grads_norm = 3.4474
	sim_grads_norm = 0.0623
-- Starting training on experience 163 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4755
	data_grads_norm = 4.4145
	new_data_grads_norm = 6.0724
	old_data_grads_norm = 5.8153
	sim_grads_norm = -0.0135
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4658
	data_grads_norm = 5.1214
	new_data_grads_norm = 8.1900
	old_data_grads_norm = 6.2739
	sim_grads_norm = -0.0302
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2626
	data_grads_norm = 4.4040
	new_data_grads_norm = 7.0291
	old_data_grads_norm = 3.8135
	sim_grads_norm = 0.0414
-- Starting training on experience 164 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3307
	data_grads_norm = 4.7125
	new_data_grads_norm = 6.8314
	old_data_grads_norm = 5.7416
	sim_grads_norm = 0.0068
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2525
	data_grads_norm = 4.5874
	new_data_grads_norm = 6.5909
	old_data_grads_norm = 5.8753
	sim_grads_norm = 0.0113
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4513
	data_grads_norm = 4.1308
	new_data_grads_norm = 7.2824
	old_data_grads_norm = 5.1350
	sim_grads_norm = 0.0121
-- Starting training on experience 165 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5548
	data_grads_norm = 4.1143
	new_data_grads_norm = 6.2263
	old_data_grads_norm = 4.6934
	sim_grads_norm = -0.0286
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4029
	data_grads_norm = 4.1393
	new_data_grads_norm = 6.5521
	old_data_grads_norm = 5.4609
	sim_grads_norm = -0.0024
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6204
	data_grads_norm = 4.6977
	new_data_grads_norm = 6.6209
	old_data_grads_norm = 6.1397
	sim_grads_norm = -0.0007
-- Starting training on experience 166 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6300
	data_grads_norm = 5.2032
	new_data_grads_norm = 8.7034
	old_data_grads_norm = 5.7839
	sim_grads_norm = 0.0435
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3770
	data_grads_norm = 4.4123
	new_data_grads_norm = 7.9458
	old_data_grads_norm = 5.3701
	sim_grads_norm = -0.0279
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2173
	data_grads_norm = 4.5403
	new_data_grads_norm = 7.8054
	old_data_grads_norm = 4.9426
	sim_grads_norm = 0.0068
-- Starting training on experience 167 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4449
	data_grads_norm = 4.4843
	new_data_grads_norm = 7.6810
	old_data_grads_norm = 3.0979
	sim_grads_norm = 0.0195
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2819
	data_grads_norm = 4.2789
	new_data_grads_norm = 8.5666
	old_data_grads_norm = 2.9599
	sim_grads_norm = 0.0062
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6628
	data_grads_norm = 4.9028
	new_data_grads_norm = 7.9606
	old_data_grads_norm = 6.9699
	sim_grads_norm = -0.0034
-- Starting training on experience 168 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3101
	data_grads_norm = 3.9822
	new_data_grads_norm = 6.2294
	old_data_grads_norm = 3.0462
	sim_grads_norm = -0.0086
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5585
	data_grads_norm = 4.3203
	new_data_grads_norm = 6.5680
	old_data_grads_norm = 5.7006
	sim_grads_norm = -0.0140
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3130
	data_grads_norm = 4.0469
	new_data_grads_norm = 6.1606
	old_data_grads_norm = 3.9634
	sim_grads_norm = -0.0177
-- Starting training on experience 169 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8453
	data_grads_norm = 5.1856
	new_data_grads_norm = 6.9799
	old_data_grads_norm = 5.9100
	sim_grads_norm = -0.0074
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3452
	data_grads_norm = 4.0143
	new_data_grads_norm = 7.7686
	old_data_grads_norm = 4.5085
	sim_grads_norm = -0.0144
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8325
	data_grads_norm = 5.4207
	new_data_grads_norm = 7.4280
	old_data_grads_norm = 6.6973
	sim_grads_norm = 0.0188
-- Starting training on experience 170 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7225
	data_grads_norm = 5.6179
	new_data_grads_norm = 8.2357
	old_data_grads_norm = 7.3375
	sim_grads_norm = 0.0084
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2422
	data_grads_norm = 4.6707
	new_data_grads_norm = 8.3628
	old_data_grads_norm = 4.3689
	sim_grads_norm = 0.0072
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4707
	data_grads_norm = 5.5089
	new_data_grads_norm = 8.1896
	old_data_grads_norm = 6.2292
	sim_grads_norm = -0.0012
-- Starting training on experience 171 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5058
	data_grads_norm = 4.7240
	new_data_grads_norm = 7.4568
	old_data_grads_norm = 6.7075
	sim_grads_norm = -0.0244
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3467
	data_grads_norm = 4.8744
	new_data_grads_norm = 7.4920
	old_data_grads_norm = 5.1581
	sim_grads_norm = 0.0389
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5013
	data_grads_norm = 4.4952
	new_data_grads_norm = 7.1558
	old_data_grads_norm = 7.4021
	sim_grads_norm = -0.0176
-- Starting training on experience 172 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9887
	data_grads_norm = 3.5367
	new_data_grads_norm = 6.9470
	old_data_grads_norm = 2.3527
	sim_grads_norm = -0.0147
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7102
	data_grads_norm = 4.9673
	new_data_grads_norm = 7.5178
	old_data_grads_norm = 6.2814
	sim_grads_norm = 0.0343
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3484
	data_grads_norm = 4.6695
	new_data_grads_norm = 7.2131
	old_data_grads_norm = 6.0344
	sim_grads_norm = 0.0257
-- Starting training on experience 173 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7116
	data_grads_norm = 4.6346
	new_data_grads_norm = 7.2030
	old_data_grads_norm = 3.2635
	sim_grads_norm = 0.0479
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8643
	data_grads_norm = 4.8991
	new_data_grads_norm = 6.9320
	old_data_grads_norm = 5.3127
	sim_grads_norm = 0.0037
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7446
	data_grads_norm = 4.9652
	new_data_grads_norm = 7.0699
	old_data_grads_norm = 4.2096
	sim_grads_norm = 0.0542
-- Starting training on experience 174 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5680
	data_grads_norm = 5.3697
	new_data_grads_norm = 7.8361
	old_data_grads_norm = 6.8977
	sim_grads_norm = 0.0071
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3775
	data_grads_norm = 5.1205
	new_data_grads_norm = 8.0589
	old_data_grads_norm = 8.0432
	sim_grads_norm = 0.0110
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1717
	data_grads_norm = 4.9578
	new_data_grads_norm = 8.3768
	old_data_grads_norm = 6.9564
	sim_grads_norm = -0.0254
-- Starting training on experience 175 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0378
	data_grads_norm = 4.3355
	new_data_grads_norm = 7.5881
	old_data_grads_norm = 5.5360
	sim_grads_norm = -0.0009
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2713
	data_grads_norm = 4.5212
	new_data_grads_norm = 7.2013
	old_data_grads_norm = 5.5033
	sim_grads_norm = 0.0490
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0387
	data_grads_norm = 4.4387
	new_data_grads_norm = 6.9457
	old_data_grads_norm = 3.6438
	sim_grads_norm = -0.0204
-- Starting training on experience 176 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5362
	data_grads_norm = 4.8121
	new_data_grads_norm = 8.0980
	old_data_grads_norm = 5.3910
	sim_grads_norm = 0.0022
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4833
	data_grads_norm = 4.8878
	new_data_grads_norm = 8.1361
	old_data_grads_norm = 6.8232
	sim_grads_norm = -0.0142
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4116
	data_grads_norm = 4.7619
	new_data_grads_norm = 7.9058
	old_data_grads_norm = 7.0395
	sim_grads_norm = 0.0033
-- Starting training on experience 177 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2175
	data_grads_norm = 3.9980
	new_data_grads_norm = 7.1814
	old_data_grads_norm = 4.5580
	sim_grads_norm = -0.0153
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4615
	data_grads_norm = 4.3726
	new_data_grads_norm = 7.8119
	old_data_grads_norm = 3.7937
	sim_grads_norm = -0.0105
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7103
	data_grads_norm = 4.3109
	new_data_grads_norm = 7.0787
	old_data_grads_norm = 5.2419
	sim_grads_norm = 0.0756
-- Starting training on experience 178 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6530
	data_grads_norm = 4.3007
	new_data_grads_norm = 7.4417
	old_data_grads_norm = 3.5423
	sim_grads_norm = -0.0047
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4600
	data_grads_norm = 4.3830
	new_data_grads_norm = 7.8917
	old_data_grads_norm = 5.5722
	sim_grads_norm = 0.0059
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5252
	data_grads_norm = 5.1824
	new_data_grads_norm = 7.8260
	old_data_grads_norm = 4.6602
	sim_grads_norm = 0.1416
-- Starting training on experience 179 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2410
	data_grads_norm = 4.3097
	new_data_grads_norm = 5.7065
	old_data_grads_norm = 5.6651
	sim_grads_norm = -0.0025
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9523
	data_grads_norm = 3.9635
	new_data_grads_norm = 6.0138
	old_data_grads_norm = 5.4906
	sim_grads_norm = -0.0114
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8637
	data_grads_norm = 3.6291
	new_data_grads_norm = 6.8597
	old_data_grads_norm = 4.9740
	sim_grads_norm = -0.0004
-- Starting training on experience 180 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4375
	data_grads_norm = 4.6848
	new_data_grads_norm = 7.9532
	old_data_grads_norm = 5.7666
	sim_grads_norm = -0.0312
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4374
	data_grads_norm = 5.3878
	new_data_grads_norm = 7.7208
	old_data_grads_norm = 5.1039
	sim_grads_norm = 0.1198
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5569
	data_grads_norm = 5.0679
	new_data_grads_norm = 7.1245
	old_data_grads_norm = 5.7673
	sim_grads_norm = -0.0407
-- Starting training on experience 181 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7518
	data_grads_norm = 4.7659
	new_data_grads_norm = 7.4073
	old_data_grads_norm = 4.7580
	sim_grads_norm = 0.1028
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1780
	data_grads_norm = 4.3798
	new_data_grads_norm = 7.2681
	old_data_grads_norm = 4.9828
	sim_grads_norm = -0.0071
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4693
	data_grads_norm = 4.5164
	new_data_grads_norm = 6.9450
	old_data_grads_norm = 6.9675
	sim_grads_norm = -0.0197
-- Starting training on experience 182 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6023
	data_grads_norm = 4.0757
	new_data_grads_norm = 7.1382
	old_data_grads_norm = 4.5541
	sim_grads_norm = -0.0001
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8640
	data_grads_norm = 4.9366
	new_data_grads_norm = 6.7999
	old_data_grads_norm = 6.8924
	sim_grads_norm = -0.0108
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8374
	data_grads_norm = 4.7913
	new_data_grads_norm = 7.3680
	old_data_grads_norm = 6.6303
	sim_grads_norm = 0.0189
-- Starting training on experience 183 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5822
	data_grads_norm = 5.1635
	new_data_grads_norm = 7.5516
	old_data_grads_norm = 7.1962
	sim_grads_norm = -0.0144
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3210
	data_grads_norm = 4.9442
	new_data_grads_norm = 7.1933
	old_data_grads_norm = 5.5857
	sim_grads_norm = 0.0153
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8909
	data_grads_norm = 5.4011
	new_data_grads_norm = 7.7718
	old_data_grads_norm = 7.6615
	sim_grads_norm = 0.0017
-- Starting training on experience 184 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6856
	data_grads_norm = 5.3711
	new_data_grads_norm = 7.9548
	old_data_grads_norm = 4.8983
	sim_grads_norm = 0.0031
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2825
	data_grads_norm = 5.4762
	new_data_grads_norm = 8.3921
	old_data_grads_norm = 6.3027
	sim_grads_norm = -0.0322
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0636
	data_grads_norm = 5.7366
	new_data_grads_norm = 8.8730
	old_data_grads_norm = 6.2843
	sim_grads_norm = 0.0170
-- Starting training on experience 185 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3430
	data_grads_norm = 4.6895
	new_data_grads_norm = 7.4047
	old_data_grads_norm = 4.7088
	sim_grads_norm = 0.0548
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0643
	data_grads_norm = 4.8089
	new_data_grads_norm = 7.0915
	old_data_grads_norm = 5.2446
	sim_grads_norm = -0.0282
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2843
	data_grads_norm = 5.1042
	new_data_grads_norm = 7.4343
	old_data_grads_norm = 6.7384
	sim_grads_norm = 0.0245
-- Starting training on experience 186 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4909
	data_grads_norm = 6.1245
	new_data_grads_norm = 8.4665
	old_data_grads_norm = 8.5192
	sim_grads_norm = -0.0215
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1622
	data_grads_norm = 4.0484
	new_data_grads_norm = 8.2250
	old_data_grads_norm = 4.7792
	sim_grads_norm = -0.0337
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7948
	data_grads_norm = 5.6164
	new_data_grads_norm = 8.5004
	old_data_grads_norm = 6.6407
	sim_grads_norm = 0.0503
-- Starting training on experience 187 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9786
	data_grads_norm = 4.7315
	new_data_grads_norm = 6.9538
	old_data_grads_norm = 5.4869
	sim_grads_norm = 0.0380
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0489
	data_grads_norm = 5.2699
	new_data_grads_norm = 8.1780
	old_data_grads_norm = 6.1439
	sim_grads_norm = 0.0460
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4571
	data_grads_norm = 4.2913
	new_data_grads_norm = 7.0389
	old_data_grads_norm = 5.5772
	sim_grads_norm = -0.0070
-- Starting training on experience 188 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7622
	data_grads_norm = 3.9598
	new_data_grads_norm = 7.4140
	old_data_grads_norm = 3.5487
	sim_grads_norm = 0.0024
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0856
	data_grads_norm = 4.2868
	new_data_grads_norm = 6.9782
	old_data_grads_norm = 5.0643
	sim_grads_norm = -0.0004
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1836
	data_grads_norm = 4.3264
	new_data_grads_norm = 7.4119
	old_data_grads_norm = 7.0094
	sim_grads_norm = -0.0098
-- Starting training on experience 189 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1324
	data_grads_norm = 3.9336
	new_data_grads_norm = 6.9948
	old_data_grads_norm = 5.3625
	sim_grads_norm = 0.0083
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3113
	data_grads_norm = 4.8024
	new_data_grads_norm = 7.8033
	old_data_grads_norm = 4.4384
	sim_grads_norm = 0.0064
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0367
	data_grads_norm = 4.3658
	new_data_grads_norm = 8.1368
	old_data_grads_norm = 3.8895
	sim_grads_norm = 0.0596
-- Starting training on experience 190 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4847
	data_grads_norm = 5.0310
	new_data_grads_norm = 8.1116
	old_data_grads_norm = 5.8091
	sim_grads_norm = -0.0034
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2391
	data_grads_norm = 4.7701
	new_data_grads_norm = 7.9106
	old_data_grads_norm = 4.9679
	sim_grads_norm = -0.0115
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5766
	data_grads_norm = 5.0312
	new_data_grads_norm = 8.4218
	old_data_grads_norm = 5.9262
	sim_grads_norm = 0.0118
-- Starting training on experience 191 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7318
	data_grads_norm = 4.4937
	new_data_grads_norm = 7.8910
	old_data_grads_norm = 5.1556
	sim_grads_norm = 0.0551
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7462
	data_grads_norm = 4.9913
	new_data_grads_norm = 7.0246
	old_data_grads_norm = 6.0699
	sim_grads_norm = 0.0396
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8648
	data_grads_norm = 4.6606
	new_data_grads_norm = 6.8999
	old_data_grads_norm = 6.4307
	sim_grads_norm = 0.0185
-- Starting training on experience 192 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2659
	data_grads_norm = 4.8379
	new_data_grads_norm = 8.0189
	old_data_grads_norm = 4.6540
	sim_grads_norm = 0.0008
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7141
	data_grads_norm = 5.2115
	new_data_grads_norm = 7.6194
	old_data_grads_norm = 6.7004
	sim_grads_norm = 0.0287
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9686
	data_grads_norm = 3.9956
	new_data_grads_norm = 7.0192
	old_data_grads_norm = 4.9491
	sim_grads_norm = 0.0079
-- Starting training on experience 193 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9208
	data_grads_norm = 4.7589
	new_data_grads_norm = 7.3198
	old_data_grads_norm = 4.2812
	sim_grads_norm = 0.0118
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1831
	data_grads_norm = 4.9860
	new_data_grads_norm = 7.6574
	old_data_grads_norm = 5.4725
	sim_grads_norm = -0.0187
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2554
	data_grads_norm = 4.7215
	new_data_grads_norm = 7.2762
	old_data_grads_norm = 5.3462
	sim_grads_norm = -0.0144
-- Starting training on experience 194 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8642
	data_grads_norm = 4.1225
	new_data_grads_norm = 6.6593
	old_data_grads_norm = 4.3233
	sim_grads_norm = 0.0620
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7647
	data_grads_norm = 4.5069
	new_data_grads_norm = 6.1632
	old_data_grads_norm = 5.0518
	sim_grads_norm = -0.0294
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3860
	data_grads_norm = 3.6147
	new_data_grads_norm = 6.4540
	old_data_grads_norm = 4.6872
	sim_grads_norm = 0.0102
-- Starting training on experience 195 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4630
	data_grads_norm = 4.2297
	new_data_grads_norm = 7.6491
	old_data_grads_norm = 5.1415
	sim_grads_norm = -0.0028
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3444
	data_grads_norm = 3.6509
	new_data_grads_norm = 6.6482
	old_data_grads_norm = 4.2622
	sim_grads_norm = -0.0059
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3785
	data_grads_norm = 3.7273
	new_data_grads_norm = 6.1788
	old_data_grads_norm = 3.5695
	sim_grads_norm = -0.0477
-- Starting training on experience 196 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7237
	data_grads_norm = 4.0345
	new_data_grads_norm = 6.7819
	old_data_grads_norm = 7.0475
	sim_grads_norm = -0.0226
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3215
	data_grads_norm = 4.5863
	new_data_grads_norm = 6.6308
	old_data_grads_norm = 5.7150
	sim_grads_norm = -0.0475
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4711
	data_grads_norm = 5.0010
	new_data_grads_norm = 7.4842
	old_data_grads_norm = 6.1438
	sim_grads_norm = 0.0225
-- Starting training on experience 197 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8039
	data_grads_norm = 4.2855
	new_data_grads_norm = 6.9529
	old_data_grads_norm = 5.5443
	sim_grads_norm = -0.0202
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6003
	data_grads_norm = 4.2013
	new_data_grads_norm = 7.4155
	old_data_grads_norm = 6.3277
	sim_grads_norm = -0.0198
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7722
	data_grads_norm = 4.3255
	new_data_grads_norm = 7.4749
	old_data_grads_norm = 4.5069
	sim_grads_norm = -0.0174
-- Starting training on experience 198 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0955
	data_grads_norm = 4.8177
	new_data_grads_norm = 7.8307
	old_data_grads_norm = 5.8178
	sim_grads_norm = 0.0337
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9627
	data_grads_norm = 4.6893
	new_data_grads_norm = 7.2281
	old_data_grads_norm = 5.8775
	sim_grads_norm = -0.0035
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8681
	data_grads_norm = 4.5486
	new_data_grads_norm = 8.1579
	old_data_grads_norm = 5.4023
	sim_grads_norm = -0.0006
-- Starting training on experience 199 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1874
	data_grads_norm = 4.3071
	new_data_grads_norm = 7.3502
	old_data_grads_norm = 4.4702
	sim_grads_norm = 0.0198
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3306
	data_grads_norm = 4.7033
	new_data_grads_norm = 7.2239
	old_data_grads_norm = 6.4106
	sim_grads_norm = -0.0087
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4865
	data_grads_norm = 4.5233
	new_data_grads_norm = 7.5115
	old_data_grads_norm = 5.8997
	sim_grads_norm = 0.0061
-- Starting training on experience 200 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6820
	data_grads_norm = 5.0087
	new_data_grads_norm = 7.7865
	old_data_grads_norm = 5.8051
	sim_grads_norm = 0.0040
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9049
	data_grads_norm = 4.9602
	new_data_grads_norm = 7.7589
	old_data_grads_norm = 4.7300
	sim_grads_norm = -0.0214
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7222
	data_grads_norm = 4.5772
	new_data_grads_norm = 7.6267
	old_data_grads_norm = 4.0803
	sim_grads_norm = 0.0417
-- Starting training on experience 201 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3695
	data_grads_norm = 4.5499
	new_data_grads_norm = 6.8069
	old_data_grads_norm = 6.2071
	sim_grads_norm = 0.0128
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8580
	data_grads_norm = 4.9104
	new_data_grads_norm = 7.7937
	old_data_grads_norm = 6.6889
	sim_grads_norm = -0.0254
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5766
	data_grads_norm = 3.7803
	new_data_grads_norm = 7.6338
	old_data_grads_norm = 3.2816
	sim_grads_norm = 0.0511
-- Starting training on experience 202 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1115
	data_grads_norm = 4.1316
	new_data_grads_norm = 7.0787
	old_data_grads_norm = 4.5393
	sim_grads_norm = 0.1029
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1422
	data_grads_norm = 4.5466
	new_data_grads_norm = 5.9018
	old_data_grads_norm = 5.6664
	sim_grads_norm = 0.0291
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8346
	data_grads_norm = 4.4473
	new_data_grads_norm = 7.1778
	old_data_grads_norm = 4.5148
	sim_grads_norm = -0.0207
-- Starting training on experience 203 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9526
	data_grads_norm = 4.0069
	new_data_grads_norm = 5.9229
	old_data_grads_norm = 4.6385
	sim_grads_norm = 0.1125
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7814
	data_grads_norm = 4.0676
	new_data_grads_norm = 6.4529
	old_data_grads_norm = 5.2685
	sim_grads_norm = 0.0149
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7754
	data_grads_norm = 3.7167
	new_data_grads_norm = 6.0716
	old_data_grads_norm = 4.1419
	sim_grads_norm = -0.0262
-- Starting training on experience 204 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9182
	data_grads_norm = 4.6750
	new_data_grads_norm = 7.0027
	old_data_grads_norm = 4.0344
	sim_grads_norm = 0.0829
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4820
	data_grads_norm = 3.7143
	new_data_grads_norm = 6.5554
	old_data_grads_norm = 3.8723
	sim_grads_norm = -0.0335
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3880
	data_grads_norm = 5.0650
	new_data_grads_norm = 7.3323
	old_data_grads_norm = 6.5606
	sim_grads_norm = -0.0043
-- Starting training on experience 205 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3191
	data_grads_norm = 5.0285
	new_data_grads_norm = 6.3337
	old_data_grads_norm = 7.1175
	sim_grads_norm = -0.0002
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8288
	data_grads_norm = 4.6658
	new_data_grads_norm = 6.4689
	old_data_grads_norm = 4.0840
	sim_grads_norm = 0.0073
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7353
	data_grads_norm = 3.4870
	new_data_grads_norm = 6.3735
	old_data_grads_norm = 6.0034
	sim_grads_norm = -0.0299
-- Starting training on experience 206 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5326
	data_grads_norm = 4.3027
	new_data_grads_norm = 7.4678
	old_data_grads_norm = 4.7349
	sim_grads_norm = -0.0086
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0125
	data_grads_norm = 4.4560
	new_data_grads_norm = 7.5454
	old_data_grads_norm = 5.1160
	sim_grads_norm = -0.0246
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4706
	data_grads_norm = 5.2072
	new_data_grads_norm = 7.6564
	old_data_grads_norm = 6.6292
	sim_grads_norm = -0.0369
-- Starting training on experience 207 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0124
	data_grads_norm = 5.6454
	new_data_grads_norm = 6.5195
	old_data_grads_norm = 7.6812
	sim_grads_norm = -0.0011
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7012
	data_grads_norm = 4.1287
	new_data_grads_norm = 7.2117
	old_data_grads_norm = 4.7984
	sim_grads_norm = 0.0187
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7987
	data_grads_norm = 4.3918
	new_data_grads_norm = 7.9221
	old_data_grads_norm = 3.7120
	sim_grads_norm = -0.0224
-- Starting training on experience 208 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9220
	data_grads_norm = 4.8466
	new_data_grads_norm = 7.2615
	old_data_grads_norm = 6.1264
	sim_grads_norm = 0.0140
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0641
	data_grads_norm = 4.1746
	new_data_grads_norm = 6.9539
	old_data_grads_norm = 4.3454
	sim_grads_norm = -0.0585
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0691
	data_grads_norm = 4.7221
	new_data_grads_norm = 7.1820
	old_data_grads_norm = 4.9833
	sim_grads_norm = 0.0204
-- Starting training on experience 209 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1612
	data_grads_norm = 4.3446
	new_data_grads_norm = 8.1895
	old_data_grads_norm = 2.3590
	sim_grads_norm = -0.0057
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4988
	data_grads_norm = 4.7124
	new_data_grads_norm = 6.3153
	old_data_grads_norm = 5.3451
	sim_grads_norm = 0.0127
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2940
	data_grads_norm = 4.3620
	new_data_grads_norm = 7.3164
	old_data_grads_norm = 5.7109
	sim_grads_norm = -0.0282
-- Starting training on experience 210 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1842
	data_grads_norm = 4.9461
	new_data_grads_norm = 6.8768
	old_data_grads_norm = 7.3466
	sim_grads_norm = 0.0350
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9187
	data_grads_norm = 4.7305
	new_data_grads_norm = 8.0116
	old_data_grads_norm = 4.4331
	sim_grads_norm = 0.0232
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2008
	data_grads_norm = 4.6457
	new_data_grads_norm = 8.0534
	old_data_grads_norm = 5.2689
	sim_grads_norm = 0.0981
-- Starting training on experience 211 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6774
	data_grads_norm = 4.6593
	new_data_grads_norm = 8.2937
	old_data_grads_norm = 4.0109
	sim_grads_norm = 0.0505
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3609
	data_grads_norm = 4.6564
	new_data_grads_norm = 8.1026
	old_data_grads_norm = 5.3018
	sim_grads_norm = 0.0288
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5759
	data_grads_norm = 4.4957
	new_data_grads_norm = 7.6949
	old_data_grads_norm = 6.2783
	sim_grads_norm = -0.0490
-- Starting training on experience 212 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0056
	data_grads_norm = 5.0919
	new_data_grads_norm = 6.5976
	old_data_grads_norm = 7.9304
	sim_grads_norm = 0.0020
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1036
	data_grads_norm = 3.7535
	new_data_grads_norm = 6.3457
	old_data_grads_norm = 4.0395
	sim_grads_norm = 0.0153
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0671
	data_grads_norm = 5.3587
	new_data_grads_norm = 7.3233
	old_data_grads_norm = 7.1042
	sim_grads_norm = 0.0323
-- Starting training on experience 213 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2668
	data_grads_norm = 4.6357
	new_data_grads_norm = 7.5525
	old_data_grads_norm = 5.5097
	sim_grads_norm = -0.0031
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2839
	data_grads_norm = 4.3236
	new_data_grads_norm = 7.7052
	old_data_grads_norm = 4.6195
	sim_grads_norm = -0.0223
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2685
	data_grads_norm = 5.0599
	new_data_grads_norm = 7.8505
	old_data_grads_norm = 5.5722
	sim_grads_norm = 0.0029
-- Starting training on experience 214 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7081
	data_grads_norm = 4.9236
	new_data_grads_norm = 8.6255
	old_data_grads_norm = 5.4881
	sim_grads_norm = 0.0051
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4229
	data_grads_norm = 5.3808
	new_data_grads_norm = 8.2784
	old_data_grads_norm = 6.0453
	sim_grads_norm = 0.0468
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0470
	data_grads_norm = 5.2592
	new_data_grads_norm = 8.7267
	old_data_grads_norm = 5.6382
	sim_grads_norm = 0.0473
-- Starting training on experience 215 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8730
	data_grads_norm = 3.9738
	new_data_grads_norm = 7.3042
	old_data_grads_norm = 5.5379
	sim_grads_norm = -0.0059
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2318
	data_grads_norm = 4.1929
	new_data_grads_norm = 7.0910
	old_data_grads_norm = 4.0106
	sim_grads_norm = 0.0156
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8987
	data_grads_norm = 3.7644
	new_data_grads_norm = 7.1293
	old_data_grads_norm = 4.4698
	sim_grads_norm = 0.0429
-- Starting training on experience 216 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4882
	data_grads_norm = 3.9204
	new_data_grads_norm = 6.2471
	old_data_grads_norm = 3.1711
	sim_grads_norm = -0.0213
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8671
	data_grads_norm = 4.3224
	new_data_grads_norm = 6.7538
	old_data_grads_norm = 5.1368
	sim_grads_norm = -0.0044
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8573
	data_grads_norm = 4.8958
	new_data_grads_norm = 7.1031
	old_data_grads_norm = 3.8439
	sim_grads_norm = -0.0125
-- Starting training on experience 217 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3212
	data_grads_norm = 4.7887
	new_data_grads_norm = 7.9405
	old_data_grads_norm = 5.6260
	sim_grads_norm = -0.0121
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6137
	data_grads_norm = 4.9976
	new_data_grads_norm = 7.8882
	old_data_grads_norm = 5.7064
	sim_grads_norm = 0.0048
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1030
	data_grads_norm = 5.1779
	new_data_grads_norm = 7.7260
	old_data_grads_norm = 7.4059
	sim_grads_norm = 0.0574
-- Starting training on experience 218 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2857
	data_grads_norm = 4.9123
	new_data_grads_norm = 7.8095
	old_data_grads_norm = 4.5607
	sim_grads_norm = 0.0143
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0355
	data_grads_norm = 4.6355
	new_data_grads_norm = 7.2411
	old_data_grads_norm = 6.0492
	sim_grads_norm = -0.0044
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9478
	data_grads_norm = 4.1212
	new_data_grads_norm = 6.7911
	old_data_grads_norm = 3.6472
	sim_grads_norm = 0.1266
-- Starting training on experience 219 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9759
	data_grads_norm = 4.5195
	new_data_grads_norm = 7.9017
	old_data_grads_norm = 4.4127
	sim_grads_norm = 0.0144
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9086
	data_grads_norm = 5.3300
	new_data_grads_norm = 8.0257
	old_data_grads_norm = 7.3617
	sim_grads_norm = 0.0381
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7936
	data_grads_norm = 3.9752
	new_data_grads_norm = 7.5085
	old_data_grads_norm = 3.9632
	sim_grads_norm = -0.0230
-- Starting training on experience 220 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7418
	data_grads_norm = 4.6552
	new_data_grads_norm = 8.5011
	old_data_grads_norm = 5.0192
	sim_grads_norm = 0.0206
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3408
	data_grads_norm = 4.5995
	new_data_grads_norm = 8.7295
	old_data_grads_norm = 4.2508
	sim_grads_norm = 0.0386
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6766
	data_grads_norm = 4.5879
	new_data_grads_norm = 7.6161
	old_data_grads_norm = 4.0552
	sim_grads_norm = 0.0186
-- Starting training on experience 221 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8410
	data_grads_norm = 4.5301
	new_data_grads_norm = 6.4383
	old_data_grads_norm = 5.3358
	sim_grads_norm = -0.0141
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5927
	data_grads_norm = 4.6516
	new_data_grads_norm = 5.9708
	old_data_grads_norm = 6.7101
	sim_grads_norm = 0.0164
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0306
	data_grads_norm = 4.5776
	new_data_grads_norm = 6.0574
	old_data_grads_norm = 5.7749
	sim_grads_norm = -0.0756
-- Starting training on experience 222 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4766
	data_grads_norm = 5.6693
	new_data_grads_norm = 7.8273
	old_data_grads_norm = 7.7637
	sim_grads_norm = 0.0060
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1105
	data_grads_norm = 5.2628
	new_data_grads_norm = 8.4214
	old_data_grads_norm = 5.9094
	sim_grads_norm = -0.0906
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9396
	data_grads_norm = 5.9686
	new_data_grads_norm = 9.3377
	old_data_grads_norm = 6.1513
	sim_grads_norm = 0.0254
-- Starting training on experience 223 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3157
	data_grads_norm = 5.0676
	new_data_grads_norm = 9.3586
	old_data_grads_norm = 4.1984
	sim_grads_norm = 0.0228
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0274
	data_grads_norm = 4.7841
	new_data_grads_norm = 8.7336
	old_data_grads_norm = 4.3525
	sim_grads_norm = 0.0312
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4033
	data_grads_norm = 5.3025
	new_data_grads_norm = 8.2587
	old_data_grads_norm = 5.5806
	sim_grads_norm = -0.0280
-- Starting training on experience 224 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9302
	data_grads_norm = 4.7919
	new_data_grads_norm = 8.8094
	old_data_grads_norm = 5.6128
	sim_grads_norm = -0.0138
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5274
	data_grads_norm = 4.2750
	new_data_grads_norm = 7.0810
	old_data_grads_norm = 4.7701
	sim_grads_norm = -0.0509
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7546
	data_grads_norm = 4.4018
	new_data_grads_norm = 8.6071
	old_data_grads_norm = 4.7215
	sim_grads_norm = -0.0087
-- Starting training on experience 225 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2316
	data_grads_norm = 4.8794
	new_data_grads_norm = 8.4994
	old_data_grads_norm = 3.8309
	sim_grads_norm = -0.0525
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8282
	data_grads_norm = 3.8972
	new_data_grads_norm = 7.6112
	old_data_grads_norm = 3.1097
	sim_grads_norm = 0.0264
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6299
	data_grads_norm = 5.4775
	new_data_grads_norm = 8.3369
	old_data_grads_norm = 6.3194
	sim_grads_norm = 0.0794
-- Starting training on experience 226 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6816
	data_grads_norm = 5.7429
	new_data_grads_norm = 8.8954
	old_data_grads_norm = 6.0550
	sim_grads_norm = 0.0178
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5031
	data_grads_norm = 4.9759
	new_data_grads_norm = 8.5457
	old_data_grads_norm = 4.6085
	sim_grads_norm = 0.0033
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3956
	data_grads_norm = 5.1039
	new_data_grads_norm = 8.5888
	old_data_grads_norm = 4.4106
	sim_grads_norm = -0.0036
-- Starting training on experience 227 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5063
	data_grads_norm = 3.6524
	new_data_grads_norm = 5.8347
	old_data_grads_norm = 3.9397
	sim_grads_norm = -0.0177
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7795
	data_grads_norm = 4.2985
	new_data_grads_norm = 7.3328
	old_data_grads_norm = 4.9514
	sim_grads_norm = -0.0218
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5481
	data_grads_norm = 3.8339
	new_data_grads_norm = 7.3796
	old_data_grads_norm = 6.5306
	sim_grads_norm = -0.0191
-- Starting training on experience 228 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6244
	data_grads_norm = 4.3861
	new_data_grads_norm = 8.1003
	old_data_grads_norm = 4.5596
	sim_grads_norm = 0.0304
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5093
	data_grads_norm = 4.1716
	new_data_grads_norm = 8.0867
	old_data_grads_norm = 2.5860
	sim_grads_norm = -0.0262
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1670
	data_grads_norm = 5.1222
	new_data_grads_norm = 7.8826
	old_data_grads_norm = 7.7279
	sim_grads_norm = 0.0502
-- Starting training on experience 229 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4521
	data_grads_norm = 5.6407
	new_data_grads_norm = 7.8419
	old_data_grads_norm = 7.5213
	sim_grads_norm = 0.0595
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9363
	data_grads_norm = 4.5475
	new_data_grads_norm = 7.4195
	old_data_grads_norm = 5.4052
	sim_grads_norm = -0.0471
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8761
	data_grads_norm = 4.5417
	new_data_grads_norm = 7.1448
	old_data_grads_norm = 5.3131
	sim_grads_norm = -0.0730
-- Starting training on experience 230 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5455
	data_grads_norm = 5.2240
	new_data_grads_norm = 8.0578
	old_data_grads_norm = 7.1544
	sim_grads_norm = 0.0088
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6259
	data_grads_norm = 5.3837
	new_data_grads_norm = 7.8575
	old_data_grads_norm = 6.3724
	sim_grads_norm = -0.0255
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3131
	data_grads_norm = 4.2744
	new_data_grads_norm = 6.6070
	old_data_grads_norm = 5.3934
	sim_grads_norm = 0.0475
-- Starting training on experience 231 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2415
	data_grads_norm = 4.6644
	new_data_grads_norm = 9.3828
	old_data_grads_norm = 4.4521
	sim_grads_norm = 0.0367
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4121
	data_grads_norm = 5.3395
	new_data_grads_norm = 8.9737
	old_data_grads_norm = 6.0715
	sim_grads_norm = -0.0136
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8008
	data_grads_norm = 5.2701
	new_data_grads_norm = 8.5543
	old_data_grads_norm = 6.5527
	sim_grads_norm = 0.0211
-- Starting training on experience 232 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9092
	data_grads_norm = 4.4261
	new_data_grads_norm = 7.6704
	old_data_grads_norm = 6.3239
	sim_grads_norm = -0.0054
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3114
	data_grads_norm = 5.2336
	new_data_grads_norm = 7.5959
	old_data_grads_norm = 5.9549
	sim_grads_norm = -0.0149
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1728
	data_grads_norm = 4.7873
	new_data_grads_norm = 6.8869
	old_data_grads_norm = 7.0068
	sim_grads_norm = 0.0006
-- Starting training on experience 233 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6615
	data_grads_norm = 4.7163
	new_data_grads_norm = 8.3012
	old_data_grads_norm = 5.4146
	sim_grads_norm = 0.0083
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6031
	data_grads_norm = 5.2598
	new_data_grads_norm = 7.4432
	old_data_grads_norm = 5.5649
	sim_grads_norm = 0.0063
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3221
	data_grads_norm = 4.4364
	new_data_grads_norm = 7.6116
	old_data_grads_norm = 6.1750
	sim_grads_norm = -0.0072
-- Starting training on experience 234 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6594
	data_grads_norm = 4.0420
	new_data_grads_norm = 8.3007
	old_data_grads_norm = 5.2972
	sim_grads_norm = 0.0341
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8072
	data_grads_norm = 4.1613
	new_data_grads_norm = 7.6610
	old_data_grads_norm = 4.2163
	sim_grads_norm = -0.0378
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9803
	data_grads_norm = 4.2595
	new_data_grads_norm = 7.9180
	old_data_grads_norm = 4.8960
	sim_grads_norm = -0.0183
-- Starting training on experience 235 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6471
	data_grads_norm = 5.4535
	new_data_grads_norm = 8.8405
	old_data_grads_norm = 4.3573
	sim_grads_norm = 0.0658
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1569
	data_grads_norm = 4.9188
	new_data_grads_norm = 8.4300
	old_data_grads_norm = 5.3978
	sim_grads_norm = -0.0263
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1086
	data_grads_norm = 4.5287
	new_data_grads_norm = 7.6967
	old_data_grads_norm = 4.6208
	sim_grads_norm = -0.0012
-- Starting training on experience 236 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9971
	data_grads_norm = 4.2134
	new_data_grads_norm = 6.8173
	old_data_grads_norm = 5.2442
	sim_grads_norm = -0.0303
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3990
	data_grads_norm = 2.9994
	new_data_grads_norm = 6.8938
	old_data_grads_norm = 5.1493
	sim_grads_norm = -0.0112
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5376
	data_grads_norm = 3.3693
	new_data_grads_norm = 7.3133
	old_data_grads_norm = 3.0227
	sim_grads_norm = 0.1132
-- Starting training on experience 237 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
-- >> End of training phase << --
-- >> Start of eval phase << --
-- Starting eval on experience 0 (Task 0) from test stream --
> Eval on experience 0 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp000 = 4.6066
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.2520
	mb_index = 4522
	time = 1531.6580
-- Starting eval on experience 1 (Task 0) from test stream --
> Eval on experience 1 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp001 = 3.0239
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.4300
-- Starting eval on experience 2 (Task 0) from test stream --
> Eval on experience 2 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp002 = 5.0984
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.2220
-- Starting eval on experience 3 (Task 0) from test stream --
> Eval on experience 3 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp003 = 3.6475
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.3800
-- Starting eval on experience 4 (Task 0) from test stream --
> Eval on experience 4 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp004 = 4.9126
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.2320
-- Starting eval on experience 5 (Task 0) from test stream --
> Eval on experience 5 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp005 = 4.9804
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.3060
-- Starting eval on experience 6 (Task 0) from test stream --
> Eval on experience 6 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp006 = 4.3483
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp006 = 0.2600
-- Starting eval on experience 7 (Task 0) from test stream --
> Eval on experience 7 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp007 = 4.1553
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp007 = 0.3400
-- Starting eval on experience 8 (Task 0) from test stream --
> Eval on experience 8 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp008 = 4.1648
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp008 = 0.3340
-- Starting eval on experience 9 (Task 0) from test stream --
> Eval on experience 9 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp009 = 4.2063
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp009 = 0.2440
-- Starting eval on experience 10 (Task 0) from test stream --
> Eval on experience 10 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp010 = 4.1360
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp010 = 0.2300
-- Starting eval on experience 11 (Task 0) from test stream --
> Eval on experience 11 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp011 = 3.1941
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp011 = 0.4440
-- Starting eval on experience 12 (Task 0) from test stream --
> Eval on experience 12 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp012 = 5.1312
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp012 = 0.0960
-- Starting eval on experience 13 (Task 0) from test stream --
> Eval on experience 13 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp013 = 3.4125
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp013 = 0.2920
-- Starting eval on experience 14 (Task 0) from test stream --
> Eval on experience 14 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp014 = 3.2517
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp014 = 0.3060
-- Starting eval on experience 15 (Task 0) from test stream --
> Eval on experience 15 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp015 = 3.7887
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp015 = 0.2560
-- Starting eval on experience 16 (Task 0) from test stream --
> Eval on experience 16 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp016 = 3.2962
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp016 = 0.2820
-- Starting eval on experience 17 (Task 0) from test stream --
> Eval on experience 17 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp017 = 4.2606
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp017 = 0.1400
-- Starting eval on experience 18 (Task 0) from test stream --
> Eval on experience 18 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp018 = 4.0169
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp018 = 0.1120
-- >> End of eval phase << --
	CumulativeAccuracy/eval_phase/test_stream/Exp000 = 0.7280
	CumulativeAccuracy/eval_phase/test_stream/Exp001 = 0.6890
	CumulativeAccuracy/eval_phase/test_stream/Exp002 = 0.5713
	CumulativeAccuracy/eval_phase/test_stream/Exp003 = 0.5500
	CumulativeAccuracy/eval_phase/test_stream/Exp004 = 0.5008
	CumulativeAccuracy/eval_phase/test_stream/Exp005 = 0.4730
	CumulativeAccuracy/eval_phase/test_stream/Exp006 = 0.4489
	CumulativeAccuracy/eval_phase/test_stream/Exp007 = 0.4278
	CumulativeAccuracy/eval_phase/test_stream/Exp008 = 0.4140
	CumulativeAccuracy/eval_phase/test_stream/Exp009 = 0.3990
	CumulativeAccuracy/eval_phase/test_stream/Exp010 = 0.3764
	CumulativeAccuracy/eval_phase/test_stream/Exp011 = 0.3680
	CumulativeAccuracy/eval_phase/test_stream/Exp012 = 0.3406
	CumulativeAccuracy/eval_phase/test_stream/Exp013 = 0.3254
	CumulativeAccuracy/eval_phase/test_stream/Exp014 = 0.3139
	CumulativeAccuracy/eval_phase/test_stream/Exp015 = 0.3014
	CumulativeAccuracy/eval_phase/test_stream/Exp016 = 0.2931
	CumulativeAccuracy/eval_phase/test_stream/Exp017 = 0.2828
	CumulativeAccuracy/eval_phase/test_stream/Exp018 = 0.2715
	Loss_Stream/eval_phase/test_stream/Task000 = 4.0859
	Top1_Acc_Stream/eval_phase/test_stream/Task000 = 0.2715
-- >> Start of training phase << --
-- Starting training on experience 0 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.3337
	data_grads_norm = 5.8144
	new_data_grads_norm = 9.0857
	old_data_grads_norm = 4.8620
	sim_grads_norm = 0.0057
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.1828
	data_grads_norm = 5.5928
	new_data_grads_norm = 8.7646
	old_data_grads_norm = 5.4763
	sim_grads_norm = 0.0037
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.4025
	data_grads_norm = 5.1893
	new_data_grads_norm = 8.6524
	old_data_grads_norm = 3.7934
	sim_grads_norm = 0.0159
-- Starting training on experience 1 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6320
	data_grads_norm = 4.4771
	new_data_grads_norm = 7.0874
	old_data_grads_norm = 4.9011
	sim_grads_norm = -0.0145
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.7276
	data_grads_norm = 5.0809
	new_data_grads_norm = 8.2233
	old_data_grads_norm = 6.4084
	sim_grads_norm = 0.0014
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.8868
	data_grads_norm = 4.6409
	new_data_grads_norm = 7.6397
	old_data_grads_norm = 5.7464
	sim_grads_norm = -0.0182
-- Starting training on experience 2 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6783
	data_grads_norm = 4.1757
	new_data_grads_norm = 7.4752
	old_data_grads_norm = 4.3767
	sim_grads_norm = 0.0195
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.1714
	data_grads_norm = 4.8282
	new_data_grads_norm = 7.6413
	old_data_grads_norm = 6.2117
	sim_grads_norm = 0.0299
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.0875
	data_grads_norm = 4.6033
	new_data_grads_norm = 8.4570
	old_data_grads_norm = 4.0576
	sim_grads_norm = 0.0009
-- Starting training on experience 3 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.0083
	data_grads_norm = 5.3223
	new_data_grads_norm = 8.1059
	old_data_grads_norm = 4.6332
	sim_grads_norm = 0.0042
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.5013
	data_grads_norm = 6.0499
	new_data_grads_norm = 8.3721
	old_data_grads_norm = 4.9373
	sim_grads_norm = -0.0111
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.2846
	data_grads_norm = 5.7233
	new_data_grads_norm = 8.5602
	old_data_grads_norm = 7.6907
	sim_grads_norm = 0.0219
-- Starting training on experience 4 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.3085
	data_grads_norm = 5.2471
	new_data_grads_norm = 7.2702
	old_data_grads_norm = 6.2444
	sim_grads_norm = 0.0149
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.3570
	data_grads_norm = 5.0666
	new_data_grads_norm = 7.9324
	old_data_grads_norm = 5.8035
	sim_grads_norm = 0.0120
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.1347
	data_grads_norm = 5.2555
	new_data_grads_norm = 7.0912
	old_data_grads_norm = 7.0148
	sim_grads_norm = -0.0126
-- Starting training on experience 5 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.1723
	data_grads_norm = 5.0511
	new_data_grads_norm = 7.4775
	old_data_grads_norm = 5.5868
	sim_grads_norm = -0.0065
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.8068
	data_grads_norm = 4.2826
	new_data_grads_norm = 6.8699
	old_data_grads_norm = 3.8394
	sim_grads_norm = 0.0122
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.9815
	data_grads_norm = 4.8609
	new_data_grads_norm = 6.9880
	old_data_grads_norm = 7.2733
	sim_grads_norm = 0.0104
-- Starting training on experience 6 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.5114
	data_grads_norm = 5.1828
	new_data_grads_norm = 8.0884
	old_data_grads_norm = 5.3706
	sim_grads_norm = 0.0097
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.7130
	data_grads_norm = 4.4473
	new_data_grads_norm = 7.0895
	old_data_grads_norm = 4.7379
	sim_grads_norm = -0.0103
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.5102
	data_grads_norm = 5.4827
	new_data_grads_norm = 7.9130
	old_data_grads_norm = 7.8006
	sim_grads_norm = 0.0099
-- Starting training on experience 7 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.6991
	data_grads_norm = 5.1839
	new_data_grads_norm = 8.8850
	old_data_grads_norm = 4.5227
	sim_grads_norm = 0.0592
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.0424
	data_grads_norm = 5.5157
	new_data_grads_norm = 8.2249
	old_data_grads_norm = 5.6943
	sim_grads_norm = 0.0030
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.9846
	data_grads_norm = 4.9187
	new_data_grads_norm = 8.5604
	old_data_grads_norm = 4.2577
	sim_grads_norm = -0.0203
-- Starting training on experience 8 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.3495
	data_grads_norm = 4.8738
	new_data_grads_norm = 8.3707
	old_data_grads_norm = 4.4957
	sim_grads_norm = 0.1200
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.2648
	data_grads_norm = 4.4586
	new_data_grads_norm = 7.1213
	old_data_grads_norm = 2.8787
	sim_grads_norm = 0.1122
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.3433
	data_grads_norm = 4.8590
	new_data_grads_norm = 7.3977
	old_data_grads_norm = 5.2946
	sim_grads_norm = 0.0186
-- Starting training on experience 9 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.3747
	data_grads_norm = 5.0602
	new_data_grads_norm = 7.7109
	old_data_grads_norm = 4.2680
	sim_grads_norm = 0.0158
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.6211
	data_grads_norm = 5.5768
	new_data_grads_norm = 8.4798
	old_data_grads_norm = 7.3859
	sim_grads_norm = 0.0253
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.6119
	data_grads_norm = 4.4414
	new_data_grads_norm = 7.7579
	old_data_grads_norm = 3.9920
	sim_grads_norm = -0.0018
-- Starting training on experience 10 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.0238
	data_grads_norm = 4.6498
	new_data_grads_norm = 7.2124
	old_data_grads_norm = 4.2904
	sim_grads_norm = 0.0938
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.8824
	data_grads_norm = 4.8271
	new_data_grads_norm = 7.4794
	old_data_grads_norm = 4.3641
	sim_grads_norm = 0.0123
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.2146
	data_grads_norm = 5.4585
	new_data_grads_norm = 8.1819
	old_data_grads_norm = 5.7018
	sim_grads_norm = 0.0519
-- Starting training on experience 11 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.9527
	data_grads_norm = 4.4645
	new_data_grads_norm = 6.8437
	old_data_grads_norm = 5.5026
	sim_grads_norm = 0.0663
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1720
	data_grads_norm = 4.5705
	new_data_grads_norm = 6.2117
	old_data_grads_norm = 6.6741
	sim_grads_norm = 0.0012
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.4285
	data_grads_norm = 5.3555
	new_data_grads_norm = 7.6180
	old_data_grads_norm = 6.7244
	sim_grads_norm = 0.0726
-- Starting training on experience 12 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0676
	data_grads_norm = 4.8558
	new_data_grads_norm = 6.7690
	old_data_grads_norm = 6.6488
	sim_grads_norm = -0.0074
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1271
	data_grads_norm = 5.1025
	new_data_grads_norm = 6.6465
	old_data_grads_norm = 5.4849
	sim_grads_norm = 0.0585
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5894
	data_grads_norm = 6.1146
	new_data_grads_norm = 7.8762
	old_data_grads_norm = 7.7014
	sim_grads_norm = -0.0137
-- Starting training on experience 13 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.0273
	data_grads_norm = 5.1467
	new_data_grads_norm = 8.0817
	old_data_grads_norm = 5.2553
	sim_grads_norm = 0.0561
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3530
	data_grads_norm = 5.6041
	new_data_grads_norm = 8.7924
	old_data_grads_norm = 6.0697
	sim_grads_norm = 0.0036
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3814
	data_grads_norm = 5.3243
	new_data_grads_norm = 9.2413
	old_data_grads_norm = 5.1366
	sim_grads_norm = 0.0390
-- Starting training on experience 14 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0505
	data_grads_norm = 4.7749
	new_data_grads_norm = 6.4179
	old_data_grads_norm = 6.1230
	sim_grads_norm = 0.0068
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0695
	data_grads_norm = 4.1749
	new_data_grads_norm = 7.8210
	old_data_grads_norm = 3.1416
	sim_grads_norm = 0.1237
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9546
	data_grads_norm = 4.8190
	new_data_grads_norm = 7.0656
	old_data_grads_norm = 6.2264
	sim_grads_norm = 0.0033
-- Starting training on experience 15 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1423
	data_grads_norm = 5.2058
	new_data_grads_norm = 8.1559
	old_data_grads_norm = 5.8743
	sim_grads_norm = 0.0230
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2171
	data_grads_norm = 5.9645
	new_data_grads_norm = 8.5771
	old_data_grads_norm = 7.0996
	sim_grads_norm = 0.0667
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5486
	data_grads_norm = 5.2846
	new_data_grads_norm = 8.3402
	old_data_grads_norm = 5.1310
	sim_grads_norm = 0.0050
-- Starting training on experience 16 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.1118
	data_grads_norm = 4.9440
	new_data_grads_norm = 9.2085
	old_data_grads_norm = 4.6561
	sim_grads_norm = 0.0569
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.4875
	data_grads_norm = 5.5291
	new_data_grads_norm = 7.9256
	old_data_grads_norm = 5.4067
	sim_grads_norm = 0.0652
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5558
	data_grads_norm = 4.5832
	new_data_grads_norm = 8.4991
	old_data_grads_norm = 5.6521
	sim_grads_norm = -0.0147
-- Starting training on experience 17 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7798
	data_grads_norm = 4.1943
	new_data_grads_norm = 6.3921
	old_data_grads_norm = 5.3138
	sim_grads_norm = 0.0496
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.8943
	data_grads_norm = 4.0984
	new_data_grads_norm = 6.1088
	old_data_grads_norm = 4.5895
	sim_grads_norm = 0.0404
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9108
	data_grads_norm = 4.1837
	new_data_grads_norm = 6.0782
	old_data_grads_norm = 5.1811
	sim_grads_norm = 0.0064
-- Starting training on experience 18 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 5.1176
	data_grads_norm = 5.1433
	new_data_grads_norm = 7.0109
	old_data_grads_norm = 6.6582
	sim_grads_norm = 0.0278
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.2126
	data_grads_norm = 4.4550
	new_data_grads_norm = 6.8952
	old_data_grads_norm = 5.3177
	sim_grads_norm = -0.0355
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.5508
	data_grads_norm = 5.0572
	new_data_grads_norm = 7.0428
	old_data_grads_norm = 6.9676
	sim_grads_norm = 0.1389
-- Starting training on experience 19 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7547
	data_grads_norm = 4.2932
	new_data_grads_norm = 6.8809
	old_data_grads_norm = 5.6104
	sim_grads_norm = 0.0592
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3606
	data_grads_norm = 4.6828
	new_data_grads_norm = 6.9807
	old_data_grads_norm = 5.9673
	sim_grads_norm = -0.0172
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9543
	data_grads_norm = 4.9727
	new_data_grads_norm = 7.0888
	old_data_grads_norm = 5.6492
	sim_grads_norm = 0.0131
-- Starting training on experience 20 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1825
	data_grads_norm = 4.0284
	new_data_grads_norm = 6.3544
	old_data_grads_norm = 4.1557
	sim_grads_norm = -0.0229
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2438
	data_grads_norm = 4.2806
	new_data_grads_norm = 7.1638
	old_data_grads_norm = 5.6717
	sim_grads_norm = 0.0054
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4735
	data_grads_norm = 4.7726
	new_data_grads_norm = 7.1498
	old_data_grads_norm = 5.4814
	sim_grads_norm = -0.0083
-- Starting training on experience 21 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.0661
	data_grads_norm = 5.4954
	new_data_grads_norm = 6.8669
	old_data_grads_norm = 7.9975
	sim_grads_norm = 0.0202
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3747
	data_grads_norm = 4.3381
	new_data_grads_norm = 6.4229
	old_data_grads_norm = 5.8527
	sim_grads_norm = 0.0006
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1208
	data_grads_norm = 3.6902
	new_data_grads_norm = 6.9593
	old_data_grads_norm = 1.9290
	sim_grads_norm = 0.0402
-- Starting training on experience 22 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6205
	data_grads_norm = 4.2791
	new_data_grads_norm = 6.9785
	old_data_grads_norm = 5.4224
	sim_grads_norm = -0.0024
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9338
	data_grads_norm = 5.0698
	new_data_grads_norm = 7.5577
	old_data_grads_norm = 6.4497
	sim_grads_norm = 0.0189
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 4.3503
	data_grads_norm = 4.7037
	new_data_grads_norm = 7.0061
	old_data_grads_norm = 6.9886
	sim_grads_norm = 0.0640
-- Starting training on experience 23 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4918
	data_grads_norm = 4.3591
	new_data_grads_norm = 7.1972
	old_data_grads_norm = 3.5626
	sim_grads_norm = -0.0094
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7718
	data_grads_norm = 4.2385
	new_data_grads_norm = 7.1903
	old_data_grads_norm = 5.2311
	sim_grads_norm = -0.0151
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7624
	data_grads_norm = 5.0536
	new_data_grads_norm = 6.9849
	old_data_grads_norm = 7.4564
	sim_grads_norm = -0.0085
-- Starting training on experience 24 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2723
	data_grads_norm = 4.4268
	new_data_grads_norm = 6.9756
	old_data_grads_norm = 4.9470
	sim_grads_norm = -0.0066
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3097
	data_grads_norm = 4.1052
	new_data_grads_norm = 7.1126
	old_data_grads_norm = 4.5483
	sim_grads_norm = 0.0199
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2462
	data_grads_norm = 3.9619
	new_data_grads_norm = 7.0081
	old_data_grads_norm = 5.6266
	sim_grads_norm = 0.0334
-- Starting training on experience 25 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5575
	data_grads_norm = 5.0003
	new_data_grads_norm = 7.5903
	old_data_grads_norm = 6.1393
	sim_grads_norm = 0.0046
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4307
	data_grads_norm = 4.6738
	new_data_grads_norm = 7.4746
	old_data_grads_norm = 4.4214
	sim_grads_norm = 0.0763
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9670
	data_grads_norm = 4.4639
	new_data_grads_norm = 7.2821
	old_data_grads_norm = 4.7073
	sim_grads_norm = -0.0031
-- Starting training on experience 26 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0770
	data_grads_norm = 3.8464
	new_data_grads_norm = 6.8146
	old_data_grads_norm = 3.2306
	sim_grads_norm = -0.0172
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3718
	data_grads_norm = 4.6463
	new_data_grads_norm = 6.5893
	old_data_grads_norm = 4.8228
	sim_grads_norm = 0.0079
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9627
	data_grads_norm = 3.9121
	new_data_grads_norm = 8.2518
	old_data_grads_norm = 2.1442
	sim_grads_norm = -0.0153
-- Starting training on experience 27 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2799
	data_grads_norm = 4.1829
	new_data_grads_norm = 6.2526
	old_data_grads_norm = 4.4175
	sim_grads_norm = 0.0166
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4438
	data_grads_norm = 4.8868
	new_data_grads_norm = 6.2680
	old_data_grads_norm = 4.3023
	sim_grads_norm = 0.1007
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1350
	data_grads_norm = 4.7457
	new_data_grads_norm = 7.0647
	old_data_grads_norm = 4.9248
	sim_grads_norm = 0.0200
-- Starting training on experience 28 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2794
	data_grads_norm = 4.2529
	new_data_grads_norm = 6.4036
	old_data_grads_norm = 5.2572
	sim_grads_norm = 0.0189
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1543
	data_grads_norm = 3.9049
	new_data_grads_norm = 6.3955
	old_data_grads_norm = 4.0584
	sim_grads_norm = 0.0069
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0139
	data_grads_norm = 4.1852
	new_data_grads_norm = 6.5755
	old_data_grads_norm = 6.3514
	sim_grads_norm = -0.0559
-- Starting training on experience 29 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1416
	data_grads_norm = 3.9254
	new_data_grads_norm = 6.3325
	old_data_grads_norm = 5.0724
	sim_grads_norm = 0.1122
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6144
	data_grads_norm = 3.9547
	new_data_grads_norm = 6.1847
	old_data_grads_norm = 5.9941
	sim_grads_norm = -0.0202
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6478
	data_grads_norm = 3.8651
	new_data_grads_norm = 5.9635
	old_data_grads_norm = 4.9533
	sim_grads_norm = -0.0224
-- Starting training on experience 30 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3803
	data_grads_norm = 5.1607
	new_data_grads_norm = 8.0256
	old_data_grads_norm = 6.8316
	sim_grads_norm = -0.0510
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9881
	data_grads_norm = 4.2830
	new_data_grads_norm = 7.4415
	old_data_grads_norm = 4.2753
	sim_grads_norm = -0.0201
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7138
	data_grads_norm = 4.8578
	new_data_grads_norm = 8.1181
	old_data_grads_norm = 4.2988
	sim_grads_norm = 0.0469
-- Starting training on experience 31 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9830
	data_grads_norm = 5.6694
	new_data_grads_norm = 7.9181
	old_data_grads_norm = 6.7755
	sim_grads_norm = 0.0177
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4657
	data_grads_norm = 4.2293
	new_data_grads_norm = 7.2779
	old_data_grads_norm = 4.7359
	sim_grads_norm = -0.0120
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0358
	data_grads_norm = 5.0969
	new_data_grads_norm = 6.9698
	old_data_grads_norm = 5.7454
	sim_grads_norm = 0.0489
-- Starting training on experience 32 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8230
	data_grads_norm = 3.8613
	new_data_grads_norm = 6.1990
	old_data_grads_norm = 3.6384
	sim_grads_norm = -0.0369
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8753
	data_grads_norm = 4.8118
	new_data_grads_norm = 6.9515
	old_data_grads_norm = 4.6876
	sim_grads_norm = 0.0032
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9281
	data_grads_norm = 4.1926
	new_data_grads_norm = 6.8153
	old_data_grads_norm = 3.6120
	sim_grads_norm = 0.0519
-- Starting training on experience 33 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3107
	data_grads_norm = 4.7636
	new_data_grads_norm = 7.5751
	old_data_grads_norm = 5.2556
	sim_grads_norm = -0.0165
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1369
	data_grads_norm = 4.6074
	new_data_grads_norm = 7.7365
	old_data_grads_norm = 3.8116
	sim_grads_norm = 0.0405
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8250
	data_grads_norm = 3.9373
	new_data_grads_norm = 6.6765
	old_data_grads_norm = 4.2462
	sim_grads_norm = -0.0127
-- Starting training on experience 34 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3174
	data_grads_norm = 5.0783
	new_data_grads_norm = 7.6345
	old_data_grads_norm = 6.6020
	sim_grads_norm = 0.0535
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0024
	data_grads_norm = 4.3609
	new_data_grads_norm = 7.2896
	old_data_grads_norm = 4.8102
	sim_grads_norm = 0.0130
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9209
	data_grads_norm = 4.5827
	new_data_grads_norm = 7.1095
	old_data_grads_norm = 4.0813
	sim_grads_norm = 0.0126
-- Starting training on experience 35 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6362
	data_grads_norm = 4.3091
	new_data_grads_norm = 5.2790
	old_data_grads_norm = 6.3742
	sim_grads_norm = -0.0159
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7656
	data_grads_norm = 4.7188
	new_data_grads_norm = 6.5885
	old_data_grads_norm = 7.6195
	sim_grads_norm = -0.0118
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9856
	data_grads_norm = 4.7939
	new_data_grads_norm = 6.6678
	old_data_grads_norm = 6.2243
	sim_grads_norm = 0.0190
-- Starting training on experience 36 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9479
	data_grads_norm = 4.0575
	new_data_grads_norm = 6.1223
	old_data_grads_norm = 5.9779
	sim_grads_norm = 0.0129
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9574
	data_grads_norm = 5.0148
	new_data_grads_norm = 6.9073
	old_data_grads_norm = 5.8720
	sim_grads_norm = 0.0161
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9333
	data_grads_norm = 4.5202
	new_data_grads_norm = 6.5969
	old_data_grads_norm = 4.7759
	sim_grads_norm = 0.0634
-- Starting training on experience 37 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7563
	data_grads_norm = 4.4527
	new_data_grads_norm = 6.6379
	old_data_grads_norm = 4.9040
	sim_grads_norm = -0.0043
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0081
	data_grads_norm = 5.0407
	new_data_grads_norm = 6.7753
	old_data_grads_norm = 6.1531
	sim_grads_norm = -0.0157
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7397
	data_grads_norm = 5.0233
	new_data_grads_norm = 6.7274
	old_data_grads_norm = 6.6073
	sim_grads_norm = 0.0134
-- Starting training on experience 38 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1313
	data_grads_norm = 4.9177
	new_data_grads_norm = 7.8726
	old_data_grads_norm = 5.3153
	sim_grads_norm = -0.0139
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7120
	data_grads_norm = 4.3892
	new_data_grads_norm = 7.0969
	old_data_grads_norm = 5.5476
	sim_grads_norm = 0.0228
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4766
	data_grads_norm = 3.9649
	new_data_grads_norm = 7.1717
	old_data_grads_norm = 3.4444
	sim_grads_norm = 0.0002
-- Starting training on experience 39 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3787
	data_grads_norm = 5.0439
	new_data_grads_norm = 7.7487
	old_data_grads_norm = 6.3779
	sim_grads_norm = 0.0268
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9230
	data_grads_norm = 4.8202
	new_data_grads_norm = 7.3635
	old_data_grads_norm = 5.8201
	sim_grads_norm = 0.0002
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6912
	data_grads_norm = 5.3688
	new_data_grads_norm = 6.8455
	old_data_grads_norm = 7.9053
	sim_grads_norm = -0.0220
-- Starting training on experience 40 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1922
	data_grads_norm = 5.3903
	new_data_grads_norm = 8.1624
	old_data_grads_norm = 6.0638
	sim_grads_norm = 0.0430
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3787
	data_grads_norm = 5.9059
	new_data_grads_norm = 8.5887
	old_data_grads_norm = 7.9635
	sim_grads_norm = -0.0066
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8598
	data_grads_norm = 4.8706
	new_data_grads_norm = 7.2850
	old_data_grads_norm = 5.4377
	sim_grads_norm = 0.0033
-- Starting training on experience 41 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0509
	data_grads_norm = 4.9733
	new_data_grads_norm = 6.5691
	old_data_grads_norm = 6.6580
	sim_grads_norm = 0.0248
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7603
	data_grads_norm = 4.5406
	new_data_grads_norm = 6.0922
	old_data_grads_norm = 5.6522
	sim_grads_norm = 0.0458
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8254
	data_grads_norm = 4.8099
	new_data_grads_norm = 6.8250
	old_data_grads_norm = 5.2677
	sim_grads_norm = -0.0196
-- Starting training on experience 42 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4174
	data_grads_norm = 3.9620
	new_data_grads_norm = 6.1675
	old_data_grads_norm = 4.5553
	sim_grads_norm = -0.0174
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8346
	data_grads_norm = 4.2925
	new_data_grads_norm = 6.1881
	old_data_grads_norm = 5.4279
	sim_grads_norm = 0.0032
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6336
	data_grads_norm = 4.3347
	new_data_grads_norm = 6.0624
	old_data_grads_norm = 5.9970
	sim_grads_norm = -0.0248
-- Starting training on experience 43 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8850
	data_grads_norm = 4.5992
	new_data_grads_norm = 6.9160
	old_data_grads_norm = 6.8408
	sim_grads_norm = -0.0075
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5753
	data_grads_norm = 5.3552
	new_data_grads_norm = 7.0169
	old_data_grads_norm = 7.2602
	sim_grads_norm = 0.0888
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6207
	data_grads_norm = 5.0157
	new_data_grads_norm = 7.1594
	old_data_grads_norm = 6.1121
	sim_grads_norm = 0.0210
-- Starting training on experience 44 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9477
	data_grads_norm = 4.7189
	new_data_grads_norm = 7.2810
	old_data_grads_norm = 5.4848
	sim_grads_norm = -0.0029
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8772
	data_grads_norm = 4.6004
	new_data_grads_norm = 7.4077
	old_data_grads_norm = 4.3000
	sim_grads_norm = -0.0224
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9941
	data_grads_norm = 5.0627
	new_data_grads_norm = 7.4760
	old_data_grads_norm = 5.5013
	sim_grads_norm = -0.0067
-- Starting training on experience 45 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8765
	data_grads_norm = 4.7085
	new_data_grads_norm = 8.1432
	old_data_grads_norm = 6.2935
	sim_grads_norm = 0.0000
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6203
	data_grads_norm = 4.2180
	new_data_grads_norm = 7.2642
	old_data_grads_norm = 5.0838
	sim_grads_norm = -0.0075
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5051
	data_grads_norm = 4.1783
	new_data_grads_norm = 7.9629
	old_data_grads_norm = 4.4291
	sim_grads_norm = -0.0187
-- Starting training on experience 46 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8956
	data_grads_norm = 5.2312
	new_data_grads_norm = 6.7606
	old_data_grads_norm = 7.1654
	sim_grads_norm = -0.0179
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4165
	data_grads_norm = 3.9321
	new_data_grads_norm = 6.2910
	old_data_grads_norm = 4.7119
	sim_grads_norm = 0.0397
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5655
	data_grads_norm = 4.6388
	new_data_grads_norm = 6.5600
	old_data_grads_norm = 5.9147
	sim_grads_norm = -0.0120
-- Starting training on experience 47 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4292
	data_grads_norm = 4.1106
	new_data_grads_norm = 7.4420
	old_data_grads_norm = 5.2338
	sim_grads_norm = -0.0266
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7589
	data_grads_norm = 5.0520
	new_data_grads_norm = 7.1088
	old_data_grads_norm = 6.0667
	sim_grads_norm = -0.0091
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8201
	data_grads_norm = 4.9760
	new_data_grads_norm = 7.8171
	old_data_grads_norm = 5.5140
	sim_grads_norm = -0.0363
-- Starting training on experience 48 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5669
	data_grads_norm = 4.1072
	new_data_grads_norm = 7.3876
	old_data_grads_norm = 4.3936
	sim_grads_norm = -0.0350
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5213
	data_grads_norm = 4.2639
	new_data_grads_norm = 7.6847
	old_data_grads_norm = 3.6739
	sim_grads_norm = -0.0183
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4808
	data_grads_norm = 4.1081
	new_data_grads_norm = 7.1791
	old_data_grads_norm = 6.5014
	sim_grads_norm = 0.0062
-- Starting training on experience 49 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7510
	data_grads_norm = 4.4990
	new_data_grads_norm = 6.9370
	old_data_grads_norm = 4.9539
	sim_grads_norm = 0.0149
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0283
	data_grads_norm = 5.0208
	new_data_grads_norm = 7.7366
	old_data_grads_norm = 5.5224
	sim_grads_norm = 0.0364
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6633
	data_grads_norm = 4.5921
	new_data_grads_norm = 7.3774
	old_data_grads_norm = 6.2201
	sim_grads_norm = -0.0269
-- Starting training on experience 50 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8134
	data_grads_norm = 5.0797
	new_data_grads_norm = 6.7270
	old_data_grads_norm = 7.2786
	sim_grads_norm = -0.0023
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4390
	data_grads_norm = 4.2334
	new_data_grads_norm = 6.8271
	old_data_grads_norm = 5.1027
	sim_grads_norm = -0.0060
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8307
	data_grads_norm = 4.4217
	new_data_grads_norm = 6.9673
	old_data_grads_norm = 4.6991
	sim_grads_norm = 0.0772
-- Starting training on experience 51 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7571
	data_grads_norm = 4.6537
	new_data_grads_norm = 8.5355
	old_data_grads_norm = 3.6251
	sim_grads_norm = -0.0183
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7241
	data_grads_norm = 4.5778
	new_data_grads_norm = 6.6736
	old_data_grads_norm = 5.7982
	sim_grads_norm = 0.0023
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.7099
	data_grads_norm = 5.9975
	new_data_grads_norm = 8.7579
	old_data_grads_norm = 7.3362
	sim_grads_norm = -0.0153
-- Starting training on experience 52 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7886
	data_grads_norm = 4.2273
	new_data_grads_norm = 7.8222
	old_data_grads_norm = 4.0918
	sim_grads_norm = -0.0070
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.9117
	data_grads_norm = 5.3771
	new_data_grads_norm = 6.4480
	old_data_grads_norm = 6.9552
	sim_grads_norm = -0.0102
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1706
	data_grads_norm = 4.3058
	new_data_grads_norm = 7.2722
	old_data_grads_norm = 4.4392
	sim_grads_norm = 0.0633
-- Starting training on experience 53 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7982
	data_grads_norm = 4.3386
	new_data_grads_norm = 6.3652
	old_data_grads_norm = 5.6852
	sim_grads_norm = 0.0111
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7771
	data_grads_norm = 4.2555
	new_data_grads_norm = 6.1883
	old_data_grads_norm = 5.8212
	sim_grads_norm = 0.0170
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1493
	data_grads_norm = 4.6461
	new_data_grads_norm = 7.1399
	old_data_grads_norm = 6.1141
	sim_grads_norm = -0.0157
-- Starting training on experience 54 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7803
	data_grads_norm = 4.7836
	new_data_grads_norm = 6.9483
	old_data_grads_norm = 6.1136
	sim_grads_norm = -0.0115
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5708
	data_grads_norm = 4.5578
	new_data_grads_norm = 8.0732
	old_data_grads_norm = 4.8685
	sim_grads_norm = -0.0048
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9134
	data_grads_norm = 5.4127
	new_data_grads_norm = 7.5543
	old_data_grads_norm = 5.7472
	sim_grads_norm = 0.0611
-- Starting training on experience 55 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8297
	data_grads_norm = 4.0568
	new_data_grads_norm = 6.0759
	old_data_grads_norm = 5.0168
	sim_grads_norm = 0.0206
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8414
	data_grads_norm = 4.8478
	new_data_grads_norm = 6.4695
	old_data_grads_norm = 6.5250
	sim_grads_norm = 0.0174
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6016
	data_grads_norm = 3.8114
	new_data_grads_norm = 5.9271
	old_data_grads_norm = 4.5866
	sim_grads_norm = 0.0113
-- Starting training on experience 56 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9032
	data_grads_norm = 4.6539
	new_data_grads_norm = 6.3887
	old_data_grads_norm = 5.3819
	sim_grads_norm = -0.0278
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0546
	data_grads_norm = 5.1692
	new_data_grads_norm = 7.3057
	old_data_grads_norm = 7.6084
	sim_grads_norm = 0.0174
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0975
	data_grads_norm = 5.0265
	new_data_grads_norm = 5.6979
	old_data_grads_norm = 6.8984
	sim_grads_norm = 0.0145
-- Starting training on experience 57 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6956
	data_grads_norm = 4.4100
	new_data_grads_norm = 7.5895
	old_data_grads_norm = 4.3818
	sim_grads_norm = 0.1288
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5491
	data_grads_norm = 4.0879
	new_data_grads_norm = 7.0316
	old_data_grads_norm = 4.4330
	sim_grads_norm = 0.0292
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5623
	data_grads_norm = 4.9323
	new_data_grads_norm = 7.3020
	old_data_grads_norm = 5.7517
	sim_grads_norm = -0.0299
-- Starting training on experience 58 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4825
	data_grads_norm = 4.1291
	new_data_grads_norm = 7.5266
	old_data_grads_norm = 4.3018
	sim_grads_norm = -0.0132
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8836
	data_grads_norm = 4.4482
	new_data_grads_norm = 6.9180
	old_data_grads_norm = 6.3159
	sim_grads_norm = -0.0682
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7978
	data_grads_norm = 4.9595
	new_data_grads_norm = 7.8686
	old_data_grads_norm = 3.8880
	sim_grads_norm = -0.0107
-- Starting training on experience 59 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7217
	data_grads_norm = 4.2955
	new_data_grads_norm = 5.3399
	old_data_grads_norm = 7.0876
	sim_grads_norm = -0.0032
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4136
	data_grads_norm = 3.4379
	new_data_grads_norm = 5.6655
	old_data_grads_norm = 3.6460
	sim_grads_norm = 0.1046
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6028
	data_grads_norm = 4.9547
	new_data_grads_norm = 5.0629
	old_data_grads_norm = 6.4374
	sim_grads_norm = -0.0402
-- Starting training on experience 60 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7650
	data_grads_norm = 4.4405
	new_data_grads_norm = 6.8227
	old_data_grads_norm = 5.4831
	sim_grads_norm = 0.0095
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7560
	data_grads_norm = 4.0621
	new_data_grads_norm = 7.3785
	old_data_grads_norm = 2.3298
	sim_grads_norm = 0.0448
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2169
	data_grads_norm = 5.1158
	new_data_grads_norm = 8.4374
	old_data_grads_norm = 4.9130
	sim_grads_norm = 0.0224
-- Starting training on experience 61 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6170
	data_grads_norm = 4.7085
	new_data_grads_norm = 6.6018
	old_data_grads_norm = 5.7864
	sim_grads_norm = 0.0281
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3760
	data_grads_norm = 4.5062
	new_data_grads_norm = 6.7502
	old_data_grads_norm = 5.9826
	sim_grads_norm = 0.0007
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6059
	data_grads_norm = 4.4650
	new_data_grads_norm = 6.2672
	old_data_grads_norm = 5.4516
	sim_grads_norm = -0.0108
-- Starting training on experience 62 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5640
	data_grads_norm = 4.3990
	new_data_grads_norm = 7.1355
	old_data_grads_norm = 4.9220
	sim_grads_norm = -0.0176
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7650
	data_grads_norm = 4.2707
	new_data_grads_norm = 6.6468
	old_data_grads_norm = 4.0059
	sim_grads_norm = 0.0848
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6071
	data_grads_norm = 3.9536
	new_data_grads_norm = 6.6718
	old_data_grads_norm = 4.5479
	sim_grads_norm = 0.0087
-- Starting training on experience 63 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2608
	data_grads_norm = 5.3854
	new_data_grads_norm = 7.1648
	old_data_grads_norm = 7.2504
	sim_grads_norm = 0.0097
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.6379
	data_grads_norm = 5.7556
	new_data_grads_norm = 7.7807
	old_data_grads_norm = 6.3501
	sim_grads_norm = 0.0338
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9981
	data_grads_norm = 4.9905
	new_data_grads_norm = 6.8017
	old_data_grads_norm = 6.4294
	sim_grads_norm = -0.0131
-- Starting training on experience 64 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0669
	data_grads_norm = 5.2403
	new_data_grads_norm = 6.0067
	old_data_grads_norm = 7.7188
	sim_grads_norm = 0.0497
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9800
	data_grads_norm = 4.9686
	new_data_grads_norm = 6.3019
	old_data_grads_norm = 6.6563
	sim_grads_norm = -0.0159
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3768
	data_grads_norm = 4.1171
	new_data_grads_norm = 5.8894
	old_data_grads_norm = 5.7345
	sim_grads_norm = 0.0024
-- Starting training on experience 65 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4307
	data_grads_norm = 4.2779
	new_data_grads_norm = 7.2372
	old_data_grads_norm = 3.6556
	sim_grads_norm = 0.0002
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8165
	data_grads_norm = 4.7965
	new_data_grads_norm = 7.1031
	old_data_grads_norm = 5.9485
	sim_grads_norm = -0.0131
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7290
	data_grads_norm = 4.3420
	new_data_grads_norm = 6.6242
	old_data_grads_norm = 4.2616
	sim_grads_norm = -0.0298
-- Starting training on experience 66 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8106
	data_grads_norm = 5.5523
	new_data_grads_norm = 8.4036
	old_data_grads_norm = 4.3344
	sim_grads_norm = 0.0104
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4601
	data_grads_norm = 4.5821
	new_data_grads_norm = 7.1704
	old_data_grads_norm = 5.3569
	sim_grads_norm = 0.0102
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5875
	data_grads_norm = 4.3799
	new_data_grads_norm = 8.2622
	old_data_grads_norm = 3.9633
	sim_grads_norm = -0.0083
-- Starting training on experience 67 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7715
	data_grads_norm = 4.2549
	new_data_grads_norm = 6.7884
	old_data_grads_norm = 4.5584
	sim_grads_norm = -0.0261
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9654
	data_grads_norm = 4.5500
	new_data_grads_norm = 7.2869
	old_data_grads_norm = 4.1508
	sim_grads_norm = 0.0090
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5395
	data_grads_norm = 4.0194
	new_data_grads_norm = 6.7201
	old_data_grads_norm = 3.0131
	sim_grads_norm = 0.0467
-- Starting training on experience 68 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9760
	data_grads_norm = 5.0488
	new_data_grads_norm = 8.2633
	old_data_grads_norm = 6.0738
	sim_grads_norm = -0.0004
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6430
	data_grads_norm = 4.1613
	new_data_grads_norm = 7.9719
	old_data_grads_norm = 3.1331
	sim_grads_norm = -0.0014
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6942
	data_grads_norm = 4.1144
	new_data_grads_norm = 7.4452
	old_data_grads_norm = 3.9957
	sim_grads_norm = -0.0135
-- Starting training on experience 69 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8188
	data_grads_norm = 4.5162
	new_data_grads_norm = 7.3378
	old_data_grads_norm = 7.5325
	sim_grads_norm = 0.0626
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1886
	data_grads_norm = 4.8167
	new_data_grads_norm = 7.5601
	old_data_grads_norm = 5.7055
	sim_grads_norm = -0.0162
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0363
	data_grads_norm = 5.2363
	new_data_grads_norm = 6.7010
	old_data_grads_norm = 8.1788
	sim_grads_norm = 0.0446
-- Starting training on experience 70 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6089
	data_grads_norm = 4.2937
	new_data_grads_norm = 7.1676
	old_data_grads_norm = 3.6835
	sim_grads_norm = -0.0013
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6360
	data_grads_norm = 4.3846
	new_data_grads_norm = 6.8288
	old_data_grads_norm = 6.8457
	sim_grads_norm = -0.0067
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8700
	data_grads_norm = 5.1913
	new_data_grads_norm = 7.8102
	old_data_grads_norm = 6.0712
	sim_grads_norm = -0.0085
-- Starting training on experience 71 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1452
	data_grads_norm = 4.5415
	new_data_grads_norm = 6.8983
	old_data_grads_norm = 4.8746
	sim_grads_norm = -0.0200
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3907
	data_grads_norm = 5.5218
	new_data_grads_norm = 7.3658
	old_data_grads_norm = 8.5197
	sim_grads_norm = 0.0038
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0896
	data_grads_norm = 4.6054
	new_data_grads_norm = 6.6279
	old_data_grads_norm = 5.0517
	sim_grads_norm = 0.0562
-- Starting training on experience 72 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.5746
	data_grads_norm = 5.6668
	new_data_grads_norm = 6.8252
	old_data_grads_norm = 6.7075
	sim_grads_norm = 0.0413
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8595
	data_grads_norm = 4.1784
	new_data_grads_norm = 7.4387
	old_data_grads_norm = 5.9397
	sim_grads_norm = -0.0180
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3707
	data_grads_norm = 4.8100
	new_data_grads_norm = 7.3365
	old_data_grads_norm = 6.5391
	sim_grads_norm = 0.0671
-- Starting training on experience 73 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8184
	data_grads_norm = 4.3339
	new_data_grads_norm = 6.4462
	old_data_grads_norm = 5.1850
	sim_grads_norm = -0.0010
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4095
	data_grads_norm = 3.9565
	new_data_grads_norm = 6.1179
	old_data_grads_norm = 4.6671
	sim_grads_norm = 0.0164
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8453
	data_grads_norm = 4.6945
	new_data_grads_norm = 7.3740
	old_data_grads_norm = 5.9576
	sim_grads_norm = 0.0270
-- Starting training on experience 74 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8751
	data_grads_norm = 4.5561
	new_data_grads_norm = 5.8071
	old_data_grads_norm = 6.9832
	sim_grads_norm = -0.0323
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2898
	data_grads_norm = 3.6799
	new_data_grads_norm = 5.9804
	old_data_grads_norm = 4.5675
	sim_grads_norm = -0.0154
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9835
	data_grads_norm = 4.5540
	new_data_grads_norm = 6.4865
	old_data_grads_norm = 5.4206
	sim_grads_norm = 0.1201
-- Starting training on experience 75 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6174
	data_grads_norm = 4.4899
	new_data_grads_norm = 5.4758
	old_data_grads_norm = 5.7728
	sim_grads_norm = 0.0640
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2965
	data_grads_norm = 4.3450
	new_data_grads_norm = 5.6053
	old_data_grads_norm = 5.8229
	sim_grads_norm = -0.0035
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6453
	data_grads_norm = 5.1972
	new_data_grads_norm = 5.7278
	old_data_grads_norm = 9.2456
	sim_grads_norm = 0.0363
-- Starting training on experience 76 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1266
	data_grads_norm = 5.3999
	new_data_grads_norm = 8.6235
	old_data_grads_norm = 6.1883
	sim_grads_norm = 0.0453
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9140
	data_grads_norm = 5.1013
	new_data_grads_norm = 7.4535
	old_data_grads_norm = 5.1644
	sim_grads_norm = 0.0222
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0119
	data_grads_norm = 5.6479
	new_data_grads_norm = 8.4877
	old_data_grads_norm = 5.3909
	sim_grads_norm = -0.0018
-- Starting training on experience 77 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6632
	data_grads_norm = 4.4981
	new_data_grads_norm = 7.4759
	old_data_grads_norm = 4.8537
	sim_grads_norm = 0.1256
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2607
	data_grads_norm = 4.2393
	new_data_grads_norm = 7.0944
	old_data_grads_norm = 4.6412
	sim_grads_norm = -0.0148
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2258
	data_grads_norm = 4.5705
	new_data_grads_norm = 8.4198
	old_data_grads_norm = 5.8568
	sim_grads_norm = 0.0052
-- Starting training on experience 78 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5333
	data_grads_norm = 4.0838
	new_data_grads_norm = 7.4169
	old_data_grads_norm = 4.4622
	sim_grads_norm = -0.0024
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1389
	data_grads_norm = 5.2455
	new_data_grads_norm = 7.7571
	old_data_grads_norm = 7.3147
	sim_grads_norm = 0.0178
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8493
	data_grads_norm = 4.1668
	new_data_grads_norm = 7.4164
	old_data_grads_norm = 4.0597
	sim_grads_norm = 0.0524
-- Starting training on experience 79 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3802
	data_grads_norm = 4.2516
	new_data_grads_norm = 6.1448
	old_data_grads_norm = 6.1321
	sim_grads_norm = -0.0142
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5494
	data_grads_norm = 4.2676
	new_data_grads_norm = 5.9694
	old_data_grads_norm = 6.1755
	sim_grads_norm = -0.0281
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7759
	data_grads_norm = 4.5940
	new_data_grads_norm = 5.9583
	old_data_grads_norm = 6.9518
	sim_grads_norm = 0.0019
-- Starting training on experience 80 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6187
	data_grads_norm = 4.6227
	new_data_grads_norm = 6.3336
	old_data_grads_norm = 6.1604
	sim_grads_norm = 0.0410
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5766
	data_grads_norm = 3.7342
	new_data_grads_norm = 6.0236
	old_data_grads_norm = 4.2170
	sim_grads_norm = 0.0190
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3536
	data_grads_norm = 4.0415
	new_data_grads_norm = 6.5570
	old_data_grads_norm = 6.6642
	sim_grads_norm = 0.0075
-- Starting training on experience 81 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0973
	data_grads_norm = 4.2788
	new_data_grads_norm = 6.4782
	old_data_grads_norm = 4.7129
	sim_grads_norm = 0.0847
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9302
	data_grads_norm = 4.3418
	new_data_grads_norm = 6.1786
	old_data_grads_norm = 5.4083
	sim_grads_norm = -0.0094
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7734
	data_grads_norm = 3.7754
	new_data_grads_norm = 5.9444
	old_data_grads_norm = 4.3931
	sim_grads_norm = -0.0258
-- Starting training on experience 82 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8821
	data_grads_norm = 4.5791
	new_data_grads_norm = 7.6541
	old_data_grads_norm = 5.4844
	sim_grads_norm = -0.0149
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8277
	data_grads_norm = 4.1335
	new_data_grads_norm = 7.4069
	old_data_grads_norm = 4.6102
	sim_grads_norm = -0.0089
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2180
	data_grads_norm = 5.2948
	new_data_grads_norm = 7.6586
	old_data_grads_norm = 7.3997
	sim_grads_norm = -0.0145
-- Starting training on experience 83 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1263
	data_grads_norm = 4.0111
	new_data_grads_norm = 6.3366
	old_data_grads_norm = 6.5666
	sim_grads_norm = -0.0159
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7533
	data_grads_norm = 5.2042
	new_data_grads_norm = 6.5314
	old_data_grads_norm = 7.7772
	sim_grads_norm = -0.0277
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9346
	data_grads_norm = 5.1210
	new_data_grads_norm = 7.6611
	old_data_grads_norm = 6.4290
	sim_grads_norm = -0.0002
-- Starting training on experience 84 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3059
	data_grads_norm = 5.2174
	new_data_grads_norm = 6.5864
	old_data_grads_norm = 8.1319
	sim_grads_norm = -0.0043
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8631
	data_grads_norm = 4.6636
	new_data_grads_norm = 6.8371
	old_data_grads_norm = 7.7273
	sim_grads_norm = 0.0055
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5576
	data_grads_norm = 4.1901
	new_data_grads_norm = 5.8533
	old_data_grads_norm = 5.9690
	sim_grads_norm = 0.0195
-- Starting training on experience 85 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9377
	data_grads_norm = 4.5083
	new_data_grads_norm = 6.6182
	old_data_grads_norm = 5.5943
	sim_grads_norm = -0.0154
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9382
	data_grads_norm = 4.5395
	new_data_grads_norm = 6.4314
	old_data_grads_norm = 6.9924
	sim_grads_norm = 0.0119
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.4357
	data_grads_norm = 5.5369
	new_data_grads_norm = 8.3155
	old_data_grads_norm = 5.9393
	sim_grads_norm = 0.0032
-- Starting training on experience 86 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6288
	data_grads_norm = 4.9138
	new_data_grads_norm = 7.2134
	old_data_grads_norm = 5.8031
	sim_grads_norm = 0.0468
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7728
	data_grads_norm = 4.5735
	new_data_grads_norm = 7.0714
	old_data_grads_norm = 4.8074
	sim_grads_norm = 0.0044
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5249
	data_grads_norm = 4.3768
	new_data_grads_norm = 6.6950
	old_data_grads_norm = 4.3060
	sim_grads_norm = -0.0273
-- Starting training on experience 87 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7948
	data_grads_norm = 4.8983
	new_data_grads_norm = 7.7060
	old_data_grads_norm = 5.0174
	sim_grads_norm = 0.0042
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5226
	data_grads_norm = 4.4307
	new_data_grads_norm = 7.7564
	old_data_grads_norm = 4.7296
	sim_grads_norm = 0.0272
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3712
	data_grads_norm = 4.0680
	new_data_grads_norm = 8.5086
	old_data_grads_norm = 4.2534
	sim_grads_norm = 0.0006
-- Starting training on experience 88 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7015
	data_grads_norm = 5.6260
	new_data_grads_norm = 7.4708
	old_data_grads_norm = 7.2727
	sim_grads_norm = 0.0134
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9730
	data_grads_norm = 4.3266
	new_data_grads_norm = 5.8331
	old_data_grads_norm = 4.8237
	sim_grads_norm = 0.0836
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9346
	data_grads_norm = 4.6314
	new_data_grads_norm = 6.1364
	old_data_grads_norm = 6.9518
	sim_grads_norm = -0.0003
-- Starting training on experience 89 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0187
	data_grads_norm = 5.7675
	new_data_grads_norm = 7.3651
	old_data_grads_norm = 7.3851
	sim_grads_norm = -0.0194
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0622
	data_grads_norm = 5.3328
	new_data_grads_norm = 7.8523
	old_data_grads_norm = 6.5327
	sim_grads_norm = -0.0108
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9573
	data_grads_norm = 5.2376
	new_data_grads_norm = 7.7989
	old_data_grads_norm = 5.9142
	sim_grads_norm = 0.0191
-- Starting training on experience 90 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7326
	data_grads_norm = 4.9373
	new_data_grads_norm = 9.1076
	old_data_grads_norm = 2.6214
	sim_grads_norm = 0.0138
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9102
	data_grads_norm = 4.9107
	new_data_grads_norm = 8.5519
	old_data_grads_norm = 3.7641
	sim_grads_norm = -0.0057
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9629
	data_grads_norm = 5.0672
	new_data_grads_norm = 8.6931
	old_data_grads_norm = 5.0270
	sim_grads_norm = 0.0085
-- Starting training on experience 91 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4750
	data_grads_norm = 4.6065
	new_data_grads_norm = 8.5047
	old_data_grads_norm = 4.3211
	sim_grads_norm = -0.0066
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9932
	data_grads_norm = 5.3424
	new_data_grads_norm = 8.3896
	old_data_grads_norm = 6.0058
	sim_grads_norm = 0.0454
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7870
	data_grads_norm = 5.2086
	new_data_grads_norm = 7.9626
	old_data_grads_norm = 5.5087
	sim_grads_norm = 0.0039
-- Starting training on experience 92 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1159
	data_grads_norm = 4.5134
	new_data_grads_norm = 6.7535
	old_data_grads_norm = 5.2265
	sim_grads_norm = 0.0096
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9346
	data_grads_norm = 4.2220
	new_data_grads_norm = 6.3611
	old_data_grads_norm = 5.7602
	sim_grads_norm = -0.0071
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2861
	data_grads_norm = 4.4796
	new_data_grads_norm = 7.5821
	old_data_grads_norm = 3.0074
	sim_grads_norm = -0.0059
-- Starting training on experience 93 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4921
	data_grads_norm = 4.4752
	new_data_grads_norm = 8.1718
	old_data_grads_norm = 5.1404
	sim_grads_norm = -0.0152
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4322
	data_grads_norm = 4.4509
	new_data_grads_norm = 7.6575
	old_data_grads_norm = 4.7409
	sim_grads_norm = -0.0040
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2147
	data_grads_norm = 4.2093
	new_data_grads_norm = 7.0520
	old_data_grads_norm = 4.0922
	sim_grads_norm = -0.0076
-- Starting training on experience 94 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2203
	data_grads_norm = 3.8074
	new_data_grads_norm = 6.7354
	old_data_grads_norm = 3.9493
	sim_grads_norm = -0.0103
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8672
	data_grads_norm = 4.9015
	new_data_grads_norm = 6.4722
	old_data_grads_norm = 6.6380
	sim_grads_norm = 0.0680
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2847
	data_grads_norm = 4.7674
	new_data_grads_norm = 7.2133
	old_data_grads_norm = 5.4240
	sim_grads_norm = -0.0072
-- Starting training on experience 95 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1980
	data_grads_norm = 5.4268
	new_data_grads_norm = 6.7630
	old_data_grads_norm = 7.3218
	sim_grads_norm = -0.0355
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5205
	data_grads_norm = 4.3450
	new_data_grads_norm = 6.9075
	old_data_grads_norm = 3.7384
	sim_grads_norm = 0.1222
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0177
	data_grads_norm = 4.8631
	new_data_grads_norm = 6.5085
	old_data_grads_norm = 6.2982
	sim_grads_norm = -0.0174
-- Starting training on experience 96 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2380
	data_grads_norm = 4.2134
	new_data_grads_norm = 7.1131
	old_data_grads_norm = 4.0570
	sim_grads_norm = -0.0136
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6010
	data_grads_norm = 4.6953
	new_data_grads_norm = 7.1519
	old_data_grads_norm = 4.6848
	sim_grads_norm = 0.0275
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7224
	data_grads_norm = 4.8223
	new_data_grads_norm = 7.7764
	old_data_grads_norm = 6.1536
	sim_grads_norm = 0.0109
-- Starting training on experience 97 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4194
	data_grads_norm = 4.5283
	new_data_grads_norm = 7.5851
	old_data_grads_norm = 4.8730
	sim_grads_norm = -0.0043
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8905
	data_grads_norm = 4.8374
	new_data_grads_norm = 7.5553
	old_data_grads_norm = 5.1094
	sim_grads_norm = 0.0566
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6177
	data_grads_norm = 4.2778
	new_data_grads_norm = 6.9248
	old_data_grads_norm = 4.5895
	sim_grads_norm = -0.0187
-- Starting training on experience 98 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3915
	data_grads_norm = 4.0339
	new_data_grads_norm = 6.9095
	old_data_grads_norm = 4.6626
	sim_grads_norm = 0.0003
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0896
	data_grads_norm = 5.2554
	new_data_grads_norm = 7.1764
	old_data_grads_norm = 7.6372
	sim_grads_norm = -0.0096
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3852
	data_grads_norm = 4.1547
	new_data_grads_norm = 6.8740
	old_data_grads_norm = 5.8412
	sim_grads_norm = -0.0036
-- Starting training on experience 99 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4876
	data_grads_norm = 4.2663
	new_data_grads_norm = 7.4740
	old_data_grads_norm = 2.9012
	sim_grads_norm = -0.0471
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5921
	data_grads_norm = 5.1658
	new_data_grads_norm = 7.0367
	old_data_grads_norm = 5.1265
	sim_grads_norm = -0.0227
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1135
	data_grads_norm = 5.2862
	new_data_grads_norm = 7.4206
	old_data_grads_norm = 6.5307
	sim_grads_norm = 0.0462
-- Starting training on experience 100 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4533
	data_grads_norm = 4.8384
	new_data_grads_norm = 7.2530
	old_data_grads_norm = 5.4000
	sim_grads_norm = 0.0077
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5396
	data_grads_norm = 5.1483
	new_data_grads_norm = 7.4924
	old_data_grads_norm = 6.0012
	sim_grads_norm = -0.0076
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7176
	data_grads_norm = 4.6770
	new_data_grads_norm = 6.6841
	old_data_grads_norm = 5.7140
	sim_grads_norm = 0.0166
-- Starting training on experience 101 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.3532
	data_grads_norm = 5.1539
	new_data_grads_norm = 6.3336
	old_data_grads_norm = 7.3751
	sim_grads_norm = 0.0457
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3791
	data_grads_norm = 3.6742
	new_data_grads_norm = 6.5841
	old_data_grads_norm = 3.3331
	sim_grads_norm = -0.0193
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6762
	data_grads_norm = 4.5995
	new_data_grads_norm = 6.1391
	old_data_grads_norm = 6.5837
	sim_grads_norm = 0.0407
-- Starting training on experience 102 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9877
	data_grads_norm = 5.2550
	new_data_grads_norm = 7.7246
	old_data_grads_norm = 6.4226
	sim_grads_norm = 0.0354
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8224
	data_grads_norm = 4.1851
	new_data_grads_norm = 6.7802
	old_data_grads_norm = 6.6036
	sim_grads_norm = 0.0472
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7193
	data_grads_norm = 4.3366
	new_data_grads_norm = 6.8630
	old_data_grads_norm = 4.2140
	sim_grads_norm = 0.0065
-- Starting training on experience 103 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0429
	data_grads_norm = 3.8320
	new_data_grads_norm = 6.9797
	old_data_grads_norm = 4.4167
	sim_grads_norm = -0.0293
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3325
	data_grads_norm = 4.2706
	new_data_grads_norm = 7.1273
	old_data_grads_norm = 6.3029
	sim_grads_norm = -0.0335
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2873
	data_grads_norm = 4.0759
	new_data_grads_norm = 6.3770
	old_data_grads_norm = 4.8657
	sim_grads_norm = 0.0025
-- Starting training on experience 104 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5439
	data_grads_norm = 4.4608
	new_data_grads_norm = 7.6863
	old_data_grads_norm = 4.1967
	sim_grads_norm = -0.0016
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9288
	data_grads_norm = 5.5341
	new_data_grads_norm = 8.5033
	old_data_grads_norm = 5.9274
	sim_grads_norm = 0.0425
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5530
	data_grads_norm = 5.5235
	new_data_grads_norm = 7.4358
	old_data_grads_norm = 7.2973
	sim_grads_norm = 0.0090
-- Starting training on experience 105 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2170
	data_grads_norm = 4.0345
	new_data_grads_norm = 6.8476
	old_data_grads_norm = 3.4694
	sim_grads_norm = -0.0225
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8445
	data_grads_norm = 5.3445
	new_data_grads_norm = 6.7836
	old_data_grads_norm = 5.7724
	sim_grads_norm = 0.0965
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3971
	data_grads_norm = 4.5179
	new_data_grads_norm = 6.8633
	old_data_grads_norm = 5.2054
	sim_grads_norm = 0.0098
-- Starting training on experience 106 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1933
	data_grads_norm = 4.2071
	new_data_grads_norm = 7.2815
	old_data_grads_norm = 4.0050
	sim_grads_norm = -0.0275
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5003
	data_grads_norm = 4.2724
	new_data_grads_norm = 5.9697
	old_data_grads_norm = 5.9298
	sim_grads_norm = 0.0539
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4526
	data_grads_norm = 4.2586
	new_data_grads_norm = 6.3690
	old_data_grads_norm = 4.3100
	sim_grads_norm = 0.0809
-- Starting training on experience 107 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9360
	data_grads_norm = 3.6110
	new_data_grads_norm = 5.7945
	old_data_grads_norm = 4.1280
	sim_grads_norm = -0.0070
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3274
	data_grads_norm = 4.3109
	new_data_grads_norm = 6.6001
	old_data_grads_norm = 6.9969
	sim_grads_norm = -0.0099
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3708
	data_grads_norm = 3.7291
	new_data_grads_norm = 6.2093
	old_data_grads_norm = 4.0446
	sim_grads_norm = 0.0601
-- Starting training on experience 108 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6152
	data_grads_norm = 4.2965
	new_data_grads_norm = 7.5158
	old_data_grads_norm = 4.5460
	sim_grads_norm = 0.0140
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4554
	data_grads_norm = 4.9962
	new_data_grads_norm = 6.7275
	old_data_grads_norm = 6.8412
	sim_grads_norm = 0.0039
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5621
	data_grads_norm = 4.5165
	new_data_grads_norm = 7.7174
	old_data_grads_norm = 5.5756
	sim_grads_norm = -0.0292
-- Starting training on experience 109 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2432
	data_grads_norm = 4.1347
	new_data_grads_norm = 6.6857
	old_data_grads_norm = 3.4199
	sim_grads_norm = 0.0993
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4548
	data_grads_norm = 4.5363
	new_data_grads_norm = 7.7981
	old_data_grads_norm = 4.8917
	sim_grads_norm = -0.0485
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3497
	data_grads_norm = 4.2974
	new_data_grads_norm = 6.8734
	old_data_grads_norm = 4.1557
	sim_grads_norm = -0.0038
-- Starting training on experience 110 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4889
	data_grads_norm = 4.3523
	new_data_grads_norm = 7.5287
	old_data_grads_norm = 4.0806
	sim_grads_norm = 0.0136
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2016
	data_grads_norm = 3.5575
	new_data_grads_norm = 5.4079
	old_data_grads_norm = 4.7324
	sim_grads_norm = -0.0530
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2162
	data_grads_norm = 3.8760
	new_data_grads_norm = 6.5519
	old_data_grads_norm = 4.3969
	sim_grads_norm = -0.0197
-- Starting training on experience 111 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4578
	data_grads_norm = 4.8027
	new_data_grads_norm = 7.1862
	old_data_grads_norm = 3.3578
	sim_grads_norm = -0.0181
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3840
	data_grads_norm = 4.1759
	new_data_grads_norm = 6.6583
	old_data_grads_norm = 4.9106
	sim_grads_norm = 0.0491
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4502
	data_grads_norm = 4.4915
	new_data_grads_norm = 6.7892
	old_data_grads_norm = 5.1275
	sim_grads_norm = 0.0068
-- Starting training on experience 112 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3391
	data_grads_norm = 4.7772
	new_data_grads_norm = 7.4200
	old_data_grads_norm = 6.0773
	sim_grads_norm = -0.0099
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5786
	data_grads_norm = 4.9100
	new_data_grads_norm = 7.0309
	old_data_grads_norm = 5.9027
	sim_grads_norm = 0.0459
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2965
	data_grads_norm = 4.9153
	new_data_grads_norm = 7.6654
	old_data_grads_norm = 6.2330
	sim_grads_norm = 0.0235
-- Starting training on experience 113 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5010
	data_grads_norm = 4.7059
	new_data_grads_norm = 7.3652
	old_data_grads_norm = 5.7882
	sim_grads_norm = -0.0226
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5913
	data_grads_norm = 4.7038
	new_data_grads_norm = 7.6772
	old_data_grads_norm = 6.3173
	sim_grads_norm = 0.0075
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1079
	data_grads_norm = 3.8711
	new_data_grads_norm = 7.7039
	old_data_grads_norm = 2.0357
	sim_grads_norm = -0.0274
-- Starting training on experience 114 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5440
	data_grads_norm = 4.1996
	new_data_grads_norm = 6.9271
	old_data_grads_norm = 5.3103
	sim_grads_norm = -0.0199
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5605
	data_grads_norm = 4.4875
	new_data_grads_norm = 6.6503
	old_data_grads_norm = 5.3491
	sim_grads_norm = 0.0207
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3052
	data_grads_norm = 3.9017
	new_data_grads_norm = 6.6773
	old_data_grads_norm = 5.2172
	sim_grads_norm = 0.0033
-- Starting training on experience 115 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0904
	data_grads_norm = 4.6390
	new_data_grads_norm = 7.7429
	old_data_grads_norm = 4.2534
	sim_grads_norm = -0.0122
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7822
	data_grads_norm = 5.0606
	new_data_grads_norm = 7.9662
	old_data_grads_norm = 5.7377
	sim_grads_norm = -0.0276
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7065
	data_grads_norm = 4.7125
	new_data_grads_norm = 7.1456
	old_data_grads_norm = 4.2309
	sim_grads_norm = 0.0939
-- Starting training on experience 116 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4267
	data_grads_norm = 4.6371
	new_data_grads_norm = 6.6409
	old_data_grads_norm = 6.1130
	sim_grads_norm = -0.0105
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1042
	data_grads_norm = 4.4773
	new_data_grads_norm = 6.9751
	old_data_grads_norm = 4.3938
	sim_grads_norm = -0.0023
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6481
	data_grads_norm = 4.9447
	new_data_grads_norm = 6.2243
	old_data_grads_norm = 5.7591
	sim_grads_norm = 0.0027
-- Starting training on experience 117 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9299
	data_grads_norm = 4.5971
	new_data_grads_norm = 6.7108
	old_data_grads_norm = 4.9568
	sim_grads_norm = 0.1759
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7827
	data_grads_norm = 4.7239
	new_data_grads_norm = 6.7118
	old_data_grads_norm = 5.8924
	sim_grads_norm = -0.0274
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5332
	data_grads_norm = 4.5223
	new_data_grads_norm = 6.7808
	old_data_grads_norm = 6.1841
	sim_grads_norm = -0.0037
-- Starting training on experience 118 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8844
	data_grads_norm = 3.2809
	new_data_grads_norm = 6.1803
	old_data_grads_norm = 2.4835
	sim_grads_norm = -0.0241
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1065
	data_grads_norm = 3.5212
	new_data_grads_norm = 6.0390
	old_data_grads_norm = 4.0078
	sim_grads_norm = 0.0059
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2454
	data_grads_norm = 3.6674
	new_data_grads_norm = 5.8148
	old_data_grads_norm = 5.1965
	sim_grads_norm = -0.0160
-- Starting training on experience 119 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5765
	data_grads_norm = 4.9541
	new_data_grads_norm = 6.7911
	old_data_grads_norm = 6.3492
	sim_grads_norm = 0.0148
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5414
	data_grads_norm = 5.3865
	new_data_grads_norm = 7.0362
	old_data_grads_norm = 6.3655
	sim_grads_norm = 0.0151
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3472
	data_grads_norm = 4.3311
	new_data_grads_norm = 6.6634
	old_data_grads_norm = 5.2161
	sim_grads_norm = -0.0020
-- Starting training on experience 120 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5697
	data_grads_norm = 4.7389
	new_data_grads_norm = 8.3851
	old_data_grads_norm = 4.6342
	sim_grads_norm = 0.0095
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4034
	data_grads_norm = 4.1028
	new_data_grads_norm = 7.3173
	old_data_grads_norm = 4.7124
	sim_grads_norm = 0.0111
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1312
	data_grads_norm = 4.2086
	new_data_grads_norm = 7.1377
	old_data_grads_norm = 5.0317
	sim_grads_norm = -0.0245
-- Starting training on experience 121 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3924
	data_grads_norm = 4.4775
	new_data_grads_norm = 6.4626
	old_data_grads_norm = 5.6934
	sim_grads_norm = 0.0181
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9627
	data_grads_norm = 3.9054
	new_data_grads_norm = 6.6466
	old_data_grads_norm = 3.9549
	sim_grads_norm = -0.0180
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1872
	data_grads_norm = 4.2426
	new_data_grads_norm = 6.4428
	old_data_grads_norm = 5.9094
	sim_grads_norm = -0.0045
-- Starting training on experience 122 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6187
	data_grads_norm = 5.1960
	new_data_grads_norm = 7.4851
	old_data_grads_norm = 6.5889
	sim_grads_norm = -0.0244
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3660
	data_grads_norm = 4.8953
	new_data_grads_norm = 7.2029
	old_data_grads_norm = 6.9996
	sim_grads_norm = 0.0050
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4581
	data_grads_norm = 5.0939
	new_data_grads_norm = 7.6028
	old_data_grads_norm = 6.1439
	sim_grads_norm = -0.0148
-- Starting training on experience 123 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9915
	data_grads_norm = 6.5463
	new_data_grads_norm = 7.6264
	old_data_grads_norm = 8.7359
	sim_grads_norm = 0.0034
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7768
	data_grads_norm = 5.1864
	new_data_grads_norm = 7.3489
	old_data_grads_norm = 5.5135
	sim_grads_norm = 0.0856
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9152
	data_grads_norm = 4.7714
	new_data_grads_norm = 7.7396
	old_data_grads_norm = 4.1506
	sim_grads_norm = -0.0063
-- Starting training on experience 124 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2397
	data_grads_norm = 4.6119
	new_data_grads_norm = 6.8460
	old_data_grads_norm = 5.3033
	sim_grads_norm = 0.0221
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4687
	data_grads_norm = 5.3287
	new_data_grads_norm = 8.1978
	old_data_grads_norm = 6.5573
	sim_grads_norm = -0.0007
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4629
	data_grads_norm = 4.8677
	new_data_grads_norm = 7.3336
	old_data_grads_norm = 4.9444
	sim_grads_norm = -0.0121
-- Starting training on experience 125 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2285
	data_grads_norm = 6.5322
	new_data_grads_norm = 9.8165
	old_data_grads_norm = 8.1278
	sim_grads_norm = 0.0111
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2615
	data_grads_norm = 5.0020
	new_data_grads_norm = 8.1759
	old_data_grads_norm = 5.9361
	sim_grads_norm = -0.0089
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1594
	data_grads_norm = 4.4517
	new_data_grads_norm = 8.9301
	old_data_grads_norm = 3.7396
	sim_grads_norm = -0.0150
-- Starting training on experience 126 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0831
	data_grads_norm = 4.1727
	new_data_grads_norm = 6.6606
	old_data_grads_norm = 5.5000
	sim_grads_norm = -0.0513
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5971
	data_grads_norm = 4.7619
	new_data_grads_norm = 6.9629
	old_data_grads_norm = 6.1564
	sim_grads_norm = 0.0337
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0954
	data_grads_norm = 3.9788
	new_data_grads_norm = 5.9779
	old_data_grads_norm = 5.5649
	sim_grads_norm = -0.0008
-- Starting training on experience 127 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2518
	data_grads_norm = 5.3462
	new_data_grads_norm = 6.7082
	old_data_grads_norm = 7.4364
	sim_grads_norm = 0.0041
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9183
	data_grads_norm = 4.2282
	new_data_grads_norm = 6.1750
	old_data_grads_norm = 5.5129
	sim_grads_norm = 0.0760
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5699
	data_grads_norm = 3.7585
	new_data_grads_norm = 5.4186
	old_data_grads_norm = 5.4346
	sim_grads_norm = 0.0140
-- Starting training on experience 128 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9645
	data_grads_norm = 3.5718
	new_data_grads_norm = 7.3314
	old_data_grads_norm = 4.5831
	sim_grads_norm = -0.0090
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1105
	data_grads_norm = 3.4137
	new_data_grads_norm = 6.0275
	old_data_grads_norm = 3.8357
	sim_grads_norm = 0.0363
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6729
	data_grads_norm = 5.0359
	new_data_grads_norm = 7.1487
	old_data_grads_norm = 5.9745
	sim_grads_norm = -0.0216
-- Starting training on experience 129 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3543
	data_grads_norm = 5.2167
	new_data_grads_norm = 7.0841
	old_data_grads_norm = 6.9686
	sim_grads_norm = 0.0254
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9120
	data_grads_norm = 4.3975
	new_data_grads_norm = 6.8847
	old_data_grads_norm = 4.3052
	sim_grads_norm = 0.0484
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8677
	data_grads_norm = 4.6675
	new_data_grads_norm = 7.1870
	old_data_grads_norm = 6.6076
	sim_grads_norm = -0.0420
-- Starting training on experience 130 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0160
	data_grads_norm = 4.8501
	new_data_grads_norm = 7.3073
	old_data_grads_norm = 4.0843
	sim_grads_norm = 0.0061
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2311
	data_grads_norm = 4.9686
	new_data_grads_norm = 6.6902
	old_data_grads_norm = 6.4328
	sim_grads_norm = -0.0387
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1695
	data_grads_norm = 4.3291
	new_data_grads_norm = 6.7823
	old_data_grads_norm = 6.2002
	sim_grads_norm = 0.0205
-- Starting training on experience 131 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2510
	data_grads_norm = 4.0066
	new_data_grads_norm = 6.4818
	old_data_grads_norm = 4.8866
	sim_grads_norm = 0.0200
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6211
	data_grads_norm = 4.7920
	new_data_grads_norm = 6.9892
	old_data_grads_norm = 5.0345
	sim_grads_norm = -0.0128
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8901
	data_grads_norm = 4.5443
	new_data_grads_norm = 6.8793
	old_data_grads_norm = 6.7886
	sim_grads_norm = 0.0196
-- Starting training on experience 132 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9699
	data_grads_norm = 5.5855
	new_data_grads_norm = 9.4202
	old_data_grads_norm = 5.4447
	sim_grads_norm = 0.0065
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8616
	data_grads_norm = 5.3768
	new_data_grads_norm = 9.1953
	old_data_grads_norm = 4.6871
	sim_grads_norm = 0.0649
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7456
	data_grads_norm = 5.0861
	new_data_grads_norm = 8.8800
	old_data_grads_norm = 5.8700
	sim_grads_norm = 0.0480
-- Starting training on experience 133 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7115
	data_grads_norm = 4.2328
	new_data_grads_norm = 6.2938
	old_data_grads_norm = 5.2794
	sim_grads_norm = 0.0186
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8644
	data_grads_norm = 4.6005
	new_data_grads_norm = 6.5310
	old_data_grads_norm = 7.3120
	sim_grads_norm = -0.0248
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9056
	data_grads_norm = 3.9483
	new_data_grads_norm = 6.1100
	old_data_grads_norm = 3.9036
	sim_grads_norm = -0.0362
-- Starting training on experience 134 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7623
	data_grads_norm = 3.7337
	new_data_grads_norm = 5.4563
	old_data_grads_norm = 4.8624
	sim_grads_norm = -0.0036
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9637
	data_grads_norm = 4.1949
	new_data_grads_norm = 5.6663
	old_data_grads_norm = 3.9457
	sim_grads_norm = 0.0234
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1406
	data_grads_norm = 5.4389
	new_data_grads_norm = 6.4389
	old_data_grads_norm = 8.2263
	sim_grads_norm = -0.0061
-- Starting training on experience 135 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4172
	data_grads_norm = 4.9484
	new_data_grads_norm = 8.6124
	old_data_grads_norm = 4.2928
	sim_grads_norm = -0.0192
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2079
	data_grads_norm = 4.3123
	new_data_grads_norm = 8.2031
	old_data_grads_norm = 4.9227
	sim_grads_norm = -0.0115
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3695
	data_grads_norm = 4.5249
	new_data_grads_norm = 8.0519
	old_data_grads_norm = 5.7449
	sim_grads_norm = 0.0031
-- Starting training on experience 136 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8742
	data_grads_norm = 5.0598
	new_data_grads_norm = 8.3463
	old_data_grads_norm = 5.2854
	sim_grads_norm = 0.0216
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6754
	data_grads_norm = 5.0242
	new_data_grads_norm = 7.6410
	old_data_grads_norm = 4.5143
	sim_grads_norm = 0.0164
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5035
	data_grads_norm = 4.6005
	new_data_grads_norm = 7.8319
	old_data_grads_norm = 4.9249
	sim_grads_norm = 0.0961
-- Starting training on experience 137 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1014
	data_grads_norm = 4.9735
	new_data_grads_norm = 7.0290
	old_data_grads_norm = 6.5530
	sim_grads_norm = 0.0460
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0903
	data_grads_norm = 4.2700
	new_data_grads_norm = 6.5882
	old_data_grads_norm = 6.1341
	sim_grads_norm = 0.0638
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4696
	data_grads_norm = 4.7184
	new_data_grads_norm = 7.4442
	old_data_grads_norm = 6.1324
	sim_grads_norm = -0.0322
-- Starting training on experience 138 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0319
	data_grads_norm = 4.8513
	new_data_grads_norm = 7.8300
	old_data_grads_norm = 6.3079
	sim_grads_norm = -0.0030
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4468
	data_grads_norm = 5.2760
	new_data_grads_norm = 9.0236
	old_data_grads_norm = 4.8902
	sim_grads_norm = -0.0128
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1245
	data_grads_norm = 4.2369
	new_data_grads_norm = 6.8299
	old_data_grads_norm = 6.5687
	sim_grads_norm = 0.0294
-- Starting training on experience 139 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9669
	data_grads_norm = 4.2535
	new_data_grads_norm = 6.6073
	old_data_grads_norm = 5.8311
	sim_grads_norm = 0.0018
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9900
	data_grads_norm = 4.1915
	new_data_grads_norm = 6.8426
	old_data_grads_norm = 5.1979
	sim_grads_norm = 0.0482
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2962
	data_grads_norm = 4.8093
	new_data_grads_norm = 6.4158
	old_data_grads_norm = 6.8242
	sim_grads_norm = 0.0358
-- Starting training on experience 140 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1652
	data_grads_norm = 4.2860
	new_data_grads_norm = 6.6502
	old_data_grads_norm = 4.6536
	sim_grads_norm = 0.0208
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9597
	data_grads_norm = 4.8620
	new_data_grads_norm = 7.3820
	old_data_grads_norm = 5.9155
	sim_grads_norm = -0.0006
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9949
	data_grads_norm = 4.3752
	new_data_grads_norm = 7.6519
	old_data_grads_norm = 4.7739
	sim_grads_norm = -0.0017
-- Starting training on experience 141 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7443
	data_grads_norm = 3.6386
	new_data_grads_norm = 5.9301
	old_data_grads_norm = 4.3018
	sim_grads_norm = -0.0049
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3633
	data_grads_norm = 4.3512
	new_data_grads_norm = 7.8544
	old_data_grads_norm = 4.2427
	sim_grads_norm = 0.0133
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2000
	data_grads_norm = 4.3493
	new_data_grads_norm = 6.2950
	old_data_grads_norm = 6.4822
	sim_grads_norm = -0.0145
-- Starting training on experience 142 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0277
	data_grads_norm = 4.7942
	new_data_grads_norm = 6.5753
	old_data_grads_norm = 6.1688
	sim_grads_norm = -0.0245
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7467
	data_grads_norm = 4.6840
	new_data_grads_norm = 5.8095
	old_data_grads_norm = 6.0809
	sim_grads_norm = 0.0192
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3872
	data_grads_norm = 4.6876
	new_data_grads_norm = 7.0495
	old_data_grads_norm = 5.1341
	sim_grads_norm = -0.0418
-- Starting training on experience 143 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9642
	data_grads_norm = 4.6442
	new_data_grads_norm = 5.9616
	old_data_grads_norm = 6.1462
	sim_grads_norm = 0.0169
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8172
	data_grads_norm = 3.9002
	new_data_grads_norm = 7.5233
	old_data_grads_norm = 3.7642
	sim_grads_norm = -0.0264
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3372
	data_grads_norm = 4.3488
	new_data_grads_norm = 6.6815
	old_data_grads_norm = 5.5484
	sim_grads_norm = 0.0361
-- Starting training on experience 144 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6538
	data_grads_norm = 5.8827
	new_data_grads_norm = 8.4209
	old_data_grads_norm = 6.2027
	sim_grads_norm = -0.0071
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5525
	data_grads_norm = 5.3362
	new_data_grads_norm = 8.0179
	old_data_grads_norm = 7.2972
	sim_grads_norm = -0.0171
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4508
	data_grads_norm = 5.4112
	new_data_grads_norm = 7.8979
	old_data_grads_norm = 6.2053
	sim_grads_norm = 0.0066
-- Starting training on experience 145 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3822
	data_grads_norm = 4.8724
	new_data_grads_norm = 8.1017
	old_data_grads_norm = 6.0029
	sim_grads_norm = 0.0027
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2011
	data_grads_norm = 4.3817
	new_data_grads_norm = 7.6469
	old_data_grads_norm = 5.1380
	sim_grads_norm = -0.0021
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0000
	data_grads_norm = 3.7822
	new_data_grads_norm = 6.5246
	old_data_grads_norm = 3.4596
	sim_grads_norm = -0.0105
-- Starting training on experience 146 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2014
	data_grads_norm = 5.3127
	new_data_grads_norm = 8.0591
	old_data_grads_norm = 7.2583
	sim_grads_norm = 0.0233
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6767
	data_grads_norm = 5.0422
	new_data_grads_norm = 7.9757
	old_data_grads_norm = 6.6419
	sim_grads_norm = -0.0290
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8228
	data_grads_norm = 4.1539
	new_data_grads_norm = 7.1147
	old_data_grads_norm = 4.2774
	sim_grads_norm = 0.0900
-- Starting training on experience 147 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2430
	data_grads_norm = 4.8557
	new_data_grads_norm = 7.7496
	old_data_grads_norm = 6.7597
	sim_grads_norm = -0.0121
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9588
	data_grads_norm = 3.5961
	new_data_grads_norm = 7.1923
	old_data_grads_norm = 2.9567
	sim_grads_norm = 0.0004
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3281
	data_grads_norm = 4.7521
	new_data_grads_norm = 7.2169
	old_data_grads_norm = 4.3196
	sim_grads_norm = -0.0022
-- Starting training on experience 148 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4346
	data_grads_norm = 4.7177
	new_data_grads_norm = 8.4410
	old_data_grads_norm = 5.4168
	sim_grads_norm = -0.0341
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6033
	data_grads_norm = 4.8260
	new_data_grads_norm = 8.3631
	old_data_grads_norm = 4.9389
	sim_grads_norm = -0.0177
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0820
	data_grads_norm = 5.9044
	new_data_grads_norm = 7.8242
	old_data_grads_norm = 9.7576
	sim_grads_norm = 0.0135
-- Starting training on experience 149 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4626
	data_grads_norm = 4.3410
	new_data_grads_norm = 7.9870
	old_data_grads_norm = 3.9667
	sim_grads_norm = -0.0532
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9782
	data_grads_norm = 5.1402
	new_data_grads_norm = 7.6086
	old_data_grads_norm = 5.7862
	sim_grads_norm = 0.0268
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4604
	data_grads_norm = 4.2741
	new_data_grads_norm = 7.8852
	old_data_grads_norm = 4.1795
	sim_grads_norm = -0.0136
-- Starting training on experience 150 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5138
	data_grads_norm = 5.0844
	new_data_grads_norm = 6.8900
	old_data_grads_norm = 7.7751
	sim_grads_norm = 0.0129
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4223
	data_grads_norm = 5.2512
	new_data_grads_norm = 8.3395
	old_data_grads_norm = 5.5018
	sim_grads_norm = 0.0493
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8635
	data_grads_norm = 3.9953
	new_data_grads_norm = 6.5705
	old_data_grads_norm = 4.7177
	sim_grads_norm = 0.0042
-- Starting training on experience 151 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4962
	data_grads_norm = 5.9468
	new_data_grads_norm = 8.4586
	old_data_grads_norm = 8.4756
	sim_grads_norm = 0.0142
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2424
	data_grads_norm = 4.3743
	new_data_grads_norm = 6.9646
	old_data_grads_norm = 4.7615
	sim_grads_norm = 0.0089
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5879
	data_grads_norm = 5.2406
	new_data_grads_norm = 8.2841
	old_data_grads_norm = 5.6038
	sim_grads_norm = 0.0010
-- Starting training on experience 152 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.1899
	data_grads_norm = 4.8190
	new_data_grads_norm = 7.5110
	old_data_grads_norm = 6.0140
	sim_grads_norm = 0.0320
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4788
	data_grads_norm = 4.6076
	new_data_grads_norm = 6.9636
	old_data_grads_norm = 4.8939
	sim_grads_norm = 0.0341
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4861
	data_grads_norm = 4.6842
	new_data_grads_norm = 8.0396
	old_data_grads_norm = 4.1572
	sim_grads_norm = -0.0371
-- Starting training on experience 153 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1315
	data_grads_norm = 4.8846
	new_data_grads_norm = 7.4803
	old_data_grads_norm = 6.3380
	sim_grads_norm = 0.0156
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1507
	data_grads_norm = 4.9006
	new_data_grads_norm = 7.5554
	old_data_grads_norm = 5.3919
	sim_grads_norm = -0.0177
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3013
	data_grads_norm = 5.0828
	new_data_grads_norm = 7.5224
	old_data_grads_norm = 7.0446
	sim_grads_norm = -0.0396
-- Starting training on experience 154 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2544
	data_grads_norm = 4.6471
	new_data_grads_norm = 7.0039
	old_data_grads_norm = 3.9257
	sim_grads_norm = 0.0700
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4252
	data_grads_norm = 4.8076
	new_data_grads_norm = 6.8267
	old_data_grads_norm = 5.2429
	sim_grads_norm = 0.0053
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1607
	data_grads_norm = 4.4405
	new_data_grads_norm = 7.6314
	old_data_grads_norm = 5.0394
	sim_grads_norm = 0.0434
-- Starting training on experience 155 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1055
	data_grads_norm = 3.6743
	new_data_grads_norm = 6.9575
	old_data_grads_norm = 2.3967
	sim_grads_norm = -0.0182
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7894
	data_grads_norm = 4.3162
	new_data_grads_norm = 6.7861
	old_data_grads_norm = 4.8225
	sim_grads_norm = -0.0415
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3959
	data_grads_norm = 3.9231
	new_data_grads_norm = 7.0710
	old_data_grads_norm = 3.6055
	sim_grads_norm = -0.0152
-- Starting training on experience 156 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3644
	data_grads_norm = 5.5183
	new_data_grads_norm = 7.1020
	old_data_grads_norm = 6.3707
	sim_grads_norm = -0.0227
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3137
	data_grads_norm = 5.1790
	new_data_grads_norm = 7.4544
	old_data_grads_norm = 8.2750
	sim_grads_norm = -0.0090
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3906
	data_grads_norm = 5.2193
	new_data_grads_norm = 6.8547
	old_data_grads_norm = 6.8399
	sim_grads_norm = 0.0012
-- Starting training on experience 157 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9169
	data_grads_norm = 5.9093
	new_data_grads_norm = 10.0437
	old_data_grads_norm = 4.8423
	sim_grads_norm = -0.0116
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3548
	data_grads_norm = 4.9082
	new_data_grads_norm = 7.7278
	old_data_grads_norm = 6.0565
	sim_grads_norm = 0.0063
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5117
	data_grads_norm = 5.1792
	new_data_grads_norm = 8.9236
	old_data_grads_norm = 3.7816
	sim_grads_norm = -0.0165
-- Starting training on experience 158 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4753
	data_grads_norm = 4.5767
	new_data_grads_norm = 6.6908
	old_data_grads_norm = 4.8044
	sim_grads_norm = 0.0881
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3906
	data_grads_norm = 4.3772
	new_data_grads_norm = 6.5351
	old_data_grads_norm = 5.3315
	sim_grads_norm = 0.0093
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2101
	data_grads_norm = 4.5462
	new_data_grads_norm = 6.7141
	old_data_grads_norm = 6.1930
	sim_grads_norm = 0.0242
-- Starting training on experience 159 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4090
	data_grads_norm = 4.8531
	new_data_grads_norm = 6.9798
	old_data_grads_norm = 5.4397
	sim_grads_norm = 0.0378
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2257
	data_grads_norm = 5.2027
	new_data_grads_norm = 8.2156
	old_data_grads_norm = 4.8547
	sim_grads_norm = 0.0034
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1530
	data_grads_norm = 4.8714
	new_data_grads_norm = 8.2770
	old_data_grads_norm = 4.0889
	sim_grads_norm = 0.0380
-- Starting training on experience 160 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1672
	data_grads_norm = 4.4688
	new_data_grads_norm = 6.8628
	old_data_grads_norm = 6.3434
	sim_grads_norm = 0.0040
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8779
	data_grads_norm = 5.0389
	new_data_grads_norm = 7.1693
	old_data_grads_norm = 6.7319
	sim_grads_norm = 0.0616
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5956
	data_grads_norm = 5.1935
	new_data_grads_norm = 7.5795
	old_data_grads_norm = 5.0575
	sim_grads_norm = 0.0929
-- Starting training on experience 161 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4088
	data_grads_norm = 4.7654
	new_data_grads_norm = 6.9192
	old_data_grads_norm = 6.8613
	sim_grads_norm = -0.0092
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2976
	data_grads_norm = 4.6946
	new_data_grads_norm = 7.0307
	old_data_grads_norm = 7.5210
	sim_grads_norm = -0.0028
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5752
	data_grads_norm = 3.4373
	new_data_grads_norm = 6.8009
	old_data_grads_norm = 4.5123
	sim_grads_norm = -0.0078
-- Starting training on experience 162 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9713
	data_grads_norm = 4.8741
	new_data_grads_norm = 7.6842
	old_data_grads_norm = 5.2155
	sim_grads_norm = -0.0110
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2109
	data_grads_norm = 5.3454
	new_data_grads_norm = 8.0783
	old_data_grads_norm = 6.1946
	sim_grads_norm = 0.0287
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6082
	data_grads_norm = 3.2466
	new_data_grads_norm = 6.2890
	old_data_grads_norm = 3.6713
	sim_grads_norm = -0.0406
-- Starting training on experience 163 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7038
	data_grads_norm = 6.0409
	new_data_grads_norm = 8.2396
	old_data_grads_norm = 8.0638
	sim_grads_norm = -0.0256
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8583
	data_grads_norm = 5.3503
	new_data_grads_norm = 8.8653
	old_data_grads_norm = 5.0897
	sim_grads_norm = 0.0416
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8704
	data_grads_norm = 5.6249
	new_data_grads_norm = 8.7448
	old_data_grads_norm = 6.3718
	sim_grads_norm = 0.0140
-- Starting training on experience 164 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8731
	data_grads_norm = 3.8235
	new_data_grads_norm = 6.1521
	old_data_grads_norm = 4.8747
	sim_grads_norm = 0.0073
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2104
	data_grads_norm = 4.1038
	new_data_grads_norm = 5.8370
	old_data_grads_norm = 6.0306
	sim_grads_norm = -0.0176
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0378
	data_grads_norm = 3.6524
	new_data_grads_norm = 5.9237
	old_data_grads_norm = 4.2260
	sim_grads_norm = -0.0057
-- Starting training on experience 165 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2714
	data_grads_norm = 4.0836
	new_data_grads_norm = 6.0111
	old_data_grads_norm = 6.2990
	sim_grads_norm = -0.0149
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3961
	data_grads_norm = 4.6297
	new_data_grads_norm = 7.6730
	old_data_grads_norm = 6.3660
	sim_grads_norm = -0.0170
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2101
	data_grads_norm = 4.3730
	new_data_grads_norm = 7.7053
	old_data_grads_norm = 5.2853
	sim_grads_norm = 0.0055
-- Starting training on experience 166 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5768
	data_grads_norm = 4.3223
	new_data_grads_norm = 6.5723
	old_data_grads_norm = 5.8881
	sim_grads_norm = 0.0238
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5424
	data_grads_norm = 4.6441
	new_data_grads_norm = 7.9772
	old_data_grads_norm = 5.5181
	sim_grads_norm = 0.0153
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4393
	data_grads_norm = 4.4869
	new_data_grads_norm = 7.1548
	old_data_grads_norm = 3.9547
	sim_grads_norm = -0.0438
-- Starting training on experience 167 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1915
	data_grads_norm = 4.4042
	new_data_grads_norm = 7.2972
	old_data_grads_norm = 5.4216
	sim_grads_norm = 0.0042
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3227
	data_grads_norm = 4.7479
	new_data_grads_norm = 7.3333
	old_data_grads_norm = 6.5104
	sim_grads_norm = 0.0235
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3290
	data_grads_norm = 5.2081
	new_data_grads_norm = 7.4079
	old_data_grads_norm = 7.0006
	sim_grads_norm = 0.0537
-- Starting training on experience 168 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6598
	data_grads_norm = 4.9376
	new_data_grads_norm = 8.3589
	old_data_grads_norm = 5.1568
	sim_grads_norm = 0.0760
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5956
	data_grads_norm = 4.8470
	new_data_grads_norm = 7.8035
	old_data_grads_norm = 6.3173
	sim_grads_norm = 0.0453
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0410
	data_grads_norm = 4.8050
	new_data_grads_norm = 8.4552
	old_data_grads_norm = 4.2885
	sim_grads_norm = -0.0082
-- Starting training on experience 169 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3854
	data_grads_norm = 4.8617
	new_data_grads_norm = 8.2012
	old_data_grads_norm = 5.1016
	sim_grads_norm = 0.0473
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3028
	data_grads_norm = 4.6129
	new_data_grads_norm = 7.8203
	old_data_grads_norm = 5.1859
	sim_grads_norm = -0.0058
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2255
	data_grads_norm = 4.7405
	new_data_grads_norm = 6.7898
	old_data_grads_norm = 6.5314
	sim_grads_norm = -0.0051
-- Starting training on experience 170 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3612
	data_grads_norm = 4.8849
	new_data_grads_norm = 6.5776
	old_data_grads_norm = 6.7618
	sim_grads_norm = -0.0222
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0008
	data_grads_norm = 4.9427
	new_data_grads_norm = 7.5763
	old_data_grads_norm = 6.6205
	sim_grads_norm = 0.0155
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4849
	data_grads_norm = 4.6590
	new_data_grads_norm = 7.8034
	old_data_grads_norm = 3.1320
	sim_grads_norm = 0.0071
-- Starting training on experience 171 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4391
	data_grads_norm = 5.2707
	new_data_grads_norm = 8.7376
	old_data_grads_norm = 5.3575
	sim_grads_norm = 0.0177
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1335
	data_grads_norm = 4.6962
	new_data_grads_norm = 7.4400
	old_data_grads_norm = 5.6760
	sim_grads_norm = -0.0130
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4275
	data_grads_norm = 5.0122
	new_data_grads_norm = 8.6335
	old_data_grads_norm = 4.8638
	sim_grads_norm = 0.0128
-- Starting training on experience 172 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3098
	data_grads_norm = 4.4422
	new_data_grads_norm = 6.9289
	old_data_grads_norm = 5.3510
	sim_grads_norm = -0.0199
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5141
	data_grads_norm = 4.8161
	new_data_grads_norm = 7.0771
	old_data_grads_norm = 4.9805
	sim_grads_norm = 0.1304
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9862
	data_grads_norm = 4.4529
	new_data_grads_norm = 7.2757
	old_data_grads_norm = 5.2284
	sim_grads_norm = -0.0022
-- Starting training on experience 173 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0894
	data_grads_norm = 4.4459
	new_data_grads_norm = 6.9033
	old_data_grads_norm = 4.5528
	sim_grads_norm = 0.0276
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7942
	data_grads_norm = 4.5559
	new_data_grads_norm = 6.9168
	old_data_grads_norm = 4.0449
	sim_grads_norm = 0.0052
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7540
	data_grads_norm = 4.5809
	new_data_grads_norm = 7.2159
	old_data_grads_norm = 4.4706
	sim_grads_norm = 0.0218
-- Starting training on experience 174 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3905
	data_grads_norm = 4.0308
	new_data_grads_norm = 7.1419
	old_data_grads_norm = 4.2841
	sim_grads_norm = 0.0005
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5115
	data_grads_norm = 4.1409
	new_data_grads_norm = 6.8653
	old_data_grads_norm = 4.5413
	sim_grads_norm = -0.0087
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1083
	data_grads_norm = 4.8736
	new_data_grads_norm = 6.7935
	old_data_grads_norm = 5.7766
	sim_grads_norm = 0.0694
-- Starting training on experience 175 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9252
	data_grads_norm = 5.8777
	new_data_grads_norm = 7.7066
	old_data_grads_norm = 7.8891
	sim_grads_norm = -0.0227
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3946
	data_grads_norm = 4.8374
	new_data_grads_norm = 8.3287
	old_data_grads_norm = 6.1966
	sim_grads_norm = 0.0218
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6844
	data_grads_norm = 5.0699
	new_data_grads_norm = 7.8445
	old_data_grads_norm = 5.5468
	sim_grads_norm = -0.0013
-- Starting training on experience 176 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0767
	data_grads_norm = 4.1919
	new_data_grads_norm = 6.2561
	old_data_grads_norm = 6.0520
	sim_grads_norm = -0.0143
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5766
	data_grads_norm = 5.0207
	new_data_grads_norm = 6.6063
	old_data_grads_norm = 6.2000
	sim_grads_norm = 0.0402
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0735
	data_grads_norm = 3.9421
	new_data_grads_norm = 6.0208
	old_data_grads_norm = 4.9381
	sim_grads_norm = -0.0122
-- Starting training on experience 177 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8256
	data_grads_norm = 4.5018
	new_data_grads_norm = 6.6162
	old_data_grads_norm = 6.0029
	sim_grads_norm = 0.0100
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0166
	data_grads_norm = 4.6156
	new_data_grads_norm = 6.9025
	old_data_grads_norm = 5.2217
	sim_grads_norm = 0.0690
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7120
	data_grads_norm = 3.5521
	new_data_grads_norm = 6.2294
	old_data_grads_norm = 3.4897
	sim_grads_norm = -0.0892
-- Starting training on experience 178 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3065
	data_grads_norm = 4.3754
	new_data_grads_norm = 7.1246
	old_data_grads_norm = 5.9086
	sim_grads_norm = -0.0454
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8897
	data_grads_norm = 3.8906
	new_data_grads_norm = 6.4810
	old_data_grads_norm = 4.5310
	sim_grads_norm = 0.0171
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2797
	data_grads_norm = 4.6567
	new_data_grads_norm = 7.5471
	old_data_grads_norm = 4.2069
	sim_grads_norm = -0.0005
-- Starting training on experience 179 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5839
	data_grads_norm = 4.0128
	new_data_grads_norm = 6.7874
	old_data_grads_norm = 4.1977
	sim_grads_norm = 0.0140
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8334
	data_grads_norm = 4.7457
	new_data_grads_norm = 7.3148
	old_data_grads_norm = 5.4136
	sim_grads_norm = 0.0119
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8696
	data_grads_norm = 4.5306
	new_data_grads_norm = 6.6300
	old_data_grads_norm = 6.1758
	sim_grads_norm = -0.0008
-- Starting training on experience 180 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0445
	data_grads_norm = 4.8614
	new_data_grads_norm = 6.9043
	old_data_grads_norm = 4.7894
	sim_grads_norm = 0.0332
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9061
	data_grads_norm = 4.0770
	new_data_grads_norm = 7.3385
	old_data_grads_norm = 4.7100
	sim_grads_norm = 0.0082
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6916
	data_grads_norm = 4.0063
	new_data_grads_norm = 7.3457
	old_data_grads_norm = 4.7632
	sim_grads_norm = 0.0866
-- Starting training on experience 181 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6942
	data_grads_norm = 4.8347
	new_data_grads_norm = 7.2750
	old_data_grads_norm = 6.9429
	sim_grads_norm = -0.0331
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6952
	data_grads_norm = 4.2141
	new_data_grads_norm = 7.0880
	old_data_grads_norm = 6.1904
	sim_grads_norm = -0.0034
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8629
	data_grads_norm = 4.8113
	new_data_grads_norm = 8.1479
	old_data_grads_norm = 3.5525
	sim_grads_norm = 0.0002
-- Starting training on experience 182 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0298
	data_grads_norm = 4.1834
	new_data_grads_norm = 7.6242
	old_data_grads_norm = 2.8991
	sim_grads_norm = 0.0105
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1827
	data_grads_norm = 4.5103
	new_data_grads_norm = 7.8587
	old_data_grads_norm = 4.3745
	sim_grads_norm = 0.0784
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1129
	data_grads_norm = 4.2753
	new_data_grads_norm = 7.4831
	old_data_grads_norm = 4.2776
	sim_grads_norm = -0.0165
-- Starting training on experience 183 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9872
	data_grads_norm = 5.5013
	new_data_grads_norm = 6.8183
	old_data_grads_norm = 7.8030
	sim_grads_norm = 0.0520
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0847
	data_grads_norm = 5.0402
	new_data_grads_norm = 6.8874
	old_data_grads_norm = 6.5380
	sim_grads_norm = 0.0536
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0414
	data_grads_norm = 4.8429
	new_data_grads_norm = 6.3391
	old_data_grads_norm = 7.7891
	sim_grads_norm = 0.0104
-- Starting training on experience 184 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1645
	data_grads_norm = 4.4375
	new_data_grads_norm = 6.2882
	old_data_grads_norm = 5.5245
	sim_grads_norm = -0.0025
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7007
	data_grads_norm = 3.4430
	new_data_grads_norm = 6.1100
	old_data_grads_norm = 5.0672
	sim_grads_norm = -0.0078
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6542
	data_grads_norm = 3.5537
	new_data_grads_norm = 7.4915
	old_data_grads_norm = 3.5728
	sim_grads_norm = 0.0031
-- Starting training on experience 185 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6818
	data_grads_norm = 4.8419
	new_data_grads_norm = 6.9049
	old_data_grads_norm = 5.5048
	sim_grads_norm = -0.0204
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7430
	data_grads_norm = 4.5221
	new_data_grads_norm = 6.5357
	old_data_grads_norm = 5.3633
	sim_grads_norm = -0.0101
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6508
	data_grads_norm = 4.9095
	new_data_grads_norm = 8.1929
	old_data_grads_norm = 3.3005
	sim_grads_norm = 0.0089
-- Starting training on experience 186 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3718
	data_grads_norm = 4.9298
	new_data_grads_norm = 7.5769
	old_data_grads_norm = 5.5779
	sim_grads_norm = 0.0762
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1934
	data_grads_norm = 4.9943
	new_data_grads_norm = 6.3946
	old_data_grads_norm = 8.3219
	sim_grads_norm = -0.0088
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5301
	data_grads_norm = 5.0255
	new_data_grads_norm = 7.1328
	old_data_grads_norm = 5.8802
	sim_grads_norm = 0.0413
-- Starting training on experience 187 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0026
	data_grads_norm = 4.6150
	new_data_grads_norm = 7.5652
	old_data_grads_norm = 6.9094
	sim_grads_norm = 0.0173
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2690
	data_grads_norm = 4.4116
	new_data_grads_norm = 6.8335
	old_data_grads_norm = 5.0271
	sim_grads_norm = -0.0038
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3263
	data_grads_norm = 5.2819
	new_data_grads_norm = 7.7037
	old_data_grads_norm = 7.0038
	sim_grads_norm = -0.0120
-- Starting training on experience 188 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6679
	data_grads_norm = 4.4448
	new_data_grads_norm = 8.1013
	old_data_grads_norm = 4.0187
	sim_grads_norm = 0.0660
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5497
	data_grads_norm = 4.8038
	new_data_grads_norm = 7.5023
	old_data_grads_norm = 5.2638
	sim_grads_norm = -0.0052
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5569
	data_grads_norm = 4.7910
	new_data_grads_norm = 7.7481
	old_data_grads_norm = 6.2642
	sim_grads_norm = 0.0013
-- Starting training on experience 189 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7530
	data_grads_norm = 4.1489
	new_data_grads_norm = 7.0299
	old_data_grads_norm = 4.0374
	sim_grads_norm = -0.0164
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9181
	data_grads_norm = 4.1980
	new_data_grads_norm = 6.9624
	old_data_grads_norm = 5.1391
	sim_grads_norm = 0.0037
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9699
	data_grads_norm = 3.9907
	new_data_grads_norm = 6.5665
	old_data_grads_norm = 5.5311
	sim_grads_norm = 0.0151
-- Starting training on experience 190 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9262
	data_grads_norm = 4.2594
	new_data_grads_norm = 7.1295
	old_data_grads_norm = 4.2924
	sim_grads_norm = -0.0297
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1733
	data_grads_norm = 4.8812
	new_data_grads_norm = 8.0653
	old_data_grads_norm = 4.2466
	sim_grads_norm = 0.0543
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0612
	data_grads_norm = 4.8508
	new_data_grads_norm = 7.5623
	old_data_grads_norm = 5.5703
	sim_grads_norm = -0.0036
-- Starting training on experience 191 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8753
	data_grads_norm = 5.3395
	new_data_grads_norm = 7.0263
	old_data_grads_norm = 6.6933
	sim_grads_norm = 0.0490
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2681
	data_grads_norm = 4.7171
	new_data_grads_norm = 7.2158
	old_data_grads_norm = 6.1626
	sim_grads_norm = 0.0018
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9882
	data_grads_norm = 4.0521
	new_data_grads_norm = 7.3206
	old_data_grads_norm = 3.6333
	sim_grads_norm = 0.0960
-- Starting training on experience 192 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9765
	data_grads_norm = 4.4561
	new_data_grads_norm = 6.4745
	old_data_grads_norm = 3.7095
	sim_grads_norm = -0.0256
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8896
	data_grads_norm = 4.2526
	new_data_grads_norm = 6.4946
	old_data_grads_norm = 5.0172
	sim_grads_norm = 0.0298
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1722
	data_grads_norm = 4.6664
	new_data_grads_norm = 6.5912
	old_data_grads_norm = 5.8996
	sim_grads_norm = 0.0440
-- Starting training on experience 193 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4462
	data_grads_norm = 4.2052
	new_data_grads_norm = 7.7608
	old_data_grads_norm = 4.6532
	sim_grads_norm = -0.0042
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4213
	data_grads_norm = 5.4888
	new_data_grads_norm = 7.3348
	old_data_grads_norm = 6.5286
	sim_grads_norm = -0.0097
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3375
	data_grads_norm = 4.5910
	new_data_grads_norm = 7.2746
	old_data_grads_norm = 3.8251
	sim_grads_norm = -0.0183
-- Starting training on experience 194 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1732
	data_grads_norm = 4.6424
	new_data_grads_norm = 8.1734
	old_data_grads_norm = 4.8035
	sim_grads_norm = 0.0169
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3351
	data_grads_norm = 5.1768
	new_data_grads_norm = 7.3870
	old_data_grads_norm = 6.3669
	sim_grads_norm = 0.0106
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9261
	data_grads_norm = 4.7470
	new_data_grads_norm = 7.6609
	old_data_grads_norm = 7.3718
	sim_grads_norm = 0.0060
-- Starting training on experience 195 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5255
	data_grads_norm = 5.1370
	new_data_grads_norm = 7.0081
	old_data_grads_norm = 5.1862
	sim_grads_norm = 0.0704
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0161
	data_grads_norm = 5.0506
	new_data_grads_norm = 7.3935
	old_data_grads_norm = 6.0839
	sim_grads_norm = -0.0139
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9760
	data_grads_norm = 4.9266
	new_data_grads_norm = 6.6285
	old_data_grads_norm = 7.0284
	sim_grads_norm = -0.0293
-- Starting training on experience 196 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3235
	data_grads_norm = 5.5554
	new_data_grads_norm = 7.5814
	old_data_grads_norm = 6.2988
	sim_grads_norm = -0.0459
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2912
	data_grads_norm = 5.1342
	new_data_grads_norm = 8.8202
	old_data_grads_norm = 5.0074
	sim_grads_norm = -0.0133
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0567
	data_grads_norm = 5.1938
	new_data_grads_norm = 7.8818
	old_data_grads_norm = 4.4273
	sim_grads_norm = -0.0106
-- Starting training on experience 197 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0992
	data_grads_norm = 4.6737
	new_data_grads_norm = 7.3158
	old_data_grads_norm = 5.4978
	sim_grads_norm = -0.0112
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9997
	data_grads_norm = 4.0388
	new_data_grads_norm = 7.3113
	old_data_grads_norm = 4.6342
	sim_grads_norm = 0.0173
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2255
	data_grads_norm = 4.4919
	new_data_grads_norm = 6.9434
	old_data_grads_norm = 4.2390
	sim_grads_norm = 0.0144
-- Starting training on experience 198 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5422
	data_grads_norm = 3.5872
	new_data_grads_norm = 6.6532
	old_data_grads_norm = 3.0001
	sim_grads_norm = 0.0410
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2481
	data_grads_norm = 4.3977
	new_data_grads_norm = 7.4153
	old_data_grads_norm = 4.8200
	sim_grads_norm = -0.0237
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9078
	data_grads_norm = 4.7135
	new_data_grads_norm = 7.0962
	old_data_grads_norm = 7.1341
	sim_grads_norm = 0.0056
-- Starting training on experience 199 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3830
	data_grads_norm = 5.1252
	new_data_grads_norm = 8.1903
	old_data_grads_norm = 5.4902
	sim_grads_norm = 0.0453
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0750
	data_grads_norm = 4.9460
	new_data_grads_norm = 8.0009
	old_data_grads_norm = 5.6297
	sim_grads_norm = -0.0353
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5357
	data_grads_norm = 5.0258
	new_data_grads_norm = 7.4514
	old_data_grads_norm = 5.0175
	sim_grads_norm = 0.1722
-- Starting training on experience 200 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2800
	data_grads_norm = 4.8803
	new_data_grads_norm = 7.7387
	old_data_grads_norm = 4.6402
	sim_grads_norm = 0.0386
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2741
	data_grads_norm = 4.2679
	new_data_grads_norm = 6.3718
	old_data_grads_norm = 4.6456
	sim_grads_norm = -0.0288
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9862
	data_grads_norm = 4.4458
	new_data_grads_norm = 6.3065
	old_data_grads_norm = 6.6473
	sim_grads_norm = -0.0151
-- Starting training on experience 201 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8014
	data_grads_norm = 4.0182
	new_data_grads_norm = 6.8393
	old_data_grads_norm = 5.1654
	sim_grads_norm = -0.0249
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1356
	data_grads_norm = 5.4614
	new_data_grads_norm = 7.0463
	old_data_grads_norm = 7.8559
	sim_grads_norm = 0.0281
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6795
	data_grads_norm = 5.0410
	new_data_grads_norm = 6.2627
	old_data_grads_norm = 6.7591
	sim_grads_norm = -0.0160
-- Starting training on experience 202 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8783
	data_grads_norm = 4.6741
	new_data_grads_norm = 7.4891
	old_data_grads_norm = 4.6523
	sim_grads_norm = -0.0261
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2144
	data_grads_norm = 5.6184
	new_data_grads_norm = 8.9727
	old_data_grads_norm = 5.0231
	sim_grads_norm = 0.1120
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4135
	data_grads_norm = 4.7397
	new_data_grads_norm = 7.6613
	old_data_grads_norm = 5.0666
	sim_grads_norm = -0.0066
-- Starting training on experience 203 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8678
	data_grads_norm = 4.4194
	new_data_grads_norm = 7.2200
	old_data_grads_norm = 4.0476
	sim_grads_norm = -0.0263
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7397
	data_grads_norm = 4.1277
	new_data_grads_norm = 7.6789
	old_data_grads_norm = 5.2673
	sim_grads_norm = -0.0292
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1646
	data_grads_norm = 5.1567
	new_data_grads_norm = 8.4955
	old_data_grads_norm = 5.1009
	sim_grads_norm = 0.0167
-- Starting training on experience 204 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9116
	data_grads_norm = 4.3215
	new_data_grads_norm = 7.8857
	old_data_grads_norm = 3.4803
	sim_grads_norm = 0.0256
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5374
	data_grads_norm = 5.1509
	new_data_grads_norm = 8.2467
	old_data_grads_norm = 5.9228
	sim_grads_norm = 0.0026
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2962
	data_grads_norm = 4.8110
	new_data_grads_norm = 8.8215
	old_data_grads_norm = 4.8145
	sim_grads_norm = -0.0081
-- Starting training on experience 205 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2984
	data_grads_norm = 4.8537
	new_data_grads_norm = 7.3127
	old_data_grads_norm = 5.5487
	sim_grads_norm = 0.0013
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8450
	data_grads_norm = 6.0611
	new_data_grads_norm = 7.5679
	old_data_grads_norm = 6.9206
	sim_grads_norm = 0.0189
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6890
	data_grads_norm = 5.2764
	new_data_grads_norm = 7.1025
	old_data_grads_norm = 4.9485
	sim_grads_norm = 0.0993
-- Starting training on experience 206 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0231
	data_grads_norm = 4.8431
	new_data_grads_norm = 7.7834
	old_data_grads_norm = 6.1937
	sim_grads_norm = -0.0020
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0965
	data_grads_norm = 4.4370
	new_data_grads_norm = 7.6230
	old_data_grads_norm = 4.0014
	sim_grads_norm = 0.0274
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5564
	data_grads_norm = 5.2004
	new_data_grads_norm = 8.7248
	old_data_grads_norm = 6.4356
	sim_grads_norm = 0.0545
-- Starting training on experience 207 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9228
	data_grads_norm = 4.0294
	new_data_grads_norm = 6.4649
	old_data_grads_norm = 4.6294
	sim_grads_norm = -0.0159
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3767
	data_grads_norm = 4.9070
	new_data_grads_norm = 7.1017
	old_data_grads_norm = 6.8187
	sim_grads_norm = -0.0180
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1424
	data_grads_norm = 4.0849
	new_data_grads_norm = 6.7786
	old_data_grads_norm = 5.0973
	sim_grads_norm = 0.0063
-- Starting training on experience 208 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9645
	data_grads_norm = 4.4872
	new_data_grads_norm = 7.4727
	old_data_grads_norm = 6.1464
	sim_grads_norm = 0.0539
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9100
	data_grads_norm = 4.2726
	new_data_grads_norm = 7.3509
	old_data_grads_norm = 4.7068
	sim_grads_norm = 0.0618
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8211
	data_grads_norm = 4.1878
	new_data_grads_norm = 6.6701
	old_data_grads_norm = 4.4995
	sim_grads_norm = -0.0295
-- Starting training on experience 209 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8952
	data_grads_norm = 4.3097
	new_data_grads_norm = 7.4609
	old_data_grads_norm = 4.8770
	sim_grads_norm = -0.0121
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8338
	data_grads_norm = 4.3689
	new_data_grads_norm = 8.0227
	old_data_grads_norm = 3.3054
	sim_grads_norm = -0.0003
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2203
	data_grads_norm = 4.6696
	new_data_grads_norm = 6.8578
	old_data_grads_norm = 4.9265
	sim_grads_norm = 0.0689
-- Starting training on experience 210 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7160
	data_grads_norm = 4.2667
	new_data_grads_norm = 7.2556
	old_data_grads_norm = 5.7549
	sim_grads_norm = 0.0057
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7892
	data_grads_norm = 4.2518
	new_data_grads_norm = 7.1147
	old_data_grads_norm = 4.7974
	sim_grads_norm = 0.0101
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5227
	data_grads_norm = 4.1242
	new_data_grads_norm = 7.3857
	old_data_grads_norm = 3.4774
	sim_grads_norm = -0.0668
-- Starting training on experience 211 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9676
	data_grads_norm = 4.3008
	new_data_grads_norm = 6.6031
	old_data_grads_norm = 5.3045
	sim_grads_norm = -0.0099
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7588
	data_grads_norm = 3.9702
	new_data_grads_norm = 7.7344
	old_data_grads_norm = 3.1241
	sim_grads_norm = 0.0542
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8667
	data_grads_norm = 3.9257
	new_data_grads_norm = 6.4054
	old_data_grads_norm = 4.1448
	sim_grads_norm = -0.0017
-- Starting training on experience 212 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0482
	data_grads_norm = 4.7858
	new_data_grads_norm = 7.3626
	old_data_grads_norm = 5.2277
	sim_grads_norm = 0.0021
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8995
	data_grads_norm = 4.0011
	new_data_grads_norm = 7.1510
	old_data_grads_norm = 4.3258
	sim_grads_norm = 0.0102
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3564
	data_grads_norm = 5.0278
	new_data_grads_norm = 6.6501
	old_data_grads_norm = 7.0209
	sim_grads_norm = 0.0556
-- Starting training on experience 213 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6962
	data_grads_norm = 4.2650
	new_data_grads_norm = 6.9085
	old_data_grads_norm = 5.5700
	sim_grads_norm = 0.0167
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6158
	data_grads_norm = 4.3889
	new_data_grads_norm = 6.4388
	old_data_grads_norm = 5.4363
	sim_grads_norm = -0.0395
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9306
	data_grads_norm = 4.3153
	new_data_grads_norm = 6.9231
	old_data_grads_norm = 4.6724
	sim_grads_norm = 0.0140
-- Starting training on experience 214 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3881
	data_grads_norm = 5.4624
	new_data_grads_norm = 8.6837
	old_data_grads_norm = 5.2561
	sim_grads_norm = -0.0276
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4210
	data_grads_norm = 4.7767
	new_data_grads_norm = 7.8414
	old_data_grads_norm = 5.4524
	sim_grads_norm = 0.0096
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5112
	data_grads_norm = 4.5283
	new_data_grads_norm = 7.5438
	old_data_grads_norm = 5.4069
	sim_grads_norm = -0.0215
-- Starting training on experience 215 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1224
	data_grads_norm = 4.7217
	new_data_grads_norm = 7.5211
	old_data_grads_norm = 5.2371
	sim_grads_norm = 0.0697
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3952
	data_grads_norm = 3.9645
	new_data_grads_norm = 7.0505
	old_data_grads_norm = 4.3867
	sim_grads_norm = -0.0028
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6041
	data_grads_norm = 4.2639
	new_data_grads_norm = 7.1175
	old_data_grads_norm = 4.6963
	sim_grads_norm = -0.0019
-- Starting training on experience 216 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4820
	data_grads_norm = 5.0800
	new_data_grads_norm = 6.7584
	old_data_grads_norm = 6.6397
	sim_grads_norm = 0.0226
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0981
	data_grads_norm = 4.9807
	new_data_grads_norm = 7.2909
	old_data_grads_norm = 6.6965
	sim_grads_norm = -0.0130
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4586
	data_grads_norm = 4.9587
	new_data_grads_norm = 7.3492
	old_data_grads_norm = 6.0585
	sim_grads_norm = -0.0226
-- Starting training on experience 217 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7129
	data_grads_norm = 4.1694
	new_data_grads_norm = 6.9005
	old_data_grads_norm = 2.9164
	sim_grads_norm = -0.0251
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3744
	data_grads_norm = 5.1655
	new_data_grads_norm = 7.8411
	old_data_grads_norm = 5.1551
	sim_grads_norm = 0.0416
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0571
	data_grads_norm = 4.4856
	new_data_grads_norm = 6.6647
	old_data_grads_norm = 5.0304
	sim_grads_norm = 0.0309
-- Starting training on experience 218 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7812
	data_grads_norm = 4.0120
	new_data_grads_norm = 6.2417
	old_data_grads_norm = 4.4151
	sim_grads_norm = -0.0269
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0584
	data_grads_norm = 4.6294
	new_data_grads_norm = 7.4148
	old_data_grads_norm = 6.3565
	sim_grads_norm = -0.0176
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2840
	data_grads_norm = 4.5496
	new_data_grads_norm = 7.1181
	old_data_grads_norm = 5.5541
	sim_grads_norm = 0.0071
-- Starting training on experience 219 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4418
	data_grads_norm = 5.1180
	new_data_grads_norm = 7.1892
	old_data_grads_norm = 6.0577
	sim_grads_norm = -0.0175
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6534
	data_grads_norm = 5.6485
	new_data_grads_norm = 7.6971
	old_data_grads_norm = 5.6689
	sim_grads_norm = 0.0542
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4928
	data_grads_norm = 5.3773
	new_data_grads_norm = 8.2215
	old_data_grads_norm = 6.6332
	sim_grads_norm = -0.0091
-- Starting training on experience 220 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7098
	data_grads_norm = 5.7777
	new_data_grads_norm = 7.9473
	old_data_grads_norm = 7.1747
	sim_grads_norm = 0.0050
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8212
	data_grads_norm = 5.1579
	new_data_grads_norm = 7.1641
	old_data_grads_norm = 7.7361
	sim_grads_norm = 0.0508
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3142
	data_grads_norm = 5.8473
	new_data_grads_norm = 8.0425
	old_data_grads_norm = 7.7381
	sim_grads_norm = -0.0187
-- Starting training on experience 221 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0673
	data_grads_norm = 4.6122
	new_data_grads_norm = 6.7505
	old_data_grads_norm = 5.7156
	sim_grads_norm = 0.0140
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9186
	data_grads_norm = 4.7748
	new_data_grads_norm = 7.0400
	old_data_grads_norm = 6.5914
	sim_grads_norm = 0.0263
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7003
	data_grads_norm = 3.9676
	new_data_grads_norm = 6.7128
	old_data_grads_norm = 4.4651
	sim_grads_norm = -0.0164
-- Starting training on experience 222 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6329
	data_grads_norm = 4.0716
	new_data_grads_norm = 7.8009
	old_data_grads_norm = 5.2580
	sim_grads_norm = -0.0079
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4463
	data_grads_norm = 3.6499
	new_data_grads_norm = 6.6286
	old_data_grads_norm = 3.6565
	sim_grads_norm = -0.0054
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6432
	data_grads_norm = 4.0406
	new_data_grads_norm = 7.0675
	old_data_grads_norm = 5.4956
	sim_grads_norm = -0.0163
-- Starting training on experience 223 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5547
	data_grads_norm = 5.6294
	new_data_grads_norm = 7.0478
	old_data_grads_norm = 5.5725
	sim_grads_norm = 0.0193
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1832
	data_grads_norm = 4.4347
	new_data_grads_norm = 7.1195
	old_data_grads_norm = 6.3605
	sim_grads_norm = 0.0067
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3600
	data_grads_norm = 6.0606
	new_data_grads_norm = 7.6457
	old_data_grads_norm = 8.1316
	sim_grads_norm = 0.0827
-- Starting training on experience 224 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8448
	data_grads_norm = 4.8224
	new_data_grads_norm = 8.1238
	old_data_grads_norm = 5.9224
	sim_grads_norm = -0.0046
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8162
	data_grads_norm = 4.8673
	new_data_grads_norm = 7.0238
	old_data_grads_norm = 5.2808
	sim_grads_norm = -0.0121
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1945
	data_grads_norm = 5.0335
	new_data_grads_norm = 8.5965
	old_data_grads_norm = 5.9671
	sim_grads_norm = 0.0197
-- Starting training on experience 225 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1681
	data_grads_norm = 4.8819
	new_data_grads_norm = 7.5348
	old_data_grads_norm = 4.6346
	sim_grads_norm = 0.0442
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2395
	data_grads_norm = 4.8271
	new_data_grads_norm = 6.7062
	old_data_grads_norm = 6.6974
	sim_grads_norm = -0.0005
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7266
	data_grads_norm = 4.2929
	new_data_grads_norm = 6.6486
	old_data_grads_norm = 4.6650
	sim_grads_norm = -0.0340
-- Starting training on experience 226 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6039
	data_grads_norm = 3.7548
	new_data_grads_norm = 6.5082
	old_data_grads_norm = 3.6044
	sim_grads_norm = -0.0268
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6588
	data_grads_norm = 4.0352
	new_data_grads_norm = 6.5521
	old_data_grads_norm = 5.4326
	sim_grads_norm = -0.0193
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2451
	data_grads_norm = 5.4552
	new_data_grads_norm = 6.6237
	old_data_grads_norm = 7.5893
	sim_grads_norm = -0.0225
-- Starting training on experience 227 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7640
	data_grads_norm = 3.7696
	new_data_grads_norm = 6.2018
	old_data_grads_norm = 4.4018
	sim_grads_norm = 0.0332
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7053
	data_grads_norm = 4.5275
	new_data_grads_norm = 5.8651
	old_data_grads_norm = 5.5215
	sim_grads_norm = 0.0039
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8148
	data_grads_norm = 3.7920
	new_data_grads_norm = 6.5536
	old_data_grads_norm = 3.6407
	sim_grads_norm = -0.0245
-- Starting training on experience 228 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1008
	data_grads_norm = 4.3034
	new_data_grads_norm = 6.9368
	old_data_grads_norm = 7.0333
	sim_grads_norm = -0.0213
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8595
	data_grads_norm = 5.6086
	new_data_grads_norm = 7.7159
	old_data_grads_norm = 7.3446
	sim_grads_norm = -0.0282
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2619
	data_grads_norm = 4.8727
	new_data_grads_norm = 6.6112
	old_data_grads_norm = 6.0262
	sim_grads_norm = 0.0023
-- Starting training on experience 229 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6397
	data_grads_norm = 5.1186
	new_data_grads_norm = 7.7775
	old_data_grads_norm = 5.7706
	sim_grads_norm = 0.1108
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6802
	data_grads_norm = 5.3908
	new_data_grads_norm = 7.3375
	old_data_grads_norm = 9.2996
	sim_grads_norm = -0.0322
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7909
	data_grads_norm = 3.7946
	new_data_grads_norm = 7.0522
	old_data_grads_norm = 4.5064
	sim_grads_norm = 0.0032
-- Starting training on experience 230 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9449
	data_grads_norm = 4.7060
	new_data_grads_norm = 7.9335
	old_data_grads_norm = 4.6911
	sim_grads_norm = 0.0106
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9569
	data_grads_norm = 4.4261
	new_data_grads_norm = 7.2940
	old_data_grads_norm = 5.2054
	sim_grads_norm = 0.0053
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6635
	data_grads_norm = 4.1547
	new_data_grads_norm = 6.8152
	old_data_grads_norm = 3.1971
	sim_grads_norm = -0.0403
-- Starting training on experience 231 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3525
	data_grads_norm = 4.8288
	new_data_grads_norm = 7.1591
	old_data_grads_norm = 6.4553
	sim_grads_norm = 0.0105
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3146
	data_grads_norm = 5.1963
	new_data_grads_norm = 6.6791
	old_data_grads_norm = 8.4853
	sim_grads_norm = 0.0428
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4817
	data_grads_norm = 3.7046
	new_data_grads_norm = 6.9183
	old_data_grads_norm = 3.4165
	sim_grads_norm = 0.0042
-- Starting training on experience 232 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4672
	data_grads_norm = 5.0335
	new_data_grads_norm = 7.2586
	old_data_grads_norm = 5.7376
	sim_grads_norm = 0.0578
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8010
	data_grads_norm = 4.8471
	new_data_grads_norm = 6.7975
	old_data_grads_norm = 5.4393
	sim_grads_norm = -0.0173
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0227
	data_grads_norm = 3.9658
	new_data_grads_norm = 8.1766
	old_data_grads_norm = 4.4110
	sim_grads_norm = -0.0549
-- Starting training on experience 233 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4391
	data_grads_norm = 3.7216
	new_data_grads_norm = 7.1924
	old_data_grads_norm = 1.8745
	sim_grads_norm = -0.0112
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1529
	data_grads_norm = 5.2154
	new_data_grads_norm = 7.9543
	old_data_grads_norm = 6.0772
	sim_grads_norm = -0.0042
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4387
	data_grads_norm = 6.0101
	new_data_grads_norm = 9.9094
	old_data_grads_norm = 5.7198
	sim_grads_norm = -0.0105
-- Starting training on experience 234 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2860
	data_grads_norm = 4.7426
	new_data_grads_norm = 8.0703
	old_data_grads_norm = 5.2434
	sim_grads_norm = -0.0109
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0891
	data_grads_norm = 3.9842
	new_data_grads_norm = 6.9257
	old_data_grads_norm = 5.7061
	sim_grads_norm = -0.0370
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4028
	data_grads_norm = 4.3914
	new_data_grads_norm = 8.0573
	old_data_grads_norm = 4.8224
	sim_grads_norm = 0.0084
-- Starting training on experience 235 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9537
	data_grads_norm = 4.5869
	new_data_grads_norm = 7.3981
	old_data_grads_norm = 5.0418
	sim_grads_norm = 0.0203
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8750
	data_grads_norm = 4.8652
	new_data_grads_norm = 7.2441
	old_data_grads_norm = 6.2203
	sim_grads_norm = -0.0287
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1173
	data_grads_norm = 4.8142
	new_data_grads_norm = 7.0981
	old_data_grads_norm = 5.1770
	sim_grads_norm = 0.0048
-- Starting training on experience 236 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4045
	data_grads_norm = 3.6494
	new_data_grads_norm = 6.3138
	old_data_grads_norm = 4.3964
	sim_grads_norm = 0.0044
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0282
	data_grads_norm = 5.5088
	new_data_grads_norm = 6.9489
	old_data_grads_norm = 8.0429
	sim_grads_norm = 0.0169
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6419
	data_grads_norm = 3.8021
	new_data_grads_norm = 6.5112
	old_data_grads_norm = 6.1818
	sim_grads_norm = 0.0388
-- Starting training on experience 237 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 1 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
Epoch 2 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0000
-- >> End of training phase << --
-- >> Start of eval phase << --
-- Starting eval on experience 0 (Task 0) from test stream --
> Eval on experience 0 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp000 = 5.0795
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.2460
	mb_index = 4760
	time = 1681.6558
-- Starting eval on experience 1 (Task 0) from test stream --
> Eval on experience 1 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp001 = 3.6710
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.3260
-- Starting eval on experience 2 (Task 0) from test stream --
> Eval on experience 2 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp002 = 5.5254
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.1600
-- Starting eval on experience 3 (Task 0) from test stream --
> Eval on experience 3 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp003 = 3.8493
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.4080
-- Starting eval on experience 4 (Task 0) from test stream --
> Eval on experience 4 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp004 = 5.5947
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.1800
-- Starting eval on experience 5 (Task 0) from test stream --
> Eval on experience 5 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp005 = 4.1211
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp005 = 0.3560
-- Starting eval on experience 6 (Task 0) from test stream --
> Eval on experience 6 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp006 = 4.3862
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp006 = 0.2700
-- Starting eval on experience 7 (Task 0) from test stream --
> Eval on experience 7 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp007 = 4.5971
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp007 = 0.3320
-- Starting eval on experience 8 (Task 0) from test stream --
> Eval on experience 8 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp008 = 4.2982
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp008 = 0.3080
-- Starting eval on experience 9 (Task 0) from test stream --
> Eval on experience 9 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp009 = 4.2849
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp009 = 0.2700
-- Starting eval on experience 10 (Task 0) from test stream --
> Eval on experience 10 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp010 = 4.6281
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp010 = 0.2460
-- Starting eval on experience 11 (Task 0) from test stream --
> Eval on experience 11 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp011 = 3.2883
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp011 = 0.4380
-- Starting eval on experience 12 (Task 0) from test stream --
> Eval on experience 12 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp012 = 4.8504
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp012 = 0.1540
-- Starting eval on experience 13 (Task 0) from test stream --
> Eval on experience 13 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp013 = 3.9902
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp013 = 0.2420
-- Starting eval on experience 14 (Task 0) from test stream --
> Eval on experience 14 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp014 = 3.6263
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp014 = 0.3120
-- Starting eval on experience 15 (Task 0) from test stream --
> Eval on experience 15 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp015 = 3.2736
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp015 = 0.3180
-- Starting eval on experience 16 (Task 0) from test stream --
> Eval on experience 16 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp016 = 3.4661
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp016 = 0.2420
-- Starting eval on experience 17 (Task 0) from test stream --
> Eval on experience 17 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp017 = 3.7863
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp017 = 0.2000
-- Starting eval on experience 18 (Task 0) from test stream --
> Eval on experience 18 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp018 = 3.5791
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp018 = 0.1840
-- Starting eval on experience 19 (Task 0) from test stream --
> Eval on experience 19 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp019 = 3.5569
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp019 = 0.1400
-- >> End of eval phase << --
	CumulativeAccuracy/eval_phase/test_stream/Exp000 = 0.7140
	CumulativeAccuracy/eval_phase/test_stream/Exp001 = 0.6580
	CumulativeAccuracy/eval_phase/test_stream/Exp002 = 0.5587
	CumulativeAccuracy/eval_phase/test_stream/Exp003 = 0.5435
	CumulativeAccuracy/eval_phase/test_stream/Exp004 = 0.4960
	CumulativeAccuracy/eval_phase/test_stream/Exp005 = 0.4630
	CumulativeAccuracy/eval_phase/test_stream/Exp006 = 0.4374
	CumulativeAccuracy/eval_phase/test_stream/Exp007 = 0.4198
	CumulativeAccuracy/eval_phase/test_stream/Exp008 = 0.3964
	CumulativeAccuracy/eval_phase/test_stream/Exp009 = 0.3836
	CumulativeAccuracy/eval_phase/test_stream/Exp010 = 0.3656
	CumulativeAccuracy/eval_phase/test_stream/Exp011 = 0.3602
	CumulativeAccuracy/eval_phase/test_stream/Exp012 = 0.3372
	CumulativeAccuracy/eval_phase/test_stream/Exp013 = 0.3240
	CumulativeAccuracy/eval_phase/test_stream/Exp014 = 0.3140
	CumulativeAccuracy/eval_phase/test_stream/Exp015 = 0.3063
	CumulativeAccuracy/eval_phase/test_stream/Exp016 = 0.2965
	CumulativeAccuracy/eval_phase/test_stream/Exp017 = 0.2874
	CumulativeAccuracy/eval_phase/test_stream/Exp018 = 0.2774
	CumulativeAccuracy/eval_phase/test_stream/Exp019 = 0.2666
	Loss_Stream/eval_phase/test_stream/Task000 = 4.1726
	Top1_Acc_Stream/eval_phase/test_stream/Task000 = 0.2666
