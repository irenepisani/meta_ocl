-- >> Start of training phase << --
-- Starting training on experience 0 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7497
-- Starting training on experience 1 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7690
	data_grads_norm = 6.6542
	new_data_grads_norm = 12.2162
	old_data_grads_norm = 7.6787
	sim_grads_norm_tr = 0.0332
-- Starting training on experience 2 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1306
	data_grads_norm = 8.9018
	new_data_grads_norm = 5.3810
	old_data_grads_norm = 12.7030
	sim_grads_norm_tr = -0.0420
-- Starting training on experience 3 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2616
	data_grads_norm = 12.7958
	new_data_grads_norm = 15.9550
	old_data_grads_norm = 15.2562
	sim_grads_norm_tr = 0.3988
-- Starting training on experience 4 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3421
	data_grads_norm = 10.8941
	new_data_grads_norm = 11.3465
	old_data_grads_norm = 15.0396
	sim_grads_norm_tr = 0.3843
-- Starting training on experience 5 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3707
	data_grads_norm = 9.0266
	new_data_grads_norm = 11.7936
	old_data_grads_norm = 14.2077
	sim_grads_norm_tr = 0.1701
-- Starting training on experience 6 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7431
	data_grads_norm = 7.3060
	new_data_grads_norm = 11.8376
	old_data_grads_norm = 7.7424
	sim_grads_norm_tr = 0.2019
-- Starting training on experience 7 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.6451
	data_grads_norm = 6.2907
	new_data_grads_norm = 8.5419
	old_data_grads_norm = 6.8631
	sim_grads_norm_tr = 0.2928
-- Starting training on experience 8 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0946
	data_grads_norm = 9.2256
	new_data_grads_norm = 9.8729
	old_data_grads_norm = 10.2999
	sim_grads_norm_tr = 0.7627
-- Starting training on experience 9 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4999
	data_grads_norm = 5.9965
	new_data_grads_norm = 11.5475
	old_data_grads_norm = 5.4724
	sim_grads_norm_tr = -0.1404
-- Starting training on experience 10 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7302
	data_grads_norm = 8.6809
	new_data_grads_norm = 8.9722
	old_data_grads_norm = 11.4433
	sim_grads_norm_tr = 0.3224
-- Starting training on experience 11 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9409
	data_grads_norm = 10.6439
	new_data_grads_norm = 16.8278
	old_data_grads_norm = 10.5199
	sim_grads_norm_tr = 0.2509
-- Starting training on experience 12 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7870
	data_grads_norm = 4.9806
	new_data_grads_norm = 8.9676
	old_data_grads_norm = 9.8398
	sim_grads_norm_tr = -0.0569
-- Starting training on experience 13 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.5451
	data_grads_norm = 10.1116
	new_data_grads_norm = 6.9530
	old_data_grads_norm = 16.3939
	sim_grads_norm_tr = 0.3868
-- Starting training on experience 14 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0105
	data_grads_norm = 5.6145
	new_data_grads_norm = 9.8517
	old_data_grads_norm = 5.5311
	sim_grads_norm_tr = 0.0452
-- Starting training on experience 15 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3352
	data_grads_norm = 7.7759
	new_data_grads_norm = 8.7318
	old_data_grads_norm = 8.1648
	sim_grads_norm_tr = 0.6459
-- Starting training on experience 16 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7462
	data_grads_norm = 8.3823
	new_data_grads_norm = 7.5412
	old_data_grads_norm = 10.7690
	sim_grads_norm_tr = 0.6889
-- Starting training on experience 17 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7092
	data_grads_norm = 7.0032
	new_data_grads_norm = 9.8214
	old_data_grads_norm = 6.6129
	sim_grads_norm_tr = 0.3473
-- Starting training on experience 18 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1964
	data_grads_norm = 5.1907
	new_data_grads_norm = 7.0162
	old_data_grads_norm = 7.1975
	sim_grads_norm_tr = 0.4055
-- Starting training on experience 19 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0631
	data_grads_norm = 7.5775
	new_data_grads_norm = 5.6240
	old_data_grads_norm = 9.9144
	sim_grads_norm_tr = 0.7605
-- Starting training on experience 20 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1067
	data_grads_norm = 10.6465
	new_data_grads_norm = 9.7867
	old_data_grads_norm = 13.2632
	sim_grads_norm_tr = 0.5861
-- Starting training on experience 21 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7721
	data_grads_norm = 4.6504
	new_data_grads_norm = 5.4321
	old_data_grads_norm = 4.1856
	sim_grads_norm_tr = 0.6158
-- Starting training on experience 22 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4557
	data_grads_norm = 4.5723
	new_data_grads_norm = 6.3417
	old_data_grads_norm = 7.6754
	sim_grads_norm_tr = 0.4582
-- Starting training on experience 23 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3862
	data_grads_norm = 2.9718
	new_data_grads_norm = 5.5365
	old_data_grads_norm = 4.8155
	sim_grads_norm_tr = 0.1008
-- Starting training on experience 24 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9426
	data_grads_norm = 3.9737
	new_data_grads_norm = 8.2312
	old_data_grads_norm = 4.5248
	sim_grads_norm_tr = 0.2154
-- Starting training on experience 25 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4581
	data_grads_norm = 2.3471
	new_data_grads_norm = 2.7205
	old_data_grads_norm = 7.3087
	sim_grads_norm_tr = -0.1726
-- Starting training on experience 26 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2945
	data_grads_norm = 1.9677
	new_data_grads_norm = 1.9554
	old_data_grads_norm = 5.3690
	sim_grads_norm_tr = -0.1847
-- Starting training on experience 27 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2746
	data_grads_norm = 21.9447
	new_data_grads_norm = 13.3150
	old_data_grads_norm = 7.7077
	sim_grads_norm_tr = 0.1995
-- Starting training on experience 28 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8924
	data_grads_norm = 4.8246
	new_data_grads_norm = 5.0210
	old_data_grads_norm = 9.8812
	sim_grads_norm_tr = 0.2311
-- Starting training on experience 29 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.5668
	data_grads_norm = 1.7001
	new_data_grads_norm = 6.6515
	old_data_grads_norm = 2.6060
	sim_grads_norm_tr = -0.6565
-- Starting training on experience 30 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8964
	data_grads_norm = 5.2618
	new_data_grads_norm = 6.3633
	old_data_grads_norm = 4.8062
	sim_grads_norm_tr = 0.8425
-- Starting training on experience 31 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4300
	data_grads_norm = 2.5389
	new_data_grads_norm = 4.0354
	old_data_grads_norm = 2.5942
	sim_grads_norm_tr = 0.4609
-- Starting training on experience 32 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.5069
	data_grads_norm = 2.5712
	new_data_grads_norm = 2.5648
	old_data_grads_norm = 3.7818
	sim_grads_norm_tr = 0.3411
-- Starting training on experience 33 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4369
	data_grads_norm = 2.6699
	new_data_grads_norm = 3.9562
	old_data_grads_norm = 2.3350
	sim_grads_norm_tr = 0.3584
-- Starting training on experience 34 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8015
	data_grads_norm = 4.3969
	new_data_grads_norm = 7.2584
	old_data_grads_norm = 4.7652
	sim_grads_norm_tr = 0.2370
-- Starting training on experience 35 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4241
	data_grads_norm = 3.0783
	new_data_grads_norm = 2.6108
	old_data_grads_norm = 4.5776
	sim_grads_norm_tr = 0.3270
-- Starting training on experience 36 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3207
	data_grads_norm = 1.9795
	new_data_grads_norm = 3.9330
	old_data_grads_norm = 1.8863
	sim_grads_norm_tr = -0.0368
-- Starting training on experience 37 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1179
	data_grads_norm = 6.8727
	new_data_grads_norm = 5.1551
	old_data_grads_norm = 11.9944
	sim_grads_norm_tr = 0.4819
-- Starting training on experience 38 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8382
	data_grads_norm = 6.0386
	new_data_grads_norm = 4.9125
	old_data_grads_norm = 9.8932
	sim_grads_norm_tr = 0.4909
-- Starting training on experience 39 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.6696
	data_grads_norm = 3.1437
	new_data_grads_norm = 2.3584
	old_data_grads_norm = 5.7381
	sim_grads_norm_tr = 0.3230
-- Starting training on experience 40 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1937
	data_grads_norm = 7.0503
	new_data_grads_norm = 4.6951
	old_data_grads_norm = 9.0686
	sim_grads_norm_tr = 0.7374
-- Starting training on experience 41 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.6334
	data_grads_norm = 2.9077
	new_data_grads_norm = 3.1803
	old_data_grads_norm = 4.4037
	sim_grads_norm_tr = 0.2724
-- Starting training on experience 42 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3346
	data_grads_norm = 1.6736
	new_data_grads_norm = 1.1100
	old_data_grads_norm = 4.0971
	sim_grads_norm_tr = -0.1390
-- Starting training on experience 43 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2353
	data_grads_norm = 1.3898
	new_data_grads_norm = 1.8677
	old_data_grads_norm = 1.1604
	sim_grads_norm_tr = 0.2948
-- Starting training on experience 44 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4489
	data_grads_norm = 3.2934
	new_data_grads_norm = 5.0326
	old_data_grads_norm = 3.1279
	sim_grads_norm_tr = -0.0079
-- Starting training on experience 45 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2378
	data_grads_norm = 1.4313
	new_data_grads_norm = 1.1578
	old_data_grads_norm = 2.3067
	sim_grads_norm_tr = 0.1575
-- Starting training on experience 46 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.5945
	data_grads_norm = 5.1364
	new_data_grads_norm = 4.4986
	old_data_grads_norm = 7.3160
	sim_grads_norm_tr = 0.2430
-- Starting training on experience 47 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2248
	data_grads_norm = 1.2748
	new_data_grads_norm = 1.7537
	old_data_grads_norm = 1.2535
	sim_grads_norm_tr = 0.3315
-- Starting training on experience 48 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.5036
	data_grads_norm = 2.8339
	new_data_grads_norm = 5.1899
	old_data_grads_norm = 2.6840
	sim_grads_norm_tr = -0.0836
-- Starting training on experience 49 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3806
	data_grads_norm = 2.8437
	new_data_grads_norm = 4.5719
	old_data_grads_norm = 2.4983
	sim_grads_norm_tr = 0.2576
-- Starting training on experience 50 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2954
	data_grads_norm = 2.4771
	new_data_grads_norm = 5.6105
	old_data_grads_norm = 0.8393
	sim_grads_norm_tr = 0.0657
-- Starting training on experience 51 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3704
	data_grads_norm = 2.9101
	new_data_grads_norm = 4.5438
	old_data_grads_norm = 1.6027
	sim_grads_norm_tr = 0.1554
-- Starting training on experience 52 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1400
	data_grads_norm = 2.4490
	new_data_grads_norm = 1.7783
	old_data_grads_norm = 4.1773
	sim_grads_norm_tr = -0.1826
-- Starting training on experience 53 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.5278
	data_grads_norm = 5.0149
	new_data_grads_norm = 5.4419
	old_data_grads_norm = 6.9415
	sim_grads_norm_tr = 0.3363
-- Starting training on experience 54 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7915
	data_grads_norm = 4.2955
	new_data_grads_norm = 7.5804
	old_data_grads_norm = 4.8238
	sim_grads_norm_tr = -0.0121
-- Starting training on experience 55 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1833
	data_grads_norm = 1.5574
	new_data_grads_norm = 0.9265
	old_data_grads_norm = 2.5227
	sim_grads_norm_tr = 0.0993
-- Starting training on experience 56 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.5220
	data_grads_norm = 3.0474
	new_data_grads_norm = 1.9860
	old_data_grads_norm = 4.5446
	sim_grads_norm_tr = 0.4345
-- Starting training on experience 57 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3793
	data_grads_norm = 2.3604
	new_data_grads_norm = 3.0451
	old_data_grads_norm = 2.2683
	sim_grads_norm_tr = 0.5546
-- Starting training on experience 58 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4499
	data_grads_norm = 2.2391
	new_data_grads_norm = 5.1852
	old_data_grads_norm = 2.5535
	sim_grads_norm_tr = -0.4849
-- Starting training on experience 59 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4241
	data_grads_norm = 3.0327
	new_data_grads_norm = 3.7882
	old_data_grads_norm = 3.6677
	sim_grads_norm_tr = 0.1635
-- Starting training on experience 60 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1399
	data_grads_norm = 0.8746
	new_data_grads_norm = 1.6195
	old_data_grads_norm = 1.5025
	sim_grads_norm_tr = -0.4386
-- Starting training on experience 61 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1597
	data_grads_norm = 1.3775
	new_data_grads_norm = 2.8323
	old_data_grads_norm = 0.8178
	sim_grads_norm_tr = 0.1196
-- Starting training on experience 62 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.5536
	data_grads_norm = 2.7861
	new_data_grads_norm = 4.9859
	old_data_grads_norm = 1.5286
	sim_grads_norm_tr = -0.0795
-- Starting training on experience 63 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4488
	data_grads_norm = 2.4690
	new_data_grads_norm = 4.0264
	old_data_grads_norm = 1.9754
	sim_grads_norm_tr = 0.2266
-- Starting training on experience 64 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3416
	data_grads_norm = 1.7689
	new_data_grads_norm = 2.1439
	old_data_grads_norm = 4.6352
	sim_grads_norm_tr = -0.2673
-- Starting training on experience 65 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3913
	data_grads_norm = 2.6360
	new_data_grads_norm = 1.9900
	old_data_grads_norm = 4.4427
	sim_grads_norm_tr = 0.2529
-- Starting training on experience 66 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3425
	data_grads_norm = 3.1666
	new_data_grads_norm = 1.9192
	old_data_grads_norm = 5.9867
	sim_grads_norm_tr = 0.1002
-- Starting training on experience 67 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2438
	data_grads_norm = 2.2607
	new_data_grads_norm = 2.4018
	old_data_grads_norm = 2.5343
	sim_grads_norm_tr = 0.6393
-- Starting training on experience 68 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2937
	data_grads_norm = 1.8613
	new_data_grads_norm = 3.1861
	old_data_grads_norm = 1.3073
	sim_grads_norm_tr = 0.1487
-- Starting training on experience 69 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.5018
	data_grads_norm = 3.2629
	new_data_grads_norm = 4.5342
	old_data_grads_norm = 7.4060
	sim_grads_norm_tr = -0.2123
-- Starting training on experience 70 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4467
	data_grads_norm = 3.4991
	new_data_grads_norm = 4.0105
	old_data_grads_norm = 5.1120
	sim_grads_norm_tr = 0.4008
-- Starting training on experience 71 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3344
	data_grads_norm = 2.0719
	new_data_grads_norm = 2.6808
	old_data_grads_norm = 3.6293
	sim_grads_norm_tr = -0.0861
-- Starting training on experience 72 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4110
	data_grads_norm = 2.5533
	new_data_grads_norm = 4.7653
	old_data_grads_norm = 1.5299
	sim_grads_norm_tr = 0.0755
-- Starting training on experience 73 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.5919
	data_grads_norm = 3.6398
	new_data_grads_norm = 3.4828
	old_data_grads_norm = 4.9331
	sim_grads_norm_tr = 0.4421
-- Starting training on experience 74 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3383
	data_grads_norm = 2.9063
	new_data_grads_norm = 2.5052
	old_data_grads_norm = 4.3138
	sim_grads_norm_tr = 0.1634
-- Starting training on experience 75 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9785
	data_grads_norm = 4.6315
	new_data_grads_norm = 5.7598
	old_data_grads_norm = 4.3892
	sim_grads_norm_tr = 0.5761
-- Starting training on experience 76 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.5482
	data_grads_norm = 3.9088
	new_data_grads_norm = 4.4905
	old_data_grads_norm = 4.3827
	sim_grads_norm_tr = 0.3792
-- Starting training on experience 77 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.6749
	data_grads_norm = 3.7599
	new_data_grads_norm = 4.7928
	old_data_grads_norm = 2.6983
	sim_grads_norm_tr = 0.3331
-- Starting training on experience 78 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.6603
	data_grads_norm = 4.0730
	new_data_grads_norm = 7.7820
	old_data_grads_norm = 3.3394
	sim_grads_norm_tr = 0.1767
-- Starting training on experience 79 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4509
	data_grads_norm = 2.9775
	new_data_grads_norm = 5.7011
	old_data_grads_norm = 1.7179
	sim_grads_norm_tr = 0.2147
-- Starting training on experience 80 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.6015
	data_grads_norm = 2.2670
	new_data_grads_norm = 3.2107
	old_data_grads_norm = 2.9620
	sim_grads_norm_tr = 0.0629
-- Starting training on experience 81 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0903
	data_grads_norm = 0.6871
	new_data_grads_norm = 0.9672
	old_data_grads_norm = 1.1190
	sim_grads_norm_tr = 0.0367
-- Starting training on experience 82 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1911
	data_grads_norm = 1.3577
	new_data_grads_norm = 1.4971
	old_data_grads_norm = 2.2693
	sim_grads_norm_tr = 0.0717
-- Starting training on experience 83 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3608
	data_grads_norm = 1.5756
	new_data_grads_norm = 2.5552
	old_data_grads_norm = 2.8804
	sim_grads_norm_tr = -0.1126
-- Starting training on experience 84 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2943
	data_grads_norm = 1.9810
	new_data_grads_norm = 2.5646
	old_data_grads_norm = 2.1616
	sim_grads_norm_tr = 0.3474
-- Starting training on experience 85 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3786
	data_grads_norm = 1.8016
	new_data_grads_norm = 4.4476
	old_data_grads_norm = 4.5561
	sim_grads_norm_tr = -0.1206
-- Starting training on experience 86 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.5097
	data_grads_norm = 2.5438
	new_data_grads_norm = 3.3270
	old_data_grads_norm = 3.4787
	sim_grads_norm_tr = 0.0098
-- Starting training on experience 87 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1606
	data_grads_norm = 1.2626
	new_data_grads_norm = 2.5038
	old_data_grads_norm = 1.7331
	sim_grads_norm_tr = -0.3388
-- Starting training on experience 88 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2693
	data_grads_norm = 1.8583
	new_data_grads_norm = 0.9054
	old_data_grads_norm = 2.6710
	sim_grads_norm_tr = 0.1001
-- Starting training on experience 89 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2190
	data_grads_norm = 1.9544
	new_data_grads_norm = 1.6290
	old_data_grads_norm = 2.5871
	sim_grads_norm_tr = 0.5136
-- Starting training on experience 90 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1722
	data_grads_norm = 0.8643
	new_data_grads_norm = 1.9788
	old_data_grads_norm = 0.6185
	sim_grads_norm_tr = -0.3137
-- Starting training on experience 91 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2582
	data_grads_norm = 2.0030
	new_data_grads_norm = 3.0781
	old_data_grads_norm = 1.7284
	sim_grads_norm_tr = 0.1760
-- Starting training on experience 92 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2420
	data_grads_norm = 1.9170
	new_data_grads_norm = 0.5070
	old_data_grads_norm = 4.6640
	sim_grads_norm_tr = -0.1978
-- Starting training on experience 93 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.5282
	data_grads_norm = 3.3685
	new_data_grads_norm = 3.4564
	old_data_grads_norm = 5.1533
	sim_grads_norm_tr = 0.2825
-- Starting training on experience 94 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.6078
	data_grads_norm = 3.3705
	new_data_grads_norm = 6.4676
	old_data_grads_norm = 1.3050
	sim_grads_norm_tr = 0.1451
-- Starting training on experience 95 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2434
	data_grads_norm = 2.0060
	new_data_grads_norm = 1.3932
	old_data_grads_norm = 3.5342
	sim_grads_norm_tr = 0.3836
-- Starting training on experience 96 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3802
	data_grads_norm = 3.1284
	new_data_grads_norm = 1.8193
	old_data_grads_norm = 3.3900
	sim_grads_norm_tr = 0.4770
-- Starting training on experience 97 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4078
	data_grads_norm = 2.0719
	new_data_grads_norm = 1.5789
	old_data_grads_norm = 2.9814
	sim_grads_norm_tr = 0.4306
-- Starting training on experience 98 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1726
	data_grads_norm = 1.2101
	new_data_grads_norm = 1.7161
	old_data_grads_norm = 2.1563
	sim_grads_norm_tr = -0.0559
-- Starting training on experience 99 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4224
	data_grads_norm = 3.8850
	new_data_grads_norm = 5.4096
	old_data_grads_norm = 4.0795
	sim_grads_norm_tr = 0.0958
-- Starting training on experience 100 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1693
	data_grads_norm = 1.0055
	new_data_grads_norm = 1.5564
	old_data_grads_norm = 1.6949
	sim_grads_norm_tr = -0.1546
-- Starting training on experience 101 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1287
	data_grads_norm = 1.0373
	new_data_grads_norm = 1.6374
	old_data_grads_norm = 1.3788
	sim_grads_norm_tr = 0.1579
-- Starting training on experience 102 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3014
	data_grads_norm = 3.2292
	new_data_grads_norm = 3.7641
	old_data_grads_norm = 6.0662
	sim_grads_norm_tr = 0.0268
-- Starting training on experience 103 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.6932
	data_grads_norm = 3.2954
	new_data_grads_norm = 5.5415
	old_data_grads_norm = 2.5980
	sim_grads_norm_tr = 0.4866
-- Starting training on experience 104 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.5987
	data_grads_norm = 4.9859
	new_data_grads_norm = 6.6288
	old_data_grads_norm = 3.2442
	sim_grads_norm_tr = 0.1386
-- Starting training on experience 105 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3749
	data_grads_norm = 2.2524
	new_data_grads_norm = 1.4783
	old_data_grads_norm = 4.3897
	sim_grads_norm_tr = 0.2067
-- Starting training on experience 106 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3094
	data_grads_norm = 1.3166
	new_data_grads_norm = 4.8462
	old_data_grads_norm = 2.2961
	sim_grads_norm_tr = -0.5377
-- Starting training on experience 107 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2067
	data_grads_norm = 0.9041
	new_data_grads_norm = 1.3932
	old_data_grads_norm = 0.9787
	sim_grads_norm_tr = 0.0949
-- Starting training on experience 108 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1824
	data_grads_norm = 0.9456
	new_data_grads_norm = 1.3495
	old_data_grads_norm = 1.1933
	sim_grads_norm_tr = 0.0218
-- Starting training on experience 109 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2933
	data_grads_norm = 1.9724
	new_data_grads_norm = 1.7835
	old_data_grads_norm = 2.5193
	sim_grads_norm_tr = 0.2540
-- Starting training on experience 110 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2340
	data_grads_norm = 1.5470
	new_data_grads_norm = 5.0888
	old_data_grads_norm = 0.8741
	sim_grads_norm_tr = -0.5516
-- Starting training on experience 111 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1651
	data_grads_norm = 1.2689
	new_data_grads_norm = 1.6925
	old_data_grads_norm = 2.6341
	sim_grads_norm_tr = -0.2087
-- Starting training on experience 112 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3815
	data_grads_norm = 3.3418
	new_data_grads_norm = 4.3771
	old_data_grads_norm = 4.2651
	sim_grads_norm_tr = -0.0455
-- Starting training on experience 113 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3424
	data_grads_norm = 1.6290
	new_data_grads_norm = 4.4712
	old_data_grads_norm = 1.2047
	sim_grads_norm_tr = 0.0036
-- Starting training on experience 114 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3065
	data_grads_norm = 1.7124
	new_data_grads_norm = 0.8011
	old_data_grads_norm = 3.7393
	sim_grads_norm_tr = 0.0734
-- Starting training on experience 115 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3383
	data_grads_norm = 1.7622
	new_data_grads_norm = 5.4770
	old_data_grads_norm = 2.1847
	sim_grads_norm_tr = -0.1883
-- Starting training on experience 116 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.5991
	data_grads_norm = 2.9167
	new_data_grads_norm = 5.1371
	old_data_grads_norm = 0.6809
	sim_grads_norm_tr = 0.1310
-- Starting training on experience 117 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2408
	data_grads_norm = 1.4813
	new_data_grads_norm = 1.4413
	old_data_grads_norm = 5.7683
	sim_grads_norm_tr = -0.4454
-- Starting training on experience 118 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8247
	data_grads_norm = 4.3634
	new_data_grads_norm = 5.0360
	old_data_grads_norm = 5.0326
	sim_grads_norm_tr = 0.5606
-- Starting training on experience 119 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3159
	data_grads_norm = 1.7335
	new_data_grads_norm = 3.1339
	old_data_grads_norm = 2.5096
	sim_grads_norm_tr = -0.1886
-- Starting training on experience 120 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4780
	data_grads_norm = 3.1375
	new_data_grads_norm = 5.1869
	old_data_grads_norm = 2.1118
	sim_grads_norm_tr = -0.3622
-- Starting training on experience 121 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3600
	data_grads_norm = 2.0669
	new_data_grads_norm = 6.0999
	old_data_grads_norm = 1.3400
	sim_grads_norm_tr = -0.3082
-- Starting training on experience 122 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.5647
	data_grads_norm = 3.6449
	new_data_grads_norm = 4.5603
	old_data_grads_norm = 3.8264
	sim_grads_norm_tr = 0.5458
-- Starting training on experience 123 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2079
	data_grads_norm = 1.8573
	new_data_grads_norm = 2.3687
	old_data_grads_norm = 2.9471
	sim_grads_norm_tr = -0.1249
-- Starting training on experience 124 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3514
	data_grads_norm = 3.1175
	new_data_grads_norm = 3.0037
	old_data_grads_norm = 5.9386
	sim_grads_norm_tr = 0.1136
-- Starting training on experience 125 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3222
	data_grads_norm = 2.0352
	new_data_grads_norm = 3.3687
	old_data_grads_norm = 1.6655
	sim_grads_norm_tr = 0.5487
-- Starting training on experience 126 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3651
	data_grads_norm = 2.7841
	new_data_grads_norm = 6.0779
	old_data_grads_norm = 1.2495
	sim_grads_norm_tr = 0.3228
-- Starting training on experience 127 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4713
	data_grads_norm = 2.1506
	new_data_grads_norm = 4.0869
	old_data_grads_norm = 1.3979
	sim_grads_norm_tr = -0.1694
-- Starting training on experience 128 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3263
	data_grads_norm = 1.9509
	new_data_grads_norm = 2.4993
	old_data_grads_norm = 4.4598
	sim_grads_norm_tr = -0.0577
-- Starting training on experience 129 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2078
	data_grads_norm = 1.6219
	new_data_grads_norm = 1.0960
	old_data_grads_norm = 2.4636
	sim_grads_norm_tr = 0.2129
-- Starting training on experience 130 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4164
	data_grads_norm = 1.4418
	new_data_grads_norm = 1.1853
	old_data_grads_norm = 2.1399
	sim_grads_norm_tr = 0.2342
-- Starting training on experience 131 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2185
	data_grads_norm = 1.2561
	new_data_grads_norm = 2.7792
	old_data_grads_norm = 1.0048
	sim_grads_norm_tr = 0.1405
-- Starting training on experience 132 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0953
	data_grads_norm = 0.6498
	new_data_grads_norm = 0.7469
	old_data_grads_norm = 1.3967
	sim_grads_norm_tr = -0.2083
-- Starting training on experience 133 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1581
	data_grads_norm = 0.9934
	new_data_grads_norm = 1.0704
	old_data_grads_norm = 1.1540
	sim_grads_norm_tr = 0.1145
-- Starting training on experience 134 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1929
	data_grads_norm = 0.9670
	new_data_grads_norm = 2.4980
	old_data_grads_norm = 0.8499
	sim_grads_norm_tr = -0.3877
-- Starting training on experience 135 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2246
	data_grads_norm = 1.1260
	new_data_grads_norm = 0.7278
	old_data_grads_norm = 2.1888
	sim_grads_norm_tr = 0.0998
-- Starting training on experience 136 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1028
	data_grads_norm = 0.9056
	new_data_grads_norm = 0.7649
	old_data_grads_norm = 1.8240
	sim_grads_norm_tr = 0.1085
-- Starting training on experience 137 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3586
	data_grads_norm = 2.6917
	new_data_grads_norm = 6.5942
	old_data_grads_norm = 1.1900
	sim_grads_norm_tr = 0.3880
-- Starting training on experience 138 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3970
	data_grads_norm = 2.0687
	new_data_grads_norm = 2.1391
	old_data_grads_norm = 2.4551
	sim_grads_norm_tr = 0.0952
-- Starting training on experience 139 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1513
	data_grads_norm = 2.8253
	new_data_grads_norm = 2.7834
	old_data_grads_norm = 3.9249
	sim_grads_norm_tr = 0.3202
-- Starting training on experience 140 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1823
	data_grads_norm = 1.2713
	new_data_grads_norm = 1.7020
	old_data_grads_norm = 1.4124
	sim_grads_norm_tr = 0.2204
-- Starting training on experience 141 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8109
	data_grads_norm = 5.0861
	new_data_grads_norm = 5.1774
	old_data_grads_norm = 5.9759
	sim_grads_norm_tr = -0.1232
-- Starting training on experience 142 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4045
	data_grads_norm = 1.8338
	new_data_grads_norm = 1.4070
	old_data_grads_norm = 4.1122
	sim_grads_norm_tr = 0.2168
-- Starting training on experience 143 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3193
	data_grads_norm = 2.2059
	new_data_grads_norm = 1.5345
	old_data_grads_norm = 3.2929
	sim_grads_norm_tr = -0.1057
-- Starting training on experience 144 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3544
	data_grads_norm = 1.7481
	new_data_grads_norm = 3.1001
	old_data_grads_norm = 1.5848
	sim_grads_norm_tr = -0.2260
-- Starting training on experience 145 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.5323
	data_grads_norm = 2.5108
	new_data_grads_norm = 1.2139
	old_data_grads_norm = 4.8582
	sim_grads_norm_tr = 0.2792
-- Starting training on experience 146 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0422
	data_grads_norm = 5.3423
	new_data_grads_norm = 7.2457
	old_data_grads_norm = 6.9741
	sim_grads_norm_tr = 0.1908
-- Starting training on experience 147 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4788
	data_grads_norm = 2.4947
	new_data_grads_norm = 2.9799
	old_data_grads_norm = 2.8290
	sim_grads_norm_tr = 0.4694
-- Starting training on experience 148 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3749
	data_grads_norm = 1.5203
	new_data_grads_norm = 2.1387
	old_data_grads_norm = 1.3140
	sim_grads_norm_tr = 0.2160
-- Starting training on experience 149 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9684
	data_grads_norm = 4.5502
	new_data_grads_norm = 5.6408
	old_data_grads_norm = 5.0671
	sim_grads_norm_tr = 0.4493
-- Starting training on experience 150 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4324
	data_grads_norm = 2.2939
	new_data_grads_norm = 2.8477
	old_data_grads_norm = 2.4266
	sim_grads_norm_tr = 0.7990
-- Starting training on experience 151 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.6582
	data_grads_norm = 2.3712
	new_data_grads_norm = 3.7722
	old_data_grads_norm = 2.0674
	sim_grads_norm_tr = 0.3187
-- Starting training on experience 152 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1894
	data_grads_norm = 0.8594
	new_data_grads_norm = 1.5476
	old_data_grads_norm = 1.3211
	sim_grads_norm_tr = -0.2640
-- Starting training on experience 153 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3051
	data_grads_norm = 1.1803
	new_data_grads_norm = 1.5973
	old_data_grads_norm = 1.5738
	sim_grads_norm_tr = 0.2948
-- Starting training on experience 154 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2567
	data_grads_norm = 1.1842
	new_data_grads_norm = 1.2739
	old_data_grads_norm = 4.1293
	sim_grads_norm_tr = -0.3978
-- Starting training on experience 155 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.6281
	data_grads_norm = 5.6738
	new_data_grads_norm = 5.3580
	old_data_grads_norm = 7.7445
	sim_grads_norm_tr = 0.8410
-- Starting training on experience 156 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.6895
	data_grads_norm = 3.4852
	new_data_grads_norm = 4.6938
	old_data_grads_norm = 6.6188
	sim_grads_norm_tr = -0.1333
-- Starting training on experience 157 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2530
	data_grads_norm = 0.9335
	new_data_grads_norm = 1.4476
	old_data_grads_norm = 0.8235
	sim_grads_norm_tr = -0.2421
-- Starting training on experience 158 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0201
	data_grads_norm = 5.8644
	new_data_grads_norm = 3.2186
	old_data_grads_norm = 8.1065
	sim_grads_norm_tr = 0.3196
-- Starting training on experience 159 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2624
	data_grads_norm = 0.8818
	new_data_grads_norm = 1.2019
	old_data_grads_norm = 1.8063
	sim_grads_norm_tr = -0.0596
-- Starting training on experience 160 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2911
	data_grads_norm = 1.2149
	new_data_grads_norm = 0.8711
	old_data_grads_norm = 3.2008
	sim_grads_norm_tr = 0.2031
-- Starting training on experience 161 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3470
	data_grads_norm = 1.3969
	new_data_grads_norm = 1.4349
	old_data_grads_norm = 2.0206
	sim_grads_norm_tr = 0.4558
-- Starting training on experience 162 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2502
	data_grads_norm = 1.1117
	new_data_grads_norm = 1.0873
	old_data_grads_norm = 2.1871
	sim_grads_norm_tr = -0.0906
-- Starting training on experience 163 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2958
	data_grads_norm = 1.2351
	new_data_grads_norm = 3.1748
	old_data_grads_norm = 1.4696
	sim_grads_norm_tr = -0.2096
-- Starting training on experience 164 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4787
	data_grads_norm = 2.6292
	new_data_grads_norm = 3.1875
	old_data_grads_norm = 2.8299
	sim_grads_norm_tr = 0.1902
-- Starting training on experience 165 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3141
	data_grads_norm = 1.5662
	new_data_grads_norm = 1.1913
	old_data_grads_norm = 2.5598
	sim_grads_norm_tr = 0.1279
-- Starting training on experience 166 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.6275
	data_grads_norm = 3.2458
	new_data_grads_norm = 7.5136
	old_data_grads_norm = 1.8354
	sim_grads_norm_tr = 0.0138
-- Starting training on experience 167 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3383
	data_grads_norm = 1.8012
	new_data_grads_norm = 2.3279
	old_data_grads_norm = 1.6050
	sim_grads_norm_tr = 0.6412
-- Starting training on experience 168 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.5156
	data_grads_norm = 1.7662
	new_data_grads_norm = 1.5797
	old_data_grads_norm = 2.4798
	sim_grads_norm_tr = 0.1467
-- Starting training on experience 169 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2778
	data_grads_norm = 1.5195
	new_data_grads_norm = 3.6825
	old_data_grads_norm = 1.0956
	sim_grads_norm_tr = 0.2871
-- Starting training on experience 170 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2596
	data_grads_norm = 1.2882
	new_data_grads_norm = 1.2724
	old_data_grads_norm = 2.5341
	sim_grads_norm_tr = -0.4034
-- Starting training on experience 171 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3084
	data_grads_norm = 1.5367
	new_data_grads_norm = 0.7721
	old_data_grads_norm = 3.5392
	sim_grads_norm_tr = 0.3181
-- Starting training on experience 172 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.5891
	data_grads_norm = 2.5000
	new_data_grads_norm = 2.8597
	old_data_grads_norm = 3.6854
	sim_grads_norm_tr = 0.4089
-- Starting training on experience 173 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3937
	data_grads_norm = 1.8050
	new_data_grads_norm = 3.1948
	old_data_grads_norm = 2.3641
	sim_grads_norm_tr = -0.1959
-- Starting training on experience 174 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.6253
	data_grads_norm = 2.7242
	new_data_grads_norm = 3.1478
	old_data_grads_norm = 4.0857
	sim_grads_norm_tr = 0.3829
-- Starting training on experience 175 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4318
	data_grads_norm = 1.2960
	new_data_grads_norm = 1.9425
	old_data_grads_norm = 1.5013
	sim_grads_norm_tr = 0.1886
-- Starting training on experience 176 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7605
	data_grads_norm = 2.8471
	new_data_grads_norm = 3.2035
	old_data_grads_norm = 4.0763
	sim_grads_norm_tr = 0.4038
-- Starting training on experience 177 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4162
	data_grads_norm = 1.8888
	new_data_grads_norm = 2.6816
	old_data_grads_norm = 1.5903
	sim_grads_norm_tr = 0.5023
-- Starting training on experience 178 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.5319
	data_grads_norm = 2.2383
	new_data_grads_norm = 3.3057
	old_data_grads_norm = 1.4737
	sim_grads_norm_tr = 0.4585
-- Starting training on experience 179 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3360
	data_grads_norm = 0.8914
	new_data_grads_norm = 1.0922
	old_data_grads_norm = 1.7812
	sim_grads_norm_tr = -0.1630
-- Starting training on experience 180 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3018
	data_grads_norm = 1.0047
	new_data_grads_norm = 1.2500
	old_data_grads_norm = 1.3966
	sim_grads_norm_tr = 0.3745
-- Starting training on experience 181 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3597
	data_grads_norm = 1.4422
	new_data_grads_norm = 1.7291
	old_data_grads_norm = 1.6842
	sim_grads_norm_tr = 0.2951
-- Starting training on experience 182 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3570
	data_grads_norm = 1.3317
	new_data_grads_norm = 2.2743
	old_data_grads_norm = 1.7703
	sim_grads_norm_tr = 0.0910
-- Starting training on experience 183 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2633
	data_grads_norm = 0.9411
	new_data_grads_norm = 1.3355
	old_data_grads_norm = 1.8170
	sim_grads_norm_tr = -0.2709
-- Starting training on experience 184 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2248
	data_grads_norm = 1.0830
	new_data_grads_norm = 2.0053
	old_data_grads_norm = 3.3668
	sim_grads_norm_tr = -0.5023
-- Starting training on experience 185 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4444
	data_grads_norm = 1.9416
	new_data_grads_norm = 2.7174
	old_data_grads_norm = 1.8395
	sim_grads_norm_tr = 0.3148
-- Starting training on experience 186 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3273
	data_grads_norm = 1.8753
	new_data_grads_norm = 3.5047
	old_data_grads_norm = 2.2522
	sim_grads_norm_tr = 0.3442
-- Starting training on experience 187 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3139
	data_grads_norm = 1.7764
	new_data_grads_norm = 1.5833
	old_data_grads_norm = 2.9043
	sim_grads_norm_tr = 0.4324
-- Starting training on experience 188 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3282
	data_grads_norm = 1.7049
	new_data_grads_norm = 0.8333
	old_data_grads_norm = 2.6778
	sim_grads_norm_tr = -0.0957
-- Starting training on experience 189 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2693
	data_grads_norm = 1.8291
	new_data_grads_norm = 1.5332
	old_data_grads_norm = 2.6334
	sim_grads_norm_tr = 0.7049
-- Starting training on experience 190 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3750
	data_grads_norm = 1.9875
	new_data_grads_norm = 4.7713
	old_data_grads_norm = 1.1158
	sim_grads_norm_tr = -0.0213
-- Starting training on experience 191 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3476
	data_grads_norm = 1.2933
	new_data_grads_norm = 1.2388
	old_data_grads_norm = 2.6340
	sim_grads_norm_tr = -0.1877
-- Starting training on experience 192 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2878
	data_grads_norm = 1.6164
	new_data_grads_norm = 1.9990
	old_data_grads_norm = 3.2321
	sim_grads_norm_tr = 0.0239
-- Starting training on experience 193 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3274
	data_grads_norm = 1.9986
	new_data_grads_norm = 1.8223
	old_data_grads_norm = 2.5190
	sim_grads_norm_tr = 0.6165
-- Starting training on experience 194 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1865
	data_grads_norm = 0.7533
	new_data_grads_norm = 1.1723
	old_data_grads_norm = 1.3547
	sim_grads_norm_tr = -0.4799
-- Starting training on experience 195 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1432
	data_grads_norm = 0.7769
	new_data_grads_norm = 1.4197
	old_data_grads_norm = 1.6099
	sim_grads_norm_tr = -0.3002
-- Starting training on experience 196 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3869
	data_grads_norm = 1.6207
	new_data_grads_norm = 3.1177
	old_data_grads_norm = 1.9607
	sim_grads_norm_tr = -0.0736
-- Starting training on experience 197 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2467
	data_grads_norm = 1.2241
	new_data_grads_norm = 1.8045
	old_data_grads_norm = 1.0644
	sim_grads_norm_tr = 0.2725
-- Starting training on experience 198 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2861
	data_grads_norm = 1.0236
	new_data_grads_norm = 2.9765
	old_data_grads_norm = 0.8133
	sim_grads_norm_tr = -0.4458
-- Starting training on experience 199 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4466
	data_grads_norm = 1.6578
	new_data_grads_norm = 1.5258
	old_data_grads_norm = 3.9376
	sim_grads_norm_tr = 0.1541
-- Starting training on experience 200 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.5468
	data_grads_norm = 2.8592
	new_data_grads_norm = 2.6907
	old_data_grads_norm = 6.1810
	sim_grads_norm_tr = 0.1571
-- Starting training on experience 201 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4571
	data_grads_norm = 6.8521
	new_data_grads_norm = 8.5430
	old_data_grads_norm = 6.2241
	sim_grads_norm_tr = 0.7333
-- Starting training on experience 202 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1842
	data_grads_norm = 0.7171
	new_data_grads_norm = 1.2843
	old_data_grads_norm = 0.8629
	sim_grads_norm_tr = 0.3620
-- Starting training on experience 203 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4640
	data_grads_norm = 1.4635
	new_data_grads_norm = 2.6993
	old_data_grads_norm = 1.3513
	sim_grads_norm_tr = -0.0567
-- Starting training on experience 204 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2600
	data_grads_norm = 1.2342
	new_data_grads_norm = 1.6985
	old_data_grads_norm = 2.6166
	sim_grads_norm_tr = 0.2577
-- Starting training on experience 205 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1981
	data_grads_norm = 0.6227
	new_data_grads_norm = 1.0250
	old_data_grads_norm = 0.7707
	sim_grads_norm_tr = -0.1368
-- Starting training on experience 206 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1853
	data_grads_norm = 0.6463
	new_data_grads_norm = 1.0654
	old_data_grads_norm = 0.7939
	sim_grads_norm_tr = 0.1411
-- Starting training on experience 207 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1844
	data_grads_norm = 0.8323
	new_data_grads_norm = 1.2143
	old_data_grads_norm = 1.0086
	sim_grads_norm_tr = -0.0364
-- Starting training on experience 208 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2995
	data_grads_norm = 1.1914
	new_data_grads_norm = 2.2844
	old_data_grads_norm = 3.0437
	sim_grads_norm_tr = -0.0913
-- Starting training on experience 209 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2893
	data_grads_norm = 1.5055
	new_data_grads_norm = 1.5770
	old_data_grads_norm = 1.7660
	sim_grads_norm_tr = 0.1768
-- Starting training on experience 210 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.6292
	data_grads_norm = 2.0848
	new_data_grads_norm = 2.2866
	old_data_grads_norm = 2.3579
	sim_grads_norm_tr = 0.6051
-- Starting training on experience 211 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3154
	data_grads_norm = 1.6166
	new_data_grads_norm = 3.5102
	old_data_grads_norm = 0.9700
	sim_grads_norm_tr = 0.0352
-- Starting training on experience 212 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3599
	data_grads_norm = 2.6337
	new_data_grads_norm = 0.7476
	old_data_grads_norm = 5.7395
	sim_grads_norm_tr = 0.0826
-- Starting training on experience 213 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4398
	data_grads_norm = 2.1497
	new_data_grads_norm = 2.7308
	old_data_grads_norm = 2.2332
	sim_grads_norm_tr = 0.0218
-- Starting training on experience 214 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2596
	data_grads_norm = 1.3546
	new_data_grads_norm = 1.6827
	old_data_grads_norm = 0.8879
	sim_grads_norm_tr = 0.2573
-- Starting training on experience 215 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3827
	data_grads_norm = 2.0379
	new_data_grads_norm = 6.1159
	old_data_grads_norm = 1.1467
	sim_grads_norm_tr = 0.3051
-- Starting training on experience 216 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8076
	data_grads_norm = 4.6160
	new_data_grads_norm = 5.4194
	old_data_grads_norm = 5.2148
	sim_grads_norm_tr = 0.5304
-- Starting training on experience 217 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4246
	data_grads_norm = 2.2513
	new_data_grads_norm = 1.3733
	old_data_grads_norm = 3.3825
	sim_grads_norm_tr = 0.5804
-- Starting training on experience 218 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2445
	data_grads_norm = 1.0859
	new_data_grads_norm = 0.9161
	old_data_grads_norm = 1.3925
	sim_grads_norm_tr = -0.1023
-- Starting training on experience 219 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4113
	data_grads_norm = 1.7109
	new_data_grads_norm = 2.8500
	old_data_grads_norm = 1.7904
	sim_grads_norm_tr = 0.0178
-- Starting training on experience 220 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1831
	data_grads_norm = 0.6951
	new_data_grads_norm = 1.1593
	old_data_grads_norm = 0.9965
	sim_grads_norm_tr = 0.0893
-- Starting training on experience 221 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1227
	data_grads_norm = 0.5813
	new_data_grads_norm = 0.7389
	old_data_grads_norm = 0.8390
	sim_grads_norm_tr = 0.3257
-- Starting training on experience 222 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3101
	data_grads_norm = 0.9465
	new_data_grads_norm = 1.1997
	old_data_grads_norm = 1.3382
	sim_grads_norm_tr = 0.1849
-- Starting training on experience 223 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2482
	data_grads_norm = 1.0606
	new_data_grads_norm = 1.4969
	old_data_grads_norm = 1.2280
	sim_grads_norm_tr = 0.3434
-- Starting training on experience 224 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7168
	data_grads_norm = 2.1238
	new_data_grads_norm = 2.8887
	old_data_grads_norm = 2.8697
	sim_grads_norm_tr = 0.3690
-- Starting training on experience 225 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2281
	data_grads_norm = 0.8111
	new_data_grads_norm = 0.7481
	old_data_grads_norm = 1.2924
	sim_grads_norm_tr = 0.0411
-- Starting training on experience 226 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2535
	data_grads_norm = 1.1462
	new_data_grads_norm = 0.8796
	old_data_grads_norm = 2.3882
	sim_grads_norm_tr = -0.0386
-- Starting training on experience 227 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1752
	data_grads_norm = 0.7968
	new_data_grads_norm = 2.2338
	old_data_grads_norm = 3.1578
	sim_grads_norm_tr = -0.0798
-- Starting training on experience 228 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2343
	data_grads_norm = 1.6269
	new_data_grads_norm = 3.4514
	old_data_grads_norm = 1.1845
	sim_grads_norm_tr = -0.1006
-- Starting training on experience 229 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3900
	data_grads_norm = 1.5800
	new_data_grads_norm = 1.8736
	old_data_grads_norm = 1.8601
	sim_grads_norm_tr = 0.1410
-- Starting training on experience 230 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.5562
	data_grads_norm = 1.7031
	new_data_grads_norm = 1.2775
	old_data_grads_norm = 7.0017
	sim_grads_norm_tr = -0.1442
-- Starting training on experience 231 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2188
	data_grads_norm = 1.0192
	new_data_grads_norm = 1.1333
	old_data_grads_norm = 1.0993
	sim_grads_norm_tr = 0.6799
-- Starting training on experience 232 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3410
	data_grads_norm = 0.9284
	new_data_grads_norm = 0.9581
	old_data_grads_norm = 1.6574
	sim_grads_norm_tr = -0.0233
-- Starting training on experience 233 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.6698
	data_grads_norm = 3.3430
	new_data_grads_norm = 1.0646
	old_data_grads_norm = 5.8187
	sim_grads_norm_tr = -0.1940
-- Starting training on experience 234 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4802
	data_grads_norm = 1.6352
	new_data_grads_norm = 1.2144
	old_data_grads_norm = 4.6630
	sim_grads_norm_tr = -0.4402
-- Starting training on experience 235 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3793
	data_grads_norm = 1.3651
	new_data_grads_norm = 2.0931
	old_data_grads_norm = 1.2099
	sim_grads_norm_tr = 0.2425
-- Starting training on experience 236 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4251
	data_grads_norm = 2.6423
	new_data_grads_norm = 1.6012
	old_data_grads_norm = 3.9489
	sim_grads_norm_tr = 0.3450
-- Starting training on experience 237 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3428
	data_grads_norm = 1.3946
	new_data_grads_norm = 1.6799
	old_data_grads_norm = 3.3181
	sim_grads_norm_tr = -0.0540
-- Starting training on experience 238 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3458
	data_grads_norm = 1.0331
	new_data_grads_norm = 2.5682
	old_data_grads_norm = 1.7228
	sim_grads_norm_tr = -0.4006
-- Starting training on experience 239 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4813
	data_grads_norm = 2.4768
	new_data_grads_norm = 2.8261
	old_data_grads_norm = 2.8257
	sim_grads_norm_tr = 0.5832
-- Starting training on experience 240 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3825
	data_grads_norm = 1.6387
	new_data_grads_norm = 1.8089
	old_data_grads_norm = 1.7140
	sim_grads_norm_tr = 0.6837
-- Starting training on experience 241 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1930
	data_grads_norm = 0.6928
	new_data_grads_norm = 0.9469
	old_data_grads_norm = 0.8432
	sim_grads_norm_tr = 0.2892
-- Starting training on experience 242 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2004
	data_grads_norm = 0.8746
	new_data_grads_norm = 1.2286
	old_data_grads_norm = 0.8465
	sim_grads_norm_tr = 0.1420
-- Starting training on experience 243 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2599
	data_grads_norm = 1.0673
	new_data_grads_norm = 2.5600
	old_data_grads_norm = 1.8390
	sim_grads_norm_tr = -0.4340
-- Starting training on experience 244 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2004
	data_grads_norm = 0.7847
	new_data_grads_norm = 0.7711
	old_data_grads_norm = 1.4953
	sim_grads_norm_tr = 0.0086
-- Starting training on experience 245 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4062
	data_grads_norm = 1.6365
	new_data_grads_norm = 3.9547
	old_data_grads_norm = 1.1499
	sim_grads_norm_tr = 0.0850
-- Starting training on experience 246 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4165
	data_grads_norm = 2.7724
	new_data_grads_norm = 1.7135
	old_data_grads_norm = 5.4793
	sim_grads_norm_tr = -0.3339
-- Starting training on experience 247 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.5003
	data_grads_norm = 3.2611
	new_data_grads_norm = 3.3879
	old_data_grads_norm = 3.6930
	sim_grads_norm_tr = 0.8328
-- Starting training on experience 248 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2022
	data_grads_norm = 0.8101
	new_data_grads_norm = 1.9894
	old_data_grads_norm = 1.4747
	sim_grads_norm_tr = -0.2717
-- Starting training on experience 249 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3133
	data_grads_norm = 1.4895
	new_data_grads_norm = 2.8098
	old_data_grads_norm = 2.8947
	sim_grads_norm_tr = -0.1492
-- Starting training on experience 250 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1475
	data_grads_norm = 0.6422
	new_data_grads_norm = 0.8954
	old_data_grads_norm = 0.7734
	sim_grads_norm_tr = 0.1643
-- Starting training on experience 251 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1882
	data_grads_norm = 1.0030
	new_data_grads_norm = 1.0878
	old_data_grads_norm = 1.3041
	sim_grads_norm_tr = 0.4189
-- Starting training on experience 252 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3257
	data_grads_norm = 2.6640
	new_data_grads_norm = 2.3423
	old_data_grads_norm = 3.4242
	sim_grads_norm_tr = -0.0622
-- Starting training on experience 253 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1051
	data_grads_norm = 0.6048
	new_data_grads_norm = 0.8785
	old_data_grads_norm = 0.6465
	sim_grads_norm_tr = 0.2073
-- Starting training on experience 254 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0460
	data_grads_norm = 0.3655
	new_data_grads_norm = 0.2670
	old_data_grads_norm = 0.5641
	sim_grads_norm_tr = 0.3580
-- Starting training on experience 255 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2408
	data_grads_norm = 1.6403
	new_data_grads_norm = 2.2251
	old_data_grads_norm = 1.5326
	sim_grads_norm_tr = 0.1713
-- Starting training on experience 256 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1113
	data_grads_norm = 1.1203
	new_data_grads_norm = 0.4799
	old_data_grads_norm = 1.3670
	sim_grads_norm_tr = 0.1021
-- Starting training on experience 257 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2770
	data_grads_norm = 1.6867
	new_data_grads_norm = 1.0996
	old_data_grads_norm = 2.1893
	sim_grads_norm_tr = -0.0082
-- Starting training on experience 258 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1034
	data_grads_norm = 0.7090
	new_data_grads_norm = 1.3691
	old_data_grads_norm = 0.5019
	sim_grads_norm_tr = 0.3387
-- Starting training on experience 259 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3166
	data_grads_norm = 1.7581
	new_data_grads_norm = 1.8776
	old_data_grads_norm = 2.0755
	sim_grads_norm_tr = 0.5104
-- Starting training on experience 260 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3992
	data_grads_norm = 2.9789
	new_data_grads_norm = 7.2806
	old_data_grads_norm = 0.8920
	sim_grads_norm_tr = 0.2283
-- Starting training on experience 261 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1524
	data_grads_norm = 0.9645
	new_data_grads_norm = 0.4651
	old_data_grads_norm = 1.8248
	sim_grads_norm_tr = -0.1022
-- Starting training on experience 262 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2100
	data_grads_norm = 1.2982
	new_data_grads_norm = 1.0638
	old_data_grads_norm = 2.1768
	sim_grads_norm_tr = 0.2506
-- Starting training on experience 263 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4417
	data_grads_norm = 2.3533
	new_data_grads_norm = 2.4265
	old_data_grads_norm = 4.2579
	sim_grads_norm_tr = 0.0053
-- Starting training on experience 264 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3150
	data_grads_norm = 3.4792
	new_data_grads_norm = 5.1911
	old_data_grads_norm = 1.8201
	sim_grads_norm_tr = 0.1719
-- Starting training on experience 265 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3468
	data_grads_norm = 3.3275
	new_data_grads_norm = 5.2548
	old_data_grads_norm = 1.7836
	sim_grads_norm_tr = 0.3755
-- Starting training on experience 266 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4241
	data_grads_norm = 2.5671
	new_data_grads_norm = 4.1903
	old_data_grads_norm = 2.4011
	sim_grads_norm_tr = 0.1173
-- Starting training on experience 267 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.5824
	data_grads_norm = 4.0745
	new_data_grads_norm = 3.5105
	old_data_grads_norm = 6.5642
	sim_grads_norm_tr = -0.0339
-- Starting training on experience 268 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3429
	data_grads_norm = 3.1791
	new_data_grads_norm = 2.9950
	old_data_grads_norm = 3.7873
	sim_grads_norm_tr = 0.2556
-- Starting training on experience 269 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4490
	data_grads_norm = 2.0244
	new_data_grads_norm = 5.6927
	old_data_grads_norm = 2.9368
	sim_grads_norm_tr = -0.2322
-- Starting training on experience 270 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4820
	data_grads_norm = 4.4763
	new_data_grads_norm = 4.4459
	old_data_grads_norm = 4.8033
	sim_grads_norm_tr = 0.9059
-- Starting training on experience 271 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2361
	data_grads_norm = 1.1305
	new_data_grads_norm = 3.3680
	old_data_grads_norm = 1.1669
	sim_grads_norm_tr = 0.1104
-- Starting training on experience 272 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1624
	data_grads_norm = 0.9929
	new_data_grads_norm = 1.9220
	old_data_grads_norm = 1.7927
	sim_grads_norm_tr = 0.0062
-- Starting training on experience 273 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1504
	data_grads_norm = 1.2382
	new_data_grads_norm = 1.3429
	old_data_grads_norm = 2.0394
	sim_grads_norm_tr = 0.2392
-- Starting training on experience 274 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1776
	data_grads_norm = 1.3941
	new_data_grads_norm = 1.9514
	old_data_grads_norm = 1.3853
	sim_grads_norm_tr = 0.4146
-- Starting training on experience 275 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.6716
	data_grads_norm = 6.5600
	new_data_grads_norm = 8.5171
	old_data_grads_norm = 5.8651
	sim_grads_norm_tr = 0.5642
-- Starting training on experience 276 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7367
	data_grads_norm = 7.3173
	new_data_grads_norm = 13.7858
	old_data_grads_norm = 1.9024
	sim_grads_norm_tr = 0.3031
-- Starting training on experience 277 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9780
	data_grads_norm = 6.5913
	new_data_grads_norm = 8.2713
	old_data_grads_norm = 6.0421
	sim_grads_norm_tr = 0.4232
-- Starting training on experience 278 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7803
	data_grads_norm = 5.0898
	new_data_grads_norm = 6.3288
	old_data_grads_norm = 4.9425
	sim_grads_norm_tr = 0.3397
-- Starting training on experience 279 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4165
	data_grads_norm = 2.5565
	new_data_grads_norm = 3.6590
	old_data_grads_norm = 3.9039
	sim_grads_norm_tr = 0.2451
-- Starting training on experience 280 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1083
	data_grads_norm = 0.7876
	new_data_grads_norm = 0.7489
	old_data_grads_norm = 1.3200
	sim_grads_norm_tr = 0.1236
-- Starting training on experience 281 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.6083
	data_grads_norm = 6.5989
	new_data_grads_norm = 1.6928
	old_data_grads_norm = 9.7219
	sim_grads_norm_tr = 0.0940
-- Starting training on experience 282 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3876
	data_grads_norm = 2.5583
	new_data_grads_norm = 3.6068
	old_data_grads_norm = 3.9364
	sim_grads_norm_tr = 0.1200
-- Starting training on experience 283 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2789
	data_grads_norm = 1.3798
	new_data_grads_norm = 1.5483
	old_data_grads_norm = 1.5192
	sim_grads_norm_tr = 0.6350
-- Starting training on experience 284 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2880
	data_grads_norm = 1.0985
	new_data_grads_norm = 1.6940
	old_data_grads_norm = 1.2916
	sim_grads_norm_tr = 0.1765
-- Starting training on experience 285 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3647
	data_grads_norm = 1.6405
	new_data_grads_norm = 3.3610
	old_data_grads_norm = 3.5124
	sim_grads_norm_tr = -0.1415
-- Starting training on experience 286 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1971
	data_grads_norm = 0.6722
	new_data_grads_norm = 1.4335
	old_data_grads_norm = 0.9183
	sim_grads_norm_tr = -0.1621
-- Starting training on experience 287 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.5430
	data_grads_norm = 3.4514
	new_data_grads_norm = 1.7869
	old_data_grads_norm = 5.0766
	sim_grads_norm_tr = 0.2246
-- Starting training on experience 288 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3622
	data_grads_norm = 1.7251
	new_data_grads_norm = 2.6996
	old_data_grads_norm = 1.2711
	sim_grads_norm_tr = 0.2736
-- Starting training on experience 289 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2905
	data_grads_norm = 1.7742
	new_data_grads_norm = 2.9945
	old_data_grads_norm = 2.0106
	sim_grads_norm_tr = -0.2949
-- Starting training on experience 290 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2060
	data_grads_norm = 0.9196
	new_data_grads_norm = 1.1487
	old_data_grads_norm = 1.4251
	sim_grads_norm_tr = 0.1226
-- Starting training on experience 291 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.5541
	data_grads_norm = 2.6244
	new_data_grads_norm = 2.5965
	old_data_grads_norm = 4.0158
	sim_grads_norm_tr = 0.2884
-- Starting training on experience 292 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.6307
	data_grads_norm = 3.1570
	new_data_grads_norm = 4.4196
	old_data_grads_norm = 3.5341
	sim_grads_norm_tr = 0.3562
-- Starting training on experience 293 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.5909
	data_grads_norm = 2.9277
	new_data_grads_norm = 3.3387
	old_data_grads_norm = 3.9040
	sim_grads_norm_tr = 0.4681
-- Starting training on experience 294 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3490
	data_grads_norm = 1.6643
	new_data_grads_norm = 1.3621
	old_data_grads_norm = 3.0845
	sim_grads_norm_tr = -0.2917
-- Starting training on experience 295 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2691
	data_grads_norm = 1.0977
	new_data_grads_norm = 1.5663
	old_data_grads_norm = 1.2580
	sim_grads_norm_tr = 0.0881
-- Starting training on experience 296 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4264
	data_grads_norm = 1.3077
	new_data_grads_norm = 2.7288
	old_data_grads_norm = 1.4252
	sim_grads_norm_tr = -0.0783
-- Starting training on experience 297 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2985
	data_grads_norm = 1.9256
	new_data_grads_norm = 3.0477
	old_data_grads_norm = 4.9512
	sim_grads_norm_tr = -0.2000
-- Starting training on experience 298 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2909
	data_grads_norm = 2.6142
	new_data_grads_norm = 3.7408
	old_data_grads_norm = 1.7167
	sim_grads_norm_tr = 0.7718
-- Starting training on experience 299 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2968
	data_grads_norm = 1.6971
	new_data_grads_norm = 1.6318
	old_data_grads_norm = 1.8982
	sim_grads_norm_tr = 0.5240
-- Starting training on experience 300 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2769
	data_grads_norm = 1.9660
	new_data_grads_norm = 1.2835
	old_data_grads_norm = 3.1687
	sim_grads_norm_tr = 0.4784
-- Starting training on experience 301 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2003
	data_grads_norm = 1.3540
	new_data_grads_norm = 1.7244
	old_data_grads_norm = 2.1438
	sim_grads_norm_tr = -0.0115
-- Starting training on experience 302 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1602
	data_grads_norm = 0.6832
	new_data_grads_norm = 0.9630
	old_data_grads_norm = 1.2131
	sim_grads_norm_tr = -0.1160
-- Starting training on experience 303 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3220
	data_grads_norm = 2.0686
	new_data_grads_norm = 1.7848
	old_data_grads_norm = 5.9976
	sim_grads_norm_tr = 0.3013
-- Starting training on experience 304 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3165
	data_grads_norm = 1.7536
	new_data_grads_norm = 3.6865
	old_data_grads_norm = 1.1455
	sim_grads_norm_tr = 0.3217
-- Starting training on experience 305 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.5612
	data_grads_norm = 2.1276
	new_data_grads_norm = 3.4373
	old_data_grads_norm = 2.9556
	sim_grads_norm_tr = 0.1732
-- Starting training on experience 306 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3140
	data_grads_norm = 1.6403
	new_data_grads_norm = 1.7706
	old_data_grads_norm = 1.9471
	sim_grads_norm_tr = 0.3464
-- Starting training on experience 307 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.5690
	data_grads_norm = 2.5222
	new_data_grads_norm = 2.2651
	old_data_grads_norm = 4.5634
	sim_grads_norm_tr = 0.3773
-- Starting training on experience 308 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1602
	data_grads_norm = 0.7328
	new_data_grads_norm = 0.6137
	old_data_grads_norm = 0.9345
	sim_grads_norm_tr = 0.2252
-- Starting training on experience 309 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2287
	data_grads_norm = 1.2637
	new_data_grads_norm = 1.0439
	old_data_grads_norm = 1.1848
	sim_grads_norm_tr = 0.1704
-- Starting training on experience 310 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2844
	data_grads_norm = 1.1256
	new_data_grads_norm = 0.8438
	old_data_grads_norm = 3.4950
	sim_grads_norm_tr = -0.1591
-- Starting training on experience 311 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2099
	data_grads_norm = 0.9761
	new_data_grads_norm = 1.1513
	old_data_grads_norm = 1.3175
	sim_grads_norm_tr = -0.2078
-- Starting training on experience 312 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2857
	data_grads_norm = 1.0288
	new_data_grads_norm = 2.2521
	old_data_grads_norm = 0.9911
	sim_grads_norm_tr = 0.3402
-- Starting training on experience 313 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4121
	data_grads_norm = 1.5252
	new_data_grads_norm = 3.4917
	old_data_grads_norm = 0.7251
	sim_grads_norm_tr = -0.1115
-- Starting training on experience 314 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1778
	data_grads_norm = 0.7630
	new_data_grads_norm = 0.8566
	old_data_grads_norm = 0.9552
	sim_grads_norm_tr = 0.4067
-- Starting training on experience 315 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3949
	data_grads_norm = 1.9429
	new_data_grads_norm = 2.6919
	old_data_grads_norm = 2.1326
	sim_grads_norm_tr = 0.3001
-- Starting training on experience 316 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1156
	data_grads_norm = 0.6193
	new_data_grads_norm = 0.8575
	old_data_grads_norm = 0.8050
	sim_grads_norm_tr = 0.1189
-- Starting training on experience 317 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3532
	data_grads_norm = 2.4670
	new_data_grads_norm = 4.9928
	old_data_grads_norm = 2.7559
	sim_grads_norm_tr = -0.2085
-- Starting training on experience 318 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3379
	data_grads_norm = 1.7413
	new_data_grads_norm = 3.5897
	old_data_grads_norm = 0.7260
	sim_grads_norm_tr = -0.3171
-- Starting training on experience 319 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3025
	data_grads_norm = 1.8952
	new_data_grads_norm = 1.2451
	old_data_grads_norm = 2.6470
	sim_grads_norm_tr = 0.2911
-- Starting training on experience 320 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1225
	data_grads_norm = 0.6350
	new_data_grads_norm = 1.0171
	old_data_grads_norm = 1.1391
	sim_grads_norm_tr = -0.3540
-- Starting training on experience 321 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1485
	data_grads_norm = 0.7167
	new_data_grads_norm = 0.6541
	old_data_grads_norm = 1.4957
	sim_grads_norm_tr = -0.2841
-- Starting training on experience 322 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.5276
	data_grads_norm = 1.9816
	new_data_grads_norm = 4.5453
	old_data_grads_norm = 1.8413
	sim_grads_norm_tr = -0.3319
-- Starting training on experience 323 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1971
	data_grads_norm = 1.0663
	new_data_grads_norm = 1.1821
	old_data_grads_norm = 1.3987
	sim_grads_norm_tr = 0.4539
-- Starting training on experience 324 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3287
	data_grads_norm = 2.5324
	new_data_grads_norm = 2.1468
	old_data_grads_norm = 4.6750
	sim_grads_norm_tr = -0.0242
-- Starting training on experience 325 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1236
	data_grads_norm = 0.7176
	new_data_grads_norm = 0.7179
	old_data_grads_norm = 0.9756
	sim_grads_norm_tr = 0.3679
-- Starting training on experience 326 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1910
	data_grads_norm = 1.1128
	new_data_grads_norm = 5.7600
	old_data_grads_norm = 1.8910
	sim_grads_norm_tr = -0.3602
-- Starting training on experience 327 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2854
	data_grads_norm = 1.6180
	new_data_grads_norm = 2.9244
	old_data_grads_norm = 2.2287
	sim_grads_norm_tr = -0.0424
-- Starting training on experience 328 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1519
	data_grads_norm = 1.0270
	new_data_grads_norm = 1.2045
	old_data_grads_norm = 2.0812
	sim_grads_norm_tr = -0.2427
-- Starting training on experience 329 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1717
	data_grads_norm = 1.4550
	new_data_grads_norm = 0.7983
	old_data_grads_norm = 3.1543
	sim_grads_norm_tr = 0.1810
-- Starting training on experience 330 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2797
	data_grads_norm = 1.7271
	new_data_grads_norm = 1.9858
	old_data_grads_norm = 2.4151
	sim_grads_norm_tr = 0.1957
-- Starting training on experience 331 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1750
	data_grads_norm = 1.3177
	new_data_grads_norm = 0.8953
	old_data_grads_norm = 2.4769
	sim_grads_norm_tr = -0.2728
-- Starting training on experience 332 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0963
	data_grads_norm = 0.7580
	new_data_grads_norm = 0.7757
	old_data_grads_norm = 1.0420
	sim_grads_norm_tr = 0.2230
-- Starting training on experience 333 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2936
	data_grads_norm = 1.9761
	new_data_grads_norm = 3.0503
	old_data_grads_norm = 2.1105
	sim_grads_norm_tr = 0.1752
-- Starting training on experience 334 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2175
	data_grads_norm = 1.1872
	new_data_grads_norm = 1.9905
	old_data_grads_norm = 1.3364
	sim_grads_norm_tr = 0.0662
-- Starting training on experience 335 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2621
	data_grads_norm = 1.3962
	new_data_grads_norm = 1.2016
	old_data_grads_norm = 2.3780
	sim_grads_norm_tr = 0.1377
-- Starting training on experience 336 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4550
	data_grads_norm = 2.4473
	new_data_grads_norm = 3.2013
	old_data_grads_norm = 3.2279
	sim_grads_norm_tr = 0.1404
-- Starting training on experience 337 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4091
	data_grads_norm = 1.9245
	new_data_grads_norm = 2.9354
	old_data_grads_norm = 2.4394
	sim_grads_norm_tr = -0.0967
-- Starting training on experience 338 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3385
	data_grads_norm = 1.3704
	new_data_grads_norm = 2.1231
	old_data_grads_norm = 0.8623
	sim_grads_norm_tr = 0.3000
-- Starting training on experience 339 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3846
	data_grads_norm = 2.4501
	new_data_grads_norm = 2.0858
	old_data_grads_norm = 6.0294
	sim_grads_norm_tr = -0.0616
-- Starting training on experience 340 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0724
	data_grads_norm = 4.7682
	new_data_grads_norm = 6.5480
	old_data_grads_norm = 4.1351
	sim_grads_norm_tr = 0.7100
-- Starting training on experience 341 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4124
	data_grads_norm = 1.8885
	new_data_grads_norm = 3.9571
	old_data_grads_norm = 0.8522
	sim_grads_norm_tr = -0.1989
-- Starting training on experience 342 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2434
	data_grads_norm = 0.9013
	new_data_grads_norm = 1.0908
	old_data_grads_norm = 3.0590
	sim_grads_norm_tr = -0.2476
-- Starting training on experience 343 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.6823
	data_grads_norm = 4.1629
	new_data_grads_norm = 2.9967
	old_data_grads_norm = 7.1138
	sim_grads_norm_tr = 0.4525
-- Starting training on experience 344 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2644
	data_grads_norm = 1.4181
	new_data_grads_norm = 2.0768
	old_data_grads_norm = 2.5529
	sim_grads_norm_tr = -0.2589
-- Starting training on experience 345 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2008
	data_grads_norm = 1.5487
	new_data_grads_norm = 2.4175
	old_data_grads_norm = 1.0925
	sim_grads_norm_tr = 0.4560
-- Starting training on experience 346 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2311
	data_grads_norm = 1.0771
	new_data_grads_norm = 1.2720
	old_data_grads_norm = 1.1193
	sim_grads_norm_tr = 0.4318
-- Starting training on experience 347 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2524
	data_grads_norm = 1.0565
	new_data_grads_norm = 1.8637
	old_data_grads_norm = 1.7255
	sim_grads_norm_tr = -0.2961
-- Starting training on experience 348 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4770
	data_grads_norm = 2.1582
	new_data_grads_norm = 2.7190
	old_data_grads_norm = 3.2562
	sim_grads_norm_tr = 0.2207
-- Starting training on experience 349 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1917
	data_grads_norm = 1.2260
	new_data_grads_norm = 1.4797
	old_data_grads_norm = 3.3741
	sim_grads_norm_tr = -0.2949
-- Starting training on experience 350 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3982
	data_grads_norm = 2.2402
	new_data_grads_norm = 3.7139
	old_data_grads_norm = 1.2226
	sim_grads_norm_tr = 0.0192
-- Starting training on experience 351 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4997
	data_grads_norm = 2.5512
	new_data_grads_norm = 2.5610
	old_data_grads_norm = 3.3115
	sim_grads_norm_tr = 0.6646
-- Starting training on experience 352 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2212
	data_grads_norm = 1.1768
	new_data_grads_norm = 1.1756
	old_data_grads_norm = 3.4064
	sim_grads_norm_tr = -0.3589
-- Starting training on experience 353 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2875
	data_grads_norm = 1.2958
	new_data_grads_norm = 1.8493
	old_data_grads_norm = 1.1496
	sim_grads_norm_tr = 0.4307
-- Starting training on experience 354 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8176
	data_grads_norm = 2.7634
	new_data_grads_norm = 2.1174
	old_data_grads_norm = 5.0390
	sim_grads_norm_tr = 0.2023
-- Starting training on experience 355 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2875
	data_grads_norm = 0.8097
	new_data_grads_norm = 1.2263
	old_data_grads_norm = 1.5042
	sim_grads_norm_tr = -0.1976
-- Starting training on experience 356 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2425
	data_grads_norm = 1.0744
	new_data_grads_norm = 1.2089
	old_data_grads_norm = 1.0864
	sim_grads_norm_tr = 0.6366
-- Starting training on experience 357 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1834
	data_grads_norm = 0.6235
	new_data_grads_norm = 1.0315
	old_data_grads_norm = 0.7332
	sim_grads_norm_tr = -0.0803
-- Starting training on experience 358 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1956
	data_grads_norm = 0.7019
	new_data_grads_norm = 0.9469
	old_data_grads_norm = 0.9973
	sim_grads_norm_tr = 0.3692
-- Starting training on experience 359 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1516
	data_grads_norm = 0.7383
	new_data_grads_norm = 1.2456
	old_data_grads_norm = 0.8690
	sim_grads_norm_tr = 0.0923
-- Starting training on experience 360 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.5613
	data_grads_norm = 2.4780
	new_data_grads_norm = 5.1124
	old_data_grads_norm = 2.1977
	sim_grads_norm_tr = 0.0406
-- Starting training on experience 361 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1113
	data_grads_norm = 0.8679
	new_data_grads_norm = 7.3099
	old_data_grads_norm = 1.2198
	sim_grads_norm_tr = -0.1046
-- Starting training on experience 362 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4404
	data_grads_norm = 2.2790
	new_data_grads_norm = 1.5800
	old_data_grads_norm = 4.3847
	sim_grads_norm_tr = -0.1238
-- Starting training on experience 363 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2788
	data_grads_norm = 0.9181
	new_data_grads_norm = 0.9047
	old_data_grads_norm = 4.0563
	sim_grads_norm_tr = -0.4149
-- Starting training on experience 364 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2024
	data_grads_norm = 1.0528
	new_data_grads_norm = 2.4286
	old_data_grads_norm = 0.9371
	sim_grads_norm_tr = 0.3717
-- Starting training on experience 365 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3240
	data_grads_norm = 3.0580
	new_data_grads_norm = 3.0034
	old_data_grads_norm = 3.4679
	sim_grads_norm_tr = 0.5614
-- Starting training on experience 366 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1298
	data_grads_norm = 0.9067
	new_data_grads_norm = 1.7789
	old_data_grads_norm = 0.9450
	sim_grads_norm_tr = -0.0049
-- Starting training on experience 367 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4561
	data_grads_norm = 2.4990
	new_data_grads_norm = 1.9932
	old_data_grads_norm = 3.2495
	sim_grads_norm_tr = 0.1578
-- Starting training on experience 368 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3200
	data_grads_norm = 1.7335
	new_data_grads_norm = 4.2090
	old_data_grads_norm = 2.4532
	sim_grads_norm_tr = -0.1991
-- Starting training on experience 369 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3006
	data_grads_norm = 2.4091
	new_data_grads_norm = 1.0079
	old_data_grads_norm = 5.2939
	sim_grads_norm_tr = 0.5158
-- Starting training on experience 370 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1784
	data_grads_norm = 0.9840
	new_data_grads_norm = 1.8800
	old_data_grads_norm = 0.8849
	sim_grads_norm_tr = 0.1777
-- Starting training on experience 371 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2514
	data_grads_norm = 1.2512
	new_data_grads_norm = 2.2262
	old_data_grads_norm = 0.7891
	sim_grads_norm_tr = 0.0513
-- Starting training on experience 372 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2016
	data_grads_norm = 1.3155
	new_data_grads_norm = 2.1540
	old_data_grads_norm = 0.8064
	sim_grads_norm_tr = 0.1412
-- Starting training on experience 373 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1467
	data_grads_norm = 0.7984
	new_data_grads_norm = 1.8167
	old_data_grads_norm = 0.5566
	sim_grads_norm_tr = 0.1686
-- Starting training on experience 374 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0691
	data_grads_norm = 0.5227
	new_data_grads_norm = 0.7664
	old_data_grads_norm = 1.8712
	sim_grads_norm_tr = -0.0701
-- Starting training on experience 375 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2225
	data_grads_norm = 1.2475
	new_data_grads_norm = 0.7696
	old_data_grads_norm = 2.4293
	sim_grads_norm_tr = 0.1490
-- Starting training on experience 376 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1118
	data_grads_norm = 0.7939
	new_data_grads_norm = 1.5180
	old_data_grads_norm = 0.5921
	sim_grads_norm_tr = 0.2219
-- Starting training on experience 377 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1896
	data_grads_norm = 0.9862
	new_data_grads_norm = 1.3282
	old_data_grads_norm = 1.6723
	sim_grads_norm_tr = -0.1077
-- Starting training on experience 378 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3340
	data_grads_norm = 1.5625
	new_data_grads_norm = 1.0758
	old_data_grads_norm = 2.8262
	sim_grads_norm_tr = -0.1226
-- Starting training on experience 379 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1063
	data_grads_norm = 0.5002
	new_data_grads_norm = 1.0220
	old_data_grads_norm = 0.8967
	sim_grads_norm_tr = -0.4382
-- Starting training on experience 380 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2776
	data_grads_norm = 0.8398
	new_data_grads_norm = 2.6757
	old_data_grads_norm = 1.1549
	sim_grads_norm_tr = -0.3725
-- Starting training on experience 381 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1031
	data_grads_norm = 0.6268
	new_data_grads_norm = 1.3713
	old_data_grads_norm = 0.8195
	sim_grads_norm_tr = -0.1963
-- Starting training on experience 382 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2949
	data_grads_norm = 1.5979
	new_data_grads_norm = 3.2136
	old_data_grads_norm = 1.9432
	sim_grads_norm_tr = -0.1827
-- Starting training on experience 383 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1656
	data_grads_norm = 0.7412
	new_data_grads_norm = 1.7725
	old_data_grads_norm = 0.9636
	sim_grads_norm_tr = -0.1926
-- Starting training on experience 384 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4334
	data_grads_norm = 2.0705
	new_data_grads_norm = 0.9358
	old_data_grads_norm = 4.4907
	sim_grads_norm_tr = -0.0007
-- Starting training on experience 385 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4205
	data_grads_norm = 1.9189
	new_data_grads_norm = 2.9275
	old_data_grads_norm = 1.8580
	sim_grads_norm_tr = 0.3524
-- Starting training on experience 386 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1540
	data_grads_norm = 0.6194
	new_data_grads_norm = 1.3071
	old_data_grads_norm = 1.1803
	sim_grads_norm_tr = -0.2121
-- Starting training on experience 387 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2358
	data_grads_norm = 0.7561
	new_data_grads_norm = 0.7220
	old_data_grads_norm = 1.4196
	sim_grads_norm_tr = -0.3303
-- Starting training on experience 388 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1480
	data_grads_norm = 0.7103
	new_data_grads_norm = 0.9211
	old_data_grads_norm = 1.7533
	sim_grads_norm_tr = -0.3713
-- Starting training on experience 389 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1751
	data_grads_norm = 0.9274
	new_data_grads_norm = 0.8360
	old_data_grads_norm = 1.5022
	sim_grads_norm_tr = -0.0336
-- Starting training on experience 390 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1464
	data_grads_norm = 0.7360
	new_data_grads_norm = 0.7598
	old_data_grads_norm = 1.3317
	sim_grads_norm_tr = -0.3150
-- Starting training on experience 391 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1998
	data_grads_norm = 0.8903
	new_data_grads_norm = 1.5431
	old_data_grads_norm = 1.7870
	sim_grads_norm_tr = -0.0801
-- Starting training on experience 392 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1779
	data_grads_norm = 0.9236
	new_data_grads_norm = 1.6679
	old_data_grads_norm = 0.8845
	sim_grads_norm_tr = 0.3469
-- Starting training on experience 393 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1814
	data_grads_norm = 1.2478
	new_data_grads_norm = 1.3119
	old_data_grads_norm = 1.0795
	sim_grads_norm_tr = 0.1985
-- Starting training on experience 394 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2432
	data_grads_norm = 0.9727
	new_data_grads_norm = 1.1683
	old_data_grads_norm = 2.8058
	sim_grads_norm_tr = -0.1229
-- Starting training on experience 395 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3280
	data_grads_norm = 1.4071
	new_data_grads_norm = 1.1240
	old_data_grads_norm = 2.2699
	sim_grads_norm_tr = 0.2203
-- Starting training on experience 396 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4628
	data_grads_norm = 2.3371
	new_data_grads_norm = 4.0781
	old_data_grads_norm = 1.0194
	sim_grads_norm_tr = 0.3100
-- Starting training on experience 397 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1916
	data_grads_norm = 1.1955
	new_data_grads_norm = 3.6113
	old_data_grads_norm = 1.0898
	sim_grads_norm_tr = -0.2393
-- Starting training on experience 398 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2716
	data_grads_norm = 1.5420
	new_data_grads_norm = 2.0618
	old_data_grads_norm = 1.4649
	sim_grads_norm_tr = 0.3752
-- Starting training on experience 399 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3111
	data_grads_norm = 1.4743
	new_data_grads_norm = 3.2757
	old_data_grads_norm = 1.5683
	sim_grads_norm_tr = 0.2888
-- Starting training on experience 400 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1109
	data_grads_norm = 0.6143
	new_data_grads_norm = 0.7403
	old_data_grads_norm = 1.0212
	sim_grads_norm_tr = 0.2402
-- Starting training on experience 401 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2224
	data_grads_norm = 1.2075
	new_data_grads_norm = 2.8859
	old_data_grads_norm = 1.8109
	sim_grads_norm_tr = -0.3646
-- Starting training on experience 402 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1949
	data_grads_norm = 0.9880
	new_data_grads_norm = 0.6703
	old_data_grads_norm = 2.1274
	sim_grads_norm_tr = 0.1179
-- Starting training on experience 403 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1687
	data_grads_norm = 0.6262
	new_data_grads_norm = 1.5925
	old_data_grads_norm = 0.8601
	sim_grads_norm_tr = -0.3680
-- Starting training on experience 404 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1666
	data_grads_norm = 0.7469
	new_data_grads_norm = 2.7907
	old_data_grads_norm = 2.5281
	sim_grads_norm_tr = -0.2211
-- Starting training on experience 405 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3621
	data_grads_norm = 1.9884
	new_data_grads_norm = 4.6478
	old_data_grads_norm = 0.9527
	sim_grads_norm_tr = 0.2286
-- Starting training on experience 406 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1050
	data_grads_norm = 0.7602
	new_data_grads_norm = 0.9673
	old_data_grads_norm = 0.9730
	sim_grads_norm_tr = 0.2042
-- Starting training on experience 407 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3917
	data_grads_norm = 2.5872
	new_data_grads_norm = 2.7586
	old_data_grads_norm = 4.9062
	sim_grads_norm_tr = -0.0105
-- Starting training on experience 408 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1906
	data_grads_norm = 0.7012
	new_data_grads_norm = 1.3558
	old_data_grads_norm = 0.9091
	sim_grads_norm_tr = -0.3177
-- Starting training on experience 409 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4166
	data_grads_norm = 2.1495
	new_data_grads_norm = 6.1572
	old_data_grads_norm = 0.9772
	sim_grads_norm_tr = 0.1088
-- Starting training on experience 410 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2389
	data_grads_norm = 1.3781
	new_data_grads_norm = 2.1177
	old_data_grads_norm = 1.7612
	sim_grads_norm_tr = 0.0426
-- Starting training on experience 411 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2162
	data_grads_norm = 1.7787
	new_data_grads_norm = 4.5777
	old_data_grads_norm = 0.4714
	sim_grads_norm_tr = -0.1272
-- Starting training on experience 412 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4797
	data_grads_norm = 1.7502
	new_data_grads_norm = 3.7625
	old_data_grads_norm = 3.2239
	sim_grads_norm_tr = -0.0975
-- Starting training on experience 413 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.5420
	data_grads_norm = 3.0982
	new_data_grads_norm = 4.5373
	old_data_grads_norm = 1.7331
	sim_grads_norm_tr = 0.3087
-- Starting training on experience 414 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2216
	data_grads_norm = 1.1472
	new_data_grads_norm = 1.1038
	old_data_grads_norm = 2.0205
	sim_grads_norm_tr = 0.4483
-- Starting training on experience 415 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1340
	data_grads_norm = 0.8164
	new_data_grads_norm = 0.7438
	old_data_grads_norm = 1.4119
	sim_grads_norm_tr = -0.1006
-- Starting training on experience 416 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1661
	data_grads_norm = 0.9490
	new_data_grads_norm = 1.5833
	old_data_grads_norm = 4.1375
	sim_grads_norm_tr = -0.2690
-- Starting training on experience 417 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2192
	data_grads_norm = 1.4922
	new_data_grads_norm = 1.4045
	old_data_grads_norm = 2.9577
	sim_grads_norm_tr = -0.1566
-- Starting training on experience 418 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2173
	data_grads_norm = 1.0052
	new_data_grads_norm = 6.9833
	old_data_grads_norm = 1.6441
	sim_grads_norm_tr = -0.1707
-- Starting training on experience 419 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2413
	data_grads_norm = 1.8576
	new_data_grads_norm = 6.6550
	old_data_grads_norm = 0.8287
	sim_grads_norm_tr = -0.3404
-- Starting training on experience 420 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2384
	data_grads_norm = 1.4350
	new_data_grads_norm = 1.6645
	old_data_grads_norm = 1.1358
	sim_grads_norm_tr = 0.5145
-- Starting training on experience 421 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4911
	data_grads_norm = 1.8838
	new_data_grads_norm = 2.2190
	old_data_grads_norm = 3.0760
	sim_grads_norm_tr = 0.1022
-- Starting training on experience 422 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3471
	data_grads_norm = 1.8736
	new_data_grads_norm = 2.3351
	old_data_grads_norm = 1.7461
	sim_grads_norm_tr = 0.3215
-- Starting training on experience 423 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1388
	data_grads_norm = 0.8922
	new_data_grads_norm = 0.6379
	old_data_grads_norm = 1.6208
	sim_grads_norm_tr = 0.5574
-- Starting training on experience 424 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2158
	data_grads_norm = 1.1924
	new_data_grads_norm = 2.8562
	old_data_grads_norm = 8.1139
	sim_grads_norm_tr = -0.2461
-- Starting training on experience 425 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4628
	data_grads_norm = 1.4390
	new_data_grads_norm = 2.3100
	old_data_grads_norm = 1.7707
	sim_grads_norm_tr = -0.1549
-- Starting training on experience 426 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2716
	data_grads_norm = 1.5755
	new_data_grads_norm = 2.6720
	old_data_grads_norm = 7.4565
	sim_grads_norm_tr = 0.0558
-- Starting training on experience 427 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8767
	data_grads_norm = 3.8770
	new_data_grads_norm = 5.2160
	old_data_grads_norm = 3.7998
	sim_grads_norm_tr = 0.7095
-- Starting training on experience 428 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2789
	data_grads_norm = 1.2454
	new_data_grads_norm = 2.9944
	old_data_grads_norm = 1.6630
	sim_grads_norm_tr = 0.1307
-- Starting training on experience 429 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.6705
	data_grads_norm = 3.4693
	new_data_grads_norm = 4.8559
	old_data_grads_norm = 1.4315
	sim_grads_norm_tr = 0.0594
-- Starting training on experience 430 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3341
	data_grads_norm = 2.2109
	new_data_grads_norm = 2.9896
	old_data_grads_norm = 1.7002
	sim_grads_norm_tr = 0.3131
-- Starting training on experience 431 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4200
	data_grads_norm = 3.6965
	new_data_grads_norm = 4.0697
	old_data_grads_norm = 3.7652
	sim_grads_norm_tr = 0.7612
-- Starting training on experience 432 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2268
	data_grads_norm = 1.6794
	new_data_grads_norm = 0.7934
	old_data_grads_norm = 3.8644
	sim_grads_norm_tr = -0.0910
-- Starting training on experience 433 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3182
	data_grads_norm = 1.4217
	new_data_grads_norm = 2.0633
	old_data_grads_norm = 2.0033
	sim_grads_norm_tr = 0.4134
-- Starting training on experience 434 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4267
	data_grads_norm = 1.7140
	new_data_grads_norm = 1.2301
	old_data_grads_norm = 4.2152
	sim_grads_norm_tr = 0.1544
-- Starting training on experience 435 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2429
	data_grads_norm = 1.1943
	new_data_grads_norm = 1.6825
	old_data_grads_norm = 1.3030
	sim_grads_norm_tr = 0.3288
-- Starting training on experience 436 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2460
	data_grads_norm = 1.0036
	new_data_grads_norm = 1.9907
	old_data_grads_norm = 0.7271
	sim_grads_norm_tr = -0.0881
-- Starting training on experience 437 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3332
	data_grads_norm = 1.2994
	new_data_grads_norm = 1.9532
	old_data_grads_norm = 3.0871
	sim_grads_norm_tr = -0.2926
-- Starting training on experience 438 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2069
	data_grads_norm = 0.9541
	new_data_grads_norm = 1.5341
	old_data_grads_norm = 0.8626
	sim_grads_norm_tr = -0.0106
-- Starting training on experience 439 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2451
	data_grads_norm = 1.0710
	new_data_grads_norm = 3.2859
	old_data_grads_norm = 1.0605
	sim_grads_norm_tr = -0.3292
-- Starting training on experience 440 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1821
	data_grads_norm = 1.1397
	new_data_grads_norm = 1.9247
	old_data_grads_norm = 1.3572
	sim_grads_norm_tr = 0.2423
-- Starting training on experience 441 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1772
	data_grads_norm = 1.2490
	new_data_grads_norm = 2.8919
	old_data_grads_norm = 0.5914
	sim_grads_norm_tr = -0.1584
-- Starting training on experience 442 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1974
	data_grads_norm = 1.2942
	new_data_grads_norm = 0.2253
	old_data_grads_norm = 3.7977
	sim_grads_norm_tr = -0.1661
-- Starting training on experience 443 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3992
	data_grads_norm = 2.8377
	new_data_grads_norm = 3.5420
	old_data_grads_norm = 2.9502
	sim_grads_norm_tr = 0.4637
-- Starting training on experience 444 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4021
	data_grads_norm = 1.8272
	new_data_grads_norm = 2.3638
	old_data_grads_norm = 1.8684
	sim_grads_norm_tr = 0.2326
-- Starting training on experience 445 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1408
	data_grads_norm = 0.8033
	new_data_grads_norm = 1.2172
	old_data_grads_norm = 1.0505
	sim_grads_norm_tr = 0.2141
-- Starting training on experience 446 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2701
	data_grads_norm = 1.3166
	new_data_grads_norm = 2.2496
	old_data_grads_norm = 1.4476
	sim_grads_norm_tr = 0.0868
-- Starting training on experience 447 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1124
	data_grads_norm = 1.0042
	new_data_grads_norm = 1.4270
	old_data_grads_norm = 1.1879
	sim_grads_norm_tr = -0.1710
-- Starting training on experience 448 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1764
	data_grads_norm = 1.7045
	new_data_grads_norm = 1.4668
	old_data_grads_norm = 6.2435
	sim_grads_norm_tr = -0.2814
-- Starting training on experience 449 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4460
	data_grads_norm = 7.4981
	new_data_grads_norm = 8.6146
	old_data_grads_norm = 7.9540
	sim_grads_norm_tr = 0.6301
-- Starting training on experience 450 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1864
	data_grads_norm = 1.6405
	new_data_grads_norm = 4.2598
	old_data_grads_norm = 2.9372
	sim_grads_norm_tr = -0.1155
-- Starting training on experience 451 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.6570
	data_grads_norm = 2.7847
	new_data_grads_norm = 3.9405
	old_data_grads_norm = 2.0461
	sim_grads_norm_tr = 0.5084
-- Starting training on experience 452 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4012
	data_grads_norm = 1.8193
	new_data_grads_norm = 1.2083
	old_data_grads_norm = 2.2856
	sim_grads_norm_tr = 0.1864
-- Starting training on experience 453 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2861
	data_grads_norm = 1.6798
	new_data_grads_norm = 1.5347
	old_data_grads_norm = 3.1962
	sim_grads_norm_tr = 0.1788
-- Starting training on experience 454 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1627
	data_grads_norm = 0.9333
	new_data_grads_norm = 1.9018
	old_data_grads_norm = 0.6817
	sim_grads_norm_tr = -0.2346
-- Starting training on experience 455 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.6518
	data_grads_norm = 3.3314
	new_data_grads_norm = 3.5603
	old_data_grads_norm = 3.4774
	sim_grads_norm_tr = 0.5207
-- Starting training on experience 456 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2184
	data_grads_norm = 1.5915
	new_data_grads_norm = 1.9412
	old_data_grads_norm = 2.2850
	sim_grads_norm_tr = -0.0215
-- Starting training on experience 457 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1048
	data_grads_norm = 0.8284
	new_data_grads_norm = 3.1092
	old_data_grads_norm = 3.4636
	sim_grads_norm_tr = -0.1177
-- Starting training on experience 458 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.6947
	data_grads_norm = 3.2445
	new_data_grads_norm = 2.7849
	old_data_grads_norm = 8.3751
	sim_grads_norm_tr = 0.4774
-- Starting training on experience 459 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2503
	data_grads_norm = 0.9560
	new_data_grads_norm = 0.6691
	old_data_grads_norm = 1.9033
	sim_grads_norm_tr = -0.0480
-- Starting training on experience 460 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2146
	data_grads_norm = 1.0901
	new_data_grads_norm = 3.1873
	old_data_grads_norm = 0.9833
	sim_grads_norm_tr = 0.0912
-- Starting training on experience 461 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2588
	data_grads_norm = 1.0725
	new_data_grads_norm = 1.3155
	old_data_grads_norm = 2.0922
	sim_grads_norm_tr = 0.0710
-- Starting training on experience 462 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3305
	data_grads_norm = 1.5627
	new_data_grads_norm = 2.3519
	old_data_grads_norm = 2.3381
	sim_grads_norm_tr = -0.0223
-- Starting training on experience 463 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1490
	data_grads_norm = 0.7314
	new_data_grads_norm = 1.4653
	old_data_grads_norm = 0.7234
	sim_grads_norm_tr = 0.1231
-- Starting training on experience 464 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1735
	data_grads_norm = 0.9374
	new_data_grads_norm = 1.0132
	old_data_grads_norm = 0.9135
	sim_grads_norm_tr = 0.5459
-- Starting training on experience 465 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1496
	data_grads_norm = 0.8616
	new_data_grads_norm = 0.9073
	old_data_grads_norm = 1.6932
	sim_grads_norm_tr = -0.0099
-- Starting training on experience 466 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2649
	data_grads_norm = 1.2477
	new_data_grads_norm = 1.0556
	old_data_grads_norm = 1.8550
	sim_grads_norm_tr = 0.1610
-- Starting training on experience 467 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3590
	data_grads_norm = 1.4172
	new_data_grads_norm = 3.0188
	old_data_grads_norm = 1.5716
	sim_grads_norm_tr = 0.1005
-- Starting training on experience 468 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2560
	data_grads_norm = 1.2244
	new_data_grads_norm = 1.4433
	old_data_grads_norm = 1.5558
	sim_grads_norm_tr = 0.4478
-- Starting training on experience 469 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2236
	data_grads_norm = 1.1722
	new_data_grads_norm = 1.4076
	old_data_grads_norm = 2.3409
	sim_grads_norm_tr = 0.1483
-- Starting training on experience 470 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2055
	data_grads_norm = 1.1393
	new_data_grads_norm = 0.4381
	old_data_grads_norm = 7.1848
	sim_grads_norm_tr = -0.0356
-- Starting training on experience 471 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.6859
	data_grads_norm = 3.6325
	new_data_grads_norm = 3.4594
	old_data_grads_norm = 5.5707
	sim_grads_norm_tr = 0.7751
-- Starting training on experience 472 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1387
	data_grads_norm = 0.6091
	new_data_grads_norm = 0.5954
	old_data_grads_norm = 1.0293
	sim_grads_norm_tr = 0.1383
-- Starting training on experience 473 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2805
	data_grads_norm = 1.6069
	new_data_grads_norm = 1.4284
	old_data_grads_norm = 2.9103
	sim_grads_norm_tr = 0.1343
-- Starting training on experience 474 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1355
	data_grads_norm = 0.5873
	new_data_grads_norm = 0.6725
	old_data_grads_norm = 0.6041
	sim_grads_norm_tr = 0.4377
-- Starting training on experience 475 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1269
	data_grads_norm = 0.6763
	new_data_grads_norm = 0.8756
	old_data_grads_norm = 0.7813
	sim_grads_norm_tr = 0.3348
-- Starting training on experience 476 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1973
	data_grads_norm = 0.6827
	new_data_grads_norm = 1.1456
	old_data_grads_norm = 0.8574
	sim_grads_norm_tr = -0.1559
-- Starting training on experience 477 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3207
	data_grads_norm = 1.0270
	new_data_grads_norm = 1.5837
	old_data_grads_norm = 1.1546
	sim_grads_norm_tr = -0.0269
-- Starting training on experience 478 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1859
	data_grads_norm = 1.0991
	new_data_grads_norm = 1.1085
	old_data_grads_norm = 1.3177
	sim_grads_norm_tr = 0.3273
-- Starting training on experience 479 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1499
	data_grads_norm = 0.6223
	new_data_grads_norm = 0.9851
	old_data_grads_norm = 0.7493
	sim_grads_norm_tr = -0.2918
-- Starting training on experience 480 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2185
	data_grads_norm = 1.0339
	new_data_grads_norm = 0.7142
	old_data_grads_norm = 2.2780
	sim_grads_norm_tr = 0.2372
-- Starting training on experience 481 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4123
	data_grads_norm = 2.0593
	new_data_grads_norm = 5.7433
	old_data_grads_norm = 0.9029
	sim_grads_norm_tr = 0.0778
-- Starting training on experience 482 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2583
	data_grads_norm = 1.0375
	new_data_grads_norm = 1.8308
	old_data_grads_norm = 1.5009
	sim_grads_norm_tr = -0.1897
-- Starting training on experience 483 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2713
	data_grads_norm = 1.2288
	new_data_grads_norm = 3.5752
	old_data_grads_norm = 1.3197
	sim_grads_norm_tr = -0.1331
-- Starting training on experience 484 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1926
	data_grads_norm = 0.9363
	new_data_grads_norm = 0.5000
	old_data_grads_norm = 2.6877
	sim_grads_norm_tr = -0.3208
-- Starting training on experience 485 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2437
	data_grads_norm = 0.9231
	new_data_grads_norm = 0.7825
	old_data_grads_norm = 1.6581
	sim_grads_norm_tr = 0.0199
-- Starting training on experience 486 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1779
	data_grads_norm = 0.9092
	new_data_grads_norm = 2.2099
	old_data_grads_norm = 1.2748
	sim_grads_norm_tr = -0.2904
-- Starting training on experience 487 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4591
	data_grads_norm = 2.0599
	new_data_grads_norm = 2.2419
	old_data_grads_norm = 2.2856
	sim_grads_norm_tr = 0.3756
-- Starting training on experience 488 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2280
	data_grads_norm = 1.6458
	new_data_grads_norm = 1.7904
	old_data_grads_norm = 2.1791
	sim_grads_norm_tr = 0.5010
-- Starting training on experience 489 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2341
	data_grads_norm = 1.4239
	new_data_grads_norm = 2.8497
	old_data_grads_norm = 0.7402
	sim_grads_norm_tr = -0.1138
-- Starting training on experience 490 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3664
	data_grads_norm = 2.5029
	new_data_grads_norm = 2.7779
	old_data_grads_norm = 1.8123
	sim_grads_norm_tr = -0.0882
-- Starting training on experience 491 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1672
	data_grads_norm = 1.1694
	new_data_grads_norm = 3.6794
	old_data_grads_norm = 0.5392
	sim_grads_norm_tr = -0.0616
-- Starting training on experience 492 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2794
	data_grads_norm = 1.6722
	new_data_grads_norm = 2.8236
	old_data_grads_norm = 2.2728
	sim_grads_norm_tr = -0.1761
-- Starting training on experience 493 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2066
	data_grads_norm = 0.9930
	new_data_grads_norm = 1.5017
	old_data_grads_norm = 0.7029
	sim_grads_norm_tr = 0.0951
-- Starting training on experience 494 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2498
	data_grads_norm = 1.3380
	new_data_grads_norm = 4.0212
	old_data_grads_norm = 2.2426
	sim_grads_norm_tr = -0.2817
-- Starting training on experience 495 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2334
	data_grads_norm = 1.2930
	new_data_grads_norm = 3.0338
	old_data_grads_norm = 0.9146
	sim_grads_norm_tr = -0.2030
-- Starting training on experience 496 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2797
	data_grads_norm = 1.8795
	new_data_grads_norm = 2.2059
	old_data_grads_norm = 2.1803
	sim_grads_norm_tr = 0.2838
-- Starting training on experience 497 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2244
	data_grads_norm = 1.4607
	new_data_grads_norm = 2.7728
	old_data_grads_norm = 0.6041
	sim_grads_norm_tr = -0.2856
-- Starting training on experience 498 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0945
	data_grads_norm = 0.9133
	new_data_grads_norm = 1.1273
	old_data_grads_norm = 3.1063
	sim_grads_norm_tr = 0.0516
-- Starting training on experience 499 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2789
	data_grads_norm = 3.0137
	new_data_grads_norm = 2.2562
	old_data_grads_norm = 6.5674
	sim_grads_norm_tr = 0.0837
-- Starting training on experience 500 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4574
	data_grads_norm = 2.4185
	new_data_grads_norm = 4.3688
	old_data_grads_norm = 0.8960
	sim_grads_norm_tr = -0.0240
-- Starting training on experience 501 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0927
	data_grads_norm = 0.5355
	new_data_grads_norm = 1.0589
	old_data_grads_norm = 0.4823
	sim_grads_norm_tr = 0.1415
-- Starting training on experience 502 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9318
	data_grads_norm = 4.1715
	new_data_grads_norm = 3.2367
	old_data_grads_norm = 6.8319
	sim_grads_norm_tr = 0.4236
-- Starting training on experience 503 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1542
	data_grads_norm = 0.8448
	new_data_grads_norm = 0.5772
	old_data_grads_norm = 1.7757
	sim_grads_norm_tr = -0.0948
-- Starting training on experience 504 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3800
	data_grads_norm = 1.7331
	new_data_grads_norm = 1.1541
	old_data_grads_norm = 2.7463
	sim_grads_norm_tr = -0.0348
-- Starting training on experience 505 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3629
	data_grads_norm = 1.8157
	new_data_grads_norm = 1.6110
	old_data_grads_norm = 3.8224
	sim_grads_norm_tr = -0.0585
-- Starting training on experience 506 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2227
	data_grads_norm = 1.0543
	new_data_grads_norm = 1.3057
	old_data_grads_norm = 1.0715
	sim_grads_norm_tr = 0.1449
-- Starting training on experience 507 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4413
	data_grads_norm = 1.5929
	new_data_grads_norm = 2.8551
	old_data_grads_norm = 1.8128
	sim_grads_norm_tr = -0.2384
-- Starting training on experience 508 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3524
	data_grads_norm = 1.9979
	new_data_grads_norm = 2.4617
	old_data_grads_norm = 1.7144
	sim_grads_norm_tr = 0.6898
-- Starting training on experience 509 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1538
	data_grads_norm = 1.1796
	new_data_grads_norm = 1.8417
	old_data_grads_norm = 1.2862
	sim_grads_norm_tr = 0.2361
-- Starting training on experience 510 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3213
	data_grads_norm = 1.6371
	new_data_grads_norm = 3.9248
	old_data_grads_norm = 1.4206
	sim_grads_norm_tr = -0.2538
-- Starting training on experience 511 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2254
	data_grads_norm = 1.3717
	new_data_grads_norm = 0.9870
	old_data_grads_norm = 3.0299
	sim_grads_norm_tr = 0.2414
-- Starting training on experience 512 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0778
	data_grads_norm = 0.6278
	new_data_grads_norm = 0.6394
	old_data_grads_norm = 0.5811
	sim_grads_norm_tr = 0.6789
-- Starting training on experience 513 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1431
	data_grads_norm = 0.8174
	new_data_grads_norm = 3.1725
	old_data_grads_norm = 0.9212
	sim_grads_norm_tr = -0.2961
-- Starting training on experience 514 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2493
	data_grads_norm = 1.2095
	new_data_grads_norm = 1.6125
	old_data_grads_norm = 2.2721
	sim_grads_norm_tr = -0.0580
-- Starting training on experience 515 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.5868
	data_grads_norm = 2.5000
	new_data_grads_norm = 2.4175
	old_data_grads_norm = 5.1538
	sim_grads_norm_tr = 0.3711
-- Starting training on experience 516 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4599
	data_grads_norm = 2.0361
	new_data_grads_norm = 1.8509
	old_data_grads_norm = 2.6832
	sim_grads_norm_tr = 0.4992
-- Starting training on experience 517 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0598
	data_grads_norm = 0.3913
	new_data_grads_norm = 0.5268
	old_data_grads_norm = 0.4515
	sim_grads_norm_tr = 0.2910
-- Starting training on experience 518 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2238
	data_grads_norm = 0.8511
	new_data_grads_norm = 1.8221
	old_data_grads_norm = 0.6638
	sim_grads_norm_tr = 0.1476
-- Starting training on experience 519 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1572
	data_grads_norm = 0.7479
	new_data_grads_norm = 0.4520
	old_data_grads_norm = 1.0859
	sim_grads_norm_tr = 0.2920
-- Starting training on experience 520 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1880
	data_grads_norm = 1.0546
	new_data_grads_norm = 1.3904
	old_data_grads_norm = 1.2986
	sim_grads_norm_tr = 0.2846
-- Starting training on experience 521 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1099
	data_grads_norm = 0.5766
	new_data_grads_norm = 0.8041
	old_data_grads_norm = 0.8339
	sim_grads_norm_tr = 0.0584
-- Starting training on experience 522 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1698
	data_grads_norm = 0.6833
	new_data_grads_norm = 1.7115
	old_data_grads_norm = 0.8490
	sim_grads_norm_tr = -0.2627
-- Starting training on experience 523 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1374
	data_grads_norm = 0.9673
	new_data_grads_norm = 1.1299
	old_data_grads_norm = 1.0413
	sim_grads_norm_tr = 0.0173
-- Starting training on experience 524 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1757
	data_grads_norm = 1.3061
	new_data_grads_norm = 0.6000
	old_data_grads_norm = 3.1132
	sim_grads_norm_tr = 0.0344
-- Starting training on experience 525 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2929
	data_grads_norm = 1.9154
	new_data_grads_norm = 1.8601
	old_data_grads_norm = 3.1095
	sim_grads_norm_tr = 0.3920
-- Starting training on experience 526 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2172
	data_grads_norm = 1.7210
	new_data_grads_norm = 0.7651
	old_data_grads_norm = 3.1476
	sim_grads_norm_tr = 0.0006
-- Starting training on experience 527 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2682
	data_grads_norm = 1.0531
	new_data_grads_norm = 2.3708
	old_data_grads_norm = 0.8005
	sim_grads_norm_tr = -0.0840
-- Starting training on experience 528 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2772
	data_grads_norm = 1.3243
	new_data_grads_norm = 0.5437
	old_data_grads_norm = 4.3192
	sim_grads_norm_tr = -0.3619
-- Starting training on experience 529 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3571
	data_grads_norm = 2.2232
	new_data_grads_norm = 2.5554
	old_data_grads_norm = 2.1043
	sim_grads_norm_tr = 0.7244
-- Starting training on experience 530 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1786
	data_grads_norm = 1.5968
	new_data_grads_norm = 0.9761
	old_data_grads_norm = 5.3717
	sim_grads_norm_tr = -0.0256
-- Starting training on experience 531 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.6930
	data_grads_norm = 3.2223
	new_data_grads_norm = 2.5649
	old_data_grads_norm = 5.9931
	sim_grads_norm_tr = 0.0451
-- Starting training on experience 532 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2624
	data_grads_norm = 1.2805
	new_data_grads_norm = 1.7379
	old_data_grads_norm = 1.3756
	sim_grads_norm_tr = 0.4984
-- Starting training on experience 533 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1614
	data_grads_norm = 0.7074
	new_data_grads_norm = 0.9248
	old_data_grads_norm = 1.3130
	sim_grads_norm_tr = -0.1664
-- Starting training on experience 534 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1232
	data_grads_norm = 0.5658
	new_data_grads_norm = 1.0091
	old_data_grads_norm = 0.5667
	sim_grads_norm_tr = 0.1412
-- Starting training on experience 535 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4068
	data_grads_norm = 1.4423
	new_data_grads_norm = 2.3224
	old_data_grads_norm = 1.8736
	sim_grads_norm_tr = 0.1458
-- Starting training on experience 536 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1939
	data_grads_norm = 0.8083
	new_data_grads_norm = 1.5838
	old_data_grads_norm = 0.6993
	sim_grads_norm_tr = -0.1891
-- Starting training on experience 537 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2347
	data_grads_norm = 0.8597
	new_data_grads_norm = 1.8661
	old_data_grads_norm = 0.5207
	sim_grads_norm_tr = -0.3699
-- Starting training on experience 538 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3525
	data_grads_norm = 1.1273
	new_data_grads_norm = 1.8512
	old_data_grads_norm = 2.1201
	sim_grads_norm_tr = -0.0784
-- Starting training on experience 539 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4200
	data_grads_norm = 1.6929
	new_data_grads_norm = 1.2090
	old_data_grads_norm = 3.8959
	sim_grads_norm_tr = 0.1276
-- Starting training on experience 540 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2668
	data_grads_norm = 0.9230
	new_data_grads_norm = 0.9673
	old_data_grads_norm = 1.3095
	sim_grads_norm_tr = 0.3975
-- Starting training on experience 541 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2163
	data_grads_norm = 0.8395
	new_data_grads_norm = 2.1251
	old_data_grads_norm = 0.9860
	sim_grads_norm_tr = -0.2554
-- Starting training on experience 542 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1788
	data_grads_norm = 1.2235
	new_data_grads_norm = 1.1140
	old_data_grads_norm = 1.2366
	sim_grads_norm_tr = 0.7621
-- Starting training on experience 543 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2149
	data_grads_norm = 1.0199
	new_data_grads_norm = 1.4675
	old_data_grads_norm = 0.9780
	sim_grads_norm_tr = 0.2148
-- Starting training on experience 544 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3850
	data_grads_norm = 1.1492
	new_data_grads_norm = 2.4506
	old_data_grads_norm = 0.8807
	sim_grads_norm_tr = -0.0797
-- Starting training on experience 545 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.5508
	data_grads_norm = 2.4519
	new_data_grads_norm = 3.5283
	old_data_grads_norm = 2.6020
	sim_grads_norm_tr = 0.2516
-- Starting training on experience 546 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1783
	data_grads_norm = 0.8755
	new_data_grads_norm = 0.8802
	old_data_grads_norm = 1.4580
	sim_grads_norm_tr = 0.2723
-- Starting training on experience 547 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2751
	data_grads_norm = 0.8829
	new_data_grads_norm = 1.6090
	old_data_grads_norm = 0.8166
	sim_grads_norm_tr = -0.1372
-- Starting training on experience 548 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1613
	data_grads_norm = 0.7481
	new_data_grads_norm = 0.8916
	old_data_grads_norm = 1.8758
	sim_grads_norm_tr = -0.4119
-- Starting training on experience 549 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2745
	data_grads_norm = 1.2983
	new_data_grads_norm = 1.2045
	old_data_grads_norm = 1.7266
	sim_grads_norm_tr = 0.4381
-- Starting training on experience 550 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2767
	data_grads_norm = 1.7599
	new_data_grads_norm = 2.2363
	old_data_grads_norm = 3.2238
	sim_grads_norm_tr = 0.0498
-- Starting training on experience 551 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2561
	data_grads_norm = 0.9554
	new_data_grads_norm = 2.2131
	old_data_grads_norm = 1.3059
	sim_grads_norm_tr = -0.2759
-- Starting training on experience 552 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1569
	data_grads_norm = 0.8032
	new_data_grads_norm = 1.2009
	old_data_grads_norm = 1.1963
	sim_grads_norm_tr = -0.1925
-- Starting training on experience 553 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1511
	data_grads_norm = 0.5893
	new_data_grads_norm = 0.8217
	old_data_grads_norm = 0.8552
	sim_grads_norm_tr = 0.0222
-- Starting training on experience 554 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2277
	data_grads_norm = 1.2454
	new_data_grads_norm = 3.0799
	old_data_grads_norm = 0.7775
	sim_grads_norm_tr = -0.2791
-- Starting training on experience 555 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3129
	data_grads_norm = 1.4990
	new_data_grads_norm = 1.9483
	old_data_grads_norm = 1.9574
	sim_grads_norm_tr = 0.0176
-- Starting training on experience 556 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3634
	data_grads_norm = 1.5229
	new_data_grads_norm = 1.2976
	old_data_grads_norm = 2.8769
	sim_grads_norm_tr = 0.0971
-- Starting training on experience 557 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2963
	data_grads_norm = 1.0773
	new_data_grads_norm = 1.0341
	old_data_grads_norm = 2.6303
	sim_grads_norm_tr = -0.3733
-- Starting training on experience 558 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1966
	data_grads_norm = 0.6736
	new_data_grads_norm = 1.3322
	old_data_grads_norm = 0.8924
	sim_grads_norm_tr = -0.2815
-- Starting training on experience 559 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3611
	data_grads_norm = 2.0154
	new_data_grads_norm = 3.4916
	old_data_grads_norm = 1.4339
	sim_grads_norm_tr = 0.2674
-- Starting training on experience 560 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1995
	data_grads_norm = 0.5392
	new_data_grads_norm = 0.5243
	old_data_grads_norm = 1.0356
	sim_grads_norm_tr = 0.1315
-- Starting training on experience 561 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1688
	data_grads_norm = 0.7790
	new_data_grads_norm = 0.4672
	old_data_grads_norm = 2.5835
	sim_grads_norm_tr = -0.3379
-- Starting training on experience 562 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2049
	data_grads_norm = 0.9010
	new_data_grads_norm = 0.9193
	old_data_grads_norm = 1.6826
	sim_grads_norm_tr = 0.0793
-- Starting training on experience 563 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2064
	data_grads_norm = 1.1349
	new_data_grads_norm = 2.0676
	old_data_grads_norm = 0.8856
	sim_grads_norm_tr = 0.2546
-- Starting training on experience 564 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2089
	data_grads_norm = 0.7568
	new_data_grads_norm = 0.8673
	old_data_grads_norm = 1.5825
	sim_grads_norm_tr = -0.1718
-- Starting training on experience 565 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1517
	data_grads_norm = 0.7443
	new_data_grads_norm = 0.9186
	old_data_grads_norm = 0.7926
	sim_grads_norm_tr = 0.4979
-- Starting training on experience 566 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1207
	data_grads_norm = 0.6524
	new_data_grads_norm = 1.3590
	old_data_grads_norm = 0.5420
	sim_grads_norm_tr = 0.0133
-- Starting training on experience 567 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4162
	data_grads_norm = 1.6032
	new_data_grads_norm = 1.5356
	old_data_grads_norm = 3.7438
	sim_grads_norm_tr = 0.0738
-- Starting training on experience 568 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1772
	data_grads_norm = 0.8710
	new_data_grads_norm = 0.9698
	old_data_grads_norm = 1.2366
	sim_grads_norm_tr = 0.2522
-- Starting training on experience 569 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3299
	data_grads_norm = 1.6726
	new_data_grads_norm = 3.2084
	old_data_grads_norm = 1.0191
	sim_grads_norm_tr = 0.4727
-- Starting training on experience 570 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2059
	data_grads_norm = 1.0813
	new_data_grads_norm = 2.3725
	old_data_grads_norm = 1.4238
	sim_grads_norm_tr = 0.0483
-- Starting training on experience 571 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2411
	data_grads_norm = 1.2497
	new_data_grads_norm = 2.9343
	old_data_grads_norm = 0.5988
	sim_grads_norm_tr = 0.2569
-- Starting training on experience 572 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3980
	data_grads_norm = 1.7796
	new_data_grads_norm = 4.0875
	old_data_grads_norm = 1.0009
	sim_grads_norm_tr = 0.1765
-- Starting training on experience 573 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2463
	data_grads_norm = 1.3648
	new_data_grads_norm = 3.2497
	old_data_grads_norm = 1.8043
	sim_grads_norm_tr = -0.0874
-- Starting training on experience 574 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1385
	data_grads_norm = 0.6507
	new_data_grads_norm = 1.6023
	old_data_grads_norm = 1.0736
	sim_grads_norm_tr = -0.3937
-- Starting training on experience 575 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3426
	data_grads_norm = 1.7826
	new_data_grads_norm = 0.8010
	old_data_grads_norm = 4.0932
	sim_grads_norm_tr = -0.1172
-- Starting training on experience 576 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1947
	data_grads_norm = 1.2850
	new_data_grads_norm = 1.6408
	old_data_grads_norm = 1.0927
	sim_grads_norm_tr = 0.5862
-- Starting training on experience 577 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4099
	data_grads_norm = 2.0415
	new_data_grads_norm = 4.7091
	old_data_grads_norm = 1.8282
	sim_grads_norm_tr = 0.1539
-- Starting training on experience 578 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4049
	data_grads_norm = 2.5938
	new_data_grads_norm = 1.3610
	old_data_grads_norm = 4.1692
	sim_grads_norm_tr = 0.0421
-- Starting training on experience 579 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1202
	data_grads_norm = 0.6730
	new_data_grads_norm = 1.3025
	old_data_grads_norm = 0.9745
	sim_grads_norm_tr = -0.2687
-- Starting training on experience 580 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3971
	data_grads_norm = 1.0991
	new_data_grads_norm = 1.2905
	old_data_grads_norm = 3.2721
	sim_grads_norm_tr = -0.3578
-- Starting training on experience 581 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3002
	data_grads_norm = 1.0946
	new_data_grads_norm = 1.1548
	old_data_grads_norm = 1.5064
	sim_grads_norm_tr = 0.2431
-- Starting training on experience 582 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4729
	data_grads_norm = 2.1063
	new_data_grads_norm = 0.7181
	old_data_grads_norm = 3.9798
	sim_grads_norm_tr = -0.0609
-- Starting training on experience 583 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2649
	data_grads_norm = 0.8230
	new_data_grads_norm = 1.3732
	old_data_grads_norm = 0.8359
	sim_grads_norm_tr = 0.1984
-- Starting training on experience 584 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2319
	data_grads_norm = 0.7232
	new_data_grads_norm = 1.4913
	old_data_grads_norm = 1.0053
	sim_grads_norm_tr = -0.1399
-- Starting training on experience 585 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1806
	data_grads_norm = 0.7527
	new_data_grads_norm = 0.8537
	old_data_grads_norm = 1.0363
	sim_grads_norm_tr = 0.3921
-- Starting training on experience 586 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3082
	data_grads_norm = 1.5562
	new_data_grads_norm = 2.1686
	old_data_grads_norm = 1.2755
	sim_grads_norm_tr = 0.3915
-- Starting training on experience 587 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1451
	data_grads_norm = 0.7515
	new_data_grads_norm = 0.9377
	old_data_grads_norm = 0.9960
	sim_grads_norm_tr = 0.1990
-- Starting training on experience 588 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1885
	data_grads_norm = 0.8017
	new_data_grads_norm = 0.5415
	old_data_grads_norm = 1.5209
	sim_grads_norm_tr = -0.0002
-- Starting training on experience 589 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1698
	data_grads_norm = 0.5213
	new_data_grads_norm = 0.7895
	old_data_grads_norm = 1.1215
	sim_grads_norm_tr = -0.2655
-- Starting training on experience 590 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1933
	data_grads_norm = 0.7698
	new_data_grads_norm = 1.1551
	old_data_grads_norm = 0.4709
	sim_grads_norm_tr = 0.0110
-- Starting training on experience 591 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3399
	data_grads_norm = 0.8781
	new_data_grads_norm = 1.7762
	old_data_grads_norm = 1.7181
	sim_grads_norm_tr = -0.4657
-- Starting training on experience 592 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3648
	data_grads_norm = 1.5256
	new_data_grads_norm = 1.4308
	old_data_grads_norm = 2.9230
	sim_grads_norm_tr = -0.0726
-- Starting training on experience 593 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1410
	data_grads_norm = 0.7134
	new_data_grads_norm = 0.7643
	old_data_grads_norm = 1.6162
	sim_grads_norm_tr = -0.2725
-- Starting training on experience 594 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2092
	data_grads_norm = 0.8762
	new_data_grads_norm = 1.3747
	old_data_grads_norm = 0.9738
	sim_grads_norm_tr = 0.0886
-- Starting training on experience 595 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2188
	data_grads_norm = 1.0869
	new_data_grads_norm = 1.3277
	old_data_grads_norm = 1.1438
	sim_grads_norm_tr = 0.5927
-- Starting training on experience 596 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4037
	data_grads_norm = 1.6501
	new_data_grads_norm = 1.8576
	old_data_grads_norm = 2.3452
	sim_grads_norm_tr = 0.2025
-- Starting training on experience 597 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2944
	data_grads_norm = 1.3807
	new_data_grads_norm = 0.9617
	old_data_grads_norm = 2.4886
	sim_grads_norm_tr = -0.0359
-- Starting training on experience 598 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4232
	data_grads_norm = 2.4125
	new_data_grads_norm = 2.1316
	old_data_grads_norm = 2.9003
	sim_grads_norm_tr = 0.6774
-- Starting training on experience 599 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2840
	data_grads_norm = 0.8906
	new_data_grads_norm = 1.1834
	old_data_grads_norm = 1.7700
	sim_grads_norm_tr = -0.1063
-- Starting training on experience 600 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1129
	data_grads_norm = 0.5800
	new_data_grads_norm = 0.7089
	old_data_grads_norm = 1.2617
	sim_grads_norm_tr = -0.1168
-- Starting training on experience 601 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3396
	data_grads_norm = 1.4181
	new_data_grads_norm = 3.4769
	old_data_grads_norm = 0.6509
	sim_grads_norm_tr = -0.0396
-- Starting training on experience 602 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0748
	data_grads_norm = 0.5901
	new_data_grads_norm = 0.6832
	old_data_grads_norm = 0.6725
	sim_grads_norm_tr = 0.5404
-- Starting training on experience 603 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2137
	data_grads_norm = 0.7941
	new_data_grads_norm = 0.6827
	old_data_grads_norm = 2.0020
	sim_grads_norm_tr = -0.1863
-- Starting training on experience 604 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1611
	data_grads_norm = 1.1552
	new_data_grads_norm = 0.7294
	old_data_grads_norm = 2.7346
	sim_grads_norm_tr = 0.2841
-- Starting training on experience 605 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4244
	data_grads_norm = 2.2449
	new_data_grads_norm = 4.7398
	old_data_grads_norm = 1.0745
	sim_grads_norm_tr = -0.1669
-- Starting training on experience 606 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2867
	data_grads_norm = 2.2309
	new_data_grads_norm = 1.4221
	old_data_grads_norm = 3.9363
	sim_grads_norm_tr = 0.2758
-- Starting training on experience 607 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1302
	data_grads_norm = 0.7136
	new_data_grads_norm = 0.6326
	old_data_grads_norm = 1.6103
	sim_grads_norm_tr = -0.2238
-- Starting training on experience 608 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2732
	data_grads_norm = 1.4536
	new_data_grads_norm = 1.5042
	old_data_grads_norm = 1.9178
	sim_grads_norm_tr = 0.3369
-- Starting training on experience 609 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1051
	data_grads_norm = 0.8535
	new_data_grads_norm = 1.2697
	old_data_grads_norm = 0.5704
	sim_grads_norm_tr = -0.0229
-- Starting training on experience 610 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2048
	data_grads_norm = 1.0560
	new_data_grads_norm = 1.1112
	old_data_grads_norm = 1.6688
	sim_grads_norm_tr = 0.1349
-- Starting training on experience 611 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1557
	data_grads_norm = 0.9909
	new_data_grads_norm = 0.9392
	old_data_grads_norm = 1.5444
	sim_grads_norm_tr = 0.3995
-- Starting training on experience 612 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1727
	data_grads_norm = 0.9351
	new_data_grads_norm = 0.7901
	old_data_grads_norm = 1.6716
	sim_grads_norm_tr = 0.3855
-- Starting training on experience 613 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2705
	data_grads_norm = 1.8872
	new_data_grads_norm = 3.2328
	old_data_grads_norm = 1.1778
	sim_grads_norm_tr = 0.0793
-- Starting training on experience 614 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1059
	data_grads_norm = 0.5670
	new_data_grads_norm = 0.7602
	old_data_grads_norm = 1.0413
	sim_grads_norm_tr = -0.1147
-- Starting training on experience 615 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1887
	data_grads_norm = 1.0509
	new_data_grads_norm = 1.1142
	old_data_grads_norm = 2.1927
	sim_grads_norm_tr = -0.1199
-- Starting training on experience 616 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0929
	data_grads_norm = 0.4977
	new_data_grads_norm = 0.7727
	old_data_grads_norm = 0.8894
	sim_grads_norm_tr = -0.1538
-- Starting training on experience 617 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3053
	data_grads_norm = 1.6866
	new_data_grads_norm = 2.8929
	old_data_grads_norm = 1.5087
	sim_grads_norm_tr = 0.3282
-- Starting training on experience 618 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4200
	data_grads_norm = 1.4659
	new_data_grads_norm = 1.5969
	old_data_grads_norm = 3.1711
	sim_grads_norm_tr = -0.1933
-- Starting training on experience 619 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1797
	data_grads_norm = 0.9867
	new_data_grads_norm = 0.4481
	old_data_grads_norm = 2.7176
	sim_grads_norm_tr = -0.4090
-- Starting training on experience 620 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1276
	data_grads_norm = 0.9230
	new_data_grads_norm = 0.9894
	old_data_grads_norm = 1.4005
	sim_grads_norm_tr = 0.2756
-- Starting training on experience 621 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1442
	data_grads_norm = 0.7018
	new_data_grads_norm = 1.2148
	old_data_grads_norm = 0.7565
	sim_grads_norm_tr = 0.0753
-- Starting training on experience 622 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2163
	data_grads_norm = 0.7551
	new_data_grads_norm = 1.1870
	old_data_grads_norm = 1.3782
	sim_grads_norm_tr = -0.2297
-- Starting training on experience 623 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0928
	data_grads_norm = 0.5927
	new_data_grads_norm = 0.7656
	old_data_grads_norm = 0.7153
	sim_grads_norm_tr = 0.1535
-- Starting training on experience 624 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2711
	data_grads_norm = 1.1725
	new_data_grads_norm = 3.4470
	old_data_grads_norm = 2.6001
	sim_grads_norm_tr = 0.0939
-- Starting training on experience 625 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1929
	data_grads_norm = 1.8935
	new_data_grads_norm = 4.5032
	old_data_grads_norm = 0.6763
	sim_grads_norm_tr = -0.4526
-- Starting training on experience 626 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4602
	data_grads_norm = 1.9791
	new_data_grads_norm = 2.1465
	old_data_grads_norm = 3.8706
	sim_grads_norm_tr = 0.2034
-- Starting training on experience 627 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1203
	data_grads_norm = 0.5971
	new_data_grads_norm = 1.8899
	old_data_grads_norm = 1.4100
	sim_grads_norm_tr = -0.2371
-- Starting training on experience 628 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0961
	data_grads_norm = 0.6609
	new_data_grads_norm = 0.6083
	old_data_grads_norm = 1.1543
	sim_grads_norm_tr = -0.1393
-- Starting training on experience 629 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1401
	data_grads_norm = 0.5722
	new_data_grads_norm = 0.8433
	old_data_grads_norm = 0.5024
	sim_grads_norm_tr = 0.2409
-- Starting training on experience 630 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.5138
	data_grads_norm = 2.2562
	new_data_grads_norm = 4.1670
	old_data_grads_norm = 1.6527
	sim_grads_norm_tr = -0.0179
-- Starting training on experience 631 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4633
	data_grads_norm = 2.6645
	new_data_grads_norm = 2.2027
	old_data_grads_norm = 4.9001
	sim_grads_norm_tr = 0.4299
-- Starting training on experience 632 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0985
	data_grads_norm = 0.6013
	new_data_grads_norm = 0.5589
	old_data_grads_norm = 0.9008
	sim_grads_norm_tr = 0.1172
-- Starting training on experience 633 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2843
	data_grads_norm = 1.3079
	new_data_grads_norm = 2.5661
	old_data_grads_norm = 1.0386
	sim_grads_norm_tr = 0.0749
-- Starting training on experience 634 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4098
	data_grads_norm = 1.8349
	new_data_grads_norm = 3.0965
	old_data_grads_norm = 3.4129
	sim_grads_norm_tr = 0.0470
-- Starting training on experience 635 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1835
	data_grads_norm = 0.7915
	new_data_grads_norm = 0.8821
	old_data_grads_norm = 0.9801
	sim_grads_norm_tr = 0.2747
-- Starting training on experience 636 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1756
	data_grads_norm = 1.0509
	new_data_grads_norm = 2.2582
	old_data_grads_norm = 2.6202
	sim_grads_norm_tr = -0.3451
-- Starting training on experience 637 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3023
	data_grads_norm = 1.7498
	new_data_grads_norm = 1.5918
	old_data_grads_norm = 2.2578
	sim_grads_norm_tr = 0.4795
-- Starting training on experience 638 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1283
	data_grads_norm = 0.7751
	new_data_grads_norm = 0.8815
	old_data_grads_norm = 1.0890
	sim_grads_norm_tr = 0.1888
-- Starting training on experience 639 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2229
	data_grads_norm = 1.1375
	new_data_grads_norm = 1.4830
	old_data_grads_norm = 1.7933
	sim_grads_norm_tr = 0.1523
-- Starting training on experience 640 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1247
	data_grads_norm = 0.7011
	new_data_grads_norm = 0.9836
	old_data_grads_norm = 1.1739
	sim_grads_norm_tr = -0.0096
-- Starting training on experience 641 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1329
	data_grads_norm = 0.7118
	new_data_grads_norm = 0.8793
	old_data_grads_norm = 1.0155
	sim_grads_norm_tr = 0.0993
-- Starting training on experience 642 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2094
	data_grads_norm = 1.0395
	new_data_grads_norm = 0.9024
	old_data_grads_norm = 1.2914
	sim_grads_norm_tr = 0.0517
-- Starting training on experience 643 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0559
	data_grads_norm = 0.4347
	new_data_grads_norm = 0.7503
	old_data_grads_norm = 0.2982
	sim_grads_norm_tr = 0.2608
-- Starting training on experience 644 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1371
	data_grads_norm = 0.9621
	new_data_grads_norm = 0.9251
	old_data_grads_norm = 1.0949
	sim_grads_norm_tr = 0.0032
-- Starting training on experience 645 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3256
	data_grads_norm = 1.4795
	new_data_grads_norm = 4.2049
	old_data_grads_norm = 1.6518
	sim_grads_norm_tr = 0.1903
-- Starting training on experience 646 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2165
	data_grads_norm = 1.4157
	new_data_grads_norm = 2.4714
	old_data_grads_norm = 1.2782
	sim_grads_norm_tr = 0.3444
-- Starting training on experience 647 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0854
	data_grads_norm = 0.6236
	new_data_grads_norm = 1.1659
	old_data_grads_norm = 0.7049
	sim_grads_norm_tr = 0.0417
-- Starting training on experience 648 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1396
	data_grads_norm = 1.0341
	new_data_grads_norm = 0.4377
	old_data_grads_norm = 1.7348
	sim_grads_norm_tr = 0.4007
-- Starting training on experience 649 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4042
	data_grads_norm = 1.8317
	new_data_grads_norm = 4.0883
	old_data_grads_norm = 1.9893
	sim_grads_norm_tr = -0.0978
-- Starting training on experience 650 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2508
	data_grads_norm = 1.4652
	new_data_grads_norm = 3.2051
	old_data_grads_norm = 0.8749
	sim_grads_norm_tr = -0.1545
-- Starting training on experience 651 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3313
	data_grads_norm = 1.5249
	new_data_grads_norm = 2.4745
	old_data_grads_norm = 2.5504
	sim_grads_norm_tr = -0.1582
-- Starting training on experience 652 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2435
	data_grads_norm = 2.1651
	new_data_grads_norm = 0.7563
	old_data_grads_norm = 4.8054
	sim_grads_norm_tr = 0.1210
-- Starting training on experience 653 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4501
	data_grads_norm = 1.7615
	new_data_grads_norm = 3.2233
	old_data_grads_norm = 2.5518
	sim_grads_norm_tr = -0.2603
-- Starting training on experience 654 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3217
	data_grads_norm = 1.7348
	new_data_grads_norm = 3.4714
	old_data_grads_norm = 3.6224
	sim_grads_norm_tr = -0.0535
-- Starting training on experience 655 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1710
	data_grads_norm = 1.0506
	new_data_grads_norm = 1.0317
	old_data_grads_norm = 2.1323
	sim_grads_norm_tr = 0.1512
-- Starting training on experience 656 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0558
	data_grads_norm = 0.4632
	new_data_grads_norm = 0.5259
	old_data_grads_norm = 0.7768
	sim_grads_norm_tr = 0.3410
-- Starting training on experience 657 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1796
	data_grads_norm = 1.0785
	new_data_grads_norm = 0.2888
	old_data_grads_norm = 3.6292
	sim_grads_norm_tr = -0.4307
-- Starting training on experience 658 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1089
	data_grads_norm = 1.0470
	new_data_grads_norm = 1.5391
	old_data_grads_norm = 0.9347
	sim_grads_norm_tr = 0.1579
-- Starting training on experience 659 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2041
	data_grads_norm = 1.0243
	new_data_grads_norm = 1.3396
	old_data_grads_norm = 1.6312
	sim_grads_norm_tr = -0.1806
-- Starting training on experience 660 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3100
	data_grads_norm = 1.0600
	new_data_grads_norm = 3.2662
	old_data_grads_norm = 1.1229
	sim_grads_norm_tr = -0.2194
-- Starting training on experience 661 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2482
	data_grads_norm = 1.1929
	new_data_grads_norm = 4.1109
	old_data_grads_norm = 0.8672
	sim_grads_norm_tr = -0.2873
-- Starting training on experience 662 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1673
	data_grads_norm = 0.8803
	new_data_grads_norm = 1.3160
	old_data_grads_norm = 1.0793
	sim_grads_norm_tr = 0.2058
-- Starting training on experience 663 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0871
	data_grads_norm = 0.5488
	new_data_grads_norm = 0.7563
	old_data_grads_norm = 0.9247
	sim_grads_norm_tr = 0.1447
-- Starting training on experience 664 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3090
	data_grads_norm = 2.3233
	new_data_grads_norm = 5.9788
	old_data_grads_norm = 1.3038
	sim_grads_norm_tr = 0.2334
-- Starting training on experience 665 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0965
	data_grads_norm = 0.5901
	new_data_grads_norm = 0.7996
	old_data_grads_norm = 0.9601
	sim_grads_norm_tr = 0.1150
-- Starting training on experience 666 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3893
	data_grads_norm = 2.0104
	new_data_grads_norm = 3.4265
	old_data_grads_norm = 1.8888
	sim_grads_norm_tr = 0.3354
-- Starting training on experience 667 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1518
	data_grads_norm = 1.1013
	new_data_grads_norm = 1.4626
	old_data_grads_norm = 0.9468
	sim_grads_norm_tr = 0.3746
-- Starting training on experience 668 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1011
	data_grads_norm = 0.5677
	new_data_grads_norm = 1.1706
	old_data_grads_norm = 0.7527
	sim_grads_norm_tr = -0.1671
-- Starting training on experience 669 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1856
	data_grads_norm = 1.1797
	new_data_grads_norm = 1.7803
	old_data_grads_norm = 1.9690
	sim_grads_norm_tr = -0.0091
-- Starting training on experience 670 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4331
	data_grads_norm = 2.5093
	new_data_grads_norm = 3.9889
	old_data_grads_norm = 4.6835
	sim_grads_norm_tr = -0.1503
-- Starting training on experience 671 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2565
	data_grads_norm = 1.6135
	new_data_grads_norm = 2.3286
	old_data_grads_norm = 2.1228
	sim_grads_norm_tr = -0.0932
-- Starting training on experience 672 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2475
	data_grads_norm = 1.5849
	new_data_grads_norm = 2.7099
	old_data_grads_norm = 1.2568
	sim_grads_norm_tr = -0.0172
-- Starting training on experience 673 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2350
	data_grads_norm = 1.3223
	new_data_grads_norm = 2.8882
	old_data_grads_norm = 0.7983
	sim_grads_norm_tr = 0.1697
-- Starting training on experience 674 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7843
	data_grads_norm = 3.1442
	new_data_grads_norm = 0.6836
	old_data_grads_norm = 7.6722
	sim_grads_norm_tr = -0.0268
-- Starting training on experience 675 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4304
	data_grads_norm = 3.7815
	new_data_grads_norm = 3.9273
	old_data_grads_norm = 3.8940
	sim_grads_norm_tr = 0.8184
-- Starting training on experience 676 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2199
	data_grads_norm = 1.9976
	new_data_grads_norm = 1.3071
	old_data_grads_norm = 3.6294
	sim_grads_norm_tr = 0.5722
-- Starting training on experience 677 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0958
	data_grads_norm = 0.5897
	new_data_grads_norm = 0.9138
	old_data_grads_norm = 1.2493
	sim_grads_norm_tr = -0.1579
-- Starting training on experience 678 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1949
	data_grads_norm = 1.1386
	new_data_grads_norm = 0.8854
	old_data_grads_norm = 2.2010
	sim_grads_norm_tr = 0.2917
-- Starting training on experience 679 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1258
	data_grads_norm = 0.8676
	new_data_grads_norm = 0.5144
	old_data_grads_norm = 1.7961
	sim_grads_norm_tr = 0.1420
-- Starting training on experience 680 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2497
	data_grads_norm = 1.7443
	new_data_grads_norm = 1.2423
	old_data_grads_norm = 1.5885
	sim_grads_norm_tr = 0.4583
-- Starting training on experience 681 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1601
	data_grads_norm = 0.8744
	new_data_grads_norm = 1.2465
	old_data_grads_norm = 1.1032
	sim_grads_norm_tr = 0.1101
-- Starting training on experience 682 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0710
	data_grads_norm = 0.5946
	new_data_grads_norm = 6.3809
	old_data_grads_norm = 2.0072
	sim_grads_norm_tr = -0.1965
-- Starting training on experience 683 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1166
	data_grads_norm = 0.7138
	new_data_grads_norm = 1.1240
	old_data_grads_norm = 0.6931
	sim_grads_norm_tr = 0.0896
-- Starting training on experience 684 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4064
	data_grads_norm = 1.7710
	new_data_grads_norm = 2.6679
	old_data_grads_norm = 2.2088
	sim_grads_norm_tr = -0.0203
-- Starting training on experience 685 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1725
	data_grads_norm = 1.0402
	new_data_grads_norm = 1.0481
	old_data_grads_norm = 1.5030
	sim_grads_norm_tr = 0.2337
-- Starting training on experience 686 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2347
	data_grads_norm = 1.6381
	new_data_grads_norm = 3.6065
	old_data_grads_norm = 2.3381
	sim_grads_norm_tr = -0.1794
-- Starting training on experience 687 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3228
	data_grads_norm = 1.6750
	new_data_grads_norm = 0.7540
	old_data_grads_norm = 3.3929
	sim_grads_norm_tr = 0.1965
-- Starting training on experience 688 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2010
	data_grads_norm = 1.2535
	new_data_grads_norm = 1.0682
	old_data_grads_norm = 1.8919
	sim_grads_norm_tr = 0.3652
-- Starting training on experience 689 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1656
	data_grads_norm = 0.9475
	new_data_grads_norm = 0.6529
	old_data_grads_norm = 2.0482
	sim_grads_norm_tr = -0.3087
-- Starting training on experience 690 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1328
	data_grads_norm = 0.9522
	new_data_grads_norm = 0.9211
	old_data_grads_norm = 1.2416
	sim_grads_norm_tr = 0.2971
-- Starting training on experience 691 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2732
	data_grads_norm = 1.5104
	new_data_grads_norm = 4.1384
	old_data_grads_norm = 0.5610
	sim_grads_norm_tr = -0.0374
-- Starting training on experience 692 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1931
	data_grads_norm = 1.3623
	new_data_grads_norm = 3.3948
	old_data_grads_norm = 0.8473
	sim_grads_norm_tr = 0.1791
-- Starting training on experience 693 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2821
	data_grads_norm = 1.7120
	new_data_grads_norm = 5.8753
	old_data_grads_norm = 0.9263
	sim_grads_norm_tr = -0.2983
-- Starting training on experience 694 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1382
	data_grads_norm = 0.9964
	new_data_grads_norm = 0.8156
	old_data_grads_norm = 1.4198
	sim_grads_norm_tr = 0.0143
-- Starting training on experience 695 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1658
	data_grads_norm = 0.9337
	new_data_grads_norm = 1.2507
	old_data_grads_norm = 1.0289
	sim_grads_norm_tr = 0.4270
-- Starting training on experience 696 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1325
	data_grads_norm = 1.0606
	new_data_grads_norm = 2.0235
	old_data_grads_norm = 0.8075
	sim_grads_norm_tr = 0.0402
-- Starting training on experience 697 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2918
	data_grads_norm = 1.3979
	new_data_grads_norm = 4.6837
	old_data_grads_norm = 1.9285
	sim_grads_norm_tr = -0.2862
-- Starting training on experience 698 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1230
	data_grads_norm = 0.9622
	new_data_grads_norm = 2.9312
	old_data_grads_norm = 0.7988
	sim_grads_norm_tr = 0.1329
-- Starting training on experience 699 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1061
	data_grads_norm = 1.0984
	new_data_grads_norm = 2.9795
	old_data_grads_norm = 0.5252
	sim_grads_norm_tr = -0.0246
-- Starting training on experience 700 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2336
	data_grads_norm = 1.5365
	new_data_grads_norm = 4.2016
	old_data_grads_norm = 0.8617
	sim_grads_norm_tr = -0.1731
-- Starting training on experience 701 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2022
	data_grads_norm = 1.0404
	new_data_grads_norm = 2.1479
	old_data_grads_norm = 0.6109
	sim_grads_norm_tr = -0.1507
-- Starting training on experience 702 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2233
	data_grads_norm = 1.4787
	new_data_grads_norm = 7.0284
	old_data_grads_norm = 0.8354
	sim_grads_norm_tr = 0.1645
-- Starting training on experience 703 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7016
	data_grads_norm = 3.6190
	new_data_grads_norm = 3.4162
	old_data_grads_norm = 6.9874
	sim_grads_norm_tr = 0.1897
-- Starting training on experience 704 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2820
	data_grads_norm = 1.9878
	new_data_grads_norm = 1.4102
	old_data_grads_norm = 2.7454
	sim_grads_norm_tr = 0.0608
-- Starting training on experience 705 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1837
	data_grads_norm = 1.0526
	new_data_grads_norm = 2.0920
	old_data_grads_norm = 0.7369
	sim_grads_norm_tr = 0.1927
-- Starting training on experience 706 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0902
	data_grads_norm = 0.5061
	new_data_grads_norm = 0.5341
	old_data_grads_norm = 0.6341
	sim_grads_norm_tr = 0.2541
-- Starting training on experience 707 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1152
	data_grads_norm = 0.5975
	new_data_grads_norm = 0.6678
	old_data_grads_norm = 1.1994
	sim_grads_norm_tr = -0.1369
-- Starting training on experience 708 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1803
	data_grads_norm = 1.2120
	new_data_grads_norm = 1.0119
	old_data_grads_norm = 2.5647
	sim_grads_norm_tr = -0.1439
-- Starting training on experience 709 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0665
	data_grads_norm = 0.4811
	new_data_grads_norm = 0.7542
	old_data_grads_norm = 1.2610
	sim_grads_norm_tr = -0.2156
-- Starting training on experience 710 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1008
	data_grads_norm = 0.6806
	new_data_grads_norm = 0.7049
	old_data_grads_norm = 0.8236
	sim_grads_norm_tr = 0.2877
-- Starting training on experience 711 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1885
	data_grads_norm = 3.1128
	new_data_grads_norm = 0.8123
	old_data_grads_norm = 6.5306
	sim_grads_norm_tr = -0.0133
-- Starting training on experience 712 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3666
	data_grads_norm = 1.9426
	new_data_grads_norm = 2.0160
	old_data_grads_norm = 2.5686
	sim_grads_norm_tr = 0.4535
-- Starting training on experience 713 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0496
	data_grads_norm = 0.4063
	new_data_grads_norm = 0.9624
	old_data_grads_norm = 0.4034
	sim_grads_norm_tr = -0.0442
-- Starting training on experience 714 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2388
	data_grads_norm = 1.4299
	new_data_grads_norm = 2.9002
	old_data_grads_norm = 1.3874
	sim_grads_norm_tr = -0.0696
-- Starting training on experience 715 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3047
	data_grads_norm = 1.8512
	new_data_grads_norm = 0.8439
	old_data_grads_norm = 3.7325
	sim_grads_norm_tr = 0.1302
-- Starting training on experience 716 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1615
	data_grads_norm = 1.1580
	new_data_grads_norm = 1.7270
	old_data_grads_norm = 0.9715
	sim_grads_norm_tr = 0.2943
-- Starting training on experience 717 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3552
	data_grads_norm = 1.9028
	new_data_grads_norm = 3.4177
	old_data_grads_norm = 2.0554
	sim_grads_norm_tr = 0.0859
-- Starting training on experience 718 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0983
	data_grads_norm = 0.6673
	new_data_grads_norm = 1.4463
	old_data_grads_norm = 0.4827
	sim_grads_norm_tr = 0.0069
-- Starting training on experience 719 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1014
	data_grads_norm = 0.5949
	new_data_grads_norm = 0.8017
	old_data_grads_norm = 0.6425
	sim_grads_norm_tr = -0.0455
-- Starting training on experience 720 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1956
	data_grads_norm = 1.3955
	new_data_grads_norm = 0.8366
	old_data_grads_norm = 3.0096
	sim_grads_norm_tr = 0.1808
-- Starting training on experience 721 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1909
	data_grads_norm = 1.2237
	new_data_grads_norm = 1.6486
	old_data_grads_norm = 2.3283
	sim_grads_norm_tr = -0.3276
-- Starting training on experience 722 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2949
	data_grads_norm = 1.3721
	new_data_grads_norm = 1.4149
	old_data_grads_norm = 2.6266
	sim_grads_norm_tr = -0.0552
-- Starting training on experience 723 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2145
	data_grads_norm = 1.0815
	new_data_grads_norm = 2.7271
	old_data_grads_norm = 0.3532
	sim_grads_norm_tr = -0.2322
-- Starting training on experience 724 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3521
	data_grads_norm = 1.0791
	new_data_grads_norm = 2.6711
	old_data_grads_norm = 0.6351
	sim_grads_norm_tr = -0.2501
-- Starting training on experience 725 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1538
	data_grads_norm = 1.3009
	new_data_grads_norm = 2.6212
	old_data_grads_norm = 0.5864
	sim_grads_norm_tr = 0.4733
-- Starting training on experience 726 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.5023
	data_grads_norm = 2.4863
	new_data_grads_norm = 2.8560
	old_data_grads_norm = 2.9333
	sim_grads_norm_tr = 0.1314
-- Starting training on experience 727 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1254
	data_grads_norm = 0.6529
	new_data_grads_norm = 1.7232
	old_data_grads_norm = 0.6131
	sim_grads_norm_tr = -0.1478
-- Starting training on experience 728 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0905
	data_grads_norm = 0.8159
	new_data_grads_norm = 1.5660
	old_data_grads_norm = 0.7110
	sim_grads_norm_tr = 0.0644
-- Starting training on experience 729 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1097
	data_grads_norm = 0.9166
	new_data_grads_norm = 1.1750
	old_data_grads_norm = 0.7915
	sim_grads_norm_tr = 0.0647
-- Starting training on experience 730 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3460
	data_grads_norm = 1.5934
	new_data_grads_norm = 3.6213
	old_data_grads_norm = 1.3038
	sim_grads_norm_tr = 0.0516
-- Starting training on experience 731 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1751
	data_grads_norm = 1.0835
	new_data_grads_norm = 1.0731
	old_data_grads_norm = 1.5716
	sim_grads_norm_tr = 0.1441
-- Starting training on experience 732 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3616
	data_grads_norm = 2.2141
	new_data_grads_norm = 2.7848
	old_data_grads_norm = 2.8234
	sim_grads_norm_tr = 0.1404
-- Starting training on experience 733 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1040
	data_grads_norm = 0.7184
	new_data_grads_norm = 0.8893
	old_data_grads_norm = 0.9065
	sim_grads_norm_tr = -0.0203
-- Starting training on experience 734 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2184
	data_grads_norm = 1.4018
	new_data_grads_norm = 0.6283
	old_data_grads_norm = 2.5620
	sim_grads_norm_tr = 0.1847
-- Starting training on experience 735 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2686
	data_grads_norm = 1.8470
	new_data_grads_norm = 3.8991
	old_data_grads_norm = 1.1985
	sim_grads_norm_tr = 0.2907
-- Starting training on experience 736 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2492
	data_grads_norm = 1.5324
	new_data_grads_norm = 1.7064
	old_data_grads_norm = 2.0988
	sim_grads_norm_tr = -0.0192
-- Starting training on experience 737 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1731
	data_grads_norm = 0.8268
	new_data_grads_norm = 1.5146
	old_data_grads_norm = 0.7936
	sim_grads_norm_tr = 0.1968
-- Starting training on experience 738 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1458
	data_grads_norm = 0.7379
	new_data_grads_norm = 1.2992
	old_data_grads_norm = 0.8028
	sim_grads_norm_tr = -0.0879
-- Starting training on experience 739 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4449
	data_grads_norm = 2.3819
	new_data_grads_norm = 1.5626
	old_data_grads_norm = 4.8360
	sim_grads_norm_tr = 0.3044
-- Starting training on experience 740 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1883
	data_grads_norm = 0.8437
	new_data_grads_norm = 0.9822
	old_data_grads_norm = 1.3402
	sim_grads_norm_tr = 0.1853
-- Starting training on experience 741 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1087
	data_grads_norm = 0.6950
	new_data_grads_norm = 1.2705
	old_data_grads_norm = 1.2316
	sim_grads_norm_tr = -0.2837
-- Starting training on experience 742 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2965
	data_grads_norm = 1.2365
	new_data_grads_norm = 3.3380
	old_data_grads_norm = 0.8800
	sim_grads_norm_tr = -0.3104
-- Starting training on experience 743 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4953
	data_grads_norm = 2.1951
	new_data_grads_norm = 1.6934
	old_data_grads_norm = 3.3449
	sim_grads_norm_tr = 0.3360
-- Starting training on experience 744 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3331
	data_grads_norm = 1.2072
	new_data_grads_norm = 1.0705
	old_data_grads_norm = 2.4019
	sim_grads_norm_tr = -0.2673
-- Starting training on experience 745 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3119
	data_grads_norm = 1.8258
	new_data_grads_norm = 2.5349
	old_data_grads_norm = 1.9317
	sim_grads_norm_tr = 0.4421
-- Starting training on experience 746 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2125
	data_grads_norm = 1.0258
	new_data_grads_norm = 1.1058
	old_data_grads_norm = 1.5411
	sim_grads_norm_tr = 0.2220
-- Starting training on experience 747 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0941
	data_grads_norm = 0.5549
	new_data_grads_norm = 0.8613
	old_data_grads_norm = 0.5857
	sim_grads_norm_tr = 0.2044
-- Starting training on experience 748 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2893
	data_grads_norm = 1.0922
	new_data_grads_norm = 2.1140
	old_data_grads_norm = 2.7600
	sim_grads_norm_tr = -0.2681
-- Starting training on experience 749 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1728
	data_grads_norm = 0.6550
	new_data_grads_norm = 1.3289
	old_data_grads_norm = 0.6501
	sim_grads_norm_tr = 0.1071
-- Starting training on experience 750 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2320
	data_grads_norm = 0.9245
	new_data_grads_norm = 1.4143
	old_data_grads_norm = 1.9642
	sim_grads_norm_tr = -0.1704
-- Starting training on experience 751 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1769
	data_grads_norm = 1.3587
	new_data_grads_norm = 2.7592
	old_data_grads_norm = 0.7069
	sim_grads_norm_tr = 0.2393
-- Starting training on experience 752 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2137
	data_grads_norm = 1.4056
	new_data_grads_norm = 3.1089
	old_data_grads_norm = 1.4479
	sim_grads_norm_tr = -0.1950
-- Starting training on experience 753 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0944
	data_grads_norm = 0.6230
	new_data_grads_norm = 1.4504
	old_data_grads_norm = 0.7837
	sim_grads_norm_tr = -0.1848
-- Starting training on experience 754 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1361
	data_grads_norm = 1.2164
	new_data_grads_norm = 1.9620
	old_data_grads_norm = 0.6963
	sim_grads_norm_tr = 0.1666
-- Starting training on experience 755 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3731
	data_grads_norm = 2.8053
	new_data_grads_norm = 4.9742
	old_data_grads_norm = 1.5707
	sim_grads_norm_tr = -0.3305
-- Starting training on experience 756 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2766
	data_grads_norm = 1.4435
	new_data_grads_norm = 1.1290
	old_data_grads_norm = 3.9831
	sim_grads_norm_tr = -0.3619
-- Starting training on experience 757 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4964
	data_grads_norm = 3.2742
	new_data_grads_norm = 3.3240
	old_data_grads_norm = 3.9801
	sim_grads_norm_tr = 0.6307
-- Starting training on experience 758 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4988
	data_grads_norm = 2.2212
	new_data_grads_norm = 3.5981
	old_data_grads_norm = 3.0619
	sim_grads_norm_tr = -0.0120
-- Starting training on experience 759 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1396
	data_grads_norm = 0.5257
	new_data_grads_norm = 0.8540
	old_data_grads_norm = 0.5662
	sim_grads_norm_tr = 0.3218
-- Starting training on experience 760 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2126
	data_grads_norm = 1.4568
	new_data_grads_norm = 2.9039
	old_data_grads_norm = 0.6131
	sim_grads_norm_tr = -0.0433
-- Starting training on experience 761 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1192
	data_grads_norm = 0.5513
	new_data_grads_norm = 0.7884
	old_data_grads_norm = 0.3798
	sim_grads_norm_tr = -0.0776
-- Starting training on experience 762 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2879
	data_grads_norm = 1.3268
	new_data_grads_norm = 1.6232
	old_data_grads_norm = 1.5724
	sim_grads_norm_tr = 0.0318
-- Starting training on experience 763 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0826
	data_grads_norm = 0.5787
	new_data_grads_norm = 0.3750
	old_data_grads_norm = 3.5191
	sim_grads_norm_tr = -0.4225
-- Starting training on experience 764 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1538
	data_grads_norm = 0.9873
	new_data_grads_norm = 2.0739
	old_data_grads_norm = 0.8582
	sim_grads_norm_tr = 0.1102
-- Starting training on experience 765 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1481
	data_grads_norm = 1.1231
	new_data_grads_norm = 0.7566
	old_data_grads_norm = 1.8708
	sim_grads_norm_tr = 0.2444
-- Starting training on experience 766 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0783
	data_grads_norm = 0.6352
	new_data_grads_norm = 0.4284
	old_data_grads_norm = 1.0922
	sim_grads_norm_tr = 0.4492
-- Starting training on experience 767 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3119
	data_grads_norm = 1.4239
	new_data_grads_norm = 1.9392
	old_data_grads_norm = 1.9953
	sim_grads_norm_tr = -0.2135
-- Starting training on experience 768 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1062
	data_grads_norm = 0.9178
	new_data_grads_norm = 0.7069
	old_data_grads_norm = 3.3382
	sim_grads_norm_tr = -0.2130
-- Starting training on experience 769 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1009
	data_grads_norm = 1.0296
	new_data_grads_norm = 1.3611
	old_data_grads_norm = 2.3310
	sim_grads_norm_tr = -0.3652
-- Starting training on experience 770 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1352
	data_grads_norm = 0.7841
	new_data_grads_norm = 0.5603
	old_data_grads_norm = 1.6939
	sim_grads_norm_tr = -0.2394
-- Starting training on experience 771 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0441
	data_grads_norm = 0.3744
	new_data_grads_norm = 0.2379
	old_data_grads_norm = 1.7436
	sim_grads_norm_tr = -0.2366
-- Starting training on experience 772 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.5476
	data_grads_norm = 2.2938
	new_data_grads_norm = 4.9423
	old_data_grads_norm = 1.4539
	sim_grads_norm_tr = 0.0770
-- Starting training on experience 773 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4603
	data_grads_norm = 2.1882
	new_data_grads_norm = 2.7304
	old_data_grads_norm = 2.4490
	sim_grads_norm_tr = 0.2877
-- Starting training on experience 774 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.5965
	data_grads_norm = 2.6112
	new_data_grads_norm = 3.9350
	old_data_grads_norm = 3.2990
	sim_grads_norm_tr = 0.0202
-- Starting training on experience 775 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1191
	data_grads_norm = 0.6351
	new_data_grads_norm = 0.8569
	old_data_grads_norm = 1.4554
	sim_grads_norm_tr = -0.1070
-- Starting training on experience 776 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1330
	data_grads_norm = 1.1367
	new_data_grads_norm = 2.8149
	old_data_grads_norm = 0.5570
	sim_grads_norm_tr = 0.2325
-- Starting training on experience 777 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1147
	data_grads_norm = 0.6462
	new_data_grads_norm = 0.7897
	old_data_grads_norm = 1.1197
	sim_grads_norm_tr = -0.0328
-- Starting training on experience 778 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2526
	data_grads_norm = 1.0315
	new_data_grads_norm = 1.0185
	old_data_grads_norm = 1.9539
	sim_grads_norm_tr = -0.1125
-- Starting training on experience 779 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1438
	data_grads_norm = 0.9791
	new_data_grads_norm = 1.9068
	old_data_grads_norm = 0.4931
	sim_grads_norm_tr = -0.0267
-- Starting training on experience 780 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1424
	data_grads_norm = 0.6259
	new_data_grads_norm = 2.0843
	old_data_grads_norm = 1.4653
	sim_grads_norm_tr = -0.0900
-- Starting training on experience 781 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3000
	data_grads_norm = 1.6054
	new_data_grads_norm = 1.5564
	old_data_grads_norm = 2.2714
	sim_grads_norm_tr = 0.3618
-- Starting training on experience 782 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1715
	data_grads_norm = 0.9634
	new_data_grads_norm = 0.8879
	old_data_grads_norm = 1.2181
	sim_grads_norm_tr = 0.3030
-- Starting training on experience 783 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1311
	data_grads_norm = 0.8696
	new_data_grads_norm = 1.1025
	old_data_grads_norm = 1.0969
	sim_grads_norm_tr = 0.0318
-- Starting training on experience 784 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1211
	data_grads_norm = 0.9283
	new_data_grads_norm = 1.0969
	old_data_grads_norm = 1.5877
	sim_grads_norm_tr = 0.0612
-- Starting training on experience 785 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1379
	data_grads_norm = 0.6376
	new_data_grads_norm = 3.6494
	old_data_grads_norm = 0.6143
	sim_grads_norm_tr = -0.3592
-- Starting training on experience 786 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2076
	data_grads_norm = 1.4226
	new_data_grads_norm = 1.7745
	old_data_grads_norm = 1.9053
	sim_grads_norm_tr = 0.1164
-- Starting training on experience 787 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1059
	data_grads_norm = 0.8613
	new_data_grads_norm = 0.8085
	old_data_grads_norm = 1.0560
	sim_grads_norm_tr = 0.1394
-- Starting training on experience 788 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.5105
	data_grads_norm = 2.1099
	new_data_grads_norm = 1.8619
	old_data_grads_norm = 3.9183
	sim_grads_norm_tr = 0.1294
-- Starting training on experience 789 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1307
	data_grads_norm = 0.8976
	new_data_grads_norm = 0.8044
	old_data_grads_norm = 1.6258
	sim_grads_norm_tr = 0.2865
-- Starting training on experience 790 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1940
	data_grads_norm = 1.0932
	new_data_grads_norm = 0.9417
	old_data_grads_norm = 1.8042
	sim_grads_norm_tr = 0.3443
-- Starting training on experience 791 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1137
	data_grads_norm = 0.7238
	new_data_grads_norm = 0.2487
	old_data_grads_norm = 1.4248
	sim_grads_norm_tr = 0.1698
-- Starting training on experience 792 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2712
	data_grads_norm = 1.5160
	new_data_grads_norm = 1.8287
	old_data_grads_norm = 0.9346
	sim_grads_norm_tr = -0.0494
-- Starting training on experience 793 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1611
	data_grads_norm = 0.9387
	new_data_grads_norm = 1.9279
	old_data_grads_norm = 0.8622
	sim_grads_norm_tr = 0.0917
-- Starting training on experience 794 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3599
	data_grads_norm = 2.1974
	new_data_grads_norm = 5.0070
	old_data_grads_norm = 0.9251
	sim_grads_norm_tr = 0.0435
-- Starting training on experience 795 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7332
	data_grads_norm = 2.7234
	new_data_grads_norm = 4.2434
	old_data_grads_norm = 3.3146
	sim_grads_norm_tr = 0.2715
-- Starting training on experience 796 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3337
	data_grads_norm = 1.8084
	new_data_grads_norm = 1.5790
	old_data_grads_norm = 3.7123
	sim_grads_norm_tr = 0.0197
-- Starting training on experience 797 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2645
	data_grads_norm = 3.1884
	new_data_grads_norm = 2.9747
	old_data_grads_norm = 0.9970
	sim_grads_norm_tr = 0.2892
-- Starting training on experience 798 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1459
	data_grads_norm = 1.1897
	new_data_grads_norm = 0.5502
	old_data_grads_norm = 2.1262
	sim_grads_norm_tr = 0.2121
-- Starting training on experience 799 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3424
	data_grads_norm = 2.2057
	new_data_grads_norm = 3.8371
	old_data_grads_norm = 1.9669
	sim_grads_norm_tr = 0.2724
-- Starting training on experience 800 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1950
	data_grads_norm = 1.2873
	new_data_grads_norm = 1.4880
	old_data_grads_norm = 1.4621
	sim_grads_norm_tr = 0.0138
-- Starting training on experience 801 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1445
	data_grads_norm = 0.7113
	new_data_grads_norm = 0.5190
	old_data_grads_norm = 1.5587
	sim_grads_norm_tr = 0.2039
-- Starting training on experience 802 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0944
	data_grads_norm = 0.9323
	new_data_grads_norm = 0.8129
	old_data_grads_norm = 1.0803
	sim_grads_norm_tr = 0.4102
-- Starting training on experience 803 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0852
	data_grads_norm = 0.5859
	new_data_grads_norm = 0.6231
	old_data_grads_norm = 1.4771
	sim_grads_norm_tr = -0.2863
-- Starting training on experience 804 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2479
	data_grads_norm = 2.3546
	new_data_grads_norm = 3.2843
	old_data_grads_norm = 3.9333
	sim_grads_norm_tr = -0.1932
-- Starting training on experience 805 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4461
	data_grads_norm = 2.6982
	new_data_grads_norm = 3.8060
	old_data_grads_norm = 3.2683
	sim_grads_norm_tr = 0.2616
-- Starting training on experience 806 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4284
	data_grads_norm = 2.4772
	new_data_grads_norm = 4.4858
	old_data_grads_norm = 2.2250
	sim_grads_norm_tr = -0.1654
-- Starting training on experience 807 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2996
	data_grads_norm = 1.8153
	new_data_grads_norm = 2.5606
	old_data_grads_norm = 2.5773
	sim_grads_norm_tr = -0.2024
-- Starting training on experience 808 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2823
	data_grads_norm = 1.6866
	new_data_grads_norm = 3.5224
	old_data_grads_norm = 0.9804
	sim_grads_norm_tr = -0.2765
-- Starting training on experience 809 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2913
	data_grads_norm = 2.1038
	new_data_grads_norm = 4.8299
	old_data_grads_norm = 3.6816
	sim_grads_norm_tr = -0.0075
-- Starting training on experience 810 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1867
	data_grads_norm = 1.6062
	new_data_grads_norm = 0.5628
	old_data_grads_norm = 4.9019
	sim_grads_norm_tr = 0.4762
-- Starting training on experience 811 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3680
	data_grads_norm = 1.7890
	new_data_grads_norm = 3.9196
	old_data_grads_norm = 1.1184
	sim_grads_norm_tr = 0.1197
-- Starting training on experience 812 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2467
	data_grads_norm = 1.3418
	new_data_grads_norm = 1.5139
	old_data_grads_norm = 2.8781
	sim_grads_norm_tr = 0.0796
-- Starting training on experience 813 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3167
	data_grads_norm = 2.5878
	new_data_grads_norm = 4.4985
	old_data_grads_norm = 1.0979
	sim_grads_norm_tr = 0.2865
-- Starting training on experience 814 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2300
	data_grads_norm = 0.9141
	new_data_grads_norm = 1.2615
	old_data_grads_norm = 1.3495
	sim_grads_norm_tr = 0.2555
-- Starting training on experience 815 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3531
	data_grads_norm = 2.5094
	new_data_grads_norm = 3.5944
	old_data_grads_norm = 1.6347
	sim_grads_norm_tr = 0.2762
-- Starting training on experience 816 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3341
	data_grads_norm = 1.8377
	new_data_grads_norm = 1.9844
	old_data_grads_norm = 2.2130
	sim_grads_norm_tr = 0.2071
-- Starting training on experience 817 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1240
	data_grads_norm = 0.9666
	new_data_grads_norm = 2.0872
	old_data_grads_norm = 1.4854
	sim_grads_norm_tr = -0.0472
-- Starting training on experience 818 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0806
	data_grads_norm = 0.5166
	new_data_grads_norm = 0.8375
	old_data_grads_norm = 0.2820
	sim_grads_norm_tr = 0.1861
-- Starting training on experience 819 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1672
	data_grads_norm = 0.9018
	new_data_grads_norm = 1.2887
	old_data_grads_norm = 1.7582
	sim_grads_norm_tr = -0.2133
-- Starting training on experience 820 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2458
	data_grads_norm = 1.2579
	new_data_grads_norm = 4.2893
	old_data_grads_norm = 1.4262
	sim_grads_norm_tr = 0.1285
-- Starting training on experience 821 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8054
	data_grads_norm = 3.4340
	new_data_grads_norm = 3.4130
	old_data_grads_norm = 6.2519
	sim_grads_norm_tr = 0.3882
-- Starting training on experience 822 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3531
	data_grads_norm = 1.9787
	new_data_grads_norm = 0.9321
	old_data_grads_norm = 2.7095
	sim_grads_norm_tr = 0.1436
-- Starting training on experience 823 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1894
	data_grads_norm = 1.2720
	new_data_grads_norm = 1.1994
	old_data_grads_norm = 1.3795
	sim_grads_norm_tr = 0.8169
-- Starting training on experience 824 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2215
	data_grads_norm = 0.9817
	new_data_grads_norm = 1.6746
	old_data_grads_norm = 0.8094
	sim_grads_norm_tr = 0.0606
-- Starting training on experience 825 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2843
	data_grads_norm = 1.2471
	new_data_grads_norm = 2.5912
	old_data_grads_norm = 0.9070
	sim_grads_norm_tr = 0.2418
-- Starting training on experience 826 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2958
	data_grads_norm = 1.5139
	new_data_grads_norm = 5.8901
	old_data_grads_norm = 0.4672
	sim_grads_norm_tr = -0.1945
-- Starting training on experience 827 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3322
	data_grads_norm = 1.8807
	new_data_grads_norm = 5.4464
	old_data_grads_norm = 0.8480
	sim_grads_norm_tr = -0.0769
-- Starting training on experience 828 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2178
	data_grads_norm = 1.1439
	new_data_grads_norm = 1.8302
	old_data_grads_norm = 0.8601
	sim_grads_norm_tr = 0.3164
-- Starting training on experience 829 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1985
	data_grads_norm = 1.2351
	new_data_grads_norm = 0.8706
	old_data_grads_norm = 2.0434
	sim_grads_norm_tr = 0.5695
-- Starting training on experience 830 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2149
	data_grads_norm = 1.0274
	new_data_grads_norm = 1.4059
	old_data_grads_norm = 0.6463
	sim_grads_norm_tr = 0.1145
-- Starting training on experience 831 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1284
	data_grads_norm = 0.7147
	new_data_grads_norm = 1.0786
	old_data_grads_norm = 1.6146
	sim_grads_norm_tr = -0.2538
-- Starting training on experience 832 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1303
	data_grads_norm = 0.7610
	new_data_grads_norm = 1.0175
	old_data_grads_norm = 1.3154
	sim_grads_norm_tr = -0.1244
-- Starting training on experience 833 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1598
	data_grads_norm = 1.3917
	new_data_grads_norm = 0.9092
	old_data_grads_norm = 1.9540
	sim_grads_norm_tr = 0.2628
-- Starting training on experience 834 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1224
	data_grads_norm = 0.7574
	new_data_grads_norm = 1.6179
	old_data_grads_norm = 3.8045
	sim_grads_norm_tr = -0.2669
-- Starting training on experience 835 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1950
	data_grads_norm = 1.1513
	new_data_grads_norm = 1.5594
	old_data_grads_norm = 1.8727
	sim_grads_norm_tr = -0.3887
-- Starting training on experience 836 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3778
	data_grads_norm = 1.3558
	new_data_grads_norm = 1.3405
	old_data_grads_norm = 2.7759
	sim_grads_norm_tr = 0.0321
-- Starting training on experience 837 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2254
	data_grads_norm = 0.9944
	new_data_grads_norm = 2.2712
	old_data_grads_norm = 0.7533
	sim_grads_norm_tr = -0.2955
-- Starting training on experience 838 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3302
	data_grads_norm = 1.5860
	new_data_grads_norm = 3.3528
	old_data_grads_norm = 1.3422
	sim_grads_norm_tr = 0.0845
-- Starting training on experience 839 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3064
	data_grads_norm = 1.6534
	new_data_grads_norm = 2.7663
	old_data_grads_norm = 2.1343
	sim_grads_norm_tr = -0.0107
-- Starting training on experience 840 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4430
	data_grads_norm = 1.6615
	new_data_grads_norm = 0.9957
	old_data_grads_norm = 4.1260
	sim_grads_norm_tr = -0.2775
-- Starting training on experience 841 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2942
	data_grads_norm = 1.3642
	new_data_grads_norm = 2.2556
	old_data_grads_norm = 1.0785
	sim_grads_norm_tr = 0.3248
-- Starting training on experience 842 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1929
	data_grads_norm = 1.0670
	new_data_grads_norm = 1.2822
	old_data_grads_norm = 1.2744
	sim_grads_norm_tr = 0.4074
-- Starting training on experience 843 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3069
	data_grads_norm = 1.5824
	new_data_grads_norm = 5.4673
	old_data_grads_norm = 1.4186
	sim_grads_norm_tr = 0.0013
-- Starting training on experience 844 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1609
	data_grads_norm = 0.8928
	new_data_grads_norm = 1.9005
	old_data_grads_norm = 0.8208
	sim_grads_norm_tr = -0.0140
-- Starting training on experience 845 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3247
	data_grads_norm = 1.2500
	new_data_grads_norm = 1.1297
	old_data_grads_norm = 2.1546
	sim_grads_norm_tr = 0.3354
-- Starting training on experience 846 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1419
	data_grads_norm = 0.6840
	new_data_grads_norm = 0.5076
	old_data_grads_norm = 1.8426
	sim_grads_norm_tr = 0.2488
-- Starting training on experience 847 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0516
	data_grads_norm = 0.4371
	new_data_grads_norm = 1.6232
	old_data_grads_norm = 1.4716
	sim_grads_norm_tr = -0.2515
-- Starting training on experience 848 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1519
	data_grads_norm = 0.7415
	new_data_grads_norm = 1.0564
	old_data_grads_norm = 1.1238
	sim_grads_norm_tr = -0.0251
-- Starting training on experience 849 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2945
	data_grads_norm = 1.6486
	new_data_grads_norm = 1.7674
	old_data_grads_norm = 1.6396
	sim_grads_norm_tr = 0.0819
-- Starting training on experience 850 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1267
	data_grads_norm = 0.7083
	new_data_grads_norm = 1.3755
	old_data_grads_norm = 0.8264
	sim_grads_norm_tr = -0.3470
-- Starting training on experience 851 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2793
	data_grads_norm = 1.4790
	new_data_grads_norm = 1.9709
	old_data_grads_norm = 1.6760
	sim_grads_norm_tr = 0.4368
-- Starting training on experience 852 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3108
	data_grads_norm = 2.0646
	new_data_grads_norm = 4.5362
	old_data_grads_norm = 1.1446
	sim_grads_norm_tr = 0.3113
-- Starting training on experience 853 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2509
	data_grads_norm = 1.2918
	new_data_grads_norm = 2.2540
	old_data_grads_norm = 1.1749
	sim_grads_norm_tr = 0.0690
-- Starting training on experience 854 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2509
	data_grads_norm = 1.4541
	new_data_grads_norm = 5.3042
	old_data_grads_norm = 0.8098
	sim_grads_norm_tr = -0.1050
-- Starting training on experience 855 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3261
	data_grads_norm = 2.1737
	new_data_grads_norm = 4.7010
	old_data_grads_norm = 1.5730
	sim_grads_norm_tr = 0.0047
-- Starting training on experience 856 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2722
	data_grads_norm = 2.1235
	new_data_grads_norm = 1.1407
	old_data_grads_norm = 2.8924
	sim_grads_norm_tr = -0.0504
-- Starting training on experience 857 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1402
	data_grads_norm = 0.8441
	new_data_grads_norm = 1.7829
	old_data_grads_norm = 0.6243
	sim_grads_norm_tr = 0.2102
-- Starting training on experience 858 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0861
	data_grads_norm = 0.7394
	new_data_grads_norm = 0.7133
	old_data_grads_norm = 1.2633
	sim_grads_norm_tr = 0.0330
-- Starting training on experience 859 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3544
	data_grads_norm = 2.0941
	new_data_grads_norm = 5.5476
	old_data_grads_norm = 0.7372
	sim_grads_norm_tr = 0.2819
-- Starting training on experience 860 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2436
	data_grads_norm = 1.3373
	new_data_grads_norm = 1.4752
	old_data_grads_norm = 2.4510
	sim_grads_norm_tr = -0.0544
-- Starting training on experience 861 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1865
	data_grads_norm = 2.3438
	new_data_grads_norm = 4.0518
	old_data_grads_norm = 4.8118
	sim_grads_norm_tr = 0.4123
-- Starting training on experience 862 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1872
	data_grads_norm = 1.3125
	new_data_grads_norm = 0.7215
	old_data_grads_norm = 3.3959
	sim_grads_norm_tr = -0.0756
-- Starting training on experience 863 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2548
	data_grads_norm = 1.4189
	new_data_grads_norm = 0.5553
	old_data_grads_norm = 3.4781
	sim_grads_norm_tr = -0.2412
-- Starting training on experience 864 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2247
	data_grads_norm = 1.3936
	new_data_grads_norm = 2.4992
	old_data_grads_norm = 0.6936
	sim_grads_norm_tr = -0.2744
-- Starting training on experience 865 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2433
	data_grads_norm = 1.0451
	new_data_grads_norm = 0.6227
	old_data_grads_norm = 2.7998
	sim_grads_norm_tr = -0.0733
-- Starting training on experience 866 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.6293
	data_grads_norm = 2.6224
	new_data_grads_norm = 1.6195
	old_data_grads_norm = 4.2352
	sim_grads_norm_tr = 0.3067
-- Starting training on experience 867 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0777
	data_grads_norm = 0.5535
	new_data_grads_norm = 1.1016
	old_data_grads_norm = 0.5589
	sim_grads_norm_tr = 0.1422
-- Starting training on experience 868 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4346
	data_grads_norm = 1.5897
	new_data_grads_norm = 3.1344
	old_data_grads_norm = 2.0987
	sim_grads_norm_tr = -0.0855
-- Starting training on experience 869 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1949
	data_grads_norm = 0.8928
	new_data_grads_norm = 1.4090
	old_data_grads_norm = 0.9383
	sim_grads_norm_tr = 0.0845
-- Starting training on experience 870 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1718
	data_grads_norm = 0.7939
	new_data_grads_norm = 1.3195
	old_data_grads_norm = 1.2849
	sim_grads_norm_tr = -0.3012
-- Starting training on experience 871 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1661
	data_grads_norm = 0.6985
	new_data_grads_norm = 0.7504
	old_data_grads_norm = 1.0782
	sim_grads_norm_tr = 0.1848
-- Starting training on experience 872 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2689
	data_grads_norm = 1.9304
	new_data_grads_norm = 2.3034
	old_data_grads_norm = 1.4477
	sim_grads_norm_tr = -0.1497
-- Starting training on experience 873 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1345
	data_grads_norm = 0.6645
	new_data_grads_norm = 2.5541
	old_data_grads_norm = 1.1085
	sim_grads_norm_tr = -0.1765
-- Starting training on experience 874 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1376
	data_grads_norm = 0.6908
	new_data_grads_norm = 1.0480
	old_data_grads_norm = 1.1023
	sim_grads_norm_tr = -0.1256
-- Starting training on experience 875 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2120
	data_grads_norm = 1.2404
	new_data_grads_norm = 1.6106
	old_data_grads_norm = 1.1467
	sim_grads_norm_tr = 0.1955
-- Starting training on experience 876 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1176
	data_grads_norm = 0.7592
	new_data_grads_norm = 0.6985
	old_data_grads_norm = 1.4254
	sim_grads_norm_tr = -0.0589
-- Starting training on experience 877 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2306
	data_grads_norm = 1.0455
	new_data_grads_norm = 0.6813
	old_data_grads_norm = 2.1291
	sim_grads_norm_tr = 0.0799
-- Starting training on experience 878 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1037
	data_grads_norm = 0.7579
	new_data_grads_norm = 1.5722
	old_data_grads_norm = 0.7158
	sim_grads_norm_tr = -0.2112
-- Starting training on experience 879 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3791
	data_grads_norm = 1.7740
	new_data_grads_norm = 3.0076
	old_data_grads_norm = 2.1242
	sim_grads_norm_tr = -0.2169
-- Starting training on experience 880 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2416
	data_grads_norm = 1.3392
	new_data_grads_norm = 2.7464
	old_data_grads_norm = 0.8910
	sim_grads_norm_tr = 0.2598
-- Starting training on experience 881 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1459
	data_grads_norm = 0.9731
	new_data_grads_norm = 2.3051
	old_data_grads_norm = 1.2687
	sim_grads_norm_tr = 0.0411
-- Starting training on experience 882 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2091
	data_grads_norm = 1.6752
	new_data_grads_norm = 1.2833
	old_data_grads_norm = 2.4260
	sim_grads_norm_tr = 0.2479
-- Starting training on experience 883 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2876
	data_grads_norm = 1.5796
	new_data_grads_norm = 1.3368
	old_data_grads_norm = 4.7496
	sim_grads_norm_tr = 0.0113
-- Starting training on experience 884 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1507
	data_grads_norm = 1.4199
	new_data_grads_norm = 1.8185
	old_data_grads_norm = 1.7618
	sim_grads_norm_tr = 0.1711
-- Starting training on experience 885 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8245
	data_grads_norm = 2.4193
	new_data_grads_norm = 3.7689
	old_data_grads_norm = 2.6960
	sim_grads_norm_tr = 0.1142
-- Starting training on experience 886 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2383
	data_grads_norm = 1.0846
	new_data_grads_norm = 1.5048
	old_data_grads_norm = 1.0992
	sim_grads_norm_tr = 0.4635
-- Starting training on experience 887 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1325
	data_grads_norm = 1.0312
	new_data_grads_norm = 0.8017
	old_data_grads_norm = 1.7838
	sim_grads_norm_tr = 0.3901
-- Starting training on experience 888 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3036
	data_grads_norm = 1.4723
	new_data_grads_norm = 1.0365
	old_data_grads_norm = 2.7277
	sim_grads_norm_tr = -0.1259
-- Starting training on experience 889 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2812
	data_grads_norm = 1.1648
	new_data_grads_norm = 2.1913
	old_data_grads_norm = 1.1926
	sim_grads_norm_tr = -0.0405
-- Starting training on experience 890 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0774
	data_grads_norm = 0.6435
	new_data_grads_norm = 0.6084
	old_data_grads_norm = 1.9721
	sim_grads_norm_tr = -0.1712
-- Starting training on experience 891 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3155
	data_grads_norm = 1.8102
	new_data_grads_norm = 2.7733
	old_data_grads_norm = 2.4027
	sim_grads_norm_tr = -0.0771
-- Starting training on experience 892 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1054
	data_grads_norm = 0.6997
	new_data_grads_norm = 1.2211
	old_data_grads_norm = 1.5318
	sim_grads_norm_tr = -0.2267
-- Starting training on experience 893 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1314
	data_grads_norm = 0.7619
	new_data_grads_norm = 1.6681
	old_data_grads_norm = 0.7944
	sim_grads_norm_tr = 0.0684
-- Starting training on experience 894 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1113
	data_grads_norm = 0.7642
	new_data_grads_norm = 1.1167
	old_data_grads_norm = 0.7533
	sim_grads_norm_tr = 0.1694
-- Starting training on experience 895 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2950
	data_grads_norm = 1.5404
	new_data_grads_norm = 4.2302
	old_data_grads_norm = 0.2926
	sim_grads_norm_tr = -0.2712
-- Starting training on experience 896 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1290
	data_grads_norm = 0.7123
	new_data_grads_norm = 2.3213
	old_data_grads_norm = 0.8646
	sim_grads_norm_tr = -0.0790
-- Starting training on experience 897 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3268
	data_grads_norm = 2.3457
	new_data_grads_norm = 3.5506
	old_data_grads_norm = 1.9174
	sim_grads_norm_tr = 0.2496
-- Starting training on experience 898 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0588
	data_grads_norm = 0.5526
	new_data_grads_norm = 0.6824
	old_data_grads_norm = 0.3380
	sim_grads_norm_tr = 0.2129
-- Starting training on experience 899 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2493
	data_grads_norm = 1.7862
	new_data_grads_norm = 2.5493
	old_data_grads_norm = 0.9142
	sim_grads_norm_tr = 0.4208
-- Starting training on experience 900 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0675
	data_grads_norm = 0.5063
	new_data_grads_norm = 1.0405
	old_data_grads_norm = 0.4306
	sim_grads_norm_tr = -0.1672
-- Starting training on experience 901 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2065
	data_grads_norm = 1.1458
	new_data_grads_norm = 0.8136
	old_data_grads_norm = 2.2624
	sim_grads_norm_tr = -0.1958
-- Starting training on experience 902 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1667
	data_grads_norm = 1.0059
	new_data_grads_norm = 1.7606
	old_data_grads_norm = 1.1626
	sim_grads_norm_tr = 0.1946
-- Starting training on experience 903 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.5009
	data_grads_norm = 2.0840
	new_data_grads_norm = 3.0219
	old_data_grads_norm = 1.6874
	sim_grads_norm_tr = -0.3140
-- Starting training on experience 904 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1894
	data_grads_norm = 1.0196
	new_data_grads_norm = 2.9644
	old_data_grads_norm = 0.6413
	sim_grads_norm_tr = -0.1804
-- Starting training on experience 905 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1389
	data_grads_norm = 1.1271
	new_data_grads_norm = 1.2013
	old_data_grads_norm = 1.7206
	sim_grads_norm_tr = 0.1146
-- Starting training on experience 906 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2215
	data_grads_norm = 1.3263
	new_data_grads_norm = 3.7767
	old_data_grads_norm = 2.3306
	sim_grads_norm_tr = -0.1970
-- Starting training on experience 907 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2244
	data_grads_norm = 1.3955
	new_data_grads_norm = 1.7707
	old_data_grads_norm = 2.0599
	sim_grads_norm_tr = 0.0883
-- Starting training on experience 908 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1929
	data_grads_norm = 1.5271
	new_data_grads_norm = 2.0940
	old_data_grads_norm = 1.8563
	sim_grads_norm_tr = 0.3792
-- Starting training on experience 909 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0619
	data_grads_norm = 0.5654
	new_data_grads_norm = 2.9462
	old_data_grads_norm = 0.2911
	sim_grads_norm_tr = -0.2955
-- Starting training on experience 910 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2325
	data_grads_norm = 1.2885
	new_data_grads_norm = 2.4197
	old_data_grads_norm = 1.7073
	sim_grads_norm_tr = -0.3467
-- Starting training on experience 911 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1247
	data_grads_norm = 0.9357
	new_data_grads_norm = 3.9012
	old_data_grads_norm = 0.8117
	sim_grads_norm_tr = -0.2562
-- Starting training on experience 912 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.4762
	data_grads_norm = 2.4573
	new_data_grads_norm = 2.3569
	old_data_grads_norm = 9.4183
	sim_grads_norm_tr = -0.0809
-- Starting training on experience 913 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3899
	data_grads_norm = 2.4451
	new_data_grads_norm = 1.9143
	old_data_grads_norm = 3.2401
	sim_grads_norm_tr = 0.6883
-- Starting training on experience 914 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2422
	data_grads_norm = 1.4056
	new_data_grads_norm = 2.3476
	old_data_grads_norm = 1.2506
	sim_grads_norm_tr = 0.0905
-- Starting training on experience 915 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1503
	data_grads_norm = 1.0632
	new_data_grads_norm = 1.2250
	old_data_grads_norm = 1.0560
	sim_grads_norm_tr = 0.2821
-- Starting training on experience 916 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1532
	data_grads_norm = 0.7197
	new_data_grads_norm = 1.0050
	old_data_grads_norm = 1.9017
	sim_grads_norm_tr = 0.0780
-- Starting training on experience 917 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1699
	data_grads_norm = 0.5384
	new_data_grads_norm = 1.1642
	old_data_grads_norm = 0.3226
	sim_grads_norm_tr = -0.2055
-- Starting training on experience 918 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2103
	data_grads_norm = 1.4473
	new_data_grads_norm = 1.0580
	old_data_grads_norm = 1.6866
	sim_grads_norm_tr = 0.3412
-- Starting training on experience 919 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2581
	data_grads_norm = 1.2480
	new_data_grads_norm = 1.4101
	old_data_grads_norm = 2.0124
	sim_grads_norm_tr = -0.1293
-- Starting training on experience 920 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1006
	data_grads_norm = 0.7405
	new_data_grads_norm = 0.9083
	old_data_grads_norm = 0.8250
	sim_grads_norm_tr = -0.0908
-- Starting training on experience 921 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2032
	data_grads_norm = 1.1191
	new_data_grads_norm = 2.5289
	old_data_grads_norm = 0.5558
	sim_grads_norm_tr = -0.3330
-- Starting training on experience 922 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1857
	data_grads_norm = 1.3367
	new_data_grads_norm = 2.2562
	old_data_grads_norm = 1.4976
	sim_grads_norm_tr = 0.1304
-- Starting training on experience 923 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2630
	data_grads_norm = 1.9563
	new_data_grads_norm = 3.2715
	old_data_grads_norm = 0.6509
	sim_grads_norm_tr = 0.0814
-- Starting training on experience 924 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0755
	data_grads_norm = 0.5351
	new_data_grads_norm = 0.8465
	old_data_grads_norm = 0.8026
	sim_grads_norm_tr = -0.0364
-- Starting training on experience 925 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1052
	data_grads_norm = 0.6838
	new_data_grads_norm = 1.1264
	old_data_grads_norm = 1.0077
	sim_grads_norm_tr = 0.0061
-- Starting training on experience 926 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1069
	data_grads_norm = 0.6627
	new_data_grads_norm = 1.7780
	old_data_grads_norm = 1.9980
	sim_grads_norm_tr = -0.1988
-- Starting training on experience 927 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3324
	data_grads_norm = 1.8294
	new_data_grads_norm = 1.9154
	old_data_grads_norm = 2.4632
	sim_grads_norm_tr = 0.4419
-- Starting training on experience 928 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0957
	data_grads_norm = 0.6002
	new_data_grads_norm = 0.6404
	old_data_grads_norm = 0.7206
	sim_grads_norm_tr = -0.1488
-- Starting training on experience 929 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2358
	data_grads_norm = 1.9130
	new_data_grads_norm = 3.6585
	old_data_grads_norm = 2.0852
	sim_grads_norm_tr = 0.0251
-- Starting training on experience 930 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1482
	data_grads_norm = 0.8900
	new_data_grads_norm = 0.8002
	old_data_grads_norm = 2.2739
	sim_grads_norm_tr = -0.1138
-- Starting training on experience 931 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2602
	data_grads_norm = 0.9390
	new_data_grads_norm = 1.8538
	old_data_grads_norm = 0.7330
	sim_grads_norm_tr = -0.0853
-- Starting training on experience 932 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1566
	data_grads_norm = 0.6793
	new_data_grads_norm = 0.4722
	old_data_grads_norm = 1.2891
	sim_grads_norm_tr = -0.0331
-- Starting training on experience 933 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2838
	data_grads_norm = 1.3895
	new_data_grads_norm = 2.1003
	old_data_grads_norm = 2.4891
	sim_grads_norm_tr = -0.1457
-- Starting training on experience 934 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0988
	data_grads_norm = 1.1108
	new_data_grads_norm = 0.7353
	old_data_grads_norm = 1.6947
	sim_grads_norm_tr = 0.2067
-- Starting training on experience 935 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.3685
	data_grads_norm = 1.2710
	new_data_grads_norm = 1.4110
	old_data_grads_norm = 2.3083
	sim_grads_norm_tr = -0.0373
-- Starting training on experience 936 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1175
	data_grads_norm = 1.0318
	new_data_grads_norm = 1.3903
	old_data_grads_norm = 0.7618
	sim_grads_norm_tr = 0.3084
-- Starting training on experience 937 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2084
	data_grads_norm = 1.9636
	new_data_grads_norm = 1.6031
	old_data_grads_norm = 2.8014
	sim_grads_norm_tr = 0.0945
-- Starting training on experience 938 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2653
	data_grads_norm = 2.7978
	new_data_grads_norm = 4.9211
	old_data_grads_norm = 2.7117
	sim_grads_norm_tr = -0.0412
-- Starting training on experience 939 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.2116
	data_grads_norm = 1.0642
	new_data_grads_norm = 1.7436
	old_data_grads_norm = 2.0561
	sim_grads_norm_tr = -0.1374
-- Starting training on experience 940 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1360
	data_grads_norm = 0.7375
	new_data_grads_norm = 1.0913
	old_data_grads_norm = 0.9285
	sim_grads_norm_tr = -0.0914
-- Starting training on experience 941 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1793
	data_grads_norm = 0.9968
	new_data_grads_norm = 1.3594
	old_data_grads_norm = 0.5439
	sim_grads_norm_tr = -0.0373
-- Starting training on experience 942 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1675
	data_grads_norm = 1.2542
	new_data_grads_norm = 2.4794
	old_data_grads_norm = 3.4071
	sim_grads_norm_tr = -0.3371
-- Starting training on experience 943 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1396
	data_grads_norm = 0.8662
	new_data_grads_norm = 1.1534
	old_data_grads_norm = 0.6043
	sim_grads_norm_tr = -0.0952
-- Starting training on experience 944 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0489
	data_grads_norm = 0.3586
	new_data_grads_norm = 0.3477
	old_data_grads_norm = 0.3477
	sim_grads_norm_tr = 0.3234
-- Starting training on experience 945 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1934
	data_grads_norm = 0.9245
	new_data_grads_norm = 0.8561
	old_data_grads_norm = 2.0906
	sim_grads_norm_tr = 0.2627
-- Starting training on experience 946 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0789
	data_grads_norm = 0.5234
	new_data_grads_norm = 0.6219
	old_data_grads_norm = 0.6854
	sim_grads_norm_tr = 0.1683
-- Starting training on experience 947 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1078
	data_grads_norm = 0.6309
	new_data_grads_norm = 1.3307
	old_data_grads_norm = 1.7768
	sim_grads_norm_tr = -0.2068
-- Starting training on experience 948 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.1368
	data_grads_norm = 1.0394
	new_data_grads_norm = 1.7032
	old_data_grads_norm = 1.0454
	sim_grads_norm_tr = 0.0991
-- Starting training on experience 949 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.0981
	data_grads_norm = 0.8145
	new_data_grads_norm = 1.3531
	old_data_grads_norm = 1.3375
	sim_grads_norm_tr = -0.1205
-- >> End of training phase << --
-- >> Start of eval phase << --
-- Starting eval on experience 0 (Task 0) from test stream --
> Eval on experience 0 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp000 = 0.1781
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.5615
	mb_index = 950
	time = 165.9344
-- >> End of eval phase << --
	CumulativeAccuracy/eval_phase/test_stream/Exp000 = 0.5615
	Loss_Stream/eval_phase/test_stream/Task000 = 0.1781
	Top1_Acc_Stream/eval_phase/test_stream/Task000 = 0.5615
	ValidStream/mean_grads_norm_iter = 5.7336
-- >> Start of training phase << --
-- Starting training on experience 0 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0972
	data_grads_norm = 2.4923
	new_data_grads_norm = 7.1580
	old_data_grads_norm = 1.9841
	sim_grads_norm_tr = -0.6603
-- Starting training on experience 1 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4916
	data_grads_norm = 4.5106
	new_data_grads_norm = 8.6740
	old_data_grads_norm = 1.8972
	sim_grads_norm_tr = -0.2381
-- Starting training on experience 2 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0394
	data_grads_norm = 6.6319
	new_data_grads_norm = 8.8259
	old_data_grads_norm = 1.7486
	sim_grads_norm_tr = -0.3824
-- Starting training on experience 3 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1942
	data_grads_norm = 2.6819
	new_data_grads_norm = 9.2901
	old_data_grads_norm = 1.0744
	sim_grads_norm_tr = -0.3072
-- Starting training on experience 4 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2782
	data_grads_norm = 5.8187
	new_data_grads_norm = 9.7565
	old_data_grads_norm = 4.8002
	sim_grads_norm_tr = 0.1258
-- Starting training on experience 5 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9417
	data_grads_norm = 4.2754
	new_data_grads_norm = 8.3201
	old_data_grads_norm = 3.3143
	sim_grads_norm_tr = 0.0068
-- Starting training on experience 6 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6280
	data_grads_norm = 4.0642
	new_data_grads_norm = 8.6507
	old_data_grads_norm = 2.6335
	sim_grads_norm_tr = -0.1181
-- Starting training on experience 7 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8315
	data_grads_norm = 4.5022
	new_data_grads_norm = 8.7211
	old_data_grads_norm = 2.3819
	sim_grads_norm_tr = 0.1562
-- Starting training on experience 8 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6881
	data_grads_norm = 3.9571
	new_data_grads_norm = 8.7230
	old_data_grads_norm = 1.9718
	sim_grads_norm_tr = -0.0989
-- Starting training on experience 9 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8881
	data_grads_norm = 4.4986
	new_data_grads_norm = 7.9409
	old_data_grads_norm = 2.9286
	sim_grads_norm_tr = 0.0325
-- Starting training on experience 10 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5211
	data_grads_norm = 4.3663
	new_data_grads_norm = 8.8991
	old_data_grads_norm = 1.3811
	sim_grads_norm_tr = -0.2898
-- Starting training on experience 11 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6558
	data_grads_norm = 5.5895
	new_data_grads_norm = 9.1457
	old_data_grads_norm = 5.1494
	sim_grads_norm_tr = -0.0171
-- Starting training on experience 12 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9821
	data_grads_norm = 5.3569
	new_data_grads_norm = 9.0070
	old_data_grads_norm = 4.5534
	sim_grads_norm_tr = 0.0453
-- Starting training on experience 13 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8282
	data_grads_norm = 5.2869
	new_data_grads_norm = 9.9072
	old_data_grads_norm = 4.0104
	sim_grads_norm_tr = 0.4407
-- Starting training on experience 14 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8556
	data_grads_norm = 4.2964
	new_data_grads_norm = 8.9387
	old_data_grads_norm = 2.5464
	sim_grads_norm_tr = 0.1151
-- Starting training on experience 15 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3795
	data_grads_norm = 3.9934
	new_data_grads_norm = 7.3091
	old_data_grads_norm = 4.3111
	sim_grads_norm_tr = -0.3040
-- Starting training on experience 16 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1973
	data_grads_norm = 5.5272
	new_data_grads_norm = 9.2628
	old_data_grads_norm = 4.1833
	sim_grads_norm_tr = 0.1125
-- Starting training on experience 17 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1000
	data_grads_norm = 2.6443
	new_data_grads_norm = 8.1845
	old_data_grads_norm = 2.6189
	sim_grads_norm_tr = -0.1910
-- Starting training on experience 18 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9663
	data_grads_norm = 5.0081
	new_data_grads_norm = 9.0260
	old_data_grads_norm = 3.9847
	sim_grads_norm_tr = 0.4651
-- Starting training on experience 19 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3141
	data_grads_norm = 2.6445
	new_data_grads_norm = 7.1202
	old_data_grads_norm = 2.8071
	sim_grads_norm_tr = -0.2483
-- Starting training on experience 20 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3684
	data_grads_norm = 3.9305
	new_data_grads_norm = 7.9849
	old_data_grads_norm = 2.0544
	sim_grads_norm_tr = 0.1127
-- Starting training on experience 21 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1672
	data_grads_norm = 2.8713
	new_data_grads_norm = 8.3916
	old_data_grads_norm = 2.2546
	sim_grads_norm_tr = 0.2157
-- Starting training on experience 22 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5774
	data_grads_norm = 4.3884
	new_data_grads_norm = 8.0775
	old_data_grads_norm = 3.2230
	sim_grads_norm_tr = 0.0620
-- Starting training on experience 23 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6151
	data_grads_norm = 4.2580
	new_data_grads_norm = 9.0722
	old_data_grads_norm = 2.2040
	sim_grads_norm_tr = 0.1524
-- Starting training on experience 24 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3258
	data_grads_norm = 2.8416
	new_data_grads_norm = 7.8526
	old_data_grads_norm = 3.6845
	sim_grads_norm_tr = -0.0325
-- Starting training on experience 25 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2025
	data_grads_norm = 2.8265
	new_data_grads_norm = 9.5134
	old_data_grads_norm = 1.0018
	sim_grads_norm_tr = -0.0493
-- Starting training on experience 26 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5262
	data_grads_norm = 4.1845
	new_data_grads_norm = 8.4732
	old_data_grads_norm = 2.9450
	sim_grads_norm_tr = 0.2954
-- Starting training on experience 27 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3519
	data_grads_norm = 2.9377
	new_data_grads_norm = 6.1997
	old_data_grads_norm = 1.7104
	sim_grads_norm_tr = -0.0688
-- Starting training on experience 28 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2726
	data_grads_norm = 2.3696
	new_data_grads_norm = 6.7771
	old_data_grads_norm = 3.3678
	sim_grads_norm_tr = -0.2487
-- Starting training on experience 29 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3427
	data_grads_norm = 2.7836
	new_data_grads_norm = 8.8103
	old_data_grads_norm = 1.5343
	sim_grads_norm_tr = -0.0459
-- Starting training on experience 30 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8811
	data_grads_norm = 4.2888
	new_data_grads_norm = 8.1943
	old_data_grads_norm = 2.2191
	sim_grads_norm_tr = 0.0096
-- Starting training on experience 31 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6601
	data_grads_norm = 3.5577
	new_data_grads_norm = 8.5419
	old_data_grads_norm = 3.0944
	sim_grads_norm_tr = -0.0290
-- Starting training on experience 32 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8721
	data_grads_norm = 4.4443
	new_data_grads_norm = 9.8872
	old_data_grads_norm = 4.2569
	sim_grads_norm_tr = 0.0918
-- Starting training on experience 33 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2419
	data_grads_norm = 2.8144
	new_data_grads_norm = 7.5762
	old_data_grads_norm = 2.2744
	sim_grads_norm_tr = -0.1002
-- Starting training on experience 34 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9794
	data_grads_norm = 5.1441
	new_data_grads_norm = 7.8591
	old_data_grads_norm = 4.2876
	sim_grads_norm_tr = 0.5167
-- Starting training on experience 35 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3063
	data_grads_norm = 2.7115
	new_data_grads_norm = 8.1289
	old_data_grads_norm = 2.0014
	sim_grads_norm_tr = -0.1901
-- Starting training on experience 36 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7591
	data_grads_norm = 4.0103
	new_data_grads_norm = 7.8264
	old_data_grads_norm = 4.5731
	sim_grads_norm_tr = 0.1825
-- Starting training on experience 37 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4696
	data_grads_norm = 4.1009
	new_data_grads_norm = 7.2423
	old_data_grads_norm = 3.0803
	sim_grads_norm_tr = 0.2329
-- Starting training on experience 38 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5320
	data_grads_norm = 3.5776
	new_data_grads_norm = 6.6007
	old_data_grads_norm = 3.5665
	sim_grads_norm_tr = 0.0514
-- Starting training on experience 39 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4556
	data_grads_norm = 3.3841
	new_data_grads_norm = 6.8888
	old_data_grads_norm = 3.0286
	sim_grads_norm_tr = 0.3831
-- Starting training on experience 40 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4012
	data_grads_norm = 3.1487
	new_data_grads_norm = 5.7809
	old_data_grads_norm = 3.3857
	sim_grads_norm_tr = 0.2101
-- Starting training on experience 41 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4146
	data_grads_norm = 3.1062
	new_data_grads_norm = 5.1731
	old_data_grads_norm = 4.6290
	sim_grads_norm_tr = -0.5287
-- Starting training on experience 42 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4156
	data_grads_norm = 4.2887
	new_data_grads_norm = 7.4229
	old_data_grads_norm = 1.6894
	sim_grads_norm_tr = 0.3424
-- Starting training on experience 43 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8297
	data_grads_norm = 4.1295
	new_data_grads_norm = 7.1300
	old_data_grads_norm = 3.0641
	sim_grads_norm_tr = 0.2922
-- Starting training on experience 44 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1679
	data_grads_norm = 2.8407
	new_data_grads_norm = 6.2631
	old_data_grads_norm = 3.4359
	sim_grads_norm_tr = 0.2738
-- Starting training on experience 45 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3864
	data_grads_norm = 3.3685
	new_data_grads_norm = 6.0556
	old_data_grads_norm = 2.9437
	sim_grads_norm_tr = 0.0273
-- Starting training on experience 46 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2200
	data_grads_norm = 2.5333
	new_data_grads_norm = 7.2624
	old_data_grads_norm = 2.3679
	sim_grads_norm_tr = 0.2461
-- Starting training on experience 47 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2612
	data_grads_norm = 2.5209
	new_data_grads_norm = 5.3971
	old_data_grads_norm = 2.4361
	sim_grads_norm_tr = 0.3037
-- Starting training on experience 48 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8905
	data_grads_norm = 1.6243
	new_data_grads_norm = 5.6686
	old_data_grads_norm = 3.9251
	sim_grads_norm_tr = -0.3472
-- Starting training on experience 49 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2616
	data_grads_norm = 3.3569
	new_data_grads_norm = 6.6192
	old_data_grads_norm = 2.2597
	sim_grads_norm_tr = 0.2730
-- Starting training on experience 50 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5788
	data_grads_norm = 3.9704
	new_data_grads_norm = 7.5870
	old_data_grads_norm = 4.3637
	sim_grads_norm_tr = 0.2945
-- Starting training on experience 51 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0460
	data_grads_norm = 1.9173
	new_data_grads_norm = 7.7541
	old_data_grads_norm = 1.3042
	sim_grads_norm_tr = -0.0612
-- Starting training on experience 52 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5070
	data_grads_norm = 4.0346
	new_data_grads_norm = 6.8535
	old_data_grads_norm = 2.9744
	sim_grads_norm_tr = -0.1041
-- Starting training on experience 53 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0827
	data_grads_norm = 2.6026
	new_data_grads_norm = 6.9357
	old_data_grads_norm = 1.6801
	sim_grads_norm_tr = -0.0892
-- Starting training on experience 54 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2934
	data_grads_norm = 3.5312
	new_data_grads_norm = 7.2791
	old_data_grads_norm = 2.3094
	sim_grads_norm_tr = 0.4521
-- Starting training on experience 55 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0210
	data_grads_norm = 4.8695
	new_data_grads_norm = 7.6931
	old_data_grads_norm = 3.8339
	sim_grads_norm_tr = 0.2907
-- Starting training on experience 56 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3496
	data_grads_norm = 3.0069
	new_data_grads_norm = 7.0012
	old_data_grads_norm = 2.0391
	sim_grads_norm_tr = -0.2508
-- Starting training on experience 57 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1359
	data_grads_norm = 2.5962
	new_data_grads_norm = 5.8908
	old_data_grads_norm = 1.4902
	sim_grads_norm_tr = 0.1194
-- Starting training on experience 58 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2817
	data_grads_norm = 2.3630
	new_data_grads_norm = 6.1883
	old_data_grads_norm = 1.4118
	sim_grads_norm_tr = 0.1509
-- Starting training on experience 59 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0646
	data_grads_norm = 1.9024
	new_data_grads_norm = 6.2932
	old_data_grads_norm = 2.2137
	sim_grads_norm_tr = -0.0164
-- Starting training on experience 60 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9246
	data_grads_norm = 1.9526
	new_data_grads_norm = 5.8451
	old_data_grads_norm = 1.3414
	sim_grads_norm_tr = -0.1854
-- Starting training on experience 61 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6616
	data_grads_norm = 4.4481
	new_data_grads_norm = 7.0499
	old_data_grads_norm = 2.2927
	sim_grads_norm_tr = 0.3826
-- Starting training on experience 62 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1524
	data_grads_norm = 2.5971
	new_data_grads_norm = 6.2558
	old_data_grads_norm = 2.6301
	sim_grads_norm_tr = -0.0404
-- Starting training on experience 63 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0715
	data_grads_norm = 3.1141
	new_data_grads_norm = 6.8285
	old_data_grads_norm = 2.6937
	sim_grads_norm_tr = 0.3497
-- Starting training on experience 64 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3843
	data_grads_norm = 4.7697
	new_data_grads_norm = 5.3567
	old_data_grads_norm = 5.8008
	sim_grads_norm_tr = 0.4685
-- Starting training on experience 65 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3688
	data_grads_norm = 4.4753
	new_data_grads_norm = 4.1050
	old_data_grads_norm = 5.9428
	sim_grads_norm_tr = -0.2509
-- Starting training on experience 66 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3096
	data_grads_norm = 3.8867
	new_data_grads_norm = 7.6012
	old_data_grads_norm = 4.0515
	sim_grads_norm_tr = 0.2245
-- Starting training on experience 67 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2004
	data_grads_norm = 3.2473
	new_data_grads_norm = 7.2166
	old_data_grads_norm = 3.0452
	sim_grads_norm_tr = 0.2365
-- Starting training on experience 68 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2440
	data_grads_norm = 4.6514
	new_data_grads_norm = 7.4450
	old_data_grads_norm = 4.2917
	sim_grads_norm_tr = -0.1116
-- Starting training on experience 69 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3053
	data_grads_norm = 3.9774
	new_data_grads_norm = 6.6091
	old_data_grads_norm = 3.9256
	sim_grads_norm_tr = 0.0844
-- Starting training on experience 70 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3611
	data_grads_norm = 4.9009
	new_data_grads_norm = 6.7323
	old_data_grads_norm = 6.9000
	sim_grads_norm_tr = 0.2627
-- Starting training on experience 71 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5018
	data_grads_norm = 4.0208
	new_data_grads_norm = 5.3173
	old_data_grads_norm = 4.8632
	sim_grads_norm_tr = 0.3214
-- Starting training on experience 72 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0635
	data_grads_norm = 1.6812
	new_data_grads_norm = 3.3325
	old_data_grads_norm = 1.9241
	sim_grads_norm_tr = -0.2123
-- Starting training on experience 73 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1343
	data_grads_norm = 2.6738
	new_data_grads_norm = 4.1993
	old_data_grads_norm = 3.4306
	sim_grads_norm_tr = -0.1753
-- Starting training on experience 74 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0338
	data_grads_norm = 2.4405
	new_data_grads_norm = 4.7833
	old_data_grads_norm = 3.3240
	sim_grads_norm_tr = -0.3855
-- Starting training on experience 75 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0547
	data_grads_norm = 2.1493
	new_data_grads_norm = 5.7160
	old_data_grads_norm = 1.9253
	sim_grads_norm_tr = -0.1882
-- Starting training on experience 76 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2685
	data_grads_norm = 3.1470
	new_data_grads_norm = 6.1057
	old_data_grads_norm = 2.3388
	sim_grads_norm_tr = 0.2454
-- Starting training on experience 77 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4305
	data_grads_norm = 3.5366
	new_data_grads_norm = 5.8470
	old_data_grads_norm = 2.5157
	sim_grads_norm_tr = 0.0100
-- Starting training on experience 78 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2254
	data_grads_norm = 3.1442
	new_data_grads_norm = 5.7786
	old_data_grads_norm = 3.8580
	sim_grads_norm_tr = 0.1983
-- Starting training on experience 79 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2637
	data_grads_norm = 2.7081
	new_data_grads_norm = 5.2493
	old_data_grads_norm = 3.4072
	sim_grads_norm_tr = -0.3474
-- Starting training on experience 80 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1179
	data_grads_norm = 2.5483
	new_data_grads_norm = 8.3274
	old_data_grads_norm = 2.5870
	sim_grads_norm_tr = 0.1515
-- Starting training on experience 81 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2602
	data_grads_norm = 3.5772
	new_data_grads_norm = 8.6584
	old_data_grads_norm = 2.9398
	sim_grads_norm_tr = 0.1296
-- Starting training on experience 82 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0597
	data_grads_norm = 1.9129
	new_data_grads_norm = 5.8689
	old_data_grads_norm = 1.5777
	sim_grads_norm_tr = 0.1066
-- Starting training on experience 83 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9270
	data_grads_norm = 1.9987
	new_data_grads_norm = 7.0575
	old_data_grads_norm = 2.0515
	sim_grads_norm_tr = -0.1204
-- Starting training on experience 84 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7738
	data_grads_norm = 5.7096
	new_data_grads_norm = 7.3938
	old_data_grads_norm = 3.8983
	sim_grads_norm_tr = 0.0290
-- Starting training on experience 85 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5977
	data_grads_norm = 4.6427
	new_data_grads_norm = 5.8777
	old_data_grads_norm = 6.4456
	sim_grads_norm_tr = 0.0511
-- Starting training on experience 86 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2018
	data_grads_norm = 3.0890
	new_data_grads_norm = 7.8543
	old_data_grads_norm = 1.7767
	sim_grads_norm_tr = 0.1936
-- Starting training on experience 87 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2027
	data_grads_norm = 3.1293
	new_data_grads_norm = 6.2351
	old_data_grads_norm = 2.4948
	sim_grads_norm_tr = 0.2362
-- Starting training on experience 88 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0263
	data_grads_norm = 1.9590
	new_data_grads_norm = 5.0497
	old_data_grads_norm = 1.4869
	sim_grads_norm_tr = 0.3337
-- Starting training on experience 89 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2069
	data_grads_norm = 3.0842
	new_data_grads_norm = 5.1281
	old_data_grads_norm = 3.7780
	sim_grads_norm_tr = -0.1085
-- Starting training on experience 90 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9429
	data_grads_norm = 1.8835
	new_data_grads_norm = 6.4599
	old_data_grads_norm = 3.0735
	sim_grads_norm_tr = -0.1511
-- Starting training on experience 91 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5581
	data_grads_norm = 6.8397
	new_data_grads_norm = 7.6495
	old_data_grads_norm = 6.1840
	sim_grads_norm_tr = 0.3043
-- Starting training on experience 92 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0211
	data_grads_norm = 2.2078
	new_data_grads_norm = 6.2463
	old_data_grads_norm = 2.4946
	sim_grads_norm_tr = -0.2854
-- Starting training on experience 93 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3846
	data_grads_norm = 3.5968
	new_data_grads_norm = 6.1025
	old_data_grads_norm = 5.5534
	sim_grads_norm_tr = 0.2202
-- Starting training on experience 94 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8198
	data_grads_norm = 5.0411
	new_data_grads_norm = 6.2559
	old_data_grads_norm = 5.0828
	sim_grads_norm_tr = 0.4204
-- Starting training on experience 95 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2252
	data_grads_norm = 2.6687
	new_data_grads_norm = 3.6525
	old_data_grads_norm = 3.9879
	sim_grads_norm_tr = -0.1139
-- Starting training on experience 96 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2671
	data_grads_norm = 2.4880
	new_data_grads_norm = 5.9278
	old_data_grads_norm = 2.2848
	sim_grads_norm_tr = 0.1337
-- Starting training on experience 97 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2069
	data_grads_norm = 3.4745
	new_data_grads_norm = 5.3703
	old_data_grads_norm = 4.0472
	sim_grads_norm_tr = 0.2666
-- Starting training on experience 98 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4690
	data_grads_norm = 3.5241
	new_data_grads_norm = 4.6225
	old_data_grads_norm = 4.2551
	sim_grads_norm_tr = 0.2306
-- Starting training on experience 99 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1206
	data_grads_norm = 2.6212
	new_data_grads_norm = 4.7568
	old_data_grads_norm = 1.8673
	sim_grads_norm_tr = 0.0222
-- Starting training on experience 100 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5390
	data_grads_norm = 3.9583
	new_data_grads_norm = 4.8206
	old_data_grads_norm = 4.3613
	sim_grads_norm_tr = 0.5004
-- Starting training on experience 101 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8149
	data_grads_norm = 1.8699
	new_data_grads_norm = 2.1758
	old_data_grads_norm = 2.5652
	sim_grads_norm_tr = 0.3097
-- Starting training on experience 102 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0388
	data_grads_norm = 1.9659
	new_data_grads_norm = 3.6405
	old_data_grads_norm = 2.8803
	sim_grads_norm_tr = -0.2682
-- Starting training on experience 103 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2371
	data_grads_norm = 2.6645
	new_data_grads_norm = 2.5544
	old_data_grads_norm = 4.0291
	sim_grads_norm_tr = -0.0030
-- Starting training on experience 104 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9087
	data_grads_norm = 1.6025
	new_data_grads_norm = 4.8944
	old_data_grads_norm = 1.5952
	sim_grads_norm_tr = -0.1218
-- Starting training on experience 105 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0694
	data_grads_norm = 2.9776
	new_data_grads_norm = 4.5730
	old_data_grads_norm = 3.6709
	sim_grads_norm_tr = -0.1901
-- Starting training on experience 106 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3626
	data_grads_norm = 3.2179
	new_data_grads_norm = 5.4890
	old_data_grads_norm = 3.6476
	sim_grads_norm_tr = 0.4855
-- Starting training on experience 107 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9385
	data_grads_norm = 2.3578
	new_data_grads_norm = 3.4781
	old_data_grads_norm = 2.7481
	sim_grads_norm_tr = 0.1807
-- Starting training on experience 108 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1264
	data_grads_norm = 2.3997
	new_data_grads_norm = 4.8702
	old_data_grads_norm = 3.4357
	sim_grads_norm_tr = -0.2272
-- Starting training on experience 109 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0170
	data_grads_norm = 1.7743
	new_data_grads_norm = 6.4031
	old_data_grads_norm = 2.7266
	sim_grads_norm_tr = -0.1374
-- Starting training on experience 110 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2800
	data_grads_norm = 4.1471
	new_data_grads_norm = 6.5652
	old_data_grads_norm = 2.6847
	sim_grads_norm_tr = 0.1729
-- Starting training on experience 111 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2172
	data_grads_norm = 3.2875
	new_data_grads_norm = 5.6972
	old_data_grads_norm = 2.4785
	sim_grads_norm_tr = 0.2806
-- Starting training on experience 112 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3353
	data_grads_norm = 2.4338
	new_data_grads_norm = 4.9743
	old_data_grads_norm = 3.0217
	sim_grads_norm_tr = -0.1173
-- Starting training on experience 113 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1092
	data_grads_norm = 2.2974
	new_data_grads_norm = 6.9603
	old_data_grads_norm = 1.8961
	sim_grads_norm_tr = -0.1504
-- Starting training on experience 114 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9789
	data_grads_norm = 2.2471
	new_data_grads_norm = 6.6034
	old_data_grads_norm = 1.6754
	sim_grads_norm_tr = -0.0202
-- Starting training on experience 115 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0243
	data_grads_norm = 2.5082
	new_data_grads_norm = 10.2493
	old_data_grads_norm = 2.6879
	sim_grads_norm_tr = 0.1446
-- Starting training on experience 116 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9053
	data_grads_norm = 1.9787
	new_data_grads_norm = 5.6912
	old_data_grads_norm = 1.8628
	sim_grads_norm_tr = -0.1899
-- Starting training on experience 117 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2406
	data_grads_norm = 3.3901
	new_data_grads_norm = 5.8908
	old_data_grads_norm = 3.8288
	sim_grads_norm_tr = 0.0516
-- Starting training on experience 118 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9617
	data_grads_norm = 1.4509
	new_data_grads_norm = 6.6288
	old_data_grads_norm = 2.0951
	sim_grads_norm_tr = -0.2146
-- Starting training on experience 119 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4878
	data_grads_norm = 3.7199
	new_data_grads_norm = 6.5324
	old_data_grads_norm = 2.8335
	sim_grads_norm_tr = 0.3009
-- Starting training on experience 120 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1074
	data_grads_norm = 2.3071
	new_data_grads_norm = 5.2466
	old_data_grads_norm = 2.0963
	sim_grads_norm_tr = 0.0219
-- Starting training on experience 121 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3224
	data_grads_norm = 2.8293
	new_data_grads_norm = 6.7056
	old_data_grads_norm = 3.7650
	sim_grads_norm_tr = 0.0420
-- Starting training on experience 122 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1575
	data_grads_norm = 2.6542
	new_data_grads_norm = 5.9015
	old_data_grads_norm = 2.1195
	sim_grads_norm_tr = 0.2372
-- Starting training on experience 123 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0179
	data_grads_norm = 3.1154
	new_data_grads_norm = 7.3783
	old_data_grads_norm = 2.0649
	sim_grads_norm_tr = 0.2395
-- Starting training on experience 124 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0371
	data_grads_norm = 2.9829
	new_data_grads_norm = 5.6596
	old_data_grads_norm = 2.8669
	sim_grads_norm_tr = -0.0272
-- Starting training on experience 125 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9033
	data_grads_norm = 2.1967
	new_data_grads_norm = 5.3059
	old_data_grads_norm = 4.1532
	sim_grads_norm_tr = -0.2887
-- Starting training on experience 126 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4082
	data_grads_norm = 3.6719
	new_data_grads_norm = 7.7747
	old_data_grads_norm = 3.6455
	sim_grads_norm_tr = 0.4101
-- Starting training on experience 127 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1941
	data_grads_norm = 2.5027
	new_data_grads_norm = 7.8969
	old_data_grads_norm = 1.5970
	sim_grads_norm_tr = 0.0934
-- Starting training on experience 128 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4589
	data_grads_norm = 4.3376
	new_data_grads_norm = 6.9177
	old_data_grads_norm = 2.8953
	sim_grads_norm_tr = 0.2274
-- Starting training on experience 129 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8551
	data_grads_norm = 2.1319
	new_data_grads_norm = 5.2310
	old_data_grads_norm = 1.6382
	sim_grads_norm_tr = 0.1703
-- Starting training on experience 130 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0582
	data_grads_norm = 2.8514
	new_data_grads_norm = 6.6938
	old_data_grads_norm = 2.9063
	sim_grads_norm_tr = 0.0898
-- Starting training on experience 131 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5563
	data_grads_norm = 3.9736
	new_data_grads_norm = 7.2812
	old_data_grads_norm = 3.0515
	sim_grads_norm_tr = 0.5530
-- Starting training on experience 132 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7464
	data_grads_norm = 4.4485
	new_data_grads_norm = 6.3145
	old_data_grads_norm = 5.0298
	sim_grads_norm_tr = 0.3022
-- Starting training on experience 133 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9967
	data_grads_norm = 2.4664
	new_data_grads_norm = 5.3755
	old_data_grads_norm = 3.1967
	sim_grads_norm_tr = -0.0616
-- Starting training on experience 134 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3818
	data_grads_norm = 3.2214
	new_data_grads_norm = 4.9186
	old_data_grads_norm = 3.7966
	sim_grads_norm_tr = 0.3844
-- Starting training on experience 135 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0637
	data_grads_norm = 3.2929
	new_data_grads_norm = 6.9098
	old_data_grads_norm = 4.2352
	sim_grads_norm_tr = 0.0519
-- Starting training on experience 136 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2383
	data_grads_norm = 2.5340
	new_data_grads_norm = 8.1466
	old_data_grads_norm = 3.8017
	sim_grads_norm_tr = 0.0488
-- Starting training on experience 137 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8525
	data_grads_norm = 1.4448
	new_data_grads_norm = 5.2706
	old_data_grads_norm = 2.8816
	sim_grads_norm_tr = -0.2377
-- Starting training on experience 138 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9436
	data_grads_norm = 2.2086
	new_data_grads_norm = 6.6594
	old_data_grads_norm = 1.8301
	sim_grads_norm_tr = -0.0075
-- Starting training on experience 139 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1574
	data_grads_norm = 3.4659
	new_data_grads_norm = 6.3285
	old_data_grads_norm = 3.6452
	sim_grads_norm_tr = -0.0605
-- Starting training on experience 140 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4326
	data_grads_norm = 3.7840
	new_data_grads_norm = 6.5463
	old_data_grads_norm = 3.2925
	sim_grads_norm_tr = 0.1012
-- Starting training on experience 141 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1006
	data_grads_norm = 3.0717
	new_data_grads_norm = 6.1614
	old_data_grads_norm = 2.6917
	sim_grads_norm_tr = 0.1677
-- Starting training on experience 142 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8061
	data_grads_norm = 1.6741
	new_data_grads_norm = 4.7018
	old_data_grads_norm = 2.9861
	sim_grads_norm_tr = -0.4279
-- Starting training on experience 143 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6081
	data_grads_norm = 4.1993
	new_data_grads_norm = 7.7463
	old_data_grads_norm = 3.0322
	sim_grads_norm_tr = 0.1921
-- Starting training on experience 144 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1250
	data_grads_norm = 3.0297
	new_data_grads_norm = 5.0304
	old_data_grads_norm = 2.4136
	sim_grads_norm_tr = 0.2054
-- Starting training on experience 145 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3959
	data_grads_norm = 3.8992
	new_data_grads_norm = 5.9608
	old_data_grads_norm = 2.6005
	sim_grads_norm_tr = 0.4363
-- Starting training on experience 146 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8324
	data_grads_norm = 2.1099
	new_data_grads_norm = 4.2425
	old_data_grads_norm = 3.6092
	sim_grads_norm_tr = -0.1880
-- Starting training on experience 147 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9302
	data_grads_norm = 2.5233
	new_data_grads_norm = 5.7277
	old_data_grads_norm = 2.3902
	sim_grads_norm_tr = -0.0716
-- Starting training on experience 148 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.6358
	data_grads_norm = 1.5866
	new_data_grads_norm = 6.5246
	old_data_grads_norm = 3.5498
	sim_grads_norm_tr = 0.0286
-- Starting training on experience 149 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.8247
	data_grads_norm = 6.4370
	new_data_grads_norm = 7.3078
	old_data_grads_norm = 7.8093
	sim_grads_norm_tr = 0.5184
-- Starting training on experience 150 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6508
	data_grads_norm = 4.1349
	new_data_grads_norm = 5.8677
	old_data_grads_norm = 4.3143
	sim_grads_norm_tr = 0.2360
-- Starting training on experience 151 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0859
	data_grads_norm = 2.2498
	new_data_grads_norm = 4.5328
	old_data_grads_norm = 2.0396
	sim_grads_norm_tr = -0.2113
-- Starting training on experience 152 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4914
	data_grads_norm = 4.1104
	new_data_grads_norm = 4.9254
	old_data_grads_norm = 4.3309
	sim_grads_norm_tr = 0.3564
-- Starting training on experience 153 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0255
	data_grads_norm = 1.9512
	new_data_grads_norm = 2.9787
	old_data_grads_norm = 2.6374
	sim_grads_norm_tr = -0.0422
-- Starting training on experience 154 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6132
	data_grads_norm = 3.0966
	new_data_grads_norm = 3.4065
	old_data_grads_norm = 4.2389
	sim_grads_norm_tr = 0.0843
-- Starting training on experience 155 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2173
	data_grads_norm = 3.0730
	new_data_grads_norm = 4.3052
	old_data_grads_norm = 2.8453
	sim_grads_norm_tr = 0.3278
-- Starting training on experience 156 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0162
	data_grads_norm = 2.2472
	new_data_grads_norm = 3.3377
	old_data_grads_norm = 4.5502
	sim_grads_norm_tr = -0.1721
-- Starting training on experience 157 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0281
	data_grads_norm = 2.6790
	new_data_grads_norm = 5.1415
	old_data_grads_norm = 3.3069
	sim_grads_norm_tr = -0.2003
-- Starting training on experience 158 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2856
	data_grads_norm = 2.8844
	new_data_grads_norm = 6.2200
	old_data_grads_norm = 2.9027
	sim_grads_norm_tr = 0.3456
-- Starting training on experience 159 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2550
	data_grads_norm = 2.6604
	new_data_grads_norm = 4.9997
	old_data_grads_norm = 2.6771
	sim_grads_norm_tr = -0.2264
-- Starting training on experience 160 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2290
	data_grads_norm = 3.8474
	new_data_grads_norm = 5.5101
	old_data_grads_norm = 3.2759
	sim_grads_norm_tr = 0.2920
-- Starting training on experience 161 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1187
	data_grads_norm = 2.8673
	new_data_grads_norm = 4.7854
	old_data_grads_norm = 2.5872
	sim_grads_norm_tr = 0.3005
-- Starting training on experience 162 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8829
	data_grads_norm = 2.3621
	new_data_grads_norm = 4.2219
	old_data_grads_norm = 3.3441
	sim_grads_norm_tr = -0.2235
-- Starting training on experience 163 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8660
	data_grads_norm = 2.6655
	new_data_grads_norm = 4.9513
	old_data_grads_norm = 2.6669
	sim_grads_norm_tr = -0.2278
-- Starting training on experience 164 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9555
	data_grads_norm = 2.6941
	new_data_grads_norm = 6.2698
	old_data_grads_norm = 2.0356
	sim_grads_norm_tr = 0.1182
-- Starting training on experience 165 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0006
	data_grads_norm = 2.8154
	new_data_grads_norm = 5.7173
	old_data_grads_norm = 3.3218
	sim_grads_norm_tr = 0.1648
-- Starting training on experience 166 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7999
	data_grads_norm = 1.9683
	new_data_grads_norm = 4.5932
	old_data_grads_norm = 2.4958
	sim_grads_norm_tr = -0.1549
-- Starting training on experience 167 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8271
	data_grads_norm = 1.9603
	new_data_grads_norm = 6.3143
	old_data_grads_norm = 1.7167
	sim_grads_norm_tr = -0.2253
-- Starting training on experience 168 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0324
	data_grads_norm = 3.0716
	new_data_grads_norm = 5.8722
	old_data_grads_norm = 4.2332
	sim_grads_norm_tr = -0.1264
-- Starting training on experience 169 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1240
	data_grads_norm = 3.6967
	new_data_grads_norm = 7.4498
	old_data_grads_norm = 2.3983
	sim_grads_norm_tr = 0.1599
-- Starting training on experience 170 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9331
	data_grads_norm = 3.4361
	new_data_grads_norm = 7.7725
	old_data_grads_norm = 3.8554
	sim_grads_norm_tr = -0.2590
-- Starting training on experience 171 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3472
	data_grads_norm = 4.4787
	new_data_grads_norm = 7.2248
	old_data_grads_norm = 3.0708
	sim_grads_norm_tr = 0.4466
-- Starting training on experience 172 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1428
	data_grads_norm = 3.1719
	new_data_grads_norm = 5.8301
	old_data_grads_norm = 2.5466
	sim_grads_norm_tr = 0.2052
-- Starting training on experience 173 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2362
	data_grads_norm = 3.6472
	new_data_grads_norm = 6.5312
	old_data_grads_norm = 3.8207
	sim_grads_norm_tr = 0.4005
-- Starting training on experience 174 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2228
	data_grads_norm = 1.9594
	new_data_grads_norm = 4.8989
	old_data_grads_norm = 2.8533
	sim_grads_norm_tr = -0.1526
-- Starting training on experience 175 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2036
	data_grads_norm = 3.1920
	new_data_grads_norm = 6.1249
	old_data_grads_norm = 2.7243
	sim_grads_norm_tr = 0.2647
-- Starting training on experience 176 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7723
	data_grads_norm = 1.8205
	new_data_grads_norm = 4.4986
	old_data_grads_norm = 3.1318
	sim_grads_norm_tr = -0.1125
-- Starting training on experience 177 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7124
	data_grads_norm = 2.2115
	new_data_grads_norm = 6.3238
	old_data_grads_norm = 1.8625
	sim_grads_norm_tr = 0.1308
-- Starting training on experience 178 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4414
	data_grads_norm = 4.2851
	new_data_grads_norm = 4.8813
	old_data_grads_norm = 6.2489
	sim_grads_norm_tr = 0.2279
-- Starting training on experience 179 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1239
	data_grads_norm = 3.5530
	new_data_grads_norm = 2.5020
	old_data_grads_norm = 6.0353
	sim_grads_norm_tr = -0.1105
-- Starting training on experience 180 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2272
	data_grads_norm = 3.3185
	new_data_grads_norm = 4.8634
	old_data_grads_norm = 3.5417
	sim_grads_norm_tr = 0.0753
-- Starting training on experience 181 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9700
	data_grads_norm = 2.6618
	new_data_grads_norm = 5.1078
	old_data_grads_norm = 2.2929
	sim_grads_norm_tr = -0.2198
-- Starting training on experience 182 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0110
	data_grads_norm = 3.0979
	new_data_grads_norm = 4.8716
	old_data_grads_norm = 3.5105
	sim_grads_norm_tr = 0.3060
-- Starting training on experience 183 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0408
	data_grads_norm = 2.6716
	new_data_grads_norm = 4.9208
	old_data_grads_norm = 2.4308
	sim_grads_norm_tr = 0.1065
-- Starting training on experience 184 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4106
	data_grads_norm = 3.2972
	new_data_grads_norm = 5.2278
	old_data_grads_norm = 2.9861
	sim_grads_norm_tr = 0.1129
-- Starting training on experience 185 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9701
	data_grads_norm = 2.2420
	new_data_grads_norm = 5.0964
	old_data_grads_norm = 2.1043
	sim_grads_norm_tr = 0.0196
-- Starting training on experience 186 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0902
	data_grads_norm = 3.2592
	new_data_grads_norm = 3.8468
	old_data_grads_norm = 4.2945
	sim_grads_norm_tr = 0.2508
-- Starting training on experience 187 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0195
	data_grads_norm = 2.6885
	new_data_grads_norm = 3.2094
	old_data_grads_norm = 3.9009
	sim_grads_norm_tr = -0.0070
-- Starting training on experience 188 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1778
	data_grads_norm = 3.0794
	new_data_grads_norm = 5.5534
	old_data_grads_norm = 3.4305
	sim_grads_norm_tr = -0.0663
-- Starting training on experience 189 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3495
	data_grads_norm = 3.4714
	new_data_grads_norm = 5.7535
	old_data_grads_norm = 4.9111
	sim_grads_norm_tr = 0.1082
-- Starting training on experience 190 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0750
	data_grads_norm = 2.5698
	new_data_grads_norm = 5.1209
	old_data_grads_norm = 3.2316
	sim_grads_norm_tr = -0.0731
-- Starting training on experience 191 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1695
	data_grads_norm = 3.3413
	new_data_grads_norm = 5.7254
	old_data_grads_norm = 2.5937
	sim_grads_norm_tr = -0.0693
-- Starting training on experience 192 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2594
	data_grads_norm = 3.9674
	new_data_grads_norm = 6.0975
	old_data_grads_norm = 3.6051
	sim_grads_norm_tr = 0.5529
-- Starting training on experience 193 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9851
	data_grads_norm = 2.1788
	new_data_grads_norm = 5.6066
	old_data_grads_norm = 2.5384
	sim_grads_norm_tr = -0.2727
-- Starting training on experience 194 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0701
	data_grads_norm = 2.5540
	new_data_grads_norm = 4.5679
	old_data_grads_norm = 2.7879
	sim_grads_norm_tr = 0.1292
-- Starting training on experience 195 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7948
	data_grads_norm = 4.6579
	new_data_grads_norm = 5.6822
	old_data_grads_norm = 5.5812
	sim_grads_norm_tr = 0.2296
-- Starting training on experience 196 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1176
	data_grads_norm = 1.9165
	new_data_grads_norm = 4.9285
	old_data_grads_norm = 2.3675
	sim_grads_norm_tr = -0.4329
-- Starting training on experience 197 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1845
	data_grads_norm = 2.6198
	new_data_grads_norm = 5.2214
	old_data_grads_norm = 1.9414
	sim_grads_norm_tr = -0.0448
-- Starting training on experience 198 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8687
	data_grads_norm = 2.4240
	new_data_grads_norm = 5.6845
	old_data_grads_norm = 2.8920
	sim_grads_norm_tr = -0.1284
-- Starting training on experience 199 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9576
	data_grads_norm = 3.1563
	new_data_grads_norm = 7.6629
	old_data_grads_norm = 2.0960
	sim_grads_norm_tr = -0.2794
-- Starting training on experience 200 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7729
	data_grads_norm = 4.3468
	new_data_grads_norm = 6.8280
	old_data_grads_norm = 3.1889
	sim_grads_norm_tr = 0.2678
-- Starting training on experience 201 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2311
	data_grads_norm = 3.3432
	new_data_grads_norm = 7.8450
	old_data_grads_norm = 3.9778
	sim_grads_norm_tr = 0.0375
-- Starting training on experience 202 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3779
	data_grads_norm = 3.4743
	new_data_grads_norm = 6.2991
	old_data_grads_norm = 3.6958
	sim_grads_norm_tr = 0.2536
-- Starting training on experience 203 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0605
	data_grads_norm = 2.1306
	new_data_grads_norm = 5.8281
	old_data_grads_norm = 2.8893
	sim_grads_norm_tr = -0.0030
-- Starting training on experience 204 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1391
	data_grads_norm = 2.1746
	new_data_grads_norm = 6.6944
	old_data_grads_norm = 1.2966
	sim_grads_norm_tr = -0.1614
-- Starting training on experience 205 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8865
	data_grads_norm = 2.4285
	new_data_grads_norm = 4.6562
	old_data_grads_norm = 1.8209
	sim_grads_norm_tr = 0.3539
-- Starting training on experience 206 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3216
	data_grads_norm = 4.8626
	new_data_grads_norm = 4.8936
	old_data_grads_norm = 6.1223
	sim_grads_norm_tr = 0.5422
-- Starting training on experience 207 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.6396
	data_grads_norm = 1.7894
	new_data_grads_norm = 3.3262
	old_data_grads_norm = 3.7421
	sim_grads_norm_tr = -0.4388
-- Starting training on experience 208 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7759
	data_grads_norm = 2.1159
	new_data_grads_norm = 3.8960
	old_data_grads_norm = 4.3312
	sim_grads_norm_tr = -0.3675
-- Starting training on experience 209 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0744
	data_grads_norm = 3.6613
	new_data_grads_norm = 5.9399
	old_data_grads_norm = 2.9560
	sim_grads_norm_tr = 0.3588
-- Starting training on experience 210 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1291
	data_grads_norm = 3.5754
	new_data_grads_norm = 5.4435
	old_data_grads_norm = 3.3453
	sim_grads_norm_tr = -0.0961
-- Starting training on experience 211 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9636
	data_grads_norm = 2.5782
	new_data_grads_norm = 5.7889
	old_data_grads_norm = 2.1631
	sim_grads_norm_tr = 0.2156
-- Starting training on experience 212 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0021
	data_grads_norm = 2.1883
	new_data_grads_norm = 5.2262
	old_data_grads_norm = 2.9483
	sim_grads_norm_tr = -0.1614
-- Starting training on experience 213 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7941
	data_grads_norm = 1.8473
	new_data_grads_norm = 5.4057
	old_data_grads_norm = 1.8650
	sim_grads_norm_tr = -0.0465
-- Starting training on experience 214 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9947
	data_grads_norm = 2.4832
	new_data_grads_norm = 5.7351
	old_data_grads_norm = 2.7808
	sim_grads_norm_tr = -0.0605
-- Starting training on experience 215 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9869
	data_grads_norm = 5.1598
	new_data_grads_norm = 6.8172
	old_data_grads_norm = 7.0873
	sim_grads_norm_tr = 0.1165
-- Starting training on experience 216 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0259
	data_grads_norm = 2.5028
	new_data_grads_norm = 3.6309
	old_data_grads_norm = 4.2462
	sim_grads_norm_tr = -0.2564
-- Starting training on experience 217 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1178
	data_grads_norm = 3.1309
	new_data_grads_norm = 5.7387
	old_data_grads_norm = 3.4814
	sim_grads_norm_tr = 0.1620
-- Starting training on experience 218 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4807
	data_grads_norm = 3.5838
	new_data_grads_norm = 5.4328
	old_data_grads_norm = 4.5065
	sim_grads_norm_tr = -0.0329
-- Starting training on experience 219 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1574
	data_grads_norm = 4.2752
	new_data_grads_norm = 4.8653
	old_data_grads_norm = 4.3882
	sim_grads_norm_tr = 0.4207
-- Starting training on experience 220 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1869
	data_grads_norm = 2.7976
	new_data_grads_norm = 4.6840
	old_data_grads_norm = 3.4190
	sim_grads_norm_tr = -0.1387
-- Starting training on experience 221 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2175
	data_grads_norm = 3.0532
	new_data_grads_norm = 5.0428
	old_data_grads_norm = 2.9412
	sim_grads_norm_tr = 0.2243
-- Starting training on experience 222 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9646
	data_grads_norm = 1.9695
	new_data_grads_norm = 3.3524
	old_data_grads_norm = 2.4123
	sim_grads_norm_tr = -0.1826
-- Starting training on experience 223 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2508
	data_grads_norm = 3.5805
	new_data_grads_norm = 5.4811
	old_data_grads_norm = 3.8439
	sim_grads_norm_tr = 0.1449
-- Starting training on experience 224 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9644
	data_grads_norm = 2.5563
	new_data_grads_norm = 5.0706
	old_data_grads_norm = 2.3782
	sim_grads_norm_tr = 0.2152
-- Starting training on experience 225 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9048
	data_grads_norm = 1.9885
	new_data_grads_norm = 4.3481
	old_data_grads_norm = 2.6585
	sim_grads_norm_tr = -0.4696
-- Starting training on experience 226 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8632
	data_grads_norm = 2.4163
	new_data_grads_norm = 3.9701
	old_data_grads_norm = 2.9746
	sim_grads_norm_tr = -0.1612
-- Starting training on experience 227 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8420
	data_grads_norm = 2.5090
	new_data_grads_norm = 4.7837
	old_data_grads_norm = 1.6952
	sim_grads_norm_tr = -0.0856
-- Starting training on experience 228 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1585
	data_grads_norm = 3.3140
	new_data_grads_norm = 5.5278
	old_data_grads_norm = 4.0479
	sim_grads_norm_tr = 0.1278
-- Starting training on experience 229 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5626
	data_grads_norm = 5.4243
	new_data_grads_norm = 6.1310
	old_data_grads_norm = 5.8431
	sim_grads_norm_tr = 0.4993
-- Starting training on experience 230 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2595
	data_grads_norm = 4.4987
	new_data_grads_norm = 5.7337
	old_data_grads_norm = 6.1283
	sim_grads_norm_tr = 0.3934
-- Starting training on experience 231 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8955
	data_grads_norm = 3.1759
	new_data_grads_norm = 5.7500
	old_data_grads_norm = 2.4525
	sim_grads_norm_tr = 0.4297
-- Starting training on experience 232 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8200
	data_grads_norm = 2.1810
	new_data_grads_norm = 4.0067
	old_data_grads_norm = 2.8470
	sim_grads_norm_tr = -0.2313
-- Starting training on experience 233 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.6801
	data_grads_norm = 2.1290
	new_data_grads_norm = 4.4643
	old_data_grads_norm = 3.3769
	sim_grads_norm_tr = -0.3447
-- Starting training on experience 234 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8615
	data_grads_norm = 2.4921
	new_data_grads_norm = 6.5078
	old_data_grads_norm = 3.2279
	sim_grads_norm_tr = -0.1468
-- Starting training on experience 235 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8343
	data_grads_norm = 5.5434
	new_data_grads_norm = 6.3011
	old_data_grads_norm = 7.0900
	sim_grads_norm_tr = 0.4565
-- Starting training on experience 236 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8846
	data_grads_norm = 2.0400
	new_data_grads_norm = 3.5765
	old_data_grads_norm = 2.1606
	sim_grads_norm_tr = 0.0017
-- Starting training on experience 237 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0144
	data_grads_norm = 2.9317
	new_data_grads_norm = 3.5261
	old_data_grads_norm = 3.9775
	sim_grads_norm_tr = 0.0646
-- Starting training on experience 238 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8760
	data_grads_norm = 3.0136
	new_data_grads_norm = 4.9523
	old_data_grads_norm = 2.2346
	sim_grads_norm_tr = 0.1356
-- Starting training on experience 239 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7489
	data_grads_norm = 2.1470
	new_data_grads_norm = 4.0436
	old_data_grads_norm = 2.3119
	sim_grads_norm_tr = 0.0509
-- Starting training on experience 240 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9922
	data_grads_norm = 1.8663
	new_data_grads_norm = 4.8006
	old_data_grads_norm = 3.6309
	sim_grads_norm_tr = -0.3459
-- Starting training on experience 241 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0072
	data_grads_norm = 3.3585
	new_data_grads_norm = 5.5680
	old_data_grads_norm = 3.8399
	sim_grads_norm_tr = 0.1930
-- Starting training on experience 242 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9793
	data_grads_norm = 2.6277
	new_data_grads_norm = 4.8917
	old_data_grads_norm = 1.9414
	sim_grads_norm_tr = 0.0692
-- Starting training on experience 243 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5742
	data_grads_norm = 4.6229
	new_data_grads_norm = 6.0322
	old_data_grads_norm = 4.9266
	sim_grads_norm_tr = 0.4919
-- Starting training on experience 244 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4257
	data_grads_norm = 3.6453
	new_data_grads_norm = 5.5510
	old_data_grads_norm = 3.5558
	sim_grads_norm_tr = 0.1363
-- Starting training on experience 245 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9114
	data_grads_norm = 2.6511
	new_data_grads_norm = 4.0462
	old_data_grads_norm = 3.2217
	sim_grads_norm_tr = -0.0602
-- Starting training on experience 246 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1251
	data_grads_norm = 2.4529
	new_data_grads_norm = 3.9846
	old_data_grads_norm = 3.6609
	sim_grads_norm_tr = -0.1636
-- Starting training on experience 247 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9041
	data_grads_norm = 2.4685
	new_data_grads_norm = 4.7702
	old_data_grads_norm = 2.5707
	sim_grads_norm_tr = 0.2226
-- Starting training on experience 248 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4850
	data_grads_norm = 4.4905
	new_data_grads_norm = 4.9479
	old_data_grads_norm = 5.3428
	sim_grads_norm_tr = 0.3486
-- Starting training on experience 249 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.6567
	data_grads_norm = 1.6666
	new_data_grads_norm = 3.6604
	old_data_grads_norm = 2.1128
	sim_grads_norm_tr = -0.3102
-- Starting training on experience 250 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0103
	data_grads_norm = 2.5876
	new_data_grads_norm = 4.3676
	old_data_grads_norm = 4.4518
	sim_grads_norm_tr = -0.2645
-- Starting training on experience 251 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1003
	data_grads_norm = 2.4147
	new_data_grads_norm = 5.9259
	old_data_grads_norm = 5.2537
	sim_grads_norm_tr = -0.1965
-- Starting training on experience 252 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0545
	data_grads_norm = 5.8970
	new_data_grads_norm = 7.2845
	old_data_grads_norm = 5.8283
	sim_grads_norm_tr = 0.1776
-- Starting training on experience 253 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9094
	data_grads_norm = 5.2293
	new_data_grads_norm = 5.7012
	old_data_grads_norm = 4.9331
	sim_grads_norm_tr = 0.3674
-- Starting training on experience 254 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9548
	data_grads_norm = 2.9268
	new_data_grads_norm = 4.0928
	old_data_grads_norm = 3.7475
	sim_grads_norm_tr = 0.1315
-- Starting training on experience 255 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7538
	data_grads_norm = 1.6850
	new_data_grads_norm = 5.9628
	old_data_grads_norm = 2.4630
	sim_grads_norm_tr = -0.4016
-- Starting training on experience 256 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9299
	data_grads_norm = 2.6052
	new_data_grads_norm = 5.0622
	old_data_grads_norm = 3.2978
	sim_grads_norm_tr = -0.0679
-- Starting training on experience 257 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3074
	data_grads_norm = 3.6622
	new_data_grads_norm = 6.0639
	old_data_grads_norm = 3.4568
	sim_grads_norm_tr = 0.4060
-- Starting training on experience 258 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0262
	data_grads_norm = 3.0852
	new_data_grads_norm = 5.2558
	old_data_grads_norm = 3.3893
	sim_grads_norm_tr = -0.0931
-- Starting training on experience 259 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1120
	data_grads_norm = 3.3259
	new_data_grads_norm = 6.5205
	old_data_grads_norm = 2.7722
	sim_grads_norm_tr = -0.0599
-- Starting training on experience 260 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2378
	data_grads_norm = 3.5158
	new_data_grads_norm = 4.2319
	old_data_grads_norm = 5.0407
	sim_grads_norm_tr = 0.2307
-- Starting training on experience 261 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8446
	data_grads_norm = 2.0921
	new_data_grads_norm = 3.7622
	old_data_grads_norm = 4.8285
	sim_grads_norm_tr = -0.4450
-- Starting training on experience 262 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1416
	data_grads_norm = 3.8548
	new_data_grads_norm = 4.9602
	old_data_grads_norm = 4.1074
	sim_grads_norm_tr = 0.4936
-- Starting training on experience 263 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7006
	data_grads_norm = 2.0378
	new_data_grads_norm = 3.2196
	old_data_grads_norm = 3.1993
	sim_grads_norm_tr = 0.0348
-- Starting training on experience 264 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2615
	data_grads_norm = 4.0079
	new_data_grads_norm = 4.8536
	old_data_grads_norm = 6.0442
	sim_grads_norm_tr = 0.2562
-- Starting training on experience 265 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2001
	data_grads_norm = 3.4171
	new_data_grads_norm = 4.4071
	old_data_grads_norm = 3.4108
	sim_grads_norm_tr = 0.5373
-- Starting training on experience 266 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8107
	data_grads_norm = 3.1458
	new_data_grads_norm = 2.5115
	old_data_grads_norm = 7.1322
	sim_grads_norm_tr = -0.0312
-- Starting training on experience 267 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.6961
	data_grads_norm = 1.9277
	new_data_grads_norm = 4.9153
	old_data_grads_norm = 3.1980
	sim_grads_norm_tr = -0.1682
-- Starting training on experience 268 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3452
	data_grads_norm = 4.7638
	new_data_grads_norm = 7.2121
	old_data_grads_norm = 4.9116
	sim_grads_norm_tr = 0.3748
-- Starting training on experience 269 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8972
	data_grads_norm = 2.3485
	new_data_grads_norm = 3.8912
	old_data_grads_norm = 2.8585
	sim_grads_norm_tr = -0.0355
-- Starting training on experience 270 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3088
	data_grads_norm = 3.8345
	new_data_grads_norm = 5.8294
	old_data_grads_norm = 3.4453
	sim_grads_norm_tr = 0.1187
-- Starting training on experience 271 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7284
	data_grads_norm = 2.1068
	new_data_grads_norm = 3.7905
	old_data_grads_norm = 3.8310
	sim_grads_norm_tr = -0.5117
-- Starting training on experience 272 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5432
	data_grads_norm = 3.9551
	new_data_grads_norm = 5.0339
	old_data_grads_norm = 4.8055
	sim_grads_norm_tr = 0.4298
-- Starting training on experience 273 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0151
	data_grads_norm = 2.9353
	new_data_grads_norm = 3.7998
	old_data_grads_norm = 3.7764
	sim_grads_norm_tr = 0.0548
-- Starting training on experience 274 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9377
	data_grads_norm = 2.4928
	new_data_grads_norm = 4.3315
	old_data_grads_norm = 2.6407
	sim_grads_norm_tr = 0.0899
-- Starting training on experience 275 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2483
	data_grads_norm = 3.1405
	new_data_grads_norm = 5.4276
	old_data_grads_norm = 3.6388
	sim_grads_norm_tr = 0.2279
-- Starting training on experience 276 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2340
	data_grads_norm = 3.1957
	new_data_grads_norm = 5.5108
	old_data_grads_norm = 3.3487
	sim_grads_norm_tr = 0.1888
-- Starting training on experience 277 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4483
	data_grads_norm = 4.3086
	new_data_grads_norm = 5.9672
	old_data_grads_norm = 5.2268
	sim_grads_norm_tr = 0.2446
-- Starting training on experience 278 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9483
	data_grads_norm = 2.8603
	new_data_grads_norm = 5.9925
	old_data_grads_norm = 2.5415
	sim_grads_norm_tr = 0.2659
-- Starting training on experience 279 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0070
	data_grads_norm = 2.7826
	new_data_grads_norm = 4.8887
	old_data_grads_norm = 3.3603
	sim_grads_norm_tr = -0.1157
-- Starting training on experience 280 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1629
	data_grads_norm = 2.1795
	new_data_grads_norm = 3.6562
	old_data_grads_norm = 2.8298
	sim_grads_norm_tr = -0.1395
-- Starting training on experience 281 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9181
	data_grads_norm = 2.2975
	new_data_grads_norm = 4.1646
	old_data_grads_norm = 3.4011
	sim_grads_norm_tr = -0.2383
-- Starting training on experience 282 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8553
	data_grads_norm = 2.1594
	new_data_grads_norm = 5.2544
	old_data_grads_norm = 2.4042
	sim_grads_norm_tr = 0.0686
-- Starting training on experience 283 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1570
	data_grads_norm = 3.3627
	new_data_grads_norm = 4.5680
	old_data_grads_norm = 4.4147
	sim_grads_norm_tr = 0.2876
-- Starting training on experience 284 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9759
	data_grads_norm = 1.7208
	new_data_grads_norm = 4.0615
	old_data_grads_norm = 1.7630
	sim_grads_norm_tr = -0.0002
-- Starting training on experience 285 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8979
	data_grads_norm = 1.7665
	new_data_grads_norm = 4.5734
	old_data_grads_norm = 3.2692
	sim_grads_norm_tr = -0.3293
-- Starting training on experience 286 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0261
	data_grads_norm = 2.3085
	new_data_grads_norm = 3.9986
	old_data_grads_norm = 4.3321
	sim_grads_norm_tr = -0.1176
-- Starting training on experience 287 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9754
	data_grads_norm = 2.3674
	new_data_grads_norm = 5.2706
	old_data_grads_norm = 2.4842
	sim_grads_norm_tr = 0.2840
-- Starting training on experience 288 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8345
	data_grads_norm = 1.8850
	new_data_grads_norm = 4.4472
	old_data_grads_norm = 2.2842
	sim_grads_norm_tr = -0.3047
-- Starting training on experience 289 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4183
	data_grads_norm = 4.1218
	new_data_grads_norm = 5.6090
	old_data_grads_norm = 4.4115
	sim_grads_norm_tr = 0.3631
-- Starting training on experience 290 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3033
	data_grads_norm = 2.9754
	new_data_grads_norm = 4.7747
	old_data_grads_norm = 3.7470
	sim_grads_norm_tr = -0.0795
-- Starting training on experience 291 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4156
	data_grads_norm = 3.5117
	new_data_grads_norm = 5.6858
	old_data_grads_norm = 2.8265
	sim_grads_norm_tr = 0.2213
-- Starting training on experience 292 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8618
	data_grads_norm = 2.0768
	new_data_grads_norm = 3.9910
	old_data_grads_norm = 2.0321
	sim_grads_norm_tr = 0.3327
-- Starting training on experience 293 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0062
	data_grads_norm = 2.2832
	new_data_grads_norm = 5.3716
	old_data_grads_norm = 2.1957
	sim_grads_norm_tr = -0.0928
-- Starting training on experience 294 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9513
	data_grads_norm = 3.2580
	new_data_grads_norm = 4.8540
	old_data_grads_norm = 3.9599
	sim_grads_norm_tr = 0.5492
-- Starting training on experience 295 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7465
	data_grads_norm = 2.2764
	new_data_grads_norm = 5.0593
	old_data_grads_norm = 1.8074
	sim_grads_norm_tr = 0.3556
-- Starting training on experience 296 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7307
	data_grads_norm = 1.6597
	new_data_grads_norm = 5.6396
	old_data_grads_norm = 1.4996
	sim_grads_norm_tr = -0.2306
-- Starting training on experience 297 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8735
	data_grads_norm = 1.8546
	new_data_grads_norm = 4.3802
	old_data_grads_norm = 2.0543
	sim_grads_norm_tr = 0.1041
-- Starting training on experience 298 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8526
	data_grads_norm = 1.6333
	new_data_grads_norm = 5.0938
	old_data_grads_norm = 3.0783
	sim_grads_norm_tr = -0.4307
-- Starting training on experience 299 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0203
	data_grads_norm = 1.9724
	new_data_grads_norm = 3.8665
	old_data_grads_norm = 2.2307
	sim_grads_norm_tr = 0.0780
-- Starting training on experience 300 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.6745
	data_grads_norm = 1.3079
	new_data_grads_norm = 4.8606
	old_data_grads_norm = 2.4075
	sim_grads_norm_tr = -0.3912
-- Starting training on experience 301 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8286
	data_grads_norm = 5.3947
	new_data_grads_norm = 5.9590
	old_data_grads_norm = 5.7282
	sim_grads_norm_tr = 0.7079
-- Starting training on experience 302 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1394
	data_grads_norm = 2.3062
	new_data_grads_norm = 4.3880
	old_data_grads_norm = 2.5510
	sim_grads_norm_tr = -0.1871
-- Starting training on experience 303 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2456
	data_grads_norm = 3.7970
	new_data_grads_norm = 5.8268
	old_data_grads_norm = 4.7379
	sim_grads_norm_tr = 0.1794
-- Starting training on experience 304 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0098
	data_grads_norm = 3.3358
	new_data_grads_norm = 5.8930
	old_data_grads_norm = 3.3496
	sim_grads_norm_tr = -0.1336
-- Starting training on experience 305 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9833
	data_grads_norm = 2.5119
	new_data_grads_norm = 4.9984
	old_data_grads_norm = 3.3300
	sim_grads_norm_tr = 0.0068
-- Starting training on experience 306 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9656
	data_grads_norm = 2.6933
	new_data_grads_norm = 6.1857
	old_data_grads_norm = 2.1136
	sim_grads_norm_tr = -0.4373
-- Starting training on experience 307 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1861
	data_grads_norm = 2.7573
	new_data_grads_norm = 6.4837
	old_data_grads_norm = 2.6522
	sim_grads_norm_tr = -0.0143
-- Starting training on experience 308 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5966
	data_grads_norm = 4.9257
	new_data_grads_norm = 5.8500
	old_data_grads_norm = 4.9445
	sim_grads_norm_tr = 0.5995
-- Starting training on experience 309 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0355
	data_grads_norm = 3.2063
	new_data_grads_norm = 8.2297
	old_data_grads_norm = 3.1553
	sim_grads_norm_tr = -0.3829
-- Starting training on experience 310 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4816
	data_grads_norm = 5.1442
	new_data_grads_norm = 8.2700
	old_data_grads_norm = 6.7315
	sim_grads_norm_tr = 0.1523
-- Starting training on experience 311 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1942
	data_grads_norm = 3.0710
	new_data_grads_norm = 5.9478
	old_data_grads_norm = 3.1759
	sim_grads_norm_tr = 0.0824
-- Starting training on experience 312 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9098
	data_grads_norm = 2.6321
	new_data_grads_norm = 4.1409
	old_data_grads_norm = 4.8437
	sim_grads_norm_tr = -0.1405
-- Starting training on experience 313 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5645
	data_grads_norm = 5.9636
	new_data_grads_norm = 6.6927
	old_data_grads_norm = 9.4965
	sim_grads_norm_tr = -0.0258
-- Starting training on experience 314 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1953
	data_grads_norm = 2.8060
	new_data_grads_norm = 5.5936
	old_data_grads_norm = 4.0787
	sim_grads_norm_tr = -0.0808
-- Starting training on experience 315 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1623
	data_grads_norm = 3.0385
	new_data_grads_norm = 6.7068
	old_data_grads_norm = 2.9281
	sim_grads_norm_tr = 0.3157
-- Starting training on experience 316 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2249
	data_grads_norm = 3.8107
	new_data_grads_norm = 5.0895
	old_data_grads_norm = 6.0658
	sim_grads_norm_tr = 0.0703
-- Starting training on experience 317 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3482
	data_grads_norm = 3.0358
	new_data_grads_norm = 5.8403
	old_data_grads_norm = 3.3456
	sim_grads_norm_tr = 0.2389
-- Starting training on experience 318 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8780
	data_grads_norm = 1.9077
	new_data_grads_norm = 3.9245
	old_data_grads_norm = 2.0035
	sim_grads_norm_tr = 0.2406
-- Starting training on experience 319 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7414
	data_grads_norm = 1.3728
	new_data_grads_norm = 2.7992
	old_data_grads_norm = 2.9733
	sim_grads_norm_tr = -0.5222
-- Starting training on experience 320 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9037
	data_grads_norm = 2.4069
	new_data_grads_norm = 4.8433
	old_data_grads_norm = 1.9722
	sim_grads_norm_tr = 0.2440
-- Starting training on experience 321 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9578
	data_grads_norm = 2.2078
	new_data_grads_norm = 6.7391
	old_data_grads_norm = 2.3711
	sim_grads_norm_tr = -0.2897
-- Starting training on experience 322 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8825
	data_grads_norm = 2.4769
	new_data_grads_norm = 5.7797
	old_data_grads_norm = 2.0871
	sim_grads_norm_tr = -0.3533
-- Starting training on experience 323 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0566
	data_grads_norm = 2.6728
	new_data_grads_norm = 5.9853
	old_data_grads_norm = 3.1561
	sim_grads_norm_tr = -0.0764
-- Starting training on experience 324 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0244
	data_grads_norm = 2.3912
	new_data_grads_norm = 6.3001
	old_data_grads_norm = 2.4967
	sim_grads_norm_tr = 0.0547
-- Starting training on experience 325 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0436
	data_grads_norm = 2.8936
	new_data_grads_norm = 6.0142
	old_data_grads_norm = 2.2016
	sim_grads_norm_tr = -0.0834
-- Starting training on experience 326 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6091
	data_grads_norm = 4.0202
	new_data_grads_norm = 6.3213
	old_data_grads_norm = 3.3125
	sim_grads_norm_tr = 0.3679
-- Starting training on experience 327 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5417
	data_grads_norm = 5.6132
	new_data_grads_norm = 7.4013
	old_data_grads_norm = 5.3783
	sim_grads_norm_tr = 0.1211
-- Starting training on experience 328 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0890
	data_grads_norm = 2.7385
	new_data_grads_norm = 5.0119
	old_data_grads_norm = 2.6824
	sim_grads_norm_tr = 0.1394
-- Starting training on experience 329 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8543
	data_grads_norm = 2.0873
	new_data_grads_norm = 4.2859
	old_data_grads_norm = 3.4919
	sim_grads_norm_tr = -0.2931
-- Starting training on experience 330 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4769
	data_grads_norm = 3.3678
	new_data_grads_norm = 4.7494
	old_data_grads_norm = 4.1072
	sim_grads_norm_tr = 0.1543
-- Starting training on experience 331 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0888
	data_grads_norm = 2.1793
	new_data_grads_norm = 4.4592
	old_data_grads_norm = 2.7682
	sim_grads_norm_tr = -0.1731
-- Starting training on experience 332 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1225
	data_grads_norm = 2.3626
	new_data_grads_norm = 5.2621
	old_data_grads_norm = 2.2037
	sim_grads_norm_tr = 0.2260
-- Starting training on experience 333 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3587
	data_grads_norm = 3.0344
	new_data_grads_norm = 5.4984
	old_data_grads_norm = 3.2752
	sim_grads_norm_tr = -0.0572
-- Starting training on experience 334 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0233
	data_grads_norm = 2.5281
	new_data_grads_norm = 5.3909
	old_data_grads_norm = 3.6120
	sim_grads_norm_tr = -0.1741
-- Starting training on experience 335 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1662
	data_grads_norm = 2.9844
	new_data_grads_norm = 5.2356
	old_data_grads_norm = 3.0694
	sim_grads_norm_tr = 0.2372
-- Starting training on experience 336 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8855
	data_grads_norm = 2.6744
	new_data_grads_norm = 5.4866
	old_data_grads_norm = 2.6345
	sim_grads_norm_tr = 0.1051
-- Starting training on experience 337 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4225
	data_grads_norm = 3.9696
	new_data_grads_norm = 6.1535
	old_data_grads_norm = 3.0357
	sim_grads_norm_tr = 0.2395
-- Starting training on experience 338 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4586
	data_grads_norm = 3.3579
	new_data_grads_norm = 6.1375
	old_data_grads_norm = 3.3660
	sim_grads_norm_tr = 0.1775
-- Starting training on experience 339 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9926
	data_grads_norm = 2.1568
	new_data_grads_norm = 5.8149
	old_data_grads_norm = 1.7245
	sim_grads_norm_tr = 0.1624
-- Starting training on experience 340 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1698
	data_grads_norm = 3.6234
	new_data_grads_norm = 5.0893
	old_data_grads_norm = 4.4207
	sim_grads_norm_tr = 0.0672
-- Starting training on experience 341 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0168
	data_grads_norm = 1.8613
	new_data_grads_norm = 3.8235
	old_data_grads_norm = 3.7953
	sim_grads_norm_tr = -0.5345
-- Starting training on experience 342 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4846
	data_grads_norm = 3.8972
	new_data_grads_norm = 4.8806
	old_data_grads_norm = 3.7219
	sim_grads_norm_tr = 0.5172
-- Starting training on experience 343 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8874
	data_grads_norm = 2.6542
	new_data_grads_norm = 5.0014
	old_data_grads_norm = 4.5429
	sim_grads_norm_tr = 0.1594
-- Starting training on experience 344 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0641
	data_grads_norm = 2.2379
	new_data_grads_norm = 7.0431
	old_data_grads_norm = 2.2447
	sim_grads_norm_tr = -0.2057
-- Starting training on experience 345 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9444
	data_grads_norm = 3.0652
	new_data_grads_norm = 6.9563
	old_data_grads_norm = 2.1450
	sim_grads_norm_tr = -0.2240
-- Starting training on experience 346 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0902
	data_grads_norm = 2.9817
	new_data_grads_norm = 5.4264
	old_data_grads_norm = 3.1918
	sim_grads_norm_tr = 0.2578
-- Starting training on experience 347 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3116
	data_grads_norm = 4.1158
	new_data_grads_norm = 6.0762
	old_data_grads_norm = 3.9436
	sim_grads_norm_tr = 0.3668
-- Starting training on experience 348 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0892
	data_grads_norm = 2.9202
	new_data_grads_norm = 4.7212
	old_data_grads_norm = 2.3420
	sim_grads_norm_tr = 0.2037
-- Starting training on experience 349 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9760
	data_grads_norm = 2.3612
	new_data_grads_norm = 4.9362
	old_data_grads_norm = 2.2251
	sim_grads_norm_tr = 0.1193
-- Starting training on experience 350 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3069
	data_grads_norm = 3.3207
	new_data_grads_norm = 4.5906
	old_data_grads_norm = 4.4199
	sim_grads_norm_tr = -0.2636
-- Starting training on experience 351 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0512
	data_grads_norm = 3.2790
	new_data_grads_norm = 7.2172
	old_data_grads_norm = 3.2905
	sim_grads_norm_tr = 0.1488
-- Starting training on experience 352 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1998
	data_grads_norm = 2.9637
	new_data_grads_norm = 6.0243
	old_data_grads_norm = 2.8263
	sim_grads_norm_tr = -0.0448
-- Starting training on experience 353 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9195
	data_grads_norm = 2.7327
	new_data_grads_norm = 5.2332
	old_data_grads_norm = 2.1629
	sim_grads_norm_tr = 0.3274
-- Starting training on experience 354 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4421
	data_grads_norm = 3.6034
	new_data_grads_norm = 6.2590
	old_data_grads_norm = 3.8589
	sim_grads_norm_tr = 0.0578
-- Starting training on experience 355 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8401
	data_grads_norm = 1.9963
	new_data_grads_norm = 4.1985
	old_data_grads_norm = 2.9010
	sim_grads_norm_tr = -0.2610
-- Starting training on experience 356 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3385
	data_grads_norm = 3.4280
	new_data_grads_norm = 4.4647
	old_data_grads_norm = 4.3000
	sim_grads_norm_tr = 0.1186
-- Starting training on experience 357 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9761
	data_grads_norm = 2.0300
	new_data_grads_norm = 4.4184
	old_data_grads_norm = 2.3596
	sim_grads_norm_tr = -0.0290
-- Starting training on experience 358 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2408
	data_grads_norm = 3.7507
	new_data_grads_norm = 4.9806
	old_data_grads_norm = 4.2550
	sim_grads_norm_tr = 0.3082
-- Starting training on experience 359 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0716
	data_grads_norm = 2.0954
	new_data_grads_norm = 4.7463
	old_data_grads_norm = 2.8885
	sim_grads_norm_tr = -0.1290
-- Starting training on experience 360 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9576
	data_grads_norm = 1.4366
	new_data_grads_norm = 4.5344
	old_data_grads_norm = 2.4600
	sim_grads_norm_tr = -0.2819
-- Starting training on experience 361 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0784
	data_grads_norm = 2.3845
	new_data_grads_norm = 5.4840
	old_data_grads_norm = 2.5014
	sim_grads_norm_tr = 0.0822
-- Starting training on experience 362 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0774
	data_grads_norm = 3.1514
	new_data_grads_norm = 4.6324
	old_data_grads_norm = 3.5142
	sim_grads_norm_tr = 0.3041
-- Starting training on experience 363 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9320
	data_grads_norm = 3.1404
	new_data_grads_norm = 2.2782
	old_data_grads_norm = 5.3894
	sim_grads_norm_tr = 0.0375
-- Starting training on experience 364 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0929
	data_grads_norm = 2.1003
	new_data_grads_norm = 4.4905
	old_data_grads_norm = 2.6400
	sim_grads_norm_tr = -0.1829
-- Starting training on experience 365 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8219
	data_grads_norm = 1.4435
	new_data_grads_norm = 3.2444
	old_data_grads_norm = 2.2603
	sim_grads_norm_tr = -0.2890
-- Starting training on experience 366 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0548
	data_grads_norm = 2.3832
	new_data_grads_norm = 4.7436
	old_data_grads_norm = 3.1465
	sim_grads_norm_tr = -0.0927
-- Starting training on experience 367 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8160
	data_grads_norm = 2.4525
	new_data_grads_norm = 5.3478
	old_data_grads_norm = 4.0673
	sim_grads_norm_tr = -0.2093
-- Starting training on experience 368 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8636
	data_grads_norm = 5.2993
	new_data_grads_norm = 6.4663
	old_data_grads_norm = 5.9691
	sim_grads_norm_tr = 0.3772
-- Starting training on experience 369 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8976
	data_grads_norm = 2.2921
	new_data_grads_norm = 4.6721
	old_data_grads_norm = 2.7974
	sim_grads_norm_tr = -0.0165
-- Starting training on experience 370 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0105
	data_grads_norm = 2.4471
	new_data_grads_norm = 4.6302
	old_data_grads_norm = 3.1966
	sim_grads_norm_tr = 0.0303
-- Starting training on experience 371 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1790
	data_grads_norm = 3.2254
	new_data_grads_norm = 4.7339
	old_data_grads_norm = 4.5604
	sim_grads_norm_tr = 0.1183
-- Starting training on experience 372 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4689
	data_grads_norm = 4.1057
	new_data_grads_norm = 6.2558
	old_data_grads_norm = 5.0727
	sim_grads_norm_tr = 0.0137
-- Starting training on experience 373 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2416
	data_grads_norm = 3.1462
	new_data_grads_norm = 3.8465
	old_data_grads_norm = 4.7436
	sim_grads_norm_tr = 0.0934
-- Starting training on experience 374 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0255
	data_grads_norm = 1.8481
	new_data_grads_norm = 4.7116
	old_data_grads_norm = 2.5620
	sim_grads_norm_tr = -0.3330
-- Starting training on experience 375 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9752
	data_grads_norm = 2.7912
	new_data_grads_norm = 4.5438
	old_data_grads_norm = 3.8404
	sim_grads_norm_tr = -0.0886
-- Starting training on experience 376 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4564
	data_grads_norm = 3.5901
	new_data_grads_norm = 5.8508
	old_data_grads_norm = 4.7097
	sim_grads_norm_tr = 0.0863
-- Starting training on experience 377 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9769
	data_grads_norm = 2.4711
	new_data_grads_norm = 5.1989
	old_data_grads_norm = 2.2074
	sim_grads_norm_tr = 0.0078
-- Starting training on experience 378 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2921
	data_grads_norm = 3.6760
	new_data_grads_norm = 6.1710
	old_data_grads_norm = 2.7197
	sim_grads_norm_tr = 0.2929
-- Starting training on experience 379 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0841
	data_grads_norm = 2.6567
	new_data_grads_norm = 6.1630
	old_data_grads_norm = 2.4802
	sim_grads_norm_tr = 0.0301
-- Starting training on experience 380 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0157
	data_grads_norm = 3.2754
	new_data_grads_norm = 5.6113
	old_data_grads_norm = 4.1655
	sim_grads_norm_tr = -0.0810
-- Starting training on experience 381 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4130
	data_grads_norm = 3.2344
	new_data_grads_norm = 5.4687
	old_data_grads_norm = 2.3131
	sim_grads_norm_tr = 0.3267
-- Starting training on experience 382 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0399
	data_grads_norm = 2.6220
	new_data_grads_norm = 5.3409
	old_data_grads_norm = 2.2608
	sim_grads_norm_tr = -0.1443
-- Starting training on experience 383 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8509
	data_grads_norm = 5.0373
	new_data_grads_norm = 5.4599
	old_data_grads_norm = 6.5283
	sim_grads_norm_tr = 0.5788
-- Starting training on experience 384 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1211
	data_grads_norm = 3.5028
	new_data_grads_norm = 4.3451
	old_data_grads_norm = 3.9327
	sim_grads_norm_tr = 0.0804
-- Starting training on experience 385 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0878
	data_grads_norm = 3.3955
	new_data_grads_norm = 4.6813
	old_data_grads_norm = 3.7863
	sim_grads_norm_tr = 0.1108
-- Starting training on experience 386 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7196
	data_grads_norm = 1.7836
	new_data_grads_norm = 4.0781
	old_data_grads_norm = 2.1707
	sim_grads_norm_tr = -0.4066
-- Starting training on experience 387 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.6378
	data_grads_norm = 2.0117
	new_data_grads_norm = 3.7055
	old_data_grads_norm = 2.2948
	sim_grads_norm_tr = 0.0302
-- Starting training on experience 388 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8424
	data_grads_norm = 1.9470
	new_data_grads_norm = 4.4633
	old_data_grads_norm = 2.1935
	sim_grads_norm_tr = -0.2079
-- Starting training on experience 389 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9364
	data_grads_norm = 2.4377
	new_data_grads_norm = 4.0698
	old_data_grads_norm = 3.4679
	sim_grads_norm_tr = 0.1538
-- Starting training on experience 390 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1783
	data_grads_norm = 3.6369
	new_data_grads_norm = 5.8057
	old_data_grads_norm = 4.1705
	sim_grads_norm_tr = -0.1760
-- Starting training on experience 391 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7179
	data_grads_norm = 2.5229
	new_data_grads_norm = 4.2298
	old_data_grads_norm = 3.2972
	sim_grads_norm_tr = 0.1323
-- Starting training on experience 392 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8366
	data_grads_norm = 2.0395
	new_data_grads_norm = 2.8884
	old_data_grads_norm = 3.1664
	sim_grads_norm_tr = -0.0712
-- Starting training on experience 393 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8760
	data_grads_norm = 2.7817
	new_data_grads_norm = 4.1879
	old_data_grads_norm = 2.0990
	sim_grads_norm_tr = -0.1380
-- Starting training on experience 394 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0255
	data_grads_norm = 3.3834
	new_data_grads_norm = 5.8388
	old_data_grads_norm = 2.8195
	sim_grads_norm_tr = -0.2260
-- Starting training on experience 395 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.6320
	data_grads_norm = 2.0666
	new_data_grads_norm = 4.2877
	old_data_grads_norm = 2.3905
	sim_grads_norm_tr = -0.0709
-- Starting training on experience 396 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0245
	data_grads_norm = 2.5830
	new_data_grads_norm = 5.2953
	old_data_grads_norm = 2.3849
	sim_grads_norm_tr = 0.1591
-- Starting training on experience 397 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9196
	data_grads_norm = 2.5368
	new_data_grads_norm = 4.0352
	old_data_grads_norm = 2.5859
	sim_grads_norm_tr = 0.2623
-- Starting training on experience 398 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1296
	data_grads_norm = 3.0083
	new_data_grads_norm = 4.7686
	old_data_grads_norm = 4.6948
	sim_grads_norm_tr = -0.0369
-- Starting training on experience 399 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1407
	data_grads_norm = 4.2160
	new_data_grads_norm = 8.1763
	old_data_grads_norm = 6.3357
	sim_grads_norm_tr = -0.0247
-- Starting training on experience 400 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1085
	data_grads_norm = 3.1390
	new_data_grads_norm = 6.3630
	old_data_grads_norm = 3.7802
	sim_grads_norm_tr = 0.1280
-- Starting training on experience 401 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1381
	data_grads_norm = 2.6145
	new_data_grads_norm = 4.7104
	old_data_grads_norm = 3.8760
	sim_grads_norm_tr = 0.0459
-- Starting training on experience 402 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0408
	data_grads_norm = 2.7046
	new_data_grads_norm = 4.3027
	old_data_grads_norm = 4.1420
	sim_grads_norm_tr = 0.0684
-- Starting training on experience 403 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2189
	data_grads_norm = 2.6094
	new_data_grads_norm = 3.9098
	old_data_grads_norm = 2.7575
	sim_grads_norm_tr = 0.1654
-- Starting training on experience 404 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1517
	data_grads_norm = 2.7700
	new_data_grads_norm = 4.2363
	old_data_grads_norm = 2.8041
	sim_grads_norm_tr = 0.1237
-- Starting training on experience 405 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9390
	data_grads_norm = 2.6104
	new_data_grads_norm = 5.6100
	old_data_grads_norm = 3.0942
	sim_grads_norm_tr = -0.2081
-- Starting training on experience 406 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9550
	data_grads_norm = 2.9437
	new_data_grads_norm = 6.0220
	old_data_grads_norm = 2.8705
	sim_grads_norm_tr = 0.2703
-- Starting training on experience 407 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0175
	data_grads_norm = 2.9361
	new_data_grads_norm = 6.3336
	old_data_grads_norm = 2.3943
	sim_grads_norm_tr = -0.0124
-- Starting training on experience 408 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1662
	data_grads_norm = 4.1935
	new_data_grads_norm = 5.1367
	old_data_grads_norm = 4.1292
	sim_grads_norm_tr = 0.5845
-- Starting training on experience 409 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0416
	data_grads_norm = 2.2014
	new_data_grads_norm = 3.5222
	old_data_grads_norm = 3.1240
	sim_grads_norm_tr = -0.0941
-- Starting training on experience 410 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4019
	data_grads_norm = 3.8536
	new_data_grads_norm = 5.9774
	old_data_grads_norm = 4.4097
	sim_grads_norm_tr = 0.0003
-- Starting training on experience 411 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1811
	data_grads_norm = 4.3520
	new_data_grads_norm = 5.4932
	old_data_grads_norm = 1.9784
	sim_grads_norm_tr = 0.0317
-- Starting training on experience 412 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2674
	data_grads_norm = 3.7160
	new_data_grads_norm = 4.7209
	old_data_grads_norm = 4.8175
	sim_grads_norm_tr = 0.1999
-- Starting training on experience 413 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1196
	data_grads_norm = 3.6971
	new_data_grads_norm = 4.5320
	old_data_grads_norm = 3.9257
	sim_grads_norm_tr = 0.5069
-- Starting training on experience 414 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8219
	data_grads_norm = 2.0739
	new_data_grads_norm = 4.2641
	old_data_grads_norm = 2.1997
	sim_grads_norm_tr = -0.1474
-- Starting training on experience 415 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2255
	data_grads_norm = 3.5197
	new_data_grads_norm = 4.9593
	old_data_grads_norm = 4.0012
	sim_grads_norm_tr = -0.1728
-- Starting training on experience 416 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2641
	data_grads_norm = 3.1559
	new_data_grads_norm = 5.1891
	old_data_grads_norm = 3.0957
	sim_grads_norm_tr = 0.1400
-- Starting training on experience 417 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9407
	data_grads_norm = 2.2615
	new_data_grads_norm = 4.6085
	old_data_grads_norm = 3.0364
	sim_grads_norm_tr = -0.2568
-- Starting training on experience 418 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3507
	data_grads_norm = 3.9945
	new_data_grads_norm = 5.7403
	old_data_grads_norm = 4.3700
	sim_grads_norm_tr = 0.5308
-- Starting training on experience 419 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8015
	data_grads_norm = 2.4852
	new_data_grads_norm = 4.0305
	old_data_grads_norm = 3.1427
	sim_grads_norm_tr = -0.0004
-- Starting training on experience 420 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9319
	data_grads_norm = 2.6134
	new_data_grads_norm = 3.5925
	old_data_grads_norm = 3.2988
	sim_grads_norm_tr = 0.3117
-- Starting training on experience 421 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.6625
	data_grads_norm = 1.9788
	new_data_grads_norm = 3.3876
	old_data_grads_norm = 3.7997
	sim_grads_norm_tr = -0.3711
-- Starting training on experience 422 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9735
	data_grads_norm = 3.4449
	new_data_grads_norm = 4.7860
	old_data_grads_norm = 3.4055
	sim_grads_norm_tr = 0.4991
-- Starting training on experience 423 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0618
	data_grads_norm = 2.8506
	new_data_grads_norm = 3.6453
	old_data_grads_norm = 4.1184
	sim_grads_norm_tr = 0.0823
-- Starting training on experience 424 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8954
	data_grads_norm = 3.0664
	new_data_grads_norm = 2.7019
	old_data_grads_norm = 4.7950
	sim_grads_norm_tr = 0.2171
-- Starting training on experience 425 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8990
	data_grads_norm = 2.2452
	new_data_grads_norm = 4.1944
	old_data_grads_norm = 2.5361
	sim_grads_norm_tr = 0.4063
-- Starting training on experience 426 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2305
	data_grads_norm = 3.6509
	new_data_grads_norm = 5.3966
	old_data_grads_norm = 5.0844
	sim_grads_norm_tr = -0.0277
-- Starting training on experience 427 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0337
	data_grads_norm = 2.8206
	new_data_grads_norm = 5.4522
	old_data_grads_norm = 2.5151
	sim_grads_norm_tr = 0.0381
-- Starting training on experience 428 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7716
	data_grads_norm = 1.3503
	new_data_grads_norm = 4.2600
	old_data_grads_norm = 1.9884
	sim_grads_norm_tr = -0.4475
-- Starting training on experience 429 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1122
	data_grads_norm = 3.1771
	new_data_grads_norm = 4.2048
	old_data_grads_norm = 4.1655
	sim_grads_norm_tr = 0.1253
-- Starting training on experience 430 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0510
	data_grads_norm = 2.9181
	new_data_grads_norm = 4.6168
	old_data_grads_norm = 4.6177
	sim_grads_norm_tr = -0.1671
-- Starting training on experience 431 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8048
	data_grads_norm = 2.1131
	new_data_grads_norm = 4.6828
	old_data_grads_norm = 2.2054
	sim_grads_norm_tr = -0.0815
-- Starting training on experience 432 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7270
	data_grads_norm = 1.9306
	new_data_grads_norm = 5.5883
	old_data_grads_norm = 2.9399
	sim_grads_norm_tr = -0.2451
-- Starting training on experience 433 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9738
	data_grads_norm = 2.4993
	new_data_grads_norm = 6.7643
	old_data_grads_norm = 2.6076
	sim_grads_norm_tr = 0.0824
-- Starting training on experience 434 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6676
	data_grads_norm = 5.0730
	new_data_grads_norm = 6.4265
	old_data_grads_norm = 5.2750
	sim_grads_norm_tr = 0.4077
-- Starting training on experience 435 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8649
	data_grads_norm = 1.9589
	new_data_grads_norm = 3.6865
	old_data_grads_norm = 2.9912
	sim_grads_norm_tr = -0.1938
-- Starting training on experience 436 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0887
	data_grads_norm = 2.0552
	new_data_grads_norm = 5.1615
	old_data_grads_norm = 1.7888
	sim_grads_norm_tr = -0.2142
-- Starting training on experience 437 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1732
	data_grads_norm = 3.1700
	new_data_grads_norm = 7.0842
	old_data_grads_norm = 2.4826
	sim_grads_norm_tr = 0.2181
-- Starting training on experience 438 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9542
	data_grads_norm = 2.7000
	new_data_grads_norm = 6.0973
	old_data_grads_norm = 2.9944
	sim_grads_norm_tr = -0.2083
-- Starting training on experience 439 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2370
	data_grads_norm = 3.3874
	new_data_grads_norm = 6.6537
	old_data_grads_norm = 2.8210
	sim_grads_norm_tr = 0.2860
-- Starting training on experience 440 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.6446
	data_grads_norm = 1.7183
	new_data_grads_norm = 4.7138
	old_data_grads_norm = 2.0595
	sim_grads_norm_tr = -0.3164
-- Starting training on experience 441 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9208
	data_grads_norm = 3.0572
	new_data_grads_norm = 6.1375
	old_data_grads_norm = 3.9981
	sim_grads_norm_tr = -0.1149
-- Starting training on experience 442 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9408
	data_grads_norm = 3.2618
	new_data_grads_norm = 7.1781
	old_data_grads_norm = 2.5066
	sim_grads_norm_tr = 0.0740
-- Starting training on experience 443 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0667
	data_grads_norm = 3.7457
	new_data_grads_norm = 7.4294
	old_data_grads_norm = 4.0265
	sim_grads_norm_tr = 0.2002
-- Starting training on experience 444 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7611
	data_grads_norm = 2.4937
	new_data_grads_norm = 6.7182
	old_data_grads_norm = 3.3095
	sim_grads_norm_tr = -0.1785
-- Starting training on experience 445 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4074
	data_grads_norm = 4.6736
	new_data_grads_norm = 6.9202
	old_data_grads_norm = 4.3104
	sim_grads_norm_tr = 0.4921
-- Starting training on experience 446 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8954
	data_grads_norm = 2.2636
	new_data_grads_norm = 5.3372
	old_data_grads_norm = 2.0630
	sim_grads_norm_tr = -0.1739
-- Starting training on experience 447 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8099
	data_grads_norm = 4.7452
	new_data_grads_norm = 6.5956
	old_data_grads_norm = 4.2665
	sim_grads_norm_tr = 0.4089
-- Starting training on experience 448 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7048
	data_grads_norm = 1.9595
	new_data_grads_norm = 4.3684
	old_data_grads_norm = 3.2577
	sim_grads_norm_tr = -0.2224
-- Starting training on experience 449 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0421
	data_grads_norm = 2.4367
	new_data_grads_norm = 5.6050
	old_data_grads_norm = 2.0225
	sim_grads_norm_tr = 0.2115
-- Starting training on experience 450 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2734
	data_grads_norm = 3.2148
	new_data_grads_norm = 5.8380
	old_data_grads_norm = 3.2161
	sim_grads_norm_tr = 0.0915
-- Starting training on experience 451 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3070
	data_grads_norm = 3.5099
	new_data_grads_norm = 5.2181
	old_data_grads_norm = 4.6609
	sim_grads_norm_tr = 0.1678
-- Starting training on experience 452 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2511
	data_grads_norm = 3.5613
	new_data_grads_norm = 3.7161
	old_data_grads_norm = 5.7080
	sim_grads_norm_tr = 0.1702
-- Starting training on experience 453 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.6535
	data_grads_norm = 1.3885
	new_data_grads_norm = 2.4253
	old_data_grads_norm = 2.1369
	sim_grads_norm_tr = -0.2310
-- Starting training on experience 454 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0957
	data_grads_norm = 2.3286
	new_data_grads_norm = 3.2276
	old_data_grads_norm = 3.3841
	sim_grads_norm_tr = -0.2336
-- Starting training on experience 455 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4658
	data_grads_norm = 4.5421
	new_data_grads_norm = 6.1313
	old_data_grads_norm = 4.9201
	sim_grads_norm_tr = 0.3299
-- Starting training on experience 456 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1989
	data_grads_norm = 2.4759
	new_data_grads_norm = 4.4089
	old_data_grads_norm = 4.0038
	sim_grads_norm_tr = -0.2304
-- Starting training on experience 457 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9907
	data_grads_norm = 2.6406
	new_data_grads_norm = 3.7766
	old_data_grads_norm = 3.0661
	sim_grads_norm_tr = 0.2409
-- Starting training on experience 458 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.5490
	data_grads_norm = 1.9420
	new_data_grads_norm = 3.5999
	old_data_grads_norm = 2.9698
	sim_grads_norm_tr = -0.2203
-- Starting training on experience 459 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9594
	data_grads_norm = 2.7881
	new_data_grads_norm = 4.2044
	old_data_grads_norm = 3.6438
	sim_grads_norm_tr = -0.0067
-- Starting training on experience 460 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1459
	data_grads_norm = 2.5574
	new_data_grads_norm = 6.3004
	old_data_grads_norm = 3.5355
	sim_grads_norm_tr = -0.1628
-- Starting training on experience 461 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9682
	data_grads_norm = 2.7927
	new_data_grads_norm = 4.1426
	old_data_grads_norm = 3.9355
	sim_grads_norm_tr = 0.0094
-- Starting training on experience 462 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9972
	data_grads_norm = 2.7233
	new_data_grads_norm = 4.8013
	old_data_grads_norm = 2.2350
	sim_grads_norm_tr = 0.3421
-- Starting training on experience 463 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4436
	data_grads_norm = 3.1965
	new_data_grads_norm = 5.2251
	old_data_grads_norm = 4.1142
	sim_grads_norm_tr = -0.0759
-- Starting training on experience 464 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9735
	data_grads_norm = 2.3770
	new_data_grads_norm = 4.2209
	old_data_grads_norm = 2.3213
	sim_grads_norm_tr = 0.1845
-- Starting training on experience 465 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6255
	data_grads_norm = 3.4739
	new_data_grads_norm = 7.0015
	old_data_grads_norm = 2.5234
	sim_grads_norm_tr = 0.1517
-- Starting training on experience 466 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2367
	data_grads_norm = 3.1135
	new_data_grads_norm = 4.9674
	old_data_grads_norm = 3.0401
	sim_grads_norm_tr = 0.2627
-- Starting training on experience 467 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0962
	data_grads_norm = 2.6469
	new_data_grads_norm = 4.1879
	old_data_grads_norm = 2.3454
	sim_grads_norm_tr = 0.4131
-- Starting training on experience 468 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.6749
	data_grads_norm = 1.7411
	new_data_grads_norm = 3.4308
	old_data_grads_norm = 2.2356
	sim_grads_norm_tr = 0.0082
-- Starting training on experience 469 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1328
	data_grads_norm = 2.3200
	new_data_grads_norm = 4.6093
	old_data_grads_norm = 3.3045
	sim_grads_norm_tr = -0.1961
-- Starting training on experience 470 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9137
	data_grads_norm = 2.0888
	new_data_grads_norm = 4.4282
	old_data_grads_norm = 2.4475
	sim_grads_norm_tr = 0.0230
-- Starting training on experience 471 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0943
	data_grads_norm = 2.7362
	new_data_grads_norm = 5.8583
	old_data_grads_norm = 4.3008
	sim_grads_norm_tr = -0.0929
-- Starting training on experience 472 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0858
	data_grads_norm = 2.5267
	new_data_grads_norm = 4.7885
	old_data_grads_norm = 2.8141
	sim_grads_norm_tr = 0.0987
-- Starting training on experience 473 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0346
	data_grads_norm = 3.5682
	new_data_grads_norm = 5.7539
	old_data_grads_norm = 3.8274
	sim_grads_norm_tr = 0.2807
-- Starting training on experience 474 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1305
	data_grads_norm = 2.7746
	new_data_grads_norm = 3.9104
	old_data_grads_norm = 3.0844
	sim_grads_norm_tr = -0.0183
-- Starting training on experience 475 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4239
	data_grads_norm = 3.2582
	new_data_grads_norm = 3.8482
	old_data_grads_norm = 5.4124
	sim_grads_norm_tr = -0.0987
-- Starting training on experience 476 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8977
	data_grads_norm = 2.1455
	new_data_grads_norm = 4.4656
	old_data_grads_norm = 1.7373
	sim_grads_norm_tr = 0.2729
-- Starting training on experience 477 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1520
	data_grads_norm = 2.8531
	new_data_grads_norm = 3.8141
	old_data_grads_norm = 5.0279
	sim_grads_norm_tr = -0.3651
-- Starting training on experience 478 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7454
	data_grads_norm = 6.4634
	new_data_grads_norm = 6.5846
	old_data_grads_norm = 7.9665
	sim_grads_norm_tr = 0.3295
-- Starting training on experience 479 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5055
	data_grads_norm = 4.4152
	new_data_grads_norm = 6.2857
	old_data_grads_norm = 3.1868
	sim_grads_norm_tr = 0.3570
-- Starting training on experience 480 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0389
	data_grads_norm = 3.1735
	new_data_grads_norm = 4.4206
	old_data_grads_norm = 5.3255
	sim_grads_norm_tr = -0.0541
-- Starting training on experience 481 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8329
	data_grads_norm = 1.8624
	new_data_grads_norm = 5.3650
	old_data_grads_norm = 1.9930
	sim_grads_norm_tr = -0.0759
-- Starting training on experience 482 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8665
	data_grads_norm = 1.5362
	new_data_grads_norm = 4.7003
	old_data_grads_norm = 1.1302
	sim_grads_norm_tr = -0.1351
-- Starting training on experience 483 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9645
	data_grads_norm = 2.0901
	new_data_grads_norm = 6.3255
	old_data_grads_norm = 2.4573
	sim_grads_norm_tr = 0.2125
-- Starting training on experience 484 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8973
	data_grads_norm = 2.2924
	new_data_grads_norm = 5.3401
	old_data_grads_norm = 1.9478
	sim_grads_norm_tr = 0.0042
-- Starting training on experience 485 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9244
	data_grads_norm = 1.8277
	new_data_grads_norm = 6.4637
	old_data_grads_norm = 2.3073
	sim_grads_norm_tr = -0.2630
-- Starting training on experience 486 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0871
	data_grads_norm = 4.7989
	new_data_grads_norm = 5.5184
	old_data_grads_norm = 6.2104
	sim_grads_norm_tr = 0.3373
-- Starting training on experience 487 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9762
	data_grads_norm = 2.0217
	new_data_grads_norm = 4.1909
	old_data_grads_norm = 2.0992
	sim_grads_norm_tr = -0.2764
-- Starting training on experience 488 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9675
	data_grads_norm = 2.3967
	new_data_grads_norm = 5.0169
	old_data_grads_norm = 2.0870
	sim_grads_norm_tr = -0.0538
-- Starting training on experience 489 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9910
	data_grads_norm = 2.4254
	new_data_grads_norm = 5.3227
	old_data_grads_norm = 1.8342
	sim_grads_norm_tr = 0.2826
-- Starting training on experience 490 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2758
	data_grads_norm = 2.8448
	new_data_grads_norm = 5.4765
	old_data_grads_norm = 3.1196
	sim_grads_norm_tr = 0.0513
-- Starting training on experience 491 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1675
	data_grads_norm = 3.3671
	new_data_grads_norm = 4.5245
	old_data_grads_norm = 3.3192
	sim_grads_norm_tr = 0.3058
-- Starting training on experience 492 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9266
	data_grads_norm = 1.8432
	new_data_grads_norm = 3.4278
	old_data_grads_norm = 2.0096
	sim_grads_norm_tr = 0.0751
-- Starting training on experience 493 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0718
	data_grads_norm = 2.8310
	new_data_grads_norm = 2.8193
	old_data_grads_norm = 4.9552
	sim_grads_norm_tr = 0.2589
-- Starting training on experience 494 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7834
	data_grads_norm = 1.5704
	new_data_grads_norm = 5.8826
	old_data_grads_norm = 2.2832
	sim_grads_norm_tr = -0.3501
-- Starting training on experience 495 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3364
	data_grads_norm = 4.0263
	new_data_grads_norm = 5.6827
	old_data_grads_norm = 4.1410
	sim_grads_norm_tr = 0.2513
-- Starting training on experience 496 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9375
	data_grads_norm = 2.1602
	new_data_grads_norm = 5.3545
	old_data_grads_norm = 2.9474
	sim_grads_norm_tr = -0.3342
-- Starting training on experience 497 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7298
	data_grads_norm = 1.5457
	new_data_grads_norm = 4.9660
	old_data_grads_norm = 1.7425
	sim_grads_norm_tr = -0.0446
-- Starting training on experience 498 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1165
	data_grads_norm = 3.0790
	new_data_grads_norm = 4.3859
	old_data_grads_norm = 4.3044
	sim_grads_norm_tr = 0.1892
-- Starting training on experience 499 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8238
	data_grads_norm = 1.5643
	new_data_grads_norm = 4.3180
	old_data_grads_norm = 2.1130
	sim_grads_norm_tr = -0.3600
-- Starting training on experience 500 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0938
	data_grads_norm = 2.6139
	new_data_grads_norm = 6.1102
	old_data_grads_norm = 2.6994
	sim_grads_norm_tr = -0.0345
-- Starting training on experience 501 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7310
	data_grads_norm = 4.7439
	new_data_grads_norm = 6.3338
	old_data_grads_norm = 5.0620
	sim_grads_norm_tr = 0.4384
-- Starting training on experience 502 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1023
	data_grads_norm = 2.8248
	new_data_grads_norm = 4.1908
	old_data_grads_norm = 2.6693
	sim_grads_norm_tr = 0.3376
-- Starting training on experience 503 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0700
	data_grads_norm = 2.2316
	new_data_grads_norm = 4.5057
	old_data_grads_norm = 2.8635
	sim_grads_norm_tr = -0.2166
-- Starting training on experience 504 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2311
	data_grads_norm = 4.0034
	new_data_grads_norm = 3.7356
	old_data_grads_norm = 5.7314
	sim_grads_norm_tr = 0.4499
-- Starting training on experience 505 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1354
	data_grads_norm = 3.6369
	new_data_grads_norm = 2.9388
	old_data_grads_norm = 5.1598
	sim_grads_norm_tr = -0.0586
-- Starting training on experience 506 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.6026
	data_grads_norm = 1.7856
	new_data_grads_norm = 4.0218
	old_data_grads_norm = 2.0938
	sim_grads_norm_tr = -0.1117
-- Starting training on experience 507 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8054
	data_grads_norm = 1.4863
	new_data_grads_norm = 3.3784
	old_data_grads_norm = 2.7136
	sim_grads_norm_tr = -0.3424
-- Starting training on experience 508 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8093
	data_grads_norm = 2.2226
	new_data_grads_norm = 3.8407
	old_data_grads_norm = 1.8551
	sim_grads_norm_tr = -0.0190
-- Starting training on experience 509 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9950
	data_grads_norm = 2.8618
	new_data_grads_norm = 5.3750
	old_data_grads_norm = 3.7584
	sim_grads_norm_tr = 0.1925
-- Starting training on experience 510 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2606
	data_grads_norm = 3.6486
	new_data_grads_norm = 4.7508
	old_data_grads_norm = 4.3568
	sim_grads_norm_tr = 0.1289
-- Starting training on experience 511 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.6885
	data_grads_norm = 1.8064
	new_data_grads_norm = 4.3293
	old_data_grads_norm = 3.0510
	sim_grads_norm_tr = -0.4580
-- Starting training on experience 512 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1329
	data_grads_norm = 3.1194
	new_data_grads_norm = 5.3080
	old_data_grads_norm = 4.3655
	sim_grads_norm_tr = 0.0529
-- Starting training on experience 513 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1014
	data_grads_norm = 2.8622
	new_data_grads_norm = 5.3556
	old_data_grads_norm = 3.2568
	sim_grads_norm_tr = -0.2184
-- Starting training on experience 514 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0298
	data_grads_norm = 2.5588
	new_data_grads_norm = 5.1880
	old_data_grads_norm = 1.9761
	sim_grads_norm_tr = -0.0434
-- Starting training on experience 515 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1384
	data_grads_norm = 3.2726
	new_data_grads_norm = 5.2798
	old_data_grads_norm = 3.8882
	sim_grads_norm_tr = 0.0999
-- Starting training on experience 516 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3208
	data_grads_norm = 3.2135
	new_data_grads_norm = 5.5996
	old_data_grads_norm = 3.2251
	sim_grads_norm_tr = 0.3210
-- Starting training on experience 517 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0327
	data_grads_norm = 2.8053
	new_data_grads_norm = 6.5507
	old_data_grads_norm = 1.6061
	sim_grads_norm_tr = 0.1111
-- Starting training on experience 518 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0104
	data_grads_norm = 2.2282
	new_data_grads_norm = 4.4257
	old_data_grads_norm = 2.8388
	sim_grads_norm_tr = 0.1243
-- Starting training on experience 519 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4268
	data_grads_norm = 3.5933
	new_data_grads_norm = 4.5002
	old_data_grads_norm = 4.1649
	sim_grads_norm_tr = 0.3617
-- Starting training on experience 520 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3667
	data_grads_norm = 3.4394
	new_data_grads_norm = 3.6730
	old_data_grads_norm = 4.4664
	sim_grads_norm_tr = 0.3437
-- Starting training on experience 521 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0411
	data_grads_norm = 2.2597
	new_data_grads_norm = 4.5788
	old_data_grads_norm = 2.3430
	sim_grads_norm_tr = -0.0318
-- Starting training on experience 522 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8036
	data_grads_norm = 1.9848
	new_data_grads_norm = 3.8973
	old_data_grads_norm = 3.9262
	sim_grads_norm_tr = -0.3999
-- Starting training on experience 523 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6108
	data_grads_norm = 4.2493
	new_data_grads_norm = 5.7704
	old_data_grads_norm = 4.2550
	sim_grads_norm_tr = 0.2916
-- Starting training on experience 524 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1302
	data_grads_norm = 2.8622
	new_data_grads_norm = 4.8614
	old_data_grads_norm = 2.7203
	sim_grads_norm_tr = 0.2297
-- Starting training on experience 525 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2638
	data_grads_norm = 3.1291
	new_data_grads_norm = 4.9103
	old_data_grads_norm = 2.2936
	sim_grads_norm_tr = 0.4136
-- Starting training on experience 526 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8318
	data_grads_norm = 2.1062
	new_data_grads_norm = 3.9441
	old_data_grads_norm = 2.8137
	sim_grads_norm_tr = -0.1487
-- Starting training on experience 527 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1913
	data_grads_norm = 2.9314
	new_data_grads_norm = 5.3141
	old_data_grads_norm = 3.4248
	sim_grads_norm_tr = 0.2444
-- Starting training on experience 528 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0074
	data_grads_norm = 2.3369
	new_data_grads_norm = 5.2936
	old_data_grads_norm = 2.5321
	sim_grads_norm_tr = 0.2708
-- Starting training on experience 529 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.6474
	data_grads_norm = 2.0727
	new_data_grads_norm = 5.3230
	old_data_grads_norm = 4.3023
	sim_grads_norm_tr = -0.2953
-- Starting training on experience 530 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1939
	data_grads_norm = 3.4937
	new_data_grads_norm = 6.3410
	old_data_grads_norm = 4.0433
	sim_grads_norm_tr = 0.0981
-- Starting training on experience 531 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3980
	data_grads_norm = 3.5896
	new_data_grads_norm = 5.2026
	old_data_grads_norm = 4.4834
	sim_grads_norm_tr = 0.1488
-- Starting training on experience 532 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2636
	data_grads_norm = 2.9787
	new_data_grads_norm = 4.6474
	old_data_grads_norm = 2.8184
	sim_grads_norm_tr = 0.0962
-- Starting training on experience 533 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9467
	data_grads_norm = 2.9824
	new_data_grads_norm = 4.8672
	old_data_grads_norm = 3.2326
	sim_grads_norm_tr = -0.2258
-- Starting training on experience 534 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8570
	data_grads_norm = 2.4754
	new_data_grads_norm = 5.0085
	old_data_grads_norm = 1.8641
	sim_grads_norm_tr = -0.2753
-- Starting training on experience 535 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2244
	data_grads_norm = 3.0350
	new_data_grads_norm = 5.9001
	old_data_grads_norm = 2.6328
	sim_grads_norm_tr = 0.3687
-- Starting training on experience 536 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1205
	data_grads_norm = 2.7487
	new_data_grads_norm = 5.6340
	old_data_grads_norm = 2.8691
	sim_grads_norm_tr = -0.4074
-- Starting training on experience 537 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1505
	data_grads_norm = 2.5386
	new_data_grads_norm = 5.8966
	old_data_grads_norm = 2.0245
	sim_grads_norm_tr = 0.1152
-- Starting training on experience 538 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1107
	data_grads_norm = 3.3814
	new_data_grads_norm = 5.9493
	old_data_grads_norm = 5.0320
	sim_grads_norm_tr = 0.1307
-- Starting training on experience 539 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9575
	data_grads_norm = 2.3287
	new_data_grads_norm = 5.5706
	old_data_grads_norm = 1.7649
	sim_grads_norm_tr = 0.0457
-- Starting training on experience 540 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9879
	data_grads_norm = 2.4099
	new_data_grads_norm = 6.0633
	old_data_grads_norm = 2.6100
	sim_grads_norm_tr = -0.0781
-- Starting training on experience 541 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8240
	data_grads_norm = 2.0139
	new_data_grads_norm = 3.5708
	old_data_grads_norm = 1.9795
	sim_grads_norm_tr = 0.0433
-- Starting training on experience 542 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3634
	data_grads_norm = 3.7537
	new_data_grads_norm = 6.6822
	old_data_grads_norm = 3.5694
	sim_grads_norm_tr = 0.1021
-- Starting training on experience 543 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1373
	data_grads_norm = 3.8461
	new_data_grads_norm = 5.0837
	old_data_grads_norm = 4.3438
	sim_grads_norm_tr = 0.1073
-- Starting training on experience 544 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8457
	data_grads_norm = 2.1336
	new_data_grads_norm = 5.3917
	old_data_grads_norm = 3.2929
	sim_grads_norm_tr = 0.0088
-- Starting training on experience 545 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8862
	data_grads_norm = 2.3533
	new_data_grads_norm = 5.7603
	old_data_grads_norm = 1.8341
	sim_grads_norm_tr = -0.1201
-- Starting training on experience 546 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1320
	data_grads_norm = 2.5008
	new_data_grads_norm = 3.3706
	old_data_grads_norm = 3.6896
	sim_grads_norm_tr = -0.0288
-- Starting training on experience 547 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8368
	data_grads_norm = 2.0513
	new_data_grads_norm = 3.7955
	old_data_grads_norm = 2.5316
	sim_grads_norm_tr = -0.0458
-- Starting training on experience 548 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8877
	data_grads_norm = 1.8705
	new_data_grads_norm = 5.6596
	old_data_grads_norm = 2.7187
	sim_grads_norm_tr = -0.3565
-- Starting training on experience 549 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0697
	data_grads_norm = 2.9623
	new_data_grads_norm = 5.6849
	old_data_grads_norm = 2.4917
	sim_grads_norm_tr = 0.2961
-- Starting training on experience 550 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8715
	data_grads_norm = 2.6972
	new_data_grads_norm = 5.9179
	old_data_grads_norm = 3.1012
	sim_grads_norm_tr = 0.2699
-- Starting training on experience 551 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0061
	data_grads_norm = 3.7017
	new_data_grads_norm = 5.0828
	old_data_grads_norm = 4.8209
	sim_grads_norm_tr = 0.0155
-- Starting training on experience 552 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7804
	data_grads_norm = 1.8775
	new_data_grads_norm = 3.6970
	old_data_grads_norm = 2.7902
	sim_grads_norm_tr = -0.2388
-- Starting training on experience 553 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9004
	data_grads_norm = 2.3510
	new_data_grads_norm = 4.8104
	old_data_grads_norm = 2.8359
	sim_grads_norm_tr = 0.1401
-- Starting training on experience 554 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9864
	data_grads_norm = 2.3039
	new_data_grads_norm = 4.8156
	old_data_grads_norm = 1.8979
	sim_grads_norm_tr = -0.1757
-- Starting training on experience 555 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2246
	data_grads_norm = 3.6637
	new_data_grads_norm = 5.0280
	old_data_grads_norm = 6.1088
	sim_grads_norm_tr = -0.0570
-- Starting training on experience 556 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1768
	data_grads_norm = 2.8786
	new_data_grads_norm = 5.0070
	old_data_grads_norm = 2.2585
	sim_grads_norm_tr = 0.2065
-- Starting training on experience 557 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9248
	data_grads_norm = 2.0867
	new_data_grads_norm = 4.7704
	old_data_grads_norm = 3.3928
	sim_grads_norm_tr = -0.1424
-- Starting training on experience 558 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.6672
	data_grads_norm = 2.2181
	new_data_grads_norm = 6.7531
	old_data_grads_norm = 2.6150
	sim_grads_norm_tr = -0.0659
-- Starting training on experience 559 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8912
	data_grads_norm = 1.7037
	new_data_grads_norm = 4.4952
	old_data_grads_norm = 2.3880
	sim_grads_norm_tr = -0.3013
-- Starting training on experience 560 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1454
	data_grads_norm = 3.8618
	new_data_grads_norm = 6.9271
	old_data_grads_norm = 2.7038
	sim_grads_norm_tr = 0.0409
-- Starting training on experience 561 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3074
	data_grads_norm = 4.2654
	new_data_grads_norm = 5.9666
	old_data_grads_norm = 6.0765
	sim_grads_norm_tr = 0.1682
-- Starting training on experience 562 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7726
	data_grads_norm = 4.9632
	new_data_grads_norm = 5.5073
	old_data_grads_norm = 5.0033
	sim_grads_norm_tr = 0.4282
-- Starting training on experience 563 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0402
	data_grads_norm = 2.5982
	new_data_grads_norm = 3.6465
	old_data_grads_norm = 4.1512
	sim_grads_norm_tr = -0.0462
-- Starting training on experience 564 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5978
	data_grads_norm = 3.8756
	new_data_grads_norm = 5.3800
	old_data_grads_norm = 4.4796
	sim_grads_norm_tr = 0.0891
-- Starting training on experience 565 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8348
	data_grads_norm = 1.7269
	new_data_grads_norm = 5.0732
	old_data_grads_norm = 2.7168
	sim_grads_norm_tr = -0.1848
-- Starting training on experience 566 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1178
	data_grads_norm = 3.2777
	new_data_grads_norm = 4.9721
	old_data_grads_norm = 3.6559
	sim_grads_norm_tr = 0.2280
-- Starting training on experience 567 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9131
	data_grads_norm = 2.9124
	new_data_grads_norm = 4.9956
	old_data_grads_norm = 2.9298
	sim_grads_norm_tr = 0.3749
-- Starting training on experience 568 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9842
	data_grads_norm = 2.1991
	new_data_grads_norm = 5.0517
	old_data_grads_norm = 3.2797
	sim_grads_norm_tr = -0.3454
-- Starting training on experience 569 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0169
	data_grads_norm = 2.3039
	new_data_grads_norm = 4.6785
	old_data_grads_norm = 2.5614
	sim_grads_norm_tr = 0.3276
-- Starting training on experience 570 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1295
	data_grads_norm = 2.4607
	new_data_grads_norm = 4.6041
	old_data_grads_norm = 2.9070
	sim_grads_norm_tr = -0.0523
-- Starting training on experience 571 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1845
	data_grads_norm = 3.1361
	new_data_grads_norm = 4.6374
	old_data_grads_norm = 2.4604
	sim_grads_norm_tr = -0.0836
-- Starting training on experience 572 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8884
	data_grads_norm = 2.2017
	new_data_grads_norm = 3.7110
	old_data_grads_norm = 3.7073
	sim_grads_norm_tr = 0.1663
-- Starting training on experience 573 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1133
	data_grads_norm = 2.7750
	new_data_grads_norm = 4.3962
	old_data_grads_norm = 4.1428
	sim_grads_norm_tr = 0.1349
-- Starting training on experience 574 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0007
	data_grads_norm = 2.5708
	new_data_grads_norm = 4.9291
	old_data_grads_norm = 2.8074
	sim_grads_norm_tr = -0.2829
-- Starting training on experience 575 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9806
	data_grads_norm = 2.0359
	new_data_grads_norm = 6.2860
	old_data_grads_norm = 1.8635
	sim_grads_norm_tr = 0.0511
-- Starting training on experience 576 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9065
	data_grads_norm = 3.0191
	new_data_grads_norm = 3.9680
	old_data_grads_norm = 3.5647
	sim_grads_norm_tr = 0.0225
-- Starting training on experience 577 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0977
	data_grads_norm = 2.7580
	new_data_grads_norm = 5.7295
	old_data_grads_norm = 2.4635
	sim_grads_norm_tr = -0.3237
-- Starting training on experience 578 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9653
	data_grads_norm = 2.1785
	new_data_grads_norm = 4.8721
	old_data_grads_norm = 2.6134
	sim_grads_norm_tr = -0.0203
-- Starting training on experience 579 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4798
	data_grads_norm = 4.0938
	new_data_grads_norm = 6.0569
	old_data_grads_norm = 4.3956
	sim_grads_norm_tr = 0.0966
-- Starting training on experience 580 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4551
	data_grads_norm = 4.3481
	new_data_grads_norm = 7.0693
	old_data_grads_norm = 4.7819
	sim_grads_norm_tr = 0.1626
-- Starting training on experience 581 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2401
	data_grads_norm = 2.9733
	new_data_grads_norm = 4.3235
	old_data_grads_norm = 4.8988
	sim_grads_norm_tr = -0.0279
-- Starting training on experience 582 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8633
	data_grads_norm = 2.5434
	new_data_grads_norm = 5.4460
	old_data_grads_norm = 1.9001
	sim_grads_norm_tr = 0.0505
-- Starting training on experience 583 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4333
	data_grads_norm = 4.3365
	new_data_grads_norm = 5.2531
	old_data_grads_norm = 6.1063
	sim_grads_norm_tr = 0.1689
-- Starting training on experience 584 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0008
	data_grads_norm = 2.6256
	new_data_grads_norm = 4.9021
	old_data_grads_norm = 3.5955
	sim_grads_norm_tr = -0.1289
-- Starting training on experience 585 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2785
	data_grads_norm = 2.9240
	new_data_grads_norm = 4.5575
	old_data_grads_norm = 2.6595
	sim_grads_norm_tr = 0.0744
-- Starting training on experience 586 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9851
	data_grads_norm = 2.0725
	new_data_grads_norm = 4.2267
	old_data_grads_norm = 1.9146
	sim_grads_norm_tr = 0.0213
-- Starting training on experience 587 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9178
	data_grads_norm = 1.9467
	new_data_grads_norm = 5.4514
	old_data_grads_norm = 1.6482
	sim_grads_norm_tr = -0.1710
-- Starting training on experience 588 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9075
	data_grads_norm = 2.5020
	new_data_grads_norm = 5.0423
	old_data_grads_norm = 3.3224
	sim_grads_norm_tr = -0.1079
-- Starting training on experience 589 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1213
	data_grads_norm = 3.0587
	new_data_grads_norm = 4.7814
	old_data_grads_norm = 3.1890
	sim_grads_norm_tr = 0.3929
-- Starting training on experience 590 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8294
	data_grads_norm = 2.2150
	new_data_grads_norm = 4.3534
	old_data_grads_norm = 2.5027
	sim_grads_norm_tr = 0.0672
-- Starting training on experience 591 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8846
	data_grads_norm = 1.7669
	new_data_grads_norm = 4.9767
	old_data_grads_norm = 3.2906
	sim_grads_norm_tr = -0.1928
-- Starting training on experience 592 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8485
	data_grads_norm = 2.4128
	new_data_grads_norm = 5.2959
	old_data_grads_norm = 1.7543
	sim_grads_norm_tr = 0.1724
-- Starting training on experience 593 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2106
	data_grads_norm = 4.1654
	new_data_grads_norm = 6.1712
	old_data_grads_norm = 4.4910
	sim_grads_norm_tr = 0.3365
-- Starting training on experience 594 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9728
	data_grads_norm = 3.3632
	new_data_grads_norm = 4.1223
	old_data_grads_norm = 5.8986
	sim_grads_norm_tr = -0.1392
-- Starting training on experience 595 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1179
	data_grads_norm = 3.1373
	new_data_grads_norm = 5.7094
	old_data_grads_norm = 3.5522
	sim_grads_norm_tr = 0.1663
-- Starting training on experience 596 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9343
	data_grads_norm = 2.2390
	new_data_grads_norm = 5.0151
	old_data_grads_norm = 3.2680
	sim_grads_norm_tr = -0.1597
-- Starting training on experience 597 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4900
	data_grads_norm = 3.3750
	new_data_grads_norm = 5.2902
	old_data_grads_norm = 4.0245
	sim_grads_norm_tr = 0.1702
-- Starting training on experience 598 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7797
	data_grads_norm = 2.2330
	new_data_grads_norm = 3.5770
	old_data_grads_norm = 3.6613
	sim_grads_norm_tr = -0.0834
-- Starting training on experience 599 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2920
	data_grads_norm = 4.6620
	new_data_grads_norm = 5.9305
	old_data_grads_norm = 5.5441
	sim_grads_norm_tr = 0.2996
-- Starting training on experience 600 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.6903
	data_grads_norm = 2.7681
	new_data_grads_norm = 5.5762
	old_data_grads_norm = 3.1716
	sim_grads_norm_tr = -0.0422
-- Starting training on experience 601 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8736
	data_grads_norm = 2.2335
	new_data_grads_norm = 4.8615
	old_data_grads_norm = 1.7502
	sim_grads_norm_tr = -0.1226
-- Starting training on experience 602 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.6635
	data_grads_norm = 1.8706
	new_data_grads_norm = 3.6283
	old_data_grads_norm = 1.9099
	sim_grads_norm_tr = -0.0900
-- Starting training on experience 603 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3242
	data_grads_norm = 3.3725
	new_data_grads_norm = 5.0948
	old_data_grads_norm = 4.5271
	sim_grads_norm_tr = -0.1413
-- Starting training on experience 604 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7304
	data_grads_norm = 4.7022
	new_data_grads_norm = 5.3661
	old_data_grads_norm = 5.1785
	sim_grads_norm_tr = 0.3235
-- Starting training on experience 605 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.6751
	data_grads_norm = 1.5716
	new_data_grads_norm = 4.5297
	old_data_grads_norm = 2.3800
	sim_grads_norm_tr = -0.3386
-- Starting training on experience 606 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5259
	data_grads_norm = 3.4712
	new_data_grads_norm = 6.9300
	old_data_grads_norm = 3.1674
	sim_grads_norm_tr = 0.3697
-- Starting training on experience 607 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8592
	data_grads_norm = 2.3857
	new_data_grads_norm = 4.0079
	old_data_grads_norm = 2.1970
	sim_grads_norm_tr = 0.3441
-- Starting training on experience 608 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9310
	data_grads_norm = 2.2620
	new_data_grads_norm = 5.6251
	old_data_grads_norm = 2.0898
	sim_grads_norm_tr = -0.0271
-- Starting training on experience 609 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3202
	data_grads_norm = 2.9772
	new_data_grads_norm = 5.1713
	old_data_grads_norm = 2.8032
	sim_grads_norm_tr = 0.2155
-- Starting training on experience 610 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2495
	data_grads_norm = 3.1537
	new_data_grads_norm = 6.3469
	old_data_grads_norm = 1.6774
	sim_grads_norm_tr = -0.1664
-- Starting training on experience 611 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8632
	data_grads_norm = 2.6939
	new_data_grads_norm = 3.7775
	old_data_grads_norm = 3.4423
	sim_grads_norm_tr = 0.1170
-- Starting training on experience 612 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7686
	data_grads_norm = 2.5641
	new_data_grads_norm = 4.1729
	old_data_grads_norm = 3.3578
	sim_grads_norm_tr = 0.2616
-- Starting training on experience 613 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7108
	data_grads_norm = 1.9498
	new_data_grads_norm = 3.4107
	old_data_grads_norm = 2.4353
	sim_grads_norm_tr = 0.0053
-- Starting training on experience 614 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1167
	data_grads_norm = 3.4501
	new_data_grads_norm = 5.3338
	old_data_grads_norm = 5.0054
	sim_grads_norm_tr = -0.1293
-- Starting training on experience 615 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7974
	data_grads_norm = 2.1052
	new_data_grads_norm = 6.0693
	old_data_grads_norm = 1.4829
	sim_grads_norm_tr = 0.0227
-- Starting training on experience 616 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1687
	data_grads_norm = 2.9866
	new_data_grads_norm = 6.1354
	old_data_grads_norm = 4.0804
	sim_grads_norm_tr = -0.0595
-- Starting training on experience 617 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0050
	data_grads_norm = 1.7265
	new_data_grads_norm = 4.6437
	old_data_grads_norm = 3.6738
	sim_grads_norm_tr = -0.3265
-- Starting training on experience 618 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1204
	data_grads_norm = 4.2362
	new_data_grads_norm = 4.0471
	old_data_grads_norm = 4.9975
	sim_grads_norm_tr = -0.0241
-- Starting training on experience 619 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0309
	data_grads_norm = 2.5046
	new_data_grads_norm = 2.9036
	old_data_grads_norm = 4.0643
	sim_grads_norm_tr = 0.1931
-- Starting training on experience 620 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9557
	data_grads_norm = 2.5718
	new_data_grads_norm = 4.9267
	old_data_grads_norm = 1.8488
	sim_grads_norm_tr = 0.0640
-- Starting training on experience 621 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9014
	data_grads_norm = 2.2233
	new_data_grads_norm = 4.7595
	old_data_grads_norm = 2.3963
	sim_grads_norm_tr = -0.2283
-- Starting training on experience 622 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7914
	data_grads_norm = 1.7098
	new_data_grads_norm = 3.2784
	old_data_grads_norm = 2.2623
	sim_grads_norm_tr = -0.1644
-- Starting training on experience 623 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9378
	data_grads_norm = 2.2590
	new_data_grads_norm = 3.8890
	old_data_grads_norm = 3.4265
	sim_grads_norm_tr = 0.1432
-- Starting training on experience 624 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2061
	data_grads_norm = 2.6503
	new_data_grads_norm = 4.4380
	old_data_grads_norm = 3.4998
	sim_grads_norm_tr = 0.0605
-- Starting training on experience 625 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0744
	data_grads_norm = 2.7143
	new_data_grads_norm = 5.3686
	old_data_grads_norm = 2.5984
	sim_grads_norm_tr = -0.1525
-- Starting training on experience 626 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6089
	data_grads_norm = 4.4456
	new_data_grads_norm = 4.5981
	old_data_grads_norm = 7.0254
	sim_grads_norm_tr = 0.1489
-- Starting training on experience 627 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1913
	data_grads_norm = 2.9866
	new_data_grads_norm = 4.5460
	old_data_grads_norm = 4.2836
	sim_grads_norm_tr = 0.3130
-- Starting training on experience 628 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0756
	data_grads_norm = 2.3543
	new_data_grads_norm = 5.2045
	old_data_grads_norm = 3.3490
	sim_grads_norm_tr = -0.1325
-- Starting training on experience 629 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9087
	data_grads_norm = 2.2364
	new_data_grads_norm = 4.5162
	old_data_grads_norm = 2.5540
	sim_grads_norm_tr = -0.0685
-- Starting training on experience 630 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1981
	data_grads_norm = 3.2014
	new_data_grads_norm = 5.0200
	old_data_grads_norm = 2.5215
	sim_grads_norm_tr = 0.2642
-- Starting training on experience 631 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9905
	data_grads_norm = 2.1397
	new_data_grads_norm = 4.8884
	old_data_grads_norm = 1.9647
	sim_grads_norm_tr = -0.0396
-- Starting training on experience 632 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.5473
	data_grads_norm = 1.8453
	new_data_grads_norm = 5.8969
	old_data_grads_norm = 1.6830
	sim_grads_norm_tr = -0.3420
-- Starting training on experience 633 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2929
	data_grads_norm = 3.4647
	new_data_grads_norm = 4.3152
	old_data_grads_norm = 3.3500
	sim_grads_norm_tr = 0.2344
-- Starting training on experience 634 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0309
	data_grads_norm = 2.7708
	new_data_grads_norm = 5.3340
	old_data_grads_norm = 2.5122
	sim_grads_norm_tr = 0.4702
-- Starting training on experience 635 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8932
	data_grads_norm = 1.8877
	new_data_grads_norm = 3.6865
	old_data_grads_norm = 2.2724
	sim_grads_norm_tr = -0.0050
-- Starting training on experience 636 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8905
	data_grads_norm = 1.3181
	new_data_grads_norm = 3.6803
	old_data_grads_norm = 1.7813
	sim_grads_norm_tr = -0.3587
-- Starting training on experience 637 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1607
	data_grads_norm = 3.4580
	new_data_grads_norm = 5.6280
	old_data_grads_norm = 3.8812
	sim_grads_norm_tr = 0.2841
-- Starting training on experience 638 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0798
	data_grads_norm = 2.5002
	new_data_grads_norm = 5.1456
	old_data_grads_norm = 2.0258
	sim_grads_norm_tr = 0.2715
-- Starting training on experience 639 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8807
	data_grads_norm = 2.0523
	new_data_grads_norm = 6.1751
	old_data_grads_norm = 2.9146
	sim_grads_norm_tr = 0.0136
-- Starting training on experience 640 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5237
	data_grads_norm = 4.9140
	new_data_grads_norm = 6.5012
	old_data_grads_norm = 6.3686
	sim_grads_norm_tr = 0.2278
-- Starting training on experience 641 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3110
	data_grads_norm = 3.0308
	new_data_grads_norm = 5.2071
	old_data_grads_norm = 3.0147
	sim_grads_norm_tr = -0.0428
-- Starting training on experience 642 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8116
	data_grads_norm = 1.7576
	new_data_grads_norm = 5.2095
	old_data_grads_norm = 1.8100
	sim_grads_norm_tr = -0.0994
-- Starting training on experience 643 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.6834
	data_grads_norm = 1.5531
	new_data_grads_norm = 5.3573
	old_data_grads_norm = 3.2794
	sim_grads_norm_tr = -0.4119
-- Starting training on experience 644 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3977
	data_grads_norm = 4.0109
	new_data_grads_norm = 6.5112
	old_data_grads_norm = 3.3159
	sim_grads_norm_tr = 0.2242
-- Starting training on experience 645 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3007
	data_grads_norm = 3.3372
	new_data_grads_norm = 5.2754
	old_data_grads_norm = 3.8020
	sim_grads_norm_tr = 0.1507
-- Starting training on experience 646 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9027
	data_grads_norm = 3.4493
	new_data_grads_norm = 5.1905
	old_data_grads_norm = 3.9131
	sim_grads_norm_tr = 0.0789
-- Starting training on experience 647 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2877
	data_grads_norm = 3.2711
	new_data_grads_norm = 4.8288
	old_data_grads_norm = 3.5763
	sim_grads_norm_tr = 0.0580
-- Starting training on experience 648 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1099
	data_grads_norm = 2.4997
	new_data_grads_norm = 4.4425
	old_data_grads_norm = 2.8857
	sim_grads_norm_tr = -0.0456
-- Starting training on experience 649 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7565
	data_grads_norm = 2.1179
	new_data_grads_norm = 4.2284
	old_data_grads_norm = 1.9081
	sim_grads_norm_tr = 0.0931
-- Starting training on experience 650 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9529
	data_grads_norm = 2.3183
	new_data_grads_norm = 4.9504
	old_data_grads_norm = 2.4609
	sim_grads_norm_tr = -0.0320
-- Starting training on experience 651 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0045
	data_grads_norm = 2.4922
	new_data_grads_norm = 3.4336
	old_data_grads_norm = 2.2269
	sim_grads_norm_tr = -0.2686
-- Starting training on experience 652 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8633
	data_grads_norm = 1.7579
	new_data_grads_norm = 6.4461
	old_data_grads_norm = 2.4394
	sim_grads_norm_tr = -0.2159
-- Starting training on experience 653 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9728
	data_grads_norm = 3.1116
	new_data_grads_norm = 4.7802
	old_data_grads_norm = 4.3859
	sim_grads_norm_tr = -0.0733
-- Starting training on experience 654 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8442
	data_grads_norm = 2.7169
	new_data_grads_norm = 5.7799
	old_data_grads_norm = 2.5723
	sim_grads_norm_tr = 0.0178
-- Starting training on experience 655 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7476
	data_grads_norm = 5.6157
	new_data_grads_norm = 5.4820
	old_data_grads_norm = 6.1303
	sim_grads_norm_tr = 0.5564
-- Starting training on experience 656 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7372
	data_grads_norm = 2.1238
	new_data_grads_norm = 3.6417
	old_data_grads_norm = 3.0823
	sim_grads_norm_tr = -0.0562
-- Starting training on experience 657 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0578
	data_grads_norm = 2.8597
	new_data_grads_norm = 4.6466
	old_data_grads_norm = 3.0321
	sim_grads_norm_tr = 0.1009
-- Starting training on experience 658 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0513
	data_grads_norm = 2.3350
	new_data_grads_norm = 4.0422
	old_data_grads_norm = 2.5394
	sim_grads_norm_tr = 0.0572
-- Starting training on experience 659 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9324
	data_grads_norm = 2.4183
	new_data_grads_norm = 4.1959
	old_data_grads_norm = 3.5308
	sim_grads_norm_tr = -0.1235
-- Starting training on experience 660 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9850
	data_grads_norm = 2.7735
	new_data_grads_norm = 5.0500
	old_data_grads_norm = 2.6916
	sim_grads_norm_tr = -0.1892
-- Starting training on experience 661 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9134
	data_grads_norm = 2.3933
	new_data_grads_norm = 4.7361
	old_data_grads_norm = 3.0873
	sim_grads_norm_tr = 0.0036
-- Starting training on experience 662 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5929
	data_grads_norm = 3.9110
	new_data_grads_norm = 5.8253
	old_data_grads_norm = 3.0570
	sim_grads_norm_tr = 0.0211
-- Starting training on experience 663 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9388
	data_grads_norm = 2.7847
	new_data_grads_norm = 5.6528
	old_data_grads_norm = 2.8432
	sim_grads_norm_tr = 0.0320
-- Starting training on experience 664 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3426
	data_grads_norm = 3.7350
	new_data_grads_norm = 4.9151
	old_data_grads_norm = 4.8030
	sim_grads_norm_tr = 0.0396
-- Starting training on experience 665 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4312
	data_grads_norm = 4.2075
	new_data_grads_norm = 5.7747
	old_data_grads_norm = 4.3251
	sim_grads_norm_tr = 0.4969
-- Starting training on experience 666 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9441
	data_grads_norm = 2.5650
	new_data_grads_norm = 3.3333
	old_data_grads_norm = 3.9861
	sim_grads_norm_tr = 0.0132
-- Starting training on experience 667 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2687
	data_grads_norm = 3.7089
	new_data_grads_norm = 4.0434
	old_data_grads_norm = 5.9462
	sim_grads_norm_tr = 0.2016
-- Starting training on experience 668 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0454
	data_grads_norm = 2.9925
	new_data_grads_norm = 5.0597
	old_data_grads_norm = 2.6051
	sim_grads_norm_tr = 0.1124
-- Starting training on experience 669 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.6977
	data_grads_norm = 1.4727
	new_data_grads_norm = 4.6532
	old_data_grads_norm = 1.3470
	sim_grads_norm_tr = 0.0392
-- Starting training on experience 670 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8196
	data_grads_norm = 2.1581
	new_data_grads_norm = 6.3432
	old_data_grads_norm = 2.4745
	sim_grads_norm_tr = -0.3127
-- Starting training on experience 671 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2797
	data_grads_norm = 3.6344
	new_data_grads_norm = 5.3710
	old_data_grads_norm = 3.6096
	sim_grads_norm_tr = 0.2474
-- Starting training on experience 672 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1295
	data_grads_norm = 3.0009
	new_data_grads_norm = 4.3530
	old_data_grads_norm = 4.3032
	sim_grads_norm_tr = -0.0124
-- Starting training on experience 673 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8214
	data_grads_norm = 1.9268
	new_data_grads_norm = 3.9366
	old_data_grads_norm = 4.1163
	sim_grads_norm_tr = -0.1145
-- Starting training on experience 674 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8906
	data_grads_norm = 2.5297
	new_data_grads_norm = 4.6773
	old_data_grads_norm = 3.1509
	sim_grads_norm_tr = -0.0558
-- Starting training on experience 675 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2115
	data_grads_norm = 5.0047
	new_data_grads_norm = 5.9638
	old_data_grads_norm = 6.7533
	sim_grads_norm_tr = 0.3107
-- Starting training on experience 676 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1210
	data_grads_norm = 3.0598
	new_data_grads_norm = 4.2734
	old_data_grads_norm = 4.2506
	sim_grads_norm_tr = 0.1987
-- Starting training on experience 677 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8517
	data_grads_norm = 2.3702
	new_data_grads_norm = 3.9261
	old_data_grads_norm = 3.5586
	sim_grads_norm_tr = 0.0001
-- Starting training on experience 678 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2543
	data_grads_norm = 2.7285
	new_data_grads_norm = 4.1636
	old_data_grads_norm = 3.2756
	sim_grads_norm_tr = -0.0912
-- Starting training on experience 679 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0698
	data_grads_norm = 2.2289
	new_data_grads_norm = 3.6623
	old_data_grads_norm = 2.9549
	sim_grads_norm_tr = -0.1545
-- Starting training on experience 680 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0672
	data_grads_norm = 3.2795
	new_data_grads_norm = 6.3086
	old_data_grads_norm = 4.9725
	sim_grads_norm_tr = -0.1724
-- Starting training on experience 681 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9816
	data_grads_norm = 2.6254
	new_data_grads_norm = 5.7137
	old_data_grads_norm = 2.1428
	sim_grads_norm_tr = 0.2723
-- Starting training on experience 682 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7697
	data_grads_norm = 2.4009
	new_data_grads_norm = 4.5371
	old_data_grads_norm = 2.5437
	sim_grads_norm_tr = 0.1211
-- Starting training on experience 683 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7595
	data_grads_norm = 2.4301
	new_data_grads_norm = 4.6578
	old_data_grads_norm = 2.5470
	sim_grads_norm_tr = 0.0589
-- Starting training on experience 684 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7669
	data_grads_norm = 2.1448
	new_data_grads_norm = 5.1428
	old_data_grads_norm = 1.2050
	sim_grads_norm_tr = -0.0399
-- Starting training on experience 685 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7616
	data_grads_norm = 2.1398
	new_data_grads_norm = 5.2604
	old_data_grads_norm = 1.9562
	sim_grads_norm_tr = 0.1260
-- Starting training on experience 686 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0786
	data_grads_norm = 2.7544
	new_data_grads_norm = 4.1182
	old_data_grads_norm = 3.5166
	sim_grads_norm_tr = 0.0171
-- Starting training on experience 687 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7462
	data_grads_norm = 1.9429
	new_data_grads_norm = 5.1475
	old_data_grads_norm = 1.4532
	sim_grads_norm_tr = -0.0687
-- Starting training on experience 688 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3420
	data_grads_norm = 4.4483
	new_data_grads_norm = 4.2609
	old_data_grads_norm = 5.6476
	sim_grads_norm_tr = 0.5693
-- Starting training on experience 689 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2143
	data_grads_norm = 2.9378
	new_data_grads_norm = 4.0880
	old_data_grads_norm = 4.2261
	sim_grads_norm_tr = 0.1981
-- Starting training on experience 690 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7748
	data_grads_norm = 1.8760
	new_data_grads_norm = 4.2985
	old_data_grads_norm = 2.6196
	sim_grads_norm_tr = -0.0656
-- Starting training on experience 691 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2247
	data_grads_norm = 2.7907
	new_data_grads_norm = 4.3635
	old_data_grads_norm = 3.4372
	sim_grads_norm_tr = -0.0310
-- Starting training on experience 692 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3041
	data_grads_norm = 3.3455
	new_data_grads_norm = 4.1464
	old_data_grads_norm = 5.0399
	sim_grads_norm_tr = 0.0333
-- Starting training on experience 693 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3634
	data_grads_norm = 4.2534
	new_data_grads_norm = 4.7711
	old_data_grads_norm = 4.9166
	sim_grads_norm_tr = 0.1558
-- Starting training on experience 694 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1595
	data_grads_norm = 3.1947
	new_data_grads_norm = 6.3269
	old_data_grads_norm = 3.6380
	sim_grads_norm_tr = -0.1319
-- Starting training on experience 695 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9545
	data_grads_norm = 3.4571
	new_data_grads_norm = 5.3966
	old_data_grads_norm = 4.5927
	sim_grads_norm_tr = 0.2724
-- Starting training on experience 696 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3400
	data_grads_norm = 3.1956
	new_data_grads_norm = 6.3515
	old_data_grads_norm = 2.3733
	sim_grads_norm_tr = 0.4774
-- Starting training on experience 697 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1977
	data_grads_norm = 3.6496
	new_data_grads_norm = 4.7657
	old_data_grads_norm = 2.7581
	sim_grads_norm_tr = 0.5695
-- Starting training on experience 698 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.5483
	data_grads_norm = 1.6736
	new_data_grads_norm = 3.7597
	old_data_grads_norm = 1.5902
	sim_grads_norm_tr = -0.0860
-- Starting training on experience 699 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7455
	data_grads_norm = 1.6863
	new_data_grads_norm = 3.9844
	old_data_grads_norm = 2.3504
	sim_grads_norm_tr = -0.1592
-- Starting training on experience 700 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9192
	data_grads_norm = 2.2385
	new_data_grads_norm = 4.1381
	old_data_grads_norm = 2.1677
	sim_grads_norm_tr = 0.1462
-- Starting training on experience 701 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.6912
	data_grads_norm = 2.1051
	new_data_grads_norm = 4.5944
	old_data_grads_norm = 2.6051
	sim_grads_norm_tr = -0.1961
-- Starting training on experience 702 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0634
	data_grads_norm = 2.8529
	new_data_grads_norm = 4.5892
	old_data_grads_norm = 3.5073
	sim_grads_norm_tr = 0.1206
-- Starting training on experience 703 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8468
	data_grads_norm = 3.0227
	new_data_grads_norm = 5.8364
	old_data_grads_norm = 2.1576
	sim_grads_norm_tr = 0.2214
-- Starting training on experience 704 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9757
	data_grads_norm = 2.7104
	new_data_grads_norm = 6.9449
	old_data_grads_norm = 3.1114
	sim_grads_norm_tr = -0.1212
-- Starting training on experience 705 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2015
	data_grads_norm = 2.8645
	new_data_grads_norm = 6.1600
	old_data_grads_norm = 3.1726
	sim_grads_norm_tr = 0.1948
-- Starting training on experience 706 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0591
	data_grads_norm = 2.4995
	new_data_grads_norm = 5.3607
	old_data_grads_norm = 2.7727
	sim_grads_norm_tr = 0.1823
-- Starting training on experience 707 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0682
	data_grads_norm = 2.4946
	new_data_grads_norm = 6.5046
	old_data_grads_norm = 3.2167
	sim_grads_norm_tr = -0.0059
-- Starting training on experience 708 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1890
	data_grads_norm = 3.0982
	new_data_grads_norm = 5.8540
	old_data_grads_norm = 2.9198
	sim_grads_norm_tr = 0.2139
-- Starting training on experience 709 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8678
	data_grads_norm = 3.0416
	new_data_grads_norm = 5.1737
	old_data_grads_norm = 3.5820
	sim_grads_norm_tr = -0.2164
-- Starting training on experience 710 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8709
	data_grads_norm = 2.7239
	new_data_grads_norm = 4.5929
	old_data_grads_norm = 3.3155
	sim_grads_norm_tr = -0.1228
-- Starting training on experience 711 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0717
	data_grads_norm = 2.3197
	new_data_grads_norm = 5.7852
	old_data_grads_norm = 2.8366
	sim_grads_norm_tr = 0.1192
-- Starting training on experience 712 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7845
	data_grads_norm = 2.7838
	new_data_grads_norm = 6.5493
	old_data_grads_norm = 3.5229
	sim_grads_norm_tr = 0.1234
-- Starting training on experience 713 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9408
	data_grads_norm = 2.2325
	new_data_grads_norm = 5.8548
	old_data_grads_norm = 2.6168
	sim_grads_norm_tr = -0.0198
-- Starting training on experience 714 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2928
	data_grads_norm = 4.7215
	new_data_grads_norm = 5.0673
	old_data_grads_norm = 6.4297
	sim_grads_norm_tr = 0.3484
-- Starting training on experience 715 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2317
	data_grads_norm = 2.5393
	new_data_grads_norm = 4.7835
	old_data_grads_norm = 3.6665
	sim_grads_norm_tr = -0.0749
-- Starting training on experience 716 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9974
	data_grads_norm = 3.3493
	new_data_grads_norm = 4.4674
	old_data_grads_norm = 4.3750
	sim_grads_norm_tr = 0.0852
-- Starting training on experience 717 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1637
	data_grads_norm = 3.7430
	new_data_grads_norm = 4.0280
	old_data_grads_norm = 5.1777
	sim_grads_norm_tr = 0.1370
-- Starting training on experience 718 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1513
	data_grads_norm = 2.5152
	new_data_grads_norm = 6.2421
	old_data_grads_norm = 2.4296
	sim_grads_norm_tr = 0.0588
-- Starting training on experience 719 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1627
	data_grads_norm = 2.7397
	new_data_grads_norm = 4.9680
	old_data_grads_norm = 3.4687
	sim_grads_norm_tr = 0.0677
-- Starting training on experience 720 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8507
	data_grads_norm = 1.9949
	new_data_grads_norm = 5.4335
	old_data_grads_norm = 1.6107
	sim_grads_norm_tr = -0.0685
-- Starting training on experience 721 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7844
	data_grads_norm = 2.2467
	new_data_grads_norm = 3.7743
	old_data_grads_norm = 2.6467
	sim_grads_norm_tr = 0.0184
-- Starting training on experience 722 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0506
	data_grads_norm = 2.6940
	new_data_grads_norm = 4.2424
	old_data_grads_norm = 2.4947
	sim_grads_norm_tr = 0.3204
-- Starting training on experience 723 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0464
	data_grads_norm = 2.1976
	new_data_grads_norm = 4.4526
	old_data_grads_norm = 2.8927
	sim_grads_norm_tr = -0.1447
-- Starting training on experience 724 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1823
	data_grads_norm = 3.6628
	new_data_grads_norm = 3.7187
	old_data_grads_norm = 5.6465
	sim_grads_norm_tr = 0.1697
-- Starting training on experience 725 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9919
	data_grads_norm = 2.5591
	new_data_grads_norm = 3.9900
	old_data_grads_norm = 3.8061
	sim_grads_norm_tr = -0.1912
-- Starting training on experience 726 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.6440
	data_grads_norm = 2.0359
	new_data_grads_norm = 3.8801
	old_data_grads_norm = 1.7802
	sim_grads_norm_tr = 0.2193
-- Starting training on experience 727 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7824
	data_grads_norm = 1.6815
	new_data_grads_norm = 5.0363
	old_data_grads_norm = 1.4688
	sim_grads_norm_tr = -0.0705
-- Starting training on experience 728 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9354
	data_grads_norm = 2.3337
	new_data_grads_norm = 3.5791
	old_data_grads_norm = 3.2501
	sim_grads_norm_tr = 0.0598
-- Starting training on experience 729 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0814
	data_grads_norm = 2.3661
	new_data_grads_norm = 3.6329
	old_data_grads_norm = 2.9562
	sim_grads_norm_tr = 0.1201
-- Starting training on experience 730 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.6615
	data_grads_norm = 1.7318
	new_data_grads_norm = 3.4616
	old_data_grads_norm = 2.1128
	sim_grads_norm_tr = -0.0118
-- Starting training on experience 731 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8771
	data_grads_norm = 2.1914
	new_data_grads_norm = 3.5169
	old_data_grads_norm = 2.5360
	sim_grads_norm_tr = -0.0111
-- Starting training on experience 732 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7836
	data_grads_norm = 1.9494
	new_data_grads_norm = 3.2753
	old_data_grads_norm = 3.0358
	sim_grads_norm_tr = -0.1462
-- Starting training on experience 733 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1716
	data_grads_norm = 2.9026
	new_data_grads_norm = 5.4330
	old_data_grads_norm = 3.8993
	sim_grads_norm_tr = -0.2645
-- Starting training on experience 734 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9234
	data_grads_norm = 2.6099
	new_data_grads_norm = 4.2474
	old_data_grads_norm = 2.8488
	sim_grads_norm_tr = 0.0859
-- Starting training on experience 735 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9187
	data_grads_norm = 2.6413
	new_data_grads_norm = 4.4930
	old_data_grads_norm = 3.0948
	sim_grads_norm_tr = 0.0893
-- Starting training on experience 736 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0728
	data_grads_norm = 3.0864
	new_data_grads_norm = 5.7132
	old_data_grads_norm = 3.9547
	sim_grads_norm_tr = 0.0173
-- Starting training on experience 737 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0631
	data_grads_norm = 3.0368
	new_data_grads_norm = 4.5703
	old_data_grads_norm = 3.6575
	sim_grads_norm_tr = 0.4354
-- Starting training on experience 738 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8180
	data_grads_norm = 1.9305
	new_data_grads_norm = 3.9094
	old_data_grads_norm = 2.2192
	sim_grads_norm_tr = 0.1005
-- Starting training on experience 739 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8007
	data_grads_norm = 1.8030
	new_data_grads_norm = 3.3448
	old_data_grads_norm = 2.3613
	sim_grads_norm_tr = -0.0731
-- Starting training on experience 740 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7937
	data_grads_norm = 1.8573
	new_data_grads_norm = 3.9593
	old_data_grads_norm = 3.0304
	sim_grads_norm_tr = -0.3533
-- Starting training on experience 741 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.6776
	data_grads_norm = 1.6862
	new_data_grads_norm = 3.4428
	old_data_grads_norm = 2.4352
	sim_grads_norm_tr = -0.2497
-- Starting training on experience 742 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9646
	data_grads_norm = 2.3157
	new_data_grads_norm = 4.5497
	old_data_grads_norm = 2.1405
	sim_grads_norm_tr = -0.2210
-- Starting training on experience 743 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0925
	data_grads_norm = 2.6511
	new_data_grads_norm = 5.3519
	old_data_grads_norm = 1.6747
	sim_grads_norm_tr = 0.1904
-- Starting training on experience 744 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9462
	data_grads_norm = 1.9984
	new_data_grads_norm = 6.9742
	old_data_grads_norm = 2.5263
	sim_grads_norm_tr = -0.0552
-- Starting training on experience 745 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2947
	data_grads_norm = 3.2442
	new_data_grads_norm = 5.0905
	old_data_grads_norm = 4.8890
	sim_grads_norm_tr = -0.0385
-- Starting training on experience 746 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6542
	data_grads_norm = 3.7131
	new_data_grads_norm = 5.7868
	old_data_grads_norm = 3.0389
	sim_grads_norm_tr = 0.4546
-- Starting training on experience 747 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2161
	data_grads_norm = 3.0373
	new_data_grads_norm = 5.6757
	old_data_grads_norm = 2.1596
	sim_grads_norm_tr = 0.4144
-- Starting training on experience 748 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0938
	data_grads_norm = 2.7689
	new_data_grads_norm = 6.0262
	old_data_grads_norm = 3.8986
	sim_grads_norm_tr = -0.1097
-- Starting training on experience 749 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0574
	data_grads_norm = 2.5968
	new_data_grads_norm = 4.6361
	old_data_grads_norm = 3.4364
	sim_grads_norm_tr = 0.0232
-- Starting training on experience 750 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3502
	data_grads_norm = 3.5050
	new_data_grads_norm = 4.8450
	old_data_grads_norm = 3.6365
	sim_grads_norm_tr = 0.1675
-- Starting training on experience 751 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9062
	data_grads_norm = 2.3131
	new_data_grads_norm = 3.1710
	old_data_grads_norm = 2.6390
	sim_grads_norm_tr = 0.2749
-- Starting training on experience 752 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7217
	data_grads_norm = 2.2320
	new_data_grads_norm = 2.9545
	old_data_grads_norm = 4.3428
	sim_grads_norm_tr = -0.0522
-- Starting training on experience 753 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0196
	data_grads_norm = 3.0108
	new_data_grads_norm = 5.1634
	old_data_grads_norm = 3.0132
	sim_grads_norm_tr = 0.1156
-- Starting training on experience 754 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0047
	data_grads_norm = 2.5901
	new_data_grads_norm = 6.4625
	old_data_grads_norm = 3.0308
	sim_grads_norm_tr = 0.1859
-- Starting training on experience 755 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0873
	data_grads_norm = 2.4987
	new_data_grads_norm = 3.2256
	old_data_grads_norm = 3.1973
	sim_grads_norm_tr = 0.2536
-- Starting training on experience 756 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9789
	data_grads_norm = 2.1360
	new_data_grads_norm = 3.7155
	old_data_grads_norm = 2.5691
	sim_grads_norm_tr = 0.1570
-- Starting training on experience 757 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.6472
	data_grads_norm = 1.5718
	new_data_grads_norm = 2.2264
	old_data_grads_norm = 3.1346
	sim_grads_norm_tr = -0.4923
-- Starting training on experience 758 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1315
	data_grads_norm = 3.4744
	new_data_grads_norm = 5.6368
	old_data_grads_norm = 3.2607
	sim_grads_norm_tr = -0.0356
-- Starting training on experience 759 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1745
	data_grads_norm = 3.0887
	new_data_grads_norm = 5.6002
	old_data_grads_norm = 4.1657
	sim_grads_norm_tr = 0.0952
-- Starting training on experience 760 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9037
	data_grads_norm = 2.6181
	new_data_grads_norm = 4.0424
	old_data_grads_norm = 2.8828
	sim_grads_norm_tr = 0.0055
-- Starting training on experience 761 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1267
	data_grads_norm = 3.0742
	new_data_grads_norm = 7.2279
	old_data_grads_norm = 4.0123
	sim_grads_norm_tr = -0.0926
-- Starting training on experience 762 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9847
	data_grads_norm = 2.0916
	new_data_grads_norm = 3.8758
	old_data_grads_norm = 2.2424
	sim_grads_norm_tr = 0.1225
-- Starting training on experience 763 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0514
	data_grads_norm = 2.2398
	new_data_grads_norm = 4.9775
	old_data_grads_norm = 2.0751
	sim_grads_norm_tr = 0.2552
-- Starting training on experience 764 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0543
	data_grads_norm = 2.8370
	new_data_grads_norm = 5.2350
	old_data_grads_norm = 3.4749
	sim_grads_norm_tr = 0.3537
-- Starting training on experience 765 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8515
	data_grads_norm = 2.3108
	new_data_grads_norm = 4.5210
	old_data_grads_norm = 2.9000
	sim_grads_norm_tr = -0.0236
-- Starting training on experience 766 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.5457
	data_grads_norm = 1.5783
	new_data_grads_norm = 3.9050
	old_data_grads_norm = 1.4762
	sim_grads_norm_tr = -0.0997
-- Starting training on experience 767 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9514
	data_grads_norm = 3.2351
	new_data_grads_norm = 6.0405
	old_data_grads_norm = 2.3201
	sim_grads_norm_tr = -0.0208
-- Starting training on experience 768 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.6201
	data_grads_norm = 2.1162
	new_data_grads_norm = 4.9099
	old_data_grads_norm = 4.1409
	sim_grads_norm_tr = -0.2748
-- Starting training on experience 769 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9768
	data_grads_norm = 3.3919
	new_data_grads_norm = 5.2858
	old_data_grads_norm = 3.2908
	sim_grads_norm_tr = 0.1569
-- Starting training on experience 770 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2747
	data_grads_norm = 3.6636
	new_data_grads_norm = 5.9935
	old_data_grads_norm = 3.4104
	sim_grads_norm_tr = 0.4265
-- Starting training on experience 771 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9512
	data_grads_norm = 2.1324
	new_data_grads_norm = 4.9519
	old_data_grads_norm = 2.7310
	sim_grads_norm_tr = 0.1441
-- Starting training on experience 772 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3943
	data_grads_norm = 5.0340
	new_data_grads_norm = 6.0203
	old_data_grads_norm = 6.4109
	sim_grads_norm_tr = 0.4081
-- Starting training on experience 773 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7262
	data_grads_norm = 2.2512
	new_data_grads_norm = 3.5120
	old_data_grads_norm = 2.8772
	sim_grads_norm_tr = 0.0436
-- Starting training on experience 774 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1622
	data_grads_norm = 2.9198
	new_data_grads_norm = 4.1027
	old_data_grads_norm = 3.8006
	sim_grads_norm_tr = 0.1038
-- Starting training on experience 775 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1393
	data_grads_norm = 2.1719
	new_data_grads_norm = 3.7429
	old_data_grads_norm = 2.8573
	sim_grads_norm_tr = -0.2884
-- Starting training on experience 776 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8235
	data_grads_norm = 2.1105
	new_data_grads_norm = 3.2230
	old_data_grads_norm = 3.4576
	sim_grads_norm_tr = -0.1633
-- Starting training on experience 777 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7829
	data_grads_norm = 1.8837
	new_data_grads_norm = 3.4249
	old_data_grads_norm = 2.0767
	sim_grads_norm_tr = -0.2686
-- Starting training on experience 778 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3431
	data_grads_norm = 3.7341
	new_data_grads_norm = 4.5842
	old_data_grads_norm = 4.4216
	sim_grads_norm_tr = 0.1546
-- Starting training on experience 779 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0104
	data_grads_norm = 2.5877
	new_data_grads_norm = 5.6227
	old_data_grads_norm = 2.8830
	sim_grads_norm_tr = -0.1580
-- Starting training on experience 780 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6320
	data_grads_norm = 3.4612
	new_data_grads_norm = 6.0195
	old_data_grads_norm = 2.9262
	sim_grads_norm_tr = 0.1866
-- Starting training on experience 781 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6538
	data_grads_norm = 4.5272
	new_data_grads_norm = 6.1653
	old_data_grads_norm = 6.7478
	sim_grads_norm_tr = 0.1316
-- Starting training on experience 782 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7113
	data_grads_norm = 4.0150
	new_data_grads_norm = 4.9196
	old_data_grads_norm = 4.1577
	sim_grads_norm_tr = 0.5939
-- Starting training on experience 783 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7426
	data_grads_norm = 2.0752
	new_data_grads_norm = 4.0377
	old_data_grads_norm = 5.0425
	sim_grads_norm_tr = -0.1741
-- Starting training on experience 784 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2018
	data_grads_norm = 3.2562
	new_data_grads_norm = 4.6847
	old_data_grads_norm = 3.3065
	sim_grads_norm_tr = 0.3059
-- Starting training on experience 785 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7612
	data_grads_norm = 1.9513
	new_data_grads_norm = 3.0097
	old_data_grads_norm = 3.1236
	sim_grads_norm_tr = -0.0782
-- Starting training on experience 786 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0344
	data_grads_norm = 2.4952
	new_data_grads_norm = 4.0845
	old_data_grads_norm = 2.2343
	sim_grads_norm_tr = 0.5345
-- Starting training on experience 787 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8627
	data_grads_norm = 1.9088
	new_data_grads_norm = 4.3145
	old_data_grads_norm = 2.1117
	sim_grads_norm_tr = -0.1929
-- Starting training on experience 788 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9909
	data_grads_norm = 2.7055
	new_data_grads_norm = 4.9908
	old_data_grads_norm = 2.8414
	sim_grads_norm_tr = 0.2626
-- Starting training on experience 789 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9292
	data_grads_norm = 2.6510
	new_data_grads_norm = 3.2042
	old_data_grads_norm = 3.8255
	sim_grads_norm_tr = -0.0182
-- Starting training on experience 790 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8073
	data_grads_norm = 1.9217
	new_data_grads_norm = 3.7755
	old_data_grads_norm = 2.2239
	sim_grads_norm_tr = 0.2722
-- Starting training on experience 791 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7663
	data_grads_norm = 3.1169
	new_data_grads_norm = 3.8058
	old_data_grads_norm = 5.0597
	sim_grads_norm_tr = 0.1574
-- Starting training on experience 792 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9725
	data_grads_norm = 2.3889
	new_data_grads_norm = 3.5441
	old_data_grads_norm = 3.1041
	sim_grads_norm_tr = 0.2672
-- Starting training on experience 793 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7016
	data_grads_norm = 1.8332
	new_data_grads_norm = 3.8742
	old_data_grads_norm = 1.7884
	sim_grads_norm_tr = -0.3181
-- Starting training on experience 794 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8124
	data_grads_norm = 1.8603
	new_data_grads_norm = 2.9398
	old_data_grads_norm = 3.5237
	sim_grads_norm_tr = -0.2785
-- Starting training on experience 795 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9519
	data_grads_norm = 2.0991
	new_data_grads_norm = 5.5695
	old_data_grads_norm = 3.0039
	sim_grads_norm_tr = -0.2561
-- Starting training on experience 796 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9460
	data_grads_norm = 2.1808
	new_data_grads_norm = 3.4804
	old_data_grads_norm = 2.8795
	sim_grads_norm_tr = 0.0759
-- Starting training on experience 797 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8301
	data_grads_norm = 2.4134
	new_data_grads_norm = 6.3894
	old_data_grads_norm = 2.4124
	sim_grads_norm_tr = 0.0467
-- Starting training on experience 798 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9064
	data_grads_norm = 2.5084
	new_data_grads_norm = 3.4776
	old_data_grads_norm = 3.3285
	sim_grads_norm_tr = 0.0388
-- Starting training on experience 799 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8703
	data_grads_norm = 2.2302
	new_data_grads_norm = 4.6212
	old_data_grads_norm = 2.4866
	sim_grads_norm_tr = 0.0245
-- Starting training on experience 800 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8785
	data_grads_norm = 3.1195
	new_data_grads_norm = 4.5441
	old_data_grads_norm = 4.7394
	sim_grads_norm_tr = -0.0968
-- Starting training on experience 801 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2046
	data_grads_norm = 3.3835
	new_data_grads_norm = 4.9739
	old_data_grads_norm = 3.9260
	sim_grads_norm_tr = 0.0042
-- Starting training on experience 802 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8575
	data_grads_norm = 2.5871
	new_data_grads_norm = 5.1179
	old_data_grads_norm = 2.4909
	sim_grads_norm_tr = 0.1696
-- Starting training on experience 803 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9142
	data_grads_norm = 2.2623
	new_data_grads_norm = 3.8238
	old_data_grads_norm = 3.6199
	sim_grads_norm_tr = -0.0308
-- Starting training on experience 804 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8263
	data_grads_norm = 1.8487
	new_data_grads_norm = 4.2456
	old_data_grads_norm = 1.7256
	sim_grads_norm_tr = 0.0807
-- Starting training on experience 805 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.6437
	data_grads_norm = 1.6824
	new_data_grads_norm = 3.7918
	old_data_grads_norm = 1.6446
	sim_grads_norm_tr = 0.0282
-- Starting training on experience 806 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9586
	data_grads_norm = 2.5571
	new_data_grads_norm = 7.2200
	old_data_grads_norm = 2.3949
	sim_grads_norm_tr = 0.1510
-- Starting training on experience 807 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8198
	data_grads_norm = 1.7533
	new_data_grads_norm = 4.5251
	old_data_grads_norm = 1.9641
	sim_grads_norm_tr = -0.0332
-- Starting training on experience 808 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0484
	data_grads_norm = 3.5767
	new_data_grads_norm = 4.7218
	old_data_grads_norm = 3.9052
	sim_grads_norm_tr = 0.3497
-- Starting training on experience 809 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0485
	data_grads_norm = 2.9992
	new_data_grads_norm = 7.2722
	old_data_grads_norm = 4.2031
	sim_grads_norm_tr = 0.0077
-- Starting training on experience 810 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0572
	data_grads_norm = 3.9340
	new_data_grads_norm = 4.4026
	old_data_grads_norm = 5.0152
	sim_grads_norm_tr = 0.3851
-- Starting training on experience 811 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0900
	data_grads_norm = 3.0539
	new_data_grads_norm = 6.2198
	old_data_grads_norm = 2.7509
	sim_grads_norm_tr = 0.3437
-- Starting training on experience 812 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9923
	data_grads_norm = 3.8960
	new_data_grads_norm = 6.6299
	old_data_grads_norm = 2.3627
	sim_grads_norm_tr = 0.0956
-- Starting training on experience 813 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0804
	data_grads_norm = 2.5637
	new_data_grads_norm = 4.0375
	old_data_grads_norm = 3.2985
	sim_grads_norm_tr = 0.0145
-- Starting training on experience 814 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7871
	data_grads_norm = 2.0468
	new_data_grads_norm = 3.9076
	old_data_grads_norm = 4.7696
	sim_grads_norm_tr = -0.0436
-- Starting training on experience 815 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1349
	data_grads_norm = 2.1543
	new_data_grads_norm = 5.9885
	old_data_grads_norm = 2.9159
	sim_grads_norm_tr = -0.0314
-- Starting training on experience 816 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0598
	data_grads_norm = 2.6985
	new_data_grads_norm = 5.7170
	old_data_grads_norm = 1.7329
	sim_grads_norm_tr = -0.1536
-- Starting training on experience 817 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8393
	data_grads_norm = 2.4208
	new_data_grads_norm = 4.8131
	old_data_grads_norm = 2.0283
	sim_grads_norm_tr = 0.0914
-- Starting training on experience 818 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0551
	data_grads_norm = 2.9758
	new_data_grads_norm = 5.0064
	old_data_grads_norm = 2.2933
	sim_grads_norm_tr = 0.4651
-- Starting training on experience 819 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4045
	data_grads_norm = 3.7093
	new_data_grads_norm = 5.2059
	old_data_grads_norm = 5.0922
	sim_grads_norm_tr = 0.0371
-- Starting training on experience 820 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9376
	data_grads_norm = 2.1047
	new_data_grads_norm = 6.9106
	old_data_grads_norm = 2.2477
	sim_grads_norm_tr = -0.0882
-- Starting training on experience 821 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.6743
	data_grads_norm = 1.5456
	new_data_grads_norm = 4.9679
	old_data_grads_norm = 1.8940
	sim_grads_norm_tr = -0.3047
-- Starting training on experience 822 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0463
	data_grads_norm = 3.4869
	new_data_grads_norm = 6.5442
	old_data_grads_norm = 2.4933
	sim_grads_norm_tr = 0.2687
-- Starting training on experience 823 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8041
	data_grads_norm = 2.1677
	new_data_grads_norm = 4.8386
	old_data_grads_norm = 2.4147
	sim_grads_norm_tr = 0.1298
-- Starting training on experience 824 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.6051
	data_grads_norm = 1.7040
	new_data_grads_norm = 3.3243
	old_data_grads_norm = 1.7837
	sim_grads_norm_tr = 0.1478
-- Starting training on experience 825 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7847
	data_grads_norm = 2.2320
	new_data_grads_norm = 3.5573
	old_data_grads_norm = 3.4271
	sim_grads_norm_tr = -0.0237
-- Starting training on experience 826 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4140
	data_grads_norm = 3.9910
	new_data_grads_norm = 5.7146
	old_data_grads_norm = 5.1086
	sim_grads_norm_tr = 0.0899
-- Starting training on experience 827 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9688
	data_grads_norm = 2.4984
	new_data_grads_norm = 3.8187
	old_data_grads_norm = 3.0202
	sim_grads_norm_tr = 0.1471
-- Starting training on experience 828 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1004
	data_grads_norm = 2.6082
	new_data_grads_norm = 6.0425
	old_data_grads_norm = 3.7707
	sim_grads_norm_tr = -0.1246
-- Starting training on experience 829 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9930
	data_grads_norm = 2.9992
	new_data_grads_norm = 6.9348
	old_data_grads_norm = 2.5497
	sim_grads_norm_tr = -0.0103
-- Starting training on experience 830 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0191
	data_grads_norm = 3.2974
	new_data_grads_norm = 5.5715
	old_data_grads_norm = 3.9744
	sim_grads_norm_tr = 0.0515
-- Starting training on experience 831 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9579
	data_grads_norm = 3.3735
	new_data_grads_norm = 5.6439
	old_data_grads_norm = 2.8258
	sim_grads_norm_tr = 0.2927
-- Starting training on experience 832 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2199
	data_grads_norm = 3.5609
	new_data_grads_norm = 6.3726
	old_data_grads_norm = 3.6477
	sim_grads_norm_tr = 0.0340
-- Starting training on experience 833 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8970
	data_grads_norm = 2.7991
	new_data_grads_norm = 4.0732
	old_data_grads_norm = 3.0417
	sim_grads_norm_tr = 0.1090
-- Starting training on experience 834 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7453
	data_grads_norm = 3.2105
	new_data_grads_norm = 3.8531
	old_data_grads_norm = 5.5192
	sim_grads_norm_tr = -0.0125
-- Starting training on experience 835 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0937
	data_grads_norm = 2.8923
	new_data_grads_norm = 5.8206
	old_data_grads_norm = 3.2549
	sim_grads_norm_tr = 0.1713
-- Starting training on experience 836 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9970
	data_grads_norm = 3.2560
	new_data_grads_norm = 3.9821
	old_data_grads_norm = 4.4857
	sim_grads_norm_tr = 0.0326
-- Starting training on experience 837 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0718
	data_grads_norm = 2.5121
	new_data_grads_norm = 4.0133
	old_data_grads_norm = 3.3651
	sim_grads_norm_tr = 0.0656
-- Starting training on experience 838 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3407
	data_grads_norm = 3.7428
	new_data_grads_norm = 7.2814
	old_data_grads_norm = 3.0492
	sim_grads_norm_tr = 0.3151
-- Starting training on experience 839 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7910
	data_grads_norm = 2.3457
	new_data_grads_norm = 4.3471
	old_data_grads_norm = 2.0598
	sim_grads_norm_tr = 0.2469
-- Starting training on experience 840 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.6406
	data_grads_norm = 1.8548
	new_data_grads_norm = 4.2606
	old_data_grads_norm = 1.8217
	sim_grads_norm_tr = 0.0189
-- Starting training on experience 841 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8298
	data_grads_norm = 2.0997
	new_data_grads_norm = 4.0837
	old_data_grads_norm = 2.1174
	sim_grads_norm_tr = -0.0266
-- Starting training on experience 842 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9416
	data_grads_norm = 2.5268
	new_data_grads_norm = 3.8918
	old_data_grads_norm = 4.6377
	sim_grads_norm_tr = -0.1507
-- Starting training on experience 843 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9346
	data_grads_norm = 2.4876
	new_data_grads_norm = 4.0034
	old_data_grads_norm = 3.0300
	sim_grads_norm_tr = 0.0666
-- Starting training on experience 844 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1636
	data_grads_norm = 3.2510
	new_data_grads_norm = 5.0596
	old_data_grads_norm = 3.6202
	sim_grads_norm_tr = 0.1112
-- Starting training on experience 845 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.6907
	data_grads_norm = 1.8293
	new_data_grads_norm = 3.2746
	old_data_grads_norm = 4.1041
	sim_grads_norm_tr = -0.4367
-- Starting training on experience 846 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0408
	data_grads_norm = 2.8177
	new_data_grads_norm = 5.1792
	old_data_grads_norm = 2.9114
	sim_grads_norm_tr = -0.0768
-- Starting training on experience 847 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9153
	data_grads_norm = 2.3181
	new_data_grads_norm = 5.9872
	old_data_grads_norm = 2.6380
	sim_grads_norm_tr = 0.0197
-- Starting training on experience 848 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9559
	data_grads_norm = 2.4616
	new_data_grads_norm = 4.7742
	old_data_grads_norm = 2.0667
	sim_grads_norm_tr = -0.0729
-- Starting training on experience 849 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2118
	data_grads_norm = 2.9254
	new_data_grads_norm = 4.3344
	old_data_grads_norm = 2.8083
	sim_grads_norm_tr = 0.0959
-- Starting training on experience 850 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5052
	data_grads_norm = 4.6470
	new_data_grads_norm = 6.3061
	old_data_grads_norm = 4.9053
	sim_grads_norm_tr = 0.1732
-- Starting training on experience 851 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0537
	data_grads_norm = 2.8582
	new_data_grads_norm = 4.9941
	old_data_grads_norm = 3.1833
	sim_grads_norm_tr = 0.0517
-- Starting training on experience 852 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9109
	data_grads_norm = 2.4233
	new_data_grads_norm = 4.2449
	old_data_grads_norm = 3.7589
	sim_grads_norm_tr = -0.0384
-- Starting training on experience 853 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1430
	data_grads_norm = 3.8285
	new_data_grads_norm = 5.1495
	old_data_grads_norm = 3.3108
	sim_grads_norm_tr = 0.2457
-- Starting training on experience 854 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9420
	data_grads_norm = 2.2366
	new_data_grads_norm = 5.4829
	old_data_grads_norm = 2.2886
	sim_grads_norm_tr = -0.0750
-- Starting training on experience 855 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8293
	data_grads_norm = 2.2404
	new_data_grads_norm = 4.7040
	old_data_grads_norm = 2.3688
	sim_grads_norm_tr = -0.1872
-- Starting training on experience 856 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9728
	data_grads_norm = 3.2447
	new_data_grads_norm = 5.4107
	old_data_grads_norm = 5.1749
	sim_grads_norm_tr = -0.1191
-- Starting training on experience 857 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0240
	data_grads_norm = 2.9582
	new_data_grads_norm = 5.8998
	old_data_grads_norm = 3.4270
	sim_grads_norm_tr = 0.0482
-- Starting training on experience 858 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2394
	data_grads_norm = 2.9019
	new_data_grads_norm = 5.0109
	old_data_grads_norm = 3.6860
	sim_grads_norm_tr = -0.1456
-- Starting training on experience 859 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1927
	data_grads_norm = 3.7483
	new_data_grads_norm = 5.8401
	old_data_grads_norm = 4.3764
	sim_grads_norm_tr = 0.1809
-- Starting training on experience 860 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0119
	data_grads_norm = 3.2464
	new_data_grads_norm = 4.4506
	old_data_grads_norm = 3.2964
	sim_grads_norm_tr = 0.1045
-- Starting training on experience 861 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9998
	data_grads_norm = 2.8586
	new_data_grads_norm = 4.9010
	old_data_grads_norm = 4.5641
	sim_grads_norm_tr = 0.0795
-- Starting training on experience 862 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.5947
	data_grads_norm = 2.1605
	new_data_grads_norm = 5.5329
	old_data_grads_norm = 3.0762
	sim_grads_norm_tr = -0.3058
-- Starting training on experience 863 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1727
	data_grads_norm = 4.9682
	new_data_grads_norm = 5.8877
	old_data_grads_norm = 5.4271
	sim_grads_norm_tr = 0.2127
-- Starting training on experience 864 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7673
	data_grads_norm = 1.8936
	new_data_grads_norm = 6.5065
	old_data_grads_norm = 2.0631
	sim_grads_norm_tr = -0.1343
-- Starting training on experience 865 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1098
	data_grads_norm = 3.4243
	new_data_grads_norm = 5.4490
	old_data_grads_norm = 4.7268
	sim_grads_norm_tr = 0.1831
-- Starting training on experience 866 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7941
	data_grads_norm = 2.8485
	new_data_grads_norm = 6.1390
	old_data_grads_norm = 3.0574
	sim_grads_norm_tr = -0.1160
-- Starting training on experience 867 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0925
	data_grads_norm = 3.5481
	new_data_grads_norm = 6.0736
	old_data_grads_norm = 3.9411
	sim_grads_norm_tr = 0.0851
-- Starting training on experience 868 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8855
	data_grads_norm = 5.5833
	new_data_grads_norm = 6.1807
	old_data_grads_norm = 9.1020
	sim_grads_norm_tr = 0.0165
-- Starting training on experience 869 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4973
	data_grads_norm = 3.8694
	new_data_grads_norm = 6.0127
	old_data_grads_norm = 4.5617
	sim_grads_norm_tr = 0.1018
-- Starting training on experience 870 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0664
	data_grads_norm = 2.4869
	new_data_grads_norm = 4.2234
	old_data_grads_norm = 2.8928
	sim_grads_norm_tr = 0.0289
-- Starting training on experience 871 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1287
	data_grads_norm = 3.4671
	new_data_grads_norm = 5.4485
	old_data_grads_norm = 3.2529
	sim_grads_norm_tr = 0.3196
-- Starting training on experience 872 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.6907
	data_grads_norm = 2.4659
	new_data_grads_norm = 4.5171
	old_data_grads_norm = 4.6925
	sim_grads_norm_tr = -0.2865
-- Starting training on experience 873 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9998
	data_grads_norm = 2.6273
	new_data_grads_norm = 5.4481
	old_data_grads_norm = 2.6012
	sim_grads_norm_tr = -0.1191
-- Starting training on experience 874 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3882
	data_grads_norm = 3.9353
	new_data_grads_norm = 6.2220
	old_data_grads_norm = 4.1428
	sim_grads_norm_tr = 0.3053
-- Starting training on experience 875 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8384
	data_grads_norm = 1.9951
	new_data_grads_norm = 4.5885
	old_data_grads_norm = 2.5930
	sim_grads_norm_tr = -0.1299
-- Starting training on experience 876 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0511
	data_grads_norm = 3.0577
	new_data_grads_norm = 5.6697
	old_data_grads_norm = 2.3876
	sim_grads_norm_tr = 0.1687
-- Starting training on experience 877 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0844
	data_grads_norm = 2.9722
	new_data_grads_norm = 5.3163
	old_data_grads_norm = 2.8039
	sim_grads_norm_tr = 0.2907
-- Starting training on experience 878 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7529
	data_grads_norm = 2.4606
	new_data_grads_norm = 6.9083
	old_data_grads_norm = 3.7875
	sim_grads_norm_tr = -0.0702
-- Starting training on experience 879 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.6863
	data_grads_norm = 1.9552
	new_data_grads_norm = 4.3664
	old_data_grads_norm = 2.3001
	sim_grads_norm_tr = -0.1122
-- Starting training on experience 880 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2958
	data_grads_norm = 3.6070
	new_data_grads_norm = 4.2852
	old_data_grads_norm = 4.6388
	sim_grads_norm_tr = -0.0035
-- Starting training on experience 881 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2945
	data_grads_norm = 3.2377
	new_data_grads_norm = 4.5502
	old_data_grads_norm = 3.6451
	sim_grads_norm_tr = 0.3483
-- Starting training on experience 882 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3870
	data_grads_norm = 4.0883
	new_data_grads_norm = 5.7270
	old_data_grads_norm = 4.3741
	sim_grads_norm_tr = 0.2602
-- Starting training on experience 883 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0860
	data_grads_norm = 2.1805
	new_data_grads_norm = 4.4394
	old_data_grads_norm = 2.7445
	sim_grads_norm_tr = -0.0777
-- Starting training on experience 884 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1073
	data_grads_norm = 2.3505
	new_data_grads_norm = 5.0095
	old_data_grads_norm = 1.9507
	sim_grads_norm_tr = -0.1951
-- Starting training on experience 885 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9812
	data_grads_norm = 2.8038
	new_data_grads_norm = 4.6084
	old_data_grads_norm = 2.2420
	sim_grads_norm_tr = 0.2423
-- Starting training on experience 886 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8838
	data_grads_norm = 2.3556
	new_data_grads_norm = 4.5777
	old_data_grads_norm = 2.4265
	sim_grads_norm_tr = 0.2251
-- Starting training on experience 887 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8047
	data_grads_norm = 2.5395
	new_data_grads_norm = 4.5981
	old_data_grads_norm = 2.8868
	sim_grads_norm_tr = 0.0676
-- Starting training on experience 888 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7346
	data_grads_norm = 3.3088
	new_data_grads_norm = 5.3866
	old_data_grads_norm = 3.7731
	sim_grads_norm_tr = 0.2347
-- Starting training on experience 889 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7016
	data_grads_norm = 2.2318
	new_data_grads_norm = 3.4846
	old_data_grads_norm = 3.4990
	sim_grads_norm_tr = -0.1951
-- Starting training on experience 890 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.6348
	data_grads_norm = 1.9389
	new_data_grads_norm = 7.0691
	old_data_grads_norm = 5.1121
	sim_grads_norm_tr = -0.2820
-- Starting training on experience 891 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8987
	data_grads_norm = 2.8167
	new_data_grads_norm = 7.3710
	old_data_grads_norm = 1.7906
	sim_grads_norm_tr = 0.2030
-- Starting training on experience 892 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7953
	data_grads_norm = 1.9536
	new_data_grads_norm = 6.0007
	old_data_grads_norm = 1.5982
	sim_grads_norm_tr = -0.1394
-- Starting training on experience 893 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9010
	data_grads_norm = 3.1042
	new_data_grads_norm = 7.1661
	old_data_grads_norm = 2.7780
	sim_grads_norm_tr = 0.0917
-- Starting training on experience 894 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8657
	data_grads_norm = 2.8668
	new_data_grads_norm = 4.9604
	old_data_grads_norm = 3.6222
	sim_grads_norm_tr = 0.2264
-- Starting training on experience 895 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2201
	data_grads_norm = 3.0371
	new_data_grads_norm = 6.5181
	old_data_grads_norm = 3.6648
	sim_grads_norm_tr = 0.2178
-- Starting training on experience 896 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7293
	data_grads_norm = 2.1121
	new_data_grads_norm = 4.5137
	old_data_grads_norm = 2.8453
	sim_grads_norm_tr = 0.0020
-- Starting training on experience 897 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2445
	data_grads_norm = 3.3368
	new_data_grads_norm = 6.5021
	old_data_grads_norm = 3.4278
	sim_grads_norm_tr = -0.1077
-- Starting training on experience 898 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7424
	data_grads_norm = 1.7693
	new_data_grads_norm = 7.7590
	old_data_grads_norm = 2.9267
	sim_grads_norm_tr = -0.1904
-- Starting training on experience 899 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9501
	data_grads_norm = 2.7944
	new_data_grads_norm = 7.2777
	old_data_grads_norm = 2.6667
	sim_grads_norm_tr = 0.1595
-- Starting training on experience 900 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6191
	data_grads_norm = 4.5034
	new_data_grads_norm = 5.0215
	old_data_grads_norm = 5.7637
	sim_grads_norm_tr = 0.2813
-- Starting training on experience 901 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8943
	data_grads_norm = 2.0474
	new_data_grads_norm = 3.7303
	old_data_grads_norm = 1.9157
	sim_grads_norm_tr = 0.0398
-- Starting training on experience 902 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7527
	data_grads_norm = 2.4726
	new_data_grads_norm = 3.7876
	old_data_grads_norm = 4.3065
	sim_grads_norm_tr = -0.1023
-- Starting training on experience 903 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7397
	data_grads_norm = 2.2046
	new_data_grads_norm = 5.5340
	old_data_grads_norm = 2.3947
	sim_grads_norm_tr = 0.0814
-- Starting training on experience 904 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0250
	data_grads_norm = 2.7559
	new_data_grads_norm = 4.7705
	old_data_grads_norm = 3.0282
	sim_grads_norm_tr = 0.2939
-- Starting training on experience 905 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9620
	data_grads_norm = 4.0153
	new_data_grads_norm = 4.7585
	old_data_grads_norm = 5.1552
	sim_grads_norm_tr = 0.2083
-- Starting training on experience 906 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.6232
	data_grads_norm = 2.4828
	new_data_grads_norm = 5.0340
	old_data_grads_norm = 3.2377
	sim_grads_norm_tr = -0.1816
-- Starting training on experience 907 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8222
	data_grads_norm = 2.5431
	new_data_grads_norm = 4.3050
	old_data_grads_norm = 2.9650
	sim_grads_norm_tr = 0.0543
-- Starting training on experience 908 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8716
	data_grads_norm = 2.4668
	new_data_grads_norm = 3.9305
	old_data_grads_norm = 3.1815
	sim_grads_norm_tr = -0.1411
-- Starting training on experience 909 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8916
	data_grads_norm = 2.9820
	new_data_grads_norm = 4.9118
	old_data_grads_norm = 2.8565
	sim_grads_norm_tr = 0.3402
-- Starting training on experience 910 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8222
	data_grads_norm = 2.4788
	new_data_grads_norm = 4.4406
	old_data_grads_norm = 3.0652
	sim_grads_norm_tr = -0.0553
-- Starting training on experience 911 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.5446
	data_grads_norm = 1.9528
	new_data_grads_norm = 3.8953
	old_data_grads_norm = 3.2791
	sim_grads_norm_tr = -0.0857
-- Starting training on experience 912 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8524
	data_grads_norm = 2.4194
	new_data_grads_norm = 4.3779
	old_data_grads_norm = 3.0370
	sim_grads_norm_tr = -0.0680
-- Starting training on experience 913 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8410
	data_grads_norm = 2.2596
	new_data_grads_norm = 4.2388
	old_data_grads_norm = 2.7474
	sim_grads_norm_tr = -0.1338
-- Starting training on experience 914 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0227
	data_grads_norm = 3.6992
	new_data_grads_norm = 5.8263
	old_data_grads_norm = 2.3301
	sim_grads_norm_tr = 0.4875
-- Starting training on experience 915 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9597
	data_grads_norm = 3.6008
	new_data_grads_norm = 5.1248
	old_data_grads_norm = 3.6817
	sim_grads_norm_tr = 0.2683
-- Starting training on experience 916 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8085
	data_grads_norm = 2.6690
	new_data_grads_norm = 2.9906
	old_data_grads_norm = 4.6075
	sim_grads_norm_tr = 0.0897
-- Starting training on experience 917 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0512
	data_grads_norm = 3.6488
	new_data_grads_norm = 4.7897
	old_data_grads_norm = 4.1047
	sim_grads_norm_tr = 0.0970
-- Starting training on experience 918 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1923
	data_grads_norm = 3.1653
	new_data_grads_norm = 5.2751
	old_data_grads_norm = 3.3864
	sim_grads_norm_tr = 0.2012
-- Starting training on experience 919 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2834
	data_grads_norm = 3.6468
	new_data_grads_norm = 4.3055
	old_data_grads_norm = 5.4244
	sim_grads_norm_tr = 0.1653
-- Starting training on experience 920 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0292
	data_grads_norm = 3.2061
	new_data_grads_norm = 3.9348
	old_data_grads_norm = 3.5426
	sim_grads_norm_tr = -0.0128
-- Starting training on experience 921 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1439
	data_grads_norm = 2.8165
	new_data_grads_norm = 3.1653
	old_data_grads_norm = 4.6017
	sim_grads_norm_tr = 0.0913
-- Starting training on experience 922 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.5238
	data_grads_norm = 1.9047
	new_data_grads_norm = 2.3615
	old_data_grads_norm = 4.5455
	sim_grads_norm_tr = -0.1556
-- Starting training on experience 923 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.6409
	data_grads_norm = 1.9730
	new_data_grads_norm = 4.7676
	old_data_grads_norm = 2.4675
	sim_grads_norm_tr = -0.2082
-- Starting training on experience 924 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3219
	data_grads_norm = 3.8444
	new_data_grads_norm = 5.7530
	old_data_grads_norm = 3.9243
	sim_grads_norm_tr = 0.2718
-- Starting training on experience 925 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8384
	data_grads_norm = 2.3317
	new_data_grads_norm = 3.5066
	old_data_grads_norm = 2.8515
	sim_grads_norm_tr = 0.1523
-- Starting training on experience 926 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.5310
	data_grads_norm = 2.2033
	new_data_grads_norm = 3.6888
	old_data_grads_norm = 3.0867
	sim_grads_norm_tr = -0.1796
-- Starting training on experience 927 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1037
	data_grads_norm = 3.7299
	new_data_grads_norm = 5.0911
	old_data_grads_norm = 4.8700
	sim_grads_norm_tr = 0.1672
-- Starting training on experience 928 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8035
	data_grads_norm = 2.5935
	new_data_grads_norm = 3.4688
	old_data_grads_norm = 4.1858
	sim_grads_norm_tr = -0.0230
-- Starting training on experience 929 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9679
	data_grads_norm = 3.6023
	new_data_grads_norm = 6.2755
	old_data_grads_norm = 3.6947
	sim_grads_norm_tr = 0.2386
-- Starting training on experience 930 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2350
	data_grads_norm = 2.6955
	new_data_grads_norm = 4.5328
	old_data_grads_norm = 2.0309
	sim_grads_norm_tr = 0.0093
-- Starting training on experience 931 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1973
	data_grads_norm = 4.0346
	new_data_grads_norm = 6.3654
	old_data_grads_norm = 4.0034
	sim_grads_norm_tr = 0.2155
-- Starting training on experience 932 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0336
	data_grads_norm = 2.6455
	new_data_grads_norm = 6.2709
	old_data_grads_norm = 2.8912
	sim_grads_norm_tr = 0.1094
-- Starting training on experience 933 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8917
	data_grads_norm = 3.0967
	new_data_grads_norm = 4.9375
	old_data_grads_norm = 3.0890
	sim_grads_norm_tr = 0.3251
-- Starting training on experience 934 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7349
	data_grads_norm = 2.7738
	new_data_grads_norm = 3.7917
	old_data_grads_norm = 4.0971
	sim_grads_norm_tr = 0.0451
-- Starting training on experience 935 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8627
	data_grads_norm = 2.8066
	new_data_grads_norm = 4.4990
	old_data_grads_norm = 3.5122
	sim_grads_norm_tr = 0.1055
-- Starting training on experience 936 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9198
	data_grads_norm = 2.4061
	new_data_grads_norm = 4.5710
	old_data_grads_norm = 3.8178
	sim_grads_norm_tr = -0.2246
-- Starting training on experience 937 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9883
	data_grads_norm = 3.6184
	new_data_grads_norm = 5.2737
	old_data_grads_norm = 4.7460
	sim_grads_norm_tr = 0.1156
-- Starting training on experience 938 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0940
	data_grads_norm = 3.0507
	new_data_grads_norm = 4.7912
	old_data_grads_norm = 2.9881
	sim_grads_norm_tr = 0.0134
-- Starting training on experience 939 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0152
	data_grads_norm = 2.9143
	new_data_grads_norm = 6.2162
	old_data_grads_norm = 2.7334
	sim_grads_norm_tr = -0.1442
-- Starting training on experience 940 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8904
	data_grads_norm = 3.1807
	new_data_grads_norm = 5.7289
	old_data_grads_norm = 4.2790
	sim_grads_norm_tr = -0.1083
-- Starting training on experience 941 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7181
	data_grads_norm = 2.2395
	new_data_grads_norm = 6.1829
	old_data_grads_norm = 3.7985
	sim_grads_norm_tr = -0.2471
-- Starting training on experience 942 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2413
	data_grads_norm = 4.3272
	new_data_grads_norm = 6.9534
	old_data_grads_norm = 3.4094
	sim_grads_norm_tr = 0.3836
-- Starting training on experience 943 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8379
	data_grads_norm = 2.3999
	new_data_grads_norm = 4.1356
	old_data_grads_norm = 2.8642
	sim_grads_norm_tr = -0.0338
-- Starting training on experience 944 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8688
	data_grads_norm = 2.3387
	new_data_grads_norm = 4.7723
	old_data_grads_norm = 2.5265
	sim_grads_norm_tr = -0.0549
-- Starting training on experience 945 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9432
	data_grads_norm = 2.3455
	new_data_grads_norm = 4.9015
	old_data_grads_norm = 2.8635
	sim_grads_norm_tr = -0.1197
-- Starting training on experience 946 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1249
	data_grads_norm = 2.8945
	new_data_grads_norm = 5.6360
	old_data_grads_norm = 2.8640
	sim_grads_norm_tr = -0.0403
-- Starting training on experience 947 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2728
	data_grads_norm = 3.9539
	new_data_grads_norm = 7.6415
	old_data_grads_norm = 5.1442
	sim_grads_norm_tr = 0.1571
-- Starting training on experience 948 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1977
	data_grads_norm = 3.1884
	new_data_grads_norm = 5.6018
	old_data_grads_norm = 4.0907
	sim_grads_norm_tr = -0.0180
-- Starting training on experience 949 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7558
	data_grads_norm = 2.2961
	new_data_grads_norm = 4.5427
	old_data_grads_norm = 3.0000
	sim_grads_norm_tr = -0.0107
-- >> End of training phase << --
-- >> Start of eval phase << --
-- Starting eval on experience 0 (Task 0) from test stream --
> Eval on experience 0 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp000 = 0.4919
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.3230
	mb_index = 1900
	time = 404.6138
-- Starting eval on experience 1 (Task 0) from test stream --
> Eval on experience 1 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp001 = 1.1297
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.3745
-- >> End of eval phase << --
	CumulativeAccuracy/eval_phase/test_stream/Exp000 = 0.6045
	CumulativeAccuracy/eval_phase/test_stream/Exp001 = 0.3488
	Loss_Stream/eval_phase/test_stream/Task000 = 0.8108
	Top1_Acc_Stream/eval_phase/test_stream/Task000 = 0.3488
	ValidStream/mean_grads_norm_iter = 5.4942
-- >> Start of training phase << --
-- Starting training on experience 0 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6284
	data_grads_norm = 3.1957
	new_data_grads_norm = 6.9688
	old_data_grads_norm = 3.6526
	sim_grads_norm_tr = -0.3598
-- Starting training on experience 1 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8948
	data_grads_norm = 3.4714
	new_data_grads_norm = 6.3826
	old_data_grads_norm = 3.0755
	sim_grads_norm_tr = -0.1877
-- Starting training on experience 2 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1951
	data_grads_norm = 3.6046
	new_data_grads_norm = 6.8787
	old_data_grads_norm = 3.1620
	sim_grads_norm_tr = -0.0758
-- Starting training on experience 3 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1853
	data_grads_norm = 4.0034
	new_data_grads_norm = 7.1056
	old_data_grads_norm = 3.0943
	sim_grads_norm_tr = -0.1452
-- Starting training on experience 4 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0246
	data_grads_norm = 3.7130
	new_data_grads_norm = 7.4233
	old_data_grads_norm = 3.5027
	sim_grads_norm_tr = -0.0639
-- Starting training on experience 5 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4518
	data_grads_norm = 5.1876
	new_data_grads_norm = 8.0839
	old_data_grads_norm = 3.8068
	sim_grads_norm_tr = 0.1342
-- Starting training on experience 6 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8054
	data_grads_norm = 3.9098
	new_data_grads_norm = 7.4413
	old_data_grads_norm = 2.7390
	sim_grads_norm_tr = -0.2106
-- Starting training on experience 7 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9570
	data_grads_norm = 4.2213
	new_data_grads_norm = 7.8576
	old_data_grads_norm = 2.7899
	sim_grads_norm_tr = -0.0543
-- Starting training on experience 8 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0622
	data_grads_norm = 3.6871
	new_data_grads_norm = 7.6272
	old_data_grads_norm = 1.9150
	sim_grads_norm_tr = 0.0327
-- Starting training on experience 9 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0108
	data_grads_norm = 3.4222
	new_data_grads_norm = 6.5457
	old_data_grads_norm = 4.4569
	sim_grads_norm_tr = -0.0535
-- Starting training on experience 10 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9820
	data_grads_norm = 6.7049
	new_data_grads_norm = 8.4895
	old_data_grads_norm = 6.8213
	sim_grads_norm_tr = 0.2312
-- Starting training on experience 11 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8965
	data_grads_norm = 3.3368
	new_data_grads_norm = 7.3812
	old_data_grads_norm = 3.0542
	sim_grads_norm_tr = -0.0949
-- Starting training on experience 12 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2607
	data_grads_norm = 3.8272
	new_data_grads_norm = 6.4640
	old_data_grads_norm = 2.7897
	sim_grads_norm_tr = 0.1991
-- Starting training on experience 13 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0459
	data_grads_norm = 3.5361
	new_data_grads_norm = 6.8962
	old_data_grads_norm = 2.5623
	sim_grads_norm_tr = 0.0379
-- Starting training on experience 14 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8738
	data_grads_norm = 4.5690
	new_data_grads_norm = 7.0745
	old_data_grads_norm = 3.9027
	sim_grads_norm_tr = 0.0100
-- Starting training on experience 15 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2208
	data_grads_norm = 4.8241
	new_data_grads_norm = 7.1192
	old_data_grads_norm = 4.2002
	sim_grads_norm_tr = 0.0365
-- Starting training on experience 16 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0279
	data_grads_norm = 3.5909
	new_data_grads_norm = 6.0560
	old_data_grads_norm = 4.8931
	sim_grads_norm_tr = -0.0913
-- Starting training on experience 17 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3641
	data_grads_norm = 4.6643
	new_data_grads_norm = 8.3831
	old_data_grads_norm = 5.0592
	sim_grads_norm_tr = 0.2621
-- Starting training on experience 18 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7262
	data_grads_norm = 3.0502
	new_data_grads_norm = 6.4467
	old_data_grads_norm = 2.2460
	sim_grads_norm_tr = -0.3413
-- Starting training on experience 19 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9906
	data_grads_norm = 4.0176
	new_data_grads_norm = 7.4269
	old_data_grads_norm = 3.4680
	sim_grads_norm_tr = -0.0142
-- Starting training on experience 20 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2898
	data_grads_norm = 4.0404
	new_data_grads_norm = 6.8119
	old_data_grads_norm = 3.1902
	sim_grads_norm_tr = 0.0319
-- Starting training on experience 21 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0341
	data_grads_norm = 3.9572
	new_data_grads_norm = 7.0016
	old_data_grads_norm = 2.7149
	sim_grads_norm_tr = -0.0065
-- Starting training on experience 22 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8078
	data_grads_norm = 3.4208
	new_data_grads_norm = 7.1010
	old_data_grads_norm = 1.9168
	sim_grads_norm_tr = -0.0431
-- Starting training on experience 23 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1094
	data_grads_norm = 5.1900
	new_data_grads_norm = 6.6394
	old_data_grads_norm = 6.2308
	sim_grads_norm_tr = 0.3491
-- Starting training on experience 24 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1288
	data_grads_norm = 4.5138
	new_data_grads_norm = 6.0645
	old_data_grads_norm = 5.5911
	sim_grads_norm_tr = -0.0412
-- Starting training on experience 25 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7580
	data_grads_norm = 2.7713
	new_data_grads_norm = 6.0535
	old_data_grads_norm = 2.1261
	sim_grads_norm_tr = 0.0567
-- Starting training on experience 26 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8754
	data_grads_norm = 3.8359
	new_data_grads_norm = 6.3024
	old_data_grads_norm = 3.0470
	sim_grads_norm_tr = 0.0507
-- Starting training on experience 27 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7048
	data_grads_norm = 4.2009
	new_data_grads_norm = 7.3940
	old_data_grads_norm = 2.4879
	sim_grads_norm_tr = -0.1583
-- Starting training on experience 28 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2767
	data_grads_norm = 5.2199
	new_data_grads_norm = 6.0474
	old_data_grads_norm = 5.1338
	sim_grads_norm_tr = 0.6763
-- Starting training on experience 29 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6264
	data_grads_norm = 3.1686
	new_data_grads_norm = 4.3191
	old_data_grads_norm = 5.1591
	sim_grads_norm_tr = -0.0635
-- Starting training on experience 30 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0831
	data_grads_norm = 4.3553
	new_data_grads_norm = 6.0436
	old_data_grads_norm = 4.4062
	sim_grads_norm_tr = 0.2609
-- Starting training on experience 31 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5839
	data_grads_norm = 2.7936
	new_data_grads_norm = 5.4974
	old_data_grads_norm = 3.2059
	sim_grads_norm_tr = -0.2675
-- Starting training on experience 32 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4749
	data_grads_norm = 2.8199
	new_data_grads_norm = 6.1785
	old_data_grads_norm = 2.2955
	sim_grads_norm_tr = -0.1175
-- Starting training on experience 33 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5027
	data_grads_norm = 2.9599
	new_data_grads_norm = 6.4492
	old_data_grads_norm = 3.1493
	sim_grads_norm_tr = -0.1136
-- Starting training on experience 34 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8729
	data_grads_norm = 4.1090
	new_data_grads_norm = 7.5519
	old_data_grads_norm = 3.0890
	sim_grads_norm_tr = -0.1881
-- Starting training on experience 35 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0221
	data_grads_norm = 5.2934
	new_data_grads_norm = 7.6292
	old_data_grads_norm = 3.8414
	sim_grads_norm_tr = 0.5697
-- Starting training on experience 36 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8880
	data_grads_norm = 4.7637
	new_data_grads_norm = 6.1848
	old_data_grads_norm = 4.5970
	sim_grads_norm_tr = 0.4681
-- Starting training on experience 37 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6737
	data_grads_norm = 3.4642
	new_data_grads_norm = 4.4795
	old_data_grads_norm = 5.5280
	sim_grads_norm_tr = -0.3189
-- Starting training on experience 38 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7488
	data_grads_norm = 4.3855
	new_data_grads_norm = 6.6532
	old_data_grads_norm = 3.6111
	sim_grads_norm_tr = 0.2306
-- Starting training on experience 39 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3793
	data_grads_norm = 3.4404
	new_data_grads_norm = 6.0147
	old_data_grads_norm = 3.0479
	sim_grads_norm_tr = 0.3135
-- Starting training on experience 40 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4099
	data_grads_norm = 3.4453
	new_data_grads_norm = 5.6670
	old_data_grads_norm = 2.5833
	sim_grads_norm_tr = 0.2304
-- Starting training on experience 41 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5133
	data_grads_norm = 2.6797
	new_data_grads_norm = 4.8697
	old_data_grads_norm = 2.7838
	sim_grads_norm_tr = -0.1406
-- Starting training on experience 42 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4631
	data_grads_norm = 2.8611
	new_data_grads_norm = 5.8194
	old_data_grads_norm = 3.9025
	sim_grads_norm_tr = -0.1208
-- Starting training on experience 43 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1341
	data_grads_norm = 4.6620
	new_data_grads_norm = 6.3220
	old_data_grads_norm = 4.7293
	sim_grads_norm_tr = -0.0158
-- Starting training on experience 44 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9662
	data_grads_norm = 4.1599
	new_data_grads_norm = 5.9683
	old_data_grads_norm = 3.7188
	sim_grads_norm_tr = 0.3610
-- Starting training on experience 45 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7959
	data_grads_norm = 3.5362
	new_data_grads_norm = 5.4744
	old_data_grads_norm = 4.1406
	sim_grads_norm_tr = 0.0138
-- Starting training on experience 46 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6698
	data_grads_norm = 3.8668
	new_data_grads_norm = 6.0760
	old_data_grads_norm = 3.3726
	sim_grads_norm_tr = 0.4181
-- Starting training on experience 47 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4646
	data_grads_norm = 3.6936
	new_data_grads_norm = 4.8345
	old_data_grads_norm = 4.3142
	sim_grads_norm_tr = 0.2016
-- Starting training on experience 48 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0010
	data_grads_norm = 2.2611
	new_data_grads_norm = 3.9319
	old_data_grads_norm = 3.0057
	sim_grads_norm_tr = -0.1202
-- Starting training on experience 49 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3084
	data_grads_norm = 3.0506
	new_data_grads_norm = 4.8399
	old_data_grads_norm = 4.0036
	sim_grads_norm_tr = -0.2131
-- Starting training on experience 50 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6455
	data_grads_norm = 4.2298
	new_data_grads_norm = 5.6151
	old_data_grads_norm = 4.9461
	sim_grads_norm_tr = 0.3563
-- Starting training on experience 51 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2813
	data_grads_norm = 2.9253
	new_data_grads_norm = 4.6492
	old_data_grads_norm = 3.1602
	sim_grads_norm_tr = -0.2229
-- Starting training on experience 52 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3159
	data_grads_norm = 2.2965
	new_data_grads_norm = 4.1295
	old_data_grads_norm = 2.9198
	sim_grads_norm_tr = -0.0829
-- Starting training on experience 53 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7259
	data_grads_norm = 3.6844
	new_data_grads_norm = 4.9017
	old_data_grads_norm = 4.0032
	sim_grads_norm_tr = 0.3110
-- Starting training on experience 54 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2944
	data_grads_norm = 2.7254
	new_data_grads_norm = 4.6548
	old_data_grads_norm = 3.1463
	sim_grads_norm_tr = -0.0690
-- Starting training on experience 55 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5463
	data_grads_norm = 3.5052
	new_data_grads_norm = 3.9364
	old_data_grads_norm = 5.3088
	sim_grads_norm_tr = -0.1406
-- Starting training on experience 56 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4847
	data_grads_norm = 3.3615
	new_data_grads_norm = 5.4403
	old_data_grads_norm = 2.9646
	sim_grads_norm_tr = 0.5302
-- Starting training on experience 57 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4247
	data_grads_norm = 3.5175
	new_data_grads_norm = 5.2118
	old_data_grads_norm = 3.3664
	sim_grads_norm_tr = 0.3631
-- Starting training on experience 58 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3660
	data_grads_norm = 2.8417
	new_data_grads_norm = 4.2595
	old_data_grads_norm = 3.2516
	sim_grads_norm_tr = -0.1029
-- Starting training on experience 59 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0703
	data_grads_norm = 1.9687
	new_data_grads_norm = 4.5371
	old_data_grads_norm = 2.9469
	sim_grads_norm_tr = -0.5072
-- Starting training on experience 60 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6332
	data_grads_norm = 4.1737
	new_data_grads_norm = 6.4847
	old_data_grads_norm = 3.4374
	sim_grads_norm_tr = 0.2874
-- Starting training on experience 61 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4897
	data_grads_norm = 3.7809
	new_data_grads_norm = 6.0818
	old_data_grads_norm = 3.2951
	sim_grads_norm_tr = 0.0236
-- Starting training on experience 62 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2516
	data_grads_norm = 3.9256
	new_data_grads_norm = 5.4478
	old_data_grads_norm = 3.7872
	sim_grads_norm_tr = 0.4478
-- Starting training on experience 63 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5502
	data_grads_norm = 3.5033
	new_data_grads_norm = 4.2652
	old_data_grads_norm = 5.9695
	sim_grads_norm_tr = -0.1188
-- Starting training on experience 64 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5470
	data_grads_norm = 3.5340
	new_data_grads_norm = 5.9200
	old_data_grads_norm = 2.9348
	sim_grads_norm_tr = 0.0293
-- Starting training on experience 65 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4114
	data_grads_norm = 3.3803
	new_data_grads_norm = 5.6252
	old_data_grads_norm = 2.6975
	sim_grads_norm_tr = 0.4819
-- Starting training on experience 66 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1513
	data_grads_norm = 2.7537
	new_data_grads_norm = 4.9539
	old_data_grads_norm = 3.0240
	sim_grads_norm_tr = -0.0406
-- Starting training on experience 67 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9083
	data_grads_norm = 4.3363
	new_data_grads_norm = 5.4210
	old_data_grads_norm = 6.5351
	sim_grads_norm_tr = 0.0893
-- Starting training on experience 68 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2716
	data_grads_norm = 2.2946
	new_data_grads_norm = 4.5741
	old_data_grads_norm = 2.2752
	sim_grads_norm_tr = 0.0249
-- Starting training on experience 69 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3370
	data_grads_norm = 2.9903
	new_data_grads_norm = 4.6933
	old_data_grads_norm = 3.4705
	sim_grads_norm_tr = 0.0192
-- Starting training on experience 70 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1988
	data_grads_norm = 3.2175
	new_data_grads_norm = 6.0712
	old_data_grads_norm = 2.5801
	sim_grads_norm_tr = -0.1870
-- Starting training on experience 71 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8344
	data_grads_norm = 4.0773
	new_data_grads_norm = 4.9830
	old_data_grads_norm = 5.0866
	sim_grads_norm_tr = 0.3103
-- Starting training on experience 72 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2450
	data_grads_norm = 3.3459
	new_data_grads_norm = 4.9800
	old_data_grads_norm = 3.2624
	sim_grads_norm_tr = 0.2762
-- Starting training on experience 73 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0336
	data_grads_norm = 2.1063
	new_data_grads_norm = 3.6555
	old_data_grads_norm = 2.2125
	sim_grads_norm_tr = -0.0113
-- Starting training on experience 74 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2192
	data_grads_norm = 3.3377
	new_data_grads_norm = 4.9788
	old_data_grads_norm = 4.2258
	sim_grads_norm_tr = 0.0843
-- Starting training on experience 75 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5143
	data_grads_norm = 4.1333
	new_data_grads_norm = 6.8418
	old_data_grads_norm = 3.5926
	sim_grads_norm_tr = 0.1964
-- Starting training on experience 76 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3203
	data_grads_norm = 3.0618
	new_data_grads_norm = 5.6430
	old_data_grads_norm = 3.3620
	sim_grads_norm_tr = 0.0036
-- Starting training on experience 77 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4128
	data_grads_norm = 3.4658
	new_data_grads_norm = 5.0681
	old_data_grads_norm = 3.5321
	sim_grads_norm_tr = 0.3354
-- Starting training on experience 78 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3504
	data_grads_norm = 2.5362
	new_data_grads_norm = 5.0435
	old_data_grads_norm = 4.6079
	sim_grads_norm_tr = -0.2113
-- Starting training on experience 79 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2947
	data_grads_norm = 3.4599
	new_data_grads_norm = 5.3571
	old_data_grads_norm = 2.7987
	sim_grads_norm_tr = 0.1332
-- Starting training on experience 80 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4623
	data_grads_norm = 3.0114
	new_data_grads_norm = 5.0817
	old_data_grads_norm = 3.1571
	sim_grads_norm_tr = 0.1048
-- Starting training on experience 81 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3453
	data_grads_norm = 2.8423
	new_data_grads_norm = 5.2652
	old_data_grads_norm = 3.3772
	sim_grads_norm_tr = -0.2230
-- Starting training on experience 82 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5086
	data_grads_norm = 3.7711
	new_data_grads_norm = 5.7469
	old_data_grads_norm = 3.5040
	sim_grads_norm_tr = 0.0965
-- Starting training on experience 83 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2534
	data_grads_norm = 2.9987
	new_data_grads_norm = 5.5636
	old_data_grads_norm = 3.0211
	sim_grads_norm_tr = -0.3129
-- Starting training on experience 84 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0273
	data_grads_norm = 4.7911
	new_data_grads_norm = 6.0946
	old_data_grads_norm = 4.4654
	sim_grads_norm_tr = 0.6611
-- Starting training on experience 85 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3501
	data_grads_norm = 2.7065
	new_data_grads_norm = 4.3130
	old_data_grads_norm = 2.4536
	sim_grads_norm_tr = 0.3112
-- Starting training on experience 86 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2137
	data_grads_norm = 2.8856
	new_data_grads_norm = 3.7759
	old_data_grads_norm = 4.2319
	sim_grads_norm_tr = -0.0780
-- Starting training on experience 87 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2626
	data_grads_norm = 2.3775
	new_data_grads_norm = 4.8358
	old_data_grads_norm = 3.3355
	sim_grads_norm_tr = -0.4533
-- Starting training on experience 88 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6440
	data_grads_norm = 3.7830
	new_data_grads_norm = 6.0098
	old_data_grads_norm = 4.4335
	sim_grads_norm_tr = 0.1849
-- Starting training on experience 89 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4381
	data_grads_norm = 3.0583
	new_data_grads_norm = 5.4379
	old_data_grads_norm = 3.8873
	sim_grads_norm_tr = -0.0502
-- Starting training on experience 90 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3613
	data_grads_norm = 3.9264
	new_data_grads_norm = 5.8424
	old_data_grads_norm = 3.3397
	sim_grads_norm_tr = 0.2087
-- Starting training on experience 91 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3444
	data_grads_norm = 3.1554
	new_data_grads_norm = 6.1884
	old_data_grads_norm = 2.8711
	sim_grads_norm_tr = -0.1652
-- Starting training on experience 92 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4074
	data_grads_norm = 2.8942
	new_data_grads_norm = 4.9946
	old_data_grads_norm = 3.2647
	sim_grads_norm_tr = -0.2186
-- Starting training on experience 93 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6265
	data_grads_norm = 3.5994
	new_data_grads_norm = 6.5862
	old_data_grads_norm = 3.5206
	sim_grads_norm_tr = -0.0415
-- Starting training on experience 94 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8064
	data_grads_norm = 4.6516
	new_data_grads_norm = 6.3583
	old_data_grads_norm = 4.2983
	sim_grads_norm_tr = 0.2354
-- Starting training on experience 95 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6705
	data_grads_norm = 3.9271
	new_data_grads_norm = 5.9158
	old_data_grads_norm = 3.0957
	sim_grads_norm_tr = 0.3169
-- Starting training on experience 96 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5670
	data_grads_norm = 3.5281
	new_data_grads_norm = 4.5218
	old_data_grads_norm = 3.3649
	sim_grads_norm_tr = 0.5799
-- Starting training on experience 97 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1689
	data_grads_norm = 2.5972
	new_data_grads_norm = 4.5444
	old_data_grads_norm = 4.9164
	sim_grads_norm_tr = -0.0900
-- Starting training on experience 98 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1832
	data_grads_norm = 2.6801
	new_data_grads_norm = 3.9342
	old_data_grads_norm = 3.6634
	sim_grads_norm_tr = -0.0192
-- Starting training on experience 99 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2628
	data_grads_norm = 3.0732
	new_data_grads_norm = 4.8543
	old_data_grads_norm = 3.5023
	sim_grads_norm_tr = 0.0553
-- Starting training on experience 100 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4580
	data_grads_norm = 2.9983
	new_data_grads_norm = 5.0545
	old_data_grads_norm = 2.8720
	sim_grads_norm_tr = 0.1122
-- Starting training on experience 101 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2330
	data_grads_norm = 2.3829
	new_data_grads_norm = 4.1326
	old_data_grads_norm = 3.1721
	sim_grads_norm_tr = -0.2164
-- Starting training on experience 102 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4235
	data_grads_norm = 3.7733
	new_data_grads_norm = 5.3961
	old_data_grads_norm = 3.3970
	sim_grads_norm_tr = 0.2777
-- Starting training on experience 103 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4201
	data_grads_norm = 2.5976
	new_data_grads_norm = 4.5975
	old_data_grads_norm = 3.9031
	sim_grads_norm_tr = -0.2500
-- Starting training on experience 104 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2824
	data_grads_norm = 2.9458
	new_data_grads_norm = 5.4274
	old_data_grads_norm = 2.9259
	sim_grads_norm_tr = 0.0547
-- Starting training on experience 105 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3526
	data_grads_norm = 2.4686
	new_data_grads_norm = 5.7686
	old_data_grads_norm = 2.6575
	sim_grads_norm_tr = -0.2493
-- Starting training on experience 106 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5970
	data_grads_norm = 4.5479
	new_data_grads_norm = 6.8497
	old_data_grads_norm = 3.6504
	sim_grads_norm_tr = 0.3972
-- Starting training on experience 107 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3907
	data_grads_norm = 4.6033
	new_data_grads_norm = 6.5577
	old_data_grads_norm = 3.6499
	sim_grads_norm_tr = 0.6549
-- Starting training on experience 108 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9273
	data_grads_norm = 2.0666
	new_data_grads_norm = 4.2158
	old_data_grads_norm = 3.6061
	sim_grads_norm_tr = -0.3283
-- Starting training on experience 109 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4894
	data_grads_norm = 2.9141
	new_data_grads_norm = 4.6864
	old_data_grads_norm = 4.2224
	sim_grads_norm_tr = -0.0855
-- Starting training on experience 110 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3693
	data_grads_norm = 2.9845
	new_data_grads_norm = 5.7111
	old_data_grads_norm = 2.9332
	sim_grads_norm_tr = -0.3681
-- Starting training on experience 111 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2909
	data_grads_norm = 2.9279
	new_data_grads_norm = 5.4387
	old_data_grads_norm = 2.3527
	sim_grads_norm_tr = 0.0427
-- Starting training on experience 112 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4404
	data_grads_norm = 3.9918
	new_data_grads_norm = 5.7288
	old_data_grads_norm = 3.3903
	sim_grads_norm_tr = 0.5623
-- Starting training on experience 113 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0589
	data_grads_norm = 3.2272
	new_data_grads_norm = 4.5661
	old_data_grads_norm = 3.4970
	sim_grads_norm_tr = 0.2774
-- Starting training on experience 114 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8667
	data_grads_norm = 1.9490
	new_data_grads_norm = 5.2521
	old_data_grads_norm = 3.8654
	sim_grads_norm_tr = -0.3076
-- Starting training on experience 115 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3011
	data_grads_norm = 3.9022
	new_data_grads_norm = 5.6949
	old_data_grads_norm = 3.6549
	sim_grads_norm_tr = 0.4635
-- Starting training on experience 116 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6291
	data_grads_norm = 4.4553
	new_data_grads_norm = 5.2611
	old_data_grads_norm = 6.2783
	sim_grads_norm_tr = 0.0526
-- Starting training on experience 117 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6199
	data_grads_norm = 3.9458
	new_data_grads_norm = 6.1011
	old_data_grads_norm = 3.7087
	sim_grads_norm_tr = 0.1858
-- Starting training on experience 118 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6025
	data_grads_norm = 3.8685
	new_data_grads_norm = 5.8632
	old_data_grads_norm = 4.1017
	sim_grads_norm_tr = 0.3515
-- Starting training on experience 119 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3766
	data_grads_norm = 3.0811
	new_data_grads_norm = 6.1081
	old_data_grads_norm = 2.8041
	sim_grads_norm_tr = -0.0032
-- Starting training on experience 120 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6245
	data_grads_norm = 3.6271
	new_data_grads_norm = 6.2918
	old_data_grads_norm = 3.2488
	sim_grads_norm_tr = 0.1187
-- Starting training on experience 121 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1746
	data_grads_norm = 3.0845
	new_data_grads_norm = 5.0349
	old_data_grads_norm = 2.9493
	sim_grads_norm_tr = 0.2713
-- Starting training on experience 122 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3619
	data_grads_norm = 3.6535
	new_data_grads_norm = 5.3154
	old_data_grads_norm = 4.1770
	sim_grads_norm_tr = 0.1223
-- Starting training on experience 123 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3737
	data_grads_norm = 3.2488
	new_data_grads_norm = 4.7041
	old_data_grads_norm = 3.4516
	sim_grads_norm_tr = 0.0068
-- Starting training on experience 124 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4283
	data_grads_norm = 4.1234
	new_data_grads_norm = 5.3646
	old_data_grads_norm = 4.2577
	sim_grads_norm_tr = 0.4943
-- Starting training on experience 125 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2163
	data_grads_norm = 2.9263
	new_data_grads_norm = 4.6321
	old_data_grads_norm = 3.9958
	sim_grads_norm_tr = -0.2789
-- Starting training on experience 126 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2284
	data_grads_norm = 3.4868
	new_data_grads_norm = 5.5027
	old_data_grads_norm = 4.0693
	sim_grads_norm_tr = 0.1488
-- Starting training on experience 127 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2203
	data_grads_norm = 2.5250
	new_data_grads_norm = 4.6781
	old_data_grads_norm = 3.9890
	sim_grads_norm_tr = -0.4527
-- Starting training on experience 128 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3780
	data_grads_norm = 3.6854
	new_data_grads_norm = 5.9827
	old_data_grads_norm = 3.2431
	sim_grads_norm_tr = 0.1099
-- Starting training on experience 129 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4747
	data_grads_norm = 4.1593
	new_data_grads_norm = 6.2344
	old_data_grads_norm = 3.6241
	sim_grads_norm_tr = 0.3305
-- Starting training on experience 130 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6442
	data_grads_norm = 3.8836
	new_data_grads_norm = 5.6356
	old_data_grads_norm = 3.7815
	sim_grads_norm_tr = 0.2790
-- Starting training on experience 131 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3204
	data_grads_norm = 2.6933
	new_data_grads_norm = 4.7854
	old_data_grads_norm = 3.2591
	sim_grads_norm_tr = -0.2702
-- Starting training on experience 132 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4969
	data_grads_norm = 3.9993
	new_data_grads_norm = 5.6379
	old_data_grads_norm = 3.0792
	sim_grads_norm_tr = -0.1041
-- Starting training on experience 133 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2576
	data_grads_norm = 3.3208
	new_data_grads_norm = 5.9377
	old_data_grads_norm = 2.8354
	sim_grads_norm_tr = 0.0262
-- Starting training on experience 134 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3731
	data_grads_norm = 3.5399
	new_data_grads_norm = 5.6766
	old_data_grads_norm = 3.1218
	sim_grads_norm_tr = 0.1676
-- Starting training on experience 135 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3264
	data_grads_norm = 3.1539
	new_data_grads_norm = 5.1506
	old_data_grads_norm = 3.8461
	sim_grads_norm_tr = 0.1558
-- Starting training on experience 136 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1303
	data_grads_norm = 2.9144
	new_data_grads_norm = 5.4633
	old_data_grads_norm = 2.5263
	sim_grads_norm_tr = 0.1400
-- Starting training on experience 137 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1770
	data_grads_norm = 2.7116
	new_data_grads_norm = 5.8466
	old_data_grads_norm = 2.0958
	sim_grads_norm_tr = -0.1250
-- Starting training on experience 138 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2938
	data_grads_norm = 4.2774
	new_data_grads_norm = 6.5111
	old_data_grads_norm = 3.5755
	sim_grads_norm_tr = 0.3616
-- Starting training on experience 139 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1638
	data_grads_norm = 2.4249
	new_data_grads_norm = 5.2902
	old_data_grads_norm = 3.3319
	sim_grads_norm_tr = -0.2847
-- Starting training on experience 140 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4550
	data_grads_norm = 3.4189
	new_data_grads_norm = 5.6268
	old_data_grads_norm = 3.0527
	sim_grads_norm_tr = -0.0939
-- Starting training on experience 141 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5619
	data_grads_norm = 3.6636
	new_data_grads_norm = 5.3564
	old_data_grads_norm = 4.0776
	sim_grads_norm_tr = 0.2823
-- Starting training on experience 142 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0210
	data_grads_norm = 2.5324
	new_data_grads_norm = 3.9730
	old_data_grads_norm = 2.6079
	sim_grads_norm_tr = 0.1646
-- Starting training on experience 143 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0111
	data_grads_norm = 2.5398
	new_data_grads_norm = 5.1074
	old_data_grads_norm = 2.3045
	sim_grads_norm_tr = -0.0201
-- Starting training on experience 144 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3533
	data_grads_norm = 3.9960
	new_data_grads_norm = 5.5566
	old_data_grads_norm = 5.6470
	sim_grads_norm_tr = 0.1420
-- Starting training on experience 145 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2597
	data_grads_norm = 2.6422
	new_data_grads_norm = 5.0947
	old_data_grads_norm = 2.8488
	sim_grads_norm_tr = -0.3106
-- Starting training on experience 146 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4004
	data_grads_norm = 3.2121
	new_data_grads_norm = 5.1878
	old_data_grads_norm = 4.1291
	sim_grads_norm_tr = -0.0554
-- Starting training on experience 147 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3216
	data_grads_norm = 3.0062
	new_data_grads_norm = 5.6739
	old_data_grads_norm = 3.2833
	sim_grads_norm_tr = -0.1253
-- Starting training on experience 148 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2484
	data_grads_norm = 3.7887
	new_data_grads_norm = 6.1842
	old_data_grads_norm = 2.8248
	sim_grads_norm_tr = 0.4329
-- Starting training on experience 149 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2851
	data_grads_norm = 3.1909
	new_data_grads_norm = 5.4600
	old_data_grads_norm = 3.6062
	sim_grads_norm_tr = -0.1506
-- Starting training on experience 150 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4878
	data_grads_norm = 4.7741
	new_data_grads_norm = 6.4382
	old_data_grads_norm = 4.5908
	sim_grads_norm_tr = 0.5260
-- Starting training on experience 151 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4386
	data_grads_norm = 2.7942
	new_data_grads_norm = 4.4340
	old_data_grads_norm = 3.4450
	sim_grads_norm_tr = -0.0379
-- Starting training on experience 152 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2418
	data_grads_norm = 3.3455
	new_data_grads_norm = 4.5807
	old_data_grads_norm = 3.7508
	sim_grads_norm_tr = 0.2217
-- Starting training on experience 153 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1840
	data_grads_norm = 3.3993
	new_data_grads_norm = 4.6354
	old_data_grads_norm = 4.6922
	sim_grads_norm_tr = 0.1097
-- Starting training on experience 154 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6804
	data_grads_norm = 3.4466
	new_data_grads_norm = 5.2206
	old_data_grads_norm = 3.8799
	sim_grads_norm_tr = -0.0360
-- Starting training on experience 155 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3615
	data_grads_norm = 3.0614
	new_data_grads_norm = 5.1847
	old_data_grads_norm = 3.8901
	sim_grads_norm_tr = -0.0895
-- Starting training on experience 156 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6262
	data_grads_norm = 4.6739
	new_data_grads_norm = 7.7313
	old_data_grads_norm = 5.3485
	sim_grads_norm_tr = 0.0567
-- Starting training on experience 157 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6774
	data_grads_norm = 4.1063
	new_data_grads_norm = 5.5893
	old_data_grads_norm = 4.0508
	sim_grads_norm_tr = 0.4599
-- Starting training on experience 158 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1084
	data_grads_norm = 3.1049
	new_data_grads_norm = 4.4274
	old_data_grads_norm = 3.0804
	sim_grads_norm_tr = 0.2446
-- Starting training on experience 159 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2962
	data_grads_norm = 2.9753
	new_data_grads_norm = 5.5611
	old_data_grads_norm = 2.6847
	sim_grads_norm_tr = -0.1475
-- Starting training on experience 160 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4840
	data_grads_norm = 4.3779
	new_data_grads_norm = 5.0733
	old_data_grads_norm = 4.7834
	sim_grads_norm_tr = 0.5147
-- Starting training on experience 161 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9353
	data_grads_norm = 2.0122
	new_data_grads_norm = 3.8280
	old_data_grads_norm = 3.0636
	sim_grads_norm_tr = -0.3978
-- Starting training on experience 162 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3036
	data_grads_norm = 3.2047
	new_data_grads_norm = 5.1778
	old_data_grads_norm = 3.2202
	sim_grads_norm_tr = 0.2389
-- Starting training on experience 163 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2989
	data_grads_norm = 3.7938
	new_data_grads_norm = 5.1635
	old_data_grads_norm = 4.2041
	sim_grads_norm_tr = 0.2821
-- Starting training on experience 164 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9997
	data_grads_norm = 2.5293
	new_data_grads_norm = 4.0607
	old_data_grads_norm = 2.8648
	sim_grads_norm_tr = -0.0662
-- Starting training on experience 165 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9015
	data_grads_norm = 2.7863
	new_data_grads_norm = 4.2143
	old_data_grads_norm = 2.7113
	sim_grads_norm_tr = 0.2133
-- Starting training on experience 166 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1772
	data_grads_norm = 2.3728
	new_data_grads_norm = 4.2778
	old_data_grads_norm = 2.9587
	sim_grads_norm_tr = -0.0697
-- Starting training on experience 167 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8994
	data_grads_norm = 2.1550
	new_data_grads_norm = 4.5451
	old_data_grads_norm = 2.3437
	sim_grads_norm_tr = -0.1484
-- Starting training on experience 168 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9446
	data_grads_norm = 2.4423
	new_data_grads_norm = 4.2462
	old_data_grads_norm = 2.7662
	sim_grads_norm_tr = -0.2715
-- Starting training on experience 169 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2180
	data_grads_norm = 3.2015
	new_data_grads_norm = 4.9985
	old_data_grads_norm = 3.3779
	sim_grads_norm_tr = 0.2260
-- Starting training on experience 170 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0008
	data_grads_norm = 2.4739
	new_data_grads_norm = 3.7661
	old_data_grads_norm = 3.9425
	sim_grads_norm_tr = -0.1001
-- Starting training on experience 171 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7594
	data_grads_norm = 4.8097
	new_data_grads_norm = 4.2851
	old_data_grads_norm = 8.0114
	sim_grads_norm_tr = 0.0682
-- Starting training on experience 172 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2160
	data_grads_norm = 3.9427
	new_data_grads_norm = 5.0709
	old_data_grads_norm = 4.9062
	sim_grads_norm_tr = 0.1242
-- Starting training on experience 173 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6088
	data_grads_norm = 5.2200
	new_data_grads_norm = 5.7719
	old_data_grads_norm = 5.6182
	sim_grads_norm_tr = 0.4432
-- Starting training on experience 174 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9614
	data_grads_norm = 2.2802
	new_data_grads_norm = 4.2027
	old_data_grads_norm = 3.0976
	sim_grads_norm_tr = -0.2443
-- Starting training on experience 175 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3916
	data_grads_norm = 3.8999
	new_data_grads_norm = 6.0480
	old_data_grads_norm = 4.5223
	sim_grads_norm_tr = 0.0083
-- Starting training on experience 176 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4989
	data_grads_norm = 3.4195
	new_data_grads_norm = 5.1845
	old_data_grads_norm = 2.9033
	sim_grads_norm_tr = 0.1370
-- Starting training on experience 177 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2902
	data_grads_norm = 3.5524
	new_data_grads_norm = 4.4816
	old_data_grads_norm = 3.8142
	sim_grads_norm_tr = 0.2493
-- Starting training on experience 178 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2402
	data_grads_norm = 3.2287
	new_data_grads_norm = 5.7131
	old_data_grads_norm = 4.2889
	sim_grads_norm_tr = -0.1456
-- Starting training on experience 179 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4224
	data_grads_norm = 3.1737
	new_data_grads_norm = 5.2102
	old_data_grads_norm = 2.8049
	sim_grads_norm_tr = -0.0344
-- Starting training on experience 180 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4916
	data_grads_norm = 3.3336
	new_data_grads_norm = 5.5953
	old_data_grads_norm = 4.7321
	sim_grads_norm_tr = -0.4454
-- Starting training on experience 181 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5051
	data_grads_norm = 4.2496
	new_data_grads_norm = 6.2582
	old_data_grads_norm = 4.1841
	sim_grads_norm_tr = 0.2879
-- Starting training on experience 182 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5089
	data_grads_norm = 3.4201
	new_data_grads_norm = 5.4498
	old_data_grads_norm = 5.2743
	sim_grads_norm_tr = -0.1847
-- Starting training on experience 183 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5543
	data_grads_norm = 3.3314
	new_data_grads_norm = 5.8989
	old_data_grads_norm = 3.0657
	sim_grads_norm_tr = 0.0636
-- Starting training on experience 184 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5290
	data_grads_norm = 4.1829
	new_data_grads_norm = 5.5827
	old_data_grads_norm = 4.6072
	sim_grads_norm_tr = 0.3334
-- Starting training on experience 185 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5009
	data_grads_norm = 3.4170
	new_data_grads_norm = 5.0640
	old_data_grads_norm = 3.5935
	sim_grads_norm_tr = 0.3242
-- Starting training on experience 186 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2139
	data_grads_norm = 2.7520
	new_data_grads_norm = 4.7390
	old_data_grads_norm = 2.9716
	sim_grads_norm_tr = -0.1321
-- Starting training on experience 187 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3529
	data_grads_norm = 3.4540
	new_data_grads_norm = 4.5752
	old_data_grads_norm = 4.0716
	sim_grads_norm_tr = 0.2201
-- Starting training on experience 188 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5241
	data_grads_norm = 3.6369
	new_data_grads_norm = 5.0592
	old_data_grads_norm = 3.5824
	sim_grads_norm_tr = 0.4864
-- Starting training on experience 189 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1914
	data_grads_norm = 3.0249
	new_data_grads_norm = 3.7736
	old_data_grads_norm = 3.7916
	sim_grads_norm_tr = 0.1930
-- Starting training on experience 190 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1288
	data_grads_norm = 2.8878
	new_data_grads_norm = 4.8994
	old_data_grads_norm = 3.2229
	sim_grads_norm_tr = -0.1487
-- Starting training on experience 191 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4424
	data_grads_norm = 4.2532
	new_data_grads_norm = 5.5297
	old_data_grads_norm = 4.4796
	sim_grads_norm_tr = 0.2372
-- Starting training on experience 192 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2028
	data_grads_norm = 3.0225
	new_data_grads_norm = 5.5286
	old_data_grads_norm = 3.1421
	sim_grads_norm_tr = 0.1305
-- Starting training on experience 193 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4154
	data_grads_norm = 3.8003
	new_data_grads_norm = 4.6126
	old_data_grads_norm = 4.8899
	sim_grads_norm_tr = 0.1092
-- Starting training on experience 194 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4309
	data_grads_norm = 3.5640
	new_data_grads_norm = 5.0089
	old_data_grads_norm = 3.4344
	sim_grads_norm_tr = 0.2003
-- Starting training on experience 195 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2052
	data_grads_norm = 3.5118
	new_data_grads_norm = 4.9113
	old_data_grads_norm = 4.4013
	sim_grads_norm_tr = -0.1007
-- Starting training on experience 196 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4459
	data_grads_norm = 3.0300
	new_data_grads_norm = 5.1072
	old_data_grads_norm = 4.1044
	sim_grads_norm_tr = -0.2263
-- Starting training on experience 197 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3481
	data_grads_norm = 3.2209
	new_data_grads_norm = 5.8751
	old_data_grads_norm = 2.4738
	sim_grads_norm_tr = 0.1362
-- Starting training on experience 198 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2551
	data_grads_norm = 3.1468
	new_data_grads_norm = 5.4602
	old_data_grads_norm = 3.0120
	sim_grads_norm_tr = 0.2422
-- Starting training on experience 199 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4315
	data_grads_norm = 3.0931
	new_data_grads_norm = 4.6162
	old_data_grads_norm = 3.1017
	sim_grads_norm_tr = 0.3860
-- Starting training on experience 200 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2879
	data_grads_norm = 3.1529
	new_data_grads_norm = 4.8451
	old_data_grads_norm = 3.2190
	sim_grads_norm_tr = 0.2080
-- Starting training on experience 201 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2532
	data_grads_norm = 2.2016
	new_data_grads_norm = 4.0302
	old_data_grads_norm = 5.3854
	sim_grads_norm_tr = -0.3582
-- Starting training on experience 202 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2250
	data_grads_norm = 2.7827
	new_data_grads_norm = 5.2079
	old_data_grads_norm = 2.2150
	sim_grads_norm_tr = -0.1978
-- Starting training on experience 203 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3214
	data_grads_norm = 3.7759
	new_data_grads_norm = 6.1447
	old_data_grads_norm = 2.8625
	sim_grads_norm_tr = 0.2935
-- Starting training on experience 204 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3676
	data_grads_norm = 3.4695
	new_data_grads_norm = 5.5705
	old_data_grads_norm = 2.6985
	sim_grads_norm_tr = 0.4373
-- Starting training on experience 205 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1432
	data_grads_norm = 2.9109
	new_data_grads_norm = 4.0473
	old_data_grads_norm = 3.3392
	sim_grads_norm_tr = 0.1583
-- Starting training on experience 206 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0629
	data_grads_norm = 2.4594
	new_data_grads_norm = 4.2255
	old_data_grads_norm = 4.5145
	sim_grads_norm_tr = -0.1002
-- Starting training on experience 207 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0162
	data_grads_norm = 3.0917
	new_data_grads_norm = 4.9381
	old_data_grads_norm = 2.6215
	sim_grads_norm_tr = 0.2492
-- Starting training on experience 208 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8214
	data_grads_norm = 3.1644
	new_data_grads_norm = 4.4115
	old_data_grads_norm = 4.9795
	sim_grads_norm_tr = -0.1186
-- Starting training on experience 209 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2965
	data_grads_norm = 3.3309
	new_data_grads_norm = 5.5093
	old_data_grads_norm = 2.4923
	sim_grads_norm_tr = 0.2339
-- Starting training on experience 210 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1785
	data_grads_norm = 2.4725
	new_data_grads_norm = 4.2160
	old_data_grads_norm = 3.6309
	sim_grads_norm_tr = -0.1291
-- Starting training on experience 211 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2827
	data_grads_norm = 3.1216
	new_data_grads_norm = 4.9988
	old_data_grads_norm = 2.5545
	sim_grads_norm_tr = 0.3087
-- Starting training on experience 212 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4198
	data_grads_norm = 2.9087
	new_data_grads_norm = 5.3171
	old_data_grads_norm = 2.6023
	sim_grads_norm_tr = -0.0521
-- Starting training on experience 213 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7488
	data_grads_norm = 5.0179
	new_data_grads_norm = 5.7850
	old_data_grads_norm = 5.5038
	sim_grads_norm_tr = 0.2002
-- Starting training on experience 214 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4796
	data_grads_norm = 3.8491
	new_data_grads_norm = 6.6339
	old_data_grads_norm = 2.1147
	sim_grads_norm_tr = 0.2003
-- Starting training on experience 215 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0589
	data_grads_norm = 2.5126
	new_data_grads_norm = 3.8375
	old_data_grads_norm = 2.8347
	sim_grads_norm_tr = 0.1884
-- Starting training on experience 216 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0285
	data_grads_norm = 2.9641
	new_data_grads_norm = 3.9137
	old_data_grads_norm = 3.8698
	sim_grads_norm_tr = 0.1668
-- Starting training on experience 217 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0306
	data_grads_norm = 2.5651
	new_data_grads_norm = 4.2539
	old_data_grads_norm = 2.8279
	sim_grads_norm_tr = 0.0665
-- Starting training on experience 218 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3233
	data_grads_norm = 2.3464
	new_data_grads_norm = 3.9727
	old_data_grads_norm = 3.9584
	sim_grads_norm_tr = -0.2753
-- Starting training on experience 219 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2162
	data_grads_norm = 3.4735
	new_data_grads_norm = 4.9577
	old_data_grads_norm = 3.1585
	sim_grads_norm_tr = 0.4360
-- Starting training on experience 220 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9395
	data_grads_norm = 2.2488
	new_data_grads_norm = 3.7993
	old_data_grads_norm = 3.0620
	sim_grads_norm_tr = -0.2952
-- Starting training on experience 221 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3428
	data_grads_norm = 3.1656
	new_data_grads_norm = 4.6228
	old_data_grads_norm = 3.9732
	sim_grads_norm_tr = -0.0784
-- Starting training on experience 222 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5860
	data_grads_norm = 3.6982
	new_data_grads_norm = 4.8478
	old_data_grads_norm = 4.9123
	sim_grads_norm_tr = 0.1428
-- Starting training on experience 223 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3665
	data_grads_norm = 3.4390
	new_data_grads_norm = 4.7130
	old_data_grads_norm = 3.3475
	sim_grads_norm_tr = 0.2773
-- Starting training on experience 224 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0908
	data_grads_norm = 2.7805
	new_data_grads_norm = 3.3994
	old_data_grads_norm = 3.9640
	sim_grads_norm_tr = 0.0853
-- Starting training on experience 225 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0980
	data_grads_norm = 2.2691
	new_data_grads_norm = 3.8543
	old_data_grads_norm = 3.6888
	sim_grads_norm_tr = -0.3831
-- Starting training on experience 226 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2487
	data_grads_norm = 3.2293
	new_data_grads_norm = 4.8911
	old_data_grads_norm = 2.9503
	sim_grads_norm_tr = 0.2815
-- Starting training on experience 227 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0527
	data_grads_norm = 2.7606
	new_data_grads_norm = 4.1653
	old_data_grads_norm = 3.8972
	sim_grads_norm_tr = -0.2758
-- Starting training on experience 228 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1783
	data_grads_norm = 3.3932
	new_data_grads_norm = 5.1744
	old_data_grads_norm = 3.3510
	sim_grads_norm_tr = -0.0255
-- Starting training on experience 229 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2388
	data_grads_norm = 4.3072
	new_data_grads_norm = 5.6641
	old_data_grads_norm = 4.1302
	sim_grads_norm_tr = 0.4279
-- Starting training on experience 230 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9366
	data_grads_norm = 2.9686
	new_data_grads_norm = 4.8206
	old_data_grads_norm = 3.5909
	sim_grads_norm_tr = 0.0114
-- Starting training on experience 231 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0442
	data_grads_norm = 3.0992
	new_data_grads_norm = 4.2841
	old_data_grads_norm = 3.5990
	sim_grads_norm_tr = 0.3135
-- Starting training on experience 232 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0985
	data_grads_norm = 2.8973
	new_data_grads_norm = 3.5537
	old_data_grads_norm = 5.9228
	sim_grads_norm_tr = 0.0439
-- Starting training on experience 233 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0340
	data_grads_norm = 3.4561
	new_data_grads_norm = 5.2617
	old_data_grads_norm = 3.2861
	sim_grads_norm_tr = 0.2928
-- Starting training on experience 234 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1307
	data_grads_norm = 2.7265
	new_data_grads_norm = 3.4531
	old_data_grads_norm = 5.1633
	sim_grads_norm_tr = -0.2852
-- Starting training on experience 235 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3312
	data_grads_norm = 3.5342
	new_data_grads_norm = 5.1465
	old_data_grads_norm = 5.6705
	sim_grads_norm_tr = 0.0276
-- Starting training on experience 236 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3321
	data_grads_norm = 3.2660
	new_data_grads_norm = 4.5702
	old_data_grads_norm = 3.3898
	sim_grads_norm_tr = 0.3290
-- Starting training on experience 237 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2024
	data_grads_norm = 3.3407
	new_data_grads_norm = 4.7466
	old_data_grads_norm = 2.7409
	sim_grads_norm_tr = 0.2504
-- Starting training on experience 238 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1698
	data_grads_norm = 2.6803
	new_data_grads_norm = 5.6599
	old_data_grads_norm = 2.9021
	sim_grads_norm_tr = -0.2268
-- Starting training on experience 239 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1699
	data_grads_norm = 3.3229
	new_data_grads_norm = 5.4017
	old_data_grads_norm = 2.9743
	sim_grads_norm_tr = 0.0063
-- Starting training on experience 240 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5026
	data_grads_norm = 3.6176
	new_data_grads_norm = 5.2784
	old_data_grads_norm = 3.5309
	sim_grads_norm_tr = 0.2153
-- Starting training on experience 241 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4903
	data_grads_norm = 3.5074
	new_data_grads_norm = 5.2921
	old_data_grads_norm = 3.1842
	sim_grads_norm_tr = 0.3061
-- Starting training on experience 242 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2122
	data_grads_norm = 2.3631
	new_data_grads_norm = 4.2306
	old_data_grads_norm = 3.0267
	sim_grads_norm_tr = 0.0126
-- Starting training on experience 243 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2115
	data_grads_norm = 2.1681
	new_data_grads_norm = 3.9418
	old_data_grads_norm = 2.9084
	sim_grads_norm_tr = -0.4872
-- Starting training on experience 244 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3319
	data_grads_norm = 3.8031
	new_data_grads_norm = 4.8267
	old_data_grads_norm = 5.4429
	sim_grads_norm_tr = -0.0127
-- Starting training on experience 245 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3372
	data_grads_norm = 3.3370
	new_data_grads_norm = 5.2738
	old_data_grads_norm = 4.0903
	sim_grads_norm_tr = 0.1394
-- Starting training on experience 246 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2131
	data_grads_norm = 2.4859
	new_data_grads_norm = 4.2430
	old_data_grads_norm = 2.4668
	sim_grads_norm_tr = 0.0341
-- Starting training on experience 247 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0072
	data_grads_norm = 2.3596
	new_data_grads_norm = 3.7490
	old_data_grads_norm = 3.6738
	sim_grads_norm_tr = -0.3030
-- Starting training on experience 248 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1545
	data_grads_norm = 2.9506
	new_data_grads_norm = 5.1323
	old_data_grads_norm = 2.9890
	sim_grads_norm_tr = -0.2397
-- Starting training on experience 249 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1059
	data_grads_norm = 4.2173
	new_data_grads_norm = 6.5035
	old_data_grads_norm = 3.1563
	sim_grads_norm_tr = 0.0747
-- Starting training on experience 250 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1174
	data_grads_norm = 3.3351
	new_data_grads_norm = 5.4069
	old_data_grads_norm = 3.0327
	sim_grads_norm_tr = 0.3046
-- Starting training on experience 251 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3532
	data_grads_norm = 3.6233
	new_data_grads_norm = 5.1961
	old_data_grads_norm = 4.0143
	sim_grads_norm_tr = 0.0928
-- Starting training on experience 252 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4069
	data_grads_norm = 3.3377
	new_data_grads_norm = 4.9936
	old_data_grads_norm = 4.3898
	sim_grads_norm_tr = -0.1729
-- Starting training on experience 253 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6875
	data_grads_norm = 3.6939
	new_data_grads_norm = 6.5418
	old_data_grads_norm = 3.7507
	sim_grads_norm_tr = 0.2589
-- Starting training on experience 254 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0950
	data_grads_norm = 3.1048
	new_data_grads_norm = 5.2361
	old_data_grads_norm = 3.2212
	sim_grads_norm_tr = 0.1542
-- Starting training on experience 255 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9899
	data_grads_norm = 3.0571
	new_data_grads_norm = 4.5704
	old_data_grads_norm = 2.8491
	sim_grads_norm_tr = 0.3677
-- Starting training on experience 256 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8998
	data_grads_norm = 3.0894
	new_data_grads_norm = 5.8789
	old_data_grads_norm = 2.7977
	sim_grads_norm_tr = 0.0609
-- Starting training on experience 257 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9978
	data_grads_norm = 3.1104
	new_data_grads_norm = 4.1555
	old_data_grads_norm = 4.3743
	sim_grads_norm_tr = -0.2217
-- Starting training on experience 258 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8026
	data_grads_norm = 4.8294
	new_data_grads_norm = 5.8515
	old_data_grads_norm = 5.2848
	sim_grads_norm_tr = 0.5141
-- Starting training on experience 259 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0800
	data_grads_norm = 2.7174
	new_data_grads_norm = 5.2482
	old_data_grads_norm = 2.8420
	sim_grads_norm_tr = -0.0953
-- Starting training on experience 260 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.6801
	data_grads_norm = 2.0435
	new_data_grads_norm = 3.7967
	old_data_grads_norm = 3.1189
	sim_grads_norm_tr = -0.1541
-- Starting training on experience 261 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2640
	data_grads_norm = 4.0934
	new_data_grads_norm = 4.7034
	old_data_grads_norm = 5.5609
	sim_grads_norm_tr = 0.2459
-- Starting training on experience 262 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0414
	data_grads_norm = 2.0643
	new_data_grads_norm = 3.2655
	old_data_grads_norm = 4.5884
	sim_grads_norm_tr = -0.5102
-- Starting training on experience 263 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3220
	data_grads_norm = 3.6917
	new_data_grads_norm = 5.6545
	old_data_grads_norm = 4.2865
	sim_grads_norm_tr = -0.0047
-- Starting training on experience 264 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0065
	data_grads_norm = 2.5078
	new_data_grads_norm = 4.9354
	old_data_grads_norm = 2.5800
	sim_grads_norm_tr = -0.1581
-- Starting training on experience 265 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4834
	data_grads_norm = 3.4069
	new_data_grads_norm = 5.0922
	old_data_grads_norm = 4.2074
	sim_grads_norm_tr = 0.0263
-- Starting training on experience 266 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1343
	data_grads_norm = 3.8395
	new_data_grads_norm = 6.1819
	old_data_grads_norm = 4.1603
	sim_grads_norm_tr = 0.1571
-- Starting training on experience 267 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0330
	data_grads_norm = 3.2169
	new_data_grads_norm = 5.6671
	old_data_grads_norm = 3.5609
	sim_grads_norm_tr = 0.0379
-- Starting training on experience 268 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4288
	data_grads_norm = 3.5084
	new_data_grads_norm = 5.7829
	old_data_grads_norm = 4.1187
	sim_grads_norm_tr = 0.0078
-- Starting training on experience 269 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1592
	data_grads_norm = 3.5427
	new_data_grads_norm = 5.0411
	old_data_grads_norm = 4.0443
	sim_grads_norm_tr = 0.1797
-- Starting training on experience 270 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3616
	data_grads_norm = 4.0217
	new_data_grads_norm = 6.4963
	old_data_grads_norm = 4.3351
	sim_grads_norm_tr = 0.0136
-- Starting training on experience 271 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9727
	data_grads_norm = 2.7788
	new_data_grads_norm = 4.9571
	old_data_grads_norm = 2.9664
	sim_grads_norm_tr = -0.2597
-- Starting training on experience 272 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0131
	data_grads_norm = 3.5702
	new_data_grads_norm = 5.9695
	old_data_grads_norm = 2.7650
	sim_grads_norm_tr = 0.2721
-- Starting training on experience 273 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2676
	data_grads_norm = 3.0230
	new_data_grads_norm = 4.6608
	old_data_grads_norm = 3.4155
	sim_grads_norm_tr = 0.1452
-- Starting training on experience 274 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0742
	data_grads_norm = 2.3341
	new_data_grads_norm = 4.0360
	old_data_grads_norm = 3.4594
	sim_grads_norm_tr = -0.2341
-- Starting training on experience 275 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0523
	data_grads_norm = 2.4873
	new_data_grads_norm = 4.7822
	old_data_grads_norm = 2.4609
	sim_grads_norm_tr = -0.2375
-- Starting training on experience 276 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1100
	data_grads_norm = 2.8111
	new_data_grads_norm = 6.6986
	old_data_grads_norm = 2.1701
	sim_grads_norm_tr = -0.1087
-- Starting training on experience 277 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4375
	data_grads_norm = 3.2004
	new_data_grads_norm = 6.1762
	old_data_grads_norm = 3.4312
	sim_grads_norm_tr = 0.1714
-- Starting training on experience 278 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4390
	data_grads_norm = 3.1739
	new_data_grads_norm = 5.3666
	old_data_grads_norm = 2.9377
	sim_grads_norm_tr = 0.0746
-- Starting training on experience 279 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9420
	data_grads_norm = 2.4439
	new_data_grads_norm = 5.4940
	old_data_grads_norm = 1.9628
	sim_grads_norm_tr = -0.2647
-- Starting training on experience 280 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2048
	data_grads_norm = 3.3724
	new_data_grads_norm = 5.4741
	old_data_grads_norm = 2.9678
	sim_grads_norm_tr = 0.1381
-- Starting training on experience 281 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3325
	data_grads_norm = 3.5224
	new_data_grads_norm = 5.2618
	old_data_grads_norm = 2.9719
	sim_grads_norm_tr = 0.1842
-- Starting training on experience 282 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9134
	data_grads_norm = 2.4187
	new_data_grads_norm = 6.1270
	old_data_grads_norm = 2.2473
	sim_grads_norm_tr = -0.1263
-- Starting training on experience 283 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0442
	data_grads_norm = 3.4464
	new_data_grads_norm = 5.9724
	old_data_grads_norm = 3.6654
	sim_grads_norm_tr = 0.0907
-- Starting training on experience 284 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1479
	data_grads_norm = 3.6137
	new_data_grads_norm = 5.6130
	old_data_grads_norm = 3.7258
	sim_grads_norm_tr = 0.1054
-- Starting training on experience 285 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1043
	data_grads_norm = 3.2970
	new_data_grads_norm = 5.0270
	old_data_grads_norm = 3.0960
	sim_grads_norm_tr = 0.2679
-- Starting training on experience 286 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9361
	data_grads_norm = 2.4430
	new_data_grads_norm = 5.2634
	old_data_grads_norm = 3.7089
	sim_grads_norm_tr = -0.1148
-- Starting training on experience 287 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3042
	data_grads_norm = 3.8669
	new_data_grads_norm = 5.4244
	old_data_grads_norm = 3.5758
	sim_grads_norm_tr = 0.3073
-- Starting training on experience 288 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5394
	data_grads_norm = 3.9463
	new_data_grads_norm = 5.4196
	old_data_grads_norm = 4.2114
	sim_grads_norm_tr = 0.1402
-- Starting training on experience 289 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0756
	data_grads_norm = 2.7365
	new_data_grads_norm = 4.5427
	old_data_grads_norm = 3.1297
	sim_grads_norm_tr = -0.3476
-- Starting training on experience 290 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3620
	data_grads_norm = 4.5012
	new_data_grads_norm = 6.1773
	old_data_grads_norm = 4.0200
	sim_grads_norm_tr = 0.6370
-- Starting training on experience 291 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8503
	data_grads_norm = 1.9654
	new_data_grads_norm = 3.5549
	old_data_grads_norm = 3.8038
	sim_grads_norm_tr = -0.0528
-- Starting training on experience 292 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1842
	data_grads_norm = 4.9775
	new_data_grads_norm = 6.3660
	old_data_grads_norm = 4.6426
	sim_grads_norm_tr = 0.2276
-- Starting training on experience 293 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9730
	data_grads_norm = 2.7706
	new_data_grads_norm = 5.3404
	old_data_grads_norm = 3.2414
	sim_grads_norm_tr = -0.2194
-- Starting training on experience 294 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2125
	data_grads_norm = 3.1948
	new_data_grads_norm = 5.2038
	old_data_grads_norm = 3.8637
	sim_grads_norm_tr = -0.0181
-- Starting training on experience 295 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2636
	data_grads_norm = 3.1431
	new_data_grads_norm = 4.3450
	old_data_grads_norm = 4.0941
	sim_grads_norm_tr = -0.0619
-- Starting training on experience 296 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1583
	data_grads_norm = 3.5921
	new_data_grads_norm = 5.1626
	old_data_grads_norm = 2.9171
	sim_grads_norm_tr = 0.3326
-- Starting training on experience 297 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2600
	data_grads_norm = 3.5968
	new_data_grads_norm = 5.9648
	old_data_grads_norm = 3.0558
	sim_grads_norm_tr = 0.1946
-- Starting training on experience 298 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1325
	data_grads_norm = 3.8327
	new_data_grads_norm = 6.9732
	old_data_grads_norm = 5.8976
	sim_grads_norm_tr = -0.2076
-- Starting training on experience 299 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1962
	data_grads_norm = 3.7702
	new_data_grads_norm = 5.7079
	old_data_grads_norm = 4.7301
	sim_grads_norm_tr = 0.0858
-- Starting training on experience 300 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3689
	data_grads_norm = 3.7947
	new_data_grads_norm = 5.8218
	old_data_grads_norm = 3.0960
	sim_grads_norm_tr = 0.0405
-- Starting training on experience 301 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2356
	data_grads_norm = 3.9125
	new_data_grads_norm = 5.5208
	old_data_grads_norm = 5.9749
	sim_grads_norm_tr = -0.1050
-- Starting training on experience 302 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8317
	data_grads_norm = 4.8347
	new_data_grads_norm = 6.8670
	old_data_grads_norm = 4.7943
	sim_grads_norm_tr = 0.4266
-- Starting training on experience 303 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0218
	data_grads_norm = 2.4534
	new_data_grads_norm = 3.5670
	old_data_grads_norm = 3.8789
	sim_grads_norm_tr = -0.2102
-- Starting training on experience 304 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2417
	data_grads_norm = 3.8299
	new_data_grads_norm = 5.1746
	old_data_grads_norm = 3.9735
	sim_grads_norm_tr = 0.4142
-- Starting training on experience 305 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1558
	data_grads_norm = 3.1865
	new_data_grads_norm = 4.9146
	old_data_grads_norm = 4.0146
	sim_grads_norm_tr = -0.0883
-- Starting training on experience 306 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1298
	data_grads_norm = 3.8757
	new_data_grads_norm = 5.1762
	old_data_grads_norm = 5.5422
	sim_grads_norm_tr = 0.0624
-- Starting training on experience 307 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2008
	data_grads_norm = 3.4490
	new_data_grads_norm = 5.9699
	old_data_grads_norm = 2.3361
	sim_grads_norm_tr = 0.0556
-- Starting training on experience 308 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2430
	data_grads_norm = 3.0925
	new_data_grads_norm = 5.5380
	old_data_grads_norm = 3.1371
	sim_grads_norm_tr = -0.0113
-- Starting training on experience 309 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3260
	data_grads_norm = 4.3049
	new_data_grads_norm = 7.0663
	old_data_grads_norm = 3.2270
	sim_grads_norm_tr = 0.1271
-- Starting training on experience 310 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2898
	data_grads_norm = 3.7859
	new_data_grads_norm = 5.9085
	old_data_grads_norm = 3.3212
	sim_grads_norm_tr = 0.2250
-- Starting training on experience 311 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1030
	data_grads_norm = 3.5250
	new_data_grads_norm = 4.2740
	old_data_grads_norm = 3.6130
	sim_grads_norm_tr = 0.4538
-- Starting training on experience 312 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0915
	data_grads_norm = 2.8372
	new_data_grads_norm = 6.2609
	old_data_grads_norm = 3.2109
	sim_grads_norm_tr = -0.1370
-- Starting training on experience 313 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9779
	data_grads_norm = 2.5432
	new_data_grads_norm = 4.8951
	old_data_grads_norm = 2.6100
	sim_grads_norm_tr = -0.1927
-- Starting training on experience 314 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0344
	data_grads_norm = 3.0133
	new_data_grads_norm = 5.6466
	old_data_grads_norm = 3.4903
	sim_grads_norm_tr = -0.1327
-- Starting training on experience 315 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1856
	data_grads_norm = 4.4466
	new_data_grads_norm = 6.8345
	old_data_grads_norm = 5.5029
	sim_grads_norm_tr = 0.0765
-- Starting training on experience 316 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4097
	data_grads_norm = 3.0266
	new_data_grads_norm = 5.9252
	old_data_grads_norm = 3.1732
	sim_grads_norm_tr = -0.0522
-- Starting training on experience 317 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4048
	data_grads_norm = 3.5565
	new_data_grads_norm = 5.6829
	old_data_grads_norm = 3.5040
	sim_grads_norm_tr = 0.0980
-- Starting training on experience 318 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0816
	data_grads_norm = 2.4657
	new_data_grads_norm = 5.3297
	old_data_grads_norm = 2.8671
	sim_grads_norm_tr = -0.2493
-- Starting training on experience 319 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3971
	data_grads_norm = 4.5023
	new_data_grads_norm = 5.9053
	old_data_grads_norm = 5.5807
	sim_grads_norm_tr = 0.1993
-- Starting training on experience 320 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1909
	data_grads_norm = 3.6382
	new_data_grads_norm = 5.6158
	old_data_grads_norm = 3.5809
	sim_grads_norm_tr = 0.1851
-- Starting training on experience 321 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5142
	data_grads_norm = 3.1179
	new_data_grads_norm = 5.0953
	old_data_grads_norm = 3.9167
	sim_grads_norm_tr = -0.0957
-- Starting training on experience 322 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1626
	data_grads_norm = 3.0253
	new_data_grads_norm = 5.0407
	old_data_grads_norm = 4.3461
	sim_grads_norm_tr = -0.2707
-- Starting training on experience 323 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4513
	data_grads_norm = 3.8616
	new_data_grads_norm = 5.9354
	old_data_grads_norm = 4.1207
	sim_grads_norm_tr = -0.0763
-- Starting training on experience 324 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3519
	data_grads_norm = 3.9003
	new_data_grads_norm = 6.6799
	old_data_grads_norm = 3.3363
	sim_grads_norm_tr = 0.0007
-- Starting training on experience 325 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7581
	data_grads_norm = 4.5987
	new_data_grads_norm = 6.0127
	old_data_grads_norm = 3.7378
	sim_grads_norm_tr = 0.5139
-- Starting training on experience 326 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3253
	data_grads_norm = 3.6438
	new_data_grads_norm = 5.2140
	old_data_grads_norm = 4.3113
	sim_grads_norm_tr = 0.1593
-- Starting training on experience 327 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7288
	data_grads_norm = 4.8700
	new_data_grads_norm = 5.6679
	old_data_grads_norm = 6.1911
	sim_grads_norm_tr = 0.2938
-- Starting training on experience 328 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5429
	data_grads_norm = 3.7376
	new_data_grads_norm = 5.7422
	old_data_grads_norm = 4.3009
	sim_grads_norm_tr = -0.0397
-- Starting training on experience 329 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4807
	data_grads_norm = 3.9253
	new_data_grads_norm = 5.0514
	old_data_grads_norm = 5.0969
	sim_grads_norm_tr = 0.0940
-- Starting training on experience 330 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9898
	data_grads_norm = 3.0211
	new_data_grads_norm = 3.7310
	old_data_grads_norm = 3.3396
	sim_grads_norm_tr = 0.4550
-- Starting training on experience 331 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8644
	data_grads_norm = 1.7372
	new_data_grads_norm = 2.7144
	old_data_grads_norm = 2.6587
	sim_grads_norm_tr = -0.2406
-- Starting training on experience 332 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1232
	data_grads_norm = 2.4081
	new_data_grads_norm = 3.9039
	old_data_grads_norm = 4.1184
	sim_grads_norm_tr = -0.2892
-- Starting training on experience 333 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1006
	data_grads_norm = 3.0311
	new_data_grads_norm = 4.3153
	old_data_grads_norm = 4.6024
	sim_grads_norm_tr = -0.0560
-- Starting training on experience 334 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3537
	data_grads_norm = 3.0616
	new_data_grads_norm = 4.5764
	old_data_grads_norm = 3.1627
	sim_grads_norm_tr = 0.1434
-- Starting training on experience 335 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3494
	data_grads_norm = 3.3453
	new_data_grads_norm = 6.4439
	old_data_grads_norm = 3.4319
	sim_grads_norm_tr = -0.1398
-- Starting training on experience 336 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5276
	data_grads_norm = 4.7448
	new_data_grads_norm = 6.5570
	old_data_grads_norm = 3.7568
	sim_grads_norm_tr = 0.2488
-- Starting training on experience 337 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0847
	data_grads_norm = 2.3192
	new_data_grads_norm = 4.5134
	old_data_grads_norm = 3.8040
	sim_grads_norm_tr = -0.3955
-- Starting training on experience 338 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6078
	data_grads_norm = 4.2822
	new_data_grads_norm = 6.3482
	old_data_grads_norm = 4.0081
	sim_grads_norm_tr = 0.3616
-- Starting training on experience 339 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6899
	data_grads_norm = 4.0222
	new_data_grads_norm = 5.8347
	old_data_grads_norm = 4.7385
	sim_grads_norm_tr = -0.0878
-- Starting training on experience 340 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4254
	data_grads_norm = 3.7228
	new_data_grads_norm = 5.1908
	old_data_grads_norm = 4.3444
	sim_grads_norm_tr = 0.2342
-- Starting training on experience 341 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2353
	data_grads_norm = 2.8382
	new_data_grads_norm = 5.0048
	old_data_grads_norm = 3.2910
	sim_grads_norm_tr = -0.1238
-- Starting training on experience 342 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4007
	data_grads_norm = 3.7697
	new_data_grads_norm = 6.2532
	old_data_grads_norm = 3.3253
	sim_grads_norm_tr = -0.0170
-- Starting training on experience 343 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1725
	data_grads_norm = 3.3595
	new_data_grads_norm = 6.0284
	old_data_grads_norm = 3.1246
	sim_grads_norm_tr = 0.0696
-- Starting training on experience 344 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6798
	data_grads_norm = 3.9540
	new_data_grads_norm = 5.6394
	old_data_grads_norm = 4.3318
	sim_grads_norm_tr = 0.2514
-- Starting training on experience 345 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6830
	data_grads_norm = 3.3487
	new_data_grads_norm = 5.9463
	old_data_grads_norm = 3.3983
	sim_grads_norm_tr = 0.1405
-- Starting training on experience 346 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7152
	data_grads_norm = 4.1489
	new_data_grads_norm = 5.8229
	old_data_grads_norm = 3.8384
	sim_grads_norm_tr = 0.4987
-- Starting training on experience 347 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9140
	data_grads_norm = 2.1150
	new_data_grads_norm = 4.0785
	old_data_grads_norm = 2.5091
	sim_grads_norm_tr = -0.3342
-- Starting training on experience 348 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4585
	data_grads_norm = 3.3223
	new_data_grads_norm = 5.7557
	old_data_grads_norm = 3.5744
	sim_grads_norm_tr = 0.0019
-- Starting training on experience 349 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3041
	data_grads_norm = 2.7457
	new_data_grads_norm = 5.2416
	old_data_grads_norm = 3.1256
	sim_grads_norm_tr = -0.1562
-- Starting training on experience 350 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7485
	data_grads_norm = 5.0355
	new_data_grads_norm = 6.4338
	old_data_grads_norm = 5.0828
	sim_grads_norm_tr = 0.5282
-- Starting training on experience 351 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5424
	data_grads_norm = 3.3327
	new_data_grads_norm = 5.3951
	old_data_grads_norm = 3.0391
	sim_grads_norm_tr = 0.2342
-- Starting training on experience 352 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0978
	data_grads_norm = 3.4174
	new_data_grads_norm = 4.7425
	old_data_grads_norm = 4.5588
	sim_grads_norm_tr = 0.0647
-- Starting training on experience 353 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9784
	data_grads_norm = 2.1311
	new_data_grads_norm = 4.6268
	old_data_grads_norm = 2.7922
	sim_grads_norm_tr = -0.3978
-- Starting training on experience 354 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1366
	data_grads_norm = 2.8375
	new_data_grads_norm = 5.4414
	old_data_grads_norm = 2.5900
	sim_grads_norm_tr = -0.0830
-- Starting training on experience 355 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3123
	data_grads_norm = 2.8970
	new_data_grads_norm = 5.2597
	old_data_grads_norm = 2.8492
	sim_grads_norm_tr = -0.1605
-- Starting training on experience 356 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4573
	data_grads_norm = 3.5926
	new_data_grads_norm = 5.6554
	old_data_grads_norm = 3.4060
	sim_grads_norm_tr = 0.2149
-- Starting training on experience 357 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3880
	data_grads_norm = 3.1661
	new_data_grads_norm = 6.3046
	old_data_grads_norm = 3.8347
	sim_grads_norm_tr = -0.1073
-- Starting training on experience 358 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3115
	data_grads_norm = 3.4912
	new_data_grads_norm = 5.5808
	old_data_grads_norm = 3.9571
	sim_grads_norm_tr = -0.0397
-- Starting training on experience 359 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7036
	data_grads_norm = 4.4223
	new_data_grads_norm = 6.2045
	old_data_grads_norm = 4.1294
	sim_grads_norm_tr = 0.5387
-- Starting training on experience 360 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0614
	data_grads_norm = 2.5022
	new_data_grads_norm = 5.5687
	old_data_grads_norm = 2.9246
	sim_grads_norm_tr = -0.3066
-- Starting training on experience 361 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1059
	data_grads_norm = 2.6356
	new_data_grads_norm = 4.7763
	old_data_grads_norm = 2.3473
	sim_grads_norm_tr = -0.0292
-- Starting training on experience 362 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3356
	data_grads_norm = 3.8798
	new_data_grads_norm = 4.8891
	old_data_grads_norm = 3.9087
	sim_grads_norm_tr = 0.4407
-- Starting training on experience 363 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1384
	data_grads_norm = 3.3033
	new_data_grads_norm = 4.3859
	old_data_grads_norm = 4.1497
	sim_grads_norm_tr = -0.2673
-- Starting training on experience 364 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1925
	data_grads_norm = 3.3083
	new_data_grads_norm = 5.8359
	old_data_grads_norm = 2.9264
	sim_grads_norm_tr = 0.0671
-- Starting training on experience 365 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1906
	data_grads_norm = 2.9854
	new_data_grads_norm = 4.7245
	old_data_grads_norm = 4.4718
	sim_grads_norm_tr = -0.1431
-- Starting training on experience 366 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3724
	data_grads_norm = 3.5452
	new_data_grads_norm = 5.5928
	old_data_grads_norm = 3.6538
	sim_grads_norm_tr = 0.3528
-- Starting training on experience 367 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2755
	data_grads_norm = 3.8700
	new_data_grads_norm = 5.4552
	old_data_grads_norm = 3.9544
	sim_grads_norm_tr = 0.3203
-- Starting training on experience 368 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8335
	data_grads_norm = 3.1038
	new_data_grads_norm = 4.3424
	old_data_grads_norm = 3.7263
	sim_grads_norm_tr = -0.0354
-- Starting training on experience 369 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3633
	data_grads_norm = 4.3221
	new_data_grads_norm = 5.3647
	old_data_grads_norm = 5.7379
	sim_grads_norm_tr = -0.0875
-- Starting training on experience 370 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3643
	data_grads_norm = 3.3506
	new_data_grads_norm = 5.3129
	old_data_grads_norm = 3.1222
	sim_grads_norm_tr = 0.0693
-- Starting training on experience 371 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0794
	data_grads_norm = 3.0666
	new_data_grads_norm = 7.2743
	old_data_grads_norm = 3.3355
	sim_grads_norm_tr = -0.2574
-- Starting training on experience 372 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6293
	data_grads_norm = 4.0281
	new_data_grads_norm = 6.8877
	old_data_grads_norm = 4.7927
	sim_grads_norm_tr = -0.0871
-- Starting training on experience 373 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4939
	data_grads_norm = 3.0742
	new_data_grads_norm = 6.1048
	old_data_grads_norm = 3.0768
	sim_grads_norm_tr = 0.0827
-- Starting training on experience 374 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2558
	data_grads_norm = 4.0211
	new_data_grads_norm = 5.7129
	old_data_grads_norm = 3.6676
	sim_grads_norm_tr = 0.3223
-- Starting training on experience 375 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4190
	data_grads_norm = 2.9783
	new_data_grads_norm = 4.6689
	old_data_grads_norm = 4.3476
	sim_grads_norm_tr = -0.1398
-- Starting training on experience 376 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4389
	data_grads_norm = 3.6507
	new_data_grads_norm = 5.4307
	old_data_grads_norm = 3.3218
	sim_grads_norm_tr = 0.2390
-- Starting training on experience 377 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9078
	data_grads_norm = 2.7938
	new_data_grads_norm = 5.0816
	old_data_grads_norm = 2.3412
	sim_grads_norm_tr = -0.0542
-- Starting training on experience 378 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7119
	data_grads_norm = 3.7678
	new_data_grads_norm = 5.0774
	old_data_grads_norm = 5.0881
	sim_grads_norm_tr = 0.1403
-- Starting training on experience 379 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2652
	data_grads_norm = 4.0317
	new_data_grads_norm = 6.3331
	old_data_grads_norm = 3.6177
	sim_grads_norm_tr = 0.3176
-- Starting training on experience 380 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1680
	data_grads_norm = 3.4939
	new_data_grads_norm = 4.6817
	old_data_grads_norm = 4.8965
	sim_grads_norm_tr = 0.0738
-- Starting training on experience 381 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9933
	data_grads_norm = 2.5167
	new_data_grads_norm = 4.7602
	old_data_grads_norm = 2.1268
	sim_grads_norm_tr = 0.1936
-- Starting training on experience 382 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9345
	data_grads_norm = 2.7705
	new_data_grads_norm = 5.8269
	old_data_grads_norm = 3.3899
	sim_grads_norm_tr = 0.0359
-- Starting training on experience 383 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3917
	data_grads_norm = 4.1190
	new_data_grads_norm = 5.2881
	old_data_grads_norm = 4.2950
	sim_grads_norm_tr = 0.6061
-- Starting training on experience 384 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2943
	data_grads_norm = 3.1318
	new_data_grads_norm = 4.4575
	old_data_grads_norm = 4.6429
	sim_grads_norm_tr = -0.2938
-- Starting training on experience 385 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2329
	data_grads_norm = 2.7468
	new_data_grads_norm = 5.1618
	old_data_grads_norm = 3.0822
	sim_grads_norm_tr = -0.2602
-- Starting training on experience 386 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0396
	data_grads_norm = 2.3537
	new_data_grads_norm = 4.7351
	old_data_grads_norm = 3.1498
	sim_grads_norm_tr = -0.3557
-- Starting training on experience 387 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1639
	data_grads_norm = 3.1444
	new_data_grads_norm = 5.3042
	old_data_grads_norm = 2.7177
	sim_grads_norm_tr = 0.4179
-- Starting training on experience 388 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4738
	data_grads_norm = 3.7520
	new_data_grads_norm = 5.5926
	old_data_grads_norm = 3.8344
	sim_grads_norm_tr = 0.2916
-- Starting training on experience 389 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2250
	data_grads_norm = 2.9487
	new_data_grads_norm = 4.3197
	old_data_grads_norm = 4.9840
	sim_grads_norm_tr = -0.2731
-- Starting training on experience 390 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7167
	data_grads_norm = 4.0860
	new_data_grads_norm = 5.4367
	old_data_grads_norm = 4.4397
	sim_grads_norm_tr = 0.4926
-- Starting training on experience 391 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0495
	data_grads_norm = 2.4514
	new_data_grads_norm = 4.4789
	old_data_grads_norm = 3.2933
	sim_grads_norm_tr = -0.3719
-- Starting training on experience 392 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2990
	data_grads_norm = 3.4077
	new_data_grads_norm = 5.4201
	old_data_grads_norm = 3.6767
	sim_grads_norm_tr = 0.2900
-- Starting training on experience 393 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0125
	data_grads_norm = 2.6921
	new_data_grads_norm = 4.3096
	old_data_grads_norm = 3.6127
	sim_grads_norm_tr = -0.1497
-- Starting training on experience 394 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0197
	data_grads_norm = 2.2806
	new_data_grads_norm = 3.9942
	old_data_grads_norm = 3.2123
	sim_grads_norm_tr = -0.2310
-- Starting training on experience 395 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2448
	data_grads_norm = 3.2971
	new_data_grads_norm = 4.7583
	old_data_grads_norm = 3.4535
	sim_grads_norm_tr = 0.3649
-- Starting training on experience 396 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2449
	data_grads_norm = 3.7567
	new_data_grads_norm = 4.4346
	old_data_grads_norm = 3.6059
	sim_grads_norm_tr = 0.5201
-- Starting training on experience 397 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0856
	data_grads_norm = 2.4923
	new_data_grads_norm = 4.4760
	old_data_grads_norm = 4.1384
	sim_grads_norm_tr = -0.2417
-- Starting training on experience 398 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4400
	data_grads_norm = 4.0884
	new_data_grads_norm = 5.6930
	old_data_grads_norm = 4.3355
	sim_grads_norm_tr = 0.3227
-- Starting training on experience 399 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2498
	data_grads_norm = 3.0007
	new_data_grads_norm = 4.8819
	old_data_grads_norm = 2.9731
	sim_grads_norm_tr = 0.1232
-- Starting training on experience 400 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0411
	data_grads_norm = 2.4004
	new_data_grads_norm = 4.2369
	old_data_grads_norm = 2.6766
	sim_grads_norm_tr = -0.0928
-- Starting training on experience 401 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0794
	data_grads_norm = 2.7497
	new_data_grads_norm = 4.1856
	old_data_grads_norm = 3.2279
	sim_grads_norm_tr = 0.1580
-- Starting training on experience 402 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4209
	data_grads_norm = 3.5557
	new_data_grads_norm = 4.2898
	old_data_grads_norm = 5.7574
	sim_grads_norm_tr = -0.0007
-- Starting training on experience 403 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2033
	data_grads_norm = 2.7093
	new_data_grads_norm = 4.6973
	old_data_grads_norm = 2.3765
	sim_grads_norm_tr = 0.0083
-- Starting training on experience 404 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1149
	data_grads_norm = 4.2887
	new_data_grads_norm = 6.0252
	old_data_grads_norm = 3.7564
	sim_grads_norm_tr = 0.5390
-- Starting training on experience 405 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1340
	data_grads_norm = 2.5711
	new_data_grads_norm = 3.8932
	old_data_grads_norm = 5.0890
	sim_grads_norm_tr = -0.2230
-- Starting training on experience 406 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0618
	data_grads_norm = 3.0651
	new_data_grads_norm = 4.4514
	old_data_grads_norm = 3.0055
	sim_grads_norm_tr = 0.4199
-- Starting training on experience 407 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1066
	data_grads_norm = 2.8888
	new_data_grads_norm = 4.3023
	old_data_grads_norm = 4.0245
	sim_grads_norm_tr = -0.2814
-- Starting training on experience 408 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5459
	data_grads_norm = 4.4509
	new_data_grads_norm = 5.6992
	old_data_grads_norm = 6.6538
	sim_grads_norm_tr = 0.1498
-- Starting training on experience 409 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5311
	data_grads_norm = 3.4572
	new_data_grads_norm = 5.2820
	old_data_grads_norm = 3.9689
	sim_grads_norm_tr = -0.0492
-- Starting training on experience 410 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2276
	data_grads_norm = 3.3111
	new_data_grads_norm = 5.1877
	old_data_grads_norm = 4.1578
	sim_grads_norm_tr = 0.0764
-- Starting training on experience 411 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6856
	data_grads_norm = 4.6528
	new_data_grads_norm = 5.7677
	old_data_grads_norm = 5.4956
	sim_grads_norm_tr = 0.2950
-- Starting training on experience 412 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3057
	data_grads_norm = 3.4153
	new_data_grads_norm = 4.3724
	old_data_grads_norm = 4.9585
	sim_grads_norm_tr = -0.1308
-- Starting training on experience 413 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6339
	data_grads_norm = 3.7101
	new_data_grads_norm = 5.0822
	old_data_grads_norm = 4.8144
	sim_grads_norm_tr = 0.1973
-- Starting training on experience 414 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0849
	data_grads_norm = 2.3028
	new_data_grads_norm = 4.3939
	old_data_grads_norm = 2.4571
	sim_grads_norm_tr = -0.1574
-- Starting training on experience 415 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0670
	data_grads_norm = 2.6166
	new_data_grads_norm = 4.1956
	old_data_grads_norm = 3.4109
	sim_grads_norm_tr = -0.0144
-- Starting training on experience 416 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2422
	data_grads_norm = 3.2220
	new_data_grads_norm = 4.4136
	old_data_grads_norm = 3.9686
	sim_grads_norm_tr = 0.1551
-- Starting training on experience 417 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1397
	data_grads_norm = 2.8853
	new_data_grads_norm = 4.2031
	old_data_grads_norm = 3.5799
	sim_grads_norm_tr = 0.2042
-- Starting training on experience 418 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5963
	data_grads_norm = 3.6954
	new_data_grads_norm = 5.6138
	old_data_grads_norm = 4.1816
	sim_grads_norm_tr = 0.1295
-- Starting training on experience 419 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1519
	data_grads_norm = 3.0613
	new_data_grads_norm = 5.0969
	old_data_grads_norm = 3.5669
	sim_grads_norm_tr = -0.1269
-- Starting training on experience 420 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9796
	data_grads_norm = 2.7794
	new_data_grads_norm = 4.3317
	old_data_grads_norm = 2.9644
	sim_grads_norm_tr = 0.1397
-- Starting training on experience 421 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0450
	data_grads_norm = 2.3716
	new_data_grads_norm = 3.3161
	old_data_grads_norm = 4.1050
	sim_grads_norm_tr = -0.1773
-- Starting training on experience 422 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2073
	data_grads_norm = 3.1239
	new_data_grads_norm = 4.8263
	old_data_grads_norm = 3.1452
	sim_grads_norm_tr = 0.2206
-- Starting training on experience 423 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7806
	data_grads_norm = 2.2697
	new_data_grads_norm = 4.4330
	old_data_grads_norm = 2.9097
	sim_grads_norm_tr = -0.2129
-- Starting training on experience 424 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2521
	data_grads_norm = 2.9778
	new_data_grads_norm = 5.9156
	old_data_grads_norm = 3.7805
	sim_grads_norm_tr = -0.3541
-- Starting training on experience 425 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3486
	data_grads_norm = 3.3642
	new_data_grads_norm = 5.3251
	old_data_grads_norm = 3.7088
	sim_grads_norm_tr = 0.2245
-- Starting training on experience 426 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3961
	data_grads_norm = 3.6163
	new_data_grads_norm = 6.4039
	old_data_grads_norm = 3.4538
	sim_grads_norm_tr = 0.1770
-- Starting training on experience 427 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9128
	data_grads_norm = 3.9285
	new_data_grads_norm = 5.8618
	old_data_grads_norm = 4.6608
	sim_grads_norm_tr = 0.0212
-- Starting training on experience 428 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3947
	data_grads_norm = 2.9418
	new_data_grads_norm = 4.8252
	old_data_grads_norm = 3.4599
	sim_grads_norm_tr = -0.1076
-- Starting training on experience 429 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5242
	data_grads_norm = 2.9718
	new_data_grads_norm = 5.1242
	old_data_grads_norm = 2.5621
	sim_grads_norm_tr = 0.0573
-- Starting training on experience 430 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2299
	data_grads_norm = 3.1896
	new_data_grads_norm = 5.0367
	old_data_grads_norm = 4.4903
	sim_grads_norm_tr = 0.0584
-- Starting training on experience 431 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3108
	data_grads_norm = 3.2192
	new_data_grads_norm = 5.6766
	old_data_grads_norm = 3.1070
	sim_grads_norm_tr = -0.0146
-- Starting training on experience 432 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5820
	data_grads_norm = 3.8214
	new_data_grads_norm = 6.4819
	old_data_grads_norm = 3.9945
	sim_grads_norm_tr = 0.1948
-- Starting training on experience 433 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3764
	data_grads_norm = 3.3652
	new_data_grads_norm = 6.3070
	old_data_grads_norm = 2.3826
	sim_grads_norm_tr = -0.2552
-- Starting training on experience 434 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3280
	data_grads_norm = 3.7566
	new_data_grads_norm = 5.6628
	old_data_grads_norm = 3.7968
	sim_grads_norm_tr = 0.2643
-- Starting training on experience 435 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3384
	data_grads_norm = 3.0715
	new_data_grads_norm = 4.4454
	old_data_grads_norm = 4.1033
	sim_grads_norm_tr = -0.0567
-- Starting training on experience 436 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1168
	data_grads_norm = 2.8536
	new_data_grads_norm = 4.8537
	old_data_grads_norm = 2.8013
	sim_grads_norm_tr = 0.0050
-- Starting training on experience 437 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1615
	data_grads_norm = 3.8671
	new_data_grads_norm = 5.0786
	old_data_grads_norm = 4.1972
	sim_grads_norm_tr = 0.5438
-- Starting training on experience 438 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1715
	data_grads_norm = 2.7818
	new_data_grads_norm = 4.2149
	old_data_grads_norm = 3.8405
	sim_grads_norm_tr = -0.1115
-- Starting training on experience 439 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2982
	data_grads_norm = 3.3678
	new_data_grads_norm = 5.6621
	old_data_grads_norm = 3.8664
	sim_grads_norm_tr = -0.0410
-- Starting training on experience 440 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2824
	data_grads_norm = 3.8552
	new_data_grads_norm = 4.8237
	old_data_grads_norm = 5.0526
	sim_grads_norm_tr = 0.1174
-- Starting training on experience 441 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0325
	data_grads_norm = 2.9369
	new_data_grads_norm = 5.0105
	old_data_grads_norm = 3.5157
	sim_grads_norm_tr = -0.0177
-- Starting training on experience 442 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1315
	data_grads_norm = 2.9911
	new_data_grads_norm = 4.6930
	old_data_grads_norm = 3.9474
	sim_grads_norm_tr = -0.0554
-- Starting training on experience 443 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0412
	data_grads_norm = 2.7315
	new_data_grads_norm = 4.5383
	old_data_grads_norm = 3.2433
	sim_grads_norm_tr = 0.0299
-- Starting training on experience 444 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1079
	data_grads_norm = 2.5038
	new_data_grads_norm = 4.9367
	old_data_grads_norm = 4.5215
	sim_grads_norm_tr = -0.1022
-- Starting training on experience 445 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8919
	data_grads_norm = 4.1315
	new_data_grads_norm = 5.9533
	old_data_grads_norm = 3.8718
	sim_grads_norm_tr = 0.3043
-- Starting training on experience 446 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2263
	data_grads_norm = 3.4874
	new_data_grads_norm = 6.2033
	old_data_grads_norm = 3.1248
	sim_grads_norm_tr = -0.1337
-- Starting training on experience 447 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4014
	data_grads_norm = 4.0791
	new_data_grads_norm = 5.7388
	old_data_grads_norm = 5.3850
	sim_grads_norm_tr = 0.1755
-- Starting training on experience 448 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0295
	data_grads_norm = 2.9518
	new_data_grads_norm = 4.6428
	old_data_grads_norm = 3.1706
	sim_grads_norm_tr = 0.1340
-- Starting training on experience 449 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5556
	data_grads_norm = 4.2737
	new_data_grads_norm = 5.2550
	old_data_grads_norm = 4.6111
	sim_grads_norm_tr = 0.3613
-- Starting training on experience 450 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0277
	data_grads_norm = 2.3079
	new_data_grads_norm = 4.0930
	old_data_grads_norm = 3.1040
	sim_grads_norm_tr = -0.1835
-- Starting training on experience 451 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9514
	data_grads_norm = 2.6972
	new_data_grads_norm = 4.8209
	old_data_grads_norm = 2.9057
	sim_grads_norm_tr = -0.3504
-- Starting training on experience 452 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2374
	data_grads_norm = 3.8995
	new_data_grads_norm = 5.1391
	old_data_grads_norm = 3.6679
	sim_grads_norm_tr = 0.5783
-- Starting training on experience 453 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8340
	data_grads_norm = 1.9615
	new_data_grads_norm = 3.3780
	old_data_grads_norm = 3.8308
	sim_grads_norm_tr = -0.4100
-- Starting training on experience 454 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3527
	data_grads_norm = 3.3441
	new_data_grads_norm = 5.4873
	old_data_grads_norm = 3.7349
	sim_grads_norm_tr = 0.0290
-- Starting training on experience 455 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1213
	data_grads_norm = 3.5200
	new_data_grads_norm = 6.5372
	old_data_grads_norm = 2.9075
	sim_grads_norm_tr = 0.3961
-- Starting training on experience 456 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2915
	data_grads_norm = 3.6690
	new_data_grads_norm = 5.9880
	old_data_grads_norm = 4.0054
	sim_grads_norm_tr = 0.0719
-- Starting training on experience 457 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9456
	data_grads_norm = 2.8993
	new_data_grads_norm = 4.8071
	old_data_grads_norm = 3.2061
	sim_grads_norm_tr = 0.0869
-- Starting training on experience 458 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1513
	data_grads_norm = 3.2865
	new_data_grads_norm = 4.8239
	old_data_grads_norm = 4.2002
	sim_grads_norm_tr = 0.0558
-- Starting training on experience 459 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4678
	data_grads_norm = 3.7229
	new_data_grads_norm = 6.0740
	old_data_grads_norm = 3.4394
	sim_grads_norm_tr = -0.1823
-- Starting training on experience 460 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3777
	data_grads_norm = 4.1900
	new_data_grads_norm = 6.2899
	old_data_grads_norm = 3.6271
	sim_grads_norm_tr = 0.0922
-- Starting training on experience 461 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1885
	data_grads_norm = 3.1971
	new_data_grads_norm = 5.4020
	old_data_grads_norm = 3.3718
	sim_grads_norm_tr = -0.0721
-- Starting training on experience 462 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4263
	data_grads_norm = 3.8794
	new_data_grads_norm = 5.1049
	old_data_grads_norm = 4.5580
	sim_grads_norm_tr = 0.2382
-- Starting training on experience 463 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2650
	data_grads_norm = 3.0395
	new_data_grads_norm = 4.6518
	old_data_grads_norm = 3.1618
	sim_grads_norm_tr = 0.2980
-- Starting training on experience 464 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8797
	data_grads_norm = 2.7487
	new_data_grads_norm = 4.4326
	old_data_grads_norm = 2.6934
	sim_grads_norm_tr = 0.2264
-- Starting training on experience 465 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1339
	data_grads_norm = 2.7841
	new_data_grads_norm = 4.2162
	old_data_grads_norm = 2.6787
	sim_grads_norm_tr = 0.0882
-- Starting training on experience 466 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1406
	data_grads_norm = 2.7475
	new_data_grads_norm = 3.5675
	old_data_grads_norm = 4.4739
	sim_grads_norm_tr = -0.0566
-- Starting training on experience 467 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2600
	data_grads_norm = 2.0960
	new_data_grads_norm = 3.9506
	old_data_grads_norm = 3.5963
	sim_grads_norm_tr = -0.3977
-- Starting training on experience 468 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9680
	data_grads_norm = 3.0537
	new_data_grads_norm = 5.7660
	old_data_grads_norm = 3.1432
	sim_grads_norm_tr = -0.0312
-- Starting training on experience 469 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6285
	data_grads_norm = 3.5764
	new_data_grads_norm = 5.7360
	old_data_grads_norm = 3.5114
	sim_grads_norm_tr = 0.1021
-- Starting training on experience 470 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1626
	data_grads_norm = 2.9692
	new_data_grads_norm = 4.6018
	old_data_grads_norm = 3.7250
	sim_grads_norm_tr = 0.2031
-- Starting training on experience 471 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1474
	data_grads_norm = 3.3635
	new_data_grads_norm = 4.7488
	old_data_grads_norm = 3.4588
	sim_grads_norm_tr = 0.3681
-- Starting training on experience 472 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1064
	data_grads_norm = 3.0071
	new_data_grads_norm = 3.8861
	old_data_grads_norm = 4.4040
	sim_grads_norm_tr = -0.3650
-- Starting training on experience 473 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5457
	data_grads_norm = 4.3683
	new_data_grads_norm = 5.8836
	old_data_grads_norm = 3.9127
	sim_grads_norm_tr = 0.2680
-- Starting training on experience 474 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3190
	data_grads_norm = 3.6389
	new_data_grads_norm = 5.0867
	old_data_grads_norm = 3.5744
	sim_grads_norm_tr = 0.3813
-- Starting training on experience 475 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1942
	data_grads_norm = 2.4730
	new_data_grads_norm = 4.4677
	old_data_grads_norm = 2.6926
	sim_grads_norm_tr = -0.2677
-- Starting training on experience 476 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1193
	data_grads_norm = 2.5383
	new_data_grads_norm = 4.3430
	old_data_grads_norm = 3.9037
	sim_grads_norm_tr = -0.1506
-- Starting training on experience 477 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3060
	data_grads_norm = 3.3517
	new_data_grads_norm = 5.2886
	old_data_grads_norm = 3.4923
	sim_grads_norm_tr = 0.0270
-- Starting training on experience 478 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1697
	data_grads_norm = 2.7722
	new_data_grads_norm = 4.4385
	old_data_grads_norm = 3.5002
	sim_grads_norm_tr = -0.2492
-- Starting training on experience 479 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3262
	data_grads_norm = 3.2323
	new_data_grads_norm = 5.2681
	old_data_grads_norm = 2.7905
	sim_grads_norm_tr = 0.0553
-- Starting training on experience 480 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2692
	data_grads_norm = 3.2055
	new_data_grads_norm = 5.6414
	old_data_grads_norm = 3.5891
	sim_grads_norm_tr = 0.1426
-- Starting training on experience 481 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6145
	data_grads_norm = 4.2009
	new_data_grads_norm = 5.6852
	old_data_grads_norm = 4.2074
	sim_grads_norm_tr = 0.5486
-- Starting training on experience 482 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0148
	data_grads_norm = 2.3303
	new_data_grads_norm = 4.3766
	old_data_grads_norm = 2.7704
	sim_grads_norm_tr = -0.2047
-- Starting training on experience 483 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2047
	data_grads_norm = 3.2702
	new_data_grads_norm = 4.2680
	old_data_grads_norm = 4.2029
	sim_grads_norm_tr = 0.1981
-- Starting training on experience 484 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6086
	data_grads_norm = 3.6064
	new_data_grads_norm = 4.7743
	old_data_grads_norm = 4.1426
	sim_grads_norm_tr = 0.1791
-- Starting training on experience 485 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1295
	data_grads_norm = 2.8345
	new_data_grads_norm = 4.2706
	old_data_grads_norm = 2.8517
	sim_grads_norm_tr = 0.1866
-- Starting training on experience 486 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2856
	data_grads_norm = 3.2033
	new_data_grads_norm = 5.5543
	old_data_grads_norm = 2.4677
	sim_grads_norm_tr = 0.2216
-- Starting training on experience 487 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0413
	data_grads_norm = 2.4302
	new_data_grads_norm = 4.9274
	old_data_grads_norm = 2.8622
	sim_grads_norm_tr = -0.2837
-- Starting training on experience 488 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5025
	data_grads_norm = 2.8788
	new_data_grads_norm = 4.8035
	old_data_grads_norm = 3.7009
	sim_grads_norm_tr = -0.2212
-- Starting training on experience 489 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3929
	data_grads_norm = 4.1335
	new_data_grads_norm = 5.0516
	old_data_grads_norm = 4.4794
	sim_grads_norm_tr = 0.5059
-- Starting training on experience 490 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4058
	data_grads_norm = 3.0244
	new_data_grads_norm = 4.1423
	old_data_grads_norm = 5.0181
	sim_grads_norm_tr = -0.1826
-- Starting training on experience 491 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1938
	data_grads_norm = 3.2448
	new_data_grads_norm = 5.4009
	old_data_grads_norm = 2.8051
	sim_grads_norm_tr = 0.2313
-- Starting training on experience 492 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3240
	data_grads_norm = 3.8139
	new_data_grads_norm = 5.2608
	old_data_grads_norm = 3.5938
	sim_grads_norm_tr = 0.1747
-- Starting training on experience 493 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2928
	data_grads_norm = 4.0636
	new_data_grads_norm = 4.9419
	old_data_grads_norm = 4.5350
	sim_grads_norm_tr = 0.4860
-- Starting training on experience 494 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3564
	data_grads_norm = 3.5410
	new_data_grads_norm = 3.2919
	old_data_grads_norm = 6.5151
	sim_grads_norm_tr = -0.1832
-- Starting training on experience 495 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3754
	data_grads_norm = 3.7001
	new_data_grads_norm = 5.5692
	old_data_grads_norm = 4.0649
	sim_grads_norm_tr = 0.3886
-- Starting training on experience 496 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2991
	data_grads_norm = 2.9406
	new_data_grads_norm = 4.1292
	old_data_grads_norm = 4.4180
	sim_grads_norm_tr = -0.1342
-- Starting training on experience 497 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0898
	data_grads_norm = 2.4606
	new_data_grads_norm = 4.5380
	old_data_grads_norm = 3.2940
	sim_grads_norm_tr = -0.2540
-- Starting training on experience 498 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1015
	data_grads_norm = 3.1116
	new_data_grads_norm = 4.8237
	old_data_grads_norm = 2.9587
	sim_grads_norm_tr = -0.0537
-- Starting training on experience 499 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9194
	data_grads_norm = 2.7962
	new_data_grads_norm = 4.5407
	old_data_grads_norm = 3.0848
	sim_grads_norm_tr = -0.2069
-- Starting training on experience 500 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3671
	data_grads_norm = 3.7840
	new_data_grads_norm = 5.5823
	old_data_grads_norm = 3.5103
	sim_grads_norm_tr = 0.2020
-- Starting training on experience 501 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8549
	data_grads_norm = 4.7271
	new_data_grads_norm = 6.6648
	old_data_grads_norm = 5.1218
	sim_grads_norm_tr = 0.1978
-- Starting training on experience 502 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6792
	data_grads_norm = 3.3019
	new_data_grads_norm = 4.8373
	old_data_grads_norm = 3.7307
	sim_grads_norm_tr = 0.0324
-- Starting training on experience 503 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3044
	data_grads_norm = 3.2295
	new_data_grads_norm = 4.5388
	old_data_grads_norm = 4.5248
	sim_grads_norm_tr = 0.0481
-- Starting training on experience 504 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2228
	data_grads_norm = 2.6987
	new_data_grads_norm = 4.5474
	old_data_grads_norm = 2.8070
	sim_grads_norm_tr = 0.1738
-- Starting training on experience 505 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3230
	data_grads_norm = 3.2266
	new_data_grads_norm = 4.9985
	old_data_grads_norm = 2.6490
	sim_grads_norm_tr = 0.3520
-- Starting training on experience 506 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4410
	data_grads_norm = 3.0009
	new_data_grads_norm = 4.2041
	old_data_grads_norm = 3.8295
	sim_grads_norm_tr = -0.0163
-- Starting training on experience 507 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4037
	data_grads_norm = 2.9042
	new_data_grads_norm = 4.1914
	old_data_grads_norm = 4.0580
	sim_grads_norm_tr = -0.0225
-- Starting training on experience 508 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2997
	data_grads_norm = 3.9856
	new_data_grads_norm = 4.9174
	old_data_grads_norm = 3.3715
	sim_grads_norm_tr = 0.7231
-- Starting training on experience 509 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9048
	data_grads_norm = 2.0317
	new_data_grads_norm = 3.6996
	old_data_grads_norm = 3.2073
	sim_grads_norm_tr = -0.2535
-- Starting training on experience 510 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2307
	data_grads_norm = 3.7884
	new_data_grads_norm = 4.2770
	old_data_grads_norm = 5.5341
	sim_grads_norm_tr = 0.0296
-- Starting training on experience 511 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4955
	data_grads_norm = 3.5621
	new_data_grads_norm = 6.0975
	old_data_grads_norm = 2.7808
	sim_grads_norm_tr = -0.0014
-- Starting training on experience 512 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2847
	data_grads_norm = 3.0652
	new_data_grads_norm = 5.8527
	old_data_grads_norm = 2.7743
	sim_grads_norm_tr = -0.0188
-- Starting training on experience 513 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9030
	data_grads_norm = 4.5356
	new_data_grads_norm = 5.3343
	old_data_grads_norm = 5.3496
	sim_grads_norm_tr = 0.4319
-- Starting training on experience 514 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3807
	data_grads_norm = 4.0274
	new_data_grads_norm = 5.0033
	old_data_grads_norm = 4.8561
	sim_grads_norm_tr = 0.0435
-- Starting training on experience 515 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2247
	data_grads_norm = 3.1907
	new_data_grads_norm = 5.2149
	old_data_grads_norm = 3.8888
	sim_grads_norm_tr = -0.0569
-- Starting training on experience 516 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1191
	data_grads_norm = 2.9823
	new_data_grads_norm = 5.5433
	old_data_grads_norm = 2.3721
	sim_grads_norm_tr = 0.1427
-- Starting training on experience 517 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2864
	data_grads_norm = 3.2610
	new_data_grads_norm = 5.5166
	old_data_grads_norm = 2.7272
	sim_grads_norm_tr = 0.2488
-- Starting training on experience 518 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1336
	data_grads_norm = 2.9857
	new_data_grads_norm = 4.8081
	old_data_grads_norm = 3.7200
	sim_grads_norm_tr = 0.0757
-- Starting training on experience 519 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5064
	data_grads_norm = 3.0297
	new_data_grads_norm = 5.3397
	old_data_grads_norm = 2.8485
	sim_grads_norm_tr = -0.0486
-- Starting training on experience 520 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4366
	data_grads_norm = 3.0730
	new_data_grads_norm = 4.6562
	old_data_grads_norm = 2.7365
	sim_grads_norm_tr = 0.1324
-- Starting training on experience 521 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0778
	data_grads_norm = 2.3265
	new_data_grads_norm = 5.1439
	old_data_grads_norm = 2.3981
	sim_grads_norm_tr = -0.0247
-- Starting training on experience 522 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2774
	data_grads_norm = 2.9186
	new_data_grads_norm = 4.7982
	old_data_grads_norm = 3.0424
	sim_grads_norm_tr = 0.0099
-- Starting training on experience 523 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2865
	data_grads_norm = 3.1602
	new_data_grads_norm = 4.6527
	old_data_grads_norm = 4.2437
	sim_grads_norm_tr = -0.1464
-- Starting training on experience 524 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2531
	data_grads_norm = 3.6045
	new_data_grads_norm = 4.3167
	old_data_grads_norm = 3.9319
	sim_grads_norm_tr = 0.3760
-- Starting training on experience 525 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.6928
	data_grads_norm = 2.4010
	new_data_grads_norm = 4.4531
	old_data_grads_norm = 2.7113
	sim_grads_norm_tr = -0.2403
-- Starting training on experience 526 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5245
	data_grads_norm = 3.4333
	new_data_grads_norm = 5.1156
	old_data_grads_norm = 4.4411
	sim_grads_norm_tr = 0.0453
-- Starting training on experience 527 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9811
	data_grads_norm = 3.1191
	new_data_grads_norm = 5.4187
	old_data_grads_norm = 2.5198
	sim_grads_norm_tr = -0.3015
-- Starting training on experience 528 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7097
	data_grads_norm = 3.6297
	new_data_grads_norm = 5.3983
	old_data_grads_norm = 3.2262
	sim_grads_norm_tr = 0.0351
-- Starting training on experience 529 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9867
	data_grads_norm = 4.0229
	new_data_grads_norm = 6.0372
	old_data_grads_norm = 4.3510
	sim_grads_norm_tr = 0.1634
-- Starting training on experience 530 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4795
	data_grads_norm = 3.4385
	new_data_grads_norm = 5.7439
	old_data_grads_norm = 3.6977
	sim_grads_norm_tr = 0.1565
-- Starting training on experience 531 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4308
	data_grads_norm = 4.1149
	new_data_grads_norm = 6.0978
	old_data_grads_norm = 3.2077
	sim_grads_norm_tr = 0.1770
-- Starting training on experience 532 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4895
	data_grads_norm = 3.5662
	new_data_grads_norm = 5.2009
	old_data_grads_norm = 4.2046
	sim_grads_norm_tr = 0.0893
-- Starting training on experience 533 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4509
	data_grads_norm = 3.5388
	new_data_grads_norm = 5.3000
	old_data_grads_norm = 3.9372
	sim_grads_norm_tr = 0.1752
-- Starting training on experience 534 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9306
	data_grads_norm = 2.8260
	new_data_grads_norm = 5.3631
	old_data_grads_norm = 3.3774
	sim_grads_norm_tr = -0.1153
-- Starting training on experience 535 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6517
	data_grads_norm = 4.5430
	new_data_grads_norm = 5.2375
	old_data_grads_norm = 5.4885
	sim_grads_norm_tr = 0.1570
-- Starting training on experience 536 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7576
	data_grads_norm = 4.0982
	new_data_grads_norm = 5.6424
	old_data_grads_norm = 5.5103
	sim_grads_norm_tr = 0.0036
-- Starting training on experience 537 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8123
	data_grads_norm = 2.6642
	new_data_grads_norm = 4.4298
	old_data_grads_norm = 2.6872
	sim_grads_norm_tr = 0.1266
-- Starting training on experience 538 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0952
	data_grads_norm = 3.1822
	new_data_grads_norm = 4.9143
	old_data_grads_norm = 3.0801
	sim_grads_norm_tr = 0.1810
-- Starting training on experience 539 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0028
	data_grads_norm = 2.4579
	new_data_grads_norm = 4.3169
	old_data_grads_norm = 2.2159
	sim_grads_norm_tr = 0.1690
-- Starting training on experience 540 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1122
	data_grads_norm = 4.0184
	new_data_grads_norm = 4.8634
	old_data_grads_norm = 4.4033
	sim_grads_norm_tr = 0.3646
-- Starting training on experience 541 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7575
	data_grads_norm = 2.1526
	new_data_grads_norm = 4.0768
	old_data_grads_norm = 3.1137
	sim_grads_norm_tr = -0.2108
-- Starting training on experience 542 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0741
	data_grads_norm = 2.1044
	new_data_grads_norm = 3.9774
	old_data_grads_norm = 2.7506
	sim_grads_norm_tr = -0.2605
-- Starting training on experience 543 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1570
	data_grads_norm = 2.8371
	new_data_grads_norm = 4.8054
	old_data_grads_norm = 4.5458
	sim_grads_norm_tr = -0.2444
-- Starting training on experience 544 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7054
	data_grads_norm = 4.2548
	new_data_grads_norm = 5.9818
	old_data_grads_norm = 4.3239
	sim_grads_norm_tr = 0.0577
-- Starting training on experience 545 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4878
	data_grads_norm = 3.9047
	new_data_grads_norm = 5.5091
	old_data_grads_norm = 3.6335
	sim_grads_norm_tr = 0.4218
-- Starting training on experience 546 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0871
	data_grads_norm = 3.2298
	new_data_grads_norm = 4.8976
	old_data_grads_norm = 4.1224
	sim_grads_norm_tr = 0.2075
-- Starting training on experience 547 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9607
	data_grads_norm = 2.5813
	new_data_grads_norm = 4.2340
	old_data_grads_norm = 3.7940
	sim_grads_norm_tr = -0.3106
-- Starting training on experience 548 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3416
	data_grads_norm = 4.0732
	new_data_grads_norm = 5.8525
	old_data_grads_norm = 4.2056
	sim_grads_norm_tr = 0.1811
-- Starting training on experience 549 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1897
	data_grads_norm = 4.1700
	new_data_grads_norm = 5.4871
	old_data_grads_norm = 4.0138
	sim_grads_norm_tr = 0.4667
-- Starting training on experience 550 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3489
	data_grads_norm = 3.6245
	new_data_grads_norm = 4.5785
	old_data_grads_norm = 4.1204
	sim_grads_norm_tr = 0.1818
-- Starting training on experience 551 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1398
	data_grads_norm = 2.9188
	new_data_grads_norm = 4.8739
	old_data_grads_norm = 4.6897
	sim_grads_norm_tr = -0.2887
-- Starting training on experience 552 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5264
	data_grads_norm = 3.9976
	new_data_grads_norm = 5.9278
	old_data_grads_norm = 4.0466
	sim_grads_norm_tr = 0.3374
-- Starting training on experience 553 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5074
	data_grads_norm = 3.4023
	new_data_grads_norm = 5.4625
	old_data_grads_norm = 3.7870
	sim_grads_norm_tr = 0.0419
-- Starting training on experience 554 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8134
	data_grads_norm = 2.0443
	new_data_grads_norm = 4.3914
	old_data_grads_norm = 2.2818
	sim_grads_norm_tr = -0.0846
-- Starting training on experience 555 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5907
	data_grads_norm = 3.8217
	new_data_grads_norm = 6.4000
	old_data_grads_norm = 4.0027
	sim_grads_norm_tr = -0.0394
-- Starting training on experience 556 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2602
	data_grads_norm = 3.4225
	new_data_grads_norm = 4.5631
	old_data_grads_norm = 4.2688
	sim_grads_norm_tr = 0.1074
-- Starting training on experience 557 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6492
	data_grads_norm = 4.8560
	new_data_grads_norm = 5.1747
	old_data_grads_norm = 6.9227
	sim_grads_norm_tr = 0.1006
-- Starting training on experience 558 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7255
	data_grads_norm = 4.5846
	new_data_grads_norm = 6.2916
	old_data_grads_norm = 3.9961
	sim_grads_norm_tr = 0.4655
-- Starting training on experience 559 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0864
	data_grads_norm = 2.0853
	new_data_grads_norm = 4.0366
	old_data_grads_norm = 3.4624
	sim_grads_norm_tr = -0.3318
-- Starting training on experience 560 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3715
	data_grads_norm = 2.9676
	new_data_grads_norm = 4.9537
	old_data_grads_norm = 2.9425
	sim_grads_norm_tr = 0.0487
-- Starting training on experience 561 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2822
	data_grads_norm = 2.6903
	new_data_grads_norm = 4.7198
	old_data_grads_norm = 2.9118
	sim_grads_norm_tr = 0.0137
-- Starting training on experience 562 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2954
	data_grads_norm = 3.5891
	new_data_grads_norm = 4.6899
	old_data_grads_norm = 5.1639
	sim_grads_norm_tr = 0.0847
-- Starting training on experience 563 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1430
	data_grads_norm = 3.0321
	new_data_grads_norm = 4.9940
	old_data_grads_norm = 2.3504
	sim_grads_norm_tr = 0.2641
-- Starting training on experience 564 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0684
	data_grads_norm = 3.4095
	new_data_grads_norm = 5.1647
	old_data_grads_norm = 3.7217
	sim_grads_norm_tr = 0.0320
-- Starting training on experience 565 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0834
	data_grads_norm = 2.6880
	new_data_grads_norm = 4.6766
	old_data_grads_norm = 3.1678
	sim_grads_norm_tr = -0.3259
-- Starting training on experience 566 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0259
	data_grads_norm = 3.1314
	new_data_grads_norm = 4.8272
	old_data_grads_norm = 3.1743
	sim_grads_norm_tr = -0.0143
-- Starting training on experience 567 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7010
	data_grads_norm = 4.2539
	new_data_grads_norm = 5.5454
	old_data_grads_norm = 4.0321
	sim_grads_norm_tr = 0.6151
-- Starting training on experience 568 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2021
	data_grads_norm = 3.3208
	new_data_grads_norm = 4.0719
	old_data_grads_norm = 4.9184
	sim_grads_norm_tr = 0.0584
-- Starting training on experience 569 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3374
	data_grads_norm = 3.3499
	new_data_grads_norm = 5.3125
	old_data_grads_norm = 4.6655
	sim_grads_norm_tr = -0.0408
-- Starting training on experience 570 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2063
	data_grads_norm = 3.2317
	new_data_grads_norm = 5.1715
	old_data_grads_norm = 3.1930
	sim_grads_norm_tr = 0.0929
-- Starting training on experience 571 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4569
	data_grads_norm = 3.4804
	new_data_grads_norm = 6.4304
	old_data_grads_norm = 3.4934
	sim_grads_norm_tr = 0.0482
-- Starting training on experience 572 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0922
	data_grads_norm = 2.6177
	new_data_grads_norm = 4.3620
	old_data_grads_norm = 3.9011
	sim_grads_norm_tr = -0.2699
-- Starting training on experience 573 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4972
	data_grads_norm = 3.7172
	new_data_grads_norm = 5.2665
	old_data_grads_norm = 4.1548
	sim_grads_norm_tr = 0.2649
-- Starting training on experience 574 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0659
	data_grads_norm = 2.5288
	new_data_grads_norm = 5.2542
	old_data_grads_norm = 2.7022
	sim_grads_norm_tr = -0.2490
-- Starting training on experience 575 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2791
	data_grads_norm = 2.9762
	new_data_grads_norm = 5.4558
	old_data_grads_norm = 3.2107
	sim_grads_norm_tr = -0.3119
-- Starting training on experience 576 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7576
	data_grads_norm = 4.3564
	new_data_grads_norm = 5.6738
	old_data_grads_norm = 4.1836
	sim_grads_norm_tr = 0.6269
-- Starting training on experience 577 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2268
	data_grads_norm = 3.4120
	new_data_grads_norm = 5.3374
	old_data_grads_norm = 3.1712
	sim_grads_norm_tr = 0.2047
-- Starting training on experience 578 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9577
	data_grads_norm = 2.6621
	new_data_grads_norm = 4.6881
	old_data_grads_norm = 3.5460
	sim_grads_norm_tr = -0.1274
-- Starting training on experience 579 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2013
	data_grads_norm = 2.5587
	new_data_grads_norm = 4.2522
	old_data_grads_norm = 2.7603
	sim_grads_norm_tr = -0.2261
-- Starting training on experience 580 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0542
	data_grads_norm = 2.4455
	new_data_grads_norm = 4.5220
	old_data_grads_norm = 2.4883
	sim_grads_norm_tr = -0.3427
-- Starting training on experience 581 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5166
	data_grads_norm = 4.1086
	new_data_grads_norm = 5.8395
	old_data_grads_norm = 3.6629
	sim_grads_norm_tr = 0.4514
-- Starting training on experience 582 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2230
	data_grads_norm = 3.0853
	new_data_grads_norm = 4.4011
	old_data_grads_norm = 4.2784
	sim_grads_norm_tr = -0.0503
-- Starting training on experience 583 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2336
	data_grads_norm = 3.0673
	new_data_grads_norm = 4.5592
	old_data_grads_norm = 3.1615
	sim_grads_norm_tr = 0.1580
-- Starting training on experience 584 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9901
	data_grads_norm = 2.6041
	new_data_grads_norm = 4.0528
	old_data_grads_norm = 3.1730
	sim_grads_norm_tr = -0.1043
-- Starting training on experience 585 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3271
	data_grads_norm = 3.2873
	new_data_grads_norm = 4.9237
	old_data_grads_norm = 3.6510
	sim_grads_norm_tr = 0.2811
-- Starting training on experience 586 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7528
	data_grads_norm = 1.7250
	new_data_grads_norm = 4.6814
	old_data_grads_norm = 1.9473
	sim_grads_norm_tr = -0.5291
-- Starting training on experience 587 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0264
	data_grads_norm = 3.0521
	new_data_grads_norm = 4.6276
	old_data_grads_norm = 3.4928
	sim_grads_norm_tr = 0.2561
-- Starting training on experience 588 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4674
	data_grads_norm = 4.4348
	new_data_grads_norm = 6.8625
	old_data_grads_norm = 3.9928
	sim_grads_norm_tr = 0.2335
-- Starting training on experience 589 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1100
	data_grads_norm = 3.0245
	new_data_grads_norm = 4.2814
	old_data_grads_norm = 3.5492
	sim_grads_norm_tr = 0.0709
-- Starting training on experience 590 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1848
	data_grads_norm = 3.4041
	new_data_grads_norm = 5.1303
	old_data_grads_norm = 3.1457
	sim_grads_norm_tr = 0.4141
-- Starting training on experience 591 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7860
	data_grads_norm = 2.1677
	new_data_grads_norm = 4.1334
	old_data_grads_norm = 2.8595
	sim_grads_norm_tr = -0.2044
-- Starting training on experience 592 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8309
	data_grads_norm = 2.3800
	new_data_grads_norm = 4.5656
	old_data_grads_norm = 2.7693
	sim_grads_norm_tr = -0.2097
-- Starting training on experience 593 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0858
	data_grads_norm = 3.1008
	new_data_grads_norm = 4.4288
	old_data_grads_norm = 4.3482
	sim_grads_norm_tr = 0.0061
-- Starting training on experience 594 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0454
	data_grads_norm = 2.4228
	new_data_grads_norm = 5.0686
	old_data_grads_norm = 1.8270
	sim_grads_norm_tr = -0.0994
-- Starting training on experience 595 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6312
	data_grads_norm = 3.5104
	new_data_grads_norm = 4.6954
	old_data_grads_norm = 6.1181
	sim_grads_norm_tr = 0.0602
-- Starting training on experience 596 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4612
	data_grads_norm = 3.3348
	new_data_grads_norm = 5.1893
	old_data_grads_norm = 4.4931
	sim_grads_norm_tr = 0.0366
-- Starting training on experience 597 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9570
	data_grads_norm = 2.1991
	new_data_grads_norm = 3.9321
	old_data_grads_norm = 4.3882
	sim_grads_norm_tr = -0.1626
-- Starting training on experience 598 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1615
	data_grads_norm = 3.0100
	new_data_grads_norm = 4.6483
	old_data_grads_norm = 3.8411
	sim_grads_norm_tr = 0.0883
-- Starting training on experience 599 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2355
	data_grads_norm = 2.7195
	new_data_grads_norm = 4.8172
	old_data_grads_norm = 3.3991
	sim_grads_norm_tr = -0.1347
-- Starting training on experience 600 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3925
	data_grads_norm = 3.7602
	new_data_grads_norm = 5.1498
	old_data_grads_norm = 3.5076
	sim_grads_norm_tr = 0.4102
-- Starting training on experience 601 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9942
	data_grads_norm = 2.2217
	new_data_grads_norm = 3.9138
	old_data_grads_norm = 1.9223
	sim_grads_norm_tr = 0.1193
-- Starting training on experience 602 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0412
	data_grads_norm = 2.6173
	new_data_grads_norm = 4.2064
	old_data_grads_norm = 2.1995
	sim_grads_norm_tr = 0.1626
-- Starting training on experience 603 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2539
	data_grads_norm = 3.6945
	new_data_grads_norm = 6.0568
	old_data_grads_norm = 3.8896
	sim_grads_norm_tr = -0.0837
-- Starting training on experience 604 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4398
	data_grads_norm = 3.5884
	new_data_grads_norm = 5.0694
	old_data_grads_norm = 3.7044
	sim_grads_norm_tr = 0.2555
-- Starting training on experience 605 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7384
	data_grads_norm = 4.1861
	new_data_grads_norm = 5.2637
	old_data_grads_norm = 4.3427
	sim_grads_norm_tr = 0.1771
-- Starting training on experience 606 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3267
	data_grads_norm = 3.4694
	new_data_grads_norm = 5.9867
	old_data_grads_norm = 3.7668
	sim_grads_norm_tr = 0.2106
-- Starting training on experience 607 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0359
	data_grads_norm = 2.1591
	new_data_grads_norm = 3.9263
	old_data_grads_norm = 3.2568
	sim_grads_norm_tr = -0.2873
-- Starting training on experience 608 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4395
	data_grads_norm = 3.3321
	new_data_grads_norm = 4.4093
	old_data_grads_norm = 4.2495
	sim_grads_norm_tr = 0.1288
-- Starting training on experience 609 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0527
	data_grads_norm = 2.6343
	new_data_grads_norm = 4.5142
	old_data_grads_norm = 3.0518
	sim_grads_norm_tr = -0.0849
-- Starting training on experience 610 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5589
	data_grads_norm = 3.7672
	new_data_grads_norm = 6.0383
	old_data_grads_norm = 3.0628
	sim_grads_norm_tr = 0.2930
-- Starting training on experience 611 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4416
	data_grads_norm = 3.6352
	new_data_grads_norm = 4.7165
	old_data_grads_norm = 4.5913
	sim_grads_norm_tr = -0.0056
-- Starting training on experience 612 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1425
	data_grads_norm = 3.0025
	new_data_grads_norm = 4.8587
	old_data_grads_norm = 2.7896
	sim_grads_norm_tr = 0.1967
-- Starting training on experience 613 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1461
	data_grads_norm = 3.1758
	new_data_grads_norm = 6.5467
	old_data_grads_norm = 2.5641
	sim_grads_norm_tr = -0.2077
-- Starting training on experience 614 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3372
	data_grads_norm = 3.8296
	new_data_grads_norm = 6.8748
	old_data_grads_norm = 2.4434
	sim_grads_norm_tr = 0.0413
-- Starting training on experience 615 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3455
	data_grads_norm = 3.5327
	new_data_grads_norm = 6.4850
	old_data_grads_norm = 2.8738
	sim_grads_norm_tr = 0.0713
-- Starting training on experience 616 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3281
	data_grads_norm = 3.1336
	new_data_grads_norm = 4.9776
	old_data_grads_norm = 3.1074
	sim_grads_norm_tr = 0.1446
-- Starting training on experience 617 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4056
	data_grads_norm = 3.0737
	new_data_grads_norm = 5.2239
	old_data_grads_norm = 3.3330
	sim_grads_norm_tr = -0.0237
-- Starting training on experience 618 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4157
	data_grads_norm = 3.6338
	new_data_grads_norm = 5.1819
	old_data_grads_norm = 3.1992
	sim_grads_norm_tr = 0.4406
-- Starting training on experience 619 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2024
	data_grads_norm = 3.7631
	new_data_grads_norm = 4.9861
	old_data_grads_norm = 3.4407
	sim_grads_norm_tr = 0.3504
-- Starting training on experience 620 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7973
	data_grads_norm = 2.3930
	new_data_grads_norm = 3.7609
	old_data_grads_norm = 2.5659
	sim_grads_norm_tr = 0.2332
-- Starting training on experience 621 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9993
	data_grads_norm = 2.4781
	new_data_grads_norm = 4.8717
	old_data_grads_norm = 3.4031
	sim_grads_norm_tr = -0.2732
-- Starting training on experience 622 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1697
	data_grads_norm = 3.0651
	new_data_grads_norm = 4.4686
	old_data_grads_norm = 4.4774
	sim_grads_norm_tr = 0.0681
-- Starting training on experience 623 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9457
	data_grads_norm = 2.7113
	new_data_grads_norm = 4.4144
	old_data_grads_norm = 3.0724
	sim_grads_norm_tr = -0.0407
-- Starting training on experience 624 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5872
	data_grads_norm = 3.8366
	new_data_grads_norm = 5.4554
	old_data_grads_norm = 5.0012
	sim_grads_norm_tr = 0.1442
-- Starting training on experience 625 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3636
	data_grads_norm = 3.2411
	new_data_grads_norm = 5.0252
	old_data_grads_norm = 3.3218
	sim_grads_norm_tr = 0.2009
-- Starting training on experience 626 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2267
	data_grads_norm = 2.7947
	new_data_grads_norm = 4.8013
	old_data_grads_norm = 3.0982
	sim_grads_norm_tr = -0.0316
-- Starting training on experience 627 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3326
	data_grads_norm = 3.3043
	new_data_grads_norm = 4.8996
	old_data_grads_norm = 4.8206
	sim_grads_norm_tr = -0.0111
-- Starting training on experience 628 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0539
	data_grads_norm = 2.9069
	new_data_grads_norm = 4.0622
	old_data_grads_norm = 3.0093
	sim_grads_norm_tr = 0.3631
-- Starting training on experience 629 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9371
	data_grads_norm = 2.4836
	new_data_grads_norm = 4.0910
	old_data_grads_norm = 3.2788
	sim_grads_norm_tr = -0.1859
-- Starting training on experience 630 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1899
	data_grads_norm = 2.6963
	new_data_grads_norm = 5.0015
	old_data_grads_norm = 2.3905
	sim_grads_norm_tr = 0.0593
-- Starting training on experience 631 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0144
	data_grads_norm = 2.6826
	new_data_grads_norm = 3.7696
	old_data_grads_norm = 2.6409
	sim_grads_norm_tr = 0.2822
-- Starting training on experience 632 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1574
	data_grads_norm = 3.0390
	new_data_grads_norm = 4.2201
	old_data_grads_norm = 3.4042
	sim_grads_norm_tr = 0.1417
-- Starting training on experience 633 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3221
	data_grads_norm = 3.0718
	new_data_grads_norm = 4.3855
	old_data_grads_norm = 3.7541
	sim_grads_norm_tr = 0.0276
-- Starting training on experience 634 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1114
	data_grads_norm = 2.6396
	new_data_grads_norm = 4.0382
	old_data_grads_norm = 3.9531
	sim_grads_norm_tr = -0.2173
-- Starting training on experience 635 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3643
	data_grads_norm = 4.0993
	new_data_grads_norm = 5.7179
	old_data_grads_norm = 4.4078
	sim_grads_norm_tr = 0.3266
-- Starting training on experience 636 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9206
	data_grads_norm = 2.0006
	new_data_grads_norm = 3.4851
	old_data_grads_norm = 3.4037
	sim_grads_norm_tr = -0.4047
-- Starting training on experience 637 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0456
	data_grads_norm = 2.5430
	new_data_grads_norm = 4.4871
	old_data_grads_norm = 2.6883
	sim_grads_norm_tr = -0.0611
-- Starting training on experience 638 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2907
	data_grads_norm = 3.6211
	new_data_grads_norm = 4.2304
	old_data_grads_norm = 5.7630
	sim_grads_norm_tr = 0.1012
-- Starting training on experience 639 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3077
	data_grads_norm = 3.1730
	new_data_grads_norm = 5.0706
	old_data_grads_norm = 4.3901
	sim_grads_norm_tr = -0.1941
-- Starting training on experience 640 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1231
	data_grads_norm = 3.1310
	new_data_grads_norm = 4.8837
	old_data_grads_norm = 3.4970
	sim_grads_norm_tr = -0.0065
-- Starting training on experience 641 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3359
	data_grads_norm = 3.7926
	new_data_grads_norm = 5.9819
	old_data_grads_norm = 2.9187
	sim_grads_norm_tr = 0.3913
-- Starting training on experience 642 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3992
	data_grads_norm = 3.3950
	new_data_grads_norm = 4.6782
	old_data_grads_norm = 4.6498
	sim_grads_norm_tr = 0.0267
-- Starting training on experience 643 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8463
	data_grads_norm = 2.5809
	new_data_grads_norm = 5.4874
	old_data_grads_norm = 1.8754
	sim_grads_norm_tr = -0.1924
-- Starting training on experience 644 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1677
	data_grads_norm = 2.8782
	new_data_grads_norm = 4.5906
	old_data_grads_norm = 3.2732
	sim_grads_norm_tr = 0.1364
-- Starting training on experience 645 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1621
	data_grads_norm = 2.9942
	new_data_grads_norm = 6.3907
	old_data_grads_norm = 2.8928
	sim_grads_norm_tr = -0.0594
-- Starting training on experience 646 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0880
	data_grads_norm = 3.0606
	new_data_grads_norm = 4.3374
	old_data_grads_norm = 5.4492
	sim_grads_norm_tr = -0.2297
-- Starting training on experience 647 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1109
	data_grads_norm = 3.8208
	new_data_grads_norm = 8.0858
	old_data_grads_norm = 2.7791
	sim_grads_norm_tr = -0.0808
-- Starting training on experience 648 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6359
	data_grads_norm = 3.8502
	new_data_grads_norm = 6.0951
	old_data_grads_norm = 4.0726
	sim_grads_norm_tr = 0.0535
-- Starting training on experience 649 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3079
	data_grads_norm = 3.5057
	new_data_grads_norm = 5.1993
	old_data_grads_norm = 3.9821
	sim_grads_norm_tr = 0.1762
-- Starting training on experience 650 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2817
	data_grads_norm = 3.7326
	new_data_grads_norm = 5.4261
	old_data_grads_norm = 4.1553
	sim_grads_norm_tr = 0.1657
-- Starting training on experience 651 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2430
	data_grads_norm = 3.0478
	new_data_grads_norm = 5.2844
	old_data_grads_norm = 2.6958
	sim_grads_norm_tr = 0.0566
-- Starting training on experience 652 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9823
	data_grads_norm = 2.8246
	new_data_grads_norm = 4.6718
	old_data_grads_norm = 2.9399
	sim_grads_norm_tr = -0.0016
-- Starting training on experience 653 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3555
	data_grads_norm = 3.2108
	new_data_grads_norm = 4.9676
	old_data_grads_norm = 3.9803
	sim_grads_norm_tr = 0.1664
-- Starting training on experience 654 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4680
	data_grads_norm = 3.8618
	new_data_grads_norm = 5.9380
	old_data_grads_norm = 3.9656
	sim_grads_norm_tr = 0.1077
-- Starting training on experience 655 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4139
	data_grads_norm = 3.5628
	new_data_grads_norm = 5.4396
	old_data_grads_norm = 3.1980
	sim_grads_norm_tr = 0.1707
-- Starting training on experience 656 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1998
	data_grads_norm = 3.4195
	new_data_grads_norm = 4.7217
	old_data_grads_norm = 4.3032
	sim_grads_norm_tr = 0.1138
-- Starting training on experience 657 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9606
	data_grads_norm = 2.3758
	new_data_grads_norm = 4.1025
	old_data_grads_norm = 3.2159
	sim_grads_norm_tr = -0.2088
-- Starting training on experience 658 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8383
	data_grads_norm = 2.3329
	new_data_grads_norm = 4.3503
	old_data_grads_norm = 2.8713
	sim_grads_norm_tr = -0.1200
-- Starting training on experience 659 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2560
	data_grads_norm = 3.1573
	new_data_grads_norm = 5.3071
	old_data_grads_norm = 3.9843
	sim_grads_norm_tr = 0.0335
-- Starting training on experience 660 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1007
	data_grads_norm = 2.7499
	new_data_grads_norm = 5.0158
	old_data_grads_norm = 2.8299
	sim_grads_norm_tr = 0.0261
-- Starting training on experience 661 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3802
	data_grads_norm = 3.2345
	new_data_grads_norm = 5.3415
	old_data_grads_norm = 3.2872
	sim_grads_norm_tr = 0.0563
-- Starting training on experience 662 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2897
	data_grads_norm = 4.2595
	new_data_grads_norm = 5.3947
	old_data_grads_norm = 3.9205
	sim_grads_norm_tr = 0.6858
-- Starting training on experience 663 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9455
	data_grads_norm = 2.1709
	new_data_grads_norm = 3.8405
	old_data_grads_norm = 3.0013
	sim_grads_norm_tr = -0.1799
-- Starting training on experience 664 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8535
	data_grads_norm = 2.5964
	new_data_grads_norm = 3.8648
	old_data_grads_norm = 3.9828
	sim_grads_norm_tr = 0.0303
-- Starting training on experience 665 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9004
	data_grads_norm = 2.4602
	new_data_grads_norm = 4.4578
	old_data_grads_norm = 3.3095
	sim_grads_norm_tr = -0.0291
-- Starting training on experience 666 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2241
	data_grads_norm = 3.5780
	new_data_grads_norm = 4.6119
	old_data_grads_norm = 4.2128
	sim_grads_norm_tr = 0.4296
-- Starting training on experience 667 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0669
	data_grads_norm = 2.4740
	new_data_grads_norm = 3.7398
	old_data_grads_norm = 3.6278
	sim_grads_norm_tr = -0.2714
-- Starting training on experience 668 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9812
	data_grads_norm = 2.6655
	new_data_grads_norm = 5.6754
	old_data_grads_norm = 2.8505
	sim_grads_norm_tr = -0.1545
-- Starting training on experience 669 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0065
	data_grads_norm = 3.1131
	new_data_grads_norm = 4.7913
	old_data_grads_norm = 4.2843
	sim_grads_norm_tr = -0.0934
-- Starting training on experience 670 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0949
	data_grads_norm = 3.6120
	new_data_grads_norm = 5.7711
	old_data_grads_norm = 3.4932
	sim_grads_norm_tr = 0.1051
-- Starting training on experience 671 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3856
	data_grads_norm = 3.7183
	new_data_grads_norm = 5.4934
	old_data_grads_norm = 3.8184
	sim_grads_norm_tr = 0.2904
-- Starting training on experience 672 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5033
	data_grads_norm = 3.7050
	new_data_grads_norm = 4.9919
	old_data_grads_norm = 4.7293
	sim_grads_norm_tr = 0.3166
-- Starting training on experience 673 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0914
	data_grads_norm = 3.2431
	new_data_grads_norm = 3.8250
	old_data_grads_norm = 4.6724
	sim_grads_norm_tr = 0.1163
-- Starting training on experience 674 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9274
	data_grads_norm = 3.1774
	new_data_grads_norm = 3.8969
	old_data_grads_norm = 4.5860
	sim_grads_norm_tr = 0.1813
-- Starting training on experience 675 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3116
	data_grads_norm = 2.5581
	new_data_grads_norm = 4.1702
	old_data_grads_norm = 3.6624
	sim_grads_norm_tr = -0.1593
-- Starting training on experience 676 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3403
	data_grads_norm = 3.2060
	new_data_grads_norm = 4.9139
	old_data_grads_norm = 3.6147
	sim_grads_norm_tr = -0.0167
-- Starting training on experience 677 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2911
	data_grads_norm = 3.0644
	new_data_grads_norm = 4.0845
	old_data_grads_norm = 3.8488
	sim_grads_norm_tr = 0.1687
-- Starting training on experience 678 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5147
	data_grads_norm = 3.6566
	new_data_grads_norm = 5.5537
	old_data_grads_norm = 5.0564
	sim_grads_norm_tr = -0.0716
-- Starting training on experience 679 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4125
	data_grads_norm = 3.7329
	new_data_grads_norm = 5.8366
	old_data_grads_norm = 3.5099
	sim_grads_norm_tr = -0.0976
-- Starting training on experience 680 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1770
	data_grads_norm = 2.9410
	new_data_grads_norm = 5.7867
	old_data_grads_norm = 2.7170
	sim_grads_norm_tr = -0.0309
-- Starting training on experience 681 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9933
	data_grads_norm = 2.8259
	new_data_grads_norm = 5.4183
	old_data_grads_norm = 2.5590
	sim_grads_norm_tr = 0.0529
-- Starting training on experience 682 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7308
	data_grads_norm = 4.0417
	new_data_grads_norm = 5.7796
	old_data_grads_norm = 4.6912
	sim_grads_norm_tr = 0.1341
-- Starting training on experience 683 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8508
	data_grads_norm = 4.0738
	new_data_grads_norm = 5.7912
	old_data_grads_norm = 4.5229
	sim_grads_norm_tr = 0.1114
-- Starting training on experience 684 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9105
	data_grads_norm = 2.3887
	new_data_grads_norm = 4.4577
	old_data_grads_norm = 2.3803
	sim_grads_norm_tr = -0.2168
-- Starting training on experience 685 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2135
	data_grads_norm = 3.4337
	new_data_grads_norm = 5.2194
	old_data_grads_norm = 2.7898
	sim_grads_norm_tr = 0.1416
-- Starting training on experience 686 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9741
	data_grads_norm = 2.5834
	new_data_grads_norm = 5.3659
	old_data_grads_norm = 2.2440
	sim_grads_norm_tr = -0.1495
-- Starting training on experience 687 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6881
	data_grads_norm = 3.9986
	new_data_grads_norm = 6.9124
	old_data_grads_norm = 3.7921
	sim_grads_norm_tr = 0.0543
-- Starting training on experience 688 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3275
	data_grads_norm = 3.0464
	new_data_grads_norm = 5.8332
	old_data_grads_norm = 3.9350
	sim_grads_norm_tr = -0.0264
-- Starting training on experience 689 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5752
	data_grads_norm = 3.6742
	new_data_grads_norm = 4.8836
	old_data_grads_norm = 4.6554
	sim_grads_norm_tr = -0.0521
-- Starting training on experience 690 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5979
	data_grads_norm = 3.9029
	new_data_grads_norm = 5.5244
	old_data_grads_norm = 3.5743
	sim_grads_norm_tr = 0.4072
-- Starting training on experience 691 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3707
	data_grads_norm = 3.6403
	new_data_grads_norm = 5.8951
	old_data_grads_norm = 3.4063
	sim_grads_norm_tr = 0.0584
-- Starting training on experience 692 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3387
	data_grads_norm = 3.3240
	new_data_grads_norm = 5.2175
	old_data_grads_norm = 3.1232
	sim_grads_norm_tr = 0.1663
-- Starting training on experience 693 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5609
	data_grads_norm = 3.9406
	new_data_grads_norm = 5.6434
	old_data_grads_norm = 4.4095
	sim_grads_norm_tr = 0.0566
-- Starting training on experience 694 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6876
	data_grads_norm = 3.6199
	new_data_grads_norm = 6.1169
	old_data_grads_norm = 3.4510
	sim_grads_norm_tr = 0.1059
-- Starting training on experience 695 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4640
	data_grads_norm = 3.4332
	new_data_grads_norm = 5.1123
	old_data_grads_norm = 3.3773
	sim_grads_norm_tr = 0.1592
-- Starting training on experience 696 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7608
	data_grads_norm = 3.4248
	new_data_grads_norm = 4.9625
	old_data_grads_norm = 3.6547
	sim_grads_norm_tr = 0.2679
-- Starting training on experience 697 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2978
	data_grads_norm = 2.9861
	new_data_grads_norm = 4.2219
	old_data_grads_norm = 3.5329
	sim_grads_norm_tr = 0.1516
-- Starting training on experience 698 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0538
	data_grads_norm = 2.3464
	new_data_grads_norm = 4.1726
	old_data_grads_norm = 3.5668
	sim_grads_norm_tr = -0.2845
-- Starting training on experience 699 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4764
	data_grads_norm = 3.3773
	new_data_grads_norm = 4.5132
	old_data_grads_norm = 4.3218
	sim_grads_norm_tr = 0.1511
-- Starting training on experience 700 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3079
	data_grads_norm = 4.5916
	new_data_grads_norm = 5.6655
	old_data_grads_norm = 6.3871
	sim_grads_norm_tr = 0.0141
-- Starting training on experience 701 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3246
	data_grads_norm = 3.1718
	new_data_grads_norm = 4.4948
	old_data_grads_norm = 3.8013
	sim_grads_norm_tr = -0.0016
-- Starting training on experience 702 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3899
	data_grads_norm = 3.4301
	new_data_grads_norm = 5.4630
	old_data_grads_norm = 3.7474
	sim_grads_norm_tr = 0.1130
-- Starting training on experience 703 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5227
	data_grads_norm = 3.6160
	new_data_grads_norm = 6.1919
	old_data_grads_norm = 3.6189
	sim_grads_norm_tr = 0.0123
-- Starting training on experience 704 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1581
	data_grads_norm = 3.4445
	new_data_grads_norm = 4.9899
	old_data_grads_norm = 4.1603
	sim_grads_norm_tr = 0.1118
-- Starting training on experience 705 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1734
	data_grads_norm = 3.1551
	new_data_grads_norm = 4.6380
	old_data_grads_norm = 4.2388
	sim_grads_norm_tr = 0.0706
-- Starting training on experience 706 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3693
	data_grads_norm = 3.5003
	new_data_grads_norm = 4.4927
	old_data_grads_norm = 5.2184
	sim_grads_norm_tr = 0.0741
-- Starting training on experience 707 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1564
	data_grads_norm = 2.5844
	new_data_grads_norm = 4.2207
	old_data_grads_norm = 2.7338
	sim_grads_norm_tr = -0.0188
-- Starting training on experience 708 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9967
	data_grads_norm = 2.4060
	new_data_grads_norm = 4.1277
	old_data_grads_norm = 3.6962
	sim_grads_norm_tr = -0.1078
-- Starting training on experience 709 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1993
	data_grads_norm = 3.4362
	new_data_grads_norm = 4.8235
	old_data_grads_norm = 3.7120
	sim_grads_norm_tr = 0.4363
-- Starting training on experience 710 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1536
	data_grads_norm = 3.5117
	new_data_grads_norm = 4.3564
	old_data_grads_norm = 3.6434
	sim_grads_norm_tr = 0.3138
-- Starting training on experience 711 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8318
	data_grads_norm = 2.8939
	new_data_grads_norm = 4.8103
	old_data_grads_norm = 3.2904
	sim_grads_norm_tr = 0.2694
-- Starting training on experience 712 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1599
	data_grads_norm = 2.6458
	new_data_grads_norm = 4.5683
	old_data_grads_norm = 3.9051
	sim_grads_norm_tr = -0.1371
-- Starting training on experience 713 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3320
	data_grads_norm = 2.8985
	new_data_grads_norm = 4.2988
	old_data_grads_norm = 4.0487
	sim_grads_norm_tr = -0.1365
-- Starting training on experience 714 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4192
	data_grads_norm = 3.8598
	new_data_grads_norm = 4.7558
	old_data_grads_norm = 6.0969
	sim_grads_norm_tr = 0.0907
-- Starting training on experience 715 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2250
	data_grads_norm = 3.3658
	new_data_grads_norm = 4.8950
	old_data_grads_norm = 4.5207
	sim_grads_norm_tr = -0.0559
-- Starting training on experience 716 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2689
	data_grads_norm = 2.9623
	new_data_grads_norm = 5.1883
	old_data_grads_norm = 2.9016
	sim_grads_norm_tr = -0.3521
-- Starting training on experience 717 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4449
	data_grads_norm = 3.1796
	new_data_grads_norm = 5.7880
	old_data_grads_norm = 2.9821
	sim_grads_norm_tr = -0.0140
-- Starting training on experience 718 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8086
	data_grads_norm = 4.6764
	new_data_grads_norm = 5.9758
	old_data_grads_norm = 5.0520
	sim_grads_norm_tr = 0.2590
-- Starting training on experience 719 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2317
	data_grads_norm = 3.3328
	new_data_grads_norm = 5.1883
	old_data_grads_norm = 3.4997
	sim_grads_norm_tr = 0.2392
-- Starting training on experience 720 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4319
	data_grads_norm = 3.8974
	new_data_grads_norm = 5.1861
	old_data_grads_norm = 6.7396
	sim_grads_norm_tr = -0.1672
-- Starting training on experience 721 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7717
	data_grads_norm = 4.1080
	new_data_grads_norm = 6.5254
	old_data_grads_norm = 4.4813
	sim_grads_norm_tr = 0.0669
-- Starting training on experience 722 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9606
	data_grads_norm = 2.8847
	new_data_grads_norm = 5.0426
	old_data_grads_norm = 3.2359
	sim_grads_norm_tr = 0.0174
-- Starting training on experience 723 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0239
	data_grads_norm = 2.7533
	new_data_grads_norm = 5.7957
	old_data_grads_norm = 3.4827
	sim_grads_norm_tr = -0.2266
-- Starting training on experience 724 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6392
	data_grads_norm = 3.8767
	new_data_grads_norm = 6.0973
	old_data_grads_norm = 3.8074
	sim_grads_norm_tr = -0.0995
-- Starting training on experience 725 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1951
	data_grads_norm = 3.0753
	new_data_grads_norm = 6.3234
	old_data_grads_norm = 2.9328
	sim_grads_norm_tr = -0.1949
-- Starting training on experience 726 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5542
	data_grads_norm = 3.8009
	new_data_grads_norm = 5.7737
	old_data_grads_norm = 3.2521
	sim_grads_norm_tr = 0.1624
-- Starting training on experience 727 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6310
	data_grads_norm = 3.6860
	new_data_grads_norm = 5.6293
	old_data_grads_norm = 4.5795
	sim_grads_norm_tr = -0.0595
-- Starting training on experience 728 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4905
	data_grads_norm = 4.4809
	new_data_grads_norm = 6.1828
	old_data_grads_norm = 4.8255
	sim_grads_norm_tr = 0.2876
-- Starting training on experience 729 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4187
	data_grads_norm = 4.1112
	new_data_grads_norm = 5.2249
	old_data_grads_norm = 4.0848
	sim_grads_norm_tr = 0.2948
-- Starting training on experience 730 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9723
	data_grads_norm = 2.9067
	new_data_grads_norm = 4.4202
	old_data_grads_norm = 3.7478
	sim_grads_norm_tr = 0.0437
-- Starting training on experience 731 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3791
	data_grads_norm = 3.3267
	new_data_grads_norm = 5.9474
	old_data_grads_norm = 3.6725
	sim_grads_norm_tr = -0.0733
-- Starting training on experience 732 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7018
	data_grads_norm = 2.1635
	new_data_grads_norm = 4.2901
	old_data_grads_norm = 2.3576
	sim_grads_norm_tr = -0.1538
-- Starting training on experience 733 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3747
	data_grads_norm = 3.6890
	new_data_grads_norm = 5.5156
	old_data_grads_norm = 3.2859
	sim_grads_norm_tr = 0.3666
-- Starting training on experience 734 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2382
	data_grads_norm = 2.8812
	new_data_grads_norm = 4.7366
	old_data_grads_norm = 3.4457
	sim_grads_norm_tr = 0.0062
-- Starting training on experience 735 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2719
	data_grads_norm = 3.7431
	new_data_grads_norm = 4.7905
	old_data_grads_norm = 4.7498
	sim_grads_norm_tr = 0.1365
-- Starting training on experience 736 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1764
	data_grads_norm = 3.2202
	new_data_grads_norm = 4.4952
	old_data_grads_norm = 4.3073
	sim_grads_norm_tr = 0.1828
-- Starting training on experience 737 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9766
	data_grads_norm = 3.1371
	new_data_grads_norm = 5.0907
	old_data_grads_norm = 2.7144
	sim_grads_norm_tr = 0.3195
-- Starting training on experience 738 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5078
	data_grads_norm = 3.8062
	new_data_grads_norm = 5.3552
	old_data_grads_norm = 5.3940
	sim_grads_norm_tr = -0.2143
-- Starting training on experience 739 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4900
	data_grads_norm = 3.7656
	new_data_grads_norm = 5.5141
	old_data_grads_norm = 4.0445
	sim_grads_norm_tr = 0.2430
-- Starting training on experience 740 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9736
	data_grads_norm = 2.5415
	new_data_grads_norm = 4.4029
	old_data_grads_norm = 2.5422
	sim_grads_norm_tr = 0.1450
-- Starting training on experience 741 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9514
	data_grads_norm = 2.8755
	new_data_grads_norm = 4.2514
	old_data_grads_norm = 2.9687
	sim_grads_norm_tr = 0.2621
-- Starting training on experience 742 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0053
	data_grads_norm = 2.4045
	new_data_grads_norm = 5.2666
	old_data_grads_norm = 3.1715
	sim_grads_norm_tr = -0.3381
-- Starting training on experience 743 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0553
	data_grads_norm = 3.2523
	new_data_grads_norm = 5.7205
	old_data_grads_norm = 3.1957
	sim_grads_norm_tr = -0.0877
-- Starting training on experience 744 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3171
	data_grads_norm = 3.4694
	new_data_grads_norm = 5.5709
	old_data_grads_norm = 3.7965
	sim_grads_norm_tr = -0.0391
-- Starting training on experience 745 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2874
	data_grads_norm = 3.5957
	new_data_grads_norm = 5.6082
	old_data_grads_norm = 5.3795
	sim_grads_norm_tr = -0.0569
-- Starting training on experience 746 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4977
	data_grads_norm = 3.4146
	new_data_grads_norm = 5.4173
	old_data_grads_norm = 3.7419
	sim_grads_norm_tr = -0.0694
-- Starting training on experience 747 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2495
	data_grads_norm = 3.6349
	new_data_grads_norm = 5.9294
	old_data_grads_norm = 4.3267
	sim_grads_norm_tr = 0.1687
-- Starting training on experience 748 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0866
	data_grads_norm = 3.6601
	new_data_grads_norm = 4.2318
	old_data_grads_norm = 4.6665
	sim_grads_norm_tr = 0.4013
-- Starting training on experience 749 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0575
	data_grads_norm = 2.3401
	new_data_grads_norm = 4.2827
	old_data_grads_norm = 2.6912
	sim_grads_norm_tr = -0.0893
-- Starting training on experience 750 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0131
	data_grads_norm = 2.6164
	new_data_grads_norm = 5.1045
	old_data_grads_norm = 3.5746
	sim_grads_norm_tr = -0.3913
-- Starting training on experience 751 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9838
	data_grads_norm = 2.9063
	new_data_grads_norm = 4.8391
	old_data_grads_norm = 2.6979
	sim_grads_norm_tr = 0.2486
-- Starting training on experience 752 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0452
	data_grads_norm = 3.0452
	new_data_grads_norm = 4.4580
	old_data_grads_norm = 4.9785
	sim_grads_norm_tr = -0.2200
-- Starting training on experience 753 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1319
	data_grads_norm = 3.2320
	new_data_grads_norm = 6.0423
	old_data_grads_norm = 3.2125
	sim_grads_norm_tr = -0.1312
-- Starting training on experience 754 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4362
	data_grads_norm = 3.8048
	new_data_grads_norm = 5.1634
	old_data_grads_norm = 4.6032
	sim_grads_norm_tr = 0.0425
-- Starting training on experience 755 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0860
	data_grads_norm = 2.5549
	new_data_grads_norm = 5.3791
	old_data_grads_norm = 2.5901
	sim_grads_norm_tr = -0.3508
-- Starting training on experience 756 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4543
	data_grads_norm = 3.3183
	new_data_grads_norm = 5.5569
	old_data_grads_norm = 3.6642
	sim_grads_norm_tr = -0.0173
-- Starting training on experience 757 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1960
	data_grads_norm = 3.3462
	new_data_grads_norm = 5.7281
	old_data_grads_norm = 3.0421
	sim_grads_norm_tr = 0.0716
-- Starting training on experience 758 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3682
	data_grads_norm = 3.3097
	new_data_grads_norm = 5.4778
	old_data_grads_norm = 3.6599
	sim_grads_norm_tr = 0.1152
-- Starting training on experience 759 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7725
	data_grads_norm = 3.5629
	new_data_grads_norm = 5.6269
	old_data_grads_norm = 3.4427
	sim_grads_norm_tr = 0.2515
-- Starting training on experience 760 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0233
	data_grads_norm = 2.6574
	new_data_grads_norm = 4.3977
	old_data_grads_norm = 2.9447
	sim_grads_norm_tr = -0.0643
-- Starting training on experience 761 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9381
	data_grads_norm = 2.6790
	new_data_grads_norm = 5.0130
	old_data_grads_norm = 2.5112
	sim_grads_norm_tr = -0.0134
-- Starting training on experience 762 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2313
	data_grads_norm = 3.7294
	new_data_grads_norm = 5.6566
	old_data_grads_norm = 4.5675
	sim_grads_norm_tr = 0.0625
-- Starting training on experience 763 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9379
	data_grads_norm = 3.0205
	new_data_grads_norm = 5.3251
	old_data_grads_norm = 2.3274
	sim_grads_norm_tr = 0.1412
-- Starting training on experience 764 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9335
	data_grads_norm = 2.6484
	new_data_grads_norm = 5.1078
	old_data_grads_norm = 3.3641
	sim_grads_norm_tr = -0.0240
-- Starting training on experience 765 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7892
	data_grads_norm = 2.1549
	new_data_grads_norm = 4.4967
	old_data_grads_norm = 2.8853
	sim_grads_norm_tr = -0.4178
-- Starting training on experience 766 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3901
	data_grads_norm = 3.8787
	new_data_grads_norm = 6.0413
	old_data_grads_norm = 2.6703
	sim_grads_norm_tr = 0.1221
-- Starting training on experience 767 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3747
	data_grads_norm = 3.8369
	new_data_grads_norm = 5.8726
	old_data_grads_norm = 4.1556
	sim_grads_norm_tr = 0.2475
-- Starting training on experience 768 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2820
	data_grads_norm = 4.7325
	new_data_grads_norm = 6.6135
	old_data_grads_norm = 4.1664
	sim_grads_norm_tr = 0.5343
-- Starting training on experience 769 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9472
	data_grads_norm = 2.6114
	new_data_grads_norm = 4.6997
	old_data_grads_norm = 2.7881
	sim_grads_norm_tr = 0.0885
-- Starting training on experience 770 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1068
	data_grads_norm = 3.4242
	new_data_grads_norm = 5.3526
	old_data_grads_norm = 4.9271
	sim_grads_norm_tr = 0.1162
-- Starting training on experience 771 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2147
	data_grads_norm = 2.6204
	new_data_grads_norm = 4.6038
	old_data_grads_norm = 3.6866
	sim_grads_norm_tr = -0.2977
-- Starting training on experience 772 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0916
	data_grads_norm = 3.2856
	new_data_grads_norm = 4.8131
	old_data_grads_norm = 4.4384
	sim_grads_norm_tr = -0.1022
-- Starting training on experience 773 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2300
	data_grads_norm = 4.1189
	new_data_grads_norm = 4.2932
	old_data_grads_norm = 6.9439
	sim_grads_norm_tr = 0.0800
-- Starting training on experience 774 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3244
	data_grads_norm = 3.4813
	new_data_grads_norm = 5.7989
	old_data_grads_norm = 3.6476
	sim_grads_norm_tr = 0.1237
-- Starting training on experience 775 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2883
	data_grads_norm = 2.9284
	new_data_grads_norm = 4.9184
	old_data_grads_norm = 3.0955
	sim_grads_norm_tr = -0.1042
-- Starting training on experience 776 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3954
	data_grads_norm = 3.9454
	new_data_grads_norm = 4.9770
	old_data_grads_norm = 4.2335
	sim_grads_norm_tr = 0.1895
-- Starting training on experience 777 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3876
	data_grads_norm = 3.8551
	new_data_grads_norm = 5.4432
	old_data_grads_norm = 4.7436
	sim_grads_norm_tr = 0.0279
-- Starting training on experience 778 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9554
	data_grads_norm = 2.7804
	new_data_grads_norm = 4.4224
	old_data_grads_norm = 3.6898
	sim_grads_norm_tr = -0.0346
-- Starting training on experience 779 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9007
	data_grads_norm = 2.1663
	new_data_grads_norm = 3.9491
	old_data_grads_norm = 2.7027
	sim_grads_norm_tr = -0.0581
-- Starting training on experience 780 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2577
	data_grads_norm = 3.2774
	new_data_grads_norm = 5.0348
	old_data_grads_norm = 3.4714
	sim_grads_norm_tr = 0.3291
-- Starting training on experience 781 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8713
	data_grads_norm = 2.3775
	new_data_grads_norm = 4.2000
	old_data_grads_norm = 3.0379
	sim_grads_norm_tr = -0.1914
-- Starting training on experience 782 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9867
	data_grads_norm = 2.8719
	new_data_grads_norm = 4.1583
	old_data_grads_norm = 3.7097
	sim_grads_norm_tr = 0.0071
-- Starting training on experience 783 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2205
	data_grads_norm = 2.7073
	new_data_grads_norm = 4.9523
	old_data_grads_norm = 3.3824
	sim_grads_norm_tr = -0.2865
-- Starting training on experience 784 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3067
	data_grads_norm = 3.1599
	new_data_grads_norm = 5.2199
	old_data_grads_norm = 3.0306
	sim_grads_norm_tr = -0.0611
-- Starting training on experience 785 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3232
	data_grads_norm = 3.1866
	new_data_grads_norm = 5.2111
	old_data_grads_norm = 3.2269
	sim_grads_norm_tr = -0.1814
-- Starting training on experience 786 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8676
	data_grads_norm = 4.5856
	new_data_grads_norm = 6.7487
	old_data_grads_norm = 4.5887
	sim_grads_norm_tr = 0.2621
-- Starting training on experience 787 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3046
	data_grads_norm = 2.8933
	new_data_grads_norm = 5.2988
	old_data_grads_norm = 3.0497
	sim_grads_norm_tr = -0.1007
-- Starting training on experience 788 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9721
	data_grads_norm = 2.6346
	new_data_grads_norm = 4.6297
	old_data_grads_norm = 2.6237
	sim_grads_norm_tr = -0.0682
-- Starting training on experience 789 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9627
	data_grads_norm = 2.7924
	new_data_grads_norm = 4.9437
	old_data_grads_norm = 3.5683
	sim_grads_norm_tr = -0.0034
-- Starting training on experience 790 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4881
	data_grads_norm = 4.2704
	new_data_grads_norm = 5.8074
	old_data_grads_norm = 3.8058
	sim_grads_norm_tr = 0.2803
-- Starting training on experience 791 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5009
	data_grads_norm = 3.3860
	new_data_grads_norm = 4.8044
	old_data_grads_norm = 3.6556
	sim_grads_norm_tr = 0.1213
-- Starting training on experience 792 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9136
	data_grads_norm = 2.9350
	new_data_grads_norm = 5.3187
	old_data_grads_norm = 2.9935
	sim_grads_norm_tr = 0.1363
-- Starting training on experience 793 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9934
	data_grads_norm = 2.9147
	new_data_grads_norm = 4.5558
	old_data_grads_norm = 3.6654
	sim_grads_norm_tr = -0.0813
-- Starting training on experience 794 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9986
	data_grads_norm = 4.7705
	new_data_grads_norm = 6.3691
	old_data_grads_norm = 4.7031
	sim_grads_norm_tr = 0.3512
-- Starting training on experience 795 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0528
	data_grads_norm = 3.1647
	new_data_grads_norm = 5.4223
	old_data_grads_norm = 3.5683
	sim_grads_norm_tr = -0.0605
-- Starting training on experience 796 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7026
	data_grads_norm = 3.8656
	new_data_grads_norm = 5.8921
	old_data_grads_norm = 4.4398
	sim_grads_norm_tr = 0.0378
-- Starting training on experience 797 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0652
	data_grads_norm = 3.4149
	new_data_grads_norm = 6.0451
	old_data_grads_norm = 2.5918
	sim_grads_norm_tr = 0.1944
-- Starting training on experience 798 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9767
	data_grads_norm = 2.4893
	new_data_grads_norm = 5.2391
	old_data_grads_norm = 2.1089
	sim_grads_norm_tr = -0.2754
-- Starting training on experience 799 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6032
	data_grads_norm = 4.0944
	new_data_grads_norm = 5.1372
	old_data_grads_norm = 4.4994
	sim_grads_norm_tr = 0.3001
-- Starting training on experience 800 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9498
	data_grads_norm = 3.9628
	new_data_grads_norm = 4.8537
	old_data_grads_norm = 4.4764
	sim_grads_norm_tr = 0.1433
-- Starting training on experience 801 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7329
	data_grads_norm = 2.1639
	new_data_grads_norm = 4.5017
	old_data_grads_norm = 2.8344
	sim_grads_norm_tr = -0.4167
-- Starting training on experience 802 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7223
	data_grads_norm = 3.2105
	new_data_grads_norm = 5.2321
	old_data_grads_norm = 4.1363
	sim_grads_norm_tr = -0.1485
-- Starting training on experience 803 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2246
	data_grads_norm = 2.8931
	new_data_grads_norm = 4.4538
	old_data_grads_norm = 4.0004
	sim_grads_norm_tr = 0.0803
-- Starting training on experience 804 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0897
	data_grads_norm = 2.7965
	new_data_grads_norm = 4.5728
	old_data_grads_norm = 2.1508
	sim_grads_norm_tr = 0.1910
-- Starting training on experience 805 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0292
	data_grads_norm = 2.4863
	new_data_grads_norm = 4.5801
	old_data_grads_norm = 2.7308
	sim_grads_norm_tr = -0.0411
-- Starting training on experience 806 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0743
	data_grads_norm = 2.7193
	new_data_grads_norm = 4.9501
	old_data_grads_norm = 3.8887
	sim_grads_norm_tr = -0.2740
-- Starting training on experience 807 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9416
	data_grads_norm = 3.6091
	new_data_grads_norm = 5.8373
	old_data_grads_norm = 3.8320
	sim_grads_norm_tr = 0.0834
-- Starting training on experience 808 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7420
	data_grads_norm = 4.2112
	new_data_grads_norm = 5.4110
	old_data_grads_norm = 5.0032
	sim_grads_norm_tr = 0.4793
-- Starting training on experience 809 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0630
	data_grads_norm = 2.9366
	new_data_grads_norm = 4.7065
	old_data_grads_norm = 4.0868
	sim_grads_norm_tr = -0.2339
-- Starting training on experience 810 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2931
	data_grads_norm = 3.4362
	new_data_grads_norm = 5.1829
	old_data_grads_norm = 3.9620
	sim_grads_norm_tr = -0.0143
-- Starting training on experience 811 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1884
	data_grads_norm = 3.1389
	new_data_grads_norm = 5.2616
	old_data_grads_norm = 3.5705
	sim_grads_norm_tr = 0.0412
-- Starting training on experience 812 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4649
	data_grads_norm = 3.0090
	new_data_grads_norm = 5.0523
	old_data_grads_norm = 3.1155
	sim_grads_norm_tr = 0.1228
-- Starting training on experience 813 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8521
	data_grads_norm = 2.3956
	new_data_grads_norm = 4.4133
	old_data_grads_norm = 2.4515
	sim_grads_norm_tr = -0.1901
-- Starting training on experience 814 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8757
	data_grads_norm = 2.8897
	new_data_grads_norm = 4.7683
	old_data_grads_norm = 2.7452
	sim_grads_norm_tr = 0.3165
-- Starting training on experience 815 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2372
	data_grads_norm = 2.8596
	new_data_grads_norm = 4.3063
	old_data_grads_norm = 3.1607
	sim_grads_norm_tr = 0.1771
-- Starting training on experience 816 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7955
	data_grads_norm = 2.3317
	new_data_grads_norm = 4.0674
	old_data_grads_norm = 2.0118
	sim_grads_norm_tr = -0.0439
-- Starting training on experience 817 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2697
	data_grads_norm = 3.4788
	new_data_grads_norm = 5.9300
	old_data_grads_norm = 3.4471
	sim_grads_norm_tr = -0.1548
-- Starting training on experience 818 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9812
	data_grads_norm = 2.2506
	new_data_grads_norm = 3.4039
	old_data_grads_norm = 3.4620
	sim_grads_norm_tr = -0.2800
-- Starting training on experience 819 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3205
	data_grads_norm = 2.9305
	new_data_grads_norm = 4.7569
	old_data_grads_norm = 2.7872
	sim_grads_norm_tr = 0.1190
-- Starting training on experience 820 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0898
	data_grads_norm = 2.8108
	new_data_grads_norm = 5.4694
	old_data_grads_norm = 2.8566
	sim_grads_norm_tr = 0.0053
-- Starting training on experience 821 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3792
	data_grads_norm = 3.3710
	new_data_grads_norm = 4.6286
	old_data_grads_norm = 3.9869
	sim_grads_norm_tr = 0.0840
-- Starting training on experience 822 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0532
	data_grads_norm = 2.9195
	new_data_grads_norm = 5.6229
	old_data_grads_norm = 3.3161
	sim_grads_norm_tr = -0.3490
-- Starting training on experience 823 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7381
	data_grads_norm = 4.3055
	new_data_grads_norm = 5.9152
	old_data_grads_norm = 3.8546
	sim_grads_norm_tr = 0.4037
-- Starting training on experience 824 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3389
	data_grads_norm = 3.3726
	new_data_grads_norm = 5.3625
	old_data_grads_norm = 2.5510
	sim_grads_norm_tr = -0.1314
-- Starting training on experience 825 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0325
	data_grads_norm = 3.2776
	new_data_grads_norm = 5.2456
	old_data_grads_norm = 3.1038
	sim_grads_norm_tr = 0.2408
-- Starting training on experience 826 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3158
	data_grads_norm = 4.6052
	new_data_grads_norm = 5.9929
	old_data_grads_norm = 6.2697
	sim_grads_norm_tr = 0.1644
-- Starting training on experience 827 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7842
	data_grads_norm = 5.5055
	new_data_grads_norm = 10.1129
	old_data_grads_norm = 4.4908
	sim_grads_norm_tr = 0.0668
-- Starting training on experience 828 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0571
	data_grads_norm = 2.5422
	new_data_grads_norm = 4.9217
	old_data_grads_norm = 3.0194
	sim_grads_norm_tr = -0.2456
-- Starting training on experience 829 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5008
	data_grads_norm = 4.4343
	new_data_grads_norm = 5.5532
	old_data_grads_norm = 3.6204
	sim_grads_norm_tr = 0.0928
-- Starting training on experience 830 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1972
	data_grads_norm = 3.8753
	new_data_grads_norm = 5.8117
	old_data_grads_norm = 3.7716
	sim_grads_norm_tr = 0.4034
-- Starting training on experience 831 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4474
	data_grads_norm = 3.6867
	new_data_grads_norm = 4.6313
	old_data_grads_norm = 4.3367
	sim_grads_norm_tr = 0.2969
-- Starting training on experience 832 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9976
	data_grads_norm = 3.0201
	new_data_grads_norm = 5.0748
	old_data_grads_norm = 2.9766
	sim_grads_norm_tr = 0.1003
-- Starting training on experience 833 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9923
	data_grads_norm = 3.2442
	new_data_grads_norm = 4.7804
	old_data_grads_norm = 4.2019
	sim_grads_norm_tr = 0.1218
-- Starting training on experience 834 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0552
	data_grads_norm = 2.6491
	new_data_grads_norm = 4.0942
	old_data_grads_norm = 3.6578
	sim_grads_norm_tr = -0.2662
-- Starting training on experience 835 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5458
	data_grads_norm = 3.6537
	new_data_grads_norm = 6.1824
	old_data_grads_norm = 3.6318
	sim_grads_norm_tr = -0.1098
-- Starting training on experience 836 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1854
	data_grads_norm = 3.4613
	new_data_grads_norm = 5.6916
	old_data_grads_norm = 3.2490
	sim_grads_norm_tr = 0.3489
-- Starting training on experience 837 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9978
	data_grads_norm = 2.8032
	new_data_grads_norm = 4.6528
	old_data_grads_norm = 4.5032
	sim_grads_norm_tr = -0.2502
-- Starting training on experience 838 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9940
	data_grads_norm = 3.1535
	new_data_grads_norm = 5.2878
	old_data_grads_norm = 2.8322
	sim_grads_norm_tr = 0.0918
-- Starting training on experience 839 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0010
	data_grads_norm = 2.6619
	new_data_grads_norm = 4.6285
	old_data_grads_norm = 2.7446
	sim_grads_norm_tr = -0.2002
-- Starting training on experience 840 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9037
	data_grads_norm = 3.8458
	new_data_grads_norm = 5.0916
	old_data_grads_norm = 5.3161
	sim_grads_norm_tr = 0.0785
-- Starting training on experience 841 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4212
	data_grads_norm = 3.3745
	new_data_grads_norm = 4.8086
	old_data_grads_norm = 3.3104
	sim_grads_norm_tr = 0.3539
-- Starting training on experience 842 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1611
	data_grads_norm = 3.2026
	new_data_grads_norm = 5.3244
	old_data_grads_norm = 3.0322
	sim_grads_norm_tr = 0.0762
-- Starting training on experience 843 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3980
	data_grads_norm = 3.0199
	new_data_grads_norm = 5.3975
	old_data_grads_norm = 3.4190
	sim_grads_norm_tr = -0.2529
-- Starting training on experience 844 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0532
	data_grads_norm = 2.5148
	new_data_grads_norm = 4.8588
	old_data_grads_norm = 2.6758
	sim_grads_norm_tr = -0.2842
-- Starting training on experience 845 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3463
	data_grads_norm = 3.3833
	new_data_grads_norm = 5.0174
	old_data_grads_norm = 3.0371
	sim_grads_norm_tr = 0.1194
-- Starting training on experience 846 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0925
	data_grads_norm = 3.0008
	new_data_grads_norm = 4.2248
	old_data_grads_norm = 3.5427
	sim_grads_norm_tr = 0.1627
-- Starting training on experience 847 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2405
	data_grads_norm = 3.2750
	new_data_grads_norm = 5.6520
	old_data_grads_norm = 3.2295
	sim_grads_norm_tr = -0.0767
-- Starting training on experience 848 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0252
	data_grads_norm = 2.7075
	new_data_grads_norm = 6.2111
	old_data_grads_norm = 2.2651
	sim_grads_norm_tr = -0.3059
-- Starting training on experience 849 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3906
	data_grads_norm = 3.4984
	new_data_grads_norm = 6.2905
	old_data_grads_norm = 2.8643
	sim_grads_norm_tr = 0.2714
-- Starting training on experience 850 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4410
	data_grads_norm = 3.7829
	new_data_grads_norm = 5.4393
	old_data_grads_norm = 4.8712
	sim_grads_norm_tr = 0.1932
-- Starting training on experience 851 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3063
	data_grads_norm = 2.7644
	new_data_grads_norm = 4.7028
	old_data_grads_norm = 3.0999
	sim_grads_norm_tr = -0.2186
-- Starting training on experience 852 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5763
	data_grads_norm = 3.6311
	new_data_grads_norm = 4.9558
	old_data_grads_norm = 3.7372
	sim_grads_norm_tr = 0.1932
-- Starting training on experience 853 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2408
	data_grads_norm = 3.1700
	new_data_grads_norm = 5.1206
	old_data_grads_norm = 3.3118
	sim_grads_norm_tr = -0.0238
-- Starting training on experience 854 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3412
	data_grads_norm = 3.8145
	new_data_grads_norm = 4.9390
	old_data_grads_norm = 4.7531
	sim_grads_norm_tr = 0.2689
-- Starting training on experience 855 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1081
	data_grads_norm = 3.0473
	new_data_grads_norm = 4.7609
	old_data_grads_norm = 3.3989
	sim_grads_norm_tr = -0.0534
-- Starting training on experience 856 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4028
	data_grads_norm = 2.9013
	new_data_grads_norm = 4.8835
	old_data_grads_norm = 3.4657
	sim_grads_norm_tr = -0.2684
-- Starting training on experience 857 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4452
	data_grads_norm = 3.7726
	new_data_grads_norm = 5.5475
	old_data_grads_norm = 3.2683
	sim_grads_norm_tr = 0.2762
-- Starting training on experience 858 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3475
	data_grads_norm = 3.4813
	new_data_grads_norm = 4.8997
	old_data_grads_norm = 3.9515
	sim_grads_norm_tr = 0.1735
-- Starting training on experience 859 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3820
	data_grads_norm = 2.9407
	new_data_grads_norm = 4.6446
	old_data_grads_norm = 3.4729
	sim_grads_norm_tr = 0.0137
-- Starting training on experience 860 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1549
	data_grads_norm = 3.2519
	new_data_grads_norm = 4.2923
	old_data_grads_norm = 4.1262
	sim_grads_norm_tr = 0.1903
-- Starting training on experience 861 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1868
	data_grads_norm = 3.1506
	new_data_grads_norm = 4.5801
	old_data_grads_norm = 3.1581
	sim_grads_norm_tr = 0.1249
-- Starting training on experience 862 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1570
	data_grads_norm = 2.7892
	new_data_grads_norm = 4.3150
	old_data_grads_norm = 3.7512
	sim_grads_norm_tr = -0.2363
-- Starting training on experience 863 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3372
	data_grads_norm = 3.7450
	new_data_grads_norm = 5.0820
	old_data_grads_norm = 4.4288
	sim_grads_norm_tr = 0.0917
-- Starting training on experience 864 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3145
	data_grads_norm = 3.4721
	new_data_grads_norm = 5.5768
	old_data_grads_norm = 5.3630
	sim_grads_norm_tr = -0.1305
-- Starting training on experience 865 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0800
	data_grads_norm = 2.7442
	new_data_grads_norm = 5.5577
	old_data_grads_norm = 2.5660
	sim_grads_norm_tr = -0.1555
-- Starting training on experience 866 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5043
	data_grads_norm = 3.6079
	new_data_grads_norm = 5.0370
	old_data_grads_norm = 3.8767
	sim_grads_norm_tr = 0.2660
-- Starting training on experience 867 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3836
	data_grads_norm = 3.7679
	new_data_grads_norm = 4.7972
	old_data_grads_norm = 3.8189
	sim_grads_norm_tr = 0.4081
-- Starting training on experience 868 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1103
	data_grads_norm = 2.9255
	new_data_grads_norm = 5.3724
	old_data_grads_norm = 2.5513
	sim_grads_norm_tr = -0.0298
-- Starting training on experience 869 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9141
	data_grads_norm = 2.8858
	new_data_grads_norm = 5.4224
	old_data_grads_norm = 2.3644
	sim_grads_norm_tr = 0.1715
-- Starting training on experience 870 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1496
	data_grads_norm = 2.9577
	new_data_grads_norm = 6.1778
	old_data_grads_norm = 2.9783
	sim_grads_norm_tr = -0.1085
-- Starting training on experience 871 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2417
	data_grads_norm = 2.9309
	new_data_grads_norm = 5.4588
	old_data_grads_norm = 2.4108
	sim_grads_norm_tr = -0.2075
-- Starting training on experience 872 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4612
	data_grads_norm = 3.3249
	new_data_grads_norm = 5.3296
	old_data_grads_norm = 3.5209
	sim_grads_norm_tr = -0.0439
-- Starting training on experience 873 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2785
	data_grads_norm = 2.9860
	new_data_grads_norm = 5.1414
	old_data_grads_norm = 2.7606
	sim_grads_norm_tr = -0.0756
-- Starting training on experience 874 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6341
	data_grads_norm = 3.8278
	new_data_grads_norm = 5.8465
	old_data_grads_norm = 4.5519
	sim_grads_norm_tr = 0.0939
-- Starting training on experience 875 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5790
	data_grads_norm = 4.0152
	new_data_grads_norm = 5.3176
	old_data_grads_norm = 4.4383
	sim_grads_norm_tr = 0.2989
-- Starting training on experience 876 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1045
	data_grads_norm = 2.7200
	new_data_grads_norm = 5.0476
	old_data_grads_norm = 2.9032
	sim_grads_norm_tr = -0.2022
-- Starting training on experience 877 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3348
	data_grads_norm = 3.2359
	new_data_grads_norm = 5.1779
	old_data_grads_norm = 3.0984
	sim_grads_norm_tr = -0.0004
-- Starting training on experience 878 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9952
	data_grads_norm = 4.4205
	new_data_grads_norm = 5.1800
	old_data_grads_norm = 5.2473
	sim_grads_norm_tr = 0.4958
-- Starting training on experience 879 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0027
	data_grads_norm = 2.8374
	new_data_grads_norm = 6.1808
	old_data_grads_norm = 2.6100
	sim_grads_norm_tr = -0.0186
-- Starting training on experience 880 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.6260
	data_grads_norm = 2.1634
	new_data_grads_norm = 4.6294
	old_data_grads_norm = 2.8685
	sim_grads_norm_tr = -0.0604
-- Starting training on experience 881 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8723
	data_grads_norm = 3.0879
	new_data_grads_norm = 5.4754
	old_data_grads_norm = 2.3497
	sim_grads_norm_tr = -0.0252
-- Starting training on experience 882 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3341
	data_grads_norm = 2.9287
	new_data_grads_norm = 5.2586
	old_data_grads_norm = 2.9383
	sim_grads_norm_tr = -0.1351
-- Starting training on experience 883 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2632
	data_grads_norm = 3.0206
	new_data_grads_norm = 4.1293
	old_data_grads_norm = 4.3205
	sim_grads_norm_tr = 0.0900
-- Starting training on experience 884 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8609
	data_grads_norm = 2.8788
	new_data_grads_norm = 5.4458
	old_data_grads_norm = 2.6145
	sim_grads_norm_tr = -0.2294
-- Starting training on experience 885 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3499
	data_grads_norm = 3.4969
	new_data_grads_norm = 5.4434
	old_data_grads_norm = 3.1156
	sim_grads_norm_tr = 0.3070
-- Starting training on experience 886 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2195
	data_grads_norm = 2.7359
	new_data_grads_norm = 4.9698
	old_data_grads_norm = 2.8137
	sim_grads_norm_tr = 0.1235
-- Starting training on experience 887 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9802
	data_grads_norm = 2.4397
	new_data_grads_norm = 3.8233
	old_data_grads_norm = 3.7193
	sim_grads_norm_tr = -0.2301
-- Starting training on experience 888 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0280
	data_grads_norm = 2.6477
	new_data_grads_norm = 5.9950
	old_data_grads_norm = 2.2402
	sim_grads_norm_tr = -0.1094
-- Starting training on experience 889 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1010
	data_grads_norm = 2.5747
	new_data_grads_norm = 4.8421
	old_data_grads_norm = 2.9031
	sim_grads_norm_tr = -0.2341
-- Starting training on experience 890 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4352
	data_grads_norm = 3.3702
	new_data_grads_norm = 6.5315
	old_data_grads_norm = 3.0721
	sim_grads_norm_tr = 0.0516
-- Starting training on experience 891 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6274
	data_grads_norm = 3.2800
	new_data_grads_norm = 5.2922
	old_data_grads_norm = 3.4719
	sim_grads_norm_tr = -0.1270
-- Starting training on experience 892 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0560
	data_grads_norm = 3.0671
	new_data_grads_norm = 5.5928
	old_data_grads_norm = 2.7347
	sim_grads_norm_tr = -0.1522
-- Starting training on experience 893 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4674
	data_grads_norm = 3.9024
	new_data_grads_norm = 5.7806
	old_data_grads_norm = 4.5211
	sim_grads_norm_tr = 0.1717
-- Starting training on experience 894 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0160
	data_grads_norm = 2.7917
	new_data_grads_norm = 6.1787
	old_data_grads_norm = 2.2218
	sim_grads_norm_tr = -0.2449
-- Starting training on experience 895 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3610
	data_grads_norm = 3.5017
	new_data_grads_norm = 5.6126
	old_data_grads_norm = 3.1315
	sim_grads_norm_tr = 0.1836
-- Starting training on experience 896 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3004
	data_grads_norm = 3.0778
	new_data_grads_norm = 4.9160
	old_data_grads_norm = 3.2706
	sim_grads_norm_tr = -0.0146
-- Starting training on experience 897 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1541
	data_grads_norm = 3.2151
	new_data_grads_norm = 5.0327
	old_data_grads_norm = 3.5323
	sim_grads_norm_tr = 0.0875
-- Starting training on experience 898 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2140
	data_grads_norm = 3.2453
	new_data_grads_norm = 5.4957
	old_data_grads_norm = 2.6804
	sim_grads_norm_tr = 0.1885
-- Starting training on experience 899 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1282
	data_grads_norm = 4.3980
	new_data_grads_norm = 6.2030
	old_data_grads_norm = 4.3908
	sim_grads_norm_tr = 0.1916
-- Starting training on experience 900 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0361
	data_grads_norm = 2.8748
	new_data_grads_norm = 3.4393
	old_data_grads_norm = 5.7279
	sim_grads_norm_tr = -0.2045
-- Starting training on experience 901 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0592
	data_grads_norm = 2.9393
	new_data_grads_norm = 5.1094
	old_data_grads_norm = 2.9884
	sim_grads_norm_tr = 0.0386
-- Starting training on experience 902 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1300
	data_grads_norm = 2.7617
	new_data_grads_norm = 4.6398
	old_data_grads_norm = 4.2048
	sim_grads_norm_tr = -0.2408
-- Starting training on experience 903 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0170
	data_grads_norm = 2.5886
	new_data_grads_norm = 5.5375
	old_data_grads_norm = 2.8080
	sim_grads_norm_tr = -0.1612
-- Starting training on experience 904 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5202
	data_grads_norm = 3.5053
	new_data_grads_norm = 5.8065
	old_data_grads_norm = 3.2084
	sim_grads_norm_tr = 0.2748
-- Starting training on experience 905 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4032
	data_grads_norm = 3.8486
	new_data_grads_norm = 4.7861
	old_data_grads_norm = 4.6075
	sim_grads_norm_tr = 0.3024
-- Starting training on experience 906 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0822
	data_grads_norm = 3.1711
	new_data_grads_norm = 4.2798
	old_data_grads_norm = 3.5229
	sim_grads_norm_tr = 0.3432
-- Starting training on experience 907 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1155
	data_grads_norm = 3.2151
	new_data_grads_norm = 3.9799
	old_data_grads_norm = 5.6174
	sim_grads_norm_tr = -0.1708
-- Starting training on experience 908 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0280
	data_grads_norm = 3.0784
	new_data_grads_norm = 5.5279
	old_data_grads_norm = 4.3774
	sim_grads_norm_tr = 0.1867
-- Starting training on experience 909 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3021
	data_grads_norm = 2.9495
	new_data_grads_norm = 4.6946
	old_data_grads_norm = 4.0724
	sim_grads_norm_tr = -0.0124
-- Starting training on experience 910 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2814
	data_grads_norm = 3.1162
	new_data_grads_norm = 4.1841
	old_data_grads_norm = 4.5127
	sim_grads_norm_tr = 0.0245
-- Starting training on experience 911 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0456
	data_grads_norm = 2.5070
	new_data_grads_norm = 4.4148
	old_data_grads_norm = 2.8980
	sim_grads_norm_tr = -0.0512
-- Starting training on experience 912 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0059
	data_grads_norm = 2.3525
	new_data_grads_norm = 4.5132
	old_data_grads_norm = 3.2964
	sim_grads_norm_tr = -0.3406
-- Starting training on experience 913 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6131
	data_grads_norm = 3.5524
	new_data_grads_norm = 5.0383
	old_data_grads_norm = 3.9693
	sim_grads_norm_tr = 0.2750
-- Starting training on experience 914 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1557
	data_grads_norm = 3.1677
	new_data_grads_norm = 5.1101
	old_data_grads_norm = 3.2568
	sim_grads_norm_tr = 0.0905
-- Starting training on experience 915 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1588
	data_grads_norm = 3.4788
	new_data_grads_norm = 5.3115
	old_data_grads_norm = 3.7603
	sim_grads_norm_tr = 0.0573
-- Starting training on experience 916 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4322
	data_grads_norm = 4.0072
	new_data_grads_norm = 4.9110
	old_data_grads_norm = 4.9178
	sim_grads_norm_tr = 0.2413
-- Starting training on experience 917 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4375
	data_grads_norm = 3.7878
	new_data_grads_norm = 5.5992
	old_data_grads_norm = 4.0349
	sim_grads_norm_tr = 0.0715
-- Starting training on experience 918 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1979
	data_grads_norm = 3.2506
	new_data_grads_norm = 4.7093
	old_data_grads_norm = 4.1763
	sim_grads_norm_tr = 0.1519
-- Starting training on experience 919 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0577
	data_grads_norm = 2.4065
	new_data_grads_norm = 3.6896
	old_data_grads_norm = 3.3038
	sim_grads_norm_tr = -0.0226
-- Starting training on experience 920 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8707
	data_grads_norm = 2.4298
	new_data_grads_norm = 3.6834
	old_data_grads_norm = 3.5442
	sim_grads_norm_tr = -0.0837
-- Starting training on experience 921 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9388
	data_grads_norm = 2.1472
	new_data_grads_norm = 4.0833
	old_data_grads_norm = 4.0975
	sim_grads_norm_tr = -0.4570
-- Starting training on experience 922 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5045
	data_grads_norm = 3.6215
	new_data_grads_norm = 5.6641
	old_data_grads_norm = 3.2628
	sim_grads_norm_tr = 0.2040
-- Starting training on experience 923 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2602
	data_grads_norm = 3.1549
	new_data_grads_norm = 5.0813
	old_data_grads_norm = 3.6486
	sim_grads_norm_tr = -0.0012
-- Starting training on experience 924 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0977
	data_grads_norm = 3.0823
	new_data_grads_norm = 4.5283
	old_data_grads_norm = 3.9651
	sim_grads_norm_tr = 0.1293
-- Starting training on experience 925 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.7566
	data_grads_norm = 2.2888
	new_data_grads_norm = 4.1655
	old_data_grads_norm = 2.3357
	sim_grads_norm_tr = -0.1666
-- Starting training on experience 926 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4749
	data_grads_norm = 3.7413
	new_data_grads_norm = 5.6544
	old_data_grads_norm = 4.4541
	sim_grads_norm_tr = 0.0113
-- Starting training on experience 927 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2105
	data_grads_norm = 3.6042
	new_data_grads_norm = 5.4638
	old_data_grads_norm = 4.8796
	sim_grads_norm_tr = -0.1417
-- Starting training on experience 928 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3535
	data_grads_norm = 3.8566
	new_data_grads_norm = 5.8764
	old_data_grads_norm = 4.2042
	sim_grads_norm_tr = 0.0507
-- Starting training on experience 929 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8001
	data_grads_norm = 4.4160
	new_data_grads_norm = 5.9760
	old_data_grads_norm = 4.7129
	sim_grads_norm_tr = 0.2428
-- Starting training on experience 930 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9499
	data_grads_norm = 3.1052
	new_data_grads_norm = 5.3030
	old_data_grads_norm = 3.0754
	sim_grads_norm_tr = 0.0192
-- Starting training on experience 931 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4660
	data_grads_norm = 3.5156
	new_data_grads_norm = 5.2534
	old_data_grads_norm = 3.6149
	sim_grads_norm_tr = 0.2080
-- Starting training on experience 932 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1672
	data_grads_norm = 3.2467
	new_data_grads_norm = 5.0178
	old_data_grads_norm = 4.2439
	sim_grads_norm_tr = -0.0015
-- Starting training on experience 933 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2329
	data_grads_norm = 3.4478
	new_data_grads_norm = 5.7127
	old_data_grads_norm = 3.1084
	sim_grads_norm_tr = 0.0443
-- Starting training on experience 934 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3072
	data_grads_norm = 3.7088
	new_data_grads_norm = 5.1997
	old_data_grads_norm = 3.8893
	sim_grads_norm_tr = 0.0866
-- Starting training on experience 935 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3242
	data_grads_norm = 3.2841
	new_data_grads_norm = 5.4288
	old_data_grads_norm = 3.1856
	sim_grads_norm_tr = -0.0734
-- Starting training on experience 936 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1830
	data_grads_norm = 3.4941
	new_data_grads_norm = 5.5404
	old_data_grads_norm = 4.2141
	sim_grads_norm_tr = 0.2365
-- Starting training on experience 937 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9498
	data_grads_norm = 2.5976
	new_data_grads_norm = 4.4184
	old_data_grads_norm = 2.7551
	sim_grads_norm_tr = 0.1291
-- Starting training on experience 938 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9807
	data_grads_norm = 2.7495
	new_data_grads_norm = 4.4084
	old_data_grads_norm = 3.6212
	sim_grads_norm_tr = 0.0850
-- Starting training on experience 939 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0981
	data_grads_norm = 3.4449
	new_data_grads_norm = 4.8958
	old_data_grads_norm = 4.9500
	sim_grads_norm_tr = 0.0517
-- Starting training on experience 940 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0748
	data_grads_norm = 2.6715
	new_data_grads_norm = 4.2949
	old_data_grads_norm = 3.7127
	sim_grads_norm_tr = -0.1839
-- Starting training on experience 941 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2616
	data_grads_norm = 3.6241
	new_data_grads_norm = 6.5560
	old_data_grads_norm = 4.4904
	sim_grads_norm_tr = -0.1028
-- Starting training on experience 942 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3894
	data_grads_norm = 3.7667
	new_data_grads_norm = 4.9956
	old_data_grads_norm = 4.6950
	sim_grads_norm_tr = 0.1518
-- Starting training on experience 943 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0173
	data_grads_norm = 2.9163
	new_data_grads_norm = 4.8160
	old_data_grads_norm = 2.6410
	sim_grads_norm_tr = 0.0334
-- Starting training on experience 944 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2930
	data_grads_norm = 3.4952
	new_data_grads_norm = 5.6102
	old_data_grads_norm = 3.3133
	sim_grads_norm_tr = -0.2430
-- Starting training on experience 945 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3422
	data_grads_norm = 4.0485
	new_data_grads_norm = 5.9867
	old_data_grads_norm = 4.0030
	sim_grads_norm_tr = 0.1469
-- Starting training on experience 946 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5340
	data_grads_norm = 3.8654
	new_data_grads_norm = 6.3658
	old_data_grads_norm = 4.3608
	sim_grads_norm_tr = 0.2634
-- Starting training on experience 947 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8992
	data_grads_norm = 3.5782
	new_data_grads_norm = 6.5410
	old_data_grads_norm = 2.4874
	sim_grads_norm_tr = 0.2266
-- Starting training on experience 948 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0100
	data_grads_norm = 3.3849
	new_data_grads_norm = 5.9309
	old_data_grads_norm = 2.6443
	sim_grads_norm_tr = 0.0845
-- Starting training on experience 949 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3185
	data_grads_norm = 3.1715
	new_data_grads_norm = 5.5209
	old_data_grads_norm = 3.6449
	sim_grads_norm_tr = -0.0588
-- >> End of training phase << --
-- >> Start of eval phase << --
-- Starting eval on experience 0 (Task 0) from test stream --
> Eval on experience 0 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp000 = 0.6758
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.3060
	mb_index = 2850
	time = 769.8038
-- Starting eval on experience 1 (Task 0) from test stream --
> Eval on experience 1 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp001 = 1.3902
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.1810
-- Starting eval on experience 2 (Task 0) from test stream --
> Eval on experience 2 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp002 = 1.3541
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.2530
-- >> End of eval phase << --
	CumulativeAccuracy/eval_phase/test_stream/Exp000 = 0.6115
	CumulativeAccuracy/eval_phase/test_stream/Exp001 = 0.3578
	CumulativeAccuracy/eval_phase/test_stream/Exp002 = 0.2467
	Loss_Stream/eval_phase/test_stream/Task000 = 1.1400
	Top1_Acc_Stream/eval_phase/test_stream/Task000 = 0.2467
	ValidStream/mean_grads_norm_iter = 5.8496
-- >> Start of training phase << --
-- Starting training on experience 0 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0885
	data_grads_norm = 3.6222
	new_data_grads_norm = 6.2894
	old_data_grads_norm = 3.3342
	sim_grads_norm_tr = -0.1207
-- Starting training on experience 1 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9637
	data_grads_norm = 3.1524
	new_data_grads_norm = 5.8361
	old_data_grads_norm = 3.7602
	sim_grads_norm_tr = -0.1616
-- Starting training on experience 2 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2298
	data_grads_norm = 4.3340
	new_data_grads_norm = 6.1852
	old_data_grads_norm = 3.8924
	sim_grads_norm_tr = -0.0657
-- Starting training on experience 3 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9294
	data_grads_norm = 3.3754
	new_data_grads_norm = 6.3651
	old_data_grads_norm = 2.8491
	sim_grads_norm_tr = -0.0793
-- Starting training on experience 4 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9963
	data_grads_norm = 3.2145
	new_data_grads_norm = 6.1510
	old_data_grads_norm = 2.6009
	sim_grads_norm_tr = 0.1031
-- Starting training on experience 5 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5143
	data_grads_norm = 4.0601
	new_data_grads_norm = 5.9959
	old_data_grads_norm = 3.6961
	sim_grads_norm_tr = 0.0398
-- Starting training on experience 6 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0999
	data_grads_norm = 3.9660
	new_data_grads_norm = 6.2422
	old_data_grads_norm = 3.5906
	sim_grads_norm_tr = -0.1056
-- Starting training on experience 7 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4103
	data_grads_norm = 4.4628
	new_data_grads_norm = 6.2948
	old_data_grads_norm = 4.7170
	sim_grads_norm_tr = 0.1475
-- Starting training on experience 8 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7940
	data_grads_norm = 4.4563
	new_data_grads_norm = 6.4817
	old_data_grads_norm = 5.6107
	sim_grads_norm_tr = -0.0089
-- Starting training on experience 9 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5435
	data_grads_norm = 4.3540
	new_data_grads_norm = 7.1514
	old_data_grads_norm = 5.2087
	sim_grads_norm_tr = -0.0131
-- Starting training on experience 10 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3797
	data_grads_norm = 4.4259
	new_data_grads_norm = 6.4087
	old_data_grads_norm = 3.9952
	sim_grads_norm_tr = 0.1342
-- Starting training on experience 11 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0685
	data_grads_norm = 3.2399
	new_data_grads_norm = 6.9421
	old_data_grads_norm = 2.5273
	sim_grads_norm_tr = 0.0233
-- Starting training on experience 12 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2728
	data_grads_norm = 4.2935
	new_data_grads_norm = 6.1396
	old_data_grads_norm = 5.8592
	sim_grads_norm_tr = -0.0366
-- Starting training on experience 13 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1357
	data_grads_norm = 3.6205
	new_data_grads_norm = 6.2758
	old_data_grads_norm = 2.7663
	sim_grads_norm_tr = 0.1155
-- Starting training on experience 14 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5074
	data_grads_norm = 4.1265
	new_data_grads_norm = 6.3998
	old_data_grads_norm = 4.8187
	sim_grads_norm_tr = 0.1506
-- Starting training on experience 15 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0249
	data_grads_norm = 3.4829
	new_data_grads_norm = 6.0844
	old_data_grads_norm = 2.6794
	sim_grads_norm_tr = 0.0147
-- Starting training on experience 16 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3688
	data_grads_norm = 3.8715
	new_data_grads_norm = 6.5403
	old_data_grads_norm = 4.0166
	sim_grads_norm_tr = -0.0362
-- Starting training on experience 17 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1189
	data_grads_norm = 4.0151
	new_data_grads_norm = 6.5181
	old_data_grads_norm = 3.4779
	sim_grads_norm_tr = 0.0166
-- Starting training on experience 18 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9319
	data_grads_norm = 3.0232
	new_data_grads_norm = 5.2215
	old_data_grads_norm = 2.9410
	sim_grads_norm_tr = -0.0630
-- Starting training on experience 19 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9410
	data_grads_norm = 3.7690
	new_data_grads_norm = 6.6653
	old_data_grads_norm = 3.5583
	sim_grads_norm_tr = -0.0021
-- Starting training on experience 20 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1106
	data_grads_norm = 3.4195
	new_data_grads_norm = 6.2732
	old_data_grads_norm = 2.7987
	sim_grads_norm_tr = -0.0626
-- Starting training on experience 21 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0598
	data_grads_norm = 3.2995
	new_data_grads_norm = 5.3261
	old_data_grads_norm = 3.5715
	sim_grads_norm_tr = -0.0097
-- Starting training on experience 22 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4802
	data_grads_norm = 3.8721
	new_data_grads_norm = 5.8770
	old_data_grads_norm = 4.2311
	sim_grads_norm_tr = -0.0010
-- Starting training on experience 23 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4547
	data_grads_norm = 3.6638
	new_data_grads_norm = 5.3594
	old_data_grads_norm = 3.4822
	sim_grads_norm_tr = 0.2577
-- Starting training on experience 24 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0058
	data_grads_norm = 2.9589
	new_data_grads_norm = 5.7942
	old_data_grads_norm = 2.8361
	sim_grads_norm_tr = -0.0222
-- Starting training on experience 25 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3683
	data_grads_norm = 3.7296
	new_data_grads_norm = 5.7522
	old_data_grads_norm = 3.7368
	sim_grads_norm_tr = 0.1850
-- Starting training on experience 26 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0215
	data_grads_norm = 3.5285
	new_data_grads_norm = 5.0755
	old_data_grads_norm = 3.3381
	sim_grads_norm_tr = 0.1247
-- Starting training on experience 27 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5421
	data_grads_norm = 4.2963
	new_data_grads_norm = 5.8122
	old_data_grads_norm = 4.6518
	sim_grads_norm_tr = 0.2966
-- Starting training on experience 28 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8987
	data_grads_norm = 3.4676
	new_data_grads_norm = 5.2720
	old_data_grads_norm = 3.7343
	sim_grads_norm_tr = -0.0977
-- Starting training on experience 29 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2873
	data_grads_norm = 3.8186
	new_data_grads_norm = 5.7718
	old_data_grads_norm = 3.8706
	sim_grads_norm_tr = 0.1937
-- Starting training on experience 30 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0927
	data_grads_norm = 3.5909
	new_data_grads_norm = 5.4774
	old_data_grads_norm = 4.0334
	sim_grads_norm_tr = 0.1207
-- Starting training on experience 31 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9124
	data_grads_norm = 3.8874
	new_data_grads_norm = 5.7100
	old_data_grads_norm = 3.8916
	sim_grads_norm_tr = 0.3354
-- Starting training on experience 32 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6242
	data_grads_norm = 2.5791
	new_data_grads_norm = 4.7095
	old_data_grads_norm = 3.4876
	sim_grads_norm_tr = -0.2783
-- Starting training on experience 33 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0414
	data_grads_norm = 3.5592
	new_data_grads_norm = 5.1264
	old_data_grads_norm = 3.1268
	sim_grads_norm_tr = 0.1684
-- Starting training on experience 34 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4904
	data_grads_norm = 2.6604
	new_data_grads_norm = 4.7706
	old_data_grads_norm = 2.7198
	sim_grads_norm_tr = -0.1803
-- Starting training on experience 35 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6346
	data_grads_norm = 2.8595
	new_data_grads_norm = 5.5789
	old_data_grads_norm = 3.1895
	sim_grads_norm_tr = 0.1360
-- Starting training on experience 36 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0271
	data_grads_norm = 3.3653
	new_data_grads_norm = 5.6652
	old_data_grads_norm = 4.0011
	sim_grads_norm_tr = -0.0677
-- Starting training on experience 37 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9603
	data_grads_norm = 3.5455
	new_data_grads_norm = 5.4965
	old_data_grads_norm = 3.8434
	sim_grads_norm_tr = -0.1511
-- Starting training on experience 38 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9866
	data_grads_norm = 3.1776
	new_data_grads_norm = 5.8458
	old_data_grads_norm = 2.9738
	sim_grads_norm_tr = 0.0009
-- Starting training on experience 39 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0155
	data_grads_norm = 4.1597
	new_data_grads_norm = 6.1668
	old_data_grads_norm = 4.5399
	sim_grads_norm_tr = -0.0229
-- Starting training on experience 40 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9794
	data_grads_norm = 3.4439
	new_data_grads_norm = 5.3669
	old_data_grads_norm = 3.6772
	sim_grads_norm_tr = 0.0238
-- Starting training on experience 41 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9437
	data_grads_norm = 4.2049
	new_data_grads_norm = 5.9682
	old_data_grads_norm = 3.6670
	sim_grads_norm_tr = 0.0227
-- Starting training on experience 42 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1077
	data_grads_norm = 3.7413
	new_data_grads_norm = 5.2010
	old_data_grads_norm = 3.6749
	sim_grads_norm_tr = 0.2154
-- Starting training on experience 43 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7713
	data_grads_norm = 3.4165
	new_data_grads_norm = 5.1203
	old_data_grads_norm = 3.6630
	sim_grads_norm_tr = 0.1266
-- Starting training on experience 44 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7494
	data_grads_norm = 3.0620
	new_data_grads_norm = 4.8951
	old_data_grads_norm = 3.0433
	sim_grads_norm_tr = 0.0731
-- Starting training on experience 45 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8758
	data_grads_norm = 3.7392
	new_data_grads_norm = 5.1369
	old_data_grads_norm = 4.0977
	sim_grads_norm_tr = 0.2440
-- Starting training on experience 46 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5057
	data_grads_norm = 2.9321
	new_data_grads_norm = 5.7383
	old_data_grads_norm = 2.9942
	sim_grads_norm_tr = -0.1633
-- Starting training on experience 47 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5475
	data_grads_norm = 3.1702
	new_data_grads_norm = 5.8260
	old_data_grads_norm = 3.2041
	sim_grads_norm_tr = -0.2109
-- Starting training on experience 48 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7941
	data_grads_norm = 3.1106
	new_data_grads_norm = 4.5109
	old_data_grads_norm = 3.8519
	sim_grads_norm_tr = -0.0381
-- Starting training on experience 49 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8141
	data_grads_norm = 4.1017
	new_data_grads_norm = 5.3034
	old_data_grads_norm = 4.5739
	sim_grads_norm_tr = 0.2110
-- Starting training on experience 50 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8074
	data_grads_norm = 3.4479
	new_data_grads_norm = 5.0812
	old_data_grads_norm = 4.5198
	sim_grads_norm_tr = 0.0001
-- Starting training on experience 51 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3813
	data_grads_norm = 2.8520
	new_data_grads_norm = 4.6916
	old_data_grads_norm = 3.6311
	sim_grads_norm_tr = -0.0950
-- Starting training on experience 52 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7151
	data_grads_norm = 3.3645
	new_data_grads_norm = 4.7867
	old_data_grads_norm = 5.0855
	sim_grads_norm_tr = -0.2621
-- Starting training on experience 53 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0764
	data_grads_norm = 3.3204
	new_data_grads_norm = 5.3496
	old_data_grads_norm = 3.6466
	sim_grads_norm_tr = 0.2187
-- Starting training on experience 54 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9620
	data_grads_norm = 3.9028
	new_data_grads_norm = 5.3914
	old_data_grads_norm = 4.6331
	sim_grads_norm_tr = 0.1351
-- Starting training on experience 55 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7575
	data_grads_norm = 3.6325
	new_data_grads_norm = 5.4015
	old_data_grads_norm = 3.7496
	sim_grads_norm_tr = 0.0785
-- Starting training on experience 56 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6824
	data_grads_norm = 3.5582
	new_data_grads_norm = 6.1273
	old_data_grads_norm = 4.0724
	sim_grads_norm_tr = -0.0544
-- Starting training on experience 57 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2182
	data_grads_norm = 3.7787
	new_data_grads_norm = 5.2625
	old_data_grads_norm = 4.4920
	sim_grads_norm_tr = 0.1114
-- Starting training on experience 58 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9135
	data_grads_norm = 3.2045
	new_data_grads_norm = 5.2267
	old_data_grads_norm = 3.8194
	sim_grads_norm_tr = 0.0752
-- Starting training on experience 59 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9982
	data_grads_norm = 3.8316
	new_data_grads_norm = 5.4611
	old_data_grads_norm = 4.3560
	sim_grads_norm_tr = 0.0609
-- Starting training on experience 60 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3866
	data_grads_norm = 4.0536
	new_data_grads_norm = 5.4308
	old_data_grads_norm = 4.5889
	sim_grads_norm_tr = 0.3352
-- Starting training on experience 61 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5124
	data_grads_norm = 2.5862
	new_data_grads_norm = 5.1037
	old_data_grads_norm = 2.7593
	sim_grads_norm_tr = -0.2638
-- Starting training on experience 62 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7879
	data_grads_norm = 3.6733
	new_data_grads_norm = 5.1166
	old_data_grads_norm = 2.9121
	sim_grads_norm_tr = 0.1622
-- Starting training on experience 63 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9803
	data_grads_norm = 3.6642
	new_data_grads_norm = 5.4931
	old_data_grads_norm = 4.0810
	sim_grads_norm_tr = 0.1979
-- Starting training on experience 64 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4643
	data_grads_norm = 3.0999
	new_data_grads_norm = 4.8373
	old_data_grads_norm = 2.7477
	sim_grads_norm_tr = -0.1148
-- Starting training on experience 65 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4285
	data_grads_norm = 3.2697
	new_data_grads_norm = 5.3901
	old_data_grads_norm = 3.9844
	sim_grads_norm_tr = -0.1318
-- Starting training on experience 66 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9586
	data_grads_norm = 4.2438
	new_data_grads_norm = 5.2721
	old_data_grads_norm = 4.8796
	sim_grads_norm_tr = 0.1941
-- Starting training on experience 67 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0006
	data_grads_norm = 4.2905
	new_data_grads_norm = 5.2488
	old_data_grads_norm = 4.5369
	sim_grads_norm_tr = 0.4754
-- Starting training on experience 68 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4748
	data_grads_norm = 2.8173
	new_data_grads_norm = 3.9106
	old_data_grads_norm = 3.8067
	sim_grads_norm_tr = -0.0462
-- Starting training on experience 69 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3821
	data_grads_norm = 2.5944
	new_data_grads_norm = 4.2013
	old_data_grads_norm = 3.7064
	sim_grads_norm_tr = -0.0875
-- Starting training on experience 70 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3207
	data_grads_norm = 2.3673
	new_data_grads_norm = 4.5488
	old_data_grads_norm = 2.2246
	sim_grads_norm_tr = -0.1480
-- Starting training on experience 71 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2887
	data_grads_norm = 2.3202
	new_data_grads_norm = 4.2078
	old_data_grads_norm = 2.8951
	sim_grads_norm_tr = -0.2246
-- Starting training on experience 72 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6187
	data_grads_norm = 3.3657
	new_data_grads_norm = 5.1651
	old_data_grads_norm = 4.0361
	sim_grads_norm_tr = -0.0464
-- Starting training on experience 73 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9199
	data_grads_norm = 3.8531
	new_data_grads_norm = 5.7470
	old_data_grads_norm = 4.1650
	sim_grads_norm_tr = -0.1954
-- Starting training on experience 74 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0472
	data_grads_norm = 4.0728
	new_data_grads_norm = 5.7369
	old_data_grads_norm = 4.5437
	sim_grads_norm_tr = 0.1562
-- Starting training on experience 75 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0455
	data_grads_norm = 3.9755
	new_data_grads_norm = 5.1384
	old_data_grads_norm = 4.2345
	sim_grads_norm_tr = 0.0611
-- Starting training on experience 76 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6450
	data_grads_norm = 3.8014
	new_data_grads_norm = 5.6300
	old_data_grads_norm = 2.3610
	sim_grads_norm_tr = 0.0117
-- Starting training on experience 77 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9010
	data_grads_norm = 4.0118
	new_data_grads_norm = 5.4659
	old_data_grads_norm = 3.5110
	sim_grads_norm_tr = 0.5071
-- Starting training on experience 78 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4349
	data_grads_norm = 3.3806
	new_data_grads_norm = 5.2001
	old_data_grads_norm = 3.2712
	sim_grads_norm_tr = 0.0820
-- Starting training on experience 79 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2834
	data_grads_norm = 2.6017
	new_data_grads_norm = 4.4362
	old_data_grads_norm = 2.7457
	sim_grads_norm_tr = -0.0505
-- Starting training on experience 80 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2967
	data_grads_norm = 2.6130
	new_data_grads_norm = 5.4475
	old_data_grads_norm = 3.0837
	sim_grads_norm_tr = -0.0971
-- Starting training on experience 81 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4170
	data_grads_norm = 3.2825
	new_data_grads_norm = 4.1252
	old_data_grads_norm = 4.9726
	sim_grads_norm_tr = -0.2452
-- Starting training on experience 82 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5267
	data_grads_norm = 3.0175
	new_data_grads_norm = 5.3166
	old_data_grads_norm = 3.9058
	sim_grads_norm_tr = -0.1875
-- Starting training on experience 83 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3882
	data_grads_norm = 3.2020
	new_data_grads_norm = 5.7115
	old_data_grads_norm = 4.1331
	sim_grads_norm_tr = -0.0938
-- Starting training on experience 84 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4165
	data_grads_norm = 4.3432
	new_data_grads_norm = 5.9317
	old_data_grads_norm = 5.5006
	sim_grads_norm_tr = 0.1449
-- Starting training on experience 85 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9788
	data_grads_norm = 3.6571
	new_data_grads_norm = 5.8989
	old_data_grads_norm = 3.4232
	sim_grads_norm_tr = -0.0542
-- Starting training on experience 86 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8826
	data_grads_norm = 3.9785
	new_data_grads_norm = 5.8243
	old_data_grads_norm = 3.2199
	sim_grads_norm_tr = 0.3377
-- Starting training on experience 87 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4068
	data_grads_norm = 2.6488
	new_data_grads_norm = 4.9163
	old_data_grads_norm = 3.3299
	sim_grads_norm_tr = -0.2366
-- Starting training on experience 88 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8281
	data_grads_norm = 4.0882
	new_data_grads_norm = 5.5580
	old_data_grads_norm = 4.3607
	sim_grads_norm_tr = 0.0349
-- Starting training on experience 89 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5428
	data_grads_norm = 3.6427
	new_data_grads_norm = 5.4702
	old_data_grads_norm = 4.7402
	sim_grads_norm_tr = -0.0695
-- Starting training on experience 90 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7161
	data_grads_norm = 3.1797
	new_data_grads_norm = 4.9103
	old_data_grads_norm = 4.3888
	sim_grads_norm_tr = -0.1951
-- Starting training on experience 91 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3124
	data_grads_norm = 4.4240
	new_data_grads_norm = 5.8651
	old_data_grads_norm = 4.3974
	sim_grads_norm_tr = 0.5910
-- Starting training on experience 92 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7515
	data_grads_norm = 3.8949
	new_data_grads_norm = 5.1123
	old_data_grads_norm = 3.7645
	sim_grads_norm_tr = 0.3026
-- Starting training on experience 93 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1023
	data_grads_norm = 2.6769
	new_data_grads_norm = 4.6854
	old_data_grads_norm = 4.2603
	sim_grads_norm_tr = -0.1834
-- Starting training on experience 94 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7296
	data_grads_norm = 3.7483
	new_data_grads_norm = 5.5294
	old_data_grads_norm = 4.2546
	sim_grads_norm_tr = 0.0671
-- Starting training on experience 95 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6300
	data_grads_norm = 2.9317
	new_data_grads_norm = 5.2797
	old_data_grads_norm = 3.7500
	sim_grads_norm_tr = -0.1117
-- Starting training on experience 96 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6749
	data_grads_norm = 3.6378
	new_data_grads_norm = 5.2518
	old_data_grads_norm = 3.9201
	sim_grads_norm_tr = 0.2032
-- Starting training on experience 97 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4337
	data_grads_norm = 3.0441
	new_data_grads_norm = 4.8311
	old_data_grads_norm = 3.6676
	sim_grads_norm_tr = 0.0575
-- Starting training on experience 98 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3680
	data_grads_norm = 2.8357
	new_data_grads_norm = 5.3230
	old_data_grads_norm = 3.3938
	sim_grads_norm_tr = -0.0212
-- Starting training on experience 99 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1205
	data_grads_norm = 4.2583
	new_data_grads_norm = 6.1812
	old_data_grads_norm = 4.1251
	sim_grads_norm_tr = 0.3198
-- Starting training on experience 100 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9584
	data_grads_norm = 3.4405
	new_data_grads_norm = 4.7982
	old_data_grads_norm = 4.2895
	sim_grads_norm_tr = 0.0691
-- Starting training on experience 101 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5774
	data_grads_norm = 3.1840
	new_data_grads_norm = 5.4484
	old_data_grads_norm = 3.7827
	sim_grads_norm_tr = -0.1139
-- Starting training on experience 102 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2133
	data_grads_norm = 4.2770
	new_data_grads_norm = 5.4221
	old_data_grads_norm = 4.5628
	sim_grads_norm_tr = 0.3344
-- Starting training on experience 103 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3712
	data_grads_norm = 2.7182
	new_data_grads_norm = 4.7143
	old_data_grads_norm = 2.9319
	sim_grads_norm_tr = -0.1461
-- Starting training on experience 104 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5795
	data_grads_norm = 3.1088
	new_data_grads_norm = 4.5624
	old_data_grads_norm = 3.7207
	sim_grads_norm_tr = 0.1737
-- Starting training on experience 105 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2793
	data_grads_norm = 2.9007
	new_data_grads_norm = 4.6087
	old_data_grads_norm = 3.5756
	sim_grads_norm_tr = -0.2297
-- Starting training on experience 106 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0602
	data_grads_norm = 3.8706
	new_data_grads_norm = 5.0779
	old_data_grads_norm = 4.4525
	sim_grads_norm_tr = 0.3339
-- Starting training on experience 107 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7672
	data_grads_norm = 3.4214
	new_data_grads_norm = 5.1540
	old_data_grads_norm = 3.6756
	sim_grads_norm_tr = 0.1863
-- Starting training on experience 108 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2990
	data_grads_norm = 2.7570
	new_data_grads_norm = 4.8215
	old_data_grads_norm = 3.4783
	sim_grads_norm_tr = -0.2078
-- Starting training on experience 109 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6702
	data_grads_norm = 3.0816
	new_data_grads_norm = 5.1799
	old_data_grads_norm = 3.0013
	sim_grads_norm_tr = 0.1968
-- Starting training on experience 110 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5154
	data_grads_norm = 2.9755
	new_data_grads_norm = 5.1601
	old_data_grads_norm = 4.4177
	sim_grads_norm_tr = -0.2014
-- Starting training on experience 111 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4436
	data_grads_norm = 3.2327
	new_data_grads_norm = 5.9626
	old_data_grads_norm = 2.6009
	sim_grads_norm_tr = 0.0950
-- Starting training on experience 112 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1462
	data_grads_norm = 4.4314
	new_data_grads_norm = 6.1854
	old_data_grads_norm = 5.8921
	sim_grads_norm_tr = 0.1180
-- Starting training on experience 113 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3646
	data_grads_norm = 2.1228
	new_data_grads_norm = 4.1495
	old_data_grads_norm = 3.5229
	sim_grads_norm_tr = -0.2856
-- Starting training on experience 114 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5689
	data_grads_norm = 3.4412
	new_data_grads_norm = 5.3627
	old_data_grads_norm = 3.7658
	sim_grads_norm_tr = 0.0084
-- Starting training on experience 115 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7290
	data_grads_norm = 2.9947
	new_data_grads_norm = 5.0820
	old_data_grads_norm = 3.5348
	sim_grads_norm_tr = -0.1486
-- Starting training on experience 116 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5433
	data_grads_norm = 3.1969
	new_data_grads_norm = 5.6089
	old_data_grads_norm = 3.1964
	sim_grads_norm_tr = -0.2604
-- Starting training on experience 117 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9146
	data_grads_norm = 3.9501
	new_data_grads_norm = 5.8621
	old_data_grads_norm = 3.3736
	sim_grads_norm_tr = 0.2879
-- Starting training on experience 118 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0942
	data_grads_norm = 4.1785
	new_data_grads_norm = 5.5610
	old_data_grads_norm = 4.8939
	sim_grads_norm_tr = 0.2324
-- Starting training on experience 119 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8233
	data_grads_norm = 3.7475
	new_data_grads_norm = 5.3005
	old_data_grads_norm = 3.8413
	sim_grads_norm_tr = 0.0543
-- Starting training on experience 120 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5541
	data_grads_norm = 2.7029
	new_data_grads_norm = 4.6040
	old_data_grads_norm = 3.9718
	sim_grads_norm_tr = -0.1851
-- Starting training on experience 121 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9679
	data_grads_norm = 3.9104
	new_data_grads_norm = 5.8409
	old_data_grads_norm = 3.6993
	sim_grads_norm_tr = 0.2583
-- Starting training on experience 122 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3816
	data_grads_norm = 3.3149
	new_data_grads_norm = 5.1487
	old_data_grads_norm = 3.5423
	sim_grads_norm_tr = -0.0424
-- Starting training on experience 123 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5980
	data_grads_norm = 3.3356
	new_data_grads_norm = 5.6489
	old_data_grads_norm = 2.8048
	sim_grads_norm_tr = 0.1482
-- Starting training on experience 124 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6972
	data_grads_norm = 3.6050
	new_data_grads_norm = 5.3204
	old_data_grads_norm = 4.8214
	sim_grads_norm_tr = -0.0097
-- Starting training on experience 125 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4760
	data_grads_norm = 3.2183
	new_data_grads_norm = 5.4708
	old_data_grads_norm = 4.0113
	sim_grads_norm_tr = -0.0279
-- Starting training on experience 126 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1117
	data_grads_norm = 3.6623
	new_data_grads_norm = 5.4099
	old_data_grads_norm = 4.8021
	sim_grads_norm_tr = 0.2043
-- Starting training on experience 127 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5934
	data_grads_norm = 2.8573
	new_data_grads_norm = 4.7213
	old_data_grads_norm = 3.7753
	sim_grads_norm_tr = -0.0184
-- Starting training on experience 128 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7062
	data_grads_norm = 3.2779
	new_data_grads_norm = 4.6632
	old_data_grads_norm = 3.3639
	sim_grads_norm_tr = 0.3001
-- Starting training on experience 129 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5609
	data_grads_norm = 3.9165
	new_data_grads_norm = 5.2286
	old_data_grads_norm = 3.9864
	sim_grads_norm_tr = 0.1258
-- Starting training on experience 130 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7064
	data_grads_norm = 3.2889
	new_data_grads_norm = 4.5879
	old_data_grads_norm = 3.6712
	sim_grads_norm_tr = 0.1844
-- Starting training on experience 131 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4496
	data_grads_norm = 3.1936
	new_data_grads_norm = 4.4346
	old_data_grads_norm = 3.5413
	sim_grads_norm_tr = 0.1533
-- Starting training on experience 132 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2103
	data_grads_norm = 2.1709
	new_data_grads_norm = 4.3807
	old_data_grads_norm = 2.8991
	sim_grads_norm_tr = -0.1785
-- Starting training on experience 133 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5165
	data_grads_norm = 2.8167
	new_data_grads_norm = 4.1849
	old_data_grads_norm = 3.6191
	sim_grads_norm_tr = -0.0056
-- Starting training on experience 134 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8367
	data_grads_norm = 3.1065
	new_data_grads_norm = 5.1511
	old_data_grads_norm = 3.5679
	sim_grads_norm_tr = 0.0681
-- Starting training on experience 135 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8010
	data_grads_norm = 3.5175
	new_data_grads_norm = 4.7511
	old_data_grads_norm = 3.6006
	sim_grads_norm_tr = 0.2236
-- Starting training on experience 136 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6280
	data_grads_norm = 3.2122
	new_data_grads_norm = 4.5954
	old_data_grads_norm = 3.3538
	sim_grads_norm_tr = 0.2337
-- Starting training on experience 137 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4252
	data_grads_norm = 3.1662
	new_data_grads_norm = 5.1160
	old_data_grads_norm = 3.3995
	sim_grads_norm_tr = 0.2521
-- Starting training on experience 138 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3730
	data_grads_norm = 2.7666
	new_data_grads_norm = 4.3587
	old_data_grads_norm = 4.5615
	sim_grads_norm_tr = -0.2410
-- Starting training on experience 139 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6538
	data_grads_norm = 3.1940
	new_data_grads_norm = 5.0741
	old_data_grads_norm = 3.6205
	sim_grads_norm_tr = 0.0310
-- Starting training on experience 140 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7898
	data_grads_norm = 3.5763
	new_data_grads_norm = 5.7393
	old_data_grads_norm = 4.6988
	sim_grads_norm_tr = -0.0009
-- Starting training on experience 141 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6119
	data_grads_norm = 2.9189
	new_data_grads_norm = 5.2682
	old_data_grads_norm = 2.8124
	sim_grads_norm_tr = 0.0766
-- Starting training on experience 142 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8155
	data_grads_norm = 3.7217
	new_data_grads_norm = 5.7740
	old_data_grads_norm = 5.0519
	sim_grads_norm_tr = 0.1438
-- Starting training on experience 143 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3226
	data_grads_norm = 3.1891
	new_data_grads_norm = 5.2605
	old_data_grads_norm = 3.5426
	sim_grads_norm_tr = -0.1146
-- Starting training on experience 144 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8270
	data_grads_norm = 3.9003
	new_data_grads_norm = 5.4182
	old_data_grads_norm = 5.3251
	sim_grads_norm_tr = 0.0995
-- Starting training on experience 145 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8777
	data_grads_norm = 4.2026
	new_data_grads_norm = 5.3665
	old_data_grads_norm = 3.8269
	sim_grads_norm_tr = 0.3738
-- Starting training on experience 146 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0872
	data_grads_norm = 4.0450
	new_data_grads_norm = 5.3588
	old_data_grads_norm = 5.5770
	sim_grads_norm_tr = 0.0483
-- Starting training on experience 147 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9710
	data_grads_norm = 3.6008
	new_data_grads_norm = 4.6939
	old_data_grads_norm = 5.2976
	sim_grads_norm_tr = -0.0016
-- Starting training on experience 148 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6614
	data_grads_norm = 3.3231
	new_data_grads_norm = 5.0126
	old_data_grads_norm = 3.6912
	sim_grads_norm_tr = 0.2190
-- Starting training on experience 149 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7028
	data_grads_norm = 3.5381
	new_data_grads_norm = 5.4013
	old_data_grads_norm = 4.8174
	sim_grads_norm_tr = -0.1814
-- Starting training on experience 150 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8420
	data_grads_norm = 3.7843
	new_data_grads_norm = 5.1712
	old_data_grads_norm = 3.9120
	sim_grads_norm_tr = 0.2233
-- Starting training on experience 151 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5028
	data_grads_norm = 3.5531
	new_data_grads_norm = 4.7439
	old_data_grads_norm = 4.8566
	sim_grads_norm_tr = -0.0196
-- Starting training on experience 152 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6686
	data_grads_norm = 3.4613
	new_data_grads_norm = 4.7530
	old_data_grads_norm = 4.5694
	sim_grads_norm_tr = -0.0722
-- Starting training on experience 153 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5445
	data_grads_norm = 3.5528
	new_data_grads_norm = 5.7451
	old_data_grads_norm = 3.3920
	sim_grads_norm_tr = 0.0931
-- Starting training on experience 154 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6513
	data_grads_norm = 3.9499
	new_data_grads_norm = 6.2709
	old_data_grads_norm = 5.0522
	sim_grads_norm_tr = -0.0117
-- Starting training on experience 155 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3012
	data_grads_norm = 2.7099
	new_data_grads_norm = 5.1953
	old_data_grads_norm = 3.0819
	sim_grads_norm_tr = -0.2511
-- Starting training on experience 156 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8011
	data_grads_norm = 3.8693
	new_data_grads_norm = 5.0866
	old_data_grads_norm = 3.9914
	sim_grads_norm_tr = 0.0688
-- Starting training on experience 157 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8770
	data_grads_norm = 4.1397
	new_data_grads_norm = 5.7888
	old_data_grads_norm = 4.3415
	sim_grads_norm_tr = 0.4144
-- Starting training on experience 158 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5953
	data_grads_norm = 3.4690
	new_data_grads_norm = 4.6161
	old_data_grads_norm = 4.4320
	sim_grads_norm_tr = 0.1618
-- Starting training on experience 159 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4511
	data_grads_norm = 3.1648
	new_data_grads_norm = 4.6651
	old_data_grads_norm = 4.1579
	sim_grads_norm_tr = 0.0033
-- Starting training on experience 160 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4101
	data_grads_norm = 3.0900
	new_data_grads_norm = 4.9265
	old_data_grads_norm = 3.3585
	sim_grads_norm_tr = -0.0016
-- Starting training on experience 161 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4099
	data_grads_norm = 3.0944
	new_data_grads_norm = 4.4453
	old_data_grads_norm = 4.1688
	sim_grads_norm_tr = 0.0034
-- Starting training on experience 162 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6917
	data_grads_norm = 3.4399
	new_data_grads_norm = 5.7483
	old_data_grads_norm = 4.2009
	sim_grads_norm_tr = -0.0463
-- Starting training on experience 163 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5566
	data_grads_norm = 3.4995
	new_data_grads_norm = 4.9028
	old_data_grads_norm = 3.3316
	sim_grads_norm_tr = 0.0955
-- Starting training on experience 164 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3006
	data_grads_norm = 2.2934
	new_data_grads_norm = 4.8568
	old_data_grads_norm = 3.8496
	sim_grads_norm_tr = -0.3409
-- Starting training on experience 165 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6638
	data_grads_norm = 3.6318
	new_data_grads_norm = 5.6768
	old_data_grads_norm = 3.6014
	sim_grads_norm_tr = 0.3412
-- Starting training on experience 166 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8025
	data_grads_norm = 3.3983
	new_data_grads_norm = 4.7499
	old_data_grads_norm = 4.8906
	sim_grads_norm_tr = -0.0477
-- Starting training on experience 167 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4838
	data_grads_norm = 2.9967
	new_data_grads_norm = 5.0962
	old_data_grads_norm = 2.5241
	sim_grads_norm_tr = 0.0334
-- Starting training on experience 168 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5672
	data_grads_norm = 3.1523
	new_data_grads_norm = 4.4979
	old_data_grads_norm = 4.6550
	sim_grads_norm_tr = -0.0120
-- Starting training on experience 169 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6275
	data_grads_norm = 3.3629
	new_data_grads_norm = 4.3725
	old_data_grads_norm = 3.8487
	sim_grads_norm_tr = 0.0899
-- Starting training on experience 170 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5273
	data_grads_norm = 2.7242
	new_data_grads_norm = 4.1890
	old_data_grads_norm = 3.3186
	sim_grads_norm_tr = 0.1462
-- Starting training on experience 171 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2996
	data_grads_norm = 2.7190
	new_data_grads_norm = 4.2498
	old_data_grads_norm = 3.8634
	sim_grads_norm_tr = -0.1838
-- Starting training on experience 172 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5801
	data_grads_norm = 3.8196
	new_data_grads_norm = 4.9289
	old_data_grads_norm = 4.4020
	sim_grads_norm_tr = 0.2279
-- Starting training on experience 173 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1880
	data_grads_norm = 2.9701
	new_data_grads_norm = 4.6421
	old_data_grads_norm = 3.9186
	sim_grads_norm_tr = -0.2297
-- Starting training on experience 174 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2108
	data_grads_norm = 2.5182
	new_data_grads_norm = 5.0795
	old_data_grads_norm = 2.7791
	sim_grads_norm_tr = 0.0603
-- Starting training on experience 175 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3591
	data_grads_norm = 3.3984
	new_data_grads_norm = 4.8822
	old_data_grads_norm = 4.8934
	sim_grads_norm_tr = -0.0459
-- Starting training on experience 176 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4530
	data_grads_norm = 3.1900
	new_data_grads_norm = 5.0803
	old_data_grads_norm = 4.9467
	sim_grads_norm_tr = -0.1470
-- Starting training on experience 177 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7569
	data_grads_norm = 3.8097
	new_data_grads_norm = 5.6192
	old_data_grads_norm = 3.9142
	sim_grads_norm_tr = 0.1666
-- Starting training on experience 178 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4653
	data_grads_norm = 3.9388
	new_data_grads_norm = 5.1180
	old_data_grads_norm = 4.0251
	sim_grads_norm_tr = -0.2324
-- Starting training on experience 179 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8596
	data_grads_norm = 4.4241
	new_data_grads_norm = 6.8545
	old_data_grads_norm = 3.8884
	sim_grads_norm_tr = 0.0992
-- Starting training on experience 180 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5691
	data_grads_norm = 3.6604
	new_data_grads_norm = 5.7061
	old_data_grads_norm = 4.0373
	sim_grads_norm_tr = -0.1042
-- Starting training on experience 181 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9342
	data_grads_norm = 4.6764
	new_data_grads_norm = 6.7843
	old_data_grads_norm = 4.1419
	sim_grads_norm_tr = 0.2218
-- Starting training on experience 182 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6349
	data_grads_norm = 3.3619
	new_data_grads_norm = 5.6836
	old_data_grads_norm = 3.2829
	sim_grads_norm_tr = -0.0232
-- Starting training on experience 183 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8661
	data_grads_norm = 3.6435
	new_data_grads_norm = 5.8184
	old_data_grads_norm = 3.7431
	sim_grads_norm_tr = -0.0752
-- Starting training on experience 184 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5874
	data_grads_norm = 3.5356
	new_data_grads_norm = 5.4346
	old_data_grads_norm = 3.5456
	sim_grads_norm_tr = 0.0828
-- Starting training on experience 185 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1535
	data_grads_norm = 2.7234
	new_data_grads_norm = 5.8614
	old_data_grads_norm = 2.6676
	sim_grads_norm_tr = -0.2148
-- Starting training on experience 186 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5745
	data_grads_norm = 3.1327
	new_data_grads_norm = 5.3714
	old_data_grads_norm = 3.1244
	sim_grads_norm_tr = 0.0472
-- Starting training on experience 187 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0577
	data_grads_norm = 4.1719
	new_data_grads_norm = 7.2060
	old_data_grads_norm = 4.1261
	sim_grads_norm_tr = 0.3177
-- Starting training on experience 188 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8367
	data_grads_norm = 3.9995
	new_data_grads_norm = 5.5727
	old_data_grads_norm = 4.0812
	sim_grads_norm_tr = -0.0610
-- Starting training on experience 189 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7824
	data_grads_norm = 3.5122
	new_data_grads_norm = 5.3247
	old_data_grads_norm = 4.9414
	sim_grads_norm_tr = -0.0882
-- Starting training on experience 190 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6662
	data_grads_norm = 3.6260
	new_data_grads_norm = 6.3981
	old_data_grads_norm = 4.1386
	sim_grads_norm_tr = -0.1271
-- Starting training on experience 191 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2481
	data_grads_norm = 4.5535
	new_data_grads_norm = 6.3070
	old_data_grads_norm = 4.4092
	sim_grads_norm_tr = 0.3497
-- Starting training on experience 192 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6761
	data_grads_norm = 3.9160
	new_data_grads_norm = 5.8437
	old_data_grads_norm = 4.4543
	sim_grads_norm_tr = 0.1139
-- Starting training on experience 193 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3459
	data_grads_norm = 3.2658
	new_data_grads_norm = 5.8778
	old_data_grads_norm = 3.5079
	sim_grads_norm_tr = 0.0372
-- Starting training on experience 194 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7554
	data_grads_norm = 3.5855
	new_data_grads_norm = 5.4256
	old_data_grads_norm = 4.1801
	sim_grads_norm_tr = 0.1872
-- Starting training on experience 195 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8503
	data_grads_norm = 4.2176
	new_data_grads_norm = 5.6645
	old_data_grads_norm = 4.4494
	sim_grads_norm_tr = 0.2272
-- Starting training on experience 196 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3777
	data_grads_norm = 3.2093
	new_data_grads_norm = 4.9969
	old_data_grads_norm = 3.0348
	sim_grads_norm_tr = 0.0867
-- Starting training on experience 197 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2774
	data_grads_norm = 2.9659
	new_data_grads_norm = 5.4393
	old_data_grads_norm = 3.2364
	sim_grads_norm_tr = -0.2012
-- Starting training on experience 198 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2592
	data_grads_norm = 3.1624
	new_data_grads_norm = 5.3130
	old_data_grads_norm = 3.7174
	sim_grads_norm_tr = -0.1419
-- Starting training on experience 199 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8162
	data_grads_norm = 4.3281
	new_data_grads_norm = 4.8964
	old_data_grads_norm = 4.4224
	sim_grads_norm_tr = 0.1373
-- Starting training on experience 200 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3333
	data_grads_norm = 2.9470
	new_data_grads_norm = 5.3667
	old_data_grads_norm = 4.8080
	sim_grads_norm_tr = -0.2040
-- Starting training on experience 201 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6037
	data_grads_norm = 2.8421
	new_data_grads_norm = 4.8813
	old_data_grads_norm = 4.3642
	sim_grads_norm_tr = -0.1693
-- Starting training on experience 202 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7559
	data_grads_norm = 4.2323
	new_data_grads_norm = 5.6494
	old_data_grads_norm = 4.1769
	sim_grads_norm_tr = 0.2668
-- Starting training on experience 203 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4205
	data_grads_norm = 3.6729
	new_data_grads_norm = 5.8080
	old_data_grads_norm = 3.3555
	sim_grads_norm_tr = -0.0335
-- Starting training on experience 204 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1862
	data_grads_norm = 3.9049
	new_data_grads_norm = 5.3105
	old_data_grads_norm = 5.5787
	sim_grads_norm_tr = 0.0440
-- Starting training on experience 205 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7637
	data_grads_norm = 3.5293
	new_data_grads_norm = 4.9612
	old_data_grads_norm = 4.1797
	sim_grads_norm_tr = 0.1306
-- Starting training on experience 206 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3311
	data_grads_norm = 2.8992
	new_data_grads_norm = 5.8562
	old_data_grads_norm = 3.9634
	sim_grads_norm_tr = -0.0798
-- Starting training on experience 207 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3812
	data_grads_norm = 2.9065
	new_data_grads_norm = 5.9360
	old_data_grads_norm = 3.3631
	sim_grads_norm_tr = -0.2882
-- Starting training on experience 208 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8046
	data_grads_norm = 3.8179
	new_data_grads_norm = 4.9941
	old_data_grads_norm = 4.7626
	sim_grads_norm_tr = 0.2294
-- Starting training on experience 209 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7520
	data_grads_norm = 3.3093
	new_data_grads_norm = 6.3672
	old_data_grads_norm = 4.1209
	sim_grads_norm_tr = -0.0042
-- Starting training on experience 210 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4535
	data_grads_norm = 2.7728
	new_data_grads_norm = 5.2246
	old_data_grads_norm = 3.9468
	sim_grads_norm_tr = -0.1356
-- Starting training on experience 211 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4875
	data_grads_norm = 3.5650
	new_data_grads_norm = 5.7378
	old_data_grads_norm = 3.7881
	sim_grads_norm_tr = 0.1272
-- Starting training on experience 212 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4573
	data_grads_norm = 3.1641
	new_data_grads_norm = 5.6372
	old_data_grads_norm = 3.6026
	sim_grads_norm_tr = -0.0780
-- Starting training on experience 213 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8772
	data_grads_norm = 3.7980
	new_data_grads_norm = 5.6849
	old_data_grads_norm = 4.4407
	sim_grads_norm_tr = -0.0505
-- Starting training on experience 214 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7151
	data_grads_norm = 3.9173
	new_data_grads_norm = 5.8071
	old_data_grads_norm = 4.4244
	sim_grads_norm_tr = 0.1191
-- Starting training on experience 215 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4508
	data_grads_norm = 3.9239
	new_data_grads_norm = 5.8816
	old_data_grads_norm = 3.6582
	sim_grads_norm_tr = -0.0561
-- Starting training on experience 216 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8148
	data_grads_norm = 3.7320
	new_data_grads_norm = 5.4088
	old_data_grads_norm = 3.9078
	sim_grads_norm_tr = 0.2711
-- Starting training on experience 217 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8035
	data_grads_norm = 3.7930
	new_data_grads_norm = 5.6165
	old_data_grads_norm = 4.6961
	sim_grads_norm_tr = -0.0070
-- Starting training on experience 218 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2496
	data_grads_norm = 2.9127
	new_data_grads_norm = 5.0383
	old_data_grads_norm = 4.1322
	sim_grads_norm_tr = -0.0234
-- Starting training on experience 219 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9091
	data_grads_norm = 4.3140
	new_data_grads_norm = 6.1429
	old_data_grads_norm = 5.9648
	sim_grads_norm_tr = 0.0367
-- Starting training on experience 220 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7549
	data_grads_norm = 3.5786
	new_data_grads_norm = 5.1889
	old_data_grads_norm = 4.2183
	sim_grads_norm_tr = 0.0521
-- Starting training on experience 221 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1166
	data_grads_norm = 4.4119
	new_data_grads_norm = 5.3433
	old_data_grads_norm = 5.3220
	sim_grads_norm_tr = 0.3176
-- Starting training on experience 222 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2916
	data_grads_norm = 2.5958
	new_data_grads_norm = 4.3864
	old_data_grads_norm = 3.8157
	sim_grads_norm_tr = -0.0276
-- Starting training on experience 223 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8533
	data_grads_norm = 4.2363
	new_data_grads_norm = 6.3082
	old_data_grads_norm = 4.2676
	sim_grads_norm_tr = -0.0153
-- Starting training on experience 224 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4290
	data_grads_norm = 3.5006
	new_data_grads_norm = 5.3859
	old_data_grads_norm = 3.6422
	sim_grads_norm_tr = 0.0255
-- Starting training on experience 225 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0325
	data_grads_norm = 2.2797
	new_data_grads_norm = 5.1415
	old_data_grads_norm = 3.3192
	sim_grads_norm_tr = -0.2523
-- Starting training on experience 226 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2636
	data_grads_norm = 2.7411
	new_data_grads_norm = 4.9197
	old_data_grads_norm = 4.1512
	sim_grads_norm_tr = -0.0827
-- Starting training on experience 227 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8067
	data_grads_norm = 4.1027
	new_data_grads_norm = 5.8878
	old_data_grads_norm = 4.4596
	sim_grads_norm_tr = 0.2082
-- Starting training on experience 228 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6778
	data_grads_norm = 3.9535
	new_data_grads_norm = 5.8774
	old_data_grads_norm = 4.2285
	sim_grads_norm_tr = 0.0210
-- Starting training on experience 229 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2163
	data_grads_norm = 4.0005
	new_data_grads_norm = 5.1789
	old_data_grads_norm = 5.1917
	sim_grads_norm_tr = 0.0182
-- Starting training on experience 230 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3710
	data_grads_norm = 3.7529
	new_data_grads_norm = 5.4772
	old_data_grads_norm = 4.6374
	sim_grads_norm_tr = -0.2227
-- Starting training on experience 231 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0102
	data_grads_norm = 4.0725
	new_data_grads_norm = 6.1314
	old_data_grads_norm = 4.6268
	sim_grads_norm_tr = 0.1744
-- Starting training on experience 232 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8650
	data_grads_norm = 4.4133
	new_data_grads_norm = 5.2503
	old_data_grads_norm = 5.8721
	sim_grads_norm_tr = 0.2463
-- Starting training on experience 233 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3467
	data_grads_norm = 2.9309
	new_data_grads_norm = 4.7431
	old_data_grads_norm = 3.3192
	sim_grads_norm_tr = -0.0308
-- Starting training on experience 234 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6148
	data_grads_norm = 3.7729
	new_data_grads_norm = 6.4305
	old_data_grads_norm = 3.8345
	sim_grads_norm_tr = 0.1795
-- Starting training on experience 235 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3431
	data_grads_norm = 2.8071
	new_data_grads_norm = 4.3333
	old_data_grads_norm = 4.5935
	sim_grads_norm_tr = -0.1630
-- Starting training on experience 236 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5817
	data_grads_norm = 3.8203
	new_data_grads_norm = 5.8042
	old_data_grads_norm = 4.9818
	sim_grads_norm_tr = 0.0491
-- Starting training on experience 237 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4845
	data_grads_norm = 3.3827
	new_data_grads_norm = 4.8114
	old_data_grads_norm = 4.6214
	sim_grads_norm_tr = -0.0731
-- Starting training on experience 238 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6774
	data_grads_norm = 3.2398
	new_data_grads_norm = 5.8597
	old_data_grads_norm = 4.1805
	sim_grads_norm_tr = 0.0314
-- Starting training on experience 239 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6029
	data_grads_norm = 3.6990
	new_data_grads_norm = 5.5395
	old_data_grads_norm = 5.4364
	sim_grads_norm_tr = -0.1473
-- Starting training on experience 240 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3464
	data_grads_norm = 3.1074
	new_data_grads_norm = 5.5194
	old_data_grads_norm = 3.9576
	sim_grads_norm_tr = -0.1244
-- Starting training on experience 241 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1583
	data_grads_norm = 4.4290
	new_data_grads_norm = 6.0205
	old_data_grads_norm = 5.3250
	sim_grads_norm_tr = -0.1705
-- Starting training on experience 242 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9078
	data_grads_norm = 4.1552
	new_data_grads_norm = 5.3359
	old_data_grads_norm = 4.0796
	sim_grads_norm_tr = -0.0926
-- Starting training on experience 243 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8141
	data_grads_norm = 3.7995
	new_data_grads_norm = 5.7472
	old_data_grads_norm = 3.4532
	sim_grads_norm_tr = 0.4184
-- Starting training on experience 244 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5853
	data_grads_norm = 3.4992
	new_data_grads_norm = 5.5362
	old_data_grads_norm = 3.3828
	sim_grads_norm_tr = 0.2605
-- Starting training on experience 245 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6308
	data_grads_norm = 4.0136
	new_data_grads_norm = 5.6524
	old_data_grads_norm = 5.6082
	sim_grads_norm_tr = -0.0638
-- Starting training on experience 246 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4535
	data_grads_norm = 4.0142
	new_data_grads_norm = 5.2844
	old_data_grads_norm = 5.0807
	sim_grads_norm_tr = -0.1237
-- Starting training on experience 247 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0544
	data_grads_norm = 4.2817
	new_data_grads_norm = 6.2041
	old_data_grads_norm = 4.9553
	sim_grads_norm_tr = 0.2442
-- Starting training on experience 248 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6287
	data_grads_norm = 3.9066
	new_data_grads_norm = 5.8247
	old_data_grads_norm = 3.0361
	sim_grads_norm_tr = 0.1952
-- Starting training on experience 249 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3993
	data_grads_norm = 3.2695
	new_data_grads_norm = 5.6261
	old_data_grads_norm = 3.4987
	sim_grads_norm_tr = -0.0425
-- Starting training on experience 250 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9281
	data_grads_norm = 4.1125
	new_data_grads_norm = 5.6323
	old_data_grads_norm = 4.8475
	sim_grads_norm_tr = 0.2397
-- Starting training on experience 251 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4540
	data_grads_norm = 3.5638
	new_data_grads_norm = 5.1868
	old_data_grads_norm = 3.4187
	sim_grads_norm_tr = 0.2108
-- Starting training on experience 252 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4783
	data_grads_norm = 3.5699
	new_data_grads_norm = 5.8192
	old_data_grads_norm = 4.8449
	sim_grads_norm_tr = -0.0584
-- Starting training on experience 253 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4362
	data_grads_norm = 3.1981
	new_data_grads_norm = 6.6015
	old_data_grads_norm = 4.2426
	sim_grads_norm_tr = -0.0436
-- Starting training on experience 254 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5876
	data_grads_norm = 3.7760
	new_data_grads_norm = 5.4623
	old_data_grads_norm = 4.9654
	sim_grads_norm_tr = -0.0314
-- Starting training on experience 255 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2952
	data_grads_norm = 4.3473
	new_data_grads_norm = 5.8231
	old_data_grads_norm = 4.9648
	sim_grads_norm_tr = 0.3503
-- Starting training on experience 256 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5004
	data_grads_norm = 3.9739
	new_data_grads_norm = 5.6549
	old_data_grads_norm = 3.5778
	sim_grads_norm_tr = 0.2103
-- Starting training on experience 257 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6548
	data_grads_norm = 3.4446
	new_data_grads_norm = 5.6491
	old_data_grads_norm = 5.9443
	sim_grads_norm_tr = -0.1635
-- Starting training on experience 258 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9957
	data_grads_norm = 4.4542
	new_data_grads_norm = 5.9578
	old_data_grads_norm = 4.7898
	sim_grads_norm_tr = 0.1797
-- Starting training on experience 259 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0966
	data_grads_norm = 4.6453
	new_data_grads_norm = 5.8169
	old_data_grads_norm = 4.2820
	sim_grads_norm_tr = -0.0135
-- Starting training on experience 260 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5618
	data_grads_norm = 3.4611
	new_data_grads_norm = 6.0535
	old_data_grads_norm = 3.8125
	sim_grads_norm_tr = 0.0426
-- Starting training on experience 261 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8931
	data_grads_norm = 3.7989
	new_data_grads_norm = 4.8616
	old_data_grads_norm = 5.0716
	sim_grads_norm_tr = 0.2016
-- Starting training on experience 262 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2219
	data_grads_norm = 3.1089
	new_data_grads_norm = 5.0738
	old_data_grads_norm = 3.9023
	sim_grads_norm_tr = -0.1390
-- Starting training on experience 263 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4096
	data_grads_norm = 3.4248
	new_data_grads_norm = 5.5823
	old_data_grads_norm = 5.5375
	sim_grads_norm_tr = -0.0830
-- Starting training on experience 264 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2584
	data_grads_norm = 4.1603
	new_data_grads_norm = 5.7394
	old_data_grads_norm = 4.3127
	sim_grads_norm_tr = 0.3668
-- Starting training on experience 265 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6438
	data_grads_norm = 3.3314
	new_data_grads_norm = 5.0653
	old_data_grads_norm = 5.0371
	sim_grads_norm_tr = -0.0316
-- Starting training on experience 266 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3614
	data_grads_norm = 3.0887
	new_data_grads_norm = 5.4881
	old_data_grads_norm = 3.0220
	sim_grads_norm_tr = 0.0282
-- Starting training on experience 267 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3794
	data_grads_norm = 2.5590
	new_data_grads_norm = 5.0927
	old_data_grads_norm = 3.0206
	sim_grads_norm_tr = -0.0735
-- Starting training on experience 268 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2304
	data_grads_norm = 2.7887
	new_data_grads_norm = 4.9630
	old_data_grads_norm = 3.5770
	sim_grads_norm_tr = -0.1649
-- Starting training on experience 269 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7060
	data_grads_norm = 3.3936
	new_data_grads_norm = 5.8045
	old_data_grads_norm = 3.5424
	sim_grads_norm_tr = -0.0383
-- Starting training on experience 270 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8362
	data_grads_norm = 3.5909
	new_data_grads_norm = 5.2722
	old_data_grads_norm = 4.8436
	sim_grads_norm_tr = -0.0319
-- Starting training on experience 271 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8361
	data_grads_norm = 3.4335
	new_data_grads_norm = 6.0721
	old_data_grads_norm = 4.1730
	sim_grads_norm_tr = -0.1866
-- Starting training on experience 272 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4653
	data_grads_norm = 3.4608
	new_data_grads_norm = 5.6460
	old_data_grads_norm = 3.9579
	sim_grads_norm_tr = -0.1151
-- Starting training on experience 273 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9415
	data_grads_norm = 3.4350
	new_data_grads_norm = 6.1098
	old_data_grads_norm = 3.8415
	sim_grads_norm_tr = 0.1476
-- Starting training on experience 274 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3318
	data_grads_norm = 3.2145
	new_data_grads_norm = 5.4393
	old_data_grads_norm = 3.7669
	sim_grads_norm_tr = -0.0576
-- Starting training on experience 275 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5883
	data_grads_norm = 4.0789
	new_data_grads_norm = 4.9408
	old_data_grads_norm = 6.0254
	sim_grads_norm_tr = 0.0306
-- Starting training on experience 276 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2713
	data_grads_norm = 4.2038
	new_data_grads_norm = 5.2648
	old_data_grads_norm = 4.3834
	sim_grads_norm_tr = 0.4811
-- Starting training on experience 277 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2464
	data_grads_norm = 2.7753
	new_data_grads_norm = 4.5831
	old_data_grads_norm = 3.7564
	sim_grads_norm_tr = -0.1969
-- Starting training on experience 278 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8352
	data_grads_norm = 3.7001
	new_data_grads_norm = 5.7400
	old_data_grads_norm = 4.6803
	sim_grads_norm_tr = 0.0588
-- Starting training on experience 279 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6907
	data_grads_norm = 3.8984
	new_data_grads_norm = 5.1039
	old_data_grads_norm = 4.7150
	sim_grads_norm_tr = 0.2551
-- Starting training on experience 280 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3602
	data_grads_norm = 2.9226
	new_data_grads_norm = 4.2622
	old_data_grads_norm = 4.1068
	sim_grads_norm_tr = -0.1030
-- Starting training on experience 281 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2761
	data_grads_norm = 2.8983
	new_data_grads_norm = 4.2965
	old_data_grads_norm = 3.0793
	sim_grads_norm_tr = 0.2187
-- Starting training on experience 282 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2909
	data_grads_norm = 2.7792
	new_data_grads_norm = 4.4798
	old_data_grads_norm = 3.4406
	sim_grads_norm_tr = 0.0303
-- Starting training on experience 283 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1497
	data_grads_norm = 2.6407
	new_data_grads_norm = 4.0444
	old_data_grads_norm = 3.7170
	sim_grads_norm_tr = -0.1072
-- Starting training on experience 284 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3371
	data_grads_norm = 3.1974
	new_data_grads_norm = 4.0618
	old_data_grads_norm = 5.2165
	sim_grads_norm_tr = -0.0588
-- Starting training on experience 285 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5123
	data_grads_norm = 3.6578
	new_data_grads_norm = 5.3182
	old_data_grads_norm = 3.9164
	sim_grads_norm_tr = 0.2222
-- Starting training on experience 286 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3286
	data_grads_norm = 2.7556
	new_data_grads_norm = 4.0594
	old_data_grads_norm = 3.8454
	sim_grads_norm_tr = 0.1026
-- Starting training on experience 287 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2179
	data_grads_norm = 2.6507
	new_data_grads_norm = 4.0820
	old_data_grads_norm = 3.4631
	sim_grads_norm_tr = -0.1851
-- Starting training on experience 288 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2720
	data_grads_norm = 3.0129
	new_data_grads_norm = 5.1360
	old_data_grads_norm = 4.3183
	sim_grads_norm_tr = -0.0136
-- Starting training on experience 289 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3483
	data_grads_norm = 2.7914
	new_data_grads_norm = 4.8520
	old_data_grads_norm = 4.3637
	sim_grads_norm_tr = -0.1575
-- Starting training on experience 290 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5269
	data_grads_norm = 3.3926
	new_data_grads_norm = 5.1261
	old_data_grads_norm = 3.2602
	sim_grads_norm_tr = 0.1137
-- Starting training on experience 291 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4017
	data_grads_norm = 3.6863
	new_data_grads_norm = 5.1383
	old_data_grads_norm = 4.1547
	sim_grads_norm_tr = 0.2360
-- Starting training on experience 292 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3560
	data_grads_norm = 2.8969
	new_data_grads_norm = 4.9115
	old_data_grads_norm = 3.3463
	sim_grads_norm_tr = -0.0275
-- Starting training on experience 293 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3706
	data_grads_norm = 2.7552
	new_data_grads_norm = 4.5291
	old_data_grads_norm = 3.3344
	sim_grads_norm_tr = -0.0343
-- Starting training on experience 294 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3487
	data_grads_norm = 3.1493
	new_data_grads_norm = 5.5497
	old_data_grads_norm = 2.6105
	sim_grads_norm_tr = -0.0362
-- Starting training on experience 295 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7903
	data_grads_norm = 3.5460
	new_data_grads_norm = 5.8057
	old_data_grads_norm = 2.6109
	sim_grads_norm_tr = 0.1868
-- Starting training on experience 296 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7895
	data_grads_norm = 3.6178
	new_data_grads_norm = 5.7551
	old_data_grads_norm = 4.5475
	sim_grads_norm_tr = 0.0354
-- Starting training on experience 297 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6526
	data_grads_norm = 4.0751
	new_data_grads_norm = 5.2946
	old_data_grads_norm = 5.0764
	sim_grads_norm_tr = -0.0496
-- Starting training on experience 298 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6043
	data_grads_norm = 4.0459
	new_data_grads_norm = 5.9081
	old_data_grads_norm = 5.4342
	sim_grads_norm_tr = -0.0259
-- Starting training on experience 299 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5784
	data_grads_norm = 3.8123
	new_data_grads_norm = 5.3255
	old_data_grads_norm = 4.1323
	sim_grads_norm_tr = 0.3193
-- Starting training on experience 300 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8761
	data_grads_norm = 3.5479
	new_data_grads_norm = 5.1132
	old_data_grads_norm = 5.5673
	sim_grads_norm_tr = -0.0787
-- Starting training on experience 301 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5631
	data_grads_norm = 4.3033
	new_data_grads_norm = 5.0413
	old_data_grads_norm = 3.9362
	sim_grads_norm_tr = -0.0636
-- Starting training on experience 302 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6614
	data_grads_norm = 4.1617
	new_data_grads_norm = 5.4728
	old_data_grads_norm = 5.1920
	sim_grads_norm_tr = 0.0936
-- Starting training on experience 303 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1937
	data_grads_norm = 4.2898
	new_data_grads_norm = 6.1909
	old_data_grads_norm = 4.6781
	sim_grads_norm_tr = 0.0597
-- Starting training on experience 304 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0439
	data_grads_norm = 4.1068
	new_data_grads_norm = 6.0912
	old_data_grads_norm = 4.3196
	sim_grads_norm_tr = 0.2339
-- Starting training on experience 305 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4570
	data_grads_norm = 3.0192
	new_data_grads_norm = 4.9442
	old_data_grads_norm = 4.7900
	sim_grads_norm_tr = -0.2664
-- Starting training on experience 306 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5451
	data_grads_norm = 3.1854
	new_data_grads_norm = 5.3611
	old_data_grads_norm = 4.0047
	sim_grads_norm_tr = -0.0412
-- Starting training on experience 307 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7176
	data_grads_norm = 3.7509
	new_data_grads_norm = 5.6385
	old_data_grads_norm = 5.2646
	sim_grads_norm_tr = 0.1109
-- Starting training on experience 308 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6033
	data_grads_norm = 3.7002
	new_data_grads_norm = 5.7676
	old_data_grads_norm = 4.5988
	sim_grads_norm_tr = -0.1201
-- Starting training on experience 309 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7708
	data_grads_norm = 4.1392
	new_data_grads_norm = 5.3692
	old_data_grads_norm = 5.0415
	sim_grads_norm_tr = 0.3258
-- Starting training on experience 310 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4078
	data_grads_norm = 3.0209
	new_data_grads_norm = 4.8623
	old_data_grads_norm = 4.1164
	sim_grads_norm_tr = -0.0286
-- Starting training on experience 311 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5076
	data_grads_norm = 3.3322
	new_data_grads_norm = 4.5088
	old_data_grads_norm = 3.2824
	sim_grads_norm_tr = 0.2314
-- Starting training on experience 312 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9335
	data_grads_norm = 3.7765
	new_data_grads_norm = 5.7590
	old_data_grads_norm = 4.1798
	sim_grads_norm_tr = 0.2167
-- Starting training on experience 313 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3935
	data_grads_norm = 3.2618
	new_data_grads_norm = 4.7701
	old_data_grads_norm = 4.4100
	sim_grads_norm_tr = 0.0916
-- Starting training on experience 314 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3773
	data_grads_norm = 3.4236
	new_data_grads_norm = 5.0768
	old_data_grads_norm = 4.3214
	sim_grads_norm_tr = 0.0470
-- Starting training on experience 315 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6337
	data_grads_norm = 3.8358
	new_data_grads_norm = 5.1711
	old_data_grads_norm = 5.1365
	sim_grads_norm_tr = 0.2296
-- Starting training on experience 316 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9731
	data_grads_norm = 3.7958
	new_data_grads_norm = 5.9333
	old_data_grads_norm = 4.0849
	sim_grads_norm_tr = 0.0257
-- Starting training on experience 317 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2520
	data_grads_norm = 2.4874
	new_data_grads_norm = 4.1495
	old_data_grads_norm = 3.0364
	sim_grads_norm_tr = -0.1737
-- Starting training on experience 318 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6392
	data_grads_norm = 3.1795
	new_data_grads_norm = 5.5224
	old_data_grads_norm = 3.1725
	sim_grads_norm_tr = -0.0434
-- Starting training on experience 319 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5930
	data_grads_norm = 3.1244
	new_data_grads_norm = 5.2937
	old_data_grads_norm = 3.3967
	sim_grads_norm_tr = 0.1422
-- Starting training on experience 320 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7206
	data_grads_norm = 3.6636
	new_data_grads_norm = 4.8559
	old_data_grads_norm = 3.9845
	sim_grads_norm_tr = 0.2476
-- Starting training on experience 321 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4876
	data_grads_norm = 3.2234
	new_data_grads_norm = 5.4350
	old_data_grads_norm = 4.2144
	sim_grads_norm_tr = -0.1176
-- Starting training on experience 322 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3789
	data_grads_norm = 2.8106
	new_data_grads_norm = 5.6243
	old_data_grads_norm = 3.2632
	sim_grads_norm_tr = -0.2277
-- Starting training on experience 323 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7049
	data_grads_norm = 2.8987
	new_data_grads_norm = 5.2510
	old_data_grads_norm = 3.3916
	sim_grads_norm_tr = -0.1211
-- Starting training on experience 324 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5410
	data_grads_norm = 3.1930
	new_data_grads_norm = 5.1438
	old_data_grads_norm = 3.0916
	sim_grads_norm_tr = -0.0084
-- Starting training on experience 325 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7858
	data_grads_norm = 3.9823
	new_data_grads_norm = 6.3760
	old_data_grads_norm = 3.6557
	sim_grads_norm_tr = 0.0179
-- Starting training on experience 326 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7878
	data_grads_norm = 4.0544
	new_data_grads_norm = 5.4781
	old_data_grads_norm = 3.9301
	sim_grads_norm_tr = 0.1953
-- Starting training on experience 327 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5432
	data_grads_norm = 3.3918
	new_data_grads_norm = 5.2950
	old_data_grads_norm = 3.6386
	sim_grads_norm_tr = 0.0515
-- Starting training on experience 328 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5459
	data_grads_norm = 3.3857
	new_data_grads_norm = 5.8164
	old_data_grads_norm = 3.2118
	sim_grads_norm_tr = -0.1140
-- Starting training on experience 329 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8762
	data_grads_norm = 3.9067
	new_data_grads_norm = 5.7312
	old_data_grads_norm = 4.7968
	sim_grads_norm_tr = -0.0827
-- Starting training on experience 330 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9029
	data_grads_norm = 3.8792
	new_data_grads_norm = 5.4010
	old_data_grads_norm = 3.8506
	sim_grads_norm_tr = 0.2190
-- Starting training on experience 331 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9258
	data_grads_norm = 3.5915
	new_data_grads_norm = 5.3927
	old_data_grads_norm = 5.2540
	sim_grads_norm_tr = -0.0083
-- Starting training on experience 332 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5074
	data_grads_norm = 3.0553
	new_data_grads_norm = 5.6362
	old_data_grads_norm = 2.9024
	sim_grads_norm_tr = -0.0041
-- Starting training on experience 333 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4895
	data_grads_norm = 3.6724
	new_data_grads_norm = 5.9502
	old_data_grads_norm = 5.3625
	sim_grads_norm_tr = -0.1347
-- Starting training on experience 334 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5755
	data_grads_norm = 2.8965
	new_data_grads_norm = 5.3176
	old_data_grads_norm = 3.5498
	sim_grads_norm_tr = -0.1268
-- Starting training on experience 335 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6630
	data_grads_norm = 3.5976
	new_data_grads_norm = 6.0228
	old_data_grads_norm = 4.2894
	sim_grads_norm_tr = -0.0731
-- Starting training on experience 336 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9515
	data_grads_norm = 3.8667
	new_data_grads_norm = 5.8955
	old_data_grads_norm = 3.9573
	sim_grads_norm_tr = 0.1710
-- Starting training on experience 337 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7722
	data_grads_norm = 3.6071
	new_data_grads_norm = 6.1601
	old_data_grads_norm = 4.4487
	sim_grads_norm_tr = -0.1308
-- Starting training on experience 338 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3914
	data_grads_norm = 4.1376
	new_data_grads_norm = 6.1792
	old_data_grads_norm = 3.6460
	sim_grads_norm_tr = 0.3366
-- Starting training on experience 339 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1771
	data_grads_norm = 2.9029
	new_data_grads_norm = 5.5961
	old_data_grads_norm = 2.8103
	sim_grads_norm_tr = -0.1015
-- Starting training on experience 340 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9383
	data_grads_norm = 3.9029
	new_data_grads_norm = 5.5400
	old_data_grads_norm = 4.6089
	sim_grads_norm_tr = 0.1528
-- Starting training on experience 341 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3973
	data_grads_norm = 3.0183
	new_data_grads_norm = 5.7045
	old_data_grads_norm = 3.1765
	sim_grads_norm_tr = -0.0907
-- Starting training on experience 342 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4109
	data_grads_norm = 3.6201
	new_data_grads_norm = 6.8454
	old_data_grads_norm = 4.0807
	sim_grads_norm_tr = -0.1357
-- Starting training on experience 343 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7957
	data_grads_norm = 3.1226
	new_data_grads_norm = 6.2375
	old_data_grads_norm = 3.2154
	sim_grads_norm_tr = -0.0413
-- Starting training on experience 344 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1657
	data_grads_norm = 3.8133
	new_data_grads_norm = 5.5348
	old_data_grads_norm = 3.4281
	sim_grads_norm_tr = 0.3601
-- Starting training on experience 345 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5430
	data_grads_norm = 3.1667
	new_data_grads_norm = 5.7323
	old_data_grads_norm = 2.9626
	sim_grads_norm_tr = 0.0077
-- Starting training on experience 346 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4055
	data_grads_norm = 3.0076
	new_data_grads_norm = 5.4774
	old_data_grads_norm = 3.4837
	sim_grads_norm_tr = -0.0744
-- Starting training on experience 347 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5956
	data_grads_norm = 3.5389
	new_data_grads_norm = 6.0768
	old_data_grads_norm = 3.1480
	sim_grads_norm_tr = -0.0228
-- Starting training on experience 348 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0532
	data_grads_norm = 4.0169
	new_data_grads_norm = 6.0467
	old_data_grads_norm = 5.3227
	sim_grads_norm_tr = 0.0385
-- Starting training on experience 349 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8143
	data_grads_norm = 3.7920
	new_data_grads_norm = 5.5957
	old_data_grads_norm = 3.7122
	sim_grads_norm_tr = 0.2255
-- Starting training on experience 350 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6473
	data_grads_norm = 3.4467
	new_data_grads_norm = 4.9096
	old_data_grads_norm = 4.3208
	sim_grads_norm_tr = 0.0252
-- Starting training on experience 351 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2438
	data_grads_norm = 2.8832
	new_data_grads_norm = 4.6231
	old_data_grads_norm = 2.9947
	sim_grads_norm_tr = -0.0579
-- Starting training on experience 352 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5420
	data_grads_norm = 3.4699
	new_data_grads_norm = 5.1947
	old_data_grads_norm = 4.0207
	sim_grads_norm_tr = 0.1254
-- Starting training on experience 353 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8075
	data_grads_norm = 3.8582
	new_data_grads_norm = 4.8568
	old_data_grads_norm = 4.6302
	sim_grads_norm_tr = 0.1959
-- Starting training on experience 354 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4074
	data_grads_norm = 2.6971
	new_data_grads_norm = 4.1118
	old_data_grads_norm = 4.4177
	sim_grads_norm_tr = -0.1794
-- Starting training on experience 355 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7846
	data_grads_norm = 3.5134
	new_data_grads_norm = 5.1685
	old_data_grads_norm = 3.9703
	sim_grads_norm_tr = -0.0899
-- Starting training on experience 356 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5229
	data_grads_norm = 3.9537
	new_data_grads_norm = 5.7038
	old_data_grads_norm = 4.4754
	sim_grads_norm_tr = 0.0501
-- Starting training on experience 357 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5534
	data_grads_norm = 2.6539
	new_data_grads_norm = 4.7830
	old_data_grads_norm = 3.8781
	sim_grads_norm_tr = -0.1279
-- Starting training on experience 358 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6281
	data_grads_norm = 3.3224
	new_data_grads_norm = 5.3460
	old_data_grads_norm = 3.5957
	sim_grads_norm_tr = 0.0384
-- Starting training on experience 359 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6386
	data_grads_norm = 3.7471
	new_data_grads_norm = 5.7322
	old_data_grads_norm = 4.2271
	sim_grads_norm_tr = -0.0236
-- Starting training on experience 360 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3964
	data_grads_norm = 4.5989
	new_data_grads_norm = 5.4180
	old_data_grads_norm = 5.5349
	sim_grads_norm_tr = 0.3344
-- Starting training on experience 361 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4698
	data_grads_norm = 4.2408
	new_data_grads_norm = 5.1610
	old_data_grads_norm = 5.9212
	sim_grads_norm_tr = -0.0811
-- Starting training on experience 362 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5472
	data_grads_norm = 3.1609
	new_data_grads_norm = 6.0232
	old_data_grads_norm = 4.8050
	sim_grads_norm_tr = -0.1106
-- Starting training on experience 363 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0304
	data_grads_norm = 4.3886
	new_data_grads_norm = 5.9719
	old_data_grads_norm = 4.8895
	sim_grads_norm_tr = 0.0661
-- Starting training on experience 364 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8506
	data_grads_norm = 3.6302
	new_data_grads_norm = 5.5198
	old_data_grads_norm = 3.8446
	sim_grads_norm_tr = 0.2286
-- Starting training on experience 365 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4885
	data_grads_norm = 3.6368
	new_data_grads_norm = 5.4769
	old_data_grads_norm = 3.9807
	sim_grads_norm_tr = 0.0076
-- Starting training on experience 366 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6905
	data_grads_norm = 3.6958
	new_data_grads_norm = 5.7767
	old_data_grads_norm = 4.0354
	sim_grads_norm_tr = 0.0949
-- Starting training on experience 367 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0279
	data_grads_norm = 3.8736
	new_data_grads_norm = 5.8667
	old_data_grads_norm = 3.8884
	sim_grads_norm_tr = 0.1114
-- Starting training on experience 368 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6046
	data_grads_norm = 3.7221
	new_data_grads_norm = 6.0017
	old_data_grads_norm = 4.0591
	sim_grads_norm_tr = -0.0224
-- Starting training on experience 369 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5667
	data_grads_norm = 3.3224
	new_data_grads_norm = 5.2885
	old_data_grads_norm = 3.5260
	sim_grads_norm_tr = -0.0321
-- Starting training on experience 370 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6275
	data_grads_norm = 3.5492
	new_data_grads_norm = 6.6746
	old_data_grads_norm = 3.5679
	sim_grads_norm_tr = -0.0233
-- Starting training on experience 371 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8246
	data_grads_norm = 3.3705
	new_data_grads_norm = 5.4149
	old_data_grads_norm = 3.8100
	sim_grads_norm_tr = 0.0632
-- Starting training on experience 372 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7908
	data_grads_norm = 4.0697
	new_data_grads_norm = 6.3676
	old_data_grads_norm = 3.3186
	sim_grads_norm_tr = 0.0803
-- Starting training on experience 373 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6481
	data_grads_norm = 3.1581
	new_data_grads_norm = 6.0704
	old_data_grads_norm = 3.5729
	sim_grads_norm_tr = -0.2476
-- Starting training on experience 374 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2470
	data_grads_norm = 5.4507
	new_data_grads_norm = 6.4355
	old_data_grads_norm = 5.6547
	sim_grads_norm_tr = 0.2641
-- Starting training on experience 375 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7835
	data_grads_norm = 4.6357
	new_data_grads_norm = 5.6511
	old_data_grads_norm = 6.7579
	sim_grads_norm_tr = 0.0762
-- Starting training on experience 376 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6273
	data_grads_norm = 3.1736
	new_data_grads_norm = 4.7626
	old_data_grads_norm = 3.4020
	sim_grads_norm_tr = 0.1385
-- Starting training on experience 377 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3843
	data_grads_norm = 3.1656
	new_data_grads_norm = 5.3730
	old_data_grads_norm = 3.2002
	sim_grads_norm_tr = -0.1986
-- Starting training on experience 378 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4960
	data_grads_norm = 3.4106
	new_data_grads_norm = 5.5161
	old_data_grads_norm = 3.4220
	sim_grads_norm_tr = 0.1932
-- Starting training on experience 379 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5398
	data_grads_norm = 3.8722
	new_data_grads_norm = 4.8656
	old_data_grads_norm = 4.5391
	sim_grads_norm_tr = 0.0151
-- Starting training on experience 380 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7720
	data_grads_norm = 3.6948
	new_data_grads_norm = 5.6774
	old_data_grads_norm = 4.5831
	sim_grads_norm_tr = 0.1197
-- Starting training on experience 381 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5833
	data_grads_norm = 3.1972
	new_data_grads_norm = 4.1856
	old_data_grads_norm = 5.3676
	sim_grads_norm_tr = -0.0508
-- Starting training on experience 382 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3404
	data_grads_norm = 2.8264
	new_data_grads_norm = 5.1380
	old_data_grads_norm = 4.2187
	sim_grads_norm_tr = -0.3226
-- Starting training on experience 383 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7084
	data_grads_norm = 3.6374
	new_data_grads_norm = 6.6753
	old_data_grads_norm = 2.7551
	sim_grads_norm_tr = 0.1692
-- Starting training on experience 384 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5776
	data_grads_norm = 3.7761
	new_data_grads_norm = 5.7061
	old_data_grads_norm = 4.1625
	sim_grads_norm_tr = -0.1609
-- Starting training on experience 385 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7742
	data_grads_norm = 3.5594
	new_data_grads_norm = 6.0062
	old_data_grads_norm = 4.1837
	sim_grads_norm_tr = -0.0941
-- Starting training on experience 386 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8940
	data_grads_norm = 3.8843
	new_data_grads_norm = 5.3735
	old_data_grads_norm = 5.0306
	sim_grads_norm_tr = 0.0639
-- Starting training on experience 387 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8767
	data_grads_norm = 4.1216
	new_data_grads_norm = 6.5593
	old_data_grads_norm = 3.8382
	sim_grads_norm_tr = 0.0706
-- Starting training on experience 388 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9002
	data_grads_norm = 3.6964
	new_data_grads_norm = 5.2393
	old_data_grads_norm = 3.8127
	sim_grads_norm_tr = 0.2079
-- Starting training on experience 389 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5829
	data_grads_norm = 3.7157
	new_data_grads_norm = 6.0506
	old_data_grads_norm = 5.0124
	sim_grads_norm_tr = 0.0144
-- Starting training on experience 390 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2890
	data_grads_norm = 2.7793
	new_data_grads_norm = 5.3369
	old_data_grads_norm = 3.3607
	sim_grads_norm_tr = -0.1913
-- Starting training on experience 391 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8379
	data_grads_norm = 3.5946
	new_data_grads_norm = 5.3577
	old_data_grads_norm = 4.6410
	sim_grads_norm_tr = -0.1165
-- Starting training on experience 392 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5650
	data_grads_norm = 2.9296
	new_data_grads_norm = 5.4419
	old_data_grads_norm = 3.9690
	sim_grads_norm_tr = -0.0805
-- Starting training on experience 393 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5656
	data_grads_norm = 3.3318
	new_data_grads_norm = 5.5626
	old_data_grads_norm = 3.3254
	sim_grads_norm_tr = -0.0560
-- Starting training on experience 394 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0428
	data_grads_norm = 4.1834
	new_data_grads_norm = 5.9531
	old_data_grads_norm = 3.3468
	sim_grads_norm_tr = 0.2338
-- Starting training on experience 395 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7540
	data_grads_norm = 3.5019
	new_data_grads_norm = 5.6862
	old_data_grads_norm = 3.1620
	sim_grads_norm_tr = 0.1715
-- Starting training on experience 396 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1985
	data_grads_norm = 4.0256
	new_data_grads_norm = 5.2297
	old_data_grads_norm = 4.8247
	sim_grads_norm_tr = 0.2305
-- Starting training on experience 397 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7928
	data_grads_norm = 3.7611
	new_data_grads_norm = 5.8244
	old_data_grads_norm = 4.7032
	sim_grads_norm_tr = 0.1678
-- Starting training on experience 398 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1726
	data_grads_norm = 2.6835
	new_data_grads_norm = 4.2357
	old_data_grads_norm = 4.5951
	sim_grads_norm_tr = -0.2002
-- Starting training on experience 399 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5742
	data_grads_norm = 3.2221
	new_data_grads_norm = 4.2641
	old_data_grads_norm = 4.0010
	sim_grads_norm_tr = -0.0837
-- Starting training on experience 400 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6704
	data_grads_norm = 4.5689
	new_data_grads_norm = 6.3255
	old_data_grads_norm = 4.2639
	sim_grads_norm_tr = 0.1554
-- Starting training on experience 401 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2470
	data_grads_norm = 2.6784
	new_data_grads_norm = 5.7692
	old_data_grads_norm = 3.1247
	sim_grads_norm_tr = -0.0996
-- Starting training on experience 402 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7853
	data_grads_norm = 3.7332
	new_data_grads_norm = 6.1512
	old_data_grads_norm = 4.2883
	sim_grads_norm_tr = 0.0663
-- Starting training on experience 403 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6818
	data_grads_norm = 3.3358
	new_data_grads_norm = 5.3310
	old_data_grads_norm = 3.7696
	sim_grads_norm_tr = 0.1750
-- Starting training on experience 404 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5677
	data_grads_norm = 3.3805
	new_data_grads_norm = 5.7634
	old_data_grads_norm = 3.9815
	sim_grads_norm_tr = -0.0326
-- Starting training on experience 405 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8909
	data_grads_norm = 4.1065
	new_data_grads_norm = 5.7388
	old_data_grads_norm = 3.6503
	sim_grads_norm_tr = 0.2099
-- Starting training on experience 406 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3979
	data_grads_norm = 3.1513
	new_data_grads_norm = 5.3529
	old_data_grads_norm = 3.0632
	sim_grads_norm_tr = -0.0852
-- Starting training on experience 407 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5508
	data_grads_norm = 3.6191
	new_data_grads_norm = 5.7192
	old_data_grads_norm = 4.8605
	sim_grads_norm_tr = -0.0723
-- Starting training on experience 408 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7323
	data_grads_norm = 3.5106
	new_data_grads_norm = 5.5874
	old_data_grads_norm = 3.9950
	sim_grads_norm_tr = 0.0026
-- Starting training on experience 409 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4616
	data_grads_norm = 3.5136
	new_data_grads_norm = 5.4378
	old_data_grads_norm = 4.0382
	sim_grads_norm_tr = 0.0363
-- Starting training on experience 410 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6099
	data_grads_norm = 3.4211
	new_data_grads_norm = 4.9173
	old_data_grads_norm = 4.1345
	sim_grads_norm_tr = 0.0163
-- Starting training on experience 411 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7740
	data_grads_norm = 3.3568
	new_data_grads_norm = 5.8333
	old_data_grads_norm = 4.6731
	sim_grads_norm_tr = -0.2509
-- Starting training on experience 412 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7149
	data_grads_norm = 3.4195
	new_data_grads_norm = 6.0825
	old_data_grads_norm = 3.7777
	sim_grads_norm_tr = 0.0850
-- Starting training on experience 413 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6473
	data_grads_norm = 3.6965
	new_data_grads_norm = 6.3506
	old_data_grads_norm = 4.3954
	sim_grads_norm_tr = -0.0318
-- Starting training on experience 414 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9141
	data_grads_norm = 4.0620
	new_data_grads_norm = 5.9969
	old_data_grads_norm = 4.2161
	sim_grads_norm_tr = 0.1399
-- Starting training on experience 415 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7605
	data_grads_norm = 4.3594
	new_data_grads_norm = 5.9106
	old_data_grads_norm = 5.0382
	sim_grads_norm_tr = 0.0866
-- Starting training on experience 416 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8523
	data_grads_norm = 4.4002
	new_data_grads_norm = 5.9467
	old_data_grads_norm = 5.5342
	sim_grads_norm_tr = 0.0685
-- Starting training on experience 417 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1076
	data_grads_norm = 4.0491
	new_data_grads_norm = 5.7868
	old_data_grads_norm = 3.7545
	sim_grads_norm_tr = 0.0784
-- Starting training on experience 418 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8202
	data_grads_norm = 4.2110
	new_data_grads_norm = 5.7389
	old_data_grads_norm = 4.4707
	sim_grads_norm_tr = 0.0933
-- Starting training on experience 419 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3081
	data_grads_norm = 2.7578
	new_data_grads_norm = 6.1300
	old_data_grads_norm = 2.9707
	sim_grads_norm_tr = -0.2558
-- Starting training on experience 420 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8445
	data_grads_norm = 3.9615
	new_data_grads_norm = 5.9333
	old_data_grads_norm = 4.4675
	sim_grads_norm_tr = -0.0096
-- Starting training on experience 421 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3416
	data_grads_norm = 2.8291
	new_data_grads_norm = 5.6200
	old_data_grads_norm = 2.9578
	sim_grads_norm_tr = -0.0883
-- Starting training on experience 422 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6160
	data_grads_norm = 3.8118
	new_data_grads_norm = 5.9333
	old_data_grads_norm = 3.7972
	sim_grads_norm_tr = -0.0834
-- Starting training on experience 423 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5838
	data_grads_norm = 3.1394
	new_data_grads_norm = 5.4516
	old_data_grads_norm = 3.3647
	sim_grads_norm_tr = -0.2335
-- Starting training on experience 424 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8147
	data_grads_norm = 3.5580
	new_data_grads_norm = 5.4815
	old_data_grads_norm = 3.2009
	sim_grads_norm_tr = 0.2652
-- Starting training on experience 425 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1527
	data_grads_norm = 4.6273
	new_data_grads_norm = 6.5006
	old_data_grads_norm = 4.9693
	sim_grads_norm_tr = 0.0293
-- Starting training on experience 426 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4935
	data_grads_norm = 3.3559
	new_data_grads_norm = 5.7222
	old_data_grads_norm = 3.0631
	sim_grads_norm_tr = 0.0035
-- Starting training on experience 427 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0750
	data_grads_norm = 4.2442
	new_data_grads_norm = 5.6746
	old_data_grads_norm = 5.2421
	sim_grads_norm_tr = 0.2660
-- Starting training on experience 428 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7954
	data_grads_norm = 4.3697
	new_data_grads_norm = 6.0293
	old_data_grads_norm = 4.8017
	sim_grads_norm_tr = -0.0773
-- Starting training on experience 429 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7409
	data_grads_norm = 4.0185
	new_data_grads_norm = 6.7955
	old_data_grads_norm = 4.6922
	sim_grads_norm_tr = -0.0350
-- Starting training on experience 430 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9366
	data_grads_norm = 4.6179
	new_data_grads_norm = 6.7796
	old_data_grads_norm = 5.1674
	sim_grads_norm_tr = 0.1185
-- Starting training on experience 431 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6958
	data_grads_norm = 3.7754
	new_data_grads_norm = 5.9598
	old_data_grads_norm = 3.5198
	sim_grads_norm_tr = 0.2245
-- Starting training on experience 432 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6850
	data_grads_norm = 3.7598
	new_data_grads_norm = 5.7639
	old_data_grads_norm = 4.1583
	sim_grads_norm_tr = -0.0753
-- Starting training on experience 433 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1760
	data_grads_norm = 4.9140
	new_data_grads_norm = 5.8930
	old_data_grads_norm = 3.9676
	sim_grads_norm_tr = 0.1877
-- Starting training on experience 434 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1449
	data_grads_norm = 2.5557
	new_data_grads_norm = 5.5305
	old_data_grads_norm = 3.3750
	sim_grads_norm_tr = -0.0683
-- Starting training on experience 435 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2062
	data_grads_norm = 3.1737
	new_data_grads_norm = 5.7252
	old_data_grads_norm = 2.6620
	sim_grads_norm_tr = 0.0888
-- Starting training on experience 436 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5638
	data_grads_norm = 4.3930
	new_data_grads_norm = 5.9212
	old_data_grads_norm = 4.2296
	sim_grads_norm_tr = -0.0120
-- Starting training on experience 437 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9861
	data_grads_norm = 4.3871
	new_data_grads_norm = 6.0623
	old_data_grads_norm = 5.5951
	sim_grads_norm_tr = 0.1880
-- Starting training on experience 438 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4706
	data_grads_norm = 3.3848
	new_data_grads_norm = 5.6074
	old_data_grads_norm = 4.0379
	sim_grads_norm_tr = -0.2090
-- Starting training on experience 439 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7719
	data_grads_norm = 3.6976
	new_data_grads_norm = 5.6783
	old_data_grads_norm = 3.7688
	sim_grads_norm_tr = 0.2044
-- Starting training on experience 440 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7734
	data_grads_norm = 3.7239
	new_data_grads_norm = 5.9342
	old_data_grads_norm = 3.5408
	sim_grads_norm_tr = 0.1172
-- Starting training on experience 441 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6153
	data_grads_norm = 3.7237
	new_data_grads_norm = 5.0229
	old_data_grads_norm = 4.1797
	sim_grads_norm_tr = 0.3042
-- Starting training on experience 442 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7787
	data_grads_norm = 3.3862
	new_data_grads_norm = 5.5739
	old_data_grads_norm = 4.2479
	sim_grads_norm_tr = -0.1451
-- Starting training on experience 443 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1944
	data_grads_norm = 3.0557
	new_data_grads_norm = 5.6067
	old_data_grads_norm = 3.3346
	sim_grads_norm_tr = -0.2977
-- Starting training on experience 444 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8734
	data_grads_norm = 4.0887
	new_data_grads_norm = 5.0012
	old_data_grads_norm = 5.1239
	sim_grads_norm_tr = 0.2276
-- Starting training on experience 445 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4139
	data_grads_norm = 2.9587
	new_data_grads_norm = 4.5373
	old_data_grads_norm = 3.2928
	sim_grads_norm_tr = -0.0780
-- Starting training on experience 446 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8031
	data_grads_norm = 4.2027
	new_data_grads_norm = 5.7702
	old_data_grads_norm = 5.0025
	sim_grads_norm_tr = 0.0247
-- Starting training on experience 447 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3987
	data_grads_norm = 3.9677
	new_data_grads_norm = 5.9173
	old_data_grads_norm = 3.7930
	sim_grads_norm_tr = 0.1210
-- Starting training on experience 448 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7207
	data_grads_norm = 3.2708
	new_data_grads_norm = 4.9811
	old_data_grads_norm = 3.5972
	sim_grads_norm_tr = -0.1068
-- Starting training on experience 449 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3028
	data_grads_norm = 3.8785
	new_data_grads_norm = 6.1288
	old_data_grads_norm = 5.8809
	sim_grads_norm_tr = -0.1540
-- Starting training on experience 450 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2205
	data_grads_norm = 3.3641
	new_data_grads_norm = 5.8889
	old_data_grads_norm = 3.8627
	sim_grads_norm_tr = -0.1186
-- Starting training on experience 451 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4875
	data_grads_norm = 3.5403
	new_data_grads_norm = 5.6173
	old_data_grads_norm = 3.8335
	sim_grads_norm_tr = 0.2144
-- Starting training on experience 452 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7195
	data_grads_norm = 3.7664
	new_data_grads_norm = 6.4182
	old_data_grads_norm = 3.9058
	sim_grads_norm_tr = 0.1386
-- Starting training on experience 453 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0958
	data_grads_norm = 4.1156
	new_data_grads_norm = 5.6731
	old_data_grads_norm = 6.0295
	sim_grads_norm_tr = 0.0649
-- Starting training on experience 454 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3641
	data_grads_norm = 3.2025
	new_data_grads_norm = 5.7999
	old_data_grads_norm = 3.4341
	sim_grads_norm_tr = 0.1031
-- Starting training on experience 455 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4628
	data_grads_norm = 3.0454
	new_data_grads_norm = 4.6733
	old_data_grads_norm = 4.2660
	sim_grads_norm_tr = 0.0998
-- Starting training on experience 456 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8964
	data_grads_norm = 3.8906
	new_data_grads_norm = 5.5748
	old_data_grads_norm = 4.9287
	sim_grads_norm_tr = 0.1679
-- Starting training on experience 457 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6237
	data_grads_norm = 3.0966
	new_data_grads_norm = 5.1391
	old_data_grads_norm = 3.2718
	sim_grads_norm_tr = -0.0106
-- Starting training on experience 458 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4494
	data_grads_norm = 3.4581
	new_data_grads_norm = 4.9888
	old_data_grads_norm = 3.6820
	sim_grads_norm_tr = 0.1475
-- Starting training on experience 459 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2193
	data_grads_norm = 3.0138
	new_data_grads_norm = 6.2968
	old_data_grads_norm = 2.9458
	sim_grads_norm_tr = -0.3178
-- Starting training on experience 460 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5152
	data_grads_norm = 4.0218
	new_data_grads_norm = 5.7822
	old_data_grads_norm = 4.8160
	sim_grads_norm_tr = -0.0647
-- Starting training on experience 461 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3933
	data_grads_norm = 3.7611
	new_data_grads_norm = 5.7611
	old_data_grads_norm = 3.9166
	sim_grads_norm_tr = 0.0820
-- Starting training on experience 462 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6720
	data_grads_norm = 3.4261
	new_data_grads_norm = 5.8593
	old_data_grads_norm = 3.4064
	sim_grads_norm_tr = -0.0462
-- Starting training on experience 463 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0969
	data_grads_norm = 3.2146
	new_data_grads_norm = 5.8138
	old_data_grads_norm = 4.9140
	sim_grads_norm_tr = -0.0643
-- Starting training on experience 464 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9069
	data_grads_norm = 4.2412
	new_data_grads_norm = 6.2932
	old_data_grads_norm = 4.3006
	sim_grads_norm_tr = 0.1251
-- Starting training on experience 465 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6139
	data_grads_norm = 3.7902
	new_data_grads_norm = 5.2873
	old_data_grads_norm = 5.1428
	sim_grads_norm_tr = 0.0265
-- Starting training on experience 466 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3534
	data_grads_norm = 4.0707
	new_data_grads_norm = 6.2529
	old_data_grads_norm = 5.4064
	sim_grads_norm_tr = 0.0312
-- Starting training on experience 467 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7200
	data_grads_norm = 4.2260
	new_data_grads_norm = 7.0460
	old_data_grads_norm = 5.5804
	sim_grads_norm_tr = -0.1224
-- Starting training on experience 468 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7495
	data_grads_norm = 3.6591
	new_data_grads_norm = 5.4980
	old_data_grads_norm = 3.6520
	sim_grads_norm_tr = 0.1406
-- Starting training on experience 469 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4297
	data_grads_norm = 3.3126
	new_data_grads_norm = 5.4926
	old_data_grads_norm = 4.3184
	sim_grads_norm_tr = -0.0951
-- Starting training on experience 470 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8806
	data_grads_norm = 4.1836
	new_data_grads_norm = 6.2880
	old_data_grads_norm = 4.1461
	sim_grads_norm_tr = 0.2328
-- Starting training on experience 471 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2828
	data_grads_norm = 3.5942
	new_data_grads_norm = 6.1587
	old_data_grads_norm = 3.7478
	sim_grads_norm_tr = -0.0585
-- Starting training on experience 472 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8875
	data_grads_norm = 4.1253
	new_data_grads_norm = 5.9670
	old_data_grads_norm = 4.7842
	sim_grads_norm_tr = 0.0552
-- Starting training on experience 473 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8814
	data_grads_norm = 4.5146
	new_data_grads_norm = 6.4694
	old_data_grads_norm = 5.5148
	sim_grads_norm_tr = 0.0656
-- Starting training on experience 474 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3272
	data_grads_norm = 3.5735
	new_data_grads_norm = 5.6606
	old_data_grads_norm = 4.7531
	sim_grads_norm_tr = 0.0536
-- Starting training on experience 475 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6897
	data_grads_norm = 4.0541
	new_data_grads_norm = 5.7908
	old_data_grads_norm = 6.1695
	sim_grads_norm_tr = -0.0388
-- Starting training on experience 476 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7417
	data_grads_norm = 3.8378
	new_data_grads_norm = 5.5891
	old_data_grads_norm = 6.0060
	sim_grads_norm_tr = 0.0263
-- Starting training on experience 477 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8620
	data_grads_norm = 3.8629
	new_data_grads_norm = 5.3170
	old_data_grads_norm = 4.3219
	sim_grads_norm_tr = 0.3182
-- Starting training on experience 478 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5785
	data_grads_norm = 3.7983
	new_data_grads_norm = 5.3357
	old_data_grads_norm = 5.5134
	sim_grads_norm_tr = 0.0960
-- Starting training on experience 479 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3671
	data_grads_norm = 3.1009
	new_data_grads_norm = 5.2800
	old_data_grads_norm = 2.7470
	sim_grads_norm_tr = -0.0482
-- Starting training on experience 480 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6239
	data_grads_norm = 3.4158
	new_data_grads_norm = 5.3927
	old_data_grads_norm = 3.2967
	sim_grads_norm_tr = 0.1211
-- Starting training on experience 481 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2042
	data_grads_norm = 2.8597
	new_data_grads_norm = 5.3918
	old_data_grads_norm = 3.3513
	sim_grads_norm_tr = -0.0810
-- Starting training on experience 482 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3814
	data_grads_norm = 3.2915
	new_data_grads_norm = 5.6530
	old_data_grads_norm = 3.8943
	sim_grads_norm_tr = 0.0366
-- Starting training on experience 483 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4024
	data_grads_norm = 3.0731
	new_data_grads_norm = 4.8206
	old_data_grads_norm = 3.3625
	sim_grads_norm_tr = -0.0385
-- Starting training on experience 484 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4540
	data_grads_norm = 3.6255
	new_data_grads_norm = 5.6140
	old_data_grads_norm = 3.9428
	sim_grads_norm_tr = -0.1327
-- Starting training on experience 485 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5487
	data_grads_norm = 3.4203
	new_data_grads_norm = 5.6414
	old_data_grads_norm = 3.6235
	sim_grads_norm_tr = 0.0001
-- Starting training on experience 486 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4373
	data_grads_norm = 3.5605
	new_data_grads_norm = 5.8093
	old_data_grads_norm = 3.5456
	sim_grads_norm_tr = 0.0142
-- Starting training on experience 487 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5032
	data_grads_norm = 4.1486
	new_data_grads_norm = 6.2984
	old_data_grads_norm = 5.4986
	sim_grads_norm_tr = -0.0489
-- Starting training on experience 488 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9046
	data_grads_norm = 3.9918
	new_data_grads_norm = 5.3879
	old_data_grads_norm = 4.7392
	sim_grads_norm_tr = 0.0288
-- Starting training on experience 489 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6620
	data_grads_norm = 3.8268
	new_data_grads_norm = 6.2656
	old_data_grads_norm = 3.6167
	sim_grads_norm_tr = 0.1435
-- Starting training on experience 490 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4974
	data_grads_norm = 3.5459
	new_data_grads_norm = 5.3620
	old_data_grads_norm = 4.5240
	sim_grads_norm_tr = -0.0334
-- Starting training on experience 491 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8587
	data_grads_norm = 4.0226
	new_data_grads_norm = 5.6561
	old_data_grads_norm = 3.9581
	sim_grads_norm_tr = -0.0223
-- Starting training on experience 492 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4212
	data_grads_norm = 3.1661
	new_data_grads_norm = 5.2300
	old_data_grads_norm = 3.7358
	sim_grads_norm_tr = 0.1997
-- Starting training on experience 493 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4791
	data_grads_norm = 3.6721
	new_data_grads_norm = 6.0655
	old_data_grads_norm = 5.1236
	sim_grads_norm_tr = 0.1265
-- Starting training on experience 494 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7652
	data_grads_norm = 3.3306
	new_data_grads_norm = 5.6069
	old_data_grads_norm = 4.1053
	sim_grads_norm_tr = -0.1115
-- Starting training on experience 495 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6516
	data_grads_norm = 3.7323
	new_data_grads_norm = 5.7311
	old_data_grads_norm = 4.7371
	sim_grads_norm_tr = -0.0170
-- Starting training on experience 496 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6146
	data_grads_norm = 3.4677
	new_data_grads_norm = 6.1239
	old_data_grads_norm = 2.8403
	sim_grads_norm_tr = 0.1071
-- Starting training on experience 497 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0496
	data_grads_norm = 4.2400
	new_data_grads_norm = 6.4289
	old_data_grads_norm = 3.9232
	sim_grads_norm_tr = 0.0734
-- Starting training on experience 498 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7213
	data_grads_norm = 3.9062
	new_data_grads_norm = 5.9473
	old_data_grads_norm = 4.9879
	sim_grads_norm_tr = -0.0875
-- Starting training on experience 499 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9814
	data_grads_norm = 4.1130
	new_data_grads_norm = 5.9229
	old_data_grads_norm = 4.0886
	sim_grads_norm_tr = 0.1189
-- Starting training on experience 500 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9580
	data_grads_norm = 4.3910
	new_data_grads_norm = 6.8216
	old_data_grads_norm = 4.4392
	sim_grads_norm_tr = 0.2027
-- Starting training on experience 501 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5976
	data_grads_norm = 3.6339
	new_data_grads_norm = 5.6037
	old_data_grads_norm = 4.1402
	sim_grads_norm_tr = -0.0388
-- Starting training on experience 502 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5232
	data_grads_norm = 3.6179
	new_data_grads_norm = 5.3254
	old_data_grads_norm = 4.1725
	sim_grads_norm_tr = -0.1081
-- Starting training on experience 503 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6647
	data_grads_norm = 4.0939
	new_data_grads_norm = 6.0218
	old_data_grads_norm = 5.1901
	sim_grads_norm_tr = 0.0436
-- Starting training on experience 504 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8930
	data_grads_norm = 4.3526
	new_data_grads_norm = 5.7305
	old_data_grads_norm = 4.2214
	sim_grads_norm_tr = 0.3044
-- Starting training on experience 505 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9133
	data_grads_norm = 3.5177
	new_data_grads_norm = 5.2016
	old_data_grads_norm = 5.5798
	sim_grads_norm_tr = -0.0976
-- Starting training on experience 506 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7991
	data_grads_norm = 4.1113
	new_data_grads_norm = 6.1869
	old_data_grads_norm = 3.8896
	sim_grads_norm_tr = 0.0790
-- Starting training on experience 507 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8334
	data_grads_norm = 3.3943
	new_data_grads_norm = 5.4216
	old_data_grads_norm = 3.8127
	sim_grads_norm_tr = 0.0358
-- Starting training on experience 508 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4790
	data_grads_norm = 3.2097
	new_data_grads_norm = 5.3080
	old_data_grads_norm = 4.0582
	sim_grads_norm_tr = -0.0047
-- Starting training on experience 509 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1569
	data_grads_norm = 2.6150
	new_data_grads_norm = 5.8685
	old_data_grads_norm = 2.7751
	sim_grads_norm_tr = -0.2458
-- Starting training on experience 510 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6437
	data_grads_norm = 3.5334
	new_data_grads_norm = 5.4635
	old_data_grads_norm = 3.6546
	sim_grads_norm_tr = 0.2032
-- Starting training on experience 511 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4493
	data_grads_norm = 3.3641
	new_data_grads_norm = 6.2950
	old_data_grads_norm = 3.3036
	sim_grads_norm_tr = -0.0242
-- Starting training on experience 512 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4209
	data_grads_norm = 3.4557
	new_data_grads_norm = 5.9408
	old_data_grads_norm = 3.4326
	sim_grads_norm_tr = -0.0303
-- Starting training on experience 513 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5932
	data_grads_norm = 3.3158
	new_data_grads_norm = 6.6844
	old_data_grads_norm = 2.8105
	sim_grads_norm_tr = -0.1023
-- Starting training on experience 514 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6624
	data_grads_norm = 4.3644
	new_data_grads_norm = 6.1749
	old_data_grads_norm = 4.8142
	sim_grads_norm_tr = 0.1559
-- Starting training on experience 515 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4686
	data_grads_norm = 3.4107
	new_data_grads_norm = 6.0173
	old_data_grads_norm = 3.4874
	sim_grads_norm_tr = -0.0924
-- Starting training on experience 516 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2259
	data_grads_norm = 4.1328
	new_data_grads_norm = 6.0435
	old_data_grads_norm = 4.8217
	sim_grads_norm_tr = 0.1805
-- Starting training on experience 517 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4681
	data_grads_norm = 3.5269
	new_data_grads_norm = 4.9163
	old_data_grads_norm = 2.9716
	sim_grads_norm_tr = 0.0983
-- Starting training on experience 518 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3540
	data_grads_norm = 2.8854
	new_data_grads_norm = 6.0755
	old_data_grads_norm = 3.2457
	sim_grads_norm_tr = -0.2443
-- Starting training on experience 519 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2570
	data_grads_norm = 2.8879
	new_data_grads_norm = 5.7436
	old_data_grads_norm = 3.5910
	sim_grads_norm_tr = -0.0584
-- Starting training on experience 520 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6898
	data_grads_norm = 3.9894
	new_data_grads_norm = 5.6394
	old_data_grads_norm = 3.9827
	sim_grads_norm_tr = -0.0585
-- Starting training on experience 521 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7629
	data_grads_norm = 3.7276
	new_data_grads_norm = 5.0600
	old_data_grads_norm = 4.9080
	sim_grads_norm_tr = 0.1181
-- Starting training on experience 522 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0184
	data_grads_norm = 4.3083
	new_data_grads_norm = 5.8388
	old_data_grads_norm = 4.2831
	sim_grads_norm_tr = 0.2177
-- Starting training on experience 523 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5026
	data_grads_norm = 3.2875
	new_data_grads_norm = 5.4997
	old_data_grads_norm = 3.4539
	sim_grads_norm_tr = 0.0133
-- Starting training on experience 524 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3731
	data_grads_norm = 3.1613
	new_data_grads_norm = 5.3964
	old_data_grads_norm = 3.4737
	sim_grads_norm_tr = 0.1061
-- Starting training on experience 525 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6098
	data_grads_norm = 4.0508
	new_data_grads_norm = 6.0136
	old_data_grads_norm = 4.9687
	sim_grads_norm_tr = 0.1131
-- Starting training on experience 526 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1560
	data_grads_norm = 2.4946
	new_data_grads_norm = 4.6770
	old_data_grads_norm = 5.0253
	sim_grads_norm_tr = -0.1353
-- Starting training on experience 527 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2934
	data_grads_norm = 2.7813
	new_data_grads_norm = 5.2312
	old_data_grads_norm = 3.4185
	sim_grads_norm_tr = -0.1520
-- Starting training on experience 528 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6758
	data_grads_norm = 3.5976
	new_data_grads_norm = 5.9784
	old_data_grads_norm = 3.2571
	sim_grads_norm_tr = 0.0174
-- Starting training on experience 529 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4766
	data_grads_norm = 2.9890
	new_data_grads_norm = 5.2422
	old_data_grads_norm = 3.0310
	sim_grads_norm_tr = 0.0998
-- Starting training on experience 530 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7967
	data_grads_norm = 3.9020
	new_data_grads_norm = 5.3908
	old_data_grads_norm = 4.5786
	sim_grads_norm_tr = 0.1081
-- Starting training on experience 531 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3412
	data_grads_norm = 3.1712
	new_data_grads_norm = 5.5332
	old_data_grads_norm = 4.4409
	sim_grads_norm_tr = -0.1549
-- Starting training on experience 532 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4213
	data_grads_norm = 3.6531
	new_data_grads_norm = 5.1630
	old_data_grads_norm = 6.1204
	sim_grads_norm_tr = 0.0734
-- Starting training on experience 533 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5255
	data_grads_norm = 3.6682
	new_data_grads_norm = 5.7511
	old_data_grads_norm = 4.6457
	sim_grads_norm_tr = -0.0500
-- Starting training on experience 534 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3898
	data_grads_norm = 3.8155
	new_data_grads_norm = 5.1401
	old_data_grads_norm = 3.8853
	sim_grads_norm_tr = -0.1012
-- Starting training on experience 535 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2422
	data_grads_norm = 3.2594
	new_data_grads_norm = 5.7803
	old_data_grads_norm = 3.4837
	sim_grads_norm_tr = 0.0528
-- Starting training on experience 536 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5776
	data_grads_norm = 3.6911
	new_data_grads_norm = 6.1745
	old_data_grads_norm = 5.2407
	sim_grads_norm_tr = -0.0554
-- Starting training on experience 537 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5997
	data_grads_norm = 3.9504
	new_data_grads_norm = 6.2652
	old_data_grads_norm = 3.6951
	sim_grads_norm_tr = 0.1238
-- Starting training on experience 538 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5118
	data_grads_norm = 3.6438
	new_data_grads_norm = 5.3724
	old_data_grads_norm = 4.1549
	sim_grads_norm_tr = -0.1062
-- Starting training on experience 539 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2649
	data_grads_norm = 2.7789
	new_data_grads_norm = 5.2210
	old_data_grads_norm = 3.7245
	sim_grads_norm_tr = -0.2161
-- Starting training on experience 540 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6554
	data_grads_norm = 3.7490
	new_data_grads_norm = 6.2129
	old_data_grads_norm = 3.6689
	sim_grads_norm_tr = -0.1355
-- Starting training on experience 541 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8411
	data_grads_norm = 4.1353
	new_data_grads_norm = 6.3174
	old_data_grads_norm = 4.3053
	sim_grads_norm_tr = -0.0099
-- Starting training on experience 542 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7663
	data_grads_norm = 4.2620
	new_data_grads_norm = 6.0749
	old_data_grads_norm = 5.3196
	sim_grads_norm_tr = 0.1195
-- Starting training on experience 543 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3016
	data_grads_norm = 4.1843
	new_data_grads_norm = 6.1348
	old_data_grads_norm = 4.3676
	sim_grads_norm_tr = 0.1871
-- Starting training on experience 544 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7142
	data_grads_norm = 3.7709
	new_data_grads_norm = 5.3583
	old_data_grads_norm = 5.2299
	sim_grads_norm_tr = -0.1057
-- Starting training on experience 545 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7334
	data_grads_norm = 3.6520
	new_data_grads_norm = 5.4144
	old_data_grads_norm = 3.8576
	sim_grads_norm_tr = 0.2131
-- Starting training on experience 546 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7733
	data_grads_norm = 4.1396
	new_data_grads_norm = 5.7120
	old_data_grads_norm = 5.4602
	sim_grads_norm_tr = 0.0238
-- Starting training on experience 547 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3874
	data_grads_norm = 3.7054
	new_data_grads_norm = 5.6949
	old_data_grads_norm = 4.3529
	sim_grads_norm_tr = 0.0967
-- Starting training on experience 548 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2879
	data_grads_norm = 2.9541
	new_data_grads_norm = 5.5291
	old_data_grads_norm = 3.3754
	sim_grads_norm_tr = 0.0446
-- Starting training on experience 549 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3915
	data_grads_norm = 2.9947
	new_data_grads_norm = 5.7431
	old_data_grads_norm = 3.1472
	sim_grads_norm_tr = 0.0163
-- Starting training on experience 550 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7140
	data_grads_norm = 4.2483
	new_data_grads_norm = 6.7321
	old_data_grads_norm = 4.0568
	sim_grads_norm_tr = 0.1471
-- Starting training on experience 551 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6384
	data_grads_norm = 3.2246
	new_data_grads_norm = 5.3204
	old_data_grads_norm = 3.3615
	sim_grads_norm_tr = 0.1354
-- Starting training on experience 552 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5328
	data_grads_norm = 3.3781
	new_data_grads_norm = 5.3798
	old_data_grads_norm = 4.5529
	sim_grads_norm_tr = 0.0151
-- Starting training on experience 553 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1106
	data_grads_norm = 2.8351
	new_data_grads_norm = 4.7795
	old_data_grads_norm = 4.6209
	sim_grads_norm_tr = -0.2062
-- Starting training on experience 554 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4976
	data_grads_norm = 4.1466
	new_data_grads_norm = 5.8870
	old_data_grads_norm = 3.8299
	sim_grads_norm_tr = 0.1781
-- Starting training on experience 555 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6368
	data_grads_norm = 4.2009
	new_data_grads_norm = 6.1426
	old_data_grads_norm = 3.6527
	sim_grads_norm_tr = -0.1375
-- Starting training on experience 556 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6533
	data_grads_norm = 3.7239
	new_data_grads_norm = 5.8016
	old_data_grads_norm = 3.6019
	sim_grads_norm_tr = 0.0855
-- Starting training on experience 557 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0356
	data_grads_norm = 4.9470
	new_data_grads_norm = 6.8110
	old_data_grads_norm = 5.2775
	sim_grads_norm_tr = 0.0808
-- Starting training on experience 558 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5670
	data_grads_norm = 3.6436
	new_data_grads_norm = 5.6051
	old_data_grads_norm = 2.6792
	sim_grads_norm_tr = 0.0109
-- Starting training on experience 559 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5740
	data_grads_norm = 3.9241
	new_data_grads_norm = 6.5846
	old_data_grads_norm = 3.7612
	sim_grads_norm_tr = -0.1389
-- Starting training on experience 560 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8602
	data_grads_norm = 4.1941
	new_data_grads_norm = 6.2556
	old_data_grads_norm = 4.2667
	sim_grads_norm_tr = 0.3298
-- Starting training on experience 561 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1854
	data_grads_norm = 3.8015
	new_data_grads_norm = 5.7520
	old_data_grads_norm = 3.9575
	sim_grads_norm_tr = -0.0405
-- Starting training on experience 562 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7040
	data_grads_norm = 4.0107
	new_data_grads_norm = 7.1549
	old_data_grads_norm = 4.5817
	sim_grads_norm_tr = 0.1453
-- Starting training on experience 563 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2619
	data_grads_norm = 3.1287
	new_data_grads_norm = 5.3874
	old_data_grads_norm = 4.5328
	sim_grads_norm_tr = -0.0854
-- Starting training on experience 564 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1946
	data_grads_norm = 3.1899
	new_data_grads_norm = 5.5090
	old_data_grads_norm = 3.1358
	sim_grads_norm_tr = -0.1599
-- Starting training on experience 565 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4963
	data_grads_norm = 3.5194
	new_data_grads_norm = 5.9407
	old_data_grads_norm = 5.4330
	sim_grads_norm_tr = -0.0246
-- Starting training on experience 566 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6031
	data_grads_norm = 3.5633
	new_data_grads_norm = 5.4461
	old_data_grads_norm = 5.0500
	sim_grads_norm_tr = -0.0250
-- Starting training on experience 567 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5981
	data_grads_norm = 3.8604
	new_data_grads_norm = 5.8715
	old_data_grads_norm = 3.8719
	sim_grads_norm_tr = 0.0426
-- Starting training on experience 568 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5483
	data_grads_norm = 3.6091
	new_data_grads_norm = 6.2224
	old_data_grads_norm = 3.5712
	sim_grads_norm_tr = 0.1082
-- Starting training on experience 569 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7421
	data_grads_norm = 3.7214
	new_data_grads_norm = 6.1054
	old_data_grads_norm = 3.9823
	sim_grads_norm_tr = -0.1116
-- Starting training on experience 570 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7854
	data_grads_norm = 4.2623
	new_data_grads_norm = 6.1135
	old_data_grads_norm = 6.5045
	sim_grads_norm_tr = -0.0947
-- Starting training on experience 571 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3279
	data_grads_norm = 3.6941
	new_data_grads_norm = 6.6605
	old_data_grads_norm = 2.2983
	sim_grads_norm_tr = 0.0386
-- Starting training on experience 572 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2404
	data_grads_norm = 4.3352
	new_data_grads_norm = 5.6668
	old_data_grads_norm = 4.8359
	sim_grads_norm_tr = 0.2623
-- Starting training on experience 573 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5680
	data_grads_norm = 3.5127
	new_data_grads_norm = 6.1996
	old_data_grads_norm = 4.3687
	sim_grads_norm_tr = -0.0439
-- Starting training on experience 574 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4685
	data_grads_norm = 3.8590
	new_data_grads_norm = 6.0291
	old_data_grads_norm = 4.7450
	sim_grads_norm_tr = -0.0904
-- Starting training on experience 575 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7699
	data_grads_norm = 3.8632
	new_data_grads_norm = 5.5228
	old_data_grads_norm = 5.3605
	sim_grads_norm_tr = -0.0921
-- Starting training on experience 576 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6544
	data_grads_norm = 4.3198
	new_data_grads_norm = 5.3963
	old_data_grads_norm = 5.0038
	sim_grads_norm_tr = -0.0456
-- Starting training on experience 577 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7920
	data_grads_norm = 4.7065
	new_data_grads_norm = 7.1115
	old_data_grads_norm = 3.5483
	sim_grads_norm_tr = 0.0402
-- Starting training on experience 578 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2721
	data_grads_norm = 4.8758
	new_data_grads_norm = 6.3958
	old_data_grads_norm = 5.3871
	sim_grads_norm_tr = 0.3291
-- Starting training on experience 579 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0001
	data_grads_norm = 2.9370
	new_data_grads_norm = 5.6318
	old_data_grads_norm = 4.4170
	sim_grads_norm_tr = 0.0316
-- Starting training on experience 580 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2733
	data_grads_norm = 3.4055
	new_data_grads_norm = 5.8167
	old_data_grads_norm = 3.8695
	sim_grads_norm_tr = 0.0380
-- Starting training on experience 581 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7209
	data_grads_norm = 4.3822
	new_data_grads_norm = 6.7950
	old_data_grads_norm = 6.1956
	sim_grads_norm_tr = 0.0375
-- Starting training on experience 582 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3534
	data_grads_norm = 5.3333
	new_data_grads_norm = 6.7560
	old_data_grads_norm = 6.8094
	sim_grads_norm_tr = 0.2858
-- Starting training on experience 583 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4030
	data_grads_norm = 3.8760
	new_data_grads_norm = 6.7344
	old_data_grads_norm = 4.7012
	sim_grads_norm_tr = 0.0522
-- Starting training on experience 584 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0763
	data_grads_norm = 3.1016
	new_data_grads_norm = 5.0107
	old_data_grads_norm = 2.5122
	sim_grads_norm_tr = -0.1626
-- Starting training on experience 585 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4535
	data_grads_norm = 3.5980
	new_data_grads_norm = 5.4006
	old_data_grads_norm = 4.0437
	sim_grads_norm_tr = -0.1333
-- Starting training on experience 586 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1092
	data_grads_norm = 2.7792
	new_data_grads_norm = 5.6984
	old_data_grads_norm = 2.4479
	sim_grads_norm_tr = -0.0647
-- Starting training on experience 587 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4659
	data_grads_norm = 3.5497
	new_data_grads_norm = 5.8950
	old_data_grads_norm = 3.9580
	sim_grads_norm_tr = 0.0564
-- Starting training on experience 588 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3454
	data_grads_norm = 4.0513
	new_data_grads_norm = 5.9956
	old_data_grads_norm = 3.6702
	sim_grads_norm_tr = 0.1204
-- Starting training on experience 589 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6193
	data_grads_norm = 3.8839
	new_data_grads_norm = 5.3284
	old_data_grads_norm = 4.5389
	sim_grads_norm_tr = 0.0757
-- Starting training on experience 590 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2412
	data_grads_norm = 3.0585
	new_data_grads_norm = 4.9099
	old_data_grads_norm = 4.5816
	sim_grads_norm_tr = -0.2938
-- Starting training on experience 591 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2565
	data_grads_norm = 3.2669
	new_data_grads_norm = 5.1583
	old_data_grads_norm = 4.2394
	sim_grads_norm_tr = -0.0048
-- Starting training on experience 592 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7978
	data_grads_norm = 4.0353
	new_data_grads_norm = 5.4791
	old_data_grads_norm = 4.2553
	sim_grads_norm_tr = 0.3328
-- Starting training on experience 593 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3268
	data_grads_norm = 2.9016
	new_data_grads_norm = 5.5620
	old_data_grads_norm = 3.3556
	sim_grads_norm_tr = -0.0257
-- Starting training on experience 594 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3906
	data_grads_norm = 3.4204
	new_data_grads_norm = 4.7809
	old_data_grads_norm = 5.1045
	sim_grads_norm_tr = 0.0485
-- Starting training on experience 595 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4123
	data_grads_norm = 4.2642
	new_data_grads_norm = 6.7272
	old_data_grads_norm = 4.6336
	sim_grads_norm_tr = -0.1486
-- Starting training on experience 596 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7124
	data_grads_norm = 3.5537
	new_data_grads_norm = 5.1864
	old_data_grads_norm = 6.2628
	sim_grads_norm_tr = -0.1225
-- Starting training on experience 597 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6883
	data_grads_norm = 3.8158
	new_data_grads_norm = 5.9576
	old_data_grads_norm = 4.0017
	sim_grads_norm_tr = -0.0155
-- Starting training on experience 598 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8741
	data_grads_norm = 4.7648
	new_data_grads_norm = 6.4740
	old_data_grads_norm = 4.4448
	sim_grads_norm_tr = 0.0804
-- Starting training on experience 599 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8890
	data_grads_norm = 4.4037
	new_data_grads_norm = 5.8031
	old_data_grads_norm = 4.6327
	sim_grads_norm_tr = 0.3688
-- Starting training on experience 600 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3461
	data_grads_norm = 3.1157
	new_data_grads_norm = 5.5648
	old_data_grads_norm = 4.1168
	sim_grads_norm_tr = -0.1937
-- Starting training on experience 601 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6175
	data_grads_norm = 3.4348
	new_data_grads_norm = 5.3746
	old_data_grads_norm = 2.5886
	sim_grads_norm_tr = 0.1112
-- Starting training on experience 602 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7532
	data_grads_norm = 4.0542
	new_data_grads_norm = 6.0982
	old_data_grads_norm = 3.7998
	sim_grads_norm_tr = -0.0563
-- Starting training on experience 603 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3650
	data_grads_norm = 3.0400
	new_data_grads_norm = 5.5890
	old_data_grads_norm = 3.6854
	sim_grads_norm_tr = 0.1252
-- Starting training on experience 604 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5183
	data_grads_norm = 3.4715
	new_data_grads_norm = 5.3053
	old_data_grads_norm = 3.8595
	sim_grads_norm_tr = 0.0962
-- Starting training on experience 605 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5948
	data_grads_norm = 3.3427
	new_data_grads_norm = 5.7370
	old_data_grads_norm = 3.1537
	sim_grads_norm_tr = 0.0513
-- Starting training on experience 606 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7346
	data_grads_norm = 3.6122
	new_data_grads_norm = 4.8861
	old_data_grads_norm = 4.3672
	sim_grads_norm_tr = 0.0080
-- Starting training on experience 607 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3212
	data_grads_norm = 3.8981
	new_data_grads_norm = 5.9890
	old_data_grads_norm = 4.6376
	sim_grads_norm_tr = -0.0325
-- Starting training on experience 608 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7550
	data_grads_norm = 4.1018
	new_data_grads_norm = 5.6724
	old_data_grads_norm = 5.5876
	sim_grads_norm_tr = 0.0313
-- Starting training on experience 609 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3240
	data_grads_norm = 4.3178
	new_data_grads_norm = 7.2224
	old_data_grads_norm = 3.8370
	sim_grads_norm_tr = 0.0005
-- Starting training on experience 610 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7776
	data_grads_norm = 3.7687
	new_data_grads_norm = 5.7503
	old_data_grads_norm = 4.3088
	sim_grads_norm_tr = -0.0198
-- Starting training on experience 611 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5380
	data_grads_norm = 3.4801
	new_data_grads_norm = 6.4141
	old_data_grads_norm = 3.6162
	sim_grads_norm_tr = -0.0211
-- Starting training on experience 612 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5756
	data_grads_norm = 3.4541
	new_data_grads_norm = 5.5481
	old_data_grads_norm = 3.9466
	sim_grads_norm_tr = -0.1045
-- Starting training on experience 613 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6616
	data_grads_norm = 4.4050
	new_data_grads_norm = 6.5416
	old_data_grads_norm = 5.0805
	sim_grads_norm_tr = 0.1075
-- Starting training on experience 614 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0155
	data_grads_norm = 3.9572
	new_data_grads_norm = 6.1040
	old_data_grads_norm = 4.7389
	sim_grads_norm_tr = 0.0069
-- Starting training on experience 615 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8055
	data_grads_norm = 4.7520
	new_data_grads_norm = 7.0801
	old_data_grads_norm = 5.6580
	sim_grads_norm_tr = 0.1092
-- Starting training on experience 616 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8186
	data_grads_norm = 4.1483
	new_data_grads_norm = 6.3976
	old_data_grads_norm = 4.5227
	sim_grads_norm_tr = 0.2097
-- Starting training on experience 617 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8375
	data_grads_norm = 3.6957
	new_data_grads_norm = 6.4166
	old_data_grads_norm = 5.0249
	sim_grads_norm_tr = 0.0900
-- Starting training on experience 618 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6045
	data_grads_norm = 3.4406
	new_data_grads_norm = 5.9165
	old_data_grads_norm = 4.5890
	sim_grads_norm_tr = -0.0570
-- Starting training on experience 619 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3685
	data_grads_norm = 3.7472
	new_data_grads_norm = 6.7414
	old_data_grads_norm = 3.1947
	sim_grads_norm_tr = 0.0679
-- Starting training on experience 620 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7599
	data_grads_norm = 3.6641
	new_data_grads_norm = 5.7432
	old_data_grads_norm = 3.5375
	sim_grads_norm_tr = -0.0307
-- Starting training on experience 621 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8283
	data_grads_norm = 3.8776
	new_data_grads_norm = 6.1126
	old_data_grads_norm = 3.6321
	sim_grads_norm_tr = 0.2351
-- Starting training on experience 622 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7815
	data_grads_norm = 3.5439
	new_data_grads_norm = 5.7250
	old_data_grads_norm = 3.9947
	sim_grads_norm_tr = 0.1591
-- Starting training on experience 623 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3378
	data_grads_norm = 3.4258
	new_data_grads_norm = 5.7070
	old_data_grads_norm = 3.6553
	sim_grads_norm_tr = -0.0972
-- Starting training on experience 624 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8178
	data_grads_norm = 3.8626
	new_data_grads_norm = 5.7553
	old_data_grads_norm = 4.0551
	sim_grads_norm_tr = 0.2875
-- Starting training on experience 625 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6036
	data_grads_norm = 3.8161
	new_data_grads_norm = 6.4397
	old_data_grads_norm = 4.3430
	sim_grads_norm_tr = -0.0290
-- Starting training on experience 626 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8028
	data_grads_norm = 4.9228
	new_data_grads_norm = 7.0922
	old_data_grads_norm = 5.2448
	sim_grads_norm_tr = 0.3600
-- Starting training on experience 627 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2299
	data_grads_norm = 3.7111
	new_data_grads_norm = 5.9808
	old_data_grads_norm = 5.3858
	sim_grads_norm_tr = -0.0325
-- Starting training on experience 628 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3225
	data_grads_norm = 3.2117
	new_data_grads_norm = 5.4175
	old_data_grads_norm = 3.8732
	sim_grads_norm_tr = -0.0527
-- Starting training on experience 629 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4316
	data_grads_norm = 3.8870
	new_data_grads_norm = 5.6568
	old_data_grads_norm = 4.2047
	sim_grads_norm_tr = -0.0289
-- Starting training on experience 630 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8805
	data_grads_norm = 3.7981
	new_data_grads_norm = 5.7445
	old_data_grads_norm = 4.0834
	sim_grads_norm_tr = 0.0052
-- Starting training on experience 631 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1278
	data_grads_norm = 4.0995
	new_data_grads_norm = 5.2804
	old_data_grads_norm = 5.0717
	sim_grads_norm_tr = -0.0035
-- Starting training on experience 632 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9201
	data_grads_norm = 4.5378
	new_data_grads_norm = 6.2766
	old_data_grads_norm = 5.5827
	sim_grads_norm_tr = -0.1251
-- Starting training on experience 633 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1652
	data_grads_norm = 3.9486
	new_data_grads_norm = 6.3628
	old_data_grads_norm = 4.3665
	sim_grads_norm_tr = 0.1060
-- Starting training on experience 634 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8268
	data_grads_norm = 3.6932
	new_data_grads_norm = 6.1856
	old_data_grads_norm = 3.2254
	sim_grads_norm_tr = 0.2310
-- Starting training on experience 635 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7796
	data_grads_norm = 3.8075
	new_data_grads_norm = 5.8466
	old_data_grads_norm = 3.9849
	sim_grads_norm_tr = 0.2285
-- Starting training on experience 636 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3750
	data_grads_norm = 3.8579
	new_data_grads_norm = 6.2406
	old_data_grads_norm = 3.8985
	sim_grads_norm_tr = 0.0370
-- Starting training on experience 637 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9963
	data_grads_norm = 4.4880
	new_data_grads_norm = 6.0163
	old_data_grads_norm = 4.1782
	sim_grads_norm_tr = 0.2325
-- Starting training on experience 638 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6114
	data_grads_norm = 3.8296
	new_data_grads_norm = 5.9512
	old_data_grads_norm = 3.7922
	sim_grads_norm_tr = 0.1776
-- Starting training on experience 639 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2272
	data_grads_norm = 3.3371
	new_data_grads_norm = 5.3179
	old_data_grads_norm = 4.3783
	sim_grads_norm_tr = -0.1561
-- Starting training on experience 640 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3706
	data_grads_norm = 4.5410
	new_data_grads_norm = 6.3419
	old_data_grads_norm = 4.3245
	sim_grads_norm_tr = -0.0150
-- Starting training on experience 641 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4648
	data_grads_norm = 3.6695
	new_data_grads_norm = 6.1265
	old_data_grads_norm = 3.9196
	sim_grads_norm_tr = 0.0544
-- Starting training on experience 642 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4156
	data_grads_norm = 4.2563
	new_data_grads_norm = 5.6060
	old_data_grads_norm = 5.6640
	sim_grads_norm_tr = 0.0962
-- Starting training on experience 643 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8368
	data_grads_norm = 3.9121
	new_data_grads_norm = 6.3721
	old_data_grads_norm = 4.3748
	sim_grads_norm_tr = 0.0509
-- Starting training on experience 644 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5306
	data_grads_norm = 3.5568
	new_data_grads_norm = 6.1701
	old_data_grads_norm = 3.8228
	sim_grads_norm_tr = 0.1537
-- Starting training on experience 645 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0031
	data_grads_norm = 2.7289
	new_data_grads_norm = 6.2493
	old_data_grads_norm = 3.0315
	sim_grads_norm_tr = -0.0118
-- Starting training on experience 646 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6284
	data_grads_norm = 4.1417
	new_data_grads_norm = 7.2152
	old_data_grads_norm = 4.1648
	sim_grads_norm_tr = -0.0934
-- Starting training on experience 647 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1182
	data_grads_norm = 3.1537
	new_data_grads_norm = 5.8337
	old_data_grads_norm = 4.5111
	sim_grads_norm_tr = -0.0120
-- Starting training on experience 648 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5276
	data_grads_norm = 4.2495
	new_data_grads_norm = 5.9872
	old_data_grads_norm = 6.5417
	sim_grads_norm_tr = -0.0466
-- Starting training on experience 649 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9619
	data_grads_norm = 5.8222
	new_data_grads_norm = 6.2379
	old_data_grads_norm = 6.6187
	sim_grads_norm_tr = 0.2852
-- Starting training on experience 650 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0647
	data_grads_norm = 3.0171
	new_data_grads_norm = 5.9315
	old_data_grads_norm = 3.4112
	sim_grads_norm_tr = -0.0232
-- Starting training on experience 651 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0201
	data_grads_norm = 2.9207
	new_data_grads_norm = 6.0387
	old_data_grads_norm = 3.9870
	sim_grads_norm_tr = -0.0465
-- Starting training on experience 652 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1145
	data_grads_norm = 3.1166
	new_data_grads_norm = 6.2160
	old_data_grads_norm = 4.4079
	sim_grads_norm_tr = -0.1449
-- Starting training on experience 653 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4624
	data_grads_norm = 3.7266
	new_data_grads_norm = 5.9302
	old_data_grads_norm = 3.9107
	sim_grads_norm_tr = -0.0727
-- Starting training on experience 654 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7338
	data_grads_norm = 4.3248
	new_data_grads_norm = 6.3770
	old_data_grads_norm = 3.7383
	sim_grads_norm_tr = 0.2909
-- Starting training on experience 655 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8276
	data_grads_norm = 3.9079
	new_data_grads_norm = 5.7820
	old_data_grads_norm = 4.8221
	sim_grads_norm_tr = -0.0597
-- Starting training on experience 656 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1828
	data_grads_norm = 4.4992
	new_data_grads_norm = 5.9241
	old_data_grads_norm = 5.6972
	sim_grads_norm_tr = -0.0078
-- Starting training on experience 657 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6664
	data_grads_norm = 3.7887
	new_data_grads_norm = 6.1403
	old_data_grads_norm = 3.5157
	sim_grads_norm_tr = 0.1343
-- Starting training on experience 658 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7815
	data_grads_norm = 3.9157
	new_data_grads_norm = 5.7712
	old_data_grads_norm = 4.2385
	sim_grads_norm_tr = 0.1525
-- Starting training on experience 659 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4656
	data_grads_norm = 3.1084
	new_data_grads_norm = 5.1011
	old_data_grads_norm = 3.9204
	sim_grads_norm_tr = -0.0500
-- Starting training on experience 660 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7818
	data_grads_norm = 4.6425
	new_data_grads_norm = 6.2832
	old_data_grads_norm = 5.4723
	sim_grads_norm_tr = -0.0033
-- Starting training on experience 661 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2571
	data_grads_norm = 3.7577
	new_data_grads_norm = 5.7895
	old_data_grads_norm = 3.4972
	sim_grads_norm_tr = 0.0330
-- Starting training on experience 662 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6246
	data_grads_norm = 3.6267
	new_data_grads_norm = 5.7055
	old_data_grads_norm = 4.4674
	sim_grads_norm_tr = 0.0574
-- Starting training on experience 663 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6920
	data_grads_norm = 4.7618
	new_data_grads_norm = 6.1238
	old_data_grads_norm = 4.9667
	sim_grads_norm_tr = 0.1308
-- Starting training on experience 664 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3855
	data_grads_norm = 3.4013
	new_data_grads_norm = 5.8225
	old_data_grads_norm = 4.1803
	sim_grads_norm_tr = -0.1150
-- Starting training on experience 665 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4130
	data_grads_norm = 3.3806
	new_data_grads_norm = 5.4781
	old_data_grads_norm = 2.9326
	sim_grads_norm_tr = -0.0421
-- Starting training on experience 666 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5811
	data_grads_norm = 3.4987
	new_data_grads_norm = 5.5981
	old_data_grads_norm = 3.7675
	sim_grads_norm_tr = -0.0014
-- Starting training on experience 667 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6236
	data_grads_norm = 4.6414
	new_data_grads_norm = 6.0717
	old_data_grads_norm = 4.8754
	sim_grads_norm_tr = 0.1705
-- Starting training on experience 668 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1760
	data_grads_norm = 3.4391
	new_data_grads_norm = 5.9406
	old_data_grads_norm = 4.1043
	sim_grads_norm_tr = -0.0080
-- Starting training on experience 669 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6335
	data_grads_norm = 3.8046
	new_data_grads_norm = 5.6381
	old_data_grads_norm = 4.8420
	sim_grads_norm_tr = -0.0234
-- Starting training on experience 670 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7426
	data_grads_norm = 3.6179
	new_data_grads_norm = 6.4788
	old_data_grads_norm = 2.6074
	sim_grads_norm_tr = -0.0413
-- Starting training on experience 671 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2945
	data_grads_norm = 3.7540
	new_data_grads_norm = 6.2065
	old_data_grads_norm = 4.5386
	sim_grads_norm_tr = -0.1310
-- Starting training on experience 672 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5634
	data_grads_norm = 5.1694
	new_data_grads_norm = 6.7365
	old_data_grads_norm = 5.5252
	sim_grads_norm_tr = 0.2104
-- Starting training on experience 673 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8514
	data_grads_norm = 4.5310
	new_data_grads_norm = 6.6628
	old_data_grads_norm = 4.2661
	sim_grads_norm_tr = 0.1712
-- Starting training on experience 674 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2746
	data_grads_norm = 3.6949
	new_data_grads_norm = 6.1477
	old_data_grads_norm = 4.4459
	sim_grads_norm_tr = -0.1061
-- Starting training on experience 675 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4969
	data_grads_norm = 3.7176
	new_data_grads_norm = 6.1479
	old_data_grads_norm = 2.8895
	sim_grads_norm_tr = -0.1220
-- Starting training on experience 676 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8799
	data_grads_norm = 4.9872
	new_data_grads_norm = 6.5923
	old_data_grads_norm = 5.2703
	sim_grads_norm_tr = 0.0885
-- Starting training on experience 677 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4860
	data_grads_norm = 4.0225
	new_data_grads_norm = 6.9096
	old_data_grads_norm = 4.5923
	sim_grads_norm_tr = -0.0394
-- Starting training on experience 678 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3131
	data_grads_norm = 4.1382
	new_data_grads_norm = 6.6619
	old_data_grads_norm = 2.9701
	sim_grads_norm_tr = 0.0853
-- Starting training on experience 679 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7875
	data_grads_norm = 4.5645
	new_data_grads_norm = 6.0686
	old_data_grads_norm = 5.5559
	sim_grads_norm_tr = 0.0567
-- Starting training on experience 680 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6002
	data_grads_norm = 4.0912
	new_data_grads_norm = 6.9450
	old_data_grads_norm = 3.9688
	sim_grads_norm_tr = 0.0199
-- Starting training on experience 681 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2447
	data_grads_norm = 2.6996
	new_data_grads_norm = 5.6975
	old_data_grads_norm = 3.0266
	sim_grads_norm_tr = -0.0860
-- Starting training on experience 682 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5277
	data_grads_norm = 5.0711
	new_data_grads_norm = 6.4735
	old_data_grads_norm = 5.2686
	sim_grads_norm_tr = 0.0538
-- Starting training on experience 683 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2713
	data_grads_norm = 3.6441
	new_data_grads_norm = 6.7585
	old_data_grads_norm = 4.2111
	sim_grads_norm_tr = -0.0896
-- Starting training on experience 684 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6204
	data_grads_norm = 4.0377
	new_data_grads_norm = 6.2491
	old_data_grads_norm = 3.5666
	sim_grads_norm_tr = 0.3093
-- Starting training on experience 685 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5524
	data_grads_norm = 4.0747
	new_data_grads_norm = 6.2416
	old_data_grads_norm = 4.1287
	sim_grads_norm_tr = -0.1063
-- Starting training on experience 686 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8633
	data_grads_norm = 4.2713
	new_data_grads_norm = 5.7028
	old_data_grads_norm = 5.5072
	sim_grads_norm_tr = 0.1653
-- Starting training on experience 687 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3916
	data_grads_norm = 3.1611
	new_data_grads_norm = 5.0955
	old_data_grads_norm = 3.9956
	sim_grads_norm_tr = -0.0270
-- Starting training on experience 688 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2114
	data_grads_norm = 3.6980
	new_data_grads_norm = 6.3477
	old_data_grads_norm = 4.3740
	sim_grads_norm_tr = -0.0857
-- Starting training on experience 689 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5662
	data_grads_norm = 4.1401
	new_data_grads_norm = 5.9812
	old_data_grads_norm = 4.5791
	sim_grads_norm_tr = 0.0086
-- Starting training on experience 690 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4261
	data_grads_norm = 4.0103
	new_data_grads_norm = 5.9298
	old_data_grads_norm = 4.9943
	sim_grads_norm_tr = 0.0302
-- Starting training on experience 691 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8068
	data_grads_norm = 4.6259
	new_data_grads_norm = 6.3268
	old_data_grads_norm = 5.3446
	sim_grads_norm_tr = 0.1234
-- Starting training on experience 692 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4280
	data_grads_norm = 3.6339
	new_data_grads_norm = 5.9617
	old_data_grads_norm = 5.5097
	sim_grads_norm_tr = -0.0568
-- Starting training on experience 693 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3563
	data_grads_norm = 3.6927
	new_data_grads_norm = 5.8453
	old_data_grads_norm = 3.5079
	sim_grads_norm_tr = 0.1474
-- Starting training on experience 694 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6522
	data_grads_norm = 4.0789
	new_data_grads_norm = 6.1740
	old_data_grads_norm = 3.6431
	sim_grads_norm_tr = 0.1554
-- Starting training on experience 695 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8553
	data_grads_norm = 3.9313
	new_data_grads_norm = 5.4041
	old_data_grads_norm = 5.4997
	sim_grads_norm_tr = 0.1646
-- Starting training on experience 696 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2776
	data_grads_norm = 3.0304
	new_data_grads_norm = 5.7109
	old_data_grads_norm = 3.6528
	sim_grads_norm_tr = -0.2705
-- Starting training on experience 697 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4122
	data_grads_norm = 4.1580
	new_data_grads_norm = 6.1893
	old_data_grads_norm = 4.8109
	sim_grads_norm_tr = 0.0572
-- Starting training on experience 698 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3821
	data_grads_norm = 3.4941
	new_data_grads_norm = 6.0126
	old_data_grads_norm = 3.5022
	sim_grads_norm_tr = 0.0392
-- Starting training on experience 699 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5844
	data_grads_norm = 3.9046
	new_data_grads_norm = 5.8294
	old_data_grads_norm = 3.5879
	sim_grads_norm_tr = 0.1186
-- Starting training on experience 700 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1799
	data_grads_norm = 2.9704
	new_data_grads_norm = 5.1844
	old_data_grads_norm = 3.8380
	sim_grads_norm_tr = -0.0669
-- Starting training on experience 701 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3641
	data_grads_norm = 3.2303
	new_data_grads_norm = 5.6347
	old_data_grads_norm = 2.9986
	sim_grads_norm_tr = 0.1414
-- Starting training on experience 702 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8312
	data_grads_norm = 3.9024
	new_data_grads_norm = 6.0520
	old_data_grads_norm = 4.5914
	sim_grads_norm_tr = 0.0825
-- Starting training on experience 703 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4993
	data_grads_norm = 3.7662
	new_data_grads_norm = 6.1499
	old_data_grads_norm = 4.6495
	sim_grads_norm_tr = 0.1116
-- Starting training on experience 704 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1574
	data_grads_norm = 3.3408
	new_data_grads_norm = 5.2008
	old_data_grads_norm = 4.3666
	sim_grads_norm_tr = -0.0627
-- Starting training on experience 705 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1606
	data_grads_norm = 3.5749
	new_data_grads_norm = 6.2698
	old_data_grads_norm = 3.4355
	sim_grads_norm_tr = 0.0077
-- Starting training on experience 706 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2226
	data_grads_norm = 3.1051
	new_data_grads_norm = 5.1636
	old_data_grads_norm = 3.1179
	sim_grads_norm_tr = 0.0143
-- Starting training on experience 707 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2914
	data_grads_norm = 3.7698
	new_data_grads_norm = 6.6886
	old_data_grads_norm = 3.5653
	sim_grads_norm_tr = -0.0015
-- Starting training on experience 708 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4141
	data_grads_norm = 3.4340
	new_data_grads_norm = 5.8149
	old_data_grads_norm = 3.1168
	sim_grads_norm_tr = 0.0021
-- Starting training on experience 709 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4153
	data_grads_norm = 3.6717
	new_data_grads_norm = 5.5998
	old_data_grads_norm = 4.5589
	sim_grads_norm_tr = -0.1678
-- Starting training on experience 710 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4952
	data_grads_norm = 3.8305
	new_data_grads_norm = 5.7183
	old_data_grads_norm = 3.5698
	sim_grads_norm_tr = 0.0649
-- Starting training on experience 711 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2900
	data_grads_norm = 3.5531
	new_data_grads_norm = 6.6275
	old_data_grads_norm = 5.1661
	sim_grads_norm_tr = -0.2304
-- Starting training on experience 712 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8124
	data_grads_norm = 5.1848
	new_data_grads_norm = 6.6628
	old_data_grads_norm = 5.0373
	sim_grads_norm_tr = 0.2588
-- Starting training on experience 713 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6400
	data_grads_norm = 3.6761
	new_data_grads_norm = 6.1439
	old_data_grads_norm = 4.3203
	sim_grads_norm_tr = 0.0996
-- Starting training on experience 714 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4709
	data_grads_norm = 3.6317
	new_data_grads_norm = 6.6153
	old_data_grads_norm = 3.5828
	sim_grads_norm_tr = -0.1198
-- Starting training on experience 715 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7924
	data_grads_norm = 4.3401
	new_data_grads_norm = 6.9650
	old_data_grads_norm = 4.9503
	sim_grads_norm_tr = -0.0426
-- Starting training on experience 716 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2305
	data_grads_norm = 3.8431
	new_data_grads_norm = 6.2799
	old_data_grads_norm = 3.8511
	sim_grads_norm_tr = -0.1001
-- Starting training on experience 717 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6843
	data_grads_norm = 4.5132
	new_data_grads_norm = 7.1277
	old_data_grads_norm = 5.8968
	sim_grads_norm_tr = 0.1061
-- Starting training on experience 718 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1798
	data_grads_norm = 3.8720
	new_data_grads_norm = 6.3113
	old_data_grads_norm = 3.8791
	sim_grads_norm_tr = 0.0140
-- Starting training on experience 719 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7978
	data_grads_norm = 4.6432
	new_data_grads_norm = 7.0604
	old_data_grads_norm = 5.7529
	sim_grads_norm_tr = 0.1357
-- Starting training on experience 720 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8104
	data_grads_norm = 4.3947
	new_data_grads_norm = 5.6020
	old_data_grads_norm = 5.3160
	sim_grads_norm_tr = 0.1945
-- Starting training on experience 721 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6308
	data_grads_norm = 3.6578
	new_data_grads_norm = 5.0197
	old_data_grads_norm = 5.0716
	sim_grads_norm_tr = 0.0547
-- Starting training on experience 722 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0805
	data_grads_norm = 3.0188
	new_data_grads_norm = 5.4668
	old_data_grads_norm = 4.3344
	sim_grads_norm_tr = -0.2215
-- Starting training on experience 723 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5265
	data_grads_norm = 3.7801
	new_data_grads_norm = 5.8123
	old_data_grads_norm = 4.6373
	sim_grads_norm_tr = -0.1017
-- Starting training on experience 724 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7194
	data_grads_norm = 4.0819
	new_data_grads_norm = 5.5358
	old_data_grads_norm = 6.1070
	sim_grads_norm_tr = 0.0456
-- Starting training on experience 725 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4224
	data_grads_norm = 3.0234
	new_data_grads_norm = 5.7395
	old_data_grads_norm = 4.0031
	sim_grads_norm_tr = 0.0361
-- Starting training on experience 726 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5154
	data_grads_norm = 3.6441
	new_data_grads_norm = 5.7132
	old_data_grads_norm = 4.1315
	sim_grads_norm_tr = -0.0454
-- Starting training on experience 727 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8078
	data_grads_norm = 4.2449
	new_data_grads_norm = 6.0200
	old_data_grads_norm = 5.5373
	sim_grads_norm_tr = 0.1437
-- Starting training on experience 728 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4582
	data_grads_norm = 4.1129
	new_data_grads_norm = 6.0899
	old_data_grads_norm = 4.2805
	sim_grads_norm_tr = 0.2092
-- Starting training on experience 729 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7600
	data_grads_norm = 3.9377
	new_data_grads_norm = 5.4363
	old_data_grads_norm = 3.9830
	sim_grads_norm_tr = 0.1263
-- Starting training on experience 730 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4120
	data_grads_norm = 3.6099
	new_data_grads_norm = 5.7550
	old_data_grads_norm = 4.5610
	sim_grads_norm_tr = 0.0671
-- Starting training on experience 731 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8784
	data_grads_norm = 4.9145
	new_data_grads_norm = 6.5966
	old_data_grads_norm = 5.6040
	sim_grads_norm_tr = 0.3079
-- Starting training on experience 732 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4235
	data_grads_norm = 3.0982
	new_data_grads_norm = 5.3706
	old_data_grads_norm = 3.2920
	sim_grads_norm_tr = 0.0616
-- Starting training on experience 733 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1497
	data_grads_norm = 2.7648
	new_data_grads_norm = 4.6906
	old_data_grads_norm = 4.7040
	sim_grads_norm_tr = -0.2320
-- Starting training on experience 734 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3258
	data_grads_norm = 3.3232
	new_data_grads_norm = 6.0629
	old_data_grads_norm = 3.8720
	sim_grads_norm_tr = -0.1011
-- Starting training on experience 735 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3247
	data_grads_norm = 3.7925
	new_data_grads_norm = 6.1461
	old_data_grads_norm = 4.2970
	sim_grads_norm_tr = -0.0903
-- Starting training on experience 736 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2574
	data_grads_norm = 3.2591
	new_data_grads_norm = 6.3720
	old_data_grads_norm = 1.5694
	sim_grads_norm_tr = -0.0676
-- Starting training on experience 737 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4298
	data_grads_norm = 4.1487
	new_data_grads_norm = 6.2997
	old_data_grads_norm = 3.8300
	sim_grads_norm_tr = 0.0462
-- Starting training on experience 738 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9761
	data_grads_norm = 4.0145
	new_data_grads_norm = 5.0382
	old_data_grads_norm = 5.4879
	sim_grads_norm_tr = 0.0439
-- Starting training on experience 739 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2609
	data_grads_norm = 3.2654
	new_data_grads_norm = 5.5213
	old_data_grads_norm = 4.3941
	sim_grads_norm_tr = 0.0223
-- Starting training on experience 740 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9806
	data_grads_norm = 4.5068
	new_data_grads_norm = 5.8743
	old_data_grads_norm = 4.1617
	sim_grads_norm_tr = 0.4249
-- Starting training on experience 741 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9746
	data_grads_norm = 2.5806
	new_data_grads_norm = 4.6954
	old_data_grads_norm = 2.9171
	sim_grads_norm_tr = -0.1628
-- Starting training on experience 742 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5454
	data_grads_norm = 3.4563
	new_data_grads_norm = 5.1939
	old_data_grads_norm = 4.8022
	sim_grads_norm_tr = 0.0016
-- Starting training on experience 743 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1659
	data_grads_norm = 3.4491
	new_data_grads_norm = 5.5420
	old_data_grads_norm = 4.8474
	sim_grads_norm_tr = -0.0915
-- Starting training on experience 744 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5415
	data_grads_norm = 3.8986
	new_data_grads_norm = 6.2251
	old_data_grads_norm = 4.3356
	sim_grads_norm_tr = 0.0764
-- Starting training on experience 745 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4021
	data_grads_norm = 3.7491
	new_data_grads_norm = 4.8958
	old_data_grads_norm = 6.0717
	sim_grads_norm_tr = -0.0306
-- Starting training on experience 746 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9244
	data_grads_norm = 4.0190
	new_data_grads_norm = 5.5341
	old_data_grads_norm = 5.0334
	sim_grads_norm_tr = 0.1987
-- Starting training on experience 747 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3970
	data_grads_norm = 3.2034
	new_data_grads_norm = 4.6694
	old_data_grads_norm = 3.3300
	sim_grads_norm_tr = 0.0958
-- Starting training on experience 748 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1223
	data_grads_norm = 2.7848
	new_data_grads_norm = 5.0282
	old_data_grads_norm = 3.7233
	sim_grads_norm_tr = -0.1424
-- Starting training on experience 749 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1977
	data_grads_norm = 2.8651
	new_data_grads_norm = 5.0122
	old_data_grads_norm = 3.2026
	sim_grads_norm_tr = -0.1619
-- Starting training on experience 750 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2666
	data_grads_norm = 3.1585
	new_data_grads_norm = 5.1206
	old_data_grads_norm = 4.0912
	sim_grads_norm_tr = -0.1093
-- Starting training on experience 751 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6596
	data_grads_norm = 4.7846
	new_data_grads_norm = 6.8470
	old_data_grads_norm = 5.3893
	sim_grads_norm_tr = 0.0411
-- Starting training on experience 752 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3770
	data_grads_norm = 3.7399
	new_data_grads_norm = 5.7207
	old_data_grads_norm = 4.4227
	sim_grads_norm_tr = -0.1814
-- Starting training on experience 753 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3456
	data_grads_norm = 3.5604
	new_data_grads_norm = 5.7521
	old_data_grads_norm = 3.2162
	sim_grads_norm_tr = 0.1165
-- Starting training on experience 754 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5175
	data_grads_norm = 3.6899
	new_data_grads_norm = 5.2080
	old_data_grads_norm = 4.6338
	sim_grads_norm_tr = -0.1322
-- Starting training on experience 755 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1610
	data_grads_norm = 3.1258
	new_data_grads_norm = 5.9136
	old_data_grads_norm = 3.3770
	sim_grads_norm_tr = -0.1325
-- Starting training on experience 756 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0925
	data_grads_norm = 4.9567
	new_data_grads_norm = 5.8711
	old_data_grads_norm = 5.6130
	sim_grads_norm_tr = 0.2638
-- Starting training on experience 757 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6988
	data_grads_norm = 3.7689
	new_data_grads_norm = 5.4431
	old_data_grads_norm = 3.4762
	sim_grads_norm_tr = 0.0508
-- Starting training on experience 758 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4714
	data_grads_norm = 3.6888
	new_data_grads_norm = 6.0402
	old_data_grads_norm = 4.2499
	sim_grads_norm_tr = -0.0888
-- Starting training on experience 759 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5707
	data_grads_norm = 3.7642
	new_data_grads_norm = 6.2351
	old_data_grads_norm = 3.8157
	sim_grads_norm_tr = -0.0536
-- Starting training on experience 760 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7370
	data_grads_norm = 4.4301
	new_data_grads_norm = 7.0527
	old_data_grads_norm = 4.6296
	sim_grads_norm_tr = 0.0244
-- Starting training on experience 761 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3363
	data_grads_norm = 3.7939
	new_data_grads_norm = 7.5010
	old_data_grads_norm = 3.4950
	sim_grads_norm_tr = -0.0888
-- Starting training on experience 762 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9082
	data_grads_norm = 5.0928
	new_data_grads_norm = 6.2887
	old_data_grads_norm = 5.9720
	sim_grads_norm_tr = 0.0958
-- Starting training on experience 763 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7618
	data_grads_norm = 3.5127
	new_data_grads_norm = 6.0380
	old_data_grads_norm = 4.3405
	sim_grads_norm_tr = -0.0039
-- Starting training on experience 764 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1142
	data_grads_norm = 3.3857
	new_data_grads_norm = 6.5274
	old_data_grads_norm = 4.1598
	sim_grads_norm_tr = -0.0594
-- Starting training on experience 765 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1126
	data_grads_norm = 3.6628
	new_data_grads_norm = 6.3583
	old_data_grads_norm = 3.5360
	sim_grads_norm_tr = 0.1809
-- Starting training on experience 766 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3061
	data_grads_norm = 3.4112
	new_data_grads_norm = 6.2114
	old_data_grads_norm = 3.0802
	sim_grads_norm_tr = -0.1455
-- Starting training on experience 767 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7976
	data_grads_norm = 4.4583
	new_data_grads_norm = 6.6816
	old_data_grads_norm = 4.7035
	sim_grads_norm_tr = 0.1389
-- Starting training on experience 768 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7162
	data_grads_norm = 4.2410
	new_data_grads_norm = 6.4119
	old_data_grads_norm = 4.5829
	sim_grads_norm_tr = -0.0156
-- Starting training on experience 769 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6449
	data_grads_norm = 3.5044
	new_data_grads_norm = 5.6694
	old_data_grads_norm = 4.6058
	sim_grads_norm_tr = 0.0131
-- Starting training on experience 770 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2981
	data_grads_norm = 3.6379
	new_data_grads_norm = 6.5753
	old_data_grads_norm = 3.1053
	sim_grads_norm_tr = 0.0399
-- Starting training on experience 771 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5048
	data_grads_norm = 3.1145
	new_data_grads_norm = 5.3405
	old_data_grads_norm = 3.5360
	sim_grads_norm_tr = 0.1280
-- Starting training on experience 772 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6218
	data_grads_norm = 3.8822
	new_data_grads_norm = 6.1533
	old_data_grads_norm = 4.3013
	sim_grads_norm_tr = -0.0146
-- Starting training on experience 773 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5485
	data_grads_norm = 3.1763
	new_data_grads_norm = 5.4437
	old_data_grads_norm = 4.1345
	sim_grads_norm_tr = -0.1182
-- Starting training on experience 774 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4005
	data_grads_norm = 3.4654
	new_data_grads_norm = 6.6069
	old_data_grads_norm = 3.8485
	sim_grads_norm_tr = -0.0314
-- Starting training on experience 775 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4933
	data_grads_norm = 3.5803
	new_data_grads_norm = 5.6550
	old_data_grads_norm = 4.2268
	sim_grads_norm_tr = 0.0680
-- Starting training on experience 776 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4586
	data_grads_norm = 3.6611
	new_data_grads_norm = 6.2611
	old_data_grads_norm = 3.7979
	sim_grads_norm_tr = -0.0423
-- Starting training on experience 777 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3020
	data_grads_norm = 4.0017
	new_data_grads_norm = 6.1851
	old_data_grads_norm = 4.4966
	sim_grads_norm_tr = -0.0679
-- Starting training on experience 778 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4582
	data_grads_norm = 3.8263
	new_data_grads_norm = 6.6202
	old_data_grads_norm = 3.1226
	sim_grads_norm_tr = -0.0454
-- Starting training on experience 779 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6865
	data_grads_norm = 3.5526
	new_data_grads_norm = 5.9967
	old_data_grads_norm = 3.4946
	sim_grads_norm_tr = 0.0946
-- Starting training on experience 780 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8095
	data_grads_norm = 3.5660
	new_data_grads_norm = 5.3176
	old_data_grads_norm = 4.7087
	sim_grads_norm_tr = 0.0472
-- Starting training on experience 781 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1837
	data_grads_norm = 3.1996
	new_data_grads_norm = 5.4514
	old_data_grads_norm = 4.9644
	sim_grads_norm_tr = -0.1543
-- Starting training on experience 782 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7817
	data_grads_norm = 4.2827
	new_data_grads_norm = 6.4890
	old_data_grads_norm = 4.0901
	sim_grads_norm_tr = 0.0694
-- Starting training on experience 783 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5644
	data_grads_norm = 3.3705
	new_data_grads_norm = 5.7465
	old_data_grads_norm = 3.9237
	sim_grads_norm_tr = 0.0582
-- Starting training on experience 784 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7731
	data_grads_norm = 3.3830
	new_data_grads_norm = 6.5239
	old_data_grads_norm = 3.7891
	sim_grads_norm_tr = 0.0340
-- Starting training on experience 785 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5686
	data_grads_norm = 3.6203
	new_data_grads_norm = 6.3559
	old_data_grads_norm = 3.7126
	sim_grads_norm_tr = 0.0188
-- Starting training on experience 786 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5950
	data_grads_norm = 3.7101
	new_data_grads_norm = 5.3947
	old_data_grads_norm = 5.2082
	sim_grads_norm_tr = 0.0792
-- Starting training on experience 787 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0735
	data_grads_norm = 3.0539
	new_data_grads_norm = 5.8289
	old_data_grads_norm = 5.0842
	sim_grads_norm_tr = -0.1397
-- Starting training on experience 788 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3208
	data_grads_norm = 3.0797
	new_data_grads_norm = 5.8559
	old_data_grads_norm = 4.3180
	sim_grads_norm_tr = -0.1287
-- Starting training on experience 789 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5032
	data_grads_norm = 3.4913
	new_data_grads_norm = 6.1174
	old_data_grads_norm = 3.5810
	sim_grads_norm_tr = 0.1687
-- Starting training on experience 790 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9026
	data_grads_norm = 4.3366
	new_data_grads_norm = 6.4761
	old_data_grads_norm = 4.5035
	sim_grads_norm_tr = 0.1462
-- Starting training on experience 791 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2726
	data_grads_norm = 3.8823
	new_data_grads_norm = 5.9809
	old_data_grads_norm = 4.2981
	sim_grads_norm_tr = -0.0459
-- Starting training on experience 792 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6035
	data_grads_norm = 3.9265
	new_data_grads_norm = 6.6029
	old_data_grads_norm = 4.5625
	sim_grads_norm_tr = 0.0597
-- Starting training on experience 793 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3442
	data_grads_norm = 3.7697
	new_data_grads_norm = 6.3644
	old_data_grads_norm = 3.2411
	sim_grads_norm_tr = -0.1142
-- Starting training on experience 794 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5897
	data_grads_norm = 4.5261
	new_data_grads_norm = 6.3877
	old_data_grads_norm = 4.9262
	sim_grads_norm_tr = 0.2720
-- Starting training on experience 795 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6071
	data_grads_norm = 3.4941
	new_data_grads_norm = 5.3585
	old_data_grads_norm = 4.5389
	sim_grads_norm_tr = -0.0972
-- Starting training on experience 796 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5702
	data_grads_norm = 3.8313
	new_data_grads_norm = 6.0953
	old_data_grads_norm = 5.2089
	sim_grads_norm_tr = -0.0650
-- Starting training on experience 797 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7313
	data_grads_norm = 3.7472
	new_data_grads_norm = 6.3036
	old_data_grads_norm = 4.7556
	sim_grads_norm_tr = 0.0340
-- Starting training on experience 798 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6965
	data_grads_norm = 3.7020
	new_data_grads_norm = 5.6966
	old_data_grads_norm = 3.9604
	sim_grads_norm_tr = 0.1750
-- Starting training on experience 799 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3180
	data_grads_norm = 3.0915
	new_data_grads_norm = 5.8722
	old_data_grads_norm = 2.8848
	sim_grads_norm_tr = -0.0380
-- Starting training on experience 800 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0540
	data_grads_norm = 3.7632
	new_data_grads_norm = 5.4251
	old_data_grads_norm = 4.4898
	sim_grads_norm_tr = 0.1288
-- Starting training on experience 801 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4078
	data_grads_norm = 2.8331
	new_data_grads_norm = 5.0560
	old_data_grads_norm = 5.5420
	sim_grads_norm_tr = -0.0658
-- Starting training on experience 802 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5551
	data_grads_norm = 3.1976
	new_data_grads_norm = 5.3615
	old_data_grads_norm = 4.8631
	sim_grads_norm_tr = -0.1088
-- Starting training on experience 803 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7298
	data_grads_norm = 3.4016
	new_data_grads_norm = 5.6422
	old_data_grads_norm = 3.2051
	sim_grads_norm_tr = 0.2036
-- Starting training on experience 804 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5075
	data_grads_norm = 4.3421
	new_data_grads_norm = 6.2493
	old_data_grads_norm = 4.1654
	sim_grads_norm_tr = 0.0025
-- Starting training on experience 805 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6454
	data_grads_norm = 4.2392
	new_data_grads_norm = 5.5211
	old_data_grads_norm = 4.4549
	sim_grads_norm_tr = 0.1841
-- Starting training on experience 806 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5376
	data_grads_norm = 3.9847
	new_data_grads_norm = 5.6229
	old_data_grads_norm = 3.5650
	sim_grads_norm_tr = -0.1036
-- Starting training on experience 807 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0688
	data_grads_norm = 4.8762
	new_data_grads_norm = 5.8242
	old_data_grads_norm = 5.3564
	sim_grads_norm_tr = 0.1938
-- Starting training on experience 808 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2173
	data_grads_norm = 3.0636
	new_data_grads_norm = 5.5173
	old_data_grads_norm = 3.3049
	sim_grads_norm_tr = -0.0319
-- Starting training on experience 809 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6710
	data_grads_norm = 3.8568
	new_data_grads_norm = 6.1601
	old_data_grads_norm = 4.2061
	sim_grads_norm_tr = 0.0497
-- Starting training on experience 810 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9843
	data_grads_norm = 4.1539
	new_data_grads_norm = 5.8078
	old_data_grads_norm = 5.3407
	sim_grads_norm_tr = 0.1960
-- Starting training on experience 811 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4357
	data_grads_norm = 3.4120
	new_data_grads_norm = 6.0005
	old_data_grads_norm = 3.0663
	sim_grads_norm_tr = 0.1689
-- Starting training on experience 812 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3634
	data_grads_norm = 3.5837
	new_data_grads_norm = 5.8328
	old_data_grads_norm = 5.6378
	sim_grads_norm_tr = -0.1662
-- Starting training on experience 813 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6047
	data_grads_norm = 2.9975
	new_data_grads_norm = 5.8859
	old_data_grads_norm = 2.2091
	sim_grads_norm_tr = 0.0846
-- Starting training on experience 814 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4155
	data_grads_norm = 5.0621
	new_data_grads_norm = 5.9809
	old_data_grads_norm = 6.2080
	sim_grads_norm_tr = 0.1572
-- Starting training on experience 815 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7612
	data_grads_norm = 3.9022
	new_data_grads_norm = 6.1525
	old_data_grads_norm = 3.6191
	sim_grads_norm_tr = -0.0719
-- Starting training on experience 816 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7674
	data_grads_norm = 4.1713
	new_data_grads_norm = 5.9081
	old_data_grads_norm = 5.0115
	sim_grads_norm_tr = -0.0251
-- Starting training on experience 817 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1146
	data_grads_norm = 4.1689
	new_data_grads_norm = 5.4270
	old_data_grads_norm = 5.1061
	sim_grads_norm_tr = 0.2524
-- Starting training on experience 818 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4374
	data_grads_norm = 3.4447
	new_data_grads_norm = 5.9771
	old_data_grads_norm = 3.7074
	sim_grads_norm_tr = -0.1851
-- Starting training on experience 819 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4894
	data_grads_norm = 3.7562
	new_data_grads_norm = 6.3084
	old_data_grads_norm = 3.5718
	sim_grads_norm_tr = 0.0514
-- Starting training on experience 820 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2201
	data_grads_norm = 3.3566
	new_data_grads_norm = 5.4143
	old_data_grads_norm = 4.2184
	sim_grads_norm_tr = -0.1779
-- Starting training on experience 821 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5528
	data_grads_norm = 3.2622
	new_data_grads_norm = 4.8585
	old_data_grads_norm = 3.7227
	sim_grads_norm_tr = -0.0415
-- Starting training on experience 822 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8725
	data_grads_norm = 3.5314
	new_data_grads_norm = 5.4181
	old_data_grads_norm = 3.7202
	sim_grads_norm_tr = 0.1203
-- Starting training on experience 823 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3675
	data_grads_norm = 2.7792
	new_data_grads_norm = 4.8869
	old_data_grads_norm = 4.0478
	sim_grads_norm_tr = -0.1588
-- Starting training on experience 824 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5438
	data_grads_norm = 3.2438
	new_data_grads_norm = 5.3468
	old_data_grads_norm = 3.1324
	sim_grads_norm_tr = -0.0712
-- Starting training on experience 825 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4549
	data_grads_norm = 3.3467
	new_data_grads_norm = 5.2917
	old_data_grads_norm = 3.4086
	sim_grads_norm_tr = -0.1084
-- Starting training on experience 826 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5713
	data_grads_norm = 3.5842
	new_data_grads_norm = 6.2366
	old_data_grads_norm = 2.5831
	sim_grads_norm_tr = 0.0305
-- Starting training on experience 827 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8476
	data_grads_norm = 3.9994
	new_data_grads_norm = 6.1744
	old_data_grads_norm = 4.5453
	sim_grads_norm_tr = -0.0203
-- Starting training on experience 828 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9479
	data_grads_norm = 3.6134
	new_data_grads_norm = 5.5030
	old_data_grads_norm = 4.2641
	sim_grads_norm_tr = -0.0421
-- Starting training on experience 829 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6682
	data_grads_norm = 3.7700
	new_data_grads_norm = 5.7505
	old_data_grads_norm = 3.6605
	sim_grads_norm_tr = 0.1337
-- Starting training on experience 830 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8738
	data_grads_norm = 4.1340
	new_data_grads_norm = 6.1434
	old_data_grads_norm = 4.1775
	sim_grads_norm_tr = 0.2599
-- Starting training on experience 831 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4506
	data_grads_norm = 3.7936
	new_data_grads_norm = 5.8172
	old_data_grads_norm = 4.4189
	sim_grads_norm_tr = 0.0193
-- Starting training on experience 832 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6398
	data_grads_norm = 3.6308
	new_data_grads_norm = 5.4572
	old_data_grads_norm = 4.0098
	sim_grads_norm_tr = 0.0803
-- Starting training on experience 833 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4139
	data_grads_norm = 3.4166
	new_data_grads_norm = 5.8203
	old_data_grads_norm = 3.7323
	sim_grads_norm_tr = -0.0610
-- Starting training on experience 834 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4363
	data_grads_norm = 3.1476
	new_data_grads_norm = 6.0452
	old_data_grads_norm = 4.1286
	sim_grads_norm_tr = -0.0686
-- Starting training on experience 835 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0576
	data_grads_norm = 3.3617
	new_data_grads_norm = 5.9685
	old_data_grads_norm = 2.6128
	sim_grads_norm_tr = 0.1378
-- Starting training on experience 836 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8033
	data_grads_norm = 4.5059
	new_data_grads_norm = 6.2341
	old_data_grads_norm = 4.6313
	sim_grads_norm_tr = 0.2097
-- Starting training on experience 837 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2521
	data_grads_norm = 4.0996
	new_data_grads_norm = 6.0245
	old_data_grads_norm = 5.4691
	sim_grads_norm_tr = -0.0008
-- Starting training on experience 838 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5671
	data_grads_norm = 3.8693
	new_data_grads_norm = 5.9204
	old_data_grads_norm = 3.8587
	sim_grads_norm_tr = 0.0803
-- Starting training on experience 839 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5586
	data_grads_norm = 3.2942
	new_data_grads_norm = 5.7342
	old_data_grads_norm = 4.0705
	sim_grads_norm_tr = -0.1943
-- Starting training on experience 840 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5323
	data_grads_norm = 3.7472
	new_data_grads_norm = 5.8508
	old_data_grads_norm = 3.3766
	sim_grads_norm_tr = 0.1810
-- Starting training on experience 841 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4541
	data_grads_norm = 3.6250
	new_data_grads_norm = 6.6877
	old_data_grads_norm = 3.1726
	sim_grads_norm_tr = -0.0864
-- Starting training on experience 842 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8619
	data_grads_norm = 4.3620
	new_data_grads_norm = 6.3189
	old_data_grads_norm = 5.5340
	sim_grads_norm_tr = -0.0795
-- Starting training on experience 843 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8065
	data_grads_norm = 4.2777
	new_data_grads_norm = 6.2348
	old_data_grads_norm = 4.8230
	sim_grads_norm_tr = 0.0961
-- Starting training on experience 844 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3633
	data_grads_norm = 3.5389
	new_data_grads_norm = 6.4669
	old_data_grads_norm = 4.1575
	sim_grads_norm_tr = 0.1097
-- Starting training on experience 845 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8508
	data_grads_norm = 4.0280
	new_data_grads_norm = 6.0475
	old_data_grads_norm = 5.3373
	sim_grads_norm_tr = 0.0301
-- Starting training on experience 846 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1368
	data_grads_norm = 3.4581
	new_data_grads_norm = 6.3432
	old_data_grads_norm = 3.9946
	sim_grads_norm_tr = -0.1139
-- Starting training on experience 847 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3766
	data_grads_norm = 3.1166
	new_data_grads_norm = 6.2173
	old_data_grads_norm = 3.8893
	sim_grads_norm_tr = -0.0885
-- Starting training on experience 848 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9424
	data_grads_norm = 4.5260
	new_data_grads_norm = 6.6761
	old_data_grads_norm = 4.6274
	sim_grads_norm_tr = 0.3496
-- Starting training on experience 849 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4957
	data_grads_norm = 3.7652
	new_data_grads_norm = 5.4375
	old_data_grads_norm = 4.7732
	sim_grads_norm_tr = 0.0137
-- Starting training on experience 850 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6527
	data_grads_norm = 4.2707
	new_data_grads_norm = 6.7051
	old_data_grads_norm = 5.0343
	sim_grads_norm_tr = 0.0480
-- Starting training on experience 851 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4242
	data_grads_norm = 3.8299
	new_data_grads_norm = 5.6358
	old_data_grads_norm = 4.1255
	sim_grads_norm_tr = 0.1078
-- Starting training on experience 852 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2739
	data_grads_norm = 3.4847
	new_data_grads_norm = 6.8730
	old_data_grads_norm = 3.6827
	sim_grads_norm_tr = -0.0893
-- Starting training on experience 853 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1245
	data_grads_norm = 3.1678
	new_data_grads_norm = 6.3957
	old_data_grads_norm = 4.5781
	sim_grads_norm_tr = -0.1172
-- Starting training on experience 854 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0290
	data_grads_norm = 4.1068
	new_data_grads_norm = 6.4679
	old_data_grads_norm = 4.5355
	sim_grads_norm_tr = 0.0554
-- Starting training on experience 855 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2671
	data_grads_norm = 4.1584
	new_data_grads_norm = 6.4320
	old_data_grads_norm = 4.4858
	sim_grads_norm_tr = -0.0427
-- Starting training on experience 856 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4278
	data_grads_norm = 3.9764
	new_data_grads_norm = 6.9032
	old_data_grads_norm = 4.4157
	sim_grads_norm_tr = -0.1627
-- Starting training on experience 857 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7375
	data_grads_norm = 4.6462
	new_data_grads_norm = 7.3401
	old_data_grads_norm = 4.5004
	sim_grads_norm_tr = 0.0684
-- Starting training on experience 858 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0471
	data_grads_norm = 5.2190
	new_data_grads_norm = 6.9320
	old_data_grads_norm = 5.4221
	sim_grads_norm_tr = 0.3601
-- Starting training on experience 859 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5119
	data_grads_norm = 3.5974
	new_data_grads_norm = 6.7362
	old_data_grads_norm = 4.2816
	sim_grads_norm_tr = 0.0226
-- Starting training on experience 860 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1958
	data_grads_norm = 4.6903
	new_data_grads_norm = 6.2072
	old_data_grads_norm = 4.7180
	sim_grads_norm_tr = 0.0875
-- Starting training on experience 861 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4419
	data_grads_norm = 3.6365
	new_data_grads_norm = 6.3863
	old_data_grads_norm = 4.1040
	sim_grads_norm_tr = -0.0891
-- Starting training on experience 862 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5388
	data_grads_norm = 4.5747
	new_data_grads_norm = 6.3818
	old_data_grads_norm = 5.1471
	sim_grads_norm_tr = -0.0313
-- Starting training on experience 863 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4755
	data_grads_norm = 4.3245
	new_data_grads_norm = 6.9647
	old_data_grads_norm = 4.5496
	sim_grads_norm_tr = 0.0253
-- Starting training on experience 864 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0342
	data_grads_norm = 4.2599
	new_data_grads_norm = 6.9054
	old_data_grads_norm = 4.8109
	sim_grads_norm_tr = 0.1557
-- Starting training on experience 865 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4546
	data_grads_norm = 3.7302
	new_data_grads_norm = 5.3587
	old_data_grads_norm = 5.8120
	sim_grads_norm_tr = -0.0042
-- Starting training on experience 866 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4873
	data_grads_norm = 5.3151
	new_data_grads_norm = 6.7578
	old_data_grads_norm = 6.6994
	sim_grads_norm_tr = 0.3466
-- Starting training on experience 867 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5471
	data_grads_norm = 3.4061
	new_data_grads_norm = 6.1364
	old_data_grads_norm = 3.4415
	sim_grads_norm_tr = -0.0023
-- Starting training on experience 868 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7779
	data_grads_norm = 4.1893
	new_data_grads_norm = 6.2070
	old_data_grads_norm = 6.2759
	sim_grads_norm_tr = -0.0074
-- Starting training on experience 869 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3775
	data_grads_norm = 3.7593
	new_data_grads_norm = 6.1519
	old_data_grads_norm = 3.5982
	sim_grads_norm_tr = 0.1115
-- Starting training on experience 870 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7321
	data_grads_norm = 3.4471
	new_data_grads_norm = 5.6458
	old_data_grads_norm = 3.7359
	sim_grads_norm_tr = 0.0567
-- Starting training on experience 871 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7790
	data_grads_norm = 3.8565
	new_data_grads_norm = 5.8965
	old_data_grads_norm = 4.6754
	sim_grads_norm_tr = 0.1597
-- Starting training on experience 872 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1070
	data_grads_norm = 2.7195
	new_data_grads_norm = 4.8644
	old_data_grads_norm = 3.7575
	sim_grads_norm_tr = -0.1366
-- Starting training on experience 873 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7534
	data_grads_norm = 3.3781
	new_data_grads_norm = 5.6997
	old_data_grads_norm = 3.2488
	sim_grads_norm_tr = 0.0306
-- Starting training on experience 874 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2536
	data_grads_norm = 3.3023
	new_data_grads_norm = 5.5627
	old_data_grads_norm = 4.2410
	sim_grads_norm_tr = 0.0143
-- Starting training on experience 875 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5915
	data_grads_norm = 3.7330
	new_data_grads_norm = 5.7856
	old_data_grads_norm = 4.6943
	sim_grads_norm_tr = 0.0559
-- Starting training on experience 876 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6015
	data_grads_norm = 3.7492
	new_data_grads_norm = 5.3856
	old_data_grads_norm = 4.2087
	sim_grads_norm_tr = 0.0736
-- Starting training on experience 877 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2297
	data_grads_norm = 3.3358
	new_data_grads_norm = 5.8574
	old_data_grads_norm = 4.8607
	sim_grads_norm_tr = 0.1009
-- Starting training on experience 878 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9938
	data_grads_norm = 4.4862
	new_data_grads_norm = 6.4962
	old_data_grads_norm = 4.2656
	sim_grads_norm_tr = 0.3019
-- Starting training on experience 879 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1031
	data_grads_norm = 3.2043
	new_data_grads_norm = 5.2686
	old_data_grads_norm = 3.7766
	sim_grads_norm_tr = -0.0438
-- Starting training on experience 880 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2257
	data_grads_norm = 3.4411
	new_data_grads_norm = 5.1182
	old_data_grads_norm = 4.7043
	sim_grads_norm_tr = 0.0252
-- Starting training on experience 881 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4019
	data_grads_norm = 3.5439
	new_data_grads_norm = 5.8155
	old_data_grads_norm = 3.5999
	sim_grads_norm_tr = 0.0756
-- Starting training on experience 882 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3698
	data_grads_norm = 3.3869
	new_data_grads_norm = 5.5183
	old_data_grads_norm = 5.2243
	sim_grads_norm_tr = -0.2171
-- Starting training on experience 883 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5262
	data_grads_norm = 3.7785
	new_data_grads_norm = 5.6088
	old_data_grads_norm = 4.5025
	sim_grads_norm_tr = -0.0074
-- Starting training on experience 884 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4142
	data_grads_norm = 5.0548
	new_data_grads_norm = 6.0040
	old_data_grads_norm = 6.6574
	sim_grads_norm_tr = 0.2379
-- Starting training on experience 885 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4335
	data_grads_norm = 3.2508
	new_data_grads_norm = 4.7444
	old_data_grads_norm = 3.7372
	sim_grads_norm_tr = 0.0028
-- Starting training on experience 886 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3998
	data_grads_norm = 2.9985
	new_data_grads_norm = 4.5698
	old_data_grads_norm = 4.1148
	sim_grads_norm_tr = 0.0307
-- Starting training on experience 887 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5149
	data_grads_norm = 2.7375
	new_data_grads_norm = 4.8587
	old_data_grads_norm = 3.3946
	sim_grads_norm_tr = -0.1880
-- Starting training on experience 888 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2182
	data_grads_norm = 2.8443
	new_data_grads_norm = 5.2369
	old_data_grads_norm = 3.2531
	sim_grads_norm_tr = -0.0725
-- Starting training on experience 889 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6449
	data_grads_norm = 3.6831
	new_data_grads_norm = 5.4329
	old_data_grads_norm = 4.8588
	sim_grads_norm_tr = -0.0399
-- Starting training on experience 890 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2926
	data_grads_norm = 3.3418
	new_data_grads_norm = 5.3556
	old_data_grads_norm = 2.8915
	sim_grads_norm_tr = 0.1090
-- Starting training on experience 891 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8961
	data_grads_norm = 2.5843
	new_data_grads_norm = 5.8463
	old_data_grads_norm = 4.3746
	sim_grads_norm_tr = -0.2453
-- Starting training on experience 892 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8391
	data_grads_norm = 4.2276
	new_data_grads_norm = 6.3300
	old_data_grads_norm = 4.4714
	sim_grads_norm_tr = 0.0258
-- Starting training on experience 893 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1180
	data_grads_norm = 4.4690
	new_data_grads_norm = 5.6305
	old_data_grads_norm = 5.2592
	sim_grads_norm_tr = 0.1601
-- Starting training on experience 894 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5776
	data_grads_norm = 4.0232
	new_data_grads_norm = 5.9569
	old_data_grads_norm = 5.5065
	sim_grads_norm_tr = 0.0283
-- Starting training on experience 895 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2169
	data_grads_norm = 3.3496
	new_data_grads_norm = 5.3685
	old_data_grads_norm = 3.4946
	sim_grads_norm_tr = 0.0701
-- Starting training on experience 896 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4420
	data_grads_norm = 3.6109
	new_data_grads_norm = 5.2826
	old_data_grads_norm = 3.5224
	sim_grads_norm_tr = 0.1138
-- Starting training on experience 897 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3907
	data_grads_norm = 3.2834
	new_data_grads_norm = 5.1982
	old_data_grads_norm = 4.1323
	sim_grads_norm_tr = -0.0860
-- Starting training on experience 898 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2099
	data_grads_norm = 3.0673
	new_data_grads_norm = 5.4226
	old_data_grads_norm = 3.8242
	sim_grads_norm_tr = -0.0747
-- Starting training on experience 899 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4064
	data_grads_norm = 3.8639
	new_data_grads_norm = 5.7801
	old_data_grads_norm = 3.1146
	sim_grads_norm_tr = -0.0921
-- Starting training on experience 900 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4966
	data_grads_norm = 3.5354
	new_data_grads_norm = 5.9580
	old_data_grads_norm = 3.3894
	sim_grads_norm_tr = 0.0485
-- Starting training on experience 901 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5402
	data_grads_norm = 3.5710
	new_data_grads_norm = 4.9589
	old_data_grads_norm = 4.2796
	sim_grads_norm_tr = 0.1427
-- Starting training on experience 902 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2167
	data_grads_norm = 3.2989
	new_data_grads_norm = 6.0084
	old_data_grads_norm = 3.3192
	sim_grads_norm_tr = -0.0016
-- Starting training on experience 903 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3699
	data_grads_norm = 3.6607
	new_data_grads_norm = 5.4974
	old_data_grads_norm = 4.1873
	sim_grads_norm_tr = 0.1130
-- Starting training on experience 904 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0502
	data_grads_norm = 3.4091
	new_data_grads_norm = 5.6429
	old_data_grads_norm = 3.4026
	sim_grads_norm_tr = 0.1378
-- Starting training on experience 905 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.8335
	data_grads_norm = 3.0213
	new_data_grads_norm = 7.3740
	old_data_grads_norm = 4.4665
	sim_grads_norm_tr = -0.2068
-- Starting training on experience 906 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8770
	data_grads_norm = 3.9511
	new_data_grads_norm = 5.0070
	old_data_grads_norm = 5.3615
	sim_grads_norm_tr = 0.1896
-- Starting training on experience 907 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0077
	data_grads_norm = 2.5291
	new_data_grads_norm = 4.7005
	old_data_grads_norm = 3.9422
	sim_grads_norm_tr = -0.2234
-- Starting training on experience 908 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7579
	data_grads_norm = 4.0979
	new_data_grads_norm = 5.9795
	old_data_grads_norm = 4.8746
	sim_grads_norm_tr = 0.0573
-- Starting training on experience 909 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5352
	data_grads_norm = 4.2123
	new_data_grads_norm = 5.9259
	old_data_grads_norm = 4.7068
	sim_grads_norm_tr = 0.1032
-- Starting training on experience 910 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5739
	data_grads_norm = 3.7979
	new_data_grads_norm = 6.1804
	old_data_grads_norm = 4.1671
	sim_grads_norm_tr = 0.2176
-- Starting training on experience 911 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1346
	data_grads_norm = 3.3292
	new_data_grads_norm = 6.2214
	old_data_grads_norm = 3.5813
	sim_grads_norm_tr = -0.0921
-- Starting training on experience 912 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7326
	data_grads_norm = 4.0689
	new_data_grads_norm = 5.8304
	old_data_grads_norm = 4.8821
	sim_grads_norm_tr = -0.0787
-- Starting training on experience 913 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2537
	data_grads_norm = 2.9833
	new_data_grads_norm = 6.0059
	old_data_grads_norm = 3.0643
	sim_grads_norm_tr = -0.1012
-- Starting training on experience 914 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3481
	data_grads_norm = 3.0091
	new_data_grads_norm = 5.3954
	old_data_grads_norm = 3.3620
	sim_grads_norm_tr = -0.1432
-- Starting training on experience 915 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2182
	data_grads_norm = 3.3293
	new_data_grads_norm = 6.2236
	old_data_grads_norm = 3.5221
	sim_grads_norm_tr = -0.1134
-- Starting training on experience 916 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1809
	data_grads_norm = 4.3371
	new_data_grads_norm = 6.6257
	old_data_grads_norm = 4.6954
	sim_grads_norm_tr = 0.0666
-- Starting training on experience 917 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0073
	data_grads_norm = 4.0759
	new_data_grads_norm = 6.1939
	old_data_grads_norm = 4.1644
	sim_grads_norm_tr = 0.1831
-- Starting training on experience 918 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8593
	data_grads_norm = 3.7782
	new_data_grads_norm = 5.7294
	old_data_grads_norm = 4.8151
	sim_grads_norm_tr = 0.0103
-- Starting training on experience 919 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8316
	data_grads_norm = 4.3151
	new_data_grads_norm = 6.1975
	old_data_grads_norm = 4.0165
	sim_grads_norm_tr = 0.0914
-- Starting training on experience 920 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2725
	data_grads_norm = 3.4539
	new_data_grads_norm = 5.6036
	old_data_grads_norm = 3.6514
	sim_grads_norm_tr = 0.1394
-- Starting training on experience 921 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3918
	data_grads_norm = 3.8706
	new_data_grads_norm = 6.6930
	old_data_grads_norm = 5.2659
	sim_grads_norm_tr = -0.0520
-- Starting training on experience 922 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7733
	data_grads_norm = 4.3584
	new_data_grads_norm = 6.1610
	old_data_grads_norm = 5.7356
	sim_grads_norm_tr = 0.0632
-- Starting training on experience 923 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2646
	data_grads_norm = 4.3867
	new_data_grads_norm = 6.6972
	old_data_grads_norm = 5.0487
	sim_grads_norm_tr = 0.0096
-- Starting training on experience 924 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4720
	data_grads_norm = 3.8996
	new_data_grads_norm = 6.2036
	old_data_grads_norm = 4.6168
	sim_grads_norm_tr = 0.0358
-- Starting training on experience 925 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6128
	data_grads_norm = 3.9035
	new_data_grads_norm = 5.4720
	old_data_grads_norm = 4.1588
	sim_grads_norm_tr = -0.0936
-- Starting training on experience 926 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6621
	data_grads_norm = 3.8841
	new_data_grads_norm = 6.0708
	old_data_grads_norm = 3.7192
	sim_grads_norm_tr = 0.0021
-- Starting training on experience 927 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2990
	data_grads_norm = 2.9539
	new_data_grads_norm = 6.0779
	old_data_grads_norm = 2.2343
	sim_grads_norm_tr = 0.1084
-- Starting training on experience 928 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4662
	data_grads_norm = 3.3091
	new_data_grads_norm = 5.3096
	old_data_grads_norm = 3.7619
	sim_grads_norm_tr = -0.0478
-- Starting training on experience 929 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4579
	data_grads_norm = 3.3678
	new_data_grads_norm = 5.1882
	old_data_grads_norm = 3.4032
	sim_grads_norm_tr = -0.0591
-- Starting training on experience 930 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2809
	data_grads_norm = 3.2687
	new_data_grads_norm = 5.6518
	old_data_grads_norm = 5.4468
	sim_grads_norm_tr = -0.0271
-- Starting training on experience 931 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7371
	data_grads_norm = 3.4953
	new_data_grads_norm = 6.7772
	old_data_grads_norm = 3.4466
	sim_grads_norm_tr = 0.0281
-- Starting training on experience 932 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5796
	data_grads_norm = 4.3127
	new_data_grads_norm = 6.6724
	old_data_grads_norm = 4.8231
	sim_grads_norm_tr = 0.0847
-- Starting training on experience 933 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6034
	data_grads_norm = 3.6717
	new_data_grads_norm = 5.8147
	old_data_grads_norm = 4.7297
	sim_grads_norm_tr = -0.0086
-- Starting training on experience 934 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5030
	data_grads_norm = 4.5214
	new_data_grads_norm = 5.8658
	old_data_grads_norm = 5.0189
	sim_grads_norm_tr = -0.0189
-- Starting training on experience 935 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5846
	data_grads_norm = 4.6488
	new_data_grads_norm = 7.1595
	old_data_grads_norm = 4.1984
	sim_grads_norm_tr = 0.2166
-- Starting training on experience 936 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4117
	data_grads_norm = 3.3900
	new_data_grads_norm = 5.6322
	old_data_grads_norm = 3.9069
	sim_grads_norm_tr = 0.0985
-- Starting training on experience 937 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3409
	data_grads_norm = 3.8365
	new_data_grads_norm = 6.4617
	old_data_grads_norm = 5.0138
	sim_grads_norm_tr = -0.1246
-- Starting training on experience 938 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7412
	data_grads_norm = 3.5670
	new_data_grads_norm = 5.3500
	old_data_grads_norm = 3.6854
	sim_grads_norm_tr = 0.0672
-- Starting training on experience 939 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9055
	data_grads_norm = 4.4081
	new_data_grads_norm = 5.9147
	old_data_grads_norm = 5.2700
	sim_grads_norm_tr = 0.2778
-- Starting training on experience 940 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6092
	data_grads_norm = 3.3160
	new_data_grads_norm = 4.8872
	old_data_grads_norm = 3.6442
	sim_grads_norm_tr = 0.1425
-- Starting training on experience 941 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4864
	data_grads_norm = 3.6292
	new_data_grads_norm = 6.8944
	old_data_grads_norm = 2.7402
	sim_grads_norm_tr = 0.0968
-- Starting training on experience 942 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4478
	data_grads_norm = 4.0026
	new_data_grads_norm = 7.0601
	old_data_grads_norm = 3.0702
	sim_grads_norm_tr = 0.0649
-- Starting training on experience 943 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3491
	data_grads_norm = 3.7643
	new_data_grads_norm = 6.9055
	old_data_grads_norm = 2.7874
	sim_grads_norm_tr = 0.0559
-- Starting training on experience 944 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2992
	data_grads_norm = 3.1327
	new_data_grads_norm = 6.0667
	old_data_grads_norm = 3.4885
	sim_grads_norm_tr = 0.0452
-- Starting training on experience 945 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7082
	data_grads_norm = 3.4736
	new_data_grads_norm = 5.3658
	old_data_grads_norm = 4.9094
	sim_grads_norm_tr = -0.1731
-- Starting training on experience 946 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8093
	data_grads_norm = 4.0541
	new_data_grads_norm = 5.8666
	old_data_grads_norm = 5.1761
	sim_grads_norm_tr = -0.0511
-- Starting training on experience 947 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6535
	data_grads_norm = 5.2092
	new_data_grads_norm = 6.0465
	old_data_grads_norm = 6.1998
	sim_grads_norm_tr = -0.0581
-- Starting training on experience 948 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5881
	data_grads_norm = 3.7470
	new_data_grads_norm = 5.8756
	old_data_grads_norm = 4.6280
	sim_grads_norm_tr = -0.0347
-- Starting training on experience 949 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1435
	data_grads_norm = 3.6376
	new_data_grads_norm = 5.7187
	old_data_grads_norm = 3.7511
	sim_grads_norm_tr = 0.0543
-- >> End of training phase << --
-- >> Start of eval phase << --
-- Starting eval on experience 0 (Task 0) from test stream --
> Eval on experience 0 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp000 = 1.1977
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.2500
	mb_index = 3800
	time = 1590.6811
-- Starting eval on experience 1 (Task 0) from test stream --
> Eval on experience 1 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp001 = 0.9871
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.2225
-- Starting eval on experience 2 (Task 0) from test stream --
> Eval on experience 2 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp002 = 1.6413
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.1695
-- Starting eval on experience 3 (Task 0) from test stream --
> Eval on experience 3 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp003 = 1.5248
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.1570
-- >> End of eval phase << --
	CumulativeAccuracy/eval_phase/test_stream/Exp000 = 0.6130
	CumulativeAccuracy/eval_phase/test_stream/Exp001 = 0.3703
	CumulativeAccuracy/eval_phase/test_stream/Exp002 = 0.2565
	CumulativeAccuracy/eval_phase/test_stream/Exp003 = 0.1998
	Loss_Stream/eval_phase/test_stream/Task000 = 1.3377
	Top1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1998
	ValidStream/mean_grads_norm_iter = 6.0589
-- >> Start of training phase << --
-- Starting training on experience 0 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0100
	data_grads_norm = 2.9659
	new_data_grads_norm = 5.9657
	old_data_grads_norm = 3.1852
	sim_grads_norm_tr = -0.0418
-- Starting training on experience 1 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6040
	data_grads_norm = 3.9590
	new_data_grads_norm = 6.4706
	old_data_grads_norm = 4.2292
	sim_grads_norm_tr = -0.0183
-- Starting training on experience 2 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1968
	data_grads_norm = 3.0163
	new_data_grads_norm = 6.2804
	old_data_grads_norm = 3.4261
	sim_grads_norm_tr = -0.0510
-- Starting training on experience 3 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.0387
	data_grads_norm = 4.7587
	new_data_grads_norm = 6.2942
	old_data_grads_norm = 5.0586
	sim_grads_norm_tr = 0.0600
-- Starting training on experience 4 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7481
	data_grads_norm = 3.6008
	new_data_grads_norm = 5.9626
	old_data_grads_norm = 4.2439
	sim_grads_norm_tr = -0.0318
-- Starting training on experience 5 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5168
	data_grads_norm = 3.6419
	new_data_grads_norm = 5.7776
	old_data_grads_norm = 3.7527
	sim_grads_norm_tr = 0.1033
-- Starting training on experience 6 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4753
	data_grads_norm = 3.5014
	new_data_grads_norm = 5.6099
	old_data_grads_norm = 4.3344
	sim_grads_norm_tr = -0.0631
-- Starting training on experience 7 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 3.2823
	data_grads_norm = 3.9858
	new_data_grads_norm = 6.0545
	old_data_grads_norm = 4.5555
	sim_grads_norm_tr = 0.1823
-- Starting training on experience 8 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.7616
	data_grads_norm = 3.8942
	new_data_grads_norm = 5.9119
	old_data_grads_norm = 4.2380
	sim_grads_norm_tr = 0.1366
-- Starting training on experience 9 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4411
	data_grads_norm = 3.7067
	new_data_grads_norm = 5.9875
	old_data_grads_norm = 4.1226
	sim_grads_norm_tr = -0.0448
-- Starting training on experience 10 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4078
	data_grads_norm = 3.1609
	new_data_grads_norm = 5.0797
	old_data_grads_norm = 4.0224
	sim_grads_norm_tr = -0.2304
-- Starting training on experience 11 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4016
	data_grads_norm = 3.4842
	new_data_grads_norm = 6.1172
	old_data_grads_norm = 4.0745
	sim_grads_norm_tr = 0.0110
-- Starting training on experience 12 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4304
	data_grads_norm = 3.5211
	new_data_grads_norm = 5.4299
	old_data_grads_norm = 3.6011
	sim_grads_norm_tr = 0.0571
-- Starting training on experience 13 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3890
	data_grads_norm = 2.9853
	new_data_grads_norm = 5.8814
	old_data_grads_norm = 4.1330
	sim_grads_norm_tr = 0.0374
-- Starting training on experience 14 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6030
	data_grads_norm = 3.6904
	new_data_grads_norm = 5.3390
	old_data_grads_norm = 4.4497
	sim_grads_norm_tr = 0.1291
-- Starting training on experience 15 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.9736
	data_grads_norm = 4.6730
	new_data_grads_norm = 6.2468
	old_data_grads_norm = 5.9812
	sim_grads_norm_tr = 0.0956
-- Starting training on experience 16 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3868
	data_grads_norm = 3.2893
	new_data_grads_norm = 5.5842
	old_data_grads_norm = 3.0872
	sim_grads_norm_tr = 0.1231
-- Starting training on experience 17 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2255
	data_grads_norm = 3.7519
	new_data_grads_norm = 4.9397
	old_data_grads_norm = 6.2208
	sim_grads_norm_tr = 0.0897
-- Starting training on experience 18 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2834
	data_grads_norm = 3.2305
	new_data_grads_norm = 5.5980
	old_data_grads_norm = 3.1015
	sim_grads_norm_tr = -0.1081
-- Starting training on experience 19 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3330
	data_grads_norm = 3.7225
	new_data_grads_norm = 5.3434
	old_data_grads_norm = 4.6357
	sim_grads_norm_tr = -0.0186
-- Starting training on experience 20 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0317
	data_grads_norm = 3.0408
	new_data_grads_norm = 5.3886
	old_data_grads_norm = 2.6421
	sim_grads_norm_tr = 0.0781
-- Starting training on experience 21 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4586
	data_grads_norm = 3.4745
	new_data_grads_norm = 5.4490
	old_data_grads_norm = 3.3516
	sim_grads_norm_tr = 0.1222
-- Starting training on experience 22 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5605
	data_grads_norm = 3.3765
	new_data_grads_norm = 5.2906
	old_data_grads_norm = 3.4443
	sim_grads_norm_tr = 0.0988
-- Starting training on experience 23 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0180
	data_grads_norm = 2.8406
	new_data_grads_norm = 5.6275
	old_data_grads_norm = 3.7518
	sim_grads_norm_tr = -0.1600
-- Starting training on experience 24 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3823
	data_grads_norm = 3.6036
	new_data_grads_norm = 6.4201
	old_data_grads_norm = 3.5986
	sim_grads_norm_tr = 0.0901
-- Starting training on experience 25 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8862
	data_grads_norm = 2.8362
	new_data_grads_norm = 4.7802
	old_data_grads_norm = 3.5613
	sim_grads_norm_tr = -0.0046
-- Starting training on experience 26 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1013
	data_grads_norm = 3.4000
	new_data_grads_norm = 5.6403
	old_data_grads_norm = 3.6970
	sim_grads_norm_tr = 0.0038
-- Starting training on experience 27 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1542
	data_grads_norm = 3.0447
	new_data_grads_norm = 5.1599
	old_data_grads_norm = 3.2911
	sim_grads_norm_tr = 0.0000
-- Starting training on experience 28 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1759
	data_grads_norm = 3.1632
	new_data_grads_norm = 5.6916
	old_data_grads_norm = 3.3940
	sim_grads_norm_tr = 0.1057
-- Starting training on experience 29 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8184
	data_grads_norm = 2.9301
	new_data_grads_norm = 5.5733
	old_data_grads_norm = 3.3835
	sim_grads_norm_tr = -0.1547
-- Starting training on experience 30 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1346
	data_grads_norm = 3.3666
	new_data_grads_norm = 6.4287
	old_data_grads_norm = 3.2147
	sim_grads_norm_tr = 0.1745
-- Starting training on experience 31 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2704
	data_grads_norm = 3.3007
	new_data_grads_norm = 5.1955
	old_data_grads_norm = 3.8741
	sim_grads_norm_tr = 0.0661
-- Starting training on experience 32 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0370
	data_grads_norm = 3.0596
	new_data_grads_norm = 5.4003
	old_data_grads_norm = 3.6017
	sim_grads_norm_tr = 0.0899
-- Starting training on experience 33 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2602
	data_grads_norm = 3.7582
	new_data_grads_norm = 6.0406
	old_data_grads_norm = 4.5312
	sim_grads_norm_tr = 0.0300
-- Starting training on experience 34 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.6983
	data_grads_norm = 3.8063
	new_data_grads_norm = 5.2701
	old_data_grads_norm = 4.8663
	sim_grads_norm_tr = 0.0705
-- Starting training on experience 35 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9424
	data_grads_norm = 3.1382
	new_data_grads_norm = 6.2228
	old_data_grads_norm = 2.9387
	sim_grads_norm_tr = 0.1361
-- Starting training on experience 36 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8965
	data_grads_norm = 2.6886
	new_data_grads_norm = 5.1200
	old_data_grads_norm = 2.8937
	sim_grads_norm_tr = -0.0508
-- Starting training on experience 37 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8588
	data_grads_norm = 3.0099
	new_data_grads_norm = 5.7542
	old_data_grads_norm = 4.0870
	sim_grads_norm_tr = -0.0745
-- Starting training on experience 38 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9663
	data_grads_norm = 3.3434
	new_data_grads_norm = 5.7907
	old_data_grads_norm = 3.7805
	sim_grads_norm_tr = -0.0102
-- Starting training on experience 39 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8832
	data_grads_norm = 2.9119
	new_data_grads_norm = 5.8271
	old_data_grads_norm = 2.7393
	sim_grads_norm_tr = 0.0645
-- Starting training on experience 40 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5966
	data_grads_norm = 4.0771
	new_data_grads_norm = 6.0988
	old_data_grads_norm = 4.1147
	sim_grads_norm_tr = 0.3167
-- Starting training on experience 41 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5578
	data_grads_norm = 2.5978
	new_data_grads_norm = 4.7245
	old_data_grads_norm = 2.6830
	sim_grads_norm_tr = -0.0359
-- Starting training on experience 42 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8198
	data_grads_norm = 3.1087
	new_data_grads_norm = 5.5490
	old_data_grads_norm = 4.3228
	sim_grads_norm_tr = -0.0877
-- Starting training on experience 43 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1787
	data_grads_norm = 3.7572
	new_data_grads_norm = 5.9031
	old_data_grads_norm = 5.1540
	sim_grads_norm_tr = -0.0250
-- Starting training on experience 44 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0327
	data_grads_norm = 3.5498
	new_data_grads_norm = 5.8515
	old_data_grads_norm = 4.1143
	sim_grads_norm_tr = -0.0108
-- Starting training on experience 45 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8782
	data_grads_norm = 3.0189
	new_data_grads_norm = 5.2401
	old_data_grads_norm = 3.3332
	sim_grads_norm_tr = 0.0164
-- Starting training on experience 46 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0275
	data_grads_norm = 3.4784
	new_data_grads_norm = 5.8834
	old_data_grads_norm = 4.3112
	sim_grads_norm_tr = -0.0301
-- Starting training on experience 47 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2587
	data_grads_norm = 3.8874
	new_data_grads_norm = 5.6177
	old_data_grads_norm = 3.8715
	sim_grads_norm_tr = 0.2574
-- Starting training on experience 48 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0874
	data_grads_norm = 3.8431
	new_data_grads_norm = 5.6386
	old_data_grads_norm = 5.0628
	sim_grads_norm_tr = 0.0476
-- Starting training on experience 49 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7834
	data_grads_norm = 3.4807
	new_data_grads_norm = 5.9865
	old_data_grads_norm = 4.3637
	sim_grads_norm_tr = 0.0527
-- Starting training on experience 50 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3547
	data_grads_norm = 3.7151
	new_data_grads_norm = 5.4760
	old_data_grads_norm = 4.6843
	sim_grads_norm_tr = 0.0150
-- Starting training on experience 51 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9512
	data_grads_norm = 3.0063
	new_data_grads_norm = 5.1166
	old_data_grads_norm = 4.2772
	sim_grads_norm_tr = -0.1014
-- Starting training on experience 52 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2500
	data_grads_norm = 3.8482
	new_data_grads_norm = 4.8136
	old_data_grads_norm = 4.6731
	sim_grads_norm_tr = 0.3514
-- Starting training on experience 53 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7093
	data_grads_norm = 2.6761
	new_data_grads_norm = 4.4626
	old_data_grads_norm = 3.7506
	sim_grads_norm_tr = -0.0887
-- Starting training on experience 54 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5349
	data_grads_norm = 2.6280
	new_data_grads_norm = 4.1828
	old_data_grads_norm = 4.0368
	sim_grads_norm_tr = -0.2419
-- Starting training on experience 55 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9681
	data_grads_norm = 3.4089
	new_data_grads_norm = 5.9601
	old_data_grads_norm = 3.1819
	sim_grads_norm_tr = 0.0993
-- Starting training on experience 56 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9817
	data_grads_norm = 3.7995
	new_data_grads_norm = 5.0813
	old_data_grads_norm = 5.4068
	sim_grads_norm_tr = -0.0530
-- Starting training on experience 57 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2782
	data_grads_norm = 3.8004
	new_data_grads_norm = 5.4148
	old_data_grads_norm = 4.7550
	sim_grads_norm_tr = 0.0892
-- Starting training on experience 58 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0426
	data_grads_norm = 3.3958
	new_data_grads_norm = 4.6422
	old_data_grads_norm = 3.1016
	sim_grads_norm_tr = 0.0636
-- Starting training on experience 59 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1331
	data_grads_norm = 3.5989
	new_data_grads_norm = 5.2709
	old_data_grads_norm = 3.8605
	sim_grads_norm_tr = 0.1157
-- Starting training on experience 60 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8253
	data_grads_norm = 3.4571
	new_data_grads_norm = 4.9031
	old_data_grads_norm = 4.1881
	sim_grads_norm_tr = 0.1443
-- Starting training on experience 61 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1670
	data_grads_norm = 3.8238
	new_data_grads_norm = 5.3266
	old_data_grads_norm = 4.9737
	sim_grads_norm_tr = 0.1956
-- Starting training on experience 62 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7458
	data_grads_norm = 3.1478
	new_data_grads_norm = 4.5163
	old_data_grads_norm = 3.5323
	sim_grads_norm_tr = 0.1557
-- Starting training on experience 63 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6675
	data_grads_norm = 2.8258
	new_data_grads_norm = 4.3529
	old_data_grads_norm = 3.8335
	sim_grads_norm_tr = 0.0289
-- Starting training on experience 64 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6414
	data_grads_norm = 3.1730
	new_data_grads_norm = 5.1086
	old_data_grads_norm = 5.0447
	sim_grads_norm_tr = -0.0179
-- Starting training on experience 65 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0869
	data_grads_norm = 3.8445
	new_data_grads_norm = 4.1829
	old_data_grads_norm = 5.2368
	sim_grads_norm_tr = 0.1837
-- Starting training on experience 66 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8941
	data_grads_norm = 3.7233
	new_data_grads_norm = 4.6440
	old_data_grads_norm = 5.4740
	sim_grads_norm_tr = 0.0480
-- Starting training on experience 67 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6125
	data_grads_norm = 2.5463
	new_data_grads_norm = 4.4600
	old_data_grads_norm = 3.7247
	sim_grads_norm_tr = -0.1630
-- Starting training on experience 68 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9813
	data_grads_norm = 3.1112
	new_data_grads_norm = 5.3203
	old_data_grads_norm = 3.6983
	sim_grads_norm_tr = -0.0129
-- Starting training on experience 69 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5817
	data_grads_norm = 2.8408
	new_data_grads_norm = 4.8089
	old_data_grads_norm = 4.3186
	sim_grads_norm_tr = 0.0062
-- Starting training on experience 70 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5101
	data_grads_norm = 2.7671
	new_data_grads_norm = 4.7332
	old_data_grads_norm = 2.7004
	sim_grads_norm_tr = 0.4662
-- Starting training on experience 71 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6815
	data_grads_norm = 3.2049
	new_data_grads_norm = 4.9577
	old_data_grads_norm = 3.8329
	sim_grads_norm_tr = 0.1230
-- Starting training on experience 72 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6702
	data_grads_norm = 2.8895
	new_data_grads_norm = 4.3108
	old_data_grads_norm = 4.6179
	sim_grads_norm_tr = -0.0987
-- Starting training on experience 73 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9288
	data_grads_norm = 3.6112
	new_data_grads_norm = 4.8808
	old_data_grads_norm = 4.6275
	sim_grads_norm_tr = -0.0083
-- Starting training on experience 74 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8216
	data_grads_norm = 3.0242
	new_data_grads_norm = 5.2684
	old_data_grads_norm = 4.0824
	sim_grads_norm_tr = -0.1126
-- Starting training on experience 75 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8078
	data_grads_norm = 3.5509
	new_data_grads_norm = 5.6789
	old_data_grads_norm = 3.2333
	sim_grads_norm_tr = -0.0248
-- Starting training on experience 76 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9915
	data_grads_norm = 3.7999
	new_data_grads_norm = 6.0227
	old_data_grads_norm = 4.0978
	sim_grads_norm_tr = 0.2104
-- Starting training on experience 77 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3814
	data_grads_norm = 2.8074
	new_data_grads_norm = 5.9183
	old_data_grads_norm = 3.5971
	sim_grads_norm_tr = -0.1348
-- Starting training on experience 78 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8698
	data_grads_norm = 3.6859
	new_data_grads_norm = 5.5482
	old_data_grads_norm = 4.4553
	sim_grads_norm_tr = 0.1986
-- Starting training on experience 79 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6899
	data_grads_norm = 2.8681
	new_data_grads_norm = 5.1438
	old_data_grads_norm = 3.0740
	sim_grads_norm_tr = 0.0482
-- Starting training on experience 80 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8728
	data_grads_norm = 3.0706
	new_data_grads_norm = 5.2875
	old_data_grads_norm = 2.9811
	sim_grads_norm_tr = 0.0565
-- Starting training on experience 81 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0883
	data_grads_norm = 4.4489
	new_data_grads_norm = 5.5593
	old_data_grads_norm = 4.6921
	sim_grads_norm_tr = 0.2837
-- Starting training on experience 82 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5273
	data_grads_norm = 3.2145
	new_data_grads_norm = 5.6625
	old_data_grads_norm = 4.2887
	sim_grads_norm_tr = -0.1410
-- Starting training on experience 83 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6336
	data_grads_norm = 2.7863
	new_data_grads_norm = 5.0966
	old_data_grads_norm = 3.6721
	sim_grads_norm_tr = 0.0171
-- Starting training on experience 84 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3358
	data_grads_norm = 2.3225
	new_data_grads_norm = 4.7283
	old_data_grads_norm = 3.2675
	sim_grads_norm_tr = -0.1641
-- Starting training on experience 85 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0076
	data_grads_norm = 3.2842
	new_data_grads_norm = 4.9255
	old_data_grads_norm = 3.6166
	sim_grads_norm_tr = 0.1513
-- Starting training on experience 86 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6567
	data_grads_norm = 3.1621
	new_data_grads_norm = 5.0274
	old_data_grads_norm = 4.6485
	sim_grads_norm_tr = -0.0990
-- Starting training on experience 87 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7178
	data_grads_norm = 3.1779
	new_data_grads_norm = 5.9164
	old_data_grads_norm = 3.0821
	sim_grads_norm_tr = -0.1604
-- Starting training on experience 88 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6669
	data_grads_norm = 2.9915
	new_data_grads_norm = 4.9724
	old_data_grads_norm = 3.4043
	sim_grads_norm_tr = 0.0273
-- Starting training on experience 89 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5605
	data_grads_norm = 3.1814
	new_data_grads_norm = 4.4880
	old_data_grads_norm = 4.9904
	sim_grads_norm_tr = 0.1112
-- Starting training on experience 90 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5026
	data_grads_norm = 3.0187
	new_data_grads_norm = 6.4916
	old_data_grads_norm = 2.6739
	sim_grads_norm_tr = 0.0780
-- Starting training on experience 91 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9039
	data_grads_norm = 3.4466
	new_data_grads_norm = 4.8308
	old_data_grads_norm = 4.5028
	sim_grads_norm_tr = 0.0068
-- Starting training on experience 92 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3934
	data_grads_norm = 2.8344
	new_data_grads_norm = 5.1288
	old_data_grads_norm = 2.9940
	sim_grads_norm_tr = 0.0263
-- Starting training on experience 93 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5933
	data_grads_norm = 2.9502
	new_data_grads_norm = 5.3042
	old_data_grads_norm = 4.4227
	sim_grads_norm_tr = -0.1633
-- Starting training on experience 94 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5947
	data_grads_norm = 3.2292
	new_data_grads_norm = 5.8301
	old_data_grads_norm = 3.4684
	sim_grads_norm_tr = 0.1755
-- Starting training on experience 95 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1599
	data_grads_norm = 3.9144
	new_data_grads_norm = 5.4293
	old_data_grads_norm = 5.0229
	sim_grads_norm_tr = 0.1150
-- Starting training on experience 96 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4968
	data_grads_norm = 2.6874
	new_data_grads_norm = 5.0824
	old_data_grads_norm = 3.8729
	sim_grads_norm_tr = -0.1496
-- Starting training on experience 97 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8891
	data_grads_norm = 3.3016
	new_data_grads_norm = 5.3041
	old_data_grads_norm = 3.5336
	sim_grads_norm_tr = 0.0512
-- Starting training on experience 98 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9096
	data_grads_norm = 3.6545
	new_data_grads_norm = 6.5769
	old_data_grads_norm = 4.4310
	sim_grads_norm_tr = 0.0252
-- Starting training on experience 99 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6961
	data_grads_norm = 3.4750
	new_data_grads_norm = 6.1910
	old_data_grads_norm = 3.9477
	sim_grads_norm_tr = 0.0795
-- Starting training on experience 100 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1108
	data_grads_norm = 3.5286
	new_data_grads_norm = 5.2987
	old_data_grads_norm = 4.0759
	sim_grads_norm_tr = -0.1491
-- Starting training on experience 101 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8093
	data_grads_norm = 3.5144
	new_data_grads_norm = 5.2758
	old_data_grads_norm = 3.6384
	sim_grads_norm_tr = 0.2053
-- Starting training on experience 102 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9195
	data_grads_norm = 3.6334
	new_data_grads_norm = 4.8673
	old_data_grads_norm = 4.8950
	sim_grads_norm_tr = 0.0519
-- Starting training on experience 103 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8534
	data_grads_norm = 3.7069
	new_data_grads_norm = 5.5940
	old_data_grads_norm = 3.2582
	sim_grads_norm_tr = 0.1500
-- Starting training on experience 104 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9790
	data_grads_norm = 3.8251
	new_data_grads_norm = 5.5838
	old_data_grads_norm = 3.7695
	sim_grads_norm_tr = 0.1434
-- Starting training on experience 105 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6849
	data_grads_norm = 2.9166
	new_data_grads_norm = 5.1797
	old_data_grads_norm = 3.7955
	sim_grads_norm_tr = -0.1165
-- Starting training on experience 106 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9286
	data_grads_norm = 3.9592
	new_data_grads_norm = 5.3888
	old_data_grads_norm = 4.7134
	sim_grads_norm_tr = 0.2574
-- Starting training on experience 107 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5083
	data_grads_norm = 2.8603
	new_data_grads_norm = 5.1559
	old_data_grads_norm = 4.0269
	sim_grads_norm_tr = 0.0460
-- Starting training on experience 108 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3521
	data_grads_norm = 2.5720
	new_data_grads_norm = 5.0047
	old_data_grads_norm = 2.6909
	sim_grads_norm_tr = 0.0830
-- Starting training on experience 109 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7291
	data_grads_norm = 3.5224
	new_data_grads_norm = 5.4853
	old_data_grads_norm = 4.9925
	sim_grads_norm_tr = -0.0124
-- Starting training on experience 110 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9728
	data_grads_norm = 3.4296
	new_data_grads_norm = 5.4802
	old_data_grads_norm = 3.8386
	sim_grads_norm_tr = 0.1441
-- Starting training on experience 111 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6769
	data_grads_norm = 2.6399
	new_data_grads_norm = 5.1452
	old_data_grads_norm = 3.1368
	sim_grads_norm_tr = -0.0813
-- Starting training on experience 112 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5691
	data_grads_norm = 2.9495
	new_data_grads_norm = 5.0684
	old_data_grads_norm = 2.9367
	sim_grads_norm_tr = 0.0670
-- Starting training on experience 113 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4234
	data_grads_norm = 3.0565
	new_data_grads_norm = 5.3144
	old_data_grads_norm = 3.4437
	sim_grads_norm_tr = -0.0307
-- Starting training on experience 114 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6780
	data_grads_norm = 2.9603
	new_data_grads_norm = 5.1786
	old_data_grads_norm = 3.7284
	sim_grads_norm_tr = -0.0055
-- Starting training on experience 115 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2395
	data_grads_norm = 2.6923
	new_data_grads_norm = 5.1810
	old_data_grads_norm = 3.4664
	sim_grads_norm_tr = -0.1185
-- Starting training on experience 116 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1308
	data_grads_norm = 3.9703
	new_data_grads_norm = 6.1227
	old_data_grads_norm = 4.1250
	sim_grads_norm_tr = 0.1476
-- Starting training on experience 117 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6012
	data_grads_norm = 3.1871
	new_data_grads_norm = 5.7950
	old_data_grads_norm = 3.1397
	sim_grads_norm_tr = 0.0330
-- Starting training on experience 118 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6626
	data_grads_norm = 3.1245
	new_data_grads_norm = 5.3203
	old_data_grads_norm = 4.2434
	sim_grads_norm_tr = -0.2227
-- Starting training on experience 119 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7682
	data_grads_norm = 3.3953
	new_data_grads_norm = 5.2104
	old_data_grads_norm = 4.3407
	sim_grads_norm_tr = 0.0299
-- Starting training on experience 120 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0837
	data_grads_norm = 3.8171
	new_data_grads_norm = 5.7036
	old_data_grads_norm = 4.8198
	sim_grads_norm_tr = -0.0075
-- Starting training on experience 121 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5375
	data_grads_norm = 2.6221
	new_data_grads_norm = 5.1090
	old_data_grads_norm = 3.5646
	sim_grads_norm_tr = -0.0727
-- Starting training on experience 122 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0856
	data_grads_norm = 4.2234
	new_data_grads_norm = 5.6172
	old_data_grads_norm = 5.2255
	sim_grads_norm_tr = 0.1749
-- Starting training on experience 123 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6827
	data_grads_norm = 3.2815
	new_data_grads_norm = 4.8165
	old_data_grads_norm = 4.3090
	sim_grads_norm_tr = 0.0357
-- Starting training on experience 124 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6938
	data_grads_norm = 3.3617
	new_data_grads_norm = 4.7366
	old_data_grads_norm = 4.8734
	sim_grads_norm_tr = -0.0140
-- Starting training on experience 125 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9159
	data_grads_norm = 4.0494
	new_data_grads_norm = 5.4260
	old_data_grads_norm = 4.0858
	sim_grads_norm_tr = 0.2249
-- Starting training on experience 126 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5991
	data_grads_norm = 3.4329
	new_data_grads_norm = 5.6348
	old_data_grads_norm = 4.6948
	sim_grads_norm_tr = -0.1977
-- Starting training on experience 127 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3662
	data_grads_norm = 2.7359
	new_data_grads_norm = 5.6242
	old_data_grads_norm = 3.6783
	sim_grads_norm_tr = -0.0037
-- Starting training on experience 128 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2509
	data_grads_norm = 2.6385
	new_data_grads_norm = 4.7711
	old_data_grads_norm = 3.8318
	sim_grads_norm_tr = -0.1410
-- Starting training on experience 129 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8939
	data_grads_norm = 3.8902
	new_data_grads_norm = 5.2162
	old_data_grads_norm = 5.0150
	sim_grads_norm_tr = -0.1715
-- Starting training on experience 130 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0257
	data_grads_norm = 3.6964
	new_data_grads_norm = 5.3501
	old_data_grads_norm = 4.1741
	sim_grads_norm_tr = 0.0210
-- Starting training on experience 131 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2503
	data_grads_norm = 3.9194
	new_data_grads_norm = 5.9632
	old_data_grads_norm = 4.8064
	sim_grads_norm_tr = 0.0873
-- Starting training on experience 132 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5910
	data_grads_norm = 3.0870
	new_data_grads_norm = 5.1259
	old_data_grads_norm = 4.2398
	sim_grads_norm_tr = -0.0533
-- Starting training on experience 133 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1717
	data_grads_norm = 3.9430
	new_data_grads_norm = 5.7344
	old_data_grads_norm = 3.9663
	sim_grads_norm_tr = 0.1385
-- Starting training on experience 134 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2923
	data_grads_norm = 3.8271
	new_data_grads_norm = 5.1441
	old_data_grads_norm = 3.9666
	sim_grads_norm_tr = 0.3675
-- Starting training on experience 135 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5772
	data_grads_norm = 2.8085
	new_data_grads_norm = 4.4888
	old_data_grads_norm = 2.9110
	sim_grads_norm_tr = 0.0770
-- Starting training on experience 136 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0116
	data_grads_norm = 3.9926
	new_data_grads_norm = 5.8772
	old_data_grads_norm = 4.7979
	sim_grads_norm_tr = -0.0727
-- Starting training on experience 137 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7043
	data_grads_norm = 2.8919
	new_data_grads_norm = 6.1717
	old_data_grads_norm = 2.4201
	sim_grads_norm_tr = 0.1588
-- Starting training on experience 138 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8312
	data_grads_norm = 3.7037
	new_data_grads_norm = 5.2431
	old_data_grads_norm = 4.2187
	sim_grads_norm_tr = 0.0679
-- Starting training on experience 139 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7241
	data_grads_norm = 3.4589
	new_data_grads_norm = 4.5603
	old_data_grads_norm = 3.2424
	sim_grads_norm_tr = 0.1715
-- Starting training on experience 140 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5247
	data_grads_norm = 2.7312
	new_data_grads_norm = 4.3362
	old_data_grads_norm = 4.4616
	sim_grads_norm_tr = -0.1396
-- Starting training on experience 141 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3511
	data_grads_norm = 2.6780
	new_data_grads_norm = 5.3866
	old_data_grads_norm = 3.6889
	sim_grads_norm_tr = -0.0584
-- Starting training on experience 142 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7826
	data_grads_norm = 3.8043
	new_data_grads_norm = 5.3903
	old_data_grads_norm = 6.5018
	sim_grads_norm_tr = -0.0811
-- Starting training on experience 143 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8935
	data_grads_norm = 3.0571
	new_data_grads_norm = 5.2518
	old_data_grads_norm = 4.0961
	sim_grads_norm_tr = 0.0208
-- Starting training on experience 144 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4990
	data_grads_norm = 2.8011
	new_data_grads_norm = 5.3703
	old_data_grads_norm = 3.4837
	sim_grads_norm_tr = 0.0307
-- Starting training on experience 145 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5809
	data_grads_norm = 2.7044
	new_data_grads_norm = 5.3694
	old_data_grads_norm = 4.8660
	sim_grads_norm_tr = -0.1398
-- Starting training on experience 146 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8909
	data_grads_norm = 4.1491
	new_data_grads_norm = 5.5088
	old_data_grads_norm = 6.0994
	sim_grads_norm_tr = -0.0241
-- Starting training on experience 147 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8831
	data_grads_norm = 3.5377
	new_data_grads_norm = 5.9957
	old_data_grads_norm = 3.6583
	sim_grads_norm_tr = -0.0492
-- Starting training on experience 148 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6452
	data_grads_norm = 3.7783
	new_data_grads_norm = 5.4374
	old_data_grads_norm = 4.5786
	sim_grads_norm_tr = 0.1732
-- Starting training on experience 149 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8892
	data_grads_norm = 4.3131
	new_data_grads_norm = 6.5389
	old_data_grads_norm = 4.4585
	sim_grads_norm_tr = 0.0776
-- Starting training on experience 150 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3149
	data_grads_norm = 2.6400
	new_data_grads_norm = 5.9759
	old_data_grads_norm = 2.4197
	sim_grads_norm_tr = -0.0293
-- Starting training on experience 151 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7271
	data_grads_norm = 3.7714
	new_data_grads_norm = 5.1952
	old_data_grads_norm = 4.6476
	sim_grads_norm_tr = -0.0005
-- Starting training on experience 152 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8735
	data_grads_norm = 3.5130
	new_data_grads_norm = 5.9894
	old_data_grads_norm = 4.0954
	sim_grads_norm_tr = 0.0246
-- Starting training on experience 153 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9002
	data_grads_norm = 3.8453
	new_data_grads_norm = 4.7178
	old_data_grads_norm = 5.3928
	sim_grads_norm_tr = 0.1514
-- Starting training on experience 154 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9419
	data_grads_norm = 3.7099
	new_data_grads_norm = 5.4247
	old_data_grads_norm = 4.8084
	sim_grads_norm_tr = 0.0002
-- Starting training on experience 155 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2891
	data_grads_norm = 3.3606
	new_data_grads_norm = 5.0856
	old_data_grads_norm = 5.0055
	sim_grads_norm_tr = 0.0480
-- Starting training on experience 156 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8955
	data_grads_norm = 3.8300
	new_data_grads_norm = 5.8688
	old_data_grads_norm = 4.9331
	sim_grads_norm_tr = -0.0373
-- Starting training on experience 157 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6643
	data_grads_norm = 3.1735
	new_data_grads_norm = 4.8951
	old_data_grads_norm = 4.2455
	sim_grads_norm_tr = -0.1176
-- Starting training on experience 158 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3316
	data_grads_norm = 2.7597
	new_data_grads_norm = 5.6498
	old_data_grads_norm = 3.6515
	sim_grads_norm_tr = -0.0467
-- Starting training on experience 159 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5494
	data_grads_norm = 3.3713
	new_data_grads_norm = 5.8105
	old_data_grads_norm = 2.9603
	sim_grads_norm_tr = 0.0308
-- Starting training on experience 160 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5688
	data_grads_norm = 3.1055
	new_data_grads_norm = 5.4457
	old_data_grads_norm = 5.2172
	sim_grads_norm_tr = -0.0802
-- Starting training on experience 161 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5749
	data_grads_norm = 3.2426
	new_data_grads_norm = 5.1923
	old_data_grads_norm = 3.4569
	sim_grads_norm_tr = 0.0483
-- Starting training on experience 162 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5216
	data_grads_norm = 3.7348
	new_data_grads_norm = 6.0455
	old_data_grads_norm = 4.7139
	sim_grads_norm_tr = -0.0419
-- Starting training on experience 163 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6549
	data_grads_norm = 3.0696
	new_data_grads_norm = 5.5996
	old_data_grads_norm = 3.5319
	sim_grads_norm_tr = -0.1048
-- Starting training on experience 164 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8069
	data_grads_norm = 3.3460
	new_data_grads_norm = 5.4101
	old_data_grads_norm = 3.6450
	sim_grads_norm_tr = 0.1139
-- Starting training on experience 165 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3861
	data_grads_norm = 2.5203
	new_data_grads_norm = 5.7632
	old_data_grads_norm = 2.5743
	sim_grads_norm_tr = 0.0386
-- Starting training on experience 166 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8282
	data_grads_norm = 3.7196
	new_data_grads_norm = 5.4981
	old_data_grads_norm = 4.5588
	sim_grads_norm_tr = 0.0495
-- Starting training on experience 167 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7474
	data_grads_norm = 3.4867
	new_data_grads_norm = 6.3677
	old_data_grads_norm = 5.2083
	sim_grads_norm_tr = -0.0348
-- Starting training on experience 168 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6958
	data_grads_norm = 3.3339
	new_data_grads_norm = 5.5455
	old_data_grads_norm = 4.0385
	sim_grads_norm_tr = -0.0567
-- Starting training on experience 169 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8482
	data_grads_norm = 3.8384
	new_data_grads_norm = 6.1816
	old_data_grads_norm = 4.8080
	sim_grads_norm_tr = -0.0338
-- Starting training on experience 170 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7074
	data_grads_norm = 3.7589
	new_data_grads_norm = 6.3247
	old_data_grads_norm = 3.6732
	sim_grads_norm_tr = 0.2626
-- Starting training on experience 171 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4561
	data_grads_norm = 3.1163
	new_data_grads_norm = 5.3233
	old_data_grads_norm = 3.6666
	sim_grads_norm_tr = -0.0575
-- Starting training on experience 172 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8847
	data_grads_norm = 3.7735
	new_data_grads_norm = 6.5710
	old_data_grads_norm = 4.1320
	sim_grads_norm_tr = 0.0456
-- Starting training on experience 173 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4802
	data_grads_norm = 3.6910
	new_data_grads_norm = 7.5634
	old_data_grads_norm = 4.5808
	sim_grads_norm_tr = 0.0287
-- Starting training on experience 174 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6501
	data_grads_norm = 3.7591
	new_data_grads_norm = 6.5794
	old_data_grads_norm = 4.0851
	sim_grads_norm_tr = 0.0716
-- Starting training on experience 175 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8162
	data_grads_norm = 4.0655
	new_data_grads_norm = 6.4394
	old_data_grads_norm = 4.6234
	sim_grads_norm_tr = -0.0266
-- Starting training on experience 176 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8635
	data_grads_norm = 4.1276
	new_data_grads_norm = 7.4796
	old_data_grads_norm = 3.7330
	sim_grads_norm_tr = 0.1603
-- Starting training on experience 177 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2104
	data_grads_norm = 4.0943
	new_data_grads_norm = 5.8815
	old_data_grads_norm = 4.6375
	sim_grads_norm_tr = 0.1918
-- Starting training on experience 178 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4138
	data_grads_norm = 3.0988
	new_data_grads_norm = 6.0043
	old_data_grads_norm = 3.2013
	sim_grads_norm_tr = 0.0025
-- Starting training on experience 179 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4744
	data_grads_norm = 2.7529
	new_data_grads_norm = 4.9491
	old_data_grads_norm = 3.9927
	sim_grads_norm_tr = -0.1335
-- Starting training on experience 180 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6638
	data_grads_norm = 3.1854
	new_data_grads_norm = 5.9832
	old_data_grads_norm = 3.6006
	sim_grads_norm_tr = -0.0287
-- Starting training on experience 181 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1694
	data_grads_norm = 4.1027
	new_data_grads_norm = 5.6777
	old_data_grads_norm = 4.5579
	sim_grads_norm_tr = -0.0482
-- Starting training on experience 182 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8988
	data_grads_norm = 3.7543
	new_data_grads_norm = 6.1606
	old_data_grads_norm = 4.9524
	sim_grads_norm_tr = -0.0141
-- Starting training on experience 183 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7415
	data_grads_norm = 3.6253
	new_data_grads_norm = 4.6849
	old_data_grads_norm = 4.3744
	sim_grads_norm_tr = 0.3459
-- Starting training on experience 184 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5806
	data_grads_norm = 2.9584
	new_data_grads_norm = 5.6722
	old_data_grads_norm = 3.9252
	sim_grads_norm_tr = -0.2397
-- Starting training on experience 185 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9041
	data_grads_norm = 3.7164
	new_data_grads_norm = 5.0386
	old_data_grads_norm = 4.8992
	sim_grads_norm_tr = 0.0439
-- Starting training on experience 186 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5766
	data_grads_norm = 3.6214
	new_data_grads_norm = 5.8424
	old_data_grads_norm = 4.3474
	sim_grads_norm_tr = 0.0861
-- Starting training on experience 187 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9439
	data_grads_norm = 3.6273
	new_data_grads_norm = 5.3358
	old_data_grads_norm = 4.8810
	sim_grads_norm_tr = -0.1283
-- Starting training on experience 188 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4603
	data_grads_norm = 3.4093
	new_data_grads_norm = 5.8377
	old_data_grads_norm = 3.9918
	sim_grads_norm_tr = 0.1204
-- Starting training on experience 189 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2699
	data_grads_norm = 3.1313
	new_data_grads_norm = 5.6233
	old_data_grads_norm = 3.0794
	sim_grads_norm_tr = -0.0136
-- Starting training on experience 190 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6932
	data_grads_norm = 3.0567
	new_data_grads_norm = 5.3507
	old_data_grads_norm = 2.2235
	sim_grads_norm_tr = -0.0233
-- Starting training on experience 191 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3500
	data_grads_norm = 3.2681
	new_data_grads_norm = 5.1692
	old_data_grads_norm = 4.5977
	sim_grads_norm_tr = -0.1269
-- Starting training on experience 192 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9166
	data_grads_norm = 3.8530
	new_data_grads_norm = 5.8397
	old_data_grads_norm = 4.5706
	sim_grads_norm_tr = 0.1558
-- Starting training on experience 193 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8062
	data_grads_norm = 3.8426
	new_data_grads_norm = 5.9073
	old_data_grads_norm = 4.7604
	sim_grads_norm_tr = -0.0598
-- Starting training on experience 194 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4399
	data_grads_norm = 3.5134
	new_data_grads_norm = 5.7855
	old_data_grads_norm = 3.9558
	sim_grads_norm_tr = 0.0003
-- Starting training on experience 195 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8524
	data_grads_norm = 3.7828
	new_data_grads_norm = 5.5109
	old_data_grads_norm = 4.9247
	sim_grads_norm_tr = -0.0011
-- Starting training on experience 196 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1898
	data_grads_norm = 4.6813
	new_data_grads_norm = 6.0878
	old_data_grads_norm = 6.2422
	sim_grads_norm_tr = 0.1828
-- Starting training on experience 197 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6137
	data_grads_norm = 3.7873
	new_data_grads_norm = 5.3297
	old_data_grads_norm = 4.1571
	sim_grads_norm_tr = 0.0227
-- Starting training on experience 198 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7743
	data_grads_norm = 3.2056
	new_data_grads_norm = 5.0550
	old_data_grads_norm = 3.6803
	sim_grads_norm_tr = 0.2153
-- Starting training on experience 199 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3942
	data_grads_norm = 2.7357
	new_data_grads_norm = 4.9511
	old_data_grads_norm = 4.2539
	sim_grads_norm_tr = -0.1219
-- Starting training on experience 200 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6697
	data_grads_norm = 3.2023
	new_data_grads_norm = 5.7682
	old_data_grads_norm = 4.2821
	sim_grads_norm_tr = -0.2475
-- Starting training on experience 201 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7055
	data_grads_norm = 3.5616
	new_data_grads_norm = 6.1052
	old_data_grads_norm = 4.8301
	sim_grads_norm_tr = 0.0304
-- Starting training on experience 202 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6916
	data_grads_norm = 3.4402
	new_data_grads_norm = 5.4513
	old_data_grads_norm = 4.3268
	sim_grads_norm_tr = 0.0021
-- Starting training on experience 203 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7744
	data_grads_norm = 3.2615
	new_data_grads_norm = 5.5153
	old_data_grads_norm = 3.8271
	sim_grads_norm_tr = 0.0740
-- Starting training on experience 204 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5336
	data_grads_norm = 4.2303
	new_data_grads_norm = 6.5077
	old_data_grads_norm = 5.2593
	sim_grads_norm_tr = -0.1071
-- Starting training on experience 205 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1843
	data_grads_norm = 5.3451
	new_data_grads_norm = 6.3591
	old_data_grads_norm = 7.5384
	sim_grads_norm_tr = 0.1554
-- Starting training on experience 206 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1676
	data_grads_norm = 4.7709
	new_data_grads_norm = 6.3478
	old_data_grads_norm = 6.6496
	sim_grads_norm_tr = 0.0607
-- Starting training on experience 207 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8544
	data_grads_norm = 4.2358
	new_data_grads_norm = 5.1420
	old_data_grads_norm = 6.1631
	sim_grads_norm_tr = -0.0402
-- Starting training on experience 208 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8561
	data_grads_norm = 3.8250
	new_data_grads_norm = 5.3629
	old_data_grads_norm = 4.7221
	sim_grads_norm_tr = 0.1016
-- Starting training on experience 209 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8589
	data_grads_norm = 3.5126
	new_data_grads_norm = 5.6056
	old_data_grads_norm = 4.4179
	sim_grads_norm_tr = -0.0629
-- Starting training on experience 210 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8845
	data_grads_norm = 3.8544
	new_data_grads_norm = 5.3494
	old_data_grads_norm = 5.7788
	sim_grads_norm_tr = 0.0523
-- Starting training on experience 211 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7459
	data_grads_norm = 3.3955
	new_data_grads_norm = 5.8723
	old_data_grads_norm = 3.4923
	sim_grads_norm_tr = 0.1538
-- Starting training on experience 212 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8862
	data_grads_norm = 4.2479
	new_data_grads_norm = 4.9112
	old_data_grads_norm = 5.7831
	sim_grads_norm_tr = -0.0013
-- Starting training on experience 213 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7946
	data_grads_norm = 3.8620
	new_data_grads_norm = 5.7413
	old_data_grads_norm = 5.4256
	sim_grads_norm_tr = -0.1500
-- Starting training on experience 214 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3210
	data_grads_norm = 5.5117
	new_data_grads_norm = 5.7364
	old_data_grads_norm = 6.8238
	sim_grads_norm_tr = 0.0934
-- Starting training on experience 215 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0322
	data_grads_norm = 5.8131
	new_data_grads_norm = 5.9532
	old_data_grads_norm = 8.1918
	sim_grads_norm_tr = 0.1845
-- Starting training on experience 216 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5093
	data_grads_norm = 3.4190
	new_data_grads_norm = 5.6434
	old_data_grads_norm = 4.5774
	sim_grads_norm_tr = -0.1083
-- Starting training on experience 217 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9615
	data_grads_norm = 3.8107
	new_data_grads_norm = 6.1289
	old_data_grads_norm = 4.0492
	sim_grads_norm_tr = 0.1188
-- Starting training on experience 218 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0285
	data_grads_norm = 3.9148
	new_data_grads_norm = 5.8326
	old_data_grads_norm = 4.7702
	sim_grads_norm_tr = 0.0988
-- Starting training on experience 219 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8261
	data_grads_norm = 3.6382
	new_data_grads_norm = 5.5600
	old_data_grads_norm = 5.2545
	sim_grads_norm_tr = -0.0722
-- Starting training on experience 220 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7128
	data_grads_norm = 3.7315
	new_data_grads_norm = 6.1031
	old_data_grads_norm = 4.6007
	sim_grads_norm_tr = 0.1893
-- Starting training on experience 221 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9580
	data_grads_norm = 3.8060
	new_data_grads_norm = 5.4544
	old_data_grads_norm = 4.7155
	sim_grads_norm_tr = 0.1241
-- Starting training on experience 222 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1308
	data_grads_norm = 4.1926
	new_data_grads_norm = 5.3081
	old_data_grads_norm = 5.8317
	sim_grads_norm_tr = 0.0205
-- Starting training on experience 223 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9263
	data_grads_norm = 3.2647
	new_data_grads_norm = 5.3084
	old_data_grads_norm = 4.0161
	sim_grads_norm_tr = -0.1190
-- Starting training on experience 224 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4949
	data_grads_norm = 3.1148
	new_data_grads_norm = 5.7909
	old_data_grads_norm = 4.2002
	sim_grads_norm_tr = -0.0738
-- Starting training on experience 225 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5715
	data_grads_norm = 3.5304
	new_data_grads_norm = 5.1742
	old_data_grads_norm = 4.6619
	sim_grads_norm_tr = 0.0513
-- Starting training on experience 226 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5386
	data_grads_norm = 3.0006
	new_data_grads_norm = 5.5242
	old_data_grads_norm = 3.2888
	sim_grads_norm_tr = -0.1036
-- Starting training on experience 227 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3768
	data_grads_norm = 2.8532
	new_data_grads_norm = 6.3362
	old_data_grads_norm = 3.3327
	sim_grads_norm_tr = -0.0692
-- Starting training on experience 228 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5562
	data_grads_norm = 3.5858
	new_data_grads_norm = 6.2572
	old_data_grads_norm = 2.8680
	sim_grads_norm_tr = 0.0521
-- Starting training on experience 229 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4775
	data_grads_norm = 3.2112
	new_data_grads_norm = 5.5105
	old_data_grads_norm = 3.6222
	sim_grads_norm_tr = -0.0300
-- Starting training on experience 230 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7947
	data_grads_norm = 3.9566
	new_data_grads_norm = 5.9325
	old_data_grads_norm = 4.9673
	sim_grads_norm_tr = -0.0196
-- Starting training on experience 231 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5084
	data_grads_norm = 2.9697
	new_data_grads_norm = 6.1878
	old_data_grads_norm = 2.7577
	sim_grads_norm_tr = 0.2204
-- Starting training on experience 232 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1271
	data_grads_norm = 4.2317
	new_data_grads_norm = 6.5197
	old_data_grads_norm = 4.0661
	sim_grads_norm_tr = 0.0917
-- Starting training on experience 233 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5490
	data_grads_norm = 4.1027
	new_data_grads_norm = 5.3530
	old_data_grads_norm = 5.0810
	sim_grads_norm_tr = 0.0996
-- Starting training on experience 234 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6054
	data_grads_norm = 2.9352
	new_data_grads_norm = 5.4701
	old_data_grads_norm = 4.1245
	sim_grads_norm_tr = -0.2231
-- Starting training on experience 235 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6137
	data_grads_norm = 3.4071
	new_data_grads_norm = 6.6791
	old_data_grads_norm = 3.3423
	sim_grads_norm_tr = -0.0352
-- Starting training on experience 236 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6873
	data_grads_norm = 3.4868
	new_data_grads_norm = 6.0775
	old_data_grads_norm = 4.0920
	sim_grads_norm_tr = 0.1012
-- Starting training on experience 237 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6673
	data_grads_norm = 3.5790
	new_data_grads_norm = 5.6096
	old_data_grads_norm = 4.0867
	sim_grads_norm_tr = -0.0040
-- Starting training on experience 238 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5173
	data_grads_norm = 3.5520
	new_data_grads_norm = 6.5595
	old_data_grads_norm = 4.8748
	sim_grads_norm_tr = 0.0080
-- Starting training on experience 239 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8022
	data_grads_norm = 4.2483
	new_data_grads_norm = 6.5458
	old_data_grads_norm = 5.2573
	sim_grads_norm_tr = 0.0561
-- Starting training on experience 240 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6589
	data_grads_norm = 3.4049
	new_data_grads_norm = 5.9084
	old_data_grads_norm = 3.7772
	sim_grads_norm_tr = 0.1067
-- Starting training on experience 241 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6512
	data_grads_norm = 3.3437
	new_data_grads_norm = 5.7322
	old_data_grads_norm = 4.7290
	sim_grads_norm_tr = -0.0514
-- Starting training on experience 242 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6206
	data_grads_norm = 3.1401
	new_data_grads_norm = 6.3432
	old_data_grads_norm = 3.5055
	sim_grads_norm_tr = -0.0250
-- Starting training on experience 243 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4749
	data_grads_norm = 3.8208
	new_data_grads_norm = 5.0202
	old_data_grads_norm = 4.7766
	sim_grads_norm_tr = 0.0763
-- Starting training on experience 244 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8241
	data_grads_norm = 3.7371
	new_data_grads_norm = 5.4455
	old_data_grads_norm = 5.8484
	sim_grads_norm_tr = 0.0152
-- Starting training on experience 245 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7274
	data_grads_norm = 3.4215
	new_data_grads_norm = 6.0565
	old_data_grads_norm = 4.3185
	sim_grads_norm_tr = -0.0960
-- Starting training on experience 246 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8712
	data_grads_norm = 4.3705
	new_data_grads_norm = 6.6106
	old_data_grads_norm = 4.9743
	sim_grads_norm_tr = -0.0071
-- Starting training on experience 247 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4546
	data_grads_norm = 4.6803
	new_data_grads_norm = 6.4304
	old_data_grads_norm = 6.3037
	sim_grads_norm_tr = 0.0338
-- Starting training on experience 248 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7408
	data_grads_norm = 3.8112
	new_data_grads_norm = 6.2107
	old_data_grads_norm = 3.5489
	sim_grads_norm_tr = 0.0184
-- Starting training on experience 249 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1067
	data_grads_norm = 3.9789
	new_data_grads_norm = 6.2042
	old_data_grads_norm = 5.1675
	sim_grads_norm_tr = 0.0862
-- Starting training on experience 250 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8799
	data_grads_norm = 4.5895
	new_data_grads_norm = 6.1254
	old_data_grads_norm = 6.0409
	sim_grads_norm_tr = 0.0065
-- Starting training on experience 251 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0135
	data_grads_norm = 4.0036
	new_data_grads_norm = 6.3863
	old_data_grads_norm = 4.1450
	sim_grads_norm_tr = 0.2306
-- Starting training on experience 252 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7079
	data_grads_norm = 3.1893
	new_data_grads_norm = 5.8639
	old_data_grads_norm = 2.9777
	sim_grads_norm_tr = 0.1427
-- Starting training on experience 253 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6372
	data_grads_norm = 3.8234
	new_data_grads_norm = 6.3494
	old_data_grads_norm = 3.6071
	sim_grads_norm_tr = 0.1825
-- Starting training on experience 254 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4093
	data_grads_norm = 2.9902
	new_data_grads_norm = 6.0415
	old_data_grads_norm = 3.5807
	sim_grads_norm_tr = 0.1011
-- Starting training on experience 255 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7529
	data_grads_norm = 4.1475
	new_data_grads_norm = 5.7779
	old_data_grads_norm = 5.0325
	sim_grads_norm_tr = 0.1302
-- Starting training on experience 256 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6042
	data_grads_norm = 3.2104
	new_data_grads_norm = 5.4370
	old_data_grads_norm = 4.1336
	sim_grads_norm_tr = -0.0808
-- Starting training on experience 257 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7154
	data_grads_norm = 3.6388
	new_data_grads_norm = 5.7357
	old_data_grads_norm = 4.6672
	sim_grads_norm_tr = -0.1162
-- Starting training on experience 258 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7406
	data_grads_norm = 3.2355
	new_data_grads_norm = 6.2063
	old_data_grads_norm = 4.1793
	sim_grads_norm_tr = -0.0591
-- Starting training on experience 259 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9468
	data_grads_norm = 3.8659
	new_data_grads_norm = 6.0111
	old_data_grads_norm = 4.0833
	sim_grads_norm_tr = 0.1333
-- Starting training on experience 260 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4513
	data_grads_norm = 3.3786
	new_data_grads_norm = 6.3846
	old_data_grads_norm = 4.3219
	sim_grads_norm_tr = -0.1685
-- Starting training on experience 261 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4294
	data_grads_norm = 3.1185
	new_data_grads_norm = 6.3075
	old_data_grads_norm = 2.6636
	sim_grads_norm_tr = 0.0352
-- Starting training on experience 262 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6394
	data_grads_norm = 3.6232
	new_data_grads_norm = 5.2137
	old_data_grads_norm = 5.2448
	sim_grads_norm_tr = 0.0728
-- Starting training on experience 263 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9924
	data_grads_norm = 4.9907
	new_data_grads_norm = 6.5620
	old_data_grads_norm = 5.5181
	sim_grads_norm_tr = 0.1155
-- Starting training on experience 264 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4278
	data_grads_norm = 3.7429
	new_data_grads_norm = 5.7212
	old_data_grads_norm = 5.5074
	sim_grads_norm_tr = 0.1482
-- Starting training on experience 265 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4321
	data_grads_norm = 3.7037
	new_data_grads_norm = 5.8709
	old_data_grads_norm = 3.5227
	sim_grads_norm_tr = 0.2937
-- Starting training on experience 266 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7673
	data_grads_norm = 3.5257
	new_data_grads_norm = 5.4158
	old_data_grads_norm = 4.1386
	sim_grads_norm_tr = -0.0034
-- Starting training on experience 267 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3732
	data_grads_norm = 3.3677
	new_data_grads_norm = 5.6922
	old_data_grads_norm = 4.1540
	sim_grads_norm_tr = -0.0016
-- Starting training on experience 268 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5697
	data_grads_norm = 4.1782
	new_data_grads_norm = 6.5279
	old_data_grads_norm = 5.2788
	sim_grads_norm_tr = 0.0533
-- Starting training on experience 269 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6340
	data_grads_norm = 3.9362
	new_data_grads_norm = 5.4627
	old_data_grads_norm = 5.9800
	sim_grads_norm_tr = 0.0046
-- Starting training on experience 270 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5793
	data_grads_norm = 3.3911
	new_data_grads_norm = 5.5886
	old_data_grads_norm = 3.8646
	sim_grads_norm_tr = 0.0115
-- Starting training on experience 271 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9160
	data_grads_norm = 3.7254
	new_data_grads_norm = 5.5861
	old_data_grads_norm = 4.4361
	sim_grads_norm_tr = -0.0614
-- Starting training on experience 272 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6821
	data_grads_norm = 3.9496
	new_data_grads_norm = 5.6738
	old_data_grads_norm = 4.3021
	sim_grads_norm_tr = 0.1325
-- Starting training on experience 273 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0673
	data_grads_norm = 4.2834
	new_data_grads_norm = 6.0286
	old_data_grads_norm = 6.3741
	sim_grads_norm_tr = 0.0470
-- Starting training on experience 274 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9963
	data_grads_norm = 3.8739
	new_data_grads_norm = 5.7841
	old_data_grads_norm = 5.8857
	sim_grads_norm_tr = 0.1010
-- Starting training on experience 275 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4066
	data_grads_norm = 2.7192
	new_data_grads_norm = 5.1973
	old_data_grads_norm = 4.7169
	sim_grads_norm_tr = -0.1515
-- Starting training on experience 276 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3525
	data_grads_norm = 2.7639
	new_data_grads_norm = 5.3500
	old_data_grads_norm = 3.3559
	sim_grads_norm_tr = -0.0906
-- Starting training on experience 277 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8684
	data_grads_norm = 3.8899
	new_data_grads_norm = 6.9507
	old_data_grads_norm = 4.3439
	sim_grads_norm_tr = 0.0955
-- Starting training on experience 278 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5281
	data_grads_norm = 3.4777
	new_data_grads_norm = 4.8950
	old_data_grads_norm = 4.4866
	sim_grads_norm_tr = -0.0327
-- Starting training on experience 279 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0006
	data_grads_norm = 3.9699
	new_data_grads_norm = 6.2452
	old_data_grads_norm = 4.5436
	sim_grads_norm_tr = 0.1182
-- Starting training on experience 280 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9199
	data_grads_norm = 3.9790
	new_data_grads_norm = 5.0258
	old_data_grads_norm = 5.9700
	sim_grads_norm_tr = -0.0689
-- Starting training on experience 281 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3157
	data_grads_norm = 3.0032
	new_data_grads_norm = 6.3329
	old_data_grads_norm = 3.2439
	sim_grads_norm_tr = 0.0201
-- Starting training on experience 282 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3676
	data_grads_norm = 3.7920
	new_data_grads_norm = 5.8598
	old_data_grads_norm = 5.5194
	sim_grads_norm_tr = -0.1011
-- Starting training on experience 283 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8864
	data_grads_norm = 4.2016
	new_data_grads_norm = 5.8750
	old_data_grads_norm = 5.0803
	sim_grads_norm_tr = 0.1529
-- Starting training on experience 284 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7783
	data_grads_norm = 3.8829
	new_data_grads_norm = 6.5084
	old_data_grads_norm = 3.6658
	sim_grads_norm_tr = -0.0643
-- Starting training on experience 285 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4270
	data_grads_norm = 3.0718
	new_data_grads_norm = 6.0466
	old_data_grads_norm = 3.1966
	sim_grads_norm_tr = 0.0896
-- Starting training on experience 286 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6280
	data_grads_norm = 3.1410
	new_data_grads_norm = 5.3561
	old_data_grads_norm = 3.4184
	sim_grads_norm_tr = 0.2261
-- Starting training on experience 287 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6899
	data_grads_norm = 4.2985
	new_data_grads_norm = 5.9850
	old_data_grads_norm = 5.3726
	sim_grads_norm_tr = 0.1997
-- Starting training on experience 288 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1345
	data_grads_norm = 2.3268
	new_data_grads_norm = 5.4753
	old_data_grads_norm = 2.4915
	sim_grads_norm_tr = -0.1263
-- Starting training on experience 289 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0450
	data_grads_norm = 4.4621
	new_data_grads_norm = 5.5731
	old_data_grads_norm = 5.8146
	sim_grads_norm_tr = 0.2273
-- Starting training on experience 290 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2694
	data_grads_norm = 2.9502
	new_data_grads_norm = 5.6376
	old_data_grads_norm = 3.3781
	sim_grads_norm_tr = -0.0092
-- Starting training on experience 291 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3960
	data_grads_norm = 3.1558
	new_data_grads_norm = 5.8453
	old_data_grads_norm = 2.9077
	sim_grads_norm_tr = -0.1614
-- Starting training on experience 292 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9188
	data_grads_norm = 4.4024
	new_data_grads_norm = 5.0874
	old_data_grads_norm = 6.8775
	sim_grads_norm_tr = 0.0679
-- Starting training on experience 293 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4637
	data_grads_norm = 3.8317
	new_data_grads_norm = 6.3766
	old_data_grads_norm = 4.2705
	sim_grads_norm_tr = 0.0303
-- Starting training on experience 294 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0823
	data_grads_norm = 4.2764
	new_data_grads_norm = 5.8704
	old_data_grads_norm = 5.8452
	sim_grads_norm_tr = 0.0730
-- Starting training on experience 295 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5789
	data_grads_norm = 3.6992
	new_data_grads_norm = 6.8237
	old_data_grads_norm = 3.5152
	sim_grads_norm_tr = 0.0549
-- Starting training on experience 296 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6401
	data_grads_norm = 3.3724
	new_data_grads_norm = 6.0594
	old_data_grads_norm = 3.8502
	sim_grads_norm_tr = -0.0316
-- Starting training on experience 297 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5259
	data_grads_norm = 2.8422
	new_data_grads_norm = 4.6393
	old_data_grads_norm = 3.9594
	sim_grads_norm_tr = -0.1390
-- Starting training on experience 298 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7015
	data_grads_norm = 3.2589
	new_data_grads_norm = 5.0341
	old_data_grads_norm = 3.6656
	sim_grads_norm_tr = 0.1067
-- Starting training on experience 299 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3834
	data_grads_norm = 3.2733
	new_data_grads_norm = 5.5236
	old_data_grads_norm = 4.3044
	sim_grads_norm_tr = -0.1211
-- Starting training on experience 300 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0007
	data_grads_norm = 3.8877
	new_data_grads_norm = 6.1583
	old_data_grads_norm = 5.2506
	sim_grads_norm_tr = -0.0472
-- Starting training on experience 301 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8411
	data_grads_norm = 3.6699
	new_data_grads_norm = 5.8194
	old_data_grads_norm = 4.1422
	sim_grads_norm_tr = 0.1184
-- Starting training on experience 302 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6929
	data_grads_norm = 3.7402
	new_data_grads_norm = 6.3768
	old_data_grads_norm = 4.4800
	sim_grads_norm_tr = 0.0066
-- Starting training on experience 303 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5117
	data_grads_norm = 3.5096
	new_data_grads_norm = 6.1936
	old_data_grads_norm = 4.1850
	sim_grads_norm_tr = -0.1016
-- Starting training on experience 304 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5023
	data_grads_norm = 3.1668
	new_data_grads_norm = 5.8334
	old_data_grads_norm = 3.0511
	sim_grads_norm_tr = 0.1214
-- Starting training on experience 305 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3644
	data_grads_norm = 3.2152
	new_data_grads_norm = 5.4997
	old_data_grads_norm = 4.9503
	sim_grads_norm_tr = -0.1636
-- Starting training on experience 306 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7094
	data_grads_norm = 3.6976
	new_data_grads_norm = 6.5517
	old_data_grads_norm = 3.5177
	sim_grads_norm_tr = 0.2349
-- Starting training on experience 307 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7428
	data_grads_norm = 3.2558
	new_data_grads_norm = 4.7509
	old_data_grads_norm = 4.8578
	sim_grads_norm_tr = -0.1306
-- Starting training on experience 308 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6925
	data_grads_norm = 2.9933
	new_data_grads_norm = 5.6495
	old_data_grads_norm = 2.8887
	sim_grads_norm_tr = -0.0221
-- Starting training on experience 309 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9280
	data_grads_norm = 3.6093
	new_data_grads_norm = 5.5366
	old_data_grads_norm = 4.8170
	sim_grads_norm_tr = -0.1107
-- Starting training on experience 310 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2876
	data_grads_norm = 4.0522
	new_data_grads_norm = 5.6629
	old_data_grads_norm = 4.6756
	sim_grads_norm_tr = 0.0159
-- Starting training on experience 311 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6754
	data_grads_norm = 3.5198
	new_data_grads_norm = 6.0167
	old_data_grads_norm = 3.3071
	sim_grads_norm_tr = 0.1436
-- Starting training on experience 312 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7883
	data_grads_norm = 3.8253
	new_data_grads_norm = 6.1959
	old_data_grads_norm = 3.8802
	sim_grads_norm_tr = 0.0812
-- Starting training on experience 313 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8529
	data_grads_norm = 4.1365
	new_data_grads_norm = 6.1538
	old_data_grads_norm = 6.1780
	sim_grads_norm_tr = -0.0357
-- Starting training on experience 314 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1519
	data_grads_norm = 4.0996
	new_data_grads_norm = 6.0883
	old_data_grads_norm = 5.1057
	sim_grads_norm_tr = 0.0701
-- Starting training on experience 315 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4747
	data_grads_norm = 3.1615
	new_data_grads_norm = 5.7738
	old_data_grads_norm = 4.0229
	sim_grads_norm_tr = -0.0900
-- Starting training on experience 316 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0982
	data_grads_norm = 3.9732
	new_data_grads_norm = 6.6595
	old_data_grads_norm = 4.3614
	sim_grads_norm_tr = 0.1447
-- Starting training on experience 317 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2216
	data_grads_norm = 4.0809
	new_data_grads_norm = 5.9649
	old_data_grads_norm = 4.6482
	sim_grads_norm_tr = 0.0692
-- Starting training on experience 318 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0785
	data_grads_norm = 4.2634
	new_data_grads_norm = 6.3484
	old_data_grads_norm = 3.3078
	sim_grads_norm_tr = 0.2278
-- Starting training on experience 319 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8248
	data_grads_norm = 3.7113
	new_data_grads_norm = 5.6507
	old_data_grads_norm = 4.6592
	sim_grads_norm_tr = -0.0386
-- Starting training on experience 320 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0876
	data_grads_norm = 3.9704
	new_data_grads_norm = 5.9163
	old_data_grads_norm = 4.0855
	sim_grads_norm_tr = 0.1273
-- Starting training on experience 321 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6052
	data_grads_norm = 2.9336
	new_data_grads_norm = 6.2398
	old_data_grads_norm = 3.2530
	sim_grads_norm_tr = -0.1875
-- Starting training on experience 322 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5868
	data_grads_norm = 3.5800
	new_data_grads_norm = 6.1220
	old_data_grads_norm = 3.6821
	sim_grads_norm_tr = 0.0470
-- Starting training on experience 323 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0904
	data_grads_norm = 4.0379
	new_data_grads_norm = 5.6520
	old_data_grads_norm = 4.1178
	sim_grads_norm_tr = 0.1808
-- Starting training on experience 324 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1627
	data_grads_norm = 3.3062
	new_data_grads_norm = 6.8861
	old_data_grads_norm = 3.9053
	sim_grads_norm_tr = 0.0542
-- Starting training on experience 325 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7615
	data_grads_norm = 4.1575
	new_data_grads_norm = 5.6019
	old_data_grads_norm = 5.0999
	sim_grads_norm_tr = 0.2142
-- Starting training on experience 326 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1665
	data_grads_norm = 2.8546
	new_data_grads_norm = 4.8225
	old_data_grads_norm = 3.2723
	sim_grads_norm_tr = -0.0599
-- Starting training on experience 327 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7075
	data_grads_norm = 3.8207
	new_data_grads_norm = 5.2376
	old_data_grads_norm = 4.6823
	sim_grads_norm_tr = 0.1012
-- Starting training on experience 328 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7816
	data_grads_norm = 3.5950
	new_data_grads_norm = 5.6896
	old_data_grads_norm = 4.0236
	sim_grads_norm_tr = 0.0019
-- Starting training on experience 329 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5895
	data_grads_norm = 3.6266
	new_data_grads_norm = 4.9645
	old_data_grads_norm = 3.9003
	sim_grads_norm_tr = 0.1775
-- Starting training on experience 330 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2565
	data_grads_norm = 3.1809
	new_data_grads_norm = 5.0400
	old_data_grads_norm = 4.2937
	sim_grads_norm_tr = -0.0790
-- Starting training on experience 331 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5796
	data_grads_norm = 3.0064
	new_data_grads_norm = 5.4475
	old_data_grads_norm = 4.4845
	sim_grads_norm_tr = -0.1450
-- Starting training on experience 332 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5959
	data_grads_norm = 3.0373
	new_data_grads_norm = 5.7425
	old_data_grads_norm = 4.3792
	sim_grads_norm_tr = -0.1499
-- Starting training on experience 333 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6650
	data_grads_norm = 3.5598
	new_data_grads_norm = 6.1296
	old_data_grads_norm = 5.3099
	sim_grads_norm_tr = -0.0335
-- Starting training on experience 334 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0082
	data_grads_norm = 3.8297
	new_data_grads_norm = 6.1819
	old_data_grads_norm = 4.4241
	sim_grads_norm_tr = 0.1398
-- Starting training on experience 335 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2487
	data_grads_norm = 2.7801
	new_data_grads_norm = 5.5956
	old_data_grads_norm = 3.3795
	sim_grads_norm_tr = 0.0012
-- Starting training on experience 336 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6455
	data_grads_norm = 4.1862
	new_data_grads_norm = 7.3791
	old_data_grads_norm = 3.5440
	sim_grads_norm_tr = 0.0128
-- Starting training on experience 337 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7151
	data_grads_norm = 4.2242
	new_data_grads_norm = 6.5599
	old_data_grads_norm = 4.0277
	sim_grads_norm_tr = 0.1588
-- Starting training on experience 338 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6259
	data_grads_norm = 3.6798
	new_data_grads_norm = 6.5413
	old_data_grads_norm = 4.5576
	sim_grads_norm_tr = 0.0101
-- Starting training on experience 339 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5844
	data_grads_norm = 3.5867
	new_data_grads_norm = 5.6795
	old_data_grads_norm = 4.6702
	sim_grads_norm_tr = -0.0143
-- Starting training on experience 340 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8263
	data_grads_norm = 3.7045
	new_data_grads_norm = 6.4200
	old_data_grads_norm = 3.8322
	sim_grads_norm_tr = 0.0104
-- Starting training on experience 341 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6080
	data_grads_norm = 3.4630
	new_data_grads_norm = 5.3849
	old_data_grads_norm = 5.5630
	sim_grads_norm_tr = -0.0837
-- Starting training on experience 342 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7909
	data_grads_norm = 3.5780
	new_data_grads_norm = 6.5295
	old_data_grads_norm = 4.1827
	sim_grads_norm_tr = -0.0682
-- Starting training on experience 343 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9772
	data_grads_norm = 4.2482
	new_data_grads_norm = 6.0989
	old_data_grads_norm = 5.4791
	sim_grads_norm_tr = -0.0781
-- Starting training on experience 344 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8301
	data_grads_norm = 4.1126
	new_data_grads_norm = 6.7629
	old_data_grads_norm = 4.1034
	sim_grads_norm_tr = 0.1483
-- Starting training on experience 345 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6677
	data_grads_norm = 4.0304
	new_data_grads_norm = 6.5138
	old_data_grads_norm = 5.1989
	sim_grads_norm_tr = 0.0589
-- Starting training on experience 346 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7859
	data_grads_norm = 3.6391
	new_data_grads_norm = 6.6513
	old_data_grads_norm = 3.7707
	sim_grads_norm_tr = 0.0491
-- Starting training on experience 347 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7310
	data_grads_norm = 3.8622
	new_data_grads_norm = 7.3295
	old_data_grads_norm = 4.1493
	sim_grads_norm_tr = 0.0113
-- Starting training on experience 348 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9273
	data_grads_norm = 3.7063
	new_data_grads_norm = 7.1144
	old_data_grads_norm = 3.8116
	sim_grads_norm_tr = 0.0090
-- Starting training on experience 349 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5763
	data_grads_norm = 3.2980
	new_data_grads_norm = 6.3199
	old_data_grads_norm = 4.6133
	sim_grads_norm_tr = -0.0861
-- Starting training on experience 350 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9984
	data_grads_norm = 4.3214
	new_data_grads_norm = 6.9407
	old_data_grads_norm = 4.4149
	sim_grads_norm_tr = -0.0115
-- Starting training on experience 351 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9894
	data_grads_norm = 4.3532
	new_data_grads_norm = 5.9820
	old_data_grads_norm = 7.3689
	sim_grads_norm_tr = -0.0936
-- Starting training on experience 352 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6341
	data_grads_norm = 3.0214
	new_data_grads_norm = 5.5530
	old_data_grads_norm = 3.1153
	sim_grads_norm_tr = 0.0333
-- Starting training on experience 353 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7713
	data_grads_norm = 3.9033
	new_data_grads_norm = 5.7355
	old_data_grads_norm = 4.1386
	sim_grads_norm_tr = 0.0603
-- Starting training on experience 354 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4611
	data_grads_norm = 4.2587
	new_data_grads_norm = 5.8645
	old_data_grads_norm = 4.6302
	sim_grads_norm_tr = 0.3714
-- Starting training on experience 355 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6052
	data_grads_norm = 3.7572
	new_data_grads_norm = 6.9757
	old_data_grads_norm = 3.8003
	sim_grads_norm_tr = -0.0638
-- Starting training on experience 356 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5068
	data_grads_norm = 3.7441
	new_data_grads_norm = 6.0838
	old_data_grads_norm = 4.6872
	sim_grads_norm_tr = -0.0422
-- Starting training on experience 357 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7386
	data_grads_norm = 3.8500
	new_data_grads_norm = 5.6848
	old_data_grads_norm = 3.9728
	sim_grads_norm_tr = 0.2577
-- Starting training on experience 358 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2753
	data_grads_norm = 3.1036
	new_data_grads_norm = 5.1904
	old_data_grads_norm = 4.2377
	sim_grads_norm_tr = -0.1118
-- Starting training on experience 359 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8499
	data_grads_norm = 3.6563
	new_data_grads_norm = 5.4087
	old_data_grads_norm = 3.8262
	sim_grads_norm_tr = 0.1198
-- Starting training on experience 360 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3934
	data_grads_norm = 3.4359
	new_data_grads_norm = 5.1005
	old_data_grads_norm = 5.3737
	sim_grads_norm_tr = -0.0826
-- Starting training on experience 361 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7154
	data_grads_norm = 3.9125
	new_data_grads_norm = 5.9714
	old_data_grads_norm = 4.2761
	sim_grads_norm_tr = -0.1244
-- Starting training on experience 362 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8925
	data_grads_norm = 3.9999
	new_data_grads_norm = 6.7758
	old_data_grads_norm = 3.7291
	sim_grads_norm_tr = -0.0936
-- Starting training on experience 363 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9430
	data_grads_norm = 4.4702
	new_data_grads_norm = 6.4216
	old_data_grads_norm = 5.0487
	sim_grads_norm_tr = 0.1632
-- Starting training on experience 364 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6725
	data_grads_norm = 4.0386
	new_data_grads_norm = 5.7955
	old_data_grads_norm = 3.5661
	sim_grads_norm_tr = 0.1021
-- Starting training on experience 365 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1951
	data_grads_norm = 3.1752
	new_data_grads_norm = 5.5915
	old_data_grads_norm = 3.5176
	sim_grads_norm_tr = -0.1756
-- Starting training on experience 366 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7042
	data_grads_norm = 3.7874
	new_data_grads_norm = 5.3558
	old_data_grads_norm = 4.3439
	sim_grads_norm_tr = 0.0908
-- Starting training on experience 367 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7340
	data_grads_norm = 4.3833
	new_data_grads_norm = 5.9084
	old_data_grads_norm = 6.6222
	sim_grads_norm_tr = -0.0722
-- Starting training on experience 368 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6520
	data_grads_norm = 4.3026
	new_data_grads_norm = 6.4185
	old_data_grads_norm = 5.4283
	sim_grads_norm_tr = 0.0461
-- Starting training on experience 369 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7358
	data_grads_norm = 3.9375
	new_data_grads_norm = 6.4628
	old_data_grads_norm = 4.2992
	sim_grads_norm_tr = 0.0279
-- Starting training on experience 370 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9822
	data_grads_norm = 3.8661
	new_data_grads_norm = 6.0912
	old_data_grads_norm = 4.1653
	sim_grads_norm_tr = 0.1571
-- Starting training on experience 371 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4956
	data_grads_norm = 3.8546
	new_data_grads_norm = 6.1071
	old_data_grads_norm = 5.1267
	sim_grads_norm_tr = 0.0064
-- Starting training on experience 372 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5868
	data_grads_norm = 3.1187
	new_data_grads_norm = 5.6857
	old_data_grads_norm = 3.5209
	sim_grads_norm_tr = -0.0050
-- Starting training on experience 373 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8620
	data_grads_norm = 3.8707
	new_data_grads_norm = 5.8749
	old_data_grads_norm = 4.5589
	sim_grads_norm_tr = 0.0776
-- Starting training on experience 374 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4347
	data_grads_norm = 3.5186
	new_data_grads_norm = 6.5807
	old_data_grads_norm = 5.7417
	sim_grads_norm_tr = -0.0219
-- Starting training on experience 375 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1705
	data_grads_norm = 3.6421
	new_data_grads_norm = 5.8297
	old_data_grads_norm = 3.6873
	sim_grads_norm_tr = 0.1747
-- Starting training on experience 376 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2004
	data_grads_norm = 2.7635
	new_data_grads_norm = 5.5348
	old_data_grads_norm = 3.2511
	sim_grads_norm_tr = 0.0688
-- Starting training on experience 377 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6936
	data_grads_norm = 3.7818
	new_data_grads_norm = 5.4102
	old_data_grads_norm = 4.3002
	sim_grads_norm_tr = -0.0031
-- Starting training on experience 378 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6074
	data_grads_norm = 3.0227
	new_data_grads_norm = 6.7497
	old_data_grads_norm = 3.5577
	sim_grads_norm_tr = -0.1313
-- Starting training on experience 379 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2592
	data_grads_norm = 3.5540
	new_data_grads_norm = 5.9021
	old_data_grads_norm = 3.3676
	sim_grads_norm_tr = 0.0818
-- Starting training on experience 380 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8691
	data_grads_norm = 4.1477
	new_data_grads_norm = 6.0187
	old_data_grads_norm = 5.7374
	sim_grads_norm_tr = 0.0229
-- Starting training on experience 381 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7723
	data_grads_norm = 3.4838
	new_data_grads_norm = 5.3252
	old_data_grads_norm = 5.5765
	sim_grads_norm_tr = -0.0439
-- Starting training on experience 382 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5109
	data_grads_norm = 2.8320
	new_data_grads_norm = 5.9133
	old_data_grads_norm = 2.9078
	sim_grads_norm_tr = -0.1042
-- Starting training on experience 383 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0060
	data_grads_norm = 3.7868
	new_data_grads_norm = 6.2883
	old_data_grads_norm = 3.7875
	sim_grads_norm_tr = 0.1515
-- Starting training on experience 384 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2250
	data_grads_norm = 4.8787
	new_data_grads_norm = 5.7817
	old_data_grads_norm = 6.9541
	sim_grads_norm_tr = 0.0760
-- Starting training on experience 385 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8416
	data_grads_norm = 3.7684
	new_data_grads_norm = 5.7559
	old_data_grads_norm = 4.2724
	sim_grads_norm_tr = 0.1455
-- Starting training on experience 386 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3843
	data_grads_norm = 3.3371
	new_data_grads_norm = 6.1067
	old_data_grads_norm = 3.8182
	sim_grads_norm_tr = 0.0433
-- Starting training on experience 387 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5262
	data_grads_norm = 2.7544
	new_data_grads_norm = 5.7840
	old_data_grads_norm = 4.5029
	sim_grads_norm_tr = -0.2388
-- Starting training on experience 388 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3335
	data_grads_norm = 2.9960
	new_data_grads_norm = 6.7185
	old_data_grads_norm = 2.8508
	sim_grads_norm_tr = -0.0531
-- Starting training on experience 389 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8920
	data_grads_norm = 3.9375
	new_data_grads_norm = 6.1584
	old_data_grads_norm = 4.2527
	sim_grads_norm_tr = 0.1494
-- Starting training on experience 390 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7230
	data_grads_norm = 3.6797
	new_data_grads_norm = 5.6221
	old_data_grads_norm = 4.5470
	sim_grads_norm_tr = 0.2614
-- Starting training on experience 391 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3362
	data_grads_norm = 3.2030
	new_data_grads_norm = 5.9620
	old_data_grads_norm = 4.1851
	sim_grads_norm_tr = -0.1934
-- Starting training on experience 392 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8927
	data_grads_norm = 3.7573
	new_data_grads_norm = 7.1204
	old_data_grads_norm = 3.9228
	sim_grads_norm_tr = 0.0560
-- Starting training on experience 393 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0094
	data_grads_norm = 4.1693
	new_data_grads_norm = 6.4000
	old_data_grads_norm = 4.5375
	sim_grads_norm_tr = 0.0030
-- Starting training on experience 394 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4062
	data_grads_norm = 3.5298
	new_data_grads_norm = 5.7451
	old_data_grads_norm = 3.5114
	sim_grads_norm_tr = 0.0759
-- Starting training on experience 395 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6784
	data_grads_norm = 3.7684
	new_data_grads_norm = 6.1031
	old_data_grads_norm = 4.8721
	sim_grads_norm_tr = -0.0290
-- Starting training on experience 396 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4466
	data_grads_norm = 3.4100
	new_data_grads_norm = 6.1723
	old_data_grads_norm = 3.2523
	sim_grads_norm_tr = 0.0382
-- Starting training on experience 397 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5437
	data_grads_norm = 4.2683
	new_data_grads_norm = 5.9203
	old_data_grads_norm = 5.8197
	sim_grads_norm_tr = 0.0796
-- Starting training on experience 398 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6761
	data_grads_norm = 3.9808
	new_data_grads_norm = 5.9216
	old_data_grads_norm = 5.2771
	sim_grads_norm_tr = 0.0205
-- Starting training on experience 399 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7654
	data_grads_norm = 3.8028
	new_data_grads_norm = 7.3003
	old_data_grads_norm = 5.4144
	sim_grads_norm_tr = -0.1524
-- Starting training on experience 400 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6678
	data_grads_norm = 3.1987
	new_data_grads_norm = 5.1495
	old_data_grads_norm = 4.4618
	sim_grads_norm_tr = -0.0154
-- Starting training on experience 401 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5458
	data_grads_norm = 3.7097
	new_data_grads_norm = 6.5161
	old_data_grads_norm = 4.4600
	sim_grads_norm_tr = 0.0303
-- Starting training on experience 402 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6458
	data_grads_norm = 3.3445
	new_data_grads_norm = 6.2173
	old_data_grads_norm = 3.4956
	sim_grads_norm_tr = -0.0277
-- Starting training on experience 403 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3362
	data_grads_norm = 4.4419
	new_data_grads_norm = 6.4505
	old_data_grads_norm = 4.4925
	sim_grads_norm_tr = 0.0298
-- Starting training on experience 404 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6968
	data_grads_norm = 4.3273
	new_data_grads_norm = 6.7577
	old_data_grads_norm = 4.6235
	sim_grads_norm_tr = 0.1599
-- Starting training on experience 405 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8288
	data_grads_norm = 3.8599
	new_data_grads_norm = 6.7424
	old_data_grads_norm = 4.2858
	sim_grads_norm_tr = -0.0014
-- Starting training on experience 406 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5483
	data_grads_norm = 3.5423
	new_data_grads_norm = 6.7539
	old_data_grads_norm = 3.1538
	sim_grads_norm_tr = -0.0199
-- Starting training on experience 407 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8098
	data_grads_norm = 4.1464
	new_data_grads_norm = 6.3170
	old_data_grads_norm = 4.1215
	sim_grads_norm_tr = 0.1086
-- Starting training on experience 408 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0521
	data_grads_norm = 3.8978
	new_data_grads_norm = 5.9814
	old_data_grads_norm = 4.2942
	sim_grads_norm_tr = 0.1977
-- Starting training on experience 409 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7570
	data_grads_norm = 3.6892
	new_data_grads_norm = 6.0794
	old_data_grads_norm = 4.6345
	sim_grads_norm_tr = -0.0584
-- Starting training on experience 410 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0090
	data_grads_norm = 4.2775
	new_data_grads_norm = 6.2964
	old_data_grads_norm = 4.6075
	sim_grads_norm_tr = 0.2336
-- Starting training on experience 411 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2695
	data_grads_norm = 2.9506
	new_data_grads_norm = 5.8861
	old_data_grads_norm = 2.9378
	sim_grads_norm_tr = 0.0324
-- Starting training on experience 412 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2198
	data_grads_norm = 3.1607
	new_data_grads_norm = 5.7080
	old_data_grads_norm = 2.8737
	sim_grads_norm_tr = -0.0687
-- Starting training on experience 413 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5935
	data_grads_norm = 3.9139
	new_data_grads_norm = 6.9728
	old_data_grads_norm = 4.3530
	sim_grads_norm_tr = 0.1269
-- Starting training on experience 414 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6641
	data_grads_norm = 3.8457
	new_data_grads_norm = 6.1165
	old_data_grads_norm = 4.6363
	sim_grads_norm_tr = 0.1396
-- Starting training on experience 415 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7617
	data_grads_norm = 3.5123
	new_data_grads_norm = 5.8419
	old_data_grads_norm = 4.3010
	sim_grads_norm_tr = 0.0673
-- Starting training on experience 416 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7359
	data_grads_norm = 4.0404
	new_data_grads_norm = 6.7233
	old_data_grads_norm = 4.0067
	sim_grads_norm_tr = 0.1518
-- Starting training on experience 417 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9222
	data_grads_norm = 3.4829
	new_data_grads_norm = 5.5148
	old_data_grads_norm = 4.1859
	sim_grads_norm_tr = 0.0336
-- Starting training on experience 418 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3160
	data_grads_norm = 3.3953
	new_data_grads_norm = 5.9701
	old_data_grads_norm = 3.6502
	sim_grads_norm_tr = -0.1504
-- Starting training on experience 419 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3974
	data_grads_norm = 4.1257
	new_data_grads_norm = 5.8205
	old_data_grads_norm = 5.2503
	sim_grads_norm_tr = -0.0088
-- Starting training on experience 420 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9557
	data_grads_norm = 4.1771
	new_data_grads_norm = 6.9349
	old_data_grads_norm = 4.4144
	sim_grads_norm_tr = 0.0867
-- Starting training on experience 421 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4077
	data_grads_norm = 3.5158
	new_data_grads_norm = 6.3817
	old_data_grads_norm = 5.2222
	sim_grads_norm_tr = 0.0324
-- Starting training on experience 422 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0582
	data_grads_norm = 3.0089
	new_data_grads_norm = 6.8400
	old_data_grads_norm = 3.7777
	sim_grads_norm_tr = 0.0140
-- Starting training on experience 423 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0484
	data_grads_norm = 3.6659
	new_data_grads_norm = 6.8359
	old_data_grads_norm = 2.5176
	sim_grads_norm_tr = 0.0670
-- Starting training on experience 424 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1748
	data_grads_norm = 3.5138
	new_data_grads_norm = 6.2936
	old_data_grads_norm = 4.1878
	sim_grads_norm_tr = -0.0966
-- Starting training on experience 425 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3508
	data_grads_norm = 3.3602
	new_data_grads_norm = 5.6620
	old_data_grads_norm = 3.9182
	sim_grads_norm_tr = 0.0246
-- Starting training on experience 426 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2817
	data_grads_norm = 3.2094
	new_data_grads_norm = 5.3501
	old_data_grads_norm = 3.8127
	sim_grads_norm_tr = -0.1393
-- Starting training on experience 427 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9122
	data_grads_norm = 4.2558
	new_data_grads_norm = 6.2055
	old_data_grads_norm = 4.9539
	sim_grads_norm_tr = -0.0503
-- Starting training on experience 428 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8892
	data_grads_norm = 4.7323
	new_data_grads_norm = 6.5798
	old_data_grads_norm = 5.6648
	sim_grads_norm_tr = -0.1223
-- Starting training on experience 429 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8765
	data_grads_norm = 4.1235
	new_data_grads_norm = 6.6671
	old_data_grads_norm = 4.1527
	sim_grads_norm_tr = 0.0897
-- Starting training on experience 430 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5002
	data_grads_norm = 3.7443
	new_data_grads_norm = 6.1664
	old_data_grads_norm = 3.6331
	sim_grads_norm_tr = -0.0682
-- Starting training on experience 431 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3114
	data_grads_norm = 3.7046
	new_data_grads_norm = 6.2324
	old_data_grads_norm = 4.9667
	sim_grads_norm_tr = -0.1077
-- Starting training on experience 432 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4663
	data_grads_norm = 4.9040
	new_data_grads_norm = 6.5691
	old_data_grads_norm = 5.6357
	sim_grads_norm_tr = 0.0807
-- Starting training on experience 433 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5029
	data_grads_norm = 3.2865
	new_data_grads_norm = 6.5678
	old_data_grads_norm = 3.3632
	sim_grads_norm_tr = -0.0731
-- Starting training on experience 434 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1191
	data_grads_norm = 4.4460
	new_data_grads_norm = 6.4498
	old_data_grads_norm = 4.7453
	sim_grads_norm_tr = 0.1400
-- Starting training on experience 435 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4654
	data_grads_norm = 3.2702
	new_data_grads_norm = 6.6515
	old_data_grads_norm = 3.0434
	sim_grads_norm_tr = 0.2146
-- Starting training on experience 436 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1512
	data_grads_norm = 2.9717
	new_data_grads_norm = 5.3254
	old_data_grads_norm = 5.2708
	sim_grads_norm_tr = -0.1032
-- Starting training on experience 437 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0033
	data_grads_norm = 3.8977
	new_data_grads_norm = 6.0146
	old_data_grads_norm = 4.8351
	sim_grads_norm_tr = 0.0508
-- Starting training on experience 438 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6167
	data_grads_norm = 4.0437
	new_data_grads_norm = 6.4523
	old_data_grads_norm = 3.5196
	sim_grads_norm_tr = 0.0813
-- Starting training on experience 439 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4431
	data_grads_norm = 3.3697
	new_data_grads_norm = 5.7233
	old_data_grads_norm = 4.1110
	sim_grads_norm_tr = -0.1814
-- Starting training on experience 440 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8060
	data_grads_norm = 4.3223
	new_data_grads_norm = 6.5359
	old_data_grads_norm = 5.0983
	sim_grads_norm_tr = -0.0079
-- Starting training on experience 441 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4353
	data_grads_norm = 4.0295
	new_data_grads_norm = 6.5289
	old_data_grads_norm = 5.0926
	sim_grads_norm_tr = -0.0574
-- Starting training on experience 442 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8027
	data_grads_norm = 3.8720
	new_data_grads_norm = 7.2459
	old_data_grads_norm = 4.0506
	sim_grads_norm_tr = -0.1505
-- Starting training on experience 443 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9845
	data_grads_norm = 4.4789
	new_data_grads_norm = 6.8258
	old_data_grads_norm = 5.2482
	sim_grads_norm_tr = 0.0920
-- Starting training on experience 444 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0862
	data_grads_norm = 4.4454
	new_data_grads_norm = 6.2798
	old_data_grads_norm = 5.1864
	sim_grads_norm_tr = 0.2267
-- Starting training on experience 445 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5718
	data_grads_norm = 4.1375
	new_data_grads_norm = 6.4230
	old_data_grads_norm = 5.3229
	sim_grads_norm_tr = 0.1051
-- Starting training on experience 446 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7610
	data_grads_norm = 3.8555
	new_data_grads_norm = 7.0616
	old_data_grads_norm = 4.1279
	sim_grads_norm_tr = -0.0078
-- Starting training on experience 447 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9526
	data_grads_norm = 4.1095
	new_data_grads_norm = 6.2014
	old_data_grads_norm = 4.2591
	sim_grads_norm_tr = 0.1604
-- Starting training on experience 448 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8042
	data_grads_norm = 3.9278
	new_data_grads_norm = 5.9952
	old_data_grads_norm = 5.5589
	sim_grads_norm_tr = -0.0568
-- Starting training on experience 449 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8632
	data_grads_norm = 3.0971
	new_data_grads_norm = 6.0504
	old_data_grads_norm = 3.5101
	sim_grads_norm_tr = -0.1375
-- Starting training on experience 450 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0715
	data_grads_norm = 4.3641
	new_data_grads_norm = 6.1796
	old_data_grads_norm = 4.9742
	sim_grads_norm_tr = 0.1135
-- Starting training on experience 451 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2094
	data_grads_norm = 4.1977
	new_data_grads_norm = 6.9456
	old_data_grads_norm = 4.6540
	sim_grads_norm_tr = 0.0736
-- Starting training on experience 452 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7148
	data_grads_norm = 3.0052
	new_data_grads_norm = 5.5746
	old_data_grads_norm = 3.6211
	sim_grads_norm_tr = -0.0487
-- Starting training on experience 453 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0921
	data_grads_norm = 4.0602
	new_data_grads_norm = 6.6050
	old_data_grads_norm = 4.5021
	sim_grads_norm_tr = 0.0678
-- Starting training on experience 454 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8423
	data_grads_norm = 3.5345
	new_data_grads_norm = 6.3783
	old_data_grads_norm = 3.1866
	sim_grads_norm_tr = -0.0437
-- Starting training on experience 455 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9118
	data_grads_norm = 3.9306
	new_data_grads_norm = 6.0657
	old_data_grads_norm = 4.2210
	sim_grads_norm_tr = -0.0049
-- Starting training on experience 456 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7486
	data_grads_norm = 3.2726
	new_data_grads_norm = 5.5237
	old_data_grads_norm = 3.3883
	sim_grads_norm_tr = 0.0494
-- Starting training on experience 457 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7310
	data_grads_norm = 3.4041
	new_data_grads_norm = 5.5667
	old_data_grads_norm = 4.1901
	sim_grads_norm_tr = -0.0368
-- Starting training on experience 458 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9050
	data_grads_norm = 3.7452
	new_data_grads_norm = 5.7905
	old_data_grads_norm = 4.1147
	sim_grads_norm_tr = 0.2352
-- Starting training on experience 459 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1674
	data_grads_norm = 4.3337
	new_data_grads_norm = 6.1128
	old_data_grads_norm = 5.3237
	sim_grads_norm_tr = -0.1004
-- Starting training on experience 460 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9498
	data_grads_norm = 3.7898
	new_data_grads_norm = 6.0433
	old_data_grads_norm = 3.8723
	sim_grads_norm_tr = 0.0871
-- Starting training on experience 461 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7478
	data_grads_norm = 3.7158
	new_data_grads_norm = 5.2826
	old_data_grads_norm = 4.4977
	sim_grads_norm_tr = 0.0509
-- Starting training on experience 462 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6833
	data_grads_norm = 3.6754
	new_data_grads_norm = 6.1041
	old_data_grads_norm = 4.5211
	sim_grads_norm_tr = -0.0266
-- Starting training on experience 463 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5675
	data_grads_norm = 4.0799
	new_data_grads_norm = 6.1701
	old_data_grads_norm = 4.9739
	sim_grads_norm_tr = 0.0440
-- Starting training on experience 464 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7502
	data_grads_norm = 3.7947
	new_data_grads_norm = 6.2350
	old_data_grads_norm = 4.6797
	sim_grads_norm_tr = 0.0683
-- Starting training on experience 465 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7592
	data_grads_norm = 3.8715
	new_data_grads_norm = 5.9444
	old_data_grads_norm = 4.3361
	sim_grads_norm_tr = 0.0573
-- Starting training on experience 466 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7392
	data_grads_norm = 3.6687
	new_data_grads_norm = 5.5905
	old_data_grads_norm = 4.5301
	sim_grads_norm_tr = -0.0343
-- Starting training on experience 467 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6424
	data_grads_norm = 3.3493
	new_data_grads_norm = 6.1110
	old_data_grads_norm = 3.9900
	sim_grads_norm_tr = 0.0021
-- Starting training on experience 468 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1036
	data_grads_norm = 4.1298
	new_data_grads_norm = 5.8652
	old_data_grads_norm = 4.6603
	sim_grads_norm_tr = 0.1074
-- Starting training on experience 469 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9871
	data_grads_norm = 4.1110
	new_data_grads_norm = 5.8905
	old_data_grads_norm = 4.7349
	sim_grads_norm_tr = -0.0491
-- Starting training on experience 470 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8224
	data_grads_norm = 3.5195
	new_data_grads_norm = 5.5945
	old_data_grads_norm = 4.6714
	sim_grads_norm_tr = 0.0979
-- Starting training on experience 471 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4464
	data_grads_norm = 3.2608
	new_data_grads_norm = 5.6821
	old_data_grads_norm = 4.1373
	sim_grads_norm_tr = -0.0940
-- Starting training on experience 472 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5613
	data_grads_norm = 2.8385
	new_data_grads_norm = 5.9112
	old_data_grads_norm = 3.3675
	sim_grads_norm_tr = -0.1059
-- Starting training on experience 473 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8978
	data_grads_norm = 3.6930
	new_data_grads_norm = 5.0512
	old_data_grads_norm = 4.3182
	sim_grads_norm_tr = -0.0791
-- Starting training on experience 474 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0527
	data_grads_norm = 4.2536
	new_data_grads_norm = 6.8346
	old_data_grads_norm = 4.3966
	sim_grads_norm_tr = 0.1411
-- Starting training on experience 475 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8439
	data_grads_norm = 3.5068
	new_data_grads_norm = 5.5483
	old_data_grads_norm = 3.0700
	sim_grads_norm_tr = 0.1099
-- Starting training on experience 476 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5245
	data_grads_norm = 3.1288
	new_data_grads_norm = 5.8560
	old_data_grads_norm = 3.3021
	sim_grads_norm_tr = 0.0525
-- Starting training on experience 477 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7683
	data_grads_norm = 3.7878
	new_data_grads_norm = 6.1598
	old_data_grads_norm = 4.1692
	sim_grads_norm_tr = 0.1985
-- Starting training on experience 478 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7797
	data_grads_norm = 3.3908
	new_data_grads_norm = 5.5980
	old_data_grads_norm = 4.3139
	sim_grads_norm_tr = -0.0425
-- Starting training on experience 479 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0584
	data_grads_norm = 3.9075
	new_data_grads_norm = 5.5117
	old_data_grads_norm = 4.5051
	sim_grads_norm_tr = 0.1148
-- Starting training on experience 480 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6194
	data_grads_norm = 3.3219
	new_data_grads_norm = 5.9533
	old_data_grads_norm = 4.1949
	sim_grads_norm_tr = 0.2013
-- Starting training on experience 481 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1776
	data_grads_norm = 4.0059
	new_data_grads_norm = 5.9305
	old_data_grads_norm = 4.9460
	sim_grads_norm_tr = 0.0242
-- Starting training on experience 482 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6444
	data_grads_norm = 3.5128
	new_data_grads_norm = 5.9698
	old_data_grads_norm = 5.4214
	sim_grads_norm_tr = -0.0913
-- Starting training on experience 483 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3990
	data_grads_norm = 3.5034
	new_data_grads_norm = 5.5544
	old_data_grads_norm = 5.4407
	sim_grads_norm_tr = 0.1825
-- Starting training on experience 484 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1976
	data_grads_norm = 4.4284
	new_data_grads_norm = 6.2545
	old_data_grads_norm = 4.9635
	sim_grads_norm_tr = 0.2272
-- Starting training on experience 485 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6233
	data_grads_norm = 3.4617
	new_data_grads_norm = 5.1180
	old_data_grads_norm = 5.5679
	sim_grads_norm_tr = -0.1171
-- Starting training on experience 486 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5501
	data_grads_norm = 3.4285
	new_data_grads_norm = 5.3612
	old_data_grads_norm = 4.2822
	sim_grads_norm_tr = 0.0377
-- Starting training on experience 487 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7363
	data_grads_norm = 4.4657
	new_data_grads_norm = 6.9969
	old_data_grads_norm = 4.8304
	sim_grads_norm_tr = 0.0695
-- Starting training on experience 488 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7774
	data_grads_norm = 3.9024
	new_data_grads_norm = 5.3889
	old_data_grads_norm = 4.6438
	sim_grads_norm_tr = 0.2061
-- Starting training on experience 489 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5565
	data_grads_norm = 3.4801
	new_data_grads_norm = 6.1643
	old_data_grads_norm = 4.4557
	sim_grads_norm_tr = -0.1519
-- Starting training on experience 490 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2800
	data_grads_norm = 2.8247
	new_data_grads_norm = 5.0929
	old_data_grads_norm = 3.3965
	sim_grads_norm_tr = -0.0105
-- Starting training on experience 491 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4219
	data_grads_norm = 3.2784
	new_data_grads_norm = 5.1400
	old_data_grads_norm = 4.1958
	sim_grads_norm_tr = 0.0372
-- Starting training on experience 492 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5143
	data_grads_norm = 3.2132
	new_data_grads_norm = 5.3788
	old_data_grads_norm = 3.8235
	sim_grads_norm_tr = 0.1313
-- Starting training on experience 493 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4060
	data_grads_norm = 3.1642
	new_data_grads_norm = 5.4908
	old_data_grads_norm = 5.0494
	sim_grads_norm_tr = -0.0850
-- Starting training on experience 494 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4605
	data_grads_norm = 3.4253
	new_data_grads_norm = 5.4797
	old_data_grads_norm = 2.8958
	sim_grads_norm_tr = -0.0014
-- Starting training on experience 495 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3523
	data_grads_norm = 3.0407
	new_data_grads_norm = 5.7576
	old_data_grads_norm = 3.5319
	sim_grads_norm_tr = -0.0693
-- Starting training on experience 496 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9568
	data_grads_norm = 3.9644
	new_data_grads_norm = 6.2272
	old_data_grads_norm = 4.2112
	sim_grads_norm_tr = 0.0264
-- Starting training on experience 497 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2609
	data_grads_norm = 2.5450
	new_data_grads_norm = 5.7466
	old_data_grads_norm = 2.4951
	sim_grads_norm_tr = -0.0583
-- Starting training on experience 498 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9547
	data_grads_norm = 4.1004
	new_data_grads_norm = 6.3212
	old_data_grads_norm = 5.1696
	sim_grads_norm_tr = -0.0407
-- Starting training on experience 499 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3878
	data_grads_norm = 3.5607
	new_data_grads_norm = 6.0381
	old_data_grads_norm = 4.7814
	sim_grads_norm_tr = 0.0098
-- Starting training on experience 500 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5324
	data_grads_norm = 3.2580
	new_data_grads_norm = 5.5418
	old_data_grads_norm = 3.8352
	sim_grads_norm_tr = 0.0277
-- Starting training on experience 501 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9193
	data_grads_norm = 4.0712
	new_data_grads_norm = 5.8265
	old_data_grads_norm = 5.5598
	sim_grads_norm_tr = -0.0077
-- Starting training on experience 502 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8907
	data_grads_norm = 4.1919
	new_data_grads_norm = 6.4784
	old_data_grads_norm = 3.5550
	sim_grads_norm_tr = -0.0319
-- Starting training on experience 503 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1535
	data_grads_norm = 4.3066
	new_data_grads_norm = 6.6358
	old_data_grads_norm = 4.6129
	sim_grads_norm_tr = 0.2578
-- Starting training on experience 504 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9718
	data_grads_norm = 4.5484
	new_data_grads_norm = 6.5952
	old_data_grads_norm = 4.3608
	sim_grads_norm_tr = 0.0797
-- Starting training on experience 505 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6683
	data_grads_norm = 4.1862
	new_data_grads_norm = 5.7008
	old_data_grads_norm = 5.1263
	sim_grads_norm_tr = 0.0808
-- Starting training on experience 506 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4238
	data_grads_norm = 3.5508
	new_data_grads_norm = 5.6619
	old_data_grads_norm = 4.2334
	sim_grads_norm_tr = 0.0412
-- Starting training on experience 507 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0850
	data_grads_norm = 4.3172
	new_data_grads_norm = 5.7778
	old_data_grads_norm = 4.2615
	sim_grads_norm_tr = 0.4852
-- Starting training on experience 508 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4898
	data_grads_norm = 3.1374
	new_data_grads_norm = 4.5770
	old_data_grads_norm = 4.5736
	sim_grads_norm_tr = 0.0539
-- Starting training on experience 509 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2492
	data_grads_norm = 2.8702
	new_data_grads_norm = 5.1331
	old_data_grads_norm = 3.9847
	sim_grads_norm_tr = -0.0099
-- Starting training on experience 510 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7525
	data_grads_norm = 3.1819
	new_data_grads_norm = 4.7467
	old_data_grads_norm = 4.8220
	sim_grads_norm_tr = 0.0022
-- Starting training on experience 511 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3732
	data_grads_norm = 2.7624
	new_data_grads_norm = 5.8697
	old_data_grads_norm = 3.6588
	sim_grads_norm_tr = -0.1400
-- Starting training on experience 512 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5991
	data_grads_norm = 3.5972
	new_data_grads_norm = 5.7661
	old_data_grads_norm = 5.4376
	sim_grads_norm_tr = -0.1214
-- Starting training on experience 513 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7833
	data_grads_norm = 3.1480
	new_data_grads_norm = 5.4757
	old_data_grads_norm = 3.1319
	sim_grads_norm_tr = 0.1527
-- Starting training on experience 514 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9424
	data_grads_norm = 2.7877
	new_data_grads_norm = 5.5064
	old_data_grads_norm = 3.8479
	sim_grads_norm_tr = -0.2637
-- Starting training on experience 515 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7864
	data_grads_norm = 3.9130
	new_data_grads_norm = 5.9102
	old_data_grads_norm = 3.8137
	sim_grads_norm_tr = 0.0231
-- Starting training on experience 516 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4567
	data_grads_norm = 3.2462
	new_data_grads_norm = 5.5077
	old_data_grads_norm = 4.7028
	sim_grads_norm_tr = -0.0537
-- Starting training on experience 517 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0469
	data_grads_norm = 3.7278
	new_data_grads_norm = 5.7875
	old_data_grads_norm = 4.5611
	sim_grads_norm_tr = -0.0775
-- Starting training on experience 518 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8917
	data_grads_norm = 4.1657
	new_data_grads_norm = 6.8245
	old_data_grads_norm = 4.8534
	sim_grads_norm_tr = 0.0834
-- Starting training on experience 519 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9032
	data_grads_norm = 4.0347
	new_data_grads_norm = 5.5673
	old_data_grads_norm = 5.1055
	sim_grads_norm_tr = 0.0614
-- Starting training on experience 520 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1463
	data_grads_norm = 2.2495
	new_data_grads_norm = 5.2309
	old_data_grads_norm = 2.9235
	sim_grads_norm_tr = -0.2225
-- Starting training on experience 521 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8343
	data_grads_norm = 4.2166
	new_data_grads_norm = 6.7948
	old_data_grads_norm = 4.2253
	sim_grads_norm_tr = 0.0162
-- Starting training on experience 522 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2092
	data_grads_norm = 4.3679
	new_data_grads_norm = 6.2839
	old_data_grads_norm = 5.0114
	sim_grads_norm_tr = 0.0420
-- Starting training on experience 523 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5376
	data_grads_norm = 3.9810
	new_data_grads_norm = 6.6267
	old_data_grads_norm = 2.7991
	sim_grads_norm_tr = 0.2725
-- Starting training on experience 524 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2658
	data_grads_norm = 3.5468
	new_data_grads_norm = 5.4730
	old_data_grads_norm = 3.8464
	sim_grads_norm_tr = -0.0390
-- Starting training on experience 525 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5566
	data_grads_norm = 3.7539
	new_data_grads_norm = 6.4235
	old_data_grads_norm = 4.9817
	sim_grads_norm_tr = -0.0486
-- Starting training on experience 526 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3435
	data_grads_norm = 3.1773
	new_data_grads_norm = 5.7349
	old_data_grads_norm = 4.4878
	sim_grads_norm_tr = -0.1957
-- Starting training on experience 527 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8047
	data_grads_norm = 3.9936
	new_data_grads_norm = 6.6042
	old_data_grads_norm = 4.3622
	sim_grads_norm_tr = 0.0330
-- Starting training on experience 528 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7128
	data_grads_norm = 3.8871
	new_data_grads_norm = 6.2151
	old_data_grads_norm = 5.0295
	sim_grads_norm_tr = 0.0807
-- Starting training on experience 529 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0026
	data_grads_norm = 4.2114
	new_data_grads_norm = 6.6811
	old_data_grads_norm = 4.8293
	sim_grads_norm_tr = 0.1083
-- Starting training on experience 530 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3699
	data_grads_norm = 3.1163
	new_data_grads_norm = 6.2465
	old_data_grads_norm = 3.5571
	sim_grads_norm_tr = -0.0664
-- Starting training on experience 531 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2375
	data_grads_norm = 4.1835
	new_data_grads_norm = 6.4918
	old_data_grads_norm = 4.3721
	sim_grads_norm_tr = -0.0202
-- Starting training on experience 532 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2189
	data_grads_norm = 4.3931
	new_data_grads_norm = 6.0290
	old_data_grads_norm = 5.6502
	sim_grads_norm_tr = -0.0146
-- Starting training on experience 533 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4724
	data_grads_norm = 3.2460
	new_data_grads_norm = 6.3844
	old_data_grads_norm = 4.9484
	sim_grads_norm_tr = -0.0969
-- Starting training on experience 534 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4891
	data_grads_norm = 3.5884
	new_data_grads_norm = 6.8734
	old_data_grads_norm = 3.7761
	sim_grads_norm_tr = -0.0126
-- Starting training on experience 535 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0587
	data_grads_norm = 3.7950
	new_data_grads_norm = 6.0680
	old_data_grads_norm = 3.4284
	sim_grads_norm_tr = 0.1422
-- Starting training on experience 536 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6930
	data_grads_norm = 3.4568
	new_data_grads_norm = 6.5799
	old_data_grads_norm = 3.2158
	sim_grads_norm_tr = 0.2881
-- Starting training on experience 537 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7325
	data_grads_norm = 3.8187
	new_data_grads_norm = 5.9829
	old_data_grads_norm = 4.1071
	sim_grads_norm_tr = 0.0586
-- Starting training on experience 538 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7290
	data_grads_norm = 3.3465
	new_data_grads_norm = 5.9541
	old_data_grads_norm = 3.6108
	sim_grads_norm_tr = -0.0593
-- Starting training on experience 539 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2848
	data_grads_norm = 3.1491
	new_data_grads_norm = 5.9496
	old_data_grads_norm = 4.1529
	sim_grads_norm_tr = 0.0021
-- Starting training on experience 540 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7288
	data_grads_norm = 3.7689
	new_data_grads_norm = 6.5098
	old_data_grads_norm = 4.2513
	sim_grads_norm_tr = 0.0260
-- Starting training on experience 541 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3906
	data_grads_norm = 3.6611
	new_data_grads_norm = 5.8462
	old_data_grads_norm = 4.7924
	sim_grads_norm_tr = 0.1922
-- Starting training on experience 542 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6303
	data_grads_norm = 3.7477
	new_data_grads_norm = 5.9617
	old_data_grads_norm = 4.1636
	sim_grads_norm_tr = 0.0555
-- Starting training on experience 543 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8237
	data_grads_norm = 4.0932
	new_data_grads_norm = 6.1784
	old_data_grads_norm = 5.7419
	sim_grads_norm_tr = -0.1611
-- Starting training on experience 544 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0011
	data_grads_norm = 3.8332
	new_data_grads_norm = 6.3111
	old_data_grads_norm = 4.5042
	sim_grads_norm_tr = 0.1088
-- Starting training on experience 545 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4369
	data_grads_norm = 3.5938
	new_data_grads_norm = 6.3127
	old_data_grads_norm = 5.0313
	sim_grads_norm_tr = 0.0955
-- Starting training on experience 546 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9203
	data_grads_norm = 3.5517
	new_data_grads_norm = 6.0890
	old_data_grads_norm = 3.4952
	sim_grads_norm_tr = 0.0895
-- Starting training on experience 547 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3126
	data_grads_norm = 3.0745
	new_data_grads_norm = 6.9356
	old_data_grads_norm = 3.4293
	sim_grads_norm_tr = -0.1372
-- Starting training on experience 548 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9541
	data_grads_norm = 4.5643
	new_data_grads_norm = 5.9118
	old_data_grads_norm = 5.8811
	sim_grads_norm_tr = 0.2065
-- Starting training on experience 549 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6981
	data_grads_norm = 4.0043
	new_data_grads_norm = 6.2478
	old_data_grads_norm = 4.4747
	sim_grads_norm_tr = 0.1189
-- Starting training on experience 550 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6890
	data_grads_norm = 3.9228
	new_data_grads_norm = 5.9580
	old_data_grads_norm = 4.2797
	sim_grads_norm_tr = 0.0972
-- Starting training on experience 551 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1474
	data_grads_norm = 4.2683
	new_data_grads_norm = 6.1296
	old_data_grads_norm = 5.0330
	sim_grads_norm_tr = 0.1087
-- Starting training on experience 552 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0877
	data_grads_norm = 2.7353
	new_data_grads_norm = 5.7129
	old_data_grads_norm = 3.9698
	sim_grads_norm_tr = -0.0975
-- Starting training on experience 553 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0455
	data_grads_norm = 3.3959
	new_data_grads_norm = 5.2145
	old_data_grads_norm = 4.2300
	sim_grads_norm_tr = -0.0662
-- Starting training on experience 554 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4776
	data_grads_norm = 3.8121
	new_data_grads_norm = 6.0325
	old_data_grads_norm = 3.8226
	sim_grads_norm_tr = 0.0631
-- Starting training on experience 555 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7448
	data_grads_norm = 3.3388
	new_data_grads_norm = 5.4183
	old_data_grads_norm = 4.4464
	sim_grads_norm_tr = -0.0125
-- Starting training on experience 556 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0760
	data_grads_norm = 3.9525
	new_data_grads_norm = 6.3867
	old_data_grads_norm = 4.7635
	sim_grads_norm_tr = -0.0669
-- Starting training on experience 557 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7010
	data_grads_norm = 3.2932
	new_data_grads_norm = 5.7369
	old_data_grads_norm = 5.0864
	sim_grads_norm_tr = -0.1239
-- Starting training on experience 558 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3474
	data_grads_norm = 4.2935
	new_data_grads_norm = 6.6130
	old_data_grads_norm = 5.2489
	sim_grads_norm_tr = 0.0536
-- Starting training on experience 559 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6092
	data_grads_norm = 3.2037
	new_data_grads_norm = 6.0256
	old_data_grads_norm = 2.7524
	sim_grads_norm_tr = 0.0124
-- Starting training on experience 560 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7120
	data_grads_norm = 3.4405
	new_data_grads_norm = 5.5227
	old_data_grads_norm = 3.6674
	sim_grads_norm_tr = 0.2641
-- Starting training on experience 561 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6493
	data_grads_norm = 2.8706
	new_data_grads_norm = 5.2674
	old_data_grads_norm = 3.1250
	sim_grads_norm_tr = -0.0750
-- Starting training on experience 562 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5226
	data_grads_norm = 3.3871
	new_data_grads_norm = 5.1829
	old_data_grads_norm = 5.5021
	sim_grads_norm_tr = 0.0389
-- Starting training on experience 563 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7015
	data_grads_norm = 3.4577
	new_data_grads_norm = 5.5049
	old_data_grads_norm = 3.6404
	sim_grads_norm_tr = 0.1377
-- Starting training on experience 564 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5340
	data_grads_norm = 2.9245
	new_data_grads_norm = 5.4922
	old_data_grads_norm = 3.4477
	sim_grads_norm_tr = 0.0266
-- Starting training on experience 565 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7125
	data_grads_norm = 3.2146
	new_data_grads_norm = 6.0245
	old_data_grads_norm = 4.2042
	sim_grads_norm_tr = 0.0721
-- Starting training on experience 566 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2539
	data_grads_norm = 2.4565
	new_data_grads_norm = 4.2092
	old_data_grads_norm = 3.6390
	sim_grads_norm_tr = -0.1356
-- Starting training on experience 567 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4648
	data_grads_norm = 3.1717
	new_data_grads_norm = 5.8666
	old_data_grads_norm = 2.8685
	sim_grads_norm_tr = 0.1011
-- Starting training on experience 568 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1274
	data_grads_norm = 2.3650
	new_data_grads_norm = 5.2032
	old_data_grads_norm = 1.9507
	sim_grads_norm_tr = -0.1440
-- Starting training on experience 569 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6821
	data_grads_norm = 3.2769
	new_data_grads_norm = 5.0685
	old_data_grads_norm = 4.3902
	sim_grads_norm_tr = -0.2132
-- Starting training on experience 570 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9994
	data_grads_norm = 3.3026
	new_data_grads_norm = 5.9427
	old_data_grads_norm = 3.6169
	sim_grads_norm_tr = 0.1887
-- Starting training on experience 571 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9424
	data_grads_norm = 3.0634
	new_data_grads_norm = 6.1917
	old_data_grads_norm = 3.0845
	sim_grads_norm_tr = -0.0807
-- Starting training on experience 572 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1942
	data_grads_norm = 4.2596
	new_data_grads_norm = 5.7203
	old_data_grads_norm = 4.6063
	sim_grads_norm_tr = 0.1551
-- Starting training on experience 573 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5628
	data_grads_norm = 3.3174
	new_data_grads_norm = 6.0145
	old_data_grads_norm = 3.2450
	sim_grads_norm_tr = -0.0647
-- Starting training on experience 574 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4072
	data_grads_norm = 2.8314
	new_data_grads_norm = 6.1087
	old_data_grads_norm = 2.0565
	sim_grads_norm_tr = 0.0372
-- Starting training on experience 575 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9949
	data_grads_norm = 3.4010
	new_data_grads_norm = 6.0185
	old_data_grads_norm = 3.4626
	sim_grads_norm_tr = -0.0308
-- Starting training on experience 576 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0952
	data_grads_norm = 4.0649
	new_data_grads_norm = 6.4949
	old_data_grads_norm = 4.8600
	sim_grads_norm_tr = -0.0125
-- Starting training on experience 577 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8579
	data_grads_norm = 3.8114
	new_data_grads_norm = 6.0001
	old_data_grads_norm = 3.9251
	sim_grads_norm_tr = -0.0366
-- Starting training on experience 578 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0311
	data_grads_norm = 3.6067
	new_data_grads_norm = 6.7101
	old_data_grads_norm = 3.6872
	sim_grads_norm_tr = 0.0431
-- Starting training on experience 579 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9037
	data_grads_norm = 4.3803
	new_data_grads_norm = 6.3150
	old_data_grads_norm = 5.5247
	sim_grads_norm_tr = 0.1382
-- Starting training on experience 580 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0543
	data_grads_norm = 4.3166
	new_data_grads_norm = 6.9990
	old_data_grads_norm = 3.7484
	sim_grads_norm_tr = 0.2292
-- Starting training on experience 581 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0030
	data_grads_norm = 3.6987
	new_data_grads_norm = 5.7631
	old_data_grads_norm = 3.7397
	sim_grads_norm_tr = 0.1510
-- Starting training on experience 582 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8990
	data_grads_norm = 3.6804
	new_data_grads_norm = 6.3233
	old_data_grads_norm = 3.8201
	sim_grads_norm_tr = 0.0785
-- Starting training on experience 583 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7283
	data_grads_norm = 3.3985
	new_data_grads_norm = 6.0064
	old_data_grads_norm = 4.2950
	sim_grads_norm_tr = -0.0450
-- Starting training on experience 584 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4868
	data_grads_norm = 3.3157
	new_data_grads_norm = 6.0003
	old_data_grads_norm = 3.6256
	sim_grads_norm_tr = -0.0568
-- Starting training on experience 585 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4939
	data_grads_norm = 3.3251
	new_data_grads_norm = 5.4344
	old_data_grads_norm = 3.5270
	sim_grads_norm_tr = 0.1288
-- Starting training on experience 586 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9004
	data_grads_norm = 4.1349
	new_data_grads_norm = 5.9865
	old_data_grads_norm = 3.9546
	sim_grads_norm_tr = 0.2623
-- Starting training on experience 587 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3541
	data_grads_norm = 3.0047
	new_data_grads_norm = 5.6472
	old_data_grads_norm = 3.5691
	sim_grads_norm_tr = -0.1388
-- Starting training on experience 588 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7187
	data_grads_norm = 3.8504
	new_data_grads_norm = 6.2404
	old_data_grads_norm = 4.9341
	sim_grads_norm_tr = 0.1374
-- Starting training on experience 589 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4540
	data_grads_norm = 3.2501
	new_data_grads_norm = 5.5177
	old_data_grads_norm = 3.6087
	sim_grads_norm_tr = 0.0965
-- Starting training on experience 590 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3479
	data_grads_norm = 3.1760
	new_data_grads_norm = 5.9443
	old_data_grads_norm = 4.0649
	sim_grads_norm_tr = 0.0875
-- Starting training on experience 591 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6995
	data_grads_norm = 3.7913
	new_data_grads_norm = 6.1558
	old_data_grads_norm = 5.4868
	sim_grads_norm_tr = -0.0697
-- Starting training on experience 592 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9147
	data_grads_norm = 3.9794
	new_data_grads_norm = 6.3557
	old_data_grads_norm = 4.6896
	sim_grads_norm_tr = 0.1339
-- Starting training on experience 593 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7101
	data_grads_norm = 3.7220
	new_data_grads_norm = 5.9966
	old_data_grads_norm = 3.3852
	sim_grads_norm_tr = 0.2790
-- Starting training on experience 594 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4076
	data_grads_norm = 3.3533
	new_data_grads_norm = 4.9326
	old_data_grads_norm = 4.1586
	sim_grads_norm_tr = -0.0452
-- Starting training on experience 595 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4089
	data_grads_norm = 3.5993
	new_data_grads_norm = 5.9961
	old_data_grads_norm = 4.6640
	sim_grads_norm_tr = -0.0715
-- Starting training on experience 596 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7214
	data_grads_norm = 4.4880
	new_data_grads_norm = 6.1167
	old_data_grads_norm = 6.5752
	sim_grads_norm_tr = 0.0440
-- Starting training on experience 597 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4775
	data_grads_norm = 3.0026
	new_data_grads_norm = 5.4171
	old_data_grads_norm = 3.8326
	sim_grads_norm_tr = -0.0544
-- Starting training on experience 598 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7916
	data_grads_norm = 4.3683
	new_data_grads_norm = 6.4092
	old_data_grads_norm = 4.7545
	sim_grads_norm_tr = 0.1413
-- Starting training on experience 599 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2387
	data_grads_norm = 2.8336
	new_data_grads_norm = 5.7496
	old_data_grads_norm = 3.0258
	sim_grads_norm_tr = 0.0634
-- Starting training on experience 600 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1681
	data_grads_norm = 2.8208
	new_data_grads_norm = 6.3120
	old_data_grads_norm = 3.6495
	sim_grads_norm_tr = -0.1219
-- Starting training on experience 601 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7759
	data_grads_norm = 3.9262
	new_data_grads_norm = 6.1537
	old_data_grads_norm = 4.5755
	sim_grads_norm_tr = 0.1604
-- Starting training on experience 602 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4807
	data_grads_norm = 3.4592
	new_data_grads_norm = 6.1464
	old_data_grads_norm = 4.2043
	sim_grads_norm_tr = -0.0698
-- Starting training on experience 603 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5113
	data_grads_norm = 3.1144
	new_data_grads_norm = 5.8336
	old_data_grads_norm = 3.5063
	sim_grads_norm_tr = 0.0311
-- Starting training on experience 604 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3187
	data_grads_norm = 3.1861
	new_data_grads_norm = 6.2081
	old_data_grads_norm = 4.0511
	sim_grads_norm_tr = -0.1141
-- Starting training on experience 605 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8089
	data_grads_norm = 4.0701
	new_data_grads_norm = 6.5919
	old_data_grads_norm = 4.1605
	sim_grads_norm_tr = 0.0826
-- Starting training on experience 606 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7993
	data_grads_norm = 3.7348
	new_data_grads_norm = 7.0979
	old_data_grads_norm = 2.8929
	sim_grads_norm_tr = 0.0464
-- Starting training on experience 607 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5528
	data_grads_norm = 3.5403
	new_data_grads_norm = 6.3503
	old_data_grads_norm = 3.5844
	sim_grads_norm_tr = 0.0421
-- Starting training on experience 608 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4389
	data_grads_norm = 3.2940
	new_data_grads_norm = 6.2867
	old_data_grads_norm = 4.8310
	sim_grads_norm_tr = 0.0392
-- Starting training on experience 609 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5582
	data_grads_norm = 3.4443
	new_data_grads_norm = 6.9086
	old_data_grads_norm = 3.3948
	sim_grads_norm_tr = 0.0123
-- Starting training on experience 610 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7362
	data_grads_norm = 4.1573
	new_data_grads_norm = 5.8899
	old_data_grads_norm = 5.4461
	sim_grads_norm_tr = -0.0218
-- Starting training on experience 611 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7579
	data_grads_norm = 3.6058
	new_data_grads_norm = 6.0234
	old_data_grads_norm = 3.5743
	sim_grads_norm_tr = 0.1282
-- Starting training on experience 612 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4679
	data_grads_norm = 3.5322
	new_data_grads_norm = 7.1978
	old_data_grads_norm = 3.8545
	sim_grads_norm_tr = 0.0291
-- Starting training on experience 613 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6856
	data_grads_norm = 3.8887
	new_data_grads_norm = 6.5570
	old_data_grads_norm = 2.8040
	sim_grads_norm_tr = 0.1108
-- Starting training on experience 614 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8779
	data_grads_norm = 4.3417
	new_data_grads_norm = 6.5152
	old_data_grads_norm = 6.2170
	sim_grads_norm_tr = 0.0249
-- Starting training on experience 615 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4068
	data_grads_norm = 4.2904
	new_data_grads_norm = 6.1588
	old_data_grads_norm = 5.5917
	sim_grads_norm_tr = 0.0286
-- Starting training on experience 616 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7454
	data_grads_norm = 4.4254
	new_data_grads_norm = 6.8883
	old_data_grads_norm = 4.6391
	sim_grads_norm_tr = -0.0230
-- Starting training on experience 617 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2378
	data_grads_norm = 3.2075
	new_data_grads_norm = 5.9732
	old_data_grads_norm = 3.8766
	sim_grads_norm_tr = 0.0440
-- Starting training on experience 618 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5429
	data_grads_norm = 3.7933
	new_data_grads_norm = 6.6893
	old_data_grads_norm = 3.1126
	sim_grads_norm_tr = 0.0711
-- Starting training on experience 619 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4145
	data_grads_norm = 3.8731
	new_data_grads_norm = 6.1212
	old_data_grads_norm = 4.6130
	sim_grads_norm_tr = 0.1370
-- Starting training on experience 620 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7199
	data_grads_norm = 4.2619
	new_data_grads_norm = 5.8635
	old_data_grads_norm = 5.4524
	sim_grads_norm_tr = 0.0801
-- Starting training on experience 621 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6079
	data_grads_norm = 3.2814
	new_data_grads_norm = 6.2254
	old_data_grads_norm = 4.7054
	sim_grads_norm_tr = -0.2381
-- Starting training on experience 622 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5846
	data_grads_norm = 4.4691
	new_data_grads_norm = 6.2840
	old_data_grads_norm = 5.8178
	sim_grads_norm_tr = 0.0622
-- Starting training on experience 623 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6183
	data_grads_norm = 3.6677
	new_data_grads_norm = 6.5689
	old_data_grads_norm = 4.3655
	sim_grads_norm_tr = 0.0455
-- Starting training on experience 624 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0513
	data_grads_norm = 3.9948
	new_data_grads_norm = 5.7042
	old_data_grads_norm = 3.8236
	sim_grads_norm_tr = 0.0858
-- Starting training on experience 625 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5577
	data_grads_norm = 3.8991
	new_data_grads_norm = 6.9536
	old_data_grads_norm = 3.6641
	sim_grads_norm_tr = 0.2153
-- Starting training on experience 626 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3981
	data_grads_norm = 2.9399
	new_data_grads_norm = 5.0698
	old_data_grads_norm = 4.1955
	sim_grads_norm_tr = -0.0851
-- Starting training on experience 627 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5785
	data_grads_norm = 3.8894
	new_data_grads_norm = 6.2522
	old_data_grads_norm = 4.2436
	sim_grads_norm_tr = 0.0173
-- Starting training on experience 628 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6630
	data_grads_norm = 3.8753
	new_data_grads_norm = 5.7271
	old_data_grads_norm = 4.4098
	sim_grads_norm_tr = -0.0682
-- Starting training on experience 629 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2813
	data_grads_norm = 5.3059
	new_data_grads_norm = 7.2520
	old_data_grads_norm = 6.0947
	sim_grads_norm_tr = 0.1628
-- Starting training on experience 630 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4295
	data_grads_norm = 3.4478
	new_data_grads_norm = 6.8780
	old_data_grads_norm = 2.5250
	sim_grads_norm_tr = 0.0320
-- Starting training on experience 631 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8019
	data_grads_norm = 3.6215
	new_data_grads_norm = 6.4371
	old_data_grads_norm = 4.7485
	sim_grads_norm_tr = -0.1632
-- Starting training on experience 632 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5492
	data_grads_norm = 3.9925
	new_data_grads_norm = 6.5813
	old_data_grads_norm = 4.3368
	sim_grads_norm_tr = 0.1057
-- Starting training on experience 633 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2629
	data_grads_norm = 3.3862
	new_data_grads_norm = 6.6434
	old_data_grads_norm = 3.3979
	sim_grads_norm_tr = 0.0134
-- Starting training on experience 634 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0973
	data_grads_norm = 4.2145
	new_data_grads_norm = 6.1707
	old_data_grads_norm = 4.7617
	sim_grads_norm_tr = 0.0266
-- Starting training on experience 635 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8905
	data_grads_norm = 3.8960
	new_data_grads_norm = 5.9841
	old_data_grads_norm = 5.3552
	sim_grads_norm_tr = -0.1100
-- Starting training on experience 636 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4506
	data_grads_norm = 3.3674
	new_data_grads_norm = 6.0845
	old_data_grads_norm = 3.5313
	sim_grads_norm_tr = -0.0589
-- Starting training on experience 637 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8567
	data_grads_norm = 3.5733
	new_data_grads_norm = 6.0585
	old_data_grads_norm = 4.0801
	sim_grads_norm_tr = -0.1153
-- Starting training on experience 638 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8695
	data_grads_norm = 4.3789
	new_data_grads_norm = 6.9474
	old_data_grads_norm = 5.1845
	sim_grads_norm_tr = 0.1968
-- Starting training on experience 639 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6100
	data_grads_norm = 3.5940
	new_data_grads_norm = 5.9637
	old_data_grads_norm = 3.8146
	sim_grads_norm_tr = -0.0977
-- Starting training on experience 640 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7349
	data_grads_norm = 4.9267
	new_data_grads_norm = 8.5045
	old_data_grads_norm = 4.9599
	sim_grads_norm_tr = 0.0630
-- Starting training on experience 641 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6292
	data_grads_norm = 3.7356
	new_data_grads_norm = 6.2810
	old_data_grads_norm = 4.9040
	sim_grads_norm_tr = -0.0871
-- Starting training on experience 642 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5426
	data_grads_norm = 3.7136
	new_data_grads_norm = 6.3375
	old_data_grads_norm = 5.5307
	sim_grads_norm_tr = -0.0586
-- Starting training on experience 643 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9193
	data_grads_norm = 4.0291
	new_data_grads_norm = 6.6171
	old_data_grads_norm = 3.3803
	sim_grads_norm_tr = 0.1357
-- Starting training on experience 644 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5859
	data_grads_norm = 5.4696
	new_data_grads_norm = 7.2626
	old_data_grads_norm = 6.0747
	sim_grads_norm_tr = 0.2098
-- Starting training on experience 645 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1067
	data_grads_norm = 4.0268
	new_data_grads_norm = 6.5394
	old_data_grads_norm = 4.2430
	sim_grads_norm_tr = 0.0914
-- Starting training on experience 646 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2728
	data_grads_norm = 3.5031
	new_data_grads_norm = 5.2989
	old_data_grads_norm = 4.4871
	sim_grads_norm_tr = -0.0305
-- Starting training on experience 647 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6225
	data_grads_norm = 3.7429
	new_data_grads_norm = 6.8496
	old_data_grads_norm = 3.8644
	sim_grads_norm_tr = -0.0762
-- Starting training on experience 648 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6638
	data_grads_norm = 4.1452
	new_data_grads_norm = 6.0257
	old_data_grads_norm = 4.6647
	sim_grads_norm_tr = 0.1011
-- Starting training on experience 649 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8739
	data_grads_norm = 4.1222
	new_data_grads_norm = 5.3618
	old_data_grads_norm = 6.2492
	sim_grads_norm_tr = -0.0233
-- Starting training on experience 650 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1805
	data_grads_norm = 3.3696
	new_data_grads_norm = 5.9430
	old_data_grads_norm = 3.6338
	sim_grads_norm_tr = 0.0424
-- Starting training on experience 651 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8112
	data_grads_norm = 4.6315
	new_data_grads_norm = 6.3477
	old_data_grads_norm = 5.5159
	sim_grads_norm_tr = 0.1155
-- Starting training on experience 652 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2929
	data_grads_norm = 3.1963
	new_data_grads_norm = 6.1400
	old_data_grads_norm = 3.5680
	sim_grads_norm_tr = -0.0843
-- Starting training on experience 653 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9606
	data_grads_norm = 4.7663
	new_data_grads_norm = 6.7271
	old_data_grads_norm = 5.5961
	sim_grads_norm_tr = 0.0015
-- Starting training on experience 654 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5461
	data_grads_norm = 3.7072
	new_data_grads_norm = 6.8152
	old_data_grads_norm = 3.5467
	sim_grads_norm_tr = 0.1788
-- Starting training on experience 655 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5084
	data_grads_norm = 3.2327
	new_data_grads_norm = 6.3183
	old_data_grads_norm = 2.4859
	sim_grads_norm_tr = 0.0206
-- Starting training on experience 656 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8043
	data_grads_norm = 4.3390
	new_data_grads_norm = 6.0967
	old_data_grads_norm = 5.0203
	sim_grads_norm_tr = 0.0944
-- Starting training on experience 657 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7704
	data_grads_norm = 4.0016
	new_data_grads_norm = 6.2102
	old_data_grads_norm = 5.7064
	sim_grads_norm_tr = 0.0525
-- Starting training on experience 658 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9099
	data_grads_norm = 4.4753
	new_data_grads_norm = 6.8513
	old_data_grads_norm = 5.0451
	sim_grads_norm_tr = 0.1509
-- Starting training on experience 659 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8011
	data_grads_norm = 3.8298
	new_data_grads_norm = 6.3356
	old_data_grads_norm = 4.0186
	sim_grads_norm_tr = 0.0039
-- Starting training on experience 660 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3391
	data_grads_norm = 3.6974
	new_data_grads_norm = 6.0665
	old_data_grads_norm = 3.9416
	sim_grads_norm_tr = 0.1989
-- Starting training on experience 661 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3716
	data_grads_norm = 3.3818
	new_data_grads_norm = 6.4422
	old_data_grads_norm = 4.6890
	sim_grads_norm_tr = -0.1537
-- Starting training on experience 662 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8658
	data_grads_norm = 4.1348
	new_data_grads_norm = 5.4971
	old_data_grads_norm = 5.7394
	sim_grads_norm_tr = 0.0479
-- Starting training on experience 663 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7379
	data_grads_norm = 3.7304
	new_data_grads_norm = 5.9053
	old_data_grads_norm = 4.1327
	sim_grads_norm_tr = 0.0483
-- Starting training on experience 664 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4447
	data_grads_norm = 3.5047
	new_data_grads_norm = 5.4311
	old_data_grads_norm = 4.7681
	sim_grads_norm_tr = -0.0079
-- Starting training on experience 665 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6484
	data_grads_norm = 4.5871
	new_data_grads_norm = 6.8220
	old_data_grads_norm = 6.8656
	sim_grads_norm_tr = -0.0488
-- Starting training on experience 666 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5031
	data_grads_norm = 3.6039
	new_data_grads_norm = 5.1332
	old_data_grads_norm = 4.6535
	sim_grads_norm_tr = 0.1080
-- Starting training on experience 667 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0547
	data_grads_norm = 2.8101
	new_data_grads_norm = 6.4818
	old_data_grads_norm = 2.7339
	sim_grads_norm_tr = -0.0127
-- Starting training on experience 668 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6970
	data_grads_norm = 3.5744
	new_data_grads_norm = 5.4016
	old_data_grads_norm = 4.7968
	sim_grads_norm_tr = 0.0715
-- Starting training on experience 669 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3984
	data_grads_norm = 3.4405
	new_data_grads_norm = 5.8779
	old_data_grads_norm = 5.0368
	sim_grads_norm_tr = -0.1484
-- Starting training on experience 670 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8808
	data_grads_norm = 4.6062
	new_data_grads_norm = 6.2146
	old_data_grads_norm = 5.2123
	sim_grads_norm_tr = 0.1826
-- Starting training on experience 671 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9835
	data_grads_norm = 4.1146
	new_data_grads_norm = 5.6504
	old_data_grads_norm = 5.4261
	sim_grads_norm_tr = 0.0279
-- Starting training on experience 672 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9511
	data_grads_norm = 4.7598
	new_data_grads_norm = 6.3890
	old_data_grads_norm = 6.1253
	sim_grads_norm_tr = 0.0875
-- Starting training on experience 673 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3449
	data_grads_norm = 3.7960
	new_data_grads_norm = 5.5827
	old_data_grads_norm = 5.4279
	sim_grads_norm_tr = -0.0459
-- Starting training on experience 674 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4446
	data_grads_norm = 3.4240
	new_data_grads_norm = 6.3784
	old_data_grads_norm = 4.1111
	sim_grads_norm_tr = -0.0667
-- Starting training on experience 675 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6873
	data_grads_norm = 4.4260
	new_data_grads_norm = 7.2183
	old_data_grads_norm = 5.0075
	sim_grads_norm_tr = 0.1846
-- Starting training on experience 676 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2472
	data_grads_norm = 3.7484
	new_data_grads_norm = 6.7181
	old_data_grads_norm = 3.3268
	sim_grads_norm_tr = 0.1716
-- Starting training on experience 677 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7245
	data_grads_norm = 3.2886
	new_data_grads_norm = 6.2168
	old_data_grads_norm = 3.2616
	sim_grads_norm_tr = 0.0068
-- Starting training on experience 678 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3054
	data_grads_norm = 4.0429
	new_data_grads_norm = 6.7271
	old_data_grads_norm = 4.8383
	sim_grads_norm_tr = -0.0332
-- Starting training on experience 679 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7718
	data_grads_norm = 4.1258
	new_data_grads_norm = 6.3605
	old_data_grads_norm = 5.1585
	sim_grads_norm_tr = -0.0448
-- Starting training on experience 680 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9253
	data_grads_norm = 4.7959
	new_data_grads_norm = 6.4966
	old_data_grads_norm = 6.8981
	sim_grads_norm_tr = -0.0629
-- Starting training on experience 681 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6733
	data_grads_norm = 4.1582
	new_data_grads_norm = 6.1065
	old_data_grads_norm = 5.2132
	sim_grads_norm_tr = 0.0467
-- Starting training on experience 682 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6233
	data_grads_norm = 3.6864
	new_data_grads_norm = 6.0927
	old_data_grads_norm = 4.7590
	sim_grads_norm_tr = 0.0525
-- Starting training on experience 683 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7686
	data_grads_norm = 3.9783
	new_data_grads_norm = 6.0205
	old_data_grads_norm = 5.3215
	sim_grads_norm_tr = -0.0195
-- Starting training on experience 684 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5627
	data_grads_norm = 4.0649
	new_data_grads_norm = 6.2264
	old_data_grads_norm = 4.6514
	sim_grads_norm_tr = 0.0941
-- Starting training on experience 685 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0800
	data_grads_norm = 2.6685
	new_data_grads_norm = 6.0277
	old_data_grads_norm = 3.0814
	sim_grads_norm_tr = -0.1026
-- Starting training on experience 686 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7710
	data_grads_norm = 4.1220
	new_data_grads_norm = 6.3729
	old_data_grads_norm = 4.5857
	sim_grads_norm_tr = 0.0982
-- Starting training on experience 687 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2109
	data_grads_norm = 3.5019
	new_data_grads_norm = 5.8501
	old_data_grads_norm = 4.7137
	sim_grads_norm_tr = -0.0296
-- Starting training on experience 688 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9771
	data_grads_norm = 4.0126
	new_data_grads_norm = 6.5954
	old_data_grads_norm = 4.3034
	sim_grads_norm_tr = 0.0076
-- Starting training on experience 689 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3607
	data_grads_norm = 3.7082
	new_data_grads_norm = 6.3024
	old_data_grads_norm = 5.8617
	sim_grads_norm_tr = -0.0780
-- Starting training on experience 690 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7754
	data_grads_norm = 4.1190
	new_data_grads_norm = 6.6528
	old_data_grads_norm = 6.2838
	sim_grads_norm_tr = 0.0015
-- Starting training on experience 691 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8879
	data_grads_norm = 4.1790
	new_data_grads_norm = 6.1992
	old_data_grads_norm = 5.1838
	sim_grads_norm_tr = 0.0050
-- Starting training on experience 692 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0948
	data_grads_norm = 4.2151
	new_data_grads_norm = 6.2440
	old_data_grads_norm = 5.9067
	sim_grads_norm_tr = -0.0111
-- Starting training on experience 693 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4632
	data_grads_norm = 4.0995
	new_data_grads_norm = 6.5976
	old_data_grads_norm = 3.9408
	sim_grads_norm_tr = 0.0651
-- Starting training on experience 694 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6692
	data_grads_norm = 4.0445
	new_data_grads_norm = 5.9783
	old_data_grads_norm = 5.3198
	sim_grads_norm_tr = 0.0810
-- Starting training on experience 695 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9563
	data_grads_norm = 4.6369
	new_data_grads_norm = 6.8009
	old_data_grads_norm = 5.8282
	sim_grads_norm_tr = 0.0280
-- Starting training on experience 696 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5279
	data_grads_norm = 3.5940
	new_data_grads_norm = 5.6977
	old_data_grads_norm = 3.7451
	sim_grads_norm_tr = 0.1838
-- Starting training on experience 697 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5987
	data_grads_norm = 3.8543
	new_data_grads_norm = 5.7670
	old_data_grads_norm = 4.8273
	sim_grads_norm_tr = 0.0607
-- Starting training on experience 698 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4366
	data_grads_norm = 3.9913
	new_data_grads_norm = 5.9038
	old_data_grads_norm = 5.6971
	sim_grads_norm_tr = -0.1669
-- Starting training on experience 699 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8168
	data_grads_norm = 4.4784
	new_data_grads_norm = 6.8653
	old_data_grads_norm = 4.8126
	sim_grads_norm_tr = 0.1694
-- Starting training on experience 700 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6233
	data_grads_norm = 3.9365
	new_data_grads_norm = 5.1723
	old_data_grads_norm = 4.4115
	sim_grads_norm_tr = 0.0750
-- Starting training on experience 701 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3900
	data_grads_norm = 3.4396
	new_data_grads_norm = 5.9320
	old_data_grads_norm = 3.8133
	sim_grads_norm_tr = -0.2547
-- Starting training on experience 702 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4529
	data_grads_norm = 3.1222
	new_data_grads_norm = 6.0994
	old_data_grads_norm = 3.1456
	sim_grads_norm_tr = -0.0391
-- Starting training on experience 703 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1035
	data_grads_norm = 2.6886
	new_data_grads_norm = 5.2125
	old_data_grads_norm = 3.8881
	sim_grads_norm_tr = -0.1492
-- Starting training on experience 704 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1882
	data_grads_norm = 3.0459
	new_data_grads_norm = 5.8991
	old_data_grads_norm = 3.5186
	sim_grads_norm_tr = -0.1297
-- Starting training on experience 705 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5218
	data_grads_norm = 3.9619
	new_data_grads_norm = 6.4365
	old_data_grads_norm = 4.6095
	sim_grads_norm_tr = -0.0280
-- Starting training on experience 706 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2473
	data_grads_norm = 2.7818
	new_data_grads_norm = 6.2048
	old_data_grads_norm = 3.1469
	sim_grads_norm_tr = -0.0251
-- Starting training on experience 707 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9000
	data_grads_norm = 3.6336
	new_data_grads_norm = 5.9981
	old_data_grads_norm = 4.9652
	sim_grads_norm_tr = -0.0320
-- Starting training on experience 708 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3915
	data_grads_norm = 4.7201
	new_data_grads_norm = 5.9064
	old_data_grads_norm = 6.0075
	sim_grads_norm_tr = 0.1630
-- Starting training on experience 709 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7372
	data_grads_norm = 4.0267
	new_data_grads_norm = 7.2622
	old_data_grads_norm = 4.1775
	sim_grads_norm_tr = 0.1176
-- Starting training on experience 710 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8143
	data_grads_norm = 4.0944
	new_data_grads_norm = 6.4472
	old_data_grads_norm = 4.8653
	sim_grads_norm_tr = 0.0082
-- Starting training on experience 711 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3192
	data_grads_norm = 3.2618
	new_data_grads_norm = 5.6729
	old_data_grads_norm = 3.7955
	sim_grads_norm_tr = 0.1627
-- Starting training on experience 712 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8031
	data_grads_norm = 3.9620
	new_data_grads_norm = 6.8650
	old_data_grads_norm = 4.2103
	sim_grads_norm_tr = -0.0724
-- Starting training on experience 713 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8648
	data_grads_norm = 3.6466
	new_data_grads_norm = 6.1548
	old_data_grads_norm = 3.6482
	sim_grads_norm_tr = 0.0586
-- Starting training on experience 714 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5726
	data_grads_norm = 3.5983
	new_data_grads_norm = 6.1820
	old_data_grads_norm = 4.6187
	sim_grads_norm_tr = 0.0428
-- Starting training on experience 715 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6493
	data_grads_norm = 3.9099
	new_data_grads_norm = 6.8454
	old_data_grads_norm = 5.6475
	sim_grads_norm_tr = 0.1110
-- Starting training on experience 716 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2743
	data_grads_norm = 3.7336
	new_data_grads_norm = 5.7234
	old_data_grads_norm = 5.2323
	sim_grads_norm_tr = 0.0132
-- Starting training on experience 717 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6132
	data_grads_norm = 4.4161
	new_data_grads_norm = 6.2819
	old_data_grads_norm = 4.9475
	sim_grads_norm_tr = 0.1027
-- Starting training on experience 718 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1076
	data_grads_norm = 4.1736
	new_data_grads_norm = 6.7322
	old_data_grads_norm = 4.3799
	sim_grads_norm_tr = 0.0634
-- Starting training on experience 719 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4553
	data_grads_norm = 3.4690
	new_data_grads_norm = 5.6534
	old_data_grads_norm = 6.0118
	sim_grads_norm_tr = -0.1469
-- Starting training on experience 720 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6176
	data_grads_norm = 4.0223
	new_data_grads_norm = 6.4081
	old_data_grads_norm = 3.3100
	sim_grads_norm_tr = 0.1162
-- Starting training on experience 721 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8027
	data_grads_norm = 4.3625
	new_data_grads_norm = 6.6022
	old_data_grads_norm = 5.2145
	sim_grads_norm_tr = 0.0713
-- Starting training on experience 722 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7048
	data_grads_norm = 3.9564
	new_data_grads_norm = 6.2976
	old_data_grads_norm = 4.8868
	sim_grads_norm_tr = 0.0321
-- Starting training on experience 723 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9357
	data_grads_norm = 3.7642
	new_data_grads_norm = 6.1345
	old_data_grads_norm = 3.7174
	sim_grads_norm_tr = -0.0000
-- Starting training on experience 724 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6184
	data_grads_norm = 3.7421
	new_data_grads_norm = 6.3154
	old_data_grads_norm = 3.9611
	sim_grads_norm_tr = 0.0882
-- Starting training on experience 725 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5885
	data_grads_norm = 3.5923
	new_data_grads_norm = 5.7680
	old_data_grads_norm = 4.7496
	sim_grads_norm_tr = -0.0449
-- Starting training on experience 726 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.5185
	data_grads_norm = 4.3748
	new_data_grads_norm = 6.0780
	old_data_grads_norm = 5.4629
	sim_grads_norm_tr = 0.1340
-- Starting training on experience 727 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7529
	data_grads_norm = 4.1980
	new_data_grads_norm = 6.2035
	old_data_grads_norm = 4.3894
	sim_grads_norm_tr = -0.0568
-- Starting training on experience 728 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8178
	data_grads_norm = 3.2313
	new_data_grads_norm = 5.8668
	old_data_grads_norm = 4.0814
	sim_grads_norm_tr = -0.1021
-- Starting training on experience 729 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0595
	data_grads_norm = 4.0785
	new_data_grads_norm = 6.0853
	old_data_grads_norm = 4.6430
	sim_grads_norm_tr = 0.0373
-- Starting training on experience 730 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2495
	data_grads_norm = 5.0792
	new_data_grads_norm = 6.7385
	old_data_grads_norm = 5.5214
	sim_grads_norm_tr = 0.2219
-- Starting training on experience 731 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8360
	data_grads_norm = 4.3264
	new_data_grads_norm = 6.2125
	old_data_grads_norm = 3.9820
	sim_grads_norm_tr = 0.3356
-- Starting training on experience 732 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4163
	data_grads_norm = 3.4134
	new_data_grads_norm = 5.5881
	old_data_grads_norm = 4.6798
	sim_grads_norm_tr = -0.1443
-- Starting training on experience 733 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5952
	data_grads_norm = 3.5763
	new_data_grads_norm = 6.6375
	old_data_grads_norm = 3.7876
	sim_grads_norm_tr = -0.0164
-- Starting training on experience 734 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2692
	data_grads_norm = 3.0254
	new_data_grads_norm = 6.1968
	old_data_grads_norm = 4.3753
	sim_grads_norm_tr = -0.0824
-- Starting training on experience 735 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8118
	data_grads_norm = 3.7129
	new_data_grads_norm = 5.7499
	old_data_grads_norm = 4.1109
	sim_grads_norm_tr = 0.1757
-- Starting training on experience 736 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6860
	data_grads_norm = 4.0969
	new_data_grads_norm = 6.7870
	old_data_grads_norm = 3.6690
	sim_grads_norm_tr = 0.0445
-- Starting training on experience 737 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5623
	data_grads_norm = 3.1350
	new_data_grads_norm = 4.7924
	old_data_grads_norm = 3.5170
	sim_grads_norm_tr = 0.0889
-- Starting training on experience 738 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5835
	data_grads_norm = 3.7926
	new_data_grads_norm = 4.9927
	old_data_grads_norm = 5.8209
	sim_grads_norm_tr = 0.0023
-- Starting training on experience 739 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6711
	data_grads_norm = 3.8781
	new_data_grads_norm = 6.5282
	old_data_grads_norm = 4.1729
	sim_grads_norm_tr = 0.0814
-- Starting training on experience 740 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5476
	data_grads_norm = 4.1638
	new_data_grads_norm = 6.0239
	old_data_grads_norm = 5.4353
	sim_grads_norm_tr = 0.0771
-- Starting training on experience 741 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7531
	data_grads_norm = 3.8744
	new_data_grads_norm = 5.9005
	old_data_grads_norm = 4.3198
	sim_grads_norm_tr = 0.1478
-- Starting training on experience 742 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4432
	data_grads_norm = 3.3682
	new_data_grads_norm = 4.9366
	old_data_grads_norm = 4.6555
	sim_grads_norm_tr = 0.0559
-- Starting training on experience 743 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4736
	data_grads_norm = 3.1662
	new_data_grads_norm = 4.9257
	old_data_grads_norm = 4.1873
	sim_grads_norm_tr = 0.0050
-- Starting training on experience 744 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5404
	data_grads_norm = 4.0222
	new_data_grads_norm = 6.4519
	old_data_grads_norm = 5.3657
	sim_grads_norm_tr = -0.1267
-- Starting training on experience 745 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8748
	data_grads_norm = 4.1622
	new_data_grads_norm = 6.2683
	old_data_grads_norm = 3.6799
	sim_grads_norm_tr = 0.3436
-- Starting training on experience 746 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6086
	data_grads_norm = 3.6021
	new_data_grads_norm = 5.6496
	old_data_grads_norm = 4.7881
	sim_grads_norm_tr = 0.0695
-- Starting training on experience 747 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3922
	data_grads_norm = 2.9060
	new_data_grads_norm = 4.6039
	old_data_grads_norm = 3.9097
	sim_grads_norm_tr = -0.1499
-- Starting training on experience 748 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6506
	data_grads_norm = 3.8537
	new_data_grads_norm = 6.3812
	old_data_grads_norm = 4.3449
	sim_grads_norm_tr = 0.1450
-- Starting training on experience 749 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8726
	data_grads_norm = 3.6464
	new_data_grads_norm = 5.3037
	old_data_grads_norm = 3.9638
	sim_grads_norm_tr = -0.0481
-- Starting training on experience 750 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2850
	data_grads_norm = 2.9387
	new_data_grads_norm = 5.7475
	old_data_grads_norm = 3.3488
	sim_grads_norm_tr = -0.0348
-- Starting training on experience 751 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4771
	data_grads_norm = 3.2271
	new_data_grads_norm = 6.1296
	old_data_grads_norm = 2.8400
	sim_grads_norm_tr = -0.0242
-- Starting training on experience 752 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9711
	data_grads_norm = 3.8942
	new_data_grads_norm = 5.4655
	old_data_grads_norm = 4.5482
	sim_grads_norm_tr = 0.1411
-- Starting training on experience 753 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2353
	data_grads_norm = 3.6494
	new_data_grads_norm = 5.8581
	old_data_grads_norm = 5.1408
	sim_grads_norm_tr = 0.0368
-- Starting training on experience 754 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1806
	data_grads_norm = 2.8605
	new_data_grads_norm = 6.3478
	old_data_grads_norm = 5.2016
	sim_grads_norm_tr = -0.0522
-- Starting training on experience 755 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5459
	data_grads_norm = 3.8699
	new_data_grads_norm = 6.6485
	old_data_grads_norm = 4.7969
	sim_grads_norm_tr = -0.1644
-- Starting training on experience 756 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0120
	data_grads_norm = 3.9500
	new_data_grads_norm = 5.4647
	old_data_grads_norm = 5.4773
	sim_grads_norm_tr = 0.0289
-- Starting training on experience 757 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5922
	data_grads_norm = 4.2069
	new_data_grads_norm = 6.2360
	old_data_grads_norm = 5.8841
	sim_grads_norm_tr = 0.0557
-- Starting training on experience 758 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3237
	data_grads_norm = 4.9174
	new_data_grads_norm = 6.2186
	old_data_grads_norm = 6.1813
	sim_grads_norm_tr = 0.1877
-- Starting training on experience 759 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4487
	data_grads_norm = 3.2806
	new_data_grads_norm = 5.1407
	old_data_grads_norm = 4.3028
	sim_grads_norm_tr = 0.1166
-- Starting training on experience 760 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6529
	data_grads_norm = 3.6023
	new_data_grads_norm = 5.6888
	old_data_grads_norm = 4.5929
	sim_grads_norm_tr = 0.0145
-- Starting training on experience 761 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7388
	data_grads_norm = 3.5630
	new_data_grads_norm = 5.4338
	old_data_grads_norm = 4.3446
	sim_grads_norm_tr = 0.0667
-- Starting training on experience 762 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6033
	data_grads_norm = 3.4953
	new_data_grads_norm = 5.1358
	old_data_grads_norm = 4.0605
	sim_grads_norm_tr = 0.0397
-- Starting training on experience 763 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5290
	data_grads_norm = 3.5430
	new_data_grads_norm = 5.0000
	old_data_grads_norm = 5.7645
	sim_grads_norm_tr = -0.0324
-- Starting training on experience 764 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2944
	data_grads_norm = 2.9880
	new_data_grads_norm = 4.7717
	old_data_grads_norm = 5.4246
	sim_grads_norm_tr = -0.0633
-- Starting training on experience 765 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4384
	data_grads_norm = 3.3426
	new_data_grads_norm = 5.1024
	old_data_grads_norm = 4.8708
	sim_grads_norm_tr = -0.0976
-- Starting training on experience 766 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8241
	data_grads_norm = 4.0067
	new_data_grads_norm = 6.3758
	old_data_grads_norm = 4.2971
	sim_grads_norm_tr = -0.0218
-- Starting training on experience 767 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9279
	data_grads_norm = 3.6869
	new_data_grads_norm = 6.7365
	old_data_grads_norm = 3.4902
	sim_grads_norm_tr = 0.0087
-- Starting training on experience 768 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0589
	data_grads_norm = 4.4893
	new_data_grads_norm = 6.7512
	old_data_grads_norm = 4.8549
	sim_grads_norm_tr = 0.1474
-- Starting training on experience 769 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4383
	data_grads_norm = 2.9693
	new_data_grads_norm = 5.8077
	old_data_grads_norm = 3.1534
	sim_grads_norm_tr = -0.1225
-- Starting training on experience 770 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5797
	data_grads_norm = 3.6763
	new_data_grads_norm = 5.9895
	old_data_grads_norm = 3.8249
	sim_grads_norm_tr = 0.0419
-- Starting training on experience 771 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7095
	data_grads_norm = 3.7159
	new_data_grads_norm = 6.2195
	old_data_grads_norm = 4.5194
	sim_grads_norm_tr = 0.0315
-- Starting training on experience 772 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3320
	data_grads_norm = 2.8441
	new_data_grads_norm = 6.5274
	old_data_grads_norm = 3.6888
	sim_grads_norm_tr = -0.2286
-- Starting training on experience 773 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9885
	data_grads_norm = 3.8080
	new_data_grads_norm = 6.0280
	old_data_grads_norm = 4.7147
	sim_grads_norm_tr = 0.1753
-- Starting training on experience 774 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1774
	data_grads_norm = 4.0411
	new_data_grads_norm = 5.1401
	old_data_grads_norm = 5.2735
	sim_grads_norm_tr = 0.0885
-- Starting training on experience 775 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5579
	data_grads_norm = 3.2511
	new_data_grads_norm = 5.9679
	old_data_grads_norm = 4.1088
	sim_grads_norm_tr = -0.0455
-- Starting training on experience 776 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8557
	data_grads_norm = 3.9433
	new_data_grads_norm = 5.7298
	old_data_grads_norm = 3.6587
	sim_grads_norm_tr = 0.1100
-- Starting training on experience 777 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4699
	data_grads_norm = 3.2045
	new_data_grads_norm = 5.7150
	old_data_grads_norm = 3.6663
	sim_grads_norm_tr = -0.1281
-- Starting training on experience 778 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6847
	data_grads_norm = 4.0722
	new_data_grads_norm = 6.8272
	old_data_grads_norm = 3.9386
	sim_grads_norm_tr = -0.0004
-- Starting training on experience 779 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6154
	data_grads_norm = 3.6701
	new_data_grads_norm = 6.1361
	old_data_grads_norm = 4.3547
	sim_grads_norm_tr = -0.0620
-- Starting training on experience 780 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6379
	data_grads_norm = 3.4908
	new_data_grads_norm = 6.8141
	old_data_grads_norm = 2.4463
	sim_grads_norm_tr = 0.0347
-- Starting training on experience 781 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9866
	data_grads_norm = 4.1993
	new_data_grads_norm = 6.7054
	old_data_grads_norm = 4.4958
	sim_grads_norm_tr = 0.1491
-- Starting training on experience 782 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0179
	data_grads_norm = 3.5471
	new_data_grads_norm = 5.9215
	old_data_grads_norm = 4.0732
	sim_grads_norm_tr = 0.0154
-- Starting training on experience 783 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8037
	data_grads_norm = 3.6057
	new_data_grads_norm = 5.7513
	old_data_grads_norm = 3.8007
	sim_grads_norm_tr = 0.0936
-- Starting training on experience 784 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6900
	data_grads_norm = 4.1702
	new_data_grads_norm = 6.6664
	old_data_grads_norm = 2.9580
	sim_grads_norm_tr = 0.0759
-- Starting training on experience 785 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4790
	data_grads_norm = 3.2025
	new_data_grads_norm = 6.1496
	old_data_grads_norm = 3.3352
	sim_grads_norm_tr = -0.1200
-- Starting training on experience 786 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7813
	data_grads_norm = 3.7619
	new_data_grads_norm = 5.9659
	old_data_grads_norm = 3.5051
	sim_grads_norm_tr = 0.0619
-- Starting training on experience 787 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9229
	data_grads_norm = 3.7902
	new_data_grads_norm = 6.2158
	old_data_grads_norm = 4.2134
	sim_grads_norm_tr = 0.0728
-- Starting training on experience 788 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2688
	data_grads_norm = 4.8244
	new_data_grads_norm = 5.6803
	old_data_grads_norm = 4.2227
	sim_grads_norm_tr = -0.0736
-- Starting training on experience 789 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6180
	data_grads_norm = 3.8373
	new_data_grads_norm = 6.0448
	old_data_grads_norm = 2.9866
	sim_grads_norm_tr = 0.1724
-- Starting training on experience 790 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8792
	data_grads_norm = 4.4001
	new_data_grads_norm = 6.2978
	old_data_grads_norm = 5.5710
	sim_grads_norm_tr = 0.0278
-- Starting training on experience 791 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2074
	data_grads_norm = 3.3700
	new_data_grads_norm = 6.6392
	old_data_grads_norm = 3.8273
	sim_grads_norm_tr = -0.1131
-- Starting training on experience 792 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3866
	data_grads_norm = 3.3760
	new_data_grads_norm = 5.9278
	old_data_grads_norm = 2.5272
	sim_grads_norm_tr = 0.0113
-- Starting training on experience 793 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4219
	data_grads_norm = 3.2673
	new_data_grads_norm = 5.6073
	old_data_grads_norm = 3.8116
	sim_grads_norm_tr = -0.0814
-- Starting training on experience 794 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4281
	data_grads_norm = 3.9559
	new_data_grads_norm = 5.9098
	old_data_grads_norm = 5.6412
	sim_grads_norm_tr = -0.0003
-- Starting training on experience 795 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4860
	data_grads_norm = 3.7967
	new_data_grads_norm = 6.0182
	old_data_grads_norm = 4.3509
	sim_grads_norm_tr = 0.0636
-- Starting training on experience 796 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2929
	data_grads_norm = 4.6771
	new_data_grads_norm = 7.1761
	old_data_grads_norm = 5.0719
	sim_grads_norm_tr = 0.1811
-- Starting training on experience 797 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8997
	data_grads_norm = 3.5773
	new_data_grads_norm = 6.4565
	old_data_grads_norm = 2.9598
	sim_grads_norm_tr = -0.0683
-- Starting training on experience 798 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8389
	data_grads_norm = 3.8826
	new_data_grads_norm = 5.9655
	old_data_grads_norm = 4.5364
	sim_grads_norm_tr = 0.0305
-- Starting training on experience 799 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6188
	data_grads_norm = 3.6184
	new_data_grads_norm = 6.2253
	old_data_grads_norm = 3.6642
	sim_grads_norm_tr = -0.0071
-- Starting training on experience 800 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8405
	data_grads_norm = 4.0409
	new_data_grads_norm = 6.3128
	old_data_grads_norm = 4.7158
	sim_grads_norm_tr = 0.0177
-- Starting training on experience 801 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4930
	data_grads_norm = 3.4451
	new_data_grads_norm = 6.3422
	old_data_grads_norm = 3.8061
	sim_grads_norm_tr = -0.0587
-- Starting training on experience 802 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5946
	data_grads_norm = 3.5486
	new_data_grads_norm = 6.1831
	old_data_grads_norm = 3.5946
	sim_grads_norm_tr = 0.2009
-- Starting training on experience 803 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7434
	data_grads_norm = 4.1560
	new_data_grads_norm = 7.2511
	old_data_grads_norm = 4.1619
	sim_grads_norm_tr = 0.1420
-- Starting training on experience 804 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4844
	data_grads_norm = 2.9164
	new_data_grads_norm = 6.0714
	old_data_grads_norm = 3.1179
	sim_grads_norm_tr = 0.0406
-- Starting training on experience 805 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2809
	data_grads_norm = 3.5545
	new_data_grads_norm = 6.3187
	old_data_grads_norm = 4.1038
	sim_grads_norm_tr = -0.2014
-- Starting training on experience 806 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7020
	data_grads_norm = 4.1305
	new_data_grads_norm = 6.7220
	old_data_grads_norm = 4.2830
	sim_grads_norm_tr = -0.0092
-- Starting training on experience 807 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3603
	data_grads_norm = 2.9903
	new_data_grads_norm = 6.7524
	old_data_grads_norm = 3.7457
	sim_grads_norm_tr = -0.0126
-- Starting training on experience 808 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3131
	data_grads_norm = 3.7723
	new_data_grads_norm = 7.0751
	old_data_grads_norm = 4.2752
	sim_grads_norm_tr = -0.0947
-- Starting training on experience 809 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2050
	data_grads_norm = 4.8190
	new_data_grads_norm = 6.8936
	old_data_grads_norm = 4.4442
	sim_grads_norm_tr = 0.2428
-- Starting training on experience 810 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8007
	data_grads_norm = 3.8339
	new_data_grads_norm = 6.8906
	old_data_grads_norm = 3.9052
	sim_grads_norm_tr = -0.0329
-- Starting training on experience 811 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1364
	data_grads_norm = 4.6896
	new_data_grads_norm = 6.9160
	old_data_grads_norm = 5.2569
	sim_grads_norm_tr = 0.2315
-- Starting training on experience 812 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2614
	data_grads_norm = 3.6540
	new_data_grads_norm = 5.8974
	old_data_grads_norm = 4.2420
	sim_grads_norm_tr = -0.0214
-- Starting training on experience 813 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0727
	data_grads_norm = 4.4994
	new_data_grads_norm = 6.9504
	old_data_grads_norm = 5.8236
	sim_grads_norm_tr = 0.0330
-- Starting training on experience 814 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3412
	data_grads_norm = 3.4267
	new_data_grads_norm = 6.1610
	old_data_grads_norm = 4.2007
	sim_grads_norm_tr = -0.1643
-- Starting training on experience 815 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2858
	data_grads_norm = 3.0084
	new_data_grads_norm = 6.0495
	old_data_grads_norm = 2.7740
	sim_grads_norm_tr = -0.0926
-- Starting training on experience 816 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7322
	data_grads_norm = 4.0201
	new_data_grads_norm = 6.8515
	old_data_grads_norm = 5.2348
	sim_grads_norm_tr = 0.0632
-- Starting training on experience 817 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5551
	data_grads_norm = 3.6537
	new_data_grads_norm = 5.4661
	old_data_grads_norm = 4.9527
	sim_grads_norm_tr = 0.0242
-- Starting training on experience 818 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8554
	data_grads_norm = 4.3453
	new_data_grads_norm = 6.6791
	old_data_grads_norm = 4.9158
	sim_grads_norm_tr = 0.0820
-- Starting training on experience 819 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1045
	data_grads_norm = 3.1589
	new_data_grads_norm = 5.4931
	old_data_grads_norm = 2.8148
	sim_grads_norm_tr = 0.0151
-- Starting training on experience 820 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2020
	data_grads_norm = 3.0817
	new_data_grads_norm = 5.8719
	old_data_grads_norm = 3.2392
	sim_grads_norm_tr = -0.0477
-- Starting training on experience 821 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9064
	data_grads_norm = 4.8253
	new_data_grads_norm = 6.1444
	old_data_grads_norm = 6.1398
	sim_grads_norm_tr = 0.1672
-- Starting training on experience 822 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2038
	data_grads_norm = 3.1648
	new_data_grads_norm = 5.1543
	old_data_grads_norm = 4.6545
	sim_grads_norm_tr = -0.0311
-- Starting training on experience 823 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8666
	data_grads_norm = 4.6955
	new_data_grads_norm = 7.1141
	old_data_grads_norm = 5.3185
	sim_grads_norm_tr = 0.1650
-- Starting training on experience 824 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7521
	data_grads_norm = 3.9184
	new_data_grads_norm = 5.5124
	old_data_grads_norm = 5.3049
	sim_grads_norm_tr = 0.1032
-- Starting training on experience 825 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3991
	data_grads_norm = 3.3477
	new_data_grads_norm = 5.6224
	old_data_grads_norm = 3.6763
	sim_grads_norm_tr = 0.1843
-- Starting training on experience 826 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3405
	data_grads_norm = 3.4855
	new_data_grads_norm = 5.6669
	old_data_grads_norm = 4.1351
	sim_grads_norm_tr = -0.0443
-- Starting training on experience 827 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5747
	data_grads_norm = 3.6092
	new_data_grads_norm = 5.6726
	old_data_grads_norm = 4.9424
	sim_grads_norm_tr = -0.1780
-- Starting training on experience 828 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7017
	data_grads_norm = 4.1849
	new_data_grads_norm = 6.4513
	old_data_grads_norm = 5.8134
	sim_grads_norm_tr = -0.1277
-- Starting training on experience 829 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8393
	data_grads_norm = 4.3484
	new_data_grads_norm = 6.9655
	old_data_grads_norm = 4.4425
	sim_grads_norm_tr = 0.0966
-- Starting training on experience 830 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7719
	data_grads_norm = 4.3443
	new_data_grads_norm = 7.5735
	old_data_grads_norm = 3.9588
	sim_grads_norm_tr = 0.0233
-- Starting training on experience 831 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7003
	data_grads_norm = 4.1921
	new_data_grads_norm = 7.6027
	old_data_grads_norm = 3.6149
	sim_grads_norm_tr = -0.0089
-- Starting training on experience 832 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5837
	data_grads_norm = 4.1933
	new_data_grads_norm = 6.5945
	old_data_grads_norm = 4.7265
	sim_grads_norm_tr = 0.1947
-- Starting training on experience 833 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5330
	data_grads_norm = 4.5079
	new_data_grads_norm = 6.9661
	old_data_grads_norm = 4.0715
	sim_grads_norm_tr = 0.0323
-- Starting training on experience 834 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4344
	data_grads_norm = 4.0582
	new_data_grads_norm = 5.6034
	old_data_grads_norm = 7.0238
	sim_grads_norm_tr = -0.1256
-- Starting training on experience 835 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2670
	data_grads_norm = 3.4991
	new_data_grads_norm = 5.7293
	old_data_grads_norm = 5.1682
	sim_grads_norm_tr = -0.1602
-- Starting training on experience 836 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5732
	data_grads_norm = 3.5883
	new_data_grads_norm = 6.5485
	old_data_grads_norm = 3.7131
	sim_grads_norm_tr = 0.1294
-- Starting training on experience 837 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5751
	data_grads_norm = 3.6439
	new_data_grads_norm = 7.1568
	old_data_grads_norm = 4.2928
	sim_grads_norm_tr = -0.0604
-- Starting training on experience 838 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7057
	data_grads_norm = 4.5647
	new_data_grads_norm = 6.9062
	old_data_grads_norm = 5.1645
	sim_grads_norm_tr = 0.1436
-- Starting training on experience 839 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3573
	data_grads_norm = 3.4598
	new_data_grads_norm = 5.7233
	old_data_grads_norm = 3.8986
	sim_grads_norm_tr = -0.0021
-- Starting training on experience 840 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7595
	data_grads_norm = 3.8475
	new_data_grads_norm = 5.6700
	old_data_grads_norm = 4.3881
	sim_grads_norm_tr = 0.0194
-- Starting training on experience 841 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9611
	data_grads_norm = 5.4653
	new_data_grads_norm = 8.5705
	old_data_grads_norm = 6.1190
	sim_grads_norm_tr = 0.1442
-- Starting training on experience 842 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7061
	data_grads_norm = 4.4674
	new_data_grads_norm = 6.5884
	old_data_grads_norm = 4.7062
	sim_grads_norm_tr = 0.1608
-- Starting training on experience 843 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3053
	data_grads_norm = 3.8399
	new_data_grads_norm = 6.5526
	old_data_grads_norm = 3.8818
	sim_grads_norm_tr = -0.0371
-- Starting training on experience 844 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7429
	data_grads_norm = 4.5921
	new_data_grads_norm = 6.8819
	old_data_grads_norm = 4.9847
	sim_grads_norm_tr = 0.2025
-- Starting training on experience 845 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7003
	data_grads_norm = 4.1403
	new_data_grads_norm = 5.6626
	old_data_grads_norm = 6.3121
	sim_grads_norm_tr = 0.0172
-- Starting training on experience 846 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4180
	data_grads_norm = 3.4591
	new_data_grads_norm = 5.9489
	old_data_grads_norm = 3.6608
	sim_grads_norm_tr = 0.0343
-- Starting training on experience 847 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5804
	data_grads_norm = 3.7122
	new_data_grads_norm = 5.3950
	old_data_grads_norm = 4.1749
	sim_grads_norm_tr = 0.1805
-- Starting training on experience 848 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2893
	data_grads_norm = 3.9726
	new_data_grads_norm = 5.7795
	old_data_grads_norm = 5.0174
	sim_grads_norm_tr = -0.0639
-- Starting training on experience 849 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3355
	data_grads_norm = 3.1774
	new_data_grads_norm = 5.6150
	old_data_grads_norm = 2.6622
	sim_grads_norm_tr = 0.0994
-- Starting training on experience 850 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2949
	data_grads_norm = 3.1200
	new_data_grads_norm = 4.8891
	old_data_grads_norm = 4.4523
	sim_grads_norm_tr = -0.1789
-- Starting training on experience 851 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5266
	data_grads_norm = 4.2208
	new_data_grads_norm = 5.7902
	old_data_grads_norm = 6.5621
	sim_grads_norm_tr = -0.0154
-- Starting training on experience 852 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3861
	data_grads_norm = 3.4329
	new_data_grads_norm = 6.2922
	old_data_grads_norm = 4.6568
	sim_grads_norm_tr = -0.1092
-- Starting training on experience 853 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5081
	data_grads_norm = 3.9400
	new_data_grads_norm = 5.2772
	old_data_grads_norm = 5.8247
	sim_grads_norm_tr = 0.1100
-- Starting training on experience 854 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6905
	data_grads_norm = 4.2308
	new_data_grads_norm = 6.7817
	old_data_grads_norm = 4.8969
	sim_grads_norm_tr = 0.0451
-- Starting training on experience 855 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6755
	data_grads_norm = 3.7460
	new_data_grads_norm = 6.2182
	old_data_grads_norm = 4.0929
	sim_grads_norm_tr = 0.0872
-- Starting training on experience 856 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1992
	data_grads_norm = 4.0971
	new_data_grads_norm = 5.4821
	old_data_grads_norm = 5.0221
	sim_grads_norm_tr = 0.2185
-- Starting training on experience 857 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2273
	data_grads_norm = 3.4240
	new_data_grads_norm = 5.9076
	old_data_grads_norm = 3.9762
	sim_grads_norm_tr = -0.1547
-- Starting training on experience 858 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4328
	data_grads_norm = 2.8461
	new_data_grads_norm = 5.5308
	old_data_grads_norm = 3.1121
	sim_grads_norm_tr = -0.1302
-- Starting training on experience 859 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2080
	data_grads_norm = 3.0511
	new_data_grads_norm = 5.1706
	old_data_grads_norm = 3.6331
	sim_grads_norm_tr = 0.0210
-- Starting training on experience 860 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5411
	data_grads_norm = 3.5621
	new_data_grads_norm = 5.5170
	old_data_grads_norm = 4.4299
	sim_grads_norm_tr = -0.0884
-- Starting training on experience 861 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7033
	data_grads_norm = 3.3414
	new_data_grads_norm = 6.4782
	old_data_grads_norm = 3.3276
	sim_grads_norm_tr = -0.1449
-- Starting training on experience 862 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2883
	data_grads_norm = 4.8389
	new_data_grads_norm = 6.7045
	old_data_grads_norm = 5.7451
	sim_grads_norm_tr = 0.1621
-- Starting training on experience 863 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8819
	data_grads_norm = 3.2096
	new_data_grads_norm = 5.5179
	old_data_grads_norm = 3.4235
	sim_grads_norm_tr = 0.0334
-- Starting training on experience 864 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6498
	data_grads_norm = 3.4239
	new_data_grads_norm = 5.6933
	old_data_grads_norm = 3.6999
	sim_grads_norm_tr = 0.0008
-- Starting training on experience 865 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5937
	data_grads_norm = 3.3998
	new_data_grads_norm = 5.9304
	old_data_grads_norm = 3.4062
	sim_grads_norm_tr = 0.1530
-- Starting training on experience 866 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5190
	data_grads_norm = 3.2184
	new_data_grads_norm = 5.6808
	old_data_grads_norm = 3.5781
	sim_grads_norm_tr = -0.1166
-- Starting training on experience 867 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5273
	data_grads_norm = 3.7692
	new_data_grads_norm = 5.9705
	old_data_grads_norm = 4.2594
	sim_grads_norm_tr = 0.1450
-- Starting training on experience 868 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.0393
	data_grads_norm = 2.7555
	new_data_grads_norm = 5.3423
	old_data_grads_norm = 2.9980
	sim_grads_norm_tr = -0.0355
-- Starting training on experience 869 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7546
	data_grads_norm = 4.2041
	new_data_grads_norm = 6.6995
	old_data_grads_norm = 4.9920
	sim_grads_norm_tr = 0.0397
-- Starting training on experience 870 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5633
	data_grads_norm = 3.8742
	new_data_grads_norm = 7.0846
	old_data_grads_norm = 3.6742
	sim_grads_norm_tr = -0.0140
-- Starting training on experience 871 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7221
	data_grads_norm = 3.8714
	new_data_grads_norm = 6.1813
	old_data_grads_norm = 4.4392
	sim_grads_norm_tr = 0.1238
-- Starting training on experience 872 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3995
	data_grads_norm = 2.9413
	new_data_grads_norm = 5.5696
	old_data_grads_norm = 3.6982
	sim_grads_norm_tr = -0.1199
-- Starting training on experience 873 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3796
	data_grads_norm = 3.4147
	new_data_grads_norm = 6.1171
	old_data_grads_norm = 5.2588
	sim_grads_norm_tr = -0.0197
-- Starting training on experience 874 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6021
	data_grads_norm = 4.3468
	new_data_grads_norm = 5.8061
	old_data_grads_norm = 4.5478
	sim_grads_norm_tr = 0.2952
-- Starting training on experience 875 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5570
	data_grads_norm = 3.7650
	new_data_grads_norm = 6.2142
	old_data_grads_norm = 4.1711
	sim_grads_norm_tr = 0.0394
-- Starting training on experience 876 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6705
	data_grads_norm = 3.6065
	new_data_grads_norm = 5.8129
	old_data_grads_norm = 4.9534
	sim_grads_norm_tr = -0.0197
-- Starting training on experience 877 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.1972
	data_grads_norm = 3.6381
	new_data_grads_norm = 6.4042
	old_data_grads_norm = 4.3320
	sim_grads_norm_tr = 0.0337
-- Starting training on experience 878 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7959
	data_grads_norm = 4.3447
	new_data_grads_norm = 6.9687
	old_data_grads_norm = 5.7771
	sim_grads_norm_tr = 0.0981
-- Starting training on experience 879 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4524
	data_grads_norm = 3.6683
	new_data_grads_norm = 5.3219
	old_data_grads_norm = 4.9099
	sim_grads_norm_tr = 0.0010
-- Starting training on experience 880 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0281
	data_grads_norm = 4.6810
	new_data_grads_norm = 6.4576
	old_data_grads_norm = 6.1927
	sim_grads_norm_tr = -0.0212
-- Starting training on experience 881 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6436
	data_grads_norm = 4.0997
	new_data_grads_norm = 6.3980
	old_data_grads_norm = 5.0331
	sim_grads_norm_tr = 0.1707
-- Starting training on experience 882 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3618
	data_grads_norm = 3.9823
	new_data_grads_norm = 6.6051
	old_data_grads_norm = 4.4302
	sim_grads_norm_tr = 0.0072
-- Starting training on experience 883 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7578
	data_grads_norm = 3.9954
	new_data_grads_norm = 5.9846
	old_data_grads_norm = 5.7033
	sim_grads_norm_tr = -0.0419
-- Starting training on experience 884 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4645
	data_grads_norm = 3.3601
	new_data_grads_norm = 5.5059
	old_data_grads_norm = 4.8361
	sim_grads_norm_tr = -0.0018
-- Starting training on experience 885 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8321
	data_grads_norm = 3.9253
	new_data_grads_norm = 6.8751
	old_data_grads_norm = 4.0155
	sim_grads_norm_tr = 0.0723
-- Starting training on experience 886 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4748
	data_grads_norm = 3.6149
	new_data_grads_norm = 5.7772
	old_data_grads_norm = 4.6775
	sim_grads_norm_tr = 0.0546
-- Starting training on experience 887 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4002
	data_grads_norm = 3.0972
	new_data_grads_norm = 5.9174
	old_data_grads_norm = 3.1929
	sim_grads_norm_tr = -0.0433
-- Starting training on experience 888 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3816
	data_grads_norm = 3.4609
	new_data_grads_norm = 6.8259
	old_data_grads_norm = 4.1112
	sim_grads_norm_tr = -0.0829
-- Starting training on experience 889 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6592
	data_grads_norm = 3.8535
	new_data_grads_norm = 6.1443
	old_data_grads_norm = 5.6687
	sim_grads_norm_tr = -0.0493
-- Starting training on experience 890 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5468
	data_grads_norm = 3.9616
	new_data_grads_norm = 6.9503
	old_data_grads_norm = 5.2898
	sim_grads_norm_tr = 0.0425
-- Starting training on experience 891 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3439
	data_grads_norm = 3.7208
	new_data_grads_norm = 5.7246
	old_data_grads_norm = 5.1422
	sim_grads_norm_tr = 0.1617
-- Starting training on experience 892 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5268
	data_grads_norm = 3.7661
	new_data_grads_norm = 6.6210
	old_data_grads_norm = 4.0391
	sim_grads_norm_tr = -0.0413
-- Starting training on experience 893 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8971
	data_grads_norm = 3.6007
	new_data_grads_norm = 6.8807
	old_data_grads_norm = 3.6054
	sim_grads_norm_tr = -0.1242
-- Starting training on experience 894 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6549
	data_grads_norm = 4.2569
	new_data_grads_norm = 6.9267
	old_data_grads_norm = 3.4918
	sim_grads_norm_tr = 0.0352
-- Starting training on experience 895 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9566
	data_grads_norm = 4.2001
	new_data_grads_norm = 6.2420
	old_data_grads_norm = 4.3579
	sim_grads_norm_tr = -0.0365
-- Starting training on experience 896 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7322
	data_grads_norm = 3.9144
	new_data_grads_norm = 6.3256
	old_data_grads_norm = 3.7581
	sim_grads_norm_tr = 0.0436
-- Starting training on experience 897 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5282
	data_grads_norm = 4.1680
	new_data_grads_norm = 6.2793
	old_data_grads_norm = 4.6177
	sim_grads_norm_tr = -0.0620
-- Starting training on experience 898 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4949
	data_grads_norm = 3.6362
	new_data_grads_norm = 7.3036
	old_data_grads_norm = 4.1062
	sim_grads_norm_tr = -0.0371
-- Starting training on experience 899 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.1210
	data_grads_norm = 4.1279
	new_data_grads_norm = 6.0691
	old_data_grads_norm = 5.1343
	sim_grads_norm_tr = 0.0134
-- Starting training on experience 900 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6348
	data_grads_norm = 3.9004
	new_data_grads_norm = 5.7303
	old_data_grads_norm = 4.4068
	sim_grads_norm_tr = 0.0806
-- Starting training on experience 901 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5465
	data_grads_norm = 4.3780
	new_data_grads_norm = 5.7326
	old_data_grads_norm = 6.1830
	sim_grads_norm_tr = 0.0465
-- Starting training on experience 902 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 0.9967
	data_grads_norm = 3.1001
	new_data_grads_norm = 6.4668
	old_data_grads_norm = 4.0415
	sim_grads_norm_tr = 0.0252
-- Starting training on experience 903 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6222
	data_grads_norm = 3.3975
	new_data_grads_norm = 6.0664
	old_data_grads_norm = 3.7047
	sim_grads_norm_tr = -0.0632
-- Starting training on experience 904 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9500
	data_grads_norm = 4.3152
	new_data_grads_norm = 6.5087
	old_data_grads_norm = 4.3129
	sim_grads_norm_tr = 0.0641
-- Starting training on experience 905 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8716
	data_grads_norm = 4.6261
	new_data_grads_norm = 7.0630
	old_data_grads_norm = 5.6598
	sim_grads_norm_tr = 0.0208
-- Starting training on experience 906 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5199
	data_grads_norm = 4.0674
	new_data_grads_norm = 5.9256
	old_data_grads_norm = 4.7015
	sim_grads_norm_tr = 0.0444
-- Starting training on experience 907 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7137
	data_grads_norm = 4.0876
	new_data_grads_norm = 6.0741
	old_data_grads_norm = 5.9903
	sim_grads_norm_tr = -0.0376
-- Starting training on experience 908 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.4637
	data_grads_norm = 5.3234
	new_data_grads_norm = 7.1656
	old_data_grads_norm = 6.5644
	sim_grads_norm_tr = 0.3522
-- Starting training on experience 909 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3530
	data_grads_norm = 3.3275
	new_data_grads_norm = 5.4507
	old_data_grads_norm = 3.1013
	sim_grads_norm_tr = 0.0208
-- Starting training on experience 910 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3940
	data_grads_norm = 3.4887
	new_data_grads_norm = 4.5449
	old_data_grads_norm = 5.7855
	sim_grads_norm_tr = -0.0338
-- Starting training on experience 911 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7989
	data_grads_norm = 3.3401
	new_data_grads_norm = 5.9302
	old_data_grads_norm = 3.7832
	sim_grads_norm_tr = -0.0145
-- Starting training on experience 912 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4948
	data_grads_norm = 3.6600
	new_data_grads_norm = 5.6072
	old_data_grads_norm = 4.3915
	sim_grads_norm_tr = 0.0423
-- Starting training on experience 913 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6232
	data_grads_norm = 3.8675
	new_data_grads_norm = 4.9197
	old_data_grads_norm = 5.7897
	sim_grads_norm_tr = -0.0304
-- Starting training on experience 914 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2937
	data_grads_norm = 2.6679
	new_data_grads_norm = 5.5950
	old_data_grads_norm = 3.1196
	sim_grads_norm_tr = 0.0304
-- Starting training on experience 915 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3007
	data_grads_norm = 3.3377
	new_data_grads_norm = 6.0822
	old_data_grads_norm = 2.6145
	sim_grads_norm_tr = 0.0640
-- Starting training on experience 916 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5305
	data_grads_norm = 3.3475
	new_data_grads_norm = 5.3511
	old_data_grads_norm = 3.8275
	sim_grads_norm_tr = -0.0080
-- Starting training on experience 917 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8643
	data_grads_norm = 3.6624
	new_data_grads_norm = 5.6388
	old_data_grads_norm = 3.8630
	sim_grads_norm_tr = -0.0411
-- Starting training on experience 918 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6114
	data_grads_norm = 3.8641
	new_data_grads_norm = 5.3160
	old_data_grads_norm = 5.3470
	sim_grads_norm_tr = -0.0869
-- Starting training on experience 919 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7788
	data_grads_norm = 3.4812
	new_data_grads_norm = 5.9489
	old_data_grads_norm = 3.2575
	sim_grads_norm_tr = 0.0215
-- Starting training on experience 920 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4971
	data_grads_norm = 3.6213
	new_data_grads_norm = 5.8239
	old_data_grads_norm = 4.3645
	sim_grads_norm_tr = -0.0598
-- Starting training on experience 921 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.3083
	data_grads_norm = 3.4755
	new_data_grads_norm = 5.6963
	old_data_grads_norm = 3.4450
	sim_grads_norm_tr = 0.0199
-- Starting training on experience 922 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8146
	data_grads_norm = 4.0288
	new_data_grads_norm = 5.7806
	old_data_grads_norm = 5.5150
	sim_grads_norm_tr = 0.1083
-- Starting training on experience 923 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8875
	data_grads_norm = 4.0833
	new_data_grads_norm = 6.3542
	old_data_grads_norm = 5.2069
	sim_grads_norm_tr = -0.0310
-- Starting training on experience 924 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7491
	data_grads_norm = 3.5877
	new_data_grads_norm = 5.3808
	old_data_grads_norm = 4.1113
	sim_grads_norm_tr = 0.0142
-- Starting training on experience 925 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9965
	data_grads_norm = 3.6469
	new_data_grads_norm = 6.1894
	old_data_grads_norm = 4.1617
	sim_grads_norm_tr = 0.0648
-- Starting training on experience 926 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7040
	data_grads_norm = 3.5761
	new_data_grads_norm = 5.1015
	old_data_grads_norm = 3.8839
	sim_grads_norm_tr = 0.1365
-- Starting training on experience 927 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7111
	data_grads_norm = 3.4998
	new_data_grads_norm = 5.5933
	old_data_grads_norm = 4.1403
	sim_grads_norm_tr = 0.1406
-- Starting training on experience 928 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7728
	data_grads_norm = 3.3936
	new_data_grads_norm = 5.3882
	old_data_grads_norm = 4.4431
	sim_grads_norm_tr = -0.1237
-- Starting training on experience 929 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8205
	data_grads_norm = 3.8482
	new_data_grads_norm = 5.5112
	old_data_grads_norm = 5.2906
	sim_grads_norm_tr = -0.0861
-- Starting training on experience 930 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9964
	data_grads_norm = 3.8726
	new_data_grads_norm = 6.4019
	old_data_grads_norm = 5.2029
	sim_grads_norm_tr = -0.0440
-- Starting training on experience 931 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9974
	data_grads_norm = 4.4645
	new_data_grads_norm = 5.5562
	old_data_grads_norm = 5.4339
	sim_grads_norm_tr = 0.3817
-- Starting training on experience 932 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4555
	data_grads_norm = 3.0836
	new_data_grads_norm = 4.8577
	old_data_grads_norm = 4.1290
	sim_grads_norm_tr = 0.0267
-- Starting training on experience 933 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.2573
	data_grads_norm = 2.6267
	new_data_grads_norm = 4.9766
	old_data_grads_norm = 3.3108
	sim_grads_norm_tr = -0.1972
-- Starting training on experience 934 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4701
	data_grads_norm = 2.5607
	new_data_grads_norm = 6.3272
	old_data_grads_norm = 2.4965
	sim_grads_norm_tr = -0.0215
-- Starting training on experience 935 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7631
	data_grads_norm = 3.5270
	new_data_grads_norm = 5.0937
	old_data_grads_norm = 4.9150
	sim_grads_norm_tr = -0.0283
-- Starting training on experience 936 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4741
	data_grads_norm = 3.3262
	new_data_grads_norm = 5.0908
	old_data_grads_norm = 3.8460
	sim_grads_norm_tr = -0.0236
-- Starting training on experience 937 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5459
	data_grads_norm = 3.2650
	new_data_grads_norm = 6.2551
	old_data_grads_norm = 3.9315
	sim_grads_norm_tr = 0.0028
-- Starting training on experience 938 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6287
	data_grads_norm = 3.5265
	new_data_grads_norm = 5.6284
	old_data_grads_norm = 4.4501
	sim_grads_norm_tr = 0.1248
-- Starting training on experience 939 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.4448
	data_grads_norm = 3.2443
	new_data_grads_norm = 5.8468
	old_data_grads_norm = 2.8225
	sim_grads_norm_tr = -0.0288
-- Starting training on experience 940 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6363
	data_grads_norm = 3.2548
	new_data_grads_norm = 5.2738
	old_data_grads_norm = 3.4886
	sim_grads_norm_tr = -0.0511
-- Starting training on experience 941 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.8049
	data_grads_norm = 3.5588
	new_data_grads_norm = 6.1579
	old_data_grads_norm = 3.9453
	sim_grads_norm_tr = -0.0603
-- Starting training on experience 942 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5420
	data_grads_norm = 3.7410
	new_data_grads_norm = 5.5810
	old_data_grads_norm = 3.9971
	sim_grads_norm_tr = -0.1094
-- Starting training on experience 943 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.6249
	data_grads_norm = 3.3740
	new_data_grads_norm = 6.1345
	old_data_grads_norm = 3.2123
	sim_grads_norm_tr = -0.0016
-- Starting training on experience 944 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.9015
	data_grads_norm = 3.3681
	new_data_grads_norm = 6.2521
	old_data_grads_norm = 4.0545
	sim_grads_norm_tr = -0.0980
-- Starting training on experience 945 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.0380
	data_grads_norm = 4.2901
	new_data_grads_norm = 6.3383
	old_data_grads_norm = 4.6703
	sim_grads_norm_tr = 0.0823
-- Starting training on experience 946 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.3360
	data_grads_norm = 4.3130
	new_data_grads_norm = 6.0638
	old_data_grads_norm = 5.2757
	sim_grads_norm_tr = 0.0789
-- Starting training on experience 947 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.7619
	data_grads_norm = 3.6552
	new_data_grads_norm = 5.8946
	old_data_grads_norm = 3.6269
	sim_grads_norm_tr = 0.0117
-- Starting training on experience 948 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 2.2994
	data_grads_norm = 4.8521
	new_data_grads_norm = 6.9349
	old_data_grads_norm = 5.1610
	sim_grads_norm_tr = 0.2915
-- Starting training on experience 949 (Task 0) from train stream --
Epoch 0 ended.
	Loss_Epoch/train_phase/train_stream/Task000 = 1.5788
	data_grads_norm = 3.9164
	new_data_grads_norm = 6.0732
	old_data_grads_norm = 3.9378
	sim_grads_norm_tr = 0.0668
-- >> End of training phase << --
-- >> Start of eval phase << --
-- Starting eval on experience 0 (Task 0) from test stream --
> Eval on experience 0 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp000 = 1.1782
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.2150
	mb_index = 4750
	time = 2653.5309
-- Starting eval on experience 1 (Task 0) from test stream --
> Eval on experience 1 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp001 = 1.8003
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.1450
-- Starting eval on experience 2 (Task 0) from test stream --
> Eval on experience 2 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp002 = 1.5335
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.2300
-- Starting eval on experience 3 (Task 0) from test stream --
> Eval on experience 3 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp003 = 1.9529
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.1495
-- Starting eval on experience 4 (Task 0) from test stream --
> Eval on experience 4 (Task 0) from test stream ended.
	Loss_Exp/eval_phase/test_stream/Task000/Exp004 = 1.6089
	Top1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0825
-- >> End of eval phase << --
	CumulativeAccuracy/eval_phase/test_stream/Exp000 = 0.6200
	CumulativeAccuracy/eval_phase/test_stream/Exp001 = 0.3553
	CumulativeAccuracy/eval_phase/test_stream/Exp002 = 0.2613
	CumulativeAccuracy/eval_phase/test_stream/Exp003 = 0.2061
	CumulativeAccuracy/eval_phase/test_stream/Exp004 = 0.1644
	Loss_Stream/eval_phase/test_stream/Task000 = 1.6148
	Top1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1644
	ValidStream/mean_grads_norm_iter = 6.1305
